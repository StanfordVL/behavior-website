<div class="section features-3 my-5 fullWidth" style="background-image: url(' {{ /assets/img/ill/p31.svg | relative_url }}')">
  <div class="container">
    <div class="row text-center justify-content-center">
      <div class="col-lg-8">
        <h3 class="display-3 text-white">Components of BEHAVIOR-100</h3>
        <br>
      </div>
      <div>
        <div class="col">
          <div class="info info-horizontal bg-white">
            <div class="icon icon-lg icon-shape icon-shape-primary shadow rounded-circle">
              <i class="ni ni-active-40 text-info"></i>
            </div>
            <div class="description pl-4">
              <h6 class="title text-info">BDDL for BEHAVIOR-100</h6>
              <p class="description opacity-8">The BDDL codebase contains the BEHAVIOR-100 activity definitions and code for loading the definitions to be usable with iGibson 2.0 or any other simulator that can similarly support all the involved predicates. The BDDL codebase interfaces with the simulator to sample the initial scene, check at each timestep to see if the goal is satisfied, and solve the goal to get ground solution states.</p>
              <span><a href="https://github.com/StanfordVL/bddl" class="text-info">BDDL code and documentation</a></span>
            </div>
          </div>
        </div>
        <div class="col">
          <p>BDDL example to go here</p>
        </div>
        <div class="w-100"></div>
        <div class="col">
          <div class="info info-horizontal bg-white">
            <div class="icon icon-lg icon-shape icon-shape-primary shadow rounded-circle">
              <i class="ni ni-istanbul text-warning"></i>
            </div>
            <div class="description pl-4">
              <h6 class="title text-warning">iGibson 2.0</h6>
              <p class="description opacity-8">iGibson is a simulation environment providing fast visual rendering and physics simulation based on Bullet. It has fifteen fully interactive high quality scenes, powerful rigid-body physics simulation, and support for nonkinematic actions like slicing objects, cleaning stains off them, cooking a food item, and more, supporting all BEHAVIOR-100 activities. iGibson 2.0 includes domain randomization, integration with motion planners, and easy-to-use tools to collect human demonstrations.</p>
              <span><a href="https://github.com/StanfordVL/iGibson" class="text-warning">iGibson 2.0 code</a> | <a href="http://svl.stanford.edu/igibson/docs/" class="text-warning">iGibson 2.0 documentation</a></span>
            </div>
          </div>
        </div>
        <div class="w-100"></div>
        <div class="col">
          <p>iGibson video to go here</p>
        </div>
        <div class="col">
          <div class="info info-horizontal bg-white">
            <div class="icon icon-lg icon-shape icon-shape-primary shadow rounded-circle">
              <i class="ni ni-trophy text-danger"></i>
            </div>
            <div class="description pl-4">
              <h6 class="title text-danger">VR Demonstrations</h6>
              <p class="description opacity-8">BEHAVIOR-100 includes a dataset of 500 VR demonstrations. Each BEHAVIOR-100 activity is demonstrated five times: three times in the same scene and instantiation, showing variation from execution; once in the same scene with a different instantiation; and once in a different scene. Demonstrators in VR have embodiment identical to one of BEHAVIOR-100's embodiments</p>
              <span><a href="/_pages/vr-demos.md" class="text-danger">VR demo download guide</a></span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
