var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"getting_started/building_blocks.html","title":"\ud83e\uddf1 Building Blocks","text":"<p><code>OmniGibson</code> ships with many demo scripts highlighting its modularity and diverse feature set intended as a set of building blocks enabling your research. Let's try them out!</p>"},{"location":"getting_started/building_blocks.html#a-quick-word-about-macros","title":"\u2699\ufe0f A quick word about macros","text":"Why macros? <p>Macros enforce global behavior that is consistent within an individual python process but can differ between processes. This is useful because globally enabling all of <code>OmniGibson</code>'s features can cause unecessary slowdowns (1), and so configuring the macros for your specific use case can optimize performance.</p> <ol> <li>For example, Omniverse provides a so-called <code>flatcache</code> feature which provides significant performance boosts, but cannot be used when fluids or soft bodies are present. So, we ideally should always have <code>gm.USE_FLATCACHE=True</code> unless we have fluids or soft bodies in our environment.</li> </ol> <p><code>macros</code> define a globally available set of magic numbers or flags set throughout <code>OmniGibson</code>. These can either be directly set in <code>omnigibson.macros.py</code>, or can be programmatically modified at runtime via:</p> <pre><code>from omnigibson.macros import gm, macros\ngm.&lt;GLOBAL_MACRO&gt; = &lt;VALUE&gt; # (1)!\nmacros.&lt;OG_DIRECTORY&gt;.&lt;OG_MODULE&gt;.&lt;MODULE_MACRO&gt; = &lt;VALUE&gt; # (2)!\n</code></pre> <ol> <li><code>gm</code> refers to the \"global\" macros -- i.e.: settings that generally impact the entire <code>OmniGibson</code> stack. These are usually the only settings you may need to modify.</li> <li><code>macros</code> captures all remaining macros defined throughout <code>OmniGibson</code>'s codebase -- these are often hardcoded default settings or magic numbers defined in a specific module. These can also be overridden, but we recommend inspecting the module first to understand how it is used.</li> </ol> <p>Many of our examples set various <code>macros</code> settings at the beginning of the script, and is a good way to understand use cases for modifying them!</p>"},{"location":"getting_started/building_blocks.html#environments","title":"\ud83c\udf0e Environments","text":"<p>These examples showcase the full <code>OmniGibson</code> stack in use, and the types of environments immediately supported.</p>"},{"location":"getting_started/building_blocks.html#behavior-task-demo","title":"BEHAVIOR Task Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to instantiate a BEHAVIOR task</li> <li>Understanding how a pre-defined configuration file is used</li> </ul> <pre><code>python -m omnigibson.examples.environments.behavior_env_demo\n</code></pre> <p>This demo instantiates one of our BEHAVIOR tasks (and optionally sampling object locations online) in a fully-populated scene and loads a <code>Fetch</code> robot. The robot executes random actions and the environment is reset periodically.</p> behavior_env_demo.py <pre><code>import os\nimport yaml\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.ui_utils import choose_from_options\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Generates a BEHAVIOR Task environment in an online fashion.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Ask the user whether they want online object sampling or not\nsampling_options = {\n# False: \"Use a pre-sampled cached BEHAVIOR activity scene\", # TODO: Add the file needed in dataset\nTrue: \"Sample the BEHAVIOR activity in an online fashion\",\n}\nshould_sample = choose_from_options(options=sampling_options, name=\"online object sampling\", random_selection=random_selection)\n# Load the pre-selected configuration and set the online_sampling flag\nconfig_filename = os.path.join(og.example_config_path, \"fetch_behavior.yaml\")\ncfg = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\ncfg[\"task\"][\"online_object_sampling\"] = should_sample\n# Load the environment\nenv = og.Environment(configs=cfg)\n# Allow user to move camera more easily\nog.sim.enable_viewer_camera_teleoperation()\n# Run a simple loop and reset periodically\nmax_iterations = 10 if not short_exec else 1\nfor j in range(max_iterations):\nog.log.info(\"Resetting environment\")\nenv.reset()\nfor i in range(100):\naction = env.action_space.sample()\nstate, reward, done, info = env.step(action)\nif done:\nog.log.info(\"Episode finished after {} timesteps\".format(i + 1))\nbreak\n# Always close the environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#navigation-task-demo","title":"Navigation Task Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to instantiate a navigation task</li> <li>Understanding how a pre-defined configuration file is used</li> </ul> <pre><code>python -m omnigibson.examples.environments.navigation_env_demo\n</code></pre> <p>This demo instantiates one of our navigation tasks in a fully-populated scene and loads a <code>Turtlebot</code> robot. The robot executes random actions and the environment is reset periodically.</p> navigation_env_demo.py <pre><code>import os\nimport yaml\nimport omnigibson as og\nfrom omnigibson.utils.ui_utils import choose_from_options\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select a type of scene and loads a turtlebot into it, generating a Point-Goal navigation\n    task within the environment.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Load the config\nconfig_filename = os.path.join(og.example_config_path, f\"turtlebot_nav.yaml\")\nconfig = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n# check if we want to quick load or full load the scene\nload_options = {\n\"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n\"Full\": \"Load all interactive objects in the scene\",\n}\nload_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\nif load_mode == \"Quick\":\nconfig[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n# Load the environment\nenv = og.Environment(configs=config)\n# Allow user to move camera more easily\nog.sim.enable_viewer_camera_teleoperation()\n# Run a simple loop and reset periodically\nmax_iterations = 10 if not short_exec else 1\nfor j in range(max_iterations):\nog.log.info(\"Resetting environment\")\nenv.reset()\nfor i in range(100):\naction = env.action_space.sample()\nstate, reward, done, info = env.step(action)\nif done:\nog.log.info(\"Episode finished after {} timesteps\".format(i + 1))\nbreak\n# Always close the environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#learning","title":"\ud83e\uddd1\u200d\ud83c\udfeb Learning","text":"<p>These examples showcase how <code>OmniGibson</code> can be used to train embodied AI agents.</p>"},{"location":"getting_started/building_blocks.html#reinforcement-learning-demo","title":"Reinforcement Learning Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to hook up <code>OmniGibson</code> to an external algorithm</li> <li>Understanding how to train and evaluate a policy</li> </ul> <pre><code>python -m omnigibson.examples.learning.navigation_policy_demo\n</code></pre> <p>This demo loads a BEHAVIOR task with a <code>Fetch</code> robot, and trains / evaluates the agent using Stable Baseline3's PPO algorithm.</p> navigation_policy_demo.py <pre><code>\"\"\"\nExample training code using stable-baselines3 PPO for one BEHAVIOR activity.\nNote that due to the sparsity of the reward, this training code will not converge and achieve task success.\nThis only serves as a starting point that users can further build upon.\n\"\"\"\nimport argparse\nimport os, time, cv2\nimport yaml\nimport omnigibson as og\nfrom omnigibson import example_config_path\nfrom omnigibson.macros import gm\ntry:\nimport gym\nimport torch as th\nimport torch.nn as nn\nimport tensorboard\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.preprocessing import maybe_transpose\nfrom stable_baselines3.common.torch_layers import BaseFeaturesExtractor\nfrom stable_baselines3.common.utils import set_random_seed\nfrom stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\nexcept ModuleNotFoundError:\nog.log.error(\"torch, stable-baselines3, or tensorboard is not installed. \"\n\"See which packages are missing, and then run the following for any missing packages:\\n\"\n\"pip install torch\\n\"\n\"pip install stable-baselines3==1.7.0\\n\"\n\"pip install tensorboard\\n\"\n\"Also, please update gym to 0.26.1 after installing sb3: pip install gym==0.26.1\")\nexit(1)\nassert gym.__version__ == '0.26.1', \"Please install/update gym to version 0.26.1\"\n# We don't need object states nor transitions rules, so we disable them now, and also enable flatcache for maximum speed\ngm.ENABLE_OBJECT_STATES = False\ngm.ENABLE_TRANSITION_RULES = False\ngm.ENABLE_FLATCACHE = True\nclass CustomCombinedExtractor(BaseFeaturesExtractor):\ndef __init__(self, observation_space: gym.spaces.Dict):\n# We do not know features-dim here before going over all the items,\n# so put something dummy for now. PyTorch requires calling\nsuper().__init__(observation_space, features_dim=1)\nextractors = {}\nself.step_index = 0\nself.img_save_dir = 'img_save_dir'\nos.makedirs(self.img_save_dir, exist_ok=True)\ntotal_concat_size = 0\nfeature_size = 128\nfor key, subspace in observation_space.spaces.items():\n# For now, only keep RGB observations\nif \"rgb\" in key:\nog.log.info(f\"obs {key} shape: {subspace.shape}\")\nn_input_channels = subspace.shape[0]  # channel first\ncnn = nn.Sequential(\nnn.Conv2d(n_input_channels, 4, kernel_size=8, stride=4, padding=0),\nnn.ReLU(),\nnn.MaxPool2d(2),\nnn.Conv2d(4, 8, kernel_size=4, stride=2, padding=0),\nnn.ReLU(),\nnn.MaxPool2d(2),\nnn.Conv2d(8, 4, kernel_size=3, stride=1, padding=0),\nnn.ReLU(),\nnn.Flatten(),\n)\ntest_tensor = th.zeros(subspace.shape)\nwith th.no_grad():\nn_flatten = cnn(test_tensor[None]).shape[1]\nfc = nn.Sequential(nn.Linear(n_flatten, feature_size), nn.ReLU())\nextractors[key] = nn.Sequential(cnn, fc)\ntotal_concat_size += feature_size\nself.extractors = nn.ModuleDict(extractors)\n# Update the features dim manually\nself._features_dim = total_concat_size\ndef forward(self, observations) -&gt; th.Tensor:\nencoded_tensor_list = []\nself.step_index += 1\n# self.extractors contain nn.Modules that do all the processing.\nfor key, extractor in self.extractors.items():\nencoded_tensor_list.append(extractor(observations[key]))\nfeature = th.cat(encoded_tensor_list, dim=1)\nreturn feature\ndef main():\n# Parse args\nparser = argparse.ArgumentParser(description=\"Train or evaluate a PPO agent in BEHAVIOR\")\nparser.add_argument(\n\"--checkpoint\",\ntype=str,\ndefault=None,\nhelp=\"Absolute path to desired PPO checkpoint to load for evaluation\",\n)\nparser.add_argument(\n\"--eval\",\naction=\"store_true\",\nhelp=\"If set, will evaluate the PPO agent found from --checkpoint\",\n)\nargs = parser.parse_args()\ntensorboard_log_dir = os.path.join(\"log_dir\", time.strftime(\"%Y%m%d-%H%M%S\"))\nos.makedirs(tensorboard_log_dir, exist_ok=True)\nprefix = ''\nseed = 0\n# Load config\nwith open(f\"{example_config_path}/turtlebot_nav.yaml\", \"r\") as f:\ncfg = yaml.load(f, Loader=yaml.FullLoader)\n# Only use RGB obs\ncfg[\"robots\"][0][\"obs_modalities\"] = [\"rgb\"]\n# If we're not eval, turn off the start / goal markers so the agent doesn't see them\nif not args.eval:\ncfg[\"task\"][\"visualize_goal\"] = False\nenv = og.Environment(\nconfigs=cfg,\naction_timestep=1 / 60.,\nphysics_timestep=1 / 60.,\nflatten_action_space=True,\nflatten_obs_space=True,\n)\n# If we're evaluating, hide the ceilings and enable camera teleoperation so the user can easily\n# visualize the rollouts dynamically\nif args.eval:\nceiling = env.scene.object_registry(\"name\", \"ceilings\")\nceiling.visible = False\nog.sim.enable_viewer_camera_teleoperation()\n# Set the set\nset_random_seed(seed)\nenv.reset()\npolicy_kwargs = dict(\nfeatures_extractor_class=CustomCombinedExtractor,\n)\nos.makedirs(tensorboard_log_dir, exist_ok=True)\nif args.eval:\nassert args.checkpoint is not None, \"If evaluating a PPO policy, @checkpoint argument must be specified!\"\nmodel = PPO.load(args.checkpoint)\nog.log.info(\"Starting evaluation...\")\nmean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=50)\nog.log.info(\"Finished evaluation!\")\nog.log.info(f\"Mean reward: {mean_reward} +/- {std_reward:.2f}\")\nelse:\nmodel = PPO(\n\"MultiInputPolicy\",\nenv,\nverbose=1,\ntensorboard_log=tensorboard_log_dir,\npolicy_kwargs=policy_kwargs,\nn_steps=20 * 10,\nbatch_size=8,\ndevice='cuda',\n)\ncheckpoint_callback = CheckpointCallback(save_freq=1000, save_path=tensorboard_log_dir, name_prefix=prefix)\neval_callback = EvalCallback(eval_env=env, eval_freq=1000, n_eval_episodes=20)\ncallback = CallbackList([checkpoint_callback, eval_callback])\nog.log.debug(model.policy)\nog.log.info(f\"model: {model}\")\nog.log.info(\"Starting training...\")\nmodel.learn(\ntotal_timesteps=10000000,\ncallback=callback,\n)\nog.log.info(\"Finished training!\")\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#scenes","title":"\ud83c\udfd4\ufe0f Scenes","text":"<p>These examples showcase how to leverage <code>OmniGibson</code>'s large-scale, diverse scenes shipped with the BEHAVIOR dataset.</p>"},{"location":"getting_started/building_blocks.html#scene-selector-demo","title":"Scene Selector Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load a scene into <code>OmniGibson</code></li> <li>Accessing all BEHAVIOR dataset scenes</li> </ul> <pre><code>python -m omnigibson.examples.scenes.scene_selector\n</code></pre> <p>This demo lets you choose a scene from the BEHAVIOR dataset, loads it along with a <code>Turtlebot</code> robot, and cycles the resulting environment periodically.</p> scene_selector.py <pre><code>import omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.asset_utils import get_available_g_scenes, get_available_og_scenes\nfrom omnigibson.utils.ui_utils import choose_from_options\n# Configure macros for maximum performance\ngm.USE_GPU_DYNAMICS = True\ngm.ENABLE_FLATCACHE = True\ngm.ENABLE_OBJECT_STATES = False\ngm.ENABLE_TRANSITION_RULES = False\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select any available interactive scene and loads a turtlebot into it.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose the scene type to load\nscene_options = {\n\"InteractiveTraversableScene\": \"Procedurally generated scene with fully interactive objects\",\n# \"StaticTraversableScene\": \"Monolithic scene mesh with no interactive objects\",\n}\nscene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n# Choose the scene model to load\nscenes = get_available_og_scenes() if scene_type == \"InteractiveTraversableScene\" else get_available_g_scenes()\nscene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\ncfg = {\n\"scene\": {\n\"type\": scene_type,\n\"scene_model\": scene_model,\n},\n\"robots\": [\n{\n\"type\": \"Turtlebot\",\n\"obs_modalities\": [\"scan\", \"rgb\", \"depth\"],\n\"action_type\": \"continuous\",\n\"action_normalize\": True,\n},\n],\n}\n# If the scene type is interactive, also check if we want to quick load or full load the scene\nif scene_type == \"InteractiveTraversableScene\":\nload_options = {\n\"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n\"Full\": \"Load all interactive objects in the scene\",\n}\nload_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\nif load_mode == \"Quick\":\ncfg[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n# Load the environment\nenv = og.Environment(configs=cfg)\n# Allow user to move camera more easily\nif not gm.HEADLESS:\nog.sim.enable_viewer_camera_teleoperation()\n# Run a simple loop and reset periodically\nmax_iterations = 10 if not short_exec else 1\nfor j in range(max_iterations):\nog.log.info(\"Resetting environment\")\nenv.reset()\nfor i in range(100):\naction = env.action_space.sample()\nstate, reward, done, info = env.step(action)\nif done:\nog.log.info(\"Episode finished after {} timesteps\".format(i + 1))\nbreak\n# Always close the environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#scene-tour-demo","title":"Scene Tour Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load a scene into <code>OmniGibson</code></li> <li>Understanding how to generate a trajectory from a set of waypoints</li> </ul> <pre><code>python -m omnigibson.examples.scenes.scene_selector\n</code></pre> <p>This demo lets you choose a scene from the BEHAVIOR dataset. It allows you to move the camera using the keyboard, select waypoints, and then programmatically generates a video trajectory from the selected waypoints</p> scene_tour_demo.py <pre><code>import numpy as np\nimport carb.input\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.asset_utils import get_available_g_scenes, get_available_og_scenes\nfrom omnigibson.utils.ui_utils import choose_from_options, KeyboardEventHandler\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select any available interactive scene and loads it.\n    It sets the camera to various poses and records images, and then generates a trajectory from a set of waypoints\n    and records the resulting video.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Make sure the example is not being run headless. If so, terminate early\nif gm.HEADLESS:\nprint(\"This demo should only be run not headless! Exiting early.\")\nog.shutdown()\n# Choose the scene type to load\nscene_options = {\n\"InteractiveTraversableScene\": \"Procedurally generated scene with fully interactive objects\",\n# \"StaticTraversableScene\": \"Monolithic scene mesh with no interactive objects\",\n}\nscene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n# Choose the scene model to load\nscenes = get_available_og_scenes() if scene_type == \"InteractiveTraversableScene\" else get_available_g_scenes()\nscene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\nprint(f\"scene model: {scene_model}\")\ncfg = {\n\"scene\": {\n\"type\": scene_type,\n\"scene_model\": scene_model,\n},\n}\n# If the scene type is interactive, also check if we want to quick load or full load the scene\nif scene_type == \"InteractiveTraversableScene\":\nload_options = {\n\"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n\"Full\": \"Load all interactive objects in the scene\",\n}\nload_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\nif load_mode == \"Quick\":\ncfg[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n# Load the environment\nenv = og.Environment(configs=cfg)\n# Allow user to teleoperate the camera\ncam_mover = og.sim.enable_viewer_camera_teleoperation()\n# Create a keyboard event handler for generating waypoints\nwaypoints = []\ndef add_waypoint():\nnonlocal waypoints\npos = cam_mover.cam.get_position()\nprint(f\"Added waypoint at {pos}\")\nwaypoints.append(pos)\ndef clear_waypoints():\nnonlocal waypoints\nprint(f\"Cleared all waypoints!\")\nwaypoints = []\nKeyboardEventHandler.initialize()\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.X,\ncallback_fn=add_waypoint,\n)\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.C,\ncallback_fn=clear_waypoints,\n)\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.J,\ncallback_fn=lambda: cam_mover.record_trajectory_from_waypoints(\nwaypoints=np.array(waypoints),\nper_step_distance=0.02,\nfps=30,\nsteps_per_frame=1,\nfpath=None,             # This corresponds to the default path inferred from cam_mover.save_dir\n),\n)\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.ESCAPE,\ncallback_fn=lambda: env.close(),\n)\n# Print out additional keyboard commands\nprint(f\"\\t X: Save the current camera pose as a waypoint\")\nprint(f\"\\t C: Clear all waypoints\")\nprint(f\"\\t J: Record the camera trajectory from the current set of waypoints\")\nprint(f\"\\t ESC: Terminate the demo\")\n# Loop indefinitely\nwhile True:\nenv.step([])\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#traversability-map-demo","title":"Traversability Map Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to leverage traversability map information from BEHAVIOR dataset scenes</li> </ul> <pre><code>python -m omnigibson.examples.scenes.traversability_map_example\n</code></pre> <p>This demo lets you choose a scene from the BEHAVIOR dataset, and generates its corresponding traversability map.</p> traversability_map_example.py <pre><code>import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport omnigibson as og\nfrom omnigibson.utils.asset_utils import get_og_scene_path, get_available_og_scenes\nfrom omnigibson.utils.ui_utils import choose_from_options\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Traversable map demo\n    Loads the floor plan and obstacles for the requested scene, and overlays them in a visual figure such that the\n    highlighted area reflects the traversable (free-space) area\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\nscenes = get_available_og_scenes()\nscene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\nprint(f\"Generating traversability map for scene {scene_model}\")\ntrav_map_size = 200\ntrav_map_erosion = 2\ntrav_map = Image.open(os.path.join(get_og_scene_path(scene_model), \"layout\", \"floor_trav_0.png\"))\ntrav_map = np.array(trav_map.resize((trav_map_size, trav_map_size)))\ntrav_map = cv2.erode(trav_map, np.ones((trav_map_erosion, trav_map_erosion)))\nif not headless:\nplt.figure(figsize=(12, 12))\nplt.imshow(trav_map)\nplt.title(f\"Traversable area of {scene_model} scene\")\nif not headless:\nplt.show()\n# Shut down omnigibson at the end\nog.shutdown()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#objects","title":"\ud83c\udfbe Objects","text":"<p>These examples showcase how to leverage objects in <code>OmniGibson</code>.</p>"},{"location":"getting_started/building_blocks.html#load-object-demo","title":"Load Object Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load an object into <code>OmniGibson</code></li> <li>Accessing all BEHAVIOR dataset asset categories and models</li> </ul> <pre><code>python -m omnigibson.examples.objects.load_object_selector\n</code></pre> <p>This demo lets you choose a specific object from the BEHAVIOR dataset, and loads the requested object into an environment.</p> load_object_selector.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson.utils.asset_utils import (\nget_all_object_categories,\nget_og_avg_category_specs,\nget_object_models_of_category,\n)\nfrom omnigibson.utils.ui_utils import choose_from_options\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    This demo shows how to load any scaled objects from the OG object model dataset\n    The user selects an object model to load\n    The objects can be loaded into an empty scene or an interactive scene (OG)\n    The example also shows how to use the Environment API or directly the Simulator API, loading objects and robots\n    and executing actions\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\nscene_options = [\"Scene\", \"InteractiveTraversableScene\"]\nscene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n# -- Choose the object to load --\n# Select a category to load\navailable_obj_categories = get_all_object_categories()\nobj_category = choose_from_options(options=available_obj_categories, name=\"object category\", random_selection=random_selection)\n# Select a model to load\navailable_obj_models = get_object_models_of_category(obj_category)\nobj_model = choose_from_options(options=available_obj_models, name=\"object model\", random_selection=random_selection)\n# Load the specs of the object categories, e.g., common scaling factor\navg_category_spec = get_og_avg_category_specs()\n# Create and load this object into the simulator\nobj_cfg = dict(\ntype=\"DatasetObject\",\nname=\"obj\",\ncategory=obj_category,\nmodel=obj_model,\nbounding_box=avg_category_spec.get(obj_category),\nfit_avg_dim_volume=True,\nposition=[0, 0, 50.0],\n)\ncfg = {\n\"scene\": {\n\"type\": scene_type,\n},\n\"objects\": [obj_cfg],\n}\nif scene_type == \"InteractiveTraversableScene\":\ncfg[\"scene\"][\"scene_model\"] = \"Rs_int\"\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Place the object so it rests on the floor\nobj = env.scene.object_registry(\"name\", \"obj\")\ncenter_offset = obj.get_position() - obj.aabb_center + np.array([0, 0, obj.aabb_extent[2] / 2.0])\nobj.set_position(center_offset)\n# Step through the environment\nmax_steps = 100 if short_exec else 10000\nfor i in range(max_steps):\nenv.step(np.array([]))\n# Always close the environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#object-visualizer-demo","title":"Object Visualizer Demo","text":"<p>This demo is useful for...</p> <ul> <li>Viewing objects' textures as rendered in <code>OmniGibson</code></li> <li>Viewing articulated objects' range of motion</li> <li>Understanding how to reference object instances from the environment</li> <li>Understanding how to set object poses and joint states</li> </ul> <pre><code>python -m omnigibson.examples.objects.visualize_object\n</code></pre> <p>This demo lets you choose a specific object from the BEHAVIOR dataset, and rotates the object in-place. If the object is articulated, it additionally moves its joints through its full range of motion.</p> visualize_object.py <pre><code>import argparse\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson.utils.asset_utils import (\nget_all_object_categories,\nget_object_models_of_category,\n)\nfrom omnigibson.utils.ui_utils import choose_from_options\nimport omnigibson.utils.transform_utils as T\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Visualizes object as specified by its USD path, @usd_path. If None if specified, will instead\n    result in an object selection from OmniGibson's object dataset\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Assuming that if random_selection=True, headless=True, short_exec=True, we are calling it from tests and we\n# do not want to parse args (it would fail because the calling function is pytest \"testfile.py\")\nusd_path = None\nif not (random_selection and headless and short_exec):\nparser = argparse.ArgumentParser()\nparser.add_argument(\n\"--usd_path\",\ndefault=None,\nhelp=\"USD Model to load\",\n)\nargs = parser.parse_args()\nusd_path = args.usd_path\n# Define objects to load\nlight0_cfg = dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"sphere_light0\",\nradius=0.01,\nintensity=1e5,\nposition=[-2.0, -2.0, 2.0],\n)\nlight1_cfg = dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"sphere_light1\",\nradius=0.01,\nintensity=1e5,\nposition=[-2.0, 2.0, 2.0],\n)\n# Make sure we have a valid usd path\nif usd_path is None:\n# Select a category to load\navailable_obj_categories = get_all_object_categories()\nobj_category = choose_from_options(options=available_obj_categories, name=\"object category\",\nrandom_selection=random_selection)\n# Select a model to load\navailable_obj_models = get_object_models_of_category(obj_category)\nobj_model = choose_from_options(options=available_obj_models, name=\"object model\",\nrandom_selection=random_selection)\nkwargs = {\n\"type\": \"DatasetObject\",\n\"category\": obj_category,\n\"model\": obj_model,\n}\nelse:\nkwargs = {\n\"type\": \"USDObject\",\n\"usd_path\": usd_path,\n}\n# Import the desired object\nobj_cfg = dict(\n**kwargs,\nname=\"obj\",\nusd_path=usd_path,\nvisual_only=True,\nposition=[0, 0, 10.0],\n)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [light0_cfg, light1_cfg, obj_cfg],\n}\n# Create the environment\nenv = og.Environment(configs=cfg)\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.00913503, -1.95750906,  1.36407314]),\norientation=np.array([0.6350064 , 0.        , 0.        , 0.77250687]),\n)\n# Grab the object references\nobj = env.scene.object_registry(\"name\", \"obj\")\n# Standardize the scale of the object so it fits in a [1,1,1] box -- note that we have to stop the simulator\n# in order to set the scale\nextents = obj.aabb_extent\nog.sim.stop()\nobj.scale = (np.ones(3) / extents).min()\nog.sim.play()\nenv.step(np.array([]))\n# Move the object so that its center is at [0, 0, 1]\ncenter_offset = obj.get_position() - obj.aabb_center + np.array([0, 0, 1.0])\nobj.set_position(center_offset)\n# Allow the user to easily move the camera around\nog.sim.enable_viewer_camera_teleoperation()\n# Rotate the object in place\nsteps_per_rotate = 360\nsteps_per_joint = steps_per_rotate / 10\nmax_steps = 100 if short_exec else 10000\nfor i in range(max_steps):\nz_angle = (2 * np.pi * (i % steps_per_rotate) / steps_per_rotate)\nquat = T.euler2quat(np.array([0, 0, z_angle]))\npos = T.quat2mat(quat) @ center_offset\nif obj.n_dof &gt; 0:\nfrac = (i % steps_per_joint) / steps_per_joint\nj_frac = -1.0 + 2.0 * frac if (i // steps_per_joint) % 2 == 0 else 1.0 - 2.0 * frac\nobj.set_joint_positions(positions=j_frac * np.ones(obj.n_dof), normalized=True, drive=False)\nobj.keep_still()\nobj.set_position_orientation(position=pos, orientation=quat)\nenv.step(np.array([]))\n# Shut down at the end\nog.shutdown()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#highlight-object","title":"Highlight Object","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to highlight individual objects within a cluttered scene</li> <li>Understanding how to access groups of objects from the environment</li> </ul> <pre><code>python -m omnigibson.examples.objects.highlight_objects\n</code></pre> <p>This demo loads the Rs_int scene and highlights windows on/off repeatedly.</p> highlight_objects.py <pre><code>import numpy as np\nimport omnigibson as og\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Highlights visually all object instances of windows and then removes the highlighting\n    It also demonstrates how to apply an action on all instances of objects of a given category\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"InteractiveTraversableScene\",\n\"scene_model\": \"Rs_int\",\n}\n}\n# Create the environment\nenv = og.Environment(configs=cfg)\n# Grab all window objects\nwindows = og.sim.scene.object_registry(\"category\", \"window\")\n# Step environment while toggling window highlighting\ni = 0\nhighlighted = False\nmax_steps = -1 if not short_exec else 1000\nwhile i != max_steps:\nenv.step(np.array([]))\nif i % 50 == 0:\nhighlighted = not highlighted\nog.log.info(f\"Toggling window highlight to: {highlighted}\")\nfor window in windows:\n# Note that this property is R/W!\nwindow.highlighted = highlighted\ni += 1\n# Always close the environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#draw-object-bounding-box-demo","title":"Draw Object Bounding Box Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to access observations from a <code>GymObservable</code> object (1)</li> <li>Understanding how to access objects' bounding box information</li> <li>Understanding how to dynamically modify vision modalities</li> </ul> <ol> <li><code>Environment</code>, all sensors extending from <code>BaseSensor</code>, and all objects extending from <code>BaseObject</code> (which includes all robots extending from <code>BaseRobot</code>!) are <code>GymObservable</code> objects!</li> </ol> <pre><code>python -m omnigibson.examples.objects.draw_bounding_box\n</code></pre> <p>This demo loads a door object and banana object, and partially obscures the banana with the door. It generates both \"loose\" and \"tight\" bounding boxes (where the latter respects occlusions) for both objects, and dumps them to an image on disk.</p> draw_bounding_box.py <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport omnigibson as og\nfrom omni.isaac.synthetic_utils.visualization import colorize_bboxes\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Shows how to obtain the bounding box of an articulated object.\n    Draws the bounding box around the loaded object, a cabinet, and writes the visualized image to disk at the\n    current directory named 'bbox_2d_[loose / tight]_img.png'.\n    NOTE: In the GUI, bounding boxes can be natively viewed by clicking on the sensor ((*)) icon at the top,\n    and then selecting the appropriate bounding box modalities, and clicking \"Show\". See:\n    https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator/visualization.html#the-visualizer\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Specify objects to load\nbanana_cfg = dict(\ntype=\"DatasetObject\",\nname=\"banana\",\ncategory=\"banana\",\nmodel=\"vvyyyv\",\nscale=[3.0, 5.0, 2.0],\nposition=[-0.906661, -0.545106,  0.136824],\norientation=[0, 0, 0.76040583, -0.6494482 ],\n)\ndoor_cfg = dict(\ntype=\"DatasetObject\",\nname=\"door\",\ncategory=\"door\",\nmodel=\"ohagsq\",\nposition=[-2.0, 0, 0.70000001],\norientation=[0, 0, -0.38268343,  0.92387953],\n)\n# Create the scene config to load -- empty scene with a few objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [banana_cfg, door_cfg],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to appropriate viewing pose\ncam = og.sim.viewer_camera\ncam.set_position_orientation(\nposition=np.array([-4.62785 , -0.418575,  0.933943]),\norientation=np.array([ 0.52196595, -0.4231939 , -0.46640436,  0.5752612 ]),\n)\n# Add bounding boxes to camera sensor\nbbox_modalities = [\"bbox_3d\", \"bbox_2d_loose\", \"bbox_2d_tight\"]\nfor bbox_modality in bbox_modalities:\ncam.add_modality(bbox_modality)\n# Take a few steps to let objects settle\nfor i in range(100):\nenv.step(np.array([]))\n# Grab observations from viewer camera and write them to disk\nobs = cam.get_obs()\nfor bbox_modality in bbox_modalities:\n# Print out each of the modalities\nog.log.info(f\"Observation modality {bbox_modality}:\\n{obs[bbox_modality]}\")\n# Also write the 2d loose bounding box to disk\nif \"3d\" not in bbox_modality:\ncolorized_img = colorize_bboxes(bboxes_2d_data=obs[bbox_modality], bboxes_2d_rgb=obs[\"rgb\"], num_channels=4)\nfpath = f\"{bbox_modality}_img.png\"\nplt.imsave(fpath, colorized_img)\nog.log.info(f\"Saving modality [{bbox_modality}] image to: {fpath}\")\n# Always close environment down at end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#object-states","title":"\ud83c\udf21\ufe0f Object States","text":"<p>These examples showcase <code>OmniGibson</code>'s powerful object states functionality, which captures both individual and relational kinematic and non-kinematic states.</p>"},{"location":"getting_started/building_blocks.html#attachment-demo","title":"Attachment Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to leverage the <code>Attached</code> state</li> <li>Understanding how to enable objects to be <code>attachable</code></li> </ul> <pre><code>python -m omnigibson.examples.object_states.attachment_demo\n</code></pre> <p>This demo loads an apple and a fridge, and showcases how they may or may not be attached upon contact based on their assigned attachment types.</p> attachment_demo.py <pre><code>import yaml\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson.macros import gm\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of attachment of different parts of a shelf\n    \"\"\"\ncfg = yaml.load(open(f\"{og.example_config_path}/default_cfg.yaml\", \"r\"), Loader=yaml.FullLoader)\n# Add objects that we want to create\nobj_cfgs = []\nobj_cfgs.append(dict(\ntype=\"LightObject\",\nname=\"light\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=5000,\nposition=[0, 0, 1.0],\n))\nbase_z = 0.2\ndelta_z = 0.01\nidx = 0\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=\"shelf_back_panel\",\ncategory=\"shelf_back_panel\",\nmodel=\"gjsnrt\",\nposition=[0, 0, 0.01],\nabilities={\"attachable\": {}},\n))\nidx += 1\nxs = [-0.4, 0.4]\nfor i in range(2):\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=f\"shelf_side_{i}\",\ncategory=\"shelf_side\",\nmodel=\"bxfkjj\",\nposition=[xs[i], 0, base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\nys = [-0.93, -0.61, -0.29, 0.03, 0.35, 0.68]\nfor i in range(6):\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=f\"shelf_shelf_{i}\",\ncategory=\"shelf_shelf\",\nmodel=\"ymtnqa\",\nposition=[0, ys[i], base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=\"shelf_top_0\",\ncategory=\"shelf_top\",\nmodel=\"pfiole\",\nposition=[0, 1.0, base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=f\"shelf_baseboard\",\ncategory=\"shelf_baseboard\",\nmodel=\"hlhneo\",\nposition=[0, -0.97884506, base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\ncfg[\"objects\"] = obj_cfgs\nenv = og.Environment(configs=cfg)\n# Set viewer camera pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-1.689292, -2.11718198, 0.93332228]),\norientation=np.array([0.57687967, -0.22995655, -0.29022759, 0.72807814]),\n)\nfor _ in range(10):\nenv.step([])\nshelf_baseboard = og.sim.scene.object_registry(\"name\", \"shelf_baseboard\")\nshelf_baseboard.set_position_orientation([0, -0.979, 0.26], [0, 0, 0, 1])\nshelf_baseboard.keep_still()\nshelf_baseboard.set_linear_velocity([-0.2, 0, 0])\ninput(\"Shelf parts fall to their correct poses and get automatically attached to the back panel.\\n\"\n\"You can try to drag the shelf to hit the floor to break it apart. Press [ENTER] to continue.\\n\")\nfor _ in range(1000):\nog.sim.step()\nog.shutdown()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#dicing-demo","title":"Dicing Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to leverage the <code>Dicing</code> state</li> <li>Understanding how to enable objects to be <code>diceable</code></li> </ul> <pre><code>python -m omnigibson.examples.object_states.dicing_demo\n</code></pre> <p>This demo loads an apple and a knife, and showcases how apple can be diced into smaller chunks with the knife.</p> dicing_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson.macros import gm\nimport omnigibson.utils.transform_utils as T\n# Make sure object states, GPU dynamics, and transition rules are enabled\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\ngm.ENABLE_TRANSITION_RULES = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of dicing an apple into apple dices\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene with table, knife, and apple\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"rjgmmy\",\nscale=0.9,\nposition=[0, 0, 0.58],\n)\napple_cfg = dict(\ntype=\"DatasetObject\",\nname=\"apple\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nscale=1.5,\nposition=[0.085, 0,  0.92],\nabilities={\"diceable\": {}}\n)\nknife_cfg = dict(\ntype=\"DatasetObject\",\nname=\"knife\",\ncategory=\"table_knife\",\nmodel=\"lrdmpf\",\nscale=2.5,\nposition=[0, 0, 10.0],\n)\nlight0_cfg = dict(\ntype=\"LightObject\",\nname=\"light0\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=1e7,\nposition=[1.217, -0.848, 1.388],\n)\nlight1_cfg = dict(\ntype=\"LightObject\",\nname=\"light1\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=1e7,\nposition=[-1.217, 0.848, 1.388],\n)\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [table_cfg, apple_cfg, knife_cfg, light0_cfg, light1_cfg]\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Grab reference to apple and knife\napple = env.scene.object_registry(\"name\", \"apple\")\nknife = env.scene.object_registry(\"name\", \"knife\")\n# Update the simulator's viewer camera's pose so it points towards the table\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.544888, -0.412084,  1.11569 ]),\norientation=np.array([0.54757518, 0.27792802, 0.35721896, 0.70378409]),\n)\n# Let apple settle\nfor _ in range(50):\nenv.step(np.array([]))\nknife.keep_still()\nknife.set_position_orientation(\nposition=apple.get_position() + np.array([-0.15, 0.0, 0.2]),\norientation=T.euler2quat([-np.pi / 2, 0, 0]),\n)\ninput(\"The knife will fall on the apple and dice it. Press [ENTER] to continue.\")\n# Step simulation for a bit so that apple is diced\nfor i in range(1000):\nenv.step(np.array([]))\ninput(\"Apple has been diced! Press [ENTER] to terminate the demo.\")\n# Always close environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#folded-and-unfolded-demo","title":"Folded and Unfolded Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load a softbody (cloth) version of a BEHAVIOR dataset object</li> <li>Understanding how to enable cloth objects to be <code>foldable</code> </li> <li>Understanding the current heuristics used for gauging a cloth's \"foldness\"</li> </ul> <pre><code>python -m omnigibson.examples.object_states.folded_unfolded_state_demo\n</code></pre> <p>This demo loads in three different cloth objects, and allows you to manipulate them (1) while printing out their <code>Folded</code> state status in real-time.</p> <ol> <li>Manipulate the object by holding down <code>Shift</code> and then <code>Left-click + Drag</code>!</li> </ol> folded_unfolded_state_demo.py <pre><code>from omnigibson.utils.constants import PrimType\nfrom omnigibson.object_states import Folded, Unfolded\nfrom omnigibson.macros import gm\nimport numpy as np\nimport omnigibson as og\n# Make sure object states and GPU dynamics are enabled (GPU dynamics needed for cloth)\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of cloth objects that can potentially be folded.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene + custom cloth object\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [\n{\n\"type\": \"DatasetObject\",\n\"name\": \"carpet\",\n\"category\": \"carpet\",\n\"model\": \"ctclvd\",\n\"prim_type\": PrimType.CLOTH,\n\"abilities\": {\"foldable\": {}, \"unfoldable\": {}},\n\"position\": [0, 0, 0.5],\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"dishtowel\",\n\"category\": \"dishtowel\",\n\"model\": \"dtfspn\",\n\"prim_type\": PrimType.CLOTH,\n\"scale\": 5.0,\n\"abilities\": {\"foldable\": {}, \"unfoldable\": {}},\n\"position\": [1, 1, 0.5],\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"shirt\",\n\"category\": \"t_shirt\",\n\"model\": \"kvidcx\",\n\"prim_type\": PrimType.CLOTH,\n\"scale\": 0.05,\n\"abilities\": {\"foldable\": {}, \"unfoldable\": {}},\n\"position\": [-1, 1, 0.5],\n\"orientation\": [0.7071, 0., 0.7071, 0.],\n},\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Grab object references\ncarpet = env.scene.object_registry(\"name\", \"carpet\")\ndishtowel = env.scene.object_registry(\"name\", \"dishtowel\")\nshirt = env.scene.object_registry(\"name\", \"shirt\")\nobjs = [carpet, dishtowel, shirt]\n# Set viewer camera\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([0.46382895, -2.66703958, 1.22616824]),\norientation=np.array([0.58779174, -0.00231237, -0.00318273, 0.80900271]),\n)\ndef print_state():\nfolded = carpet.states[Folded].get_value()\nunfolded = carpet.states[Unfolded].get_value()\ninfo = \"carpet: [folded] %d [unfolded] %d\" % (folded, unfolded)\nfolded = dishtowel.states[Folded].get_value()\nunfolded = dishtowel.states[Unfolded].get_value()\ninfo += \" || dishtowel: [folded] %d [unfolded] %d\" % (folded, unfolded)\nfolded = shirt.states[Folded].get_value()\nunfolded = shirt.states[Unfolded].get_value()\ninfo += \" || tshirt: [folded] %d [unfolded] %d\" % (folded, unfolded)\nprint(f\"{info}{' ' * (110 - len(info))}\", end=\"\\r\")\nfor _ in range(100):\nog.sim.step()\nprint(\"\\nCloth state:\\n\")\nif not short_exec:\n# Fold all three cloths along the x-axis\nfor i in range(3):\nobj = objs[i]\npos = obj.root_link.particle_positions\nx_min, x_max = np.min(pos, axis=0)[0], np.max(pos, axis=0)[0]\nx_extent = x_max - x_min\n# Get indices for the bottom 10 percent vertices in the x-axis\nindices = np.argsort(pos, axis=0)[:, 0][:(pos.shape[0] // 10)]\nstart = np.copy(pos[indices])\n# lift up a bit\nmid = np.copy(start)\nmid[:, 2] += x_extent * 0.2\n# move towards x_max\nend = np.copy(mid)\nend[:, 0] += x_extent * 0.9\nincrements = 25\nfor ctrl_pts in np.concatenate([np.linspace(start, mid, increments), np.linspace(mid, end, increments)]):\npos = obj.root_link.particle_positions\npos[indices] = ctrl_pts\nobj.root_link.particle_positions = pos\nog.sim.step()\nprint_state()\n# Fold the t-shirt twice again along the y-axis\nfor direction in [-1, 1]:\nobj = shirt\npos = obj.root_link.particle_positions\ny_min, y_max = np.min(pos, axis=0)[1], np.max(pos, axis=0)[1]\ny_extent = y_max - y_min\nif direction == 1:\nindices = np.argsort(pos, axis=0)[:, 1][:(pos.shape[0] // 20)]\nelse:\nindices = np.argsort(pos, axis=0)[:, 1][-(pos.shape[0] // 20):]\nstart = np.copy(pos[indices])\n# lift up a bit\nmid = np.copy(start)\nmid[:, 2] += y_extent * 0.2\n# move towards y_max\nend = np.copy(mid)\nend[:, 1] += direction * y_extent * 0.4\nincrements = 25\nfor ctrl_pts in np.concatenate([np.linspace(start, mid, increments), np.linspace(mid, end, increments)]):\npos = obj.root_link.particle_positions\npos[indices] = ctrl_pts\nobj.root_link.particle_positions = pos\nenv.step(np.array([]))\nprint_state()\nwhile True:\nenv.step(np.array([]))\nprint_state()\n# Shut down env at the end\nprint()\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#heat-source-or-sink-demo","title":"Heat Source or Sink Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how a heat source (or sink) is visualized in <code>OmniGibson</code></li> <li>Understanding how dynamic fire visuals are generated in real-time</li> </ul> <pre><code>python -m omnigibson.examples.object_states.heat_source_or_sink_demo\n</code></pre> <p>This demo loads in a stove and toggles its <code>HeatSource</code> on and off, showcasing the dynamic fire visuals available in <code>OmniGibson</code>.</p> heat_source_or_sink_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\ndef main():\n# Create the scene config to load -- empty scene with a stove object added\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [\n{\n\"type\": \"DatasetObject\",\n\"name\": \"stove\",\n\"category\": \"stove\",\n\"model\": \"qbjiva\",\n\"abilities\": {\n\"heatSource\": {\"requires_toggled_on\": True},\n\"toggleable\": {},\n},\n\"position\": [0, 0, 0.61],\n}\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Get reference to stove object\nstove = env.scene.object_registry(\"name\", \"stove\")\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.0792399, -1.30104, 1.51981]),\norientation=np.array([0.54897692, 0.00110359, 0.00168013, 0.83583509]),\n)\n# Make sure necessary object states are included with the stove\nassert object_states.HeatSourceOrSink in stove.states\nassert object_states.ToggledOn in stove.states\n# Take a few steps so that visibility propagates\nfor _ in range(5):\nenv.step(np.array([]))\n# Heat source is off.\nprint(\"Heat source is OFF.\")\nheat_source_state = stove.states[object_states.HeatSourceOrSink].get_value()\nassert not heat_source_state\n# Toggle on stove, notify user\ninput(\"Heat source will now turn ON: Press ENTER to continue.\")\nstove.states[object_states.ToggledOn].set_value(True)\nassert stove.states[object_states.ToggledOn].get_value()\n# Need to take a step to update the state.\nenv.step(np.array([]))\n# Heat source is on\nheat_source_state = stove.states[object_states.HeatSourceOrSink].get_value()\nassert heat_source_state\nfor _ in range(500):\nenv.step(np.array([]))\n# Toggle off stove, notify user\ninput(\"Heat source will now turn OFF: Press ENTER to continue.\")\nstove.states[object_states.ToggledOn].set_value(False)\nassert not stove.states[object_states.ToggledOn].get_value()\nfor _ in range(200):\nenv.step(np.array([]))\n# Move stove, notify user\ninput(\"Heat source is now moving: Press ENTER to continue.\")\nstove.set_position(np.array([0, 1.0, 0.61]))\nfor i in range(100):\nenv.step(np.array([]))\n# Toggle on stove again, notify user\ninput(\"Heat source will now turn ON: Press ENTER to continue.\")\nstove.states[object_states.ToggledOn].set_value(True)\nassert stove.states[object_states.ToggledOn].get_value()\nfor i in range(500):\nenv.step(np.array([]))\n# Shutdown environment at end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#heated-demo","title":"Heated Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how temperature modifications can cause objects' visual changes</li> <li>Understanding how dynamic steam visuals are generated in real-time</li> </ul> <pre><code>python -m omnigibson.examples.object_states.heated_state_demo\n</code></pre> <p>This demo loads in three bowls, and immediately sets their temperatures past their <code>Heated</code> threshold. Steam is generated in real-time from these objects, and then disappears once the temperature of the objects drops below their <code>Heated</code> threshold.</p> heated_state_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\ndef main():\n# Define object configurations for objects to load -- we want to load a light and three bowls\nobj_configs = []\nobj_configs.append(dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"light\",\nradius=0.01,\nintensity=1e8,\nposition=[-2.0, -2.0, 1.0],\n))\nfor i, (scale, x) in enumerate(zip([0.5, 1.0, 2.0], [-0.6, 0, 0.8])):\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=f\"bowl{i}\",\ncategory=\"bowl\",\nmodel=\"ajzltc\",\nscale=scale,\nabilities={\"heatable\": {}},\nposition=[x, 0, 0.2],\n))\n# Create the scene config to load -- empty scene with light object and bowls\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": obj_configs,\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.182103, -2.07295 ,  0.14017 ]),\norientation=np.array([0.77787037, 0.00267566, 0.00216149, 0.62841535]),\n)\n# Dim the skybox so we can see the bowls' steam effectively\nenv.scene.skybox.intensity = 100.0\n# Grab reference to objects of relevance\nobjs = list(env.scene.object_registry(\"category\", \"bowl\"))\ndef report_states(objs):\nfor obj in objs:\nprint(\"=\" * 20)\nprint(\"object:\", obj.name)\nprint(\"temperature:\", obj.states[object_states.Temperature].get_value())\nprint(\"obj is heated:\", obj.states[object_states.Heated].get_value())\n# Report default states\nprint(\"==== Initial state ====\")\nreport_states(objs)\n# Notify user that we're about to heat the object\ninput(\"Objects will be heated, and steam will slowly rise. Press ENTER to continue.\")\n# Heated.\nfor obj in objs:\nobj.states[object_states.Temperature].set_value(50)\nenv.step(np.array([]))\nreport_states(objs)\n# Take a look at the steam effect.\n# After a while, objects will be below the Steam temperature threshold.\nprint(\"==== Objects are now heated... ====\")\nprint()\nfor _ in range(2000):\nenv.step(np.array([]))\n# Also print temperatures\ntemps = [f\"{obj.states[object_states.Temperature].get_value():&gt;7.2f}\" for obj in objs]\nprint(f\"obj temps:\", *temps, end=\"\\r\")\nprint()\n# Objects are not heated anymore.\nprint(\"==== Objects are no longer heated... ====\")\nreport_states(objs)\n# Close environment at the end\ninput(\"Demo completed. Press ENTER to shutdown environment.\")\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#object-texture-demo","title":"Object Texture Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how different object states can result in texture changes</li> <li>Understanding how to enable objects with texture-changing states</li> <li>Understanding how to dynamically modify object states</li> </ul> <pre><code>python -m omnigibson.examples.object_states.object_state_texture_demo\n</code></pre> <p>This demo loads in a single object, and then dynamically modifies its state so that its texture changes with each modification.</p> object_state_texture_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm, macros\nfrom omnigibson.systems import get_system\nfrom omnigibson.utils.constants import ParticleModifyMethod\n# Make sure object states are enabled, we're using GPU dynamics, and HQ rendering is enabled\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\ngm.ENABLE_HQ_RENDERING = True\ndef main():\n# Create the scene config to load -- empty scene plus a light and a cabinet\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n\"floor_plane_visible\": True,\n},\n\"objects\": [\n{\n\"type\": \"LightObject\",\n\"name\": \"light\",\n\"light_type\": \"Sphere\",\n\"radius\": 0.01,\n\"intensity\": 1e8,\n\"position\": [-2.0, -2.0, 1.0],\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"cabinet\",\n\"category\": \"bottom_cabinet\",\n\"model\": \"zuwvdo\",\n\"abilities\": {\n\"freezable\": {},\n\"cookable\": {},\n\"burnable\": {},\n\"saturable\": {},\n\"toggleable\": {},\n\"particleRemover\": {\n\"method\": ParticleModifyMethod.ADJACENCY,\n\"conditions\": {\n# For a specific particle system, this specifies what conditions are required in order for the\n# particle applier / remover to apply / remover particles associated with that system\n# The list should contain functions with signature condition() --&gt; bool,\n# where True means the condition is satisfied\n# In this case, we only allow our cabinet to absorb water, with no conditions needed.\n# This is needed for the Saturated (\"saturable\") state so that we can modify the texture\n# according to the water.\n# NOTE: This will only change color if gm.ENABLE_HQ_RENDERING and gm.USE_GPU_DYNAMICS is\n# enabled!\n\"water\": [],\n},\n},\n},\n\"position\": [0, 0, 0.59],\n},\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 1.7789 , -1.68822,  1.13551]),\norientation=np.array([0.57065614, 0.20331904, 0.267029  , 0.74947212]),\n)\n# Grab reference to object of interest\nobj = env.scene.object_registry(\"name\", \"cabinet\")\n# Make sure all the appropriate states are in the object\nassert object_states.Frozen in obj.states\nassert object_states.Cooked in obj.states\nassert object_states.Burnt in obj.states\nassert object_states.Saturated in obj.states\nassert object_states.ToggledOn in obj.states\ndef report_states():\n# Make sure states are propagated before printing\nfor i in range(5):\nenv.step(np.array([]))\nprint(\"=\" * 20)\nprint(\"temperature:\", obj.states[object_states.Temperature].get_value())\nprint(\"obj is frozen:\", obj.states[object_states.Frozen].get_value())\nprint(\"obj is cooked:\", obj.states[object_states.Cooked].get_value())\nprint(\"obj is burnt:\", obj.states[object_states.Burnt].get_value())\nprint(\"obj is soaked:\", obj.states[object_states.Saturated].get_value(get_system(\"water\")))\nprint(\"obj is toggledon:\", obj.states[object_states.ToggledOn].get_value())\nprint(\"obj textures:\", obj.get_textures())\n# Report default states\nprint(\"==== Initial state ====\")\nreport_states()\n# Notify user that we're about to freeze the object, and then freeze the object\ninput(\"\\nObject will be frozen. Press ENTER to continue.\")\nobj.states[object_states.Temperature].set_value(-50)\nreport_states()\n# Notify user that we're about to cook the object, and then cook the object\ninput(\"\\nObject will be cooked. Press ENTER to continue.\")\nobj.states[object_states.Temperature].set_value(100)\nreport_states()\n# Notify user that we're about to burn the object, and then burn the object\ninput(\"\\nObject will be burned. Press ENTER to continue.\")\nobj.states[object_states.Temperature].set_value(250)\nreport_states()\n# Notify user that we're about to reset the object to its default state, and then reset state\ninput(\"\\nObject will be reset to default state. Press ENTER to continue.\")\nobj.states[object_states.Temperature].set_value(macros.object_states.temperature.DEFAULT_TEMPERATURE)\nobj.states[object_states.MaxTemperature].set_value(macros.object_states.temperature.DEFAULT_TEMPERATURE)\nreport_states()\n# Notify user that we're about to soak the object, and then soak the object\ninput(\"\\nObject will be saturated with water. Press ENTER to continue.\")\nobj.states[object_states.Saturated].set_value(get_system(\"water\"), True)\nreport_states()\n# Notify user that we're about to unsoak the object, and then unsoak the object\ninput(\"\\nObject will be unsaturated with water. Press ENTER to continue.\")\nobj.states[object_states.Saturated].set_value(get_system(\"water\"), False)\nreport_states()\n# Notify user that we're about to toggle on the object, and then toggle on the object\ninput(\"\\nObject will be toggled on. Press ENTER to continue.\")\nobj.states[object_states.ToggledOn].set_value(True)\nreport_states()\n# Notify user that we're about to toggle off the object, and then toggle off the object\ninput(\"\\nObject will be toggled off. Press ENTER to continue.\")\nobj.states[object_states.ToggledOn].set_value(False)\nreport_states()\n# Close environment at the end\ninput(\"Demo completed. Press ENTER to shutdown environment.\")\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#onfire-demo","title":"Onfire Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how changing onfire state can cause objects' visual changes</li> <li>Understanding how onfire can be triggered by nearby onfire objects</li> </ul> <pre><code>python -m omnigibson.examples.object_states.onfire_demo\n</code></pre> <p>This demo loads in a stove (toggled on) and two apples. The first apple will be ignited by the stove first, then the second apple will be ignited by the first apple.</p> onfire_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of on fire state.\n    Loads a stove (toggled on), and two apples.\n    The first apple will be ignited by the stove first, then the second apple will be ignited by the first apple.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Define specific objects we want to load in with the scene directly\nobj_configs = []\n# Light\nobj_configs.append(dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"light\",\nradius=0.01,\nintensity=1e8,\nposition=[-2.0, -2.0, 1.0],\n))\n# Stove\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"stove\",\ncategory=\"stove\",\nmodel=\"yhjzwg\",\nposition=[0, 0, 0.69],\n))\n# 2 Apples\nfor i in range(2):\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=f\"apple{i}\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nposition=[0, i * 0.07, 2.0],\nabilities={\"flammable\": {\"ignition_temperature\": 100, \"distance_threshold\": 0.5}},\n))\n# Create the scene config to load -- empty scene with desired objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": obj_configs,\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Get reference to relevant objects\nstove = env.scene.object_registry(\"name\", \"stove\")\napples = list(env.scene.object_registry(\"category\", \"apple\"))\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.42246569, -0.34745704,  1.56810353]),\norientation=np.array([ 0.50083786, -0.10407796, -0.17482619,  0.84128772]),\n)\n# Let objects settle\nfor _ in range(10):\nenv.step(np.array([]))\n# Turn on the stove\nstove.states[object_states.ToggledOn].set_value(True)\n# The first apple will be affected by the stove\napples[0].set_position(stove.states[object_states.HeatSourceOrSink].link.get_position() + np.array([0.11, 0, 0.1]))\n# The second apple will NOT be affected by the stove, but will be affected by the first apple once it's on fire.\napples[1].set_position(stove.states[object_states.HeatSourceOrSink].link.get_position() + np.array([0.32, 0, 0.1]))\nsteps = 0\nmax_steps = -1 if not short_exec else 1000\n# Main recording loop\nwhile steps != max_steps:\nenv.step(np.array([]))\ntemps = [f\"{apple.states[object_states.Temperature].get_value():&gt;20.2f}\" for apple in apples]\nprint(f\"{'Apple temperature:':&lt;20}\", *temps, end=\"\\r\")\nsteps += 1\n# Always close env at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#overlaid-demo","title":"Overlaid Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how cloth objects can be overlaid on rigid objects</li> <li>Understanding current heuristics used for gauging a cloth's \"overlaid\" status</li> </ul> <pre><code>python -m omnigibson.examples.object_states.overlaid_demo\n</code></pre> <p>This demo loads in a carpet on top of a table. The demo allows you to manipulate the carpet (1) while printing out their <code>Overlaid</code> state status in real-time.</p> <ol> <li>Manipulate the object by holding down <code>Shift</code> and then <code>Left-click + Drag</code>!</li> </ol> overlaid_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.constants import PrimType\nfrom omnigibson.object_states import Overlaid\n# Make sure object states and GPU dynamics are enabled (GPU dynamics needed for cloth)\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of cloth objects that can be overlaid on rigid objects.\n    Loads a carpet on top of a table. Initially Overlaid will be True because the carpet largely covers the table.\n    If you drag the carpet off the table or even just fold it into half, Overlaid will become False.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene + custom cloth object + custom rigid object\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [\n{\n\"type\": \"DatasetObject\",\n\"name\": \"carpet\",\n\"category\": \"carpet\",\n\"model\": \"ctclvd\",\n\"prim_type\": PrimType.CLOTH,\n\"abilities\": {\"foldable\": {}},\n\"position\": [0, 0, 1.0],\n\"scale\": [1.5] * 3,\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"breakfast_table\",\n\"category\": \"breakfast_table\",\n\"model\": \"rjgmmy\",\n\"prim_type\": PrimType.RIGID,\n\"scale\": 0.9,\n\"position\": [0, 0, 0.58],\n},\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Grab object references\ncarpet = env.scene.object_registry(\"name\", \"carpet\")\nbreakfast_table = env.scene.object_registry(\"name\", \"breakfast_table\")\n# Set camera pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.88215526, -1.40086216,  2.00311063]),\norientation=np.array([0.42013364, 0.12342107, 0.25339685, 0.86258043]),\n)\nmax_steps = 100 if short_exec else -1\nsteps = 0\nprint(\"\\nTry dragging cloth around with CTRL + Left-Click to see the Overlaid state change:\\n\")\nwhile steps != max_steps:\nprint(f\"Overlaid {carpet.states[Overlaid].get_value(breakfast_table)}    \", end=\"\\r\")\nenv.step(np.array([]))\n# Shut down env at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#particle-applier-and-remover-demo","title":"Particle Applier and Remover Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how a <code>ParticleRemover</code> or <code>ParticleApplier</code> object can be generated</li> <li>Understanding how particles can be dynamically generated on objects</li> <li>Understanding different methods for applying and removing particles via the <code>ParticleRemover</code> or <code>ParticleApplier</code> object</li> </ul> <pre><code>python -m omnigibson.examples.object_states.particle_applier_remover_demo\n</code></pre> <p>This demo loads in a washtowel and table and lets you choose the ability configuration to enable the washtowel with. The washtowel will then proceed to either remove and generate particles dynamically on the table while moving.</p> particle_applier_remover_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson.object_states import Covered\nfrom omnigibson.objects import DatasetObject\nfrom omnigibson.macros import gm, macros\nfrom omnigibson.systems import get_system\nfrom omnigibson.utils.usd_utils import create_joint\nfrom omnigibson.utils.ui_utils import choose_from_options\nfrom omnigibson.utils.constants import ParticleModifyMethod\nfrom pxr import Gf\n# Set macros for this example\nmacros.object_states.particle_modifier.VISUAL_PARTICLES_REMOVAL_LIMIT = 1000\nmacros.object_states.particle_modifier.PHYSICAL_PARTICLES_REMOVAL_LIMIT = 8000\nmacros.object_states.particle_modifier.MAX_VISUAL_PARTICLES_APPLIED_PER_STEP = 4\nmacros.object_states.particle_modifier.MAX_PHYSICAL_PARTICLES_APPLIED_PER_STEP = 40\nmacros.object_states.covered.MAX_VISUAL_PARTICLES = 300\n# Make sure object states and GPU dynamics are enabled (GPU dynamics needed for fluids)\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\ngm.ENABLE_HQ_RENDERING = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of ParticleApplier and ParticleRemover object states, which enable objects to either apply arbitrary\n    particles and remove arbitrary particles from the simulator, respectively.\n    Loads an empty scene with a table, and starts clean to allow particles to be applied or pre-covers the table\n    with particles to be removed. The ParticleApplier / ParticleRemover state is applied to an imported cloth object\n    and allowed to interact with the table, applying / removing particles from the table.\n    NOTE: The key difference between ParticleApplier/Removers and ParticleSource/Sinks is that Applier/Removers\n    requires contact (if using ParticleProjectionMethod.ADJACENCY) or overlap\n    (if using ParticleProjectionMethod.PROJECTION) in order to spawn / remove particles, and generally only spawn\n    particles at the contact points. ParticleSource/Sinks are special cases of ParticleApplier/Removers that\n    always use ParticleProjectionMethod.PROJECTION and always spawn / remove particles within their projection volume,\n    irregardless of overlap with other objects!\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose what configuration to load\nmodifier_type = choose_from_options(\noptions={\n\"particleApplier\": \"Demo object's ability to apply particles in the simulator\",\n\"particleRemover\": \"Demo object's ability to remove particles from the simulator\",\n},\nname=\"particle modifier type\",\nrandom_selection=random_selection,\n)\nmodification_metalink = {\n\"particleApplier\": \"particleapplication_link\",\n\"particleRemover\": \"particleremover_link\",\n}\nparticle_types = [\"stain\", \"water\"]\nparticle_type = choose_from_options(\noptions={name: f\"{name} particles will be applied or removed from the simulator\" for name in particle_types},\nname=\"particle type\",\nrandom_selection=random_selection,\n)\nmodification_method = {\n\"Adjacency\": ParticleModifyMethod.ADJACENCY,\n\"Projection\": ParticleModifyMethod.PROJECTION,\n}\nprojection_mesh_params = {\n\"Adjacency\": None,\n\"Projection\": {\n# Either Cone or Cylinder; shape of the projection where particles can be applied / removed\n\"type\": \"Cone\",\n# Size of the cone\n\"extents\": np.array([0.1875, 0.1875, 0.375]),\n\"visualize\": True,\n},\n}\nmethod_type = choose_from_options(\noptions={\n\"Adjacency\": \"Close proximity to the object will be used to determine whether particles can be applied / removed\",\n\"Projection\": \"A Cone or Cylinder shape protruding from the object will be used to determine whether particles can be applied / removed\",\n},\nname=\"modifier method type\",\nrandom_selection=random_selection,\n)\n# Create the ability kwargs to pass to the object state\nabilities = {\nmodifier_type: {\n\"method\": modification_method[method_type],\n\"conditions\": {\n# For a specific particle system, this specifies what conditions are required in order for the\n# particle applier / remover to apply / remover particles associated with that system\n# The list should contain functions with signature condition() --&gt; bool,\n# where True means the condition is satisified\nparticle_type: [],\n},\n\"projection_mesh_params\": projection_mesh_params[method_type],\n}\n}\n# Define objects to load: a light, table, and cloth\nlight_cfg = dict(\ntype=\"LightObject\",\nname=\"light\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=1e8,\nposition=[-2.0, -2.0, 2.0],\n)\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"kwmfdg\",\nscale=[4.0, 4.0, 4.0],\nposition=[0, 0, 0.98],\n)\n# Create the scene config to load -- empty scene with a light and table\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [light_cfg, table_cfg],\n}\n# Sanity check inputs: Remover + Adjacency + Fluid will not work because we are using a visual_only\n# object, so contacts will not be triggered with this object\n# Load the environment, then immediately stop the simulator since we need to add in the modifier object\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\nog.sim.stop()\n# Grab references to table\ntable = env.scene.object_registry(\"name\", \"table\")\n# Set the viewer camera appropriately\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-1.61340969, -1.79803028,  2.53167412]),\norientation=np.array([ 0.46291845, -0.12381886, -0.22679218,  0.84790371]),\n)\n# If we're using a projection volume, we manually add in the required metalink required in order to use the volume\nmodifier = DatasetObject(\nname=\"modifier\",\ncategory=\"dishtowel\",\nmodel=\"dtfspn\",\nscale=np.ones(3) * 2.0,\nvisual_only=method_type == \"Projection\",  # Non-fluid adjacency requires the object to have collision geoms active\nabilities=abilities,\n)\nmodifier_root_link_path = f\"{modifier.prim_path}/base_link\"\nmodifier._prim = modifier._load()\nif method_type == \"Projection\":\nmetalink_path = f\"{modifier.prim_path}/{modification_metalink[modifier_type]}\"\nog.sim.stage.DefinePrim(metalink_path, \"Xform\")\ncreate_joint(\nprim_path=f\"{modifier_root_link_path}/{modification_metalink[modifier_type]}_joint\",\nbody0=modifier_root_link_path,\nbody1=metalink_path,\njoint_type=\"FixedJoint\",\nenabled=True,\n)\nmodifier._post_load()\nmodifier._loaded = True\nog.sim.import_object(modifier)\nmodifier.set_position(np.array([0, 0, 5.0]))\n# Play the simulator and take some environment steps to let the objects settle\nog.sim.play()\nfor _ in range(25):\nenv.step(np.array([]))\n# If we're removing particles, set the table's covered state to be True\nif modifier_type == \"particleRemover\":\ntable.states[Covered].set_value(get_system(particle_type), True)\n# Take a few steps to let particles settle\nfor _ in range(25):\nenv.step(np.array([]))\n# Enable camera teleoperation for convenience\nog.sim.enable_viewer_camera_teleoperation()\n# Set the modifier object to be in position to modify particles\nif method_type == \"Projection\":\n# Higher z to showcase projection volume at work\nz = 1.85\nelif particle_type == \"stain\":\n# Lower z needed to allow for adjacency bounding box to overlap properly\nz = 1.175\nelse:\n# Higher z needed for actual physical interaction to accommodate non-negligible particle radius\nz = 1.22\nmodifier.keep_still()\nmodifier.set_position_orientation(\nposition=np.array([0, 0.3, z]),\norientation=np.array([0, 0, 0, 1.0]),\n)\n# Move object in square around table\ndeltas = [\n[150, np.array([-0.01, 0, 0])],\n[60, np.array([0, -0.01, 0])],\n[150, np.array([0.01, 0, 0])],\n[60, np.array([0, 0.01, 0])],\n]\nfor t, delta in deltas:\nfor i in range(t):\nmodifier.set_position(modifier.get_position() + delta)\nenv.step(np.array([]))\n# Always shut down environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#particle-source-and-sink-demo","title":"Particle Source and Sink Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how a <code>ParticleSource</code> or <code>ParticleSink</code> object can be generated</li> <li>Understanding how particles can be dynamically generated and destroyed via such objects</li> </ul> <pre><code>python -m omnigibson.examples.object_states.particle_source_sink_demo\n</code></pre> <p>This demo loads in a sink, which is enabled with both the ParticleSource and ParticleSink states. The sink's particle source is located at the faucet spout and spawns a continuous stream of water particles, which is then destroyed (\"sunk\") by the sink's particle sink located at the drain.</p> Difference bewteen <code>ParticleApplier/Removers</code> and <code>ParticleSource/Sinks</code> <p>The key difference between <code>ParticleApplier/Removers</code> and <code>ParticleSource/Sinks</code> is that <code>Applier/Removers</code> requires contact (if using <code>ParticleProjectionMethod.ADJACENCY</code>) or overlap (if using <code>ParticleProjectionMethod.PROJECTION</code>) in order to spawn / remove particles, and generally only spawn particles at the contact points. <code>ParticleSource/Sinks</code> are special cases of <code>ParticleApplier/Removers</code> that always use <code>ParticleProjectionMethod.PROJECTION</code> and always spawn / remove particles within their projection volume, irregardless of overlap with other objects.</p> particle_source_sink_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n# Make sure object states are enabled and GPU dynamics are used\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\ngm.ENABLE_HQ_RENDERING = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of ParticleSource and ParticleSink object states, which enable objects to either spawn arbitrary\n    particles and remove arbitrary particles from the simulator, respectively.\n    Loads an empty scene with a sink, which is enabled with both the ParticleSource and ParticleSink states.\n    The sink's particle source is located at the faucet spout and spawns a continuous stream of water particles,\n    which is then destroyed (\"sunk\") by the sink's particle sink located at the drain.\n    NOTE: The key difference between ParticleApplier/Removers and ParticleSource/Sinks is that Applier/Removers\n    requires contact (if using ParticleProjectionMethod.ADJACENCY) or overlap\n    (if using ParticleProjectionMethod.PROJECTION) in order to spawn / remove particles, and generally only spawn\n    particles at the contact points. ParticleSource/Sinks are special cases of ParticleApplier/Removers that\n    always use ParticleProjectionMethod.PROJECTION and always spawn / remove particles within their projection volume,\n    irregardless of overlap with other objects!\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n}\n}\ndef check_toggledon(obj):\nreturn obj.states[object_states.ToggledOn].get_value()\n# Define objects to load into the environment\nsink_cfg = dict(\ntype=\"DatasetObject\",\nname=\"sink\",\ncategory=\"sink\",\nmodel=\"yfaufu\",\nscale=[0.8, 0.8, 0.8],\nabilities={\n\"toggleable\": {},\n\"particleSource\": {\n\"conditions\": {\n\"water\": [check_toggledon],   # Must be toggled on for water source to be active\n},\n\"source_radius\": 0.0125,\n\"source_height\": 0.05,\n\"initial_speed\": 0.0,               # Water merely falls out of the spout\n},\n\"particleSink\": {\n\"conditions\": {\n\"water\": None,  # No conditions, always sinking nearby particles\n},\n\"sink_radius\": 0.05,\n\"sink_height\": 0.05,\n},\n},\nposition=[-0.7, 0, 0.56],\n)\ncfg[\"objects\"] = [sink_cfg]\n# Create the environment!\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to ideal angle for viewing objects\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.71452157, -0.88294428,  1.85640559]),\norientation=np.array([ 0.44909348, -0.00142818, -0.00284131,  0.89347912]),\n)\n# Take a few steps to let the objects settle, and then turn on the sink\nfor _ in range(10):\nenv.step(np.array([]))              # Empty action since no robots are in the scene\nsink = env.scene.object_registry(\"name\", \"sink\")\nassert sink.states[object_states.ToggledOn].set_value(True)\n# Take a step, and save the state\nenv.step(np.array([]))\ninitial_state = og.sim.dump_state()\n# Main simulation loop.\nmax_steps = 1000\nmax_iterations = -1 if not short_exec else 1\niteration = 0\ntry:\nwhile iteration != max_iterations:\n# Keep stepping until table or bowl are clean, or we reach 1000 steps\nsteps = 0\nwhile steps != max_steps:\nsteps += 1\nenv.step(np.array([]))\nog.log.info(\"Max steps reached; resetting.\")\n# Reset to the initial state\nog.sim.load_state(initial_state)\niteration += 1\nfinally:\n# Always shut down environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#kinematics-demo","title":"Kinematics Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to dynamically sample kinematic states for BEHAVIOR dataset objects</li> <li>Understanding how to import additional objects after the environment is created</li> </ul> <pre><code>python -m omnigibson.examples.object_states.sample_kinematics_demo\n</code></pre> <p>This demo procedurally generates a mini populated scene, spawning in a cabinet and placing boxes in its shelves, and then generating a microwave on a cabinet with a plate and apples sampled both inside and on top of it.</p> sample_kinematics_demo.py <pre><code>import os\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\nfrom omnigibson.objects import DatasetObject\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo to use the raycasting-based sampler to load objects onTop and/or inside another\n    Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet\n    Then loads a shelf and cracker boxes inside of it\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n}\n# Define objects we want to sample at runtime\nmicrowave_cfg = dict(\ntype=\"DatasetObject\",\nname=\"microwave\",\ncategory=\"microwave\",\nmodel=\"hjjxmi\",\nscale=0.5,\n)\ncabinet_cfg = dict(\ntype=\"DatasetObject\",\nname=\"cabinet\",\ncategory=\"bottom_cabinet\",\nmodel=\"bamfsz\",\n)\nplate_cfgs = [dict(\ntype=\"DatasetObject\",\nname=f\"plate{i}\",\ncategory=\"plate\",\nmodel=\"iawoof\",\nbounding_box=np.array([0.25, 0.25, 0.05]),\n) for i in range(2)]\napple_cfgs = [dict(\ntype=\"DatasetObject\",\nname=f\"apple{i}\",\ncategory=\"apple\",\nmodel=\"agveuv\",\n) for i in range(4)]\nshelf_cfg = dict(\ntype=\"DatasetObject\",\nname=f\"shelf\",\ncategory=\"shelf\",\nmodel=\"pkgbcp\",\nbounding_box=np.array([1.0, 0.4, 2.0]),\n)\nbox_cfgs = [dict(\ntype=\"DatasetObject\",\nname=f\"box{i}\",\ncategory=\"cracker_box\",\nmodel=\"cmdigf\",\nbounding_box=np.array([0.2, 0.05, 0.3]),\n) for i in range(5)]\n# Compose objects cfg\nobjects_cfg = [\nmicrowave_cfg,\ncabinet_cfg,\n*plate_cfgs,\n*apple_cfgs,\nshelf_cfg,\n*box_cfgs,\n]\n# Update their spawn positions so they don't collide immediately\nfor i, obj_cfg in enumerate(objects_cfg):\nobj_cfg[\"position\"] = [100 + i, 100 + i, 100 + i]\ncfg[\"objects\"] = objects_cfg\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\nenv.step([])\n# Sample microwave and boxes\nsample_boxes_on_shelf(env)\nsample_microwave_plates_apples(env)\nmax_steps = 100 if short_exec else -1\nstep = 0\nwhile step != max_steps:\nenv.step(np.array([]))\nstep += 1\n# Always close environment at the end\nenv.close()\ndef sample_microwave_plates_apples(env):\nmicrowave = env.scene.object_registry(\"name\", \"microwave\")\ncabinet = env.scene.object_registry(\"name\", \"cabinet\")\nplates = list(env.scene.object_registry(\"category\", \"plate\"))\napples = list(env.scene.object_registry(\"category\", \"apple\"))\n# Place the cabinet at a pre-determined location on the floor\nog.log.info(\"Placing cabinet on the floor...\")\ncabinet.set_orientation([0, 0, 0, 1.0])\nenv.step(np.array([]))\noffset = cabinet.get_position()[2] - cabinet.aabb_center[2]\ncabinet.set_position(np.array([1.0, 0, cabinet.aabb_extent[2] / 2]) + offset)\nenv.step(np.array([]))\n# Set microwave on top of the cabinet, open it, and step 100 times\nog.log.info(\"Placing microwave OnTop of the cabinet...\")\nassert microwave.states[object_states.OnTop].set_value(cabinet, True)\nassert microwave.states[object_states.Open].set_value(True)\nog.log.info(\"Microwave placed.\")\nfor _ in range(50):\nenv.step(np.array([]))\nog.log.info(\"Placing plates\")\nn_apples_per_plate = int(len(apples) / len(plates))\nfor i, plate in enumerate(plates):\n# Put the 1st plate in the microwave\nif i == 0:\nog.log.info(f\"Placing plate {i} Inside the microwave...\")\nassert plate.states[object_states.Inside].set_value(microwave, True)\nelse:\nog.log.info(f\"Placing plate {i} OnTop the microwave...\")\nassert plate.states[object_states.OnTop].set_value(microwave, True)\nog.log.info(f\"Plate {i} placed.\")\nfor _ in range(50):\nenv.step(np.array([]))\nog.log.info(f\"Placing {n_apples_per_plate} apples OnTop of the plate...\")\nfor j in range(n_apples_per_plate):\napple_idx = i * n_apples_per_plate + j\napple = apples[apple_idx]\nassert apple.states[object_states.OnTop].set_value(plate, True)\nog.log.info(f\"Apple {apple_idx} placed.\")\nfor _ in range(50):\nenv.step(np.array([]))\ndef sample_boxes_on_shelf(env):\nshelf = env.scene.object_registry(\"name\", \"shelf\")\nboxes = list(env.scene.object_registry(\"category\", \"cracker_box\"))\n# Place the shelf at a pre-determined location on the floor\nog.log.info(\"Placing shelf on the floor...\")\nshelf.set_orientation([0, 0, 0, 1.0])\nenv.step(np.array([]))\noffset = shelf.get_position()[2] - shelf.aabb_center[2]\nshelf.set_position(np.array([-1.0, 0, shelf.aabb_extent[2] / 2]) + offset)\nenv.step(np.array([]))  # One step is needed for the object to be fully initialized\nog.log.info(\"Shelf placed.\")\nfor _ in range(50):\nenv.step(np.array([]))\nog.log.info(\"Placing boxes...\")\nfor i, box in enumerate(boxes):\nbox.states[object_states.Inside].set_value(shelf, True)\nog.log.info(f\"Box {i} placed.\")\nfor _ in range(50):\nenv.step(np.array([]))\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#slicing-demo","title":"Slicing Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how slicing works in <code>OmniGibson</code></li> <li>Understanding how to access individual objects once the environment is created</li> </ul> <pre><code>python -m omnigibson.examples.object_states.slicing_demo\n</code></pre> <p>This demo spawns an apple on a table with a knife above it, and lets the knife fall to \"cut\" the apple in half.</p> slicing_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson.macros import gm\nimport omnigibson.utils.transform_utils as T\n# Make sure object states and transition rules are enabled\ngm.ENABLE_OBJECT_STATES = True\ngm.ENABLE_TRANSITION_RULES = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of slicing an apple into two apple slices\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene with table, knife, and apple\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"rjgmmy\",\nscale=0.9,\nposition=[0, 0, 0.58],\n)\napple_cfg = dict(\ntype=\"DatasetObject\",\nname=\"apple\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nscale=1.5,\nposition=[0.085, 0,  0.92],\n)\nknife_cfg = dict(\ntype=\"DatasetObject\",\nname=\"knife\",\ncategory=\"table_knife\",\nmodel=\"lrdmpf\",\nscale=2.5,\nposition=[0, 0, 10.0],\n)\nlight0_cfg = dict(\ntype=\"LightObject\",\nname=\"light0\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=4000.0,\nposition=[1.217, -0.848, 1.388],\n)\nlight1_cfg = dict(\ntype=\"LightObject\",\nname=\"light1\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=4000.0,\nposition=[-1.217, 0.848, 1.388],\n)\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [table_cfg, apple_cfg, knife_cfg, light0_cfg, light1_cfg]\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Grab reference to apple and knife\napple = env.scene.object_registry(\"name\", \"apple\")\nknife = env.scene.object_registry(\"name\", \"knife\")\n# Update the simulator's viewer camera's pose so it points towards the table\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.544888, -0.412084,  1.11569 ]),\norientation=np.array([0.54757518, 0.27792802, 0.35721896, 0.70378409]),\n)\n# Let apple settle\nfor _ in range(50):\nenv.step(np.array([]))\nknife.keep_still()\nknife.set_position_orientation(\nposition=apple.get_position() + np.array([-0.15, 0.0, 0.2]),\norientation=T.euler2quat([-np.pi / 2, 0, 0]),\n)\ninput(\"The knife will fall on the apple and slice it. Press [ENTER] to continue.\")\n# Step simulation for a bit so that apple is sliced\nfor i in range(1000):\nenv.step(np.array([]))\ninput(\"Apple has been sliced! Press [ENTER] to terminate the demo.\")\n# Always close environment at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#temperature-demo","title":"Temperature Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to dynamically sample kinematic states for BEHAVIOR dataset objects</li> <li>Understanding how temperature changes are propagated to individual objects from individual heat sources or sinks</li> </ul> <pre><code>python -m omnigibson.examples.object_states.temperature_demo\n</code></pre> <p>This demo loads in various heat sources and sinks, and places an apple within close proximity to each of them. As the environment steps, each apple's temperature is printed in real-time, showcasing <code>OmniGibson</code>'s rudimentary temperature dynamics.</p> temperature_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of temperature change\n    Loads a stove, a microwave and an oven, all toggled on, and five frozen apples\n    The user can move the apples to see them change from frozen, to normal temperature, to cooked and burnt\n    This demo also shows how to load objects ToggledOn and how to set the initial temperature of an object\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Define specific objects we want to load in with the scene directly\nobj_configs = []\n# Light\nobj_configs.append(dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"light\",\nradius=0.01,\nintensity=1e8,\nposition=[-2.0, -2.0, 1.0],\n))\n# Stove\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"stove\",\ncategory=\"stove\",\nmodel=\"yhjzwg\",\nposition=[0, 0, 0.69],\n))\n# Microwave\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"microwave\",\ncategory=\"microwave\",\nmodel=\"hjjxmi\",\nscale=0.25,\nposition=[2.5, 0, 0.10],\n))\n# Oven\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"oven\",\ncategory=\"oven\",\nmodel=\"wuinhm\",\nposition=[-1.25, 0, 0.88],\n))\n# Tray\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"tray\",\ncategory=\"tray\",\nmodel=\"xzcnjq\",\nscale=0.15,\nposition=[-0.25, -0.12, 1.26],\n))\n# Fridge\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"fridge\",\ncategory=\"fridge\",\nmodel=\"hivvdf\",\nabilities={\n\"coldSource\": {\n\"temperature\": -100.0,\n\"requires_inside\": True,\n}\n},\nposition=[1.25, 0, 0.81],\n))\n# 5 Apples\nfor i in range(5):\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=f\"apple{i}\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nposition=[0, i * 0.1, 5.0],\n))\n# Create the scene config to load -- empty scene with desired objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": obj_configs,\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Get reference to relevant objects\nstove = env.scene.object_registry(\"name\", \"stove\")\nmicrowave = env.scene.object_registry(\"name\", \"microwave\")\noven = env.scene.object_registry(\"name\", \"oven\")\ntray = env.scene.object_registry(\"name\", \"tray\")\nfridge = env.scene.object_registry(\"name\", \"fridge\")\napples = list(env.scene.object_registry(\"category\", \"apple\"))\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.46938863, -3.97887141,  1.64106008]),\norientation=np.array([0.63311689, 0.00127259, 0.00155577, 0.77405359]),\n)\n# Let objects settle\nfor _ in range(25):\nenv.step(np.array([]))\n# Turn on all scene objects\nstove.states[object_states.ToggledOn].set_value(True)\nmicrowave.states[object_states.ToggledOn].set_value(True)\noven.states[object_states.ToggledOn].set_value(True)\n# Set initial temperature of the apples to -50 degrees Celsius, and move the apples to different objects\nfor apple in apples:\napple.states[object_states.Temperature].set_value(-50)\napples[0].states[object_states.Inside].set_value(oven, True)\napples[1].set_position(stove.states[object_states.HeatSourceOrSink].link.get_position() + np.array([0, 0, 0.1]))\napples[2].states[object_states.OnTop].set_value(tray, True)\napples[3].states[object_states.Inside].set_value(fridge, True)\napples[4].states[object_states.Inside].set_value(microwave, True)\nsteps = 0\nmax_steps = -1 if not short_exec else 1000\n# Main recording loop\nlocations = [f'{loc:&gt;20}' for loc in [\"Inside oven\", \"On stove\", \"On tray\", \"Inside fridge\", \"Inside microwave\"]]\nprint()\nprint(f\"{'Apple location:':&lt;20}\", *locations)\nwhile steps != max_steps:\nenv.step(np.array([]))\ntemps = [f\"{apple.states[object_states.Temperature].get_value():&gt;20.2f}\" for apple in apples]\nprint(f\"{'Apple temperature:':&lt;20}\", *temps, end=\"\\r\")\nsteps += 1\n# Always close env at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#rendering","title":"\ud83d\uddbc\ufe0f Rendering","text":"<p>These examples showcase how to change renderer settings in <code>OmniGibson</code>.</p>"},{"location":"getting_started/building_blocks.html#renderer-settings-demo","title":"Renderer Settings Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to use RendererSettings class</li> </ul> <pre><code>python -m omnigibson.examples.renderer_settings.renderer_settings_example\n</code></pre> <p>This demo iterates over different renderer settings of and shows how they can be programmatically set with <code>OmniGibson</code> interface.</p> renderer_settings_example.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson.renderer_settings.renderer_settings import RendererSettings\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Shows how to use RendererSettings class\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Specify objects to load\nbanana_cfg = dict(\ntype=\"DatasetObject\",\nname=\"banana\",\ncategory=\"banana\",\nmodel=\"vvyyyv\",\nscale=[3.0, 5.0, 2.0],\nposition=[-0.906661, -0.545106,  0.136824],\norientation=[0, 0, 0.76040583, -0.6494482 ],\n)\ndoor_cfg = dict(\ntype=\"DatasetObject\",\nname=\"door\",\ncategory=\"door\",\nmodel=\"ohagsq\",\nposition=[-2.0, 0, 0.70000001],\norientation=[0, 0, -0.38268343,  0.92387953],\n)\n# Create the scene config to load -- empty scene with a few objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [banana_cfg, door_cfg],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to appropriate viewing pose\ncam = og.sim.viewer_camera\ncam.set_position_orientation(\nposition=np.array([-4.62785 , -0.418575,  0.933943]),\norientation=np.array([ 0.52196595, -0.4231939 , -0.46640436,  0.5752612 ]),\n)\ndef steps(n):\nfor _ in range(n):\nenv.step(np.array([]))\n# Take a few steps to let objects settle\nsteps(25)\n# Create renderer settings object.\nrenderer_setting = RendererSettings()\n# RendererSettings is a singleton.\nrenderer_setting2 = RendererSettings()\nassert renderer_setting == renderer_setting2\n# Set current renderer.\ninput(\"Setting renderer to Real-Time. Press [ENTER] to continue.\")\nrenderer_setting.set_current_renderer(\"Real-Time\")\nassert renderer_setting.get_current_renderer() == \"Real-Time\"\nsteps(5)\ninput(\"Setting renderer to Interactive (Path Tracing). Press [ENTER] to continue.\")\nrenderer_setting.set_current_renderer(\"Interactive (Path Tracing)\")\nassert renderer_setting.get_current_renderer() == \"Interactive (Path Tracing)\"\nsteps(5)\n# Get all available settings.\nprint(renderer_setting.settings.keys())\ninput(\"Showcasing how to use RendererSetting APIs. Please see example script for more information. \"\n\"Press [ENTER] to continue.\")\n# Set setting (2 lines below are equivalent).\nrenderer_setting.set_setting(path=\"/app/renderer/skipMaterialLoading\", value=True)\nrenderer_setting.common_settings.materials_settings.skip_material_loading.set(True)\n# Get setting (3 lines below are equivalent).\nassert renderer_setting.get_setting_from_path(path=\"/app/renderer/skipMaterialLoading\") == True\nassert renderer_setting.common_settings.materials_settings.skip_material_loading.value == True\nassert renderer_setting.common_settings.materials_settings.skip_material_loading.get() == True\n# Reset setting (2 lines below are equivalent).\nrenderer_setting.reset_setting(path=\"/app/renderer/skipMaterialLoading\")\nrenderer_setting.common_settings.materials_settings.skip_material_loading.reset()\nassert renderer_setting.get_setting_from_path(path=\"/app/renderer/skipMaterialLoading\") == False\n# Set setting to an unallowed value using top-level method.\n# Examples below will use the \"top-level\" setting method.\ntry:\nrenderer_setting.set_setting(path=\"/app/renderer/skipMaterialLoading\", value=\"foo\")\nexcept AssertionError as e:\nprint(e)  # All good. We got an AssertionError.\n# Set setting to a value out-of-range.\ntry:\nrenderer_setting.set_setting(path=\"/rtx/fog/fogColorIntensity\", value=0.0)\nexcept AssertionError as e:\nprint(e)  # All good. We got an AssertionError.\n# Set unallowed setting.\ntry:\nrenderer_setting.set_setting(path=\"foo\", value=\"bar\")\nexcept NotImplementedError as e:\nprint(e)  # All good. We got a NotImplementedError.\n# Set setting but the setting group is not enabled.\n# Setting is successful but there will be a warning message printed.\nrenderer_setting.set_setting(path=\"/rtx/fog/fogColorIntensity\", value=1.0)\n# Shutdown sim\ninput(\"Completed demo. Press [ENTER] to shutdown simulation.\")\nog.shutdown()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#robots","title":"\ud83e\udd16 Robots","text":"<p>These examples showcase how to interact and leverage robot objects in <code>OmniGibson</code>.</p>"},{"location":"getting_started/building_blocks.html#robot-visualizer-demo","title":"Robot Visualizer Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load a robot into <code>OmniGibson</code> after an environment is created</li> <li>Accessing all <code>OmniGibson</code> robot models</li> <li>Viewing robots' low-level joint motion</li> </ul> <pre><code>python -m omnigibson.examples.robots.all_robots_visualizer\n</code></pre> <p>This demo iterates over all robots in <code>OmniGibson</code>, loading each one into an empty scene and randomly moving its joints for a brief amount of time.</p> all_robots_visualizer.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson.robots import REGISTERED_ROBOTS\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Robot demo\n    Loads all robots in an empty scene, generate random actions\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create empty scene with no robots in it initially\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n}\n}\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Iterate over all robots and demo their motion\nfor robot_name, robot_cls in REGISTERED_ROBOTS.items():\n# Create and import robot\nrobot = robot_cls(\nprim_path=f\"/World/{robot_name}\",\nname=robot_name,\nobs_modalities=[],              # We're just moving robots around so don't load any observation modalities\n)\nog.sim.import_object(robot)\n# At least one step is always needed while sim is playing for any imported object to be fully initialized\nog.sim.play()\nog.sim.step()\n# Reset robot and make sure it's not moving\nrobot.reset()\nrobot.keep_still()\n# Log information\nog.log.info(f\"Loaded {robot_name}\")\nog.log.info(f\"Moving {robot_name}\")\nif not headless:\n# Set viewer in front facing robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 2.69918369, -3.63686664,  4.57894564]),\norientation=np.array([0.39592411, 0.1348514 , 0.29286304, 0.85982   ]),\n)\nog.sim.enable_viewer_camera_teleoperation()\n# Hold still briefly so viewer can see robot\nfor _ in range(100):\nog.sim.step()\n# Then apply random actions for a bit\nfor _ in range(30):\naction = np.random.uniform(-1, 1, robot.action_dim)\nfor _ in range(10):\nenv.step(action)\n# Stop the simulator and remove the robot\nog.sim.stop()\nog.sim.remove_object(obj=robot)\n# Always shut down the environment cleanly at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#robot-control-demo","title":"Robot Control Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how different controllers can be used to control robots</li> <li>Understanding how to teleoperate a robot through external commands</li> </ul> <pre><code>python -m omnigibson.examples.robots.robot_control_example\n</code></pre> <p>This demo lets you choose a robot and the set of controllers to control the robot, and then lets you teleoperate the robot using your keyboard.</p> robot_control_example.py <pre><code>\"\"\"\nExample script demo'ing robot control.\nOptions for random actions, as well as selection of robot action space\n\"\"\"\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.robots import REGISTERED_ROBOTS\nfrom omnigibson.utils.ui_utils import choose_from_options, KeyboardRobotController\nCONTROL_MODES = dict(\nrandom=\"Use autonomous random actions (default)\",\nteleop=\"Use keyboard control\",\n)\nSCENES = dict(\nRs_int=\"Realistic interactive home environment (default)\",\nempty=\"Empty environment with no objects\",\n)\n# Don't use GPU dynamics and use flatcache for performance boost\ngm.USE_GPU_DYNAMICS = False\ngm.ENABLE_FLATCACHE = True\ndef choose_controllers(robot, random_selection=False):\n\"\"\"\n    For a given robot, iterates over all components of the robot, and returns the requested controller type for each\n    component.\n    :param robot: BaseRobot, robot class from which to infer relevant valid controller options\n    :param random_selection: bool, if the selection is random (for automatic demo execution). Default False\n    :return dict: Mapping from individual robot component (e.g.: base, arm, etc.) to selected controller names\n    \"\"\"\n# Create new dict to store responses from user\ncontroller_choices = dict()\n# Grab the default controller config so we have the registry of all possible controller options\ndefault_config = robot._default_controller_config\n# Iterate over all components in robot\nfor component, controller_options in default_config.items():\n# Select controller\noptions = list(sorted(controller_options.keys()))\nchoice = choose_from_options(\noptions=options, name=\"{} controller\".format(component), random_selection=random_selection\n)\n# Add to user responses\ncontroller_choices[component] = choice\nreturn controller_choices\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Robot control demo with selection\n    Queries the user to select a robot, the controllers, a scene and a type of input (random actions or teleop)\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose scene to load\nscene_model = choose_from_options(options=SCENES, name=\"scene\", random_selection=random_selection)\n# Choose robot to create\nrobot_name = choose_from_options(\noptions=list(sorted(REGISTERED_ROBOTS.keys())), name=\"robot\", random_selection=random_selection\n)\n# Create the config for generating the environment we want\nscene_cfg = dict()\nif scene_model == \"empty\":\nscene_cfg[\"type\"] = \"Scene\"\nelse:\nscene_cfg[\"type\"] = \"InteractiveTraversableScene\"\nscene_cfg[\"scene_model\"] = scene_model\n# Add the robot we want to load\nrobot0_cfg = dict()\nrobot0_cfg[\"type\"] = robot_name\nrobot0_cfg[\"obs_modalities\"] = [\"rgb\", \"depth\", \"seg_instance\", \"normal\", \"scan\", \"occupancy_grid\"]\nrobot0_cfg[\"action_type\"] = \"continuous\"\nrobot0_cfg[\"action_normalize\"] = True\n# Compile config\ncfg = dict(scene=scene_cfg, robots=[robot0_cfg])\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Choose robot controller to use\nrobot = env.robots[0]\ncontroller_choices = choose_controllers(robot=robot, random_selection=random_selection)\n# Choose control mode\nif random_selection:\ncontrol_mode = \"random\"\nelse:\ncontrol_mode = choose_from_options(options=CONTROL_MODES, name=\"control mode\")\n# Update the control mode of the robot\ncontroller_config = {component: {\"name\": name} for component, name in controller_choices.items()}\nrobot.reload_controllers(controller_config=controller_config)\n# Update the simulator's viewer camera's pose so it points towards the robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([1.46949, -3.97358, 2.21529]),\norientation=np.array([0.56829048, 0.09569975, 0.13571846, 0.80589577]),\n)\n# Reset environment\nenv.reset()\n# Create teleop controller\naction_generator = KeyboardRobotController(robot=robot)\n# Print out relevant keyboard info if using keyboard teleop\nif control_mode == \"teleop\":\naction_generator.print_keyboard_teleop_info()\n# Other helpful user info\nprint(\"Running demo.\")\nprint(\"Press ESC to quit\")\n# Loop control until user quits\nmax_steps = -1 if not short_exec else 100\nstep = 0\nwhile step != max_steps:\naction = action_generator.get_random_action() if control_mode == \"random\" else action_generator.get_teleop_action()\nfor _ in range(10):\nenv.step(action=action)\nstep += 1\n# Always shut down the environment cleanly at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#robot-grasping-demo","title":"Robot Grasping Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding the difference between <code>physical</code> and <code>sticky</code> (1) grasping</li> <li>Understanding how to teleoperate a robot through external commands</li> </ul> <ol> <li><code>physical</code> means natural friction is required to hold objects, <code>sticky</code> means that objects are constrained to the robot's gripper once contact is made</li> </ol> <pre><code>python -m omnigibson.examples.robots.grasping_mode_example\n</code></pre> <p>This demo lets you choose a grasping mode and then loads a <code>Fetch</code> robot and a cube on a table. You can then teleoperate the robot to grasp the cube, observing the difference is grasping behavior based on the grasping mode chosen.</p> grasping_mode_example.py <pre><code>\"\"\"\nExample script demo'ing robot manipulation control with grasping.\n\"\"\"\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.sensors import VisionSensor\nfrom omnigibson.utils.ui_utils import choose_from_options, KeyboardRobotController\nGRASPING_MODES = dict(\nsticky=\"Sticky Mitten - Objects are magnetized when they touch the fingers and a CLOSE command is given\",\nphysical=\"Physical Grasping - No additional grasping assistance applied\",\n)\n# Don't use GPU dynamics and Use flatcache for performance boost\ngm.USE_GPU_DYNAMICS = False\ngm.ENABLE_FLATCACHE = True\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Robot grasping mode demo with selection\n    Queries the user to select a type of grasping mode\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose type of grasping\ngrasping_mode = choose_from_options(options=GRASPING_MODES, name=\"grasping mode\", random_selection=random_selection)\n# Create environment configuration to use\nscene_cfg = dict(type=\"Scene\")\nrobot0_cfg = dict(\ntype=\"Fetch\",\nobs_modalities=[\"rgb\"],     # we're just doing a grasping demo so we don't need all observation modalities\naction_type=\"continuous\",\naction_normalize=True,\ngrasping_mode=grasping_mode,\n)\n# Define objects to load\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"lcsizg\",\nbounding_box=[0.5, 0.5, 0.8],\nfit_avg_dim_volume=False,\nfixed_base=True,\nposition=[0.7, -0.1, 0.6],\norientation=[0, 0, 0.707, 0.707],\n)\nchair_cfg = dict(\ntype=\"DatasetObject\",\nname=\"chair\",\ncategory=\"straight_chair\",\nmodel=\"amgwaw\",\nbounding_box=None,\nfit_avg_dim_volume=True,\nfixed_base=False,\nposition=[0.45, 0.65, 0.425],\norientation=[0, 0, -0.9990215, -0.0442276],\n)\nbox_cfg = dict(\ntype=\"PrimitiveObject\",\nname=\"box\",\nprimitive_type=\"Cube\",\nrgba=[1.0, 0, 0, 1.0],\nsize=0.05,\nposition=[0.53, -0.1, 0.97],\n)\n# Compile config\ncfg = dict(scene=scene_cfg, robots=[robot0_cfg], objects=[table_cfg, chair_cfg, box_cfg])\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Reset the robot\nrobot = env.robots[0]\nrobot.set_position([0, 0, 0])\nrobot.reset()\nrobot.keep_still()\n# Make the robot's camera(s) high-res\nfor sensor in robot.sensors.values():\nif isinstance(sensor, VisionSensor):\nsensor.image_height = 720\nsensor.image_width = 720\n# Update the simulator's viewer camera's pose so it points towards the robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-2.39951,  2.26469,  2.66227]),\norientation=np.array([-0.23898481,  0.48475231,  0.75464013, -0.37204802]),\n)\n# Create teleop controller\naction_generator = KeyboardRobotController(robot=robot)\n# Print out relevant keyboard info if using keyboard teleop\naction_generator.print_keyboard_teleop_info()\n# Other helpful user info\nprint(\"Running demo with grasping mode {}.\".format(grasping_mode))\nprint(\"Press ESC to quit\")\n# Loop control until user quits\nmax_steps = -1 if not short_exec else 100\nstep = 0\nwhile step != max_steps:\naction = action_generator.get_random_action() if random_selection else action_generator.get_teleop_action()\nfor _ in range(10):\nenv.step(action)\nstep += 1\n# Always shut down the environment cleanly at the end\nenv.close()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#advanced-ik-demo","title":"Advanced: IK Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to construct your own IK functionality using omniverse's native lula library without explicitly utilizing all of OmniGibson's class abstractions</li> <li>Understanding how to manipulate the simulator at a lower-level than the main Environment entry point</li> </ul> <pre><code>python -m omnigibson.examples.robots.advanced.ik_example\n</code></pre> <p>This demo loads in <code>Fetch</code> robot and a IK solver to control the robot, and then lets you teleoperate the robot using your keyboard.</p> ik_example.py <pre><code>import argparse\nimport time\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson.objects import PrimitiveObject\nfrom omnigibson.robots import Fetch\nfrom omnigibson.scenes import Scene\nfrom omnigibson.utils.control_utils import IKSolver\nimport carb\nimport omni\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Minimal example of usage of inverse kinematics solver\n    This example showcases how to construct your own IK functionality using omniverse's native lula library\n    without explicitly utilizing all of OmniGibson's class abstractions, and also showcases how to manipulate\n    the simulator at a lower-level than the main Environment entry point.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Assuming that if random_selection=True, headless=True, short_exec=True, we are calling it from tests and we\n# do not want to parse args (it would fail because the calling function is pytest \"testfile.py\")\nif not (random_selection and headless and short_exec):\nparser = argparse.ArgumentParser()\nparser.add_argument(\n\"--programmatic\",\n\"-p\",\ndest=\"programmatic_pos\",\naction=\"store_true\",\nhelp=\"if the IK solvers should be used with the GUI or programmatically\",\n)\nargs = parser.parse_args()\nprogrammatic_pos = args.programmatic_pos\nelse:\nprogrammatic_pos = True\n# Import scene and robot (Fetch)\nscene = Scene()\nog.sim.import_scene(scene)\n# Update the viewer camera's pose so that it points towards the robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([4.32248, -5.74338, 6.85436]),\norientation=np.array([0.39592, 0.13485, 0.29286, 0.85982]),\n)\n# Create Fetch robot\n# Note that since we only care about IK functionality, we fix the base (this also makes the robot more stable)\n# (any object can also have its fixed_base attribute set to True!)\n# Note that since we're going to be setting joint position targets, we also need to make sure the robot's arm joints\n# (which includes the trunk) are being controlled using joint positions\nrobot = Fetch(\nprim_path=\"/World/robot\",\nname=\"robot\",\nfixed_base=True,\ncontroller_config={\n\"arm_0\": {\n\"name\": \"JointController\",\n\"motor_type\": \"position\",\n}\n}\n)\nog.sim.import_object(robot)\n# Set robot base at the origin\nrobot.set_position_orientation(np.array([0, 0, 0]), np.array([0, 0, 0, 1]))\n# At least one simulation step while the simulator is playing must occur for the robot (or in general, any object)\n# to be fully initialized after it is imported into the simulator\nog.sim.play()\nog.sim.step()\n# Make sure none of the joints are moving\nrobot.keep_still()\n# Create the IK solver -- note that we are controlling both the trunk and the arm since both are part of the\n# controllable kinematic chain for the end-effector!\ncontrol_idx = np.concatenate([robot.trunk_control_idx, robot.arm_control_idx[robot.default_arm]])\nik_solver = IKSolver(\nrobot_description_path=robot.robot_arm_descriptor_yamls[robot.default_arm],\nrobot_urdf_path=robot.urdf_path,\ndefault_joint_pos=robot.get_joint_positions()[control_idx],\neef_name=robot.eef_link_names[robot.default_arm],\n)\n# Define a helper function for executing specific end-effector commands using the ik solver\ndef execute_ik(pos, quat=None, max_iter=100):\nog.log.info(\"Querying joint configuration to current marker position\")\n# Grab the joint positions in order to reach the desired pose target\njoint_pos = ik_solver.solve(\ntarget_pos=pos,\ntarget_quat=quat,\nmax_iterations=max_iter,\n)\nif joint_pos is not None:\nog.log.info(\"Solution found. Setting new arm configuration.\")\nrobot.set_joint_positions(joint_pos, indices=control_idx, drive=True)\nelse:\nog.log.info(\"EE position not reachable.\")\nog.sim.step()\nif programmatic_pos or headless:\n# Sanity check IK using pre-defined hardcoded positions\nquery_positions = [[1, 0, 0.8], [1, 1, 1], [0.5, 0.5, 0], [0.5, 0.5, 0.5]]\nfor query_pos in query_positions:\nexecute_ik(query_pos)\ntime.sleep(2)\nelse:\n# Create a visual marker to be moved by the user, representing desired end-effector position\nmarker = PrimitiveObject(\nprim_path=f\"/World/marker\",\nname=\"marker\",\nprimitive_type=\"Sphere\",\nradius=0.03,\nvisual_only=True,\nrgba=[1.0, 0, 0, 1.0],\n)\nog.sim.import_object(marker)\n# Get initial EE position and set marker to that location\ncommand = robot.get_eef_position()\nmarker.set_position(command)\nog.sim.step()\n# Setup callbacks for grabbing keyboard inputs from omni\nexit_now = False\ndef keyboard_event_handler(event, *args, **kwargs):\nnonlocal command, exit_now\n# Check if we've received a key press or repeat\nif event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                    or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\nif event.input == carb.input.KeyboardInput.ENTER:\n# Execute the command\nexecute_ik(pos=command)\nelif event.input == carb.input.KeyboardInput.ESCAPE:\n# Quit\nog.log.info(\"Quit.\")\nexit_now = True\nelse:\n# We see if we received a valid delta command, and if so, we update our command and visualized\n# marker position\ndelta_cmd = input_to_xyz_delta_command(inp=event.input)\nif delta_cmd is not None:\ncommand = command + delta_cmd\nmarker.set_position(command)\nog.sim.step()\n# Callback must return True if valid\nreturn True\n# Hook up the callback function with omni's user interface\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\nsub_keyboard = input_interface.subscribe_to_keyboard_events(keyboard, keyboard_event_handler)\n# Print out helpful information to the user\nprint_message()\n# Loop until the user requests an exit\nwhile not exit_now:\nog.sim.step()\n# Always shut the simulation down cleanly at the end\nog.app.close()\ndef input_to_xyz_delta_command(inp, delta=0.01):\nmapping = {\ncarb.input.KeyboardInput.W: np.array([delta, 0, 0]),\ncarb.input.KeyboardInput.S: np.array([-delta, 0, 0]),\ncarb.input.KeyboardInput.DOWN: np.array([0, 0, -delta]),\ncarb.input.KeyboardInput.UP: np.array([0, 0, delta]),\ncarb.input.KeyboardInput.A: np.array([0, delta, 0]),\ncarb.input.KeyboardInput.D: np.array([0, -delta, 0]),\n}\nreturn mapping.get(inp)\ndef print_message():\nprint(\"*\" * 80)\nprint(\"Move the marker to a desired position to query IK and press ENTER\")\nprint(\"W/S: move marker further away or closer to the robot\")\nprint(\"A/D: move marker to the left or the right of the robot\")\nprint(\"T/G: move marker up and down\")\nprint(\"ESC: quit\")\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/building_blocks.html#simulator","title":"\ud83e\uddf0 Simulator","text":"<p>These examples showcase useful functionality from <code>OmniGibson</code>'s monolithic <code>Simulator</code> object.</p> What's the difference between <code>Environment</code> and <code>Simulator</code>? <p>The <code>Simulator</code> class is a lower-level object that:</p> <ul> <li>handles importing scenes and objects into the actual simulation</li> <li>directly interfaces with the underlying physics engine</li> </ul> <p>The <code>Environment</code> class thinly wraps the <code>Simulator</code>'s core functionality, by:</p> <ul> <li>providing convenience functions for automatically importing a predefined scene, object(s), and robot(s) (via the <code>cfg</code> argument), as well as a <code>task</code></li> <li>providing a OpenAI Gym interface for stepping through the simulation</li> </ul> <p>While most of the core functionality in <code>Environment</code> (as well as more fine-grained physics control) can be replicated via direct calls to <code>Simulator</code> (<code>og.sim</code>), it requires deeper understanding of <code>OmniGibson</code>'s infrastructure and is not recommended for new users.</p>"},{"location":"getting_started/building_blocks.html#state-saving-and-loading-demo","title":"State Saving and Loading Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to interact with objects using the mouse</li> <li>Understanding how to save the active simulator state to a file</li> <li>Understanding how to restore the simulator state from a given file</li> </ul> <pre><code>python -m omnigibson.examples.simulator.sim_save_load_example\n</code></pre> <p>This demo loads a stripped-down scene with the <code>Turtlebot</code> robot, and lets you interact with objects to modify the scene. The state is then saved, written to a <code>.json</code> file, and then restored in the simulation.</p> sim_save_load_example.py <pre><code>import os\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson.utils.ui_utils import KeyboardEventHandler\nimport carb\nTEST_OUT_PATH = \"\"  # Define output directory here.\ndef main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select whether they are saving or loading an environment, and interactively\n    shows how an environment can be saved or restored.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\ncfg = {\n\"scene\": {\n\"type\": \"InteractiveTraversableScene\",\n\"scene_model\": \"Rs_int\",\n\"load_object_categories\": [\"floors\", \"walls\", \"bed\", \"bottom_cabinet\", \"chair\"],\n},\n\"robots\": [\n{\n\"type\": \"Turtlebot\",\n\"obs_modalities\": [\"rgb\", \"depth\"],\n},\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg)\n# Set the camera to a good angle\ndef set_camera_pose():\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.229375, -3.40576 ,  7.26143 ]),\norientation=np.array([ 0.27619733, -0.00230233, -0.00801152,  0.9610648 ]),\n)\nset_camera_pose()\n# Give user instructions, and then loop until completed\ncompleted = short_exec\nif not short_exec and not random_selection:\n# Notify user to manipulate environment until ready, then press Z to exit\nprint()\nprint(\"Modify the scene by SHIFT + left clicking objects and dragging them. Once finished, press Z.\")\n# Register callback so user knows to press space once they're done manipulating the scene\ndef complete_loop():\nnonlocal completed\ncompleted = True\nKeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\nwhile not completed:\nenv.step(np.random.uniform(-1, 1, env.robots[0].action_dim))\nprint(\"Completed scene modification, saving scene...\")\nsave_path = os.path.join(TEST_OUT_PATH, \"saved_stage.json\")\nog.sim.save(json_path=save_path)\nprint(\"Re-loading scene...\")\nog.sim.restore(json_path=save_path)\n# Take a sim step and play\nog.sim.step()\nog.sim.play()\nset_camera_pose()\n# Loop until user terminates\ncompleted = short_exec\nif not short_exec and not random_selection:\n# Notify user to manipulate environment until ready, then press Z to exit\nprint()\nprint(\"View reloaded scene. Once finished, press Z.\")\n# Register callback so user knows to press space once they're done manipulating the scene\nKeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\nwhile not completed:\nenv.step(np.zeros(env.robots[0].action_dim))\n# Shutdown omnigibson at the end\nog.shutdown()\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"getting_started/installation.html","title":"\ud83d\udee0\ufe0f Installation","text":""},{"location":"getting_started/installation.html#requirements","title":"\ud83d\uddd2\ufe0f Requirements","text":"<p>Please make sure your system meets the following specs:</p> <ul> <li> OS: Ubuntu 20.04+ / Windows 10+</li> <li> RAM: 32GB+</li> <li> GPU: NVIDIA RTX 2070+</li> <li> VRAM: 8GB+</li> </ul> Why these specs? <p><code>OmniGibson</code> is built upon NVIDIA's Omniverse and Isaac Sim platforms, so we inherit their dependencies. For more information, please see Isaac Sim's Requirements.</p>"},{"location":"getting_started/installation.html#setup","title":"\ud83d\udcbb Setup","text":"<p>There are two ways to setup <code>OmniGibson</code>:</p> <ul> <li>\ud83d\udc33 Install with Docker (Linux only): You can quickly get <code>OmniGibson</code> immediately up and running from our pre-built docker image.</li> <li>\ud83e\uddea Install from source (Linux / Windows): This method is recommended for deeper users looking to develop upon <code>OmniGibson</code> or use it extensively for research. </li> </ul> \ud83d\udc33 Install with Docker (Linux only)\ud83e\uddea Install from source (Linux / Windows) <p>Install <code>OmniGibson</code> with Docker is supported for \ud83d\udc27 Linux only.</p> Need to install docker or NVIDIA docker? <pre><code># Install docker\ncurl https://get.docker.com | sh &amp;&amp; sudo systemctl --now enable docker\n\n# Install nvidia-docker runtime\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\\n&amp;&amp; curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \\\nsudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n&amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\nsed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\nsudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\nsudo apt-get update\nsudo apt-get install -y nvidia-docker2 # install\nsudo systemctl restart docker # restart docker engine\n</code></pre> <ol> <li> <p>Install our docker launching scripts:     <pre><code>curl -LJO https://raw.githubusercontent.com/StanfordVL/OmniGibson/main/docker/run_docker.sh\nchmod a+x run_docker.sh\n</code></pre></p> What is being installed? <p>Our docker image automatically ships with a pre-configured conda virtual environment named <code>omnigibson</code> with Isaac Sim and <code>OmniGibson</code> pre-installed. Upon running the first time, our scene and object assets will automatically be downloaded as well. (1)</p> <ol> <li>\ud83d\udcca Worried about dataset size? We will ask whether you want to install our small demo dataset or full dataset of assets!</li> </ol> </li> <li> <p>Then, simply launch the shell script:</p> HeadlessGUI <pre><code>sudo ./run_docker.sh -h &lt;ABS_DATA_PATH&gt; # (1)!\n</code></pre> <ol> <li><code>&lt;ABS_DATA_PATH&gt;</code> specifies the absolute path data will be stored on your machine (if no <code>&lt;ABS_DATA_PATH&gt;</code> is specified, it defaults to <code>./omnigibson_data</code>). This needs to be called each time the docker container is run!</li> </ol> <pre><code>sudo ./run_docker.sh &lt;ABS_DATA_PATH&gt; # (1)!\n</code></pre> <ol> <li><code>&lt;ABS_DATA_PATH&gt;</code> specifies the absolute path data will be stored on your machine (if no <code>&lt;ABS_DATA_PATH&gt;</code> is specified, it defaults to <code>./omnigibson_data</code>). This needs to be called each time the docker container is run!</li> </ol> Are you using NFS or AFS? <p>Docker containers are unable to access NFS or AFS drives, so if <code>run_docker.sh</code> are located on an NFS / AFS partition, please set <code>&lt;DATA_PATH&gt;</code> to an alternative data directory located on a non-NFS / AFS partition.</p> </li> </ol> <p>Install <code>OmniGibson</code> from source is supported for both \ud83d\udc27 Linux (bash) and \ud83d\udcc1 Windows (cmd).</p> \ud83d\udc27 Linux (bash)\ud83d\udcc1 Windows (cmd) <ol> <li> <p>Install Conda</p> </li> <li> <p>Install NVIDIA's Isaac Sim platform (1)</p> <p>The latest version of Isaac Sim (2022.2.1) has known issues when loading large <code>OmniGibson</code> scenes. Please install 2022.2.0 instead.</p> <p>Depending on the OS, you might need to install FUSE to run the Omniverse Launcher AppImage.</p> </li> <li> <p>Export IsaacSim directory path as an environment variable: (2)</p> <pre><code>export ISAAC_SIM_PATH=&lt;YOUR_PATH_TO_ISAAC_SIM&gt;\n</code></pre> </li> <li> <p>Clone <code>OmniGibson</code> and move into the directory:</p> <pre><code>git clone https://github.com/StanfordVL/OmniGibson.git\ncd OmniGibson\n</code></pre> </li> <li> <p>Setup a virtual conda environment to run <code>OmniGibson</code>:</p> <pre><code>source setup_conda_env.sh\n</code></pre> <p>This will automatically create an dump you into a conda env called <code>omnigibson</code>. If you need to activate this environment later, simply call:</p> <pre><code>conda activate omnigibson\n</code></pre> Note for zsh users <p>bash is strongly recommended on Linux. If you are using zsh, you need to change <code>${BASH_SOURCE[0]}</code> and <code>${BASH_SOURCE}</code> to <code>$0</code> in the first line of <code>&lt;ISAAC_SIM_PATH&gt;/setup_conda_env.sh</code> and <code>&lt;ISAAC_SIM_PATH&gt;/setup_python_env.sh</code> respectively in order for <code>OmniGibson</code> to work properly.</p> </li> <li> <p>Download <code>OmniGibson</code> assets and datasets:</p> <pre><code>OMNIGIBSON_NO_OMNIVERSE=1 python omnigibson/scripts/setup.py\n</code></pre> </li> <li> <p>\ud83c\udf89 Congrats! You installed <code>OmniGibson</code> successfully.  </p> </li> </ol> <ol> <li> <p>Be sure keep track of where you choose Omniverse to write package files! By default this should be <code>~/.local/share/ov/pkg</code></p> </li> <li> <p>If you installed Isaac Sim to the default location, this is <code>~/.local/share/ov/pkg/isaac_sim-2022.2.0</code></p> </li> </ol> <ol> <li> <p>Install Conda</p> </li> <li> <p>Install NVIDIA's Isaac Sim platform (1)</p> <p>The latest version of Isaac Sim (2022.2.1) has known issues when loading large <code>OmniGibson</code> scenes. Please install 2022.2.0 instead.</p> </li> <li> <p>Export IsaacSim directory path as an environment variable: (2)</p> <pre><code>set ISAAC_SIM_PATH=&lt;YOUR_PATH_TO_ISAAC_SIM&gt;\n</code></pre> </li> <li> <p>Clone <code>OmniGibson</code> and move into the directory:</p> <pre><code>git clone https://github.com/StanfordVL/OmniGibson.git\ncd OmniGibson\n</code></pre> </li> <li> <p>Setup a virtual conda environment to run <code>OmniGibson</code>:</p> <pre><code>setup_conda_env.bat\n</code></pre> <p>This will automatically create an dump you into a conda env called <code>omnigibson</code>. If you need to activate this environment later, simply call:</p> <pre><code>conda activate omnigibson\n</code></pre> </li> <li> <p>Download <code>OmniGibson</code> assets and datasets:</p> <pre><code>set OMNIGIBSON_NO_OMNIVERSE=1&amp;&amp;python omnigibson/scripts/setup.py&amp;&amp;set OMNIGIBSON_NO_OMNIVERSE=\n</code></pre> </li> <li> <p>\ud83c\udf89 Congrats! You installed <code>OmniGibson</code> successfully.</p> </li> </ol> <ol> <li> <p>Be sure keep track of where you choose Omniverse to write package files! By default this should be <code>C:\\Users\\&lt;USER_NAME&gt;\\AppData\\Local\\ov\\pkg</code></p> </li> <li> <p>If you installed Isaac Sim to the default location, this is <code>C:\\Users\\&lt;USER_NAME&gt;\\AppData\\Local\\ov\\pkg\\isaac_sim-2022.2.0</code></p> </li> </ol>"},{"location":"getting_started/installation.html#explore-omnigibson","title":"\ud83c\udf0e Explore <code>OmniGibson</code>!","text":"<p>Expect slowdown during first execution</p> <p>Omniverse requires some one-time startup setup (up to ~5 minutes) when <code>OmniGibson</code> is imported for the first time. This is expected behavior, and should only occur once!</p> <p><code>OmniGibson</code> is now successfully installed! Try exploring some of our new scenes interactively:</p> <pre><code>python -m omnigibson.examples.scenes.scene_selector # (1)!\n</code></pre> <ol> <li>This demo lets you choose a scene and interactively move around using your keyboard and mouse. Hold down <code>Shift</code> and then <code>Left-click + Drag</code> an object to apply forces!</li> </ol> <p>You can also try teleoperating one of our robots:</p> <pre><code>python -m omnigibson.examples.robots.robot_control_example # (1)!\n</code></pre> <ol> <li>This demo lets you choose a scene, robot, and set of controllers, and then teleoperate the robot using your keyboard.</li> </ol> <p>Next: Get quickly familiarized with <code>OmniGibson</code> from our Quickstart Guide!</p>"},{"location":"getting_started/quickstart.html","title":"\ud83d\ude80 Quickstart","text":"<p>Let's quickly create an environment programmatically!</p> <p><code>OmniGibson</code>'s workflow is straightforward: define the configuration of scene, object(s), robot(s), and task you'd like to load, and then instantiate our <code>Environment</code> class with that config.</p> <p>Let's start with the following:</p> <pre><code>import omnigibson as og # (1)!\nfrom omnigibson.macros import gm # (2)!\n# Start with an empty configuration\ncfg = dict()\n</code></pre> <ol> <li>All python scripts should start with this line! This allows access to key global variables through the top-level package.</li> <li>Global macros (<code>gm</code>) can always be accessed directly and modified on the fly!</li> </ol>"},{"location":"getting_started/quickstart.html#defining-a-scene","title":"\ud83c\udfd4\ufe0f Defining a scene","text":"<p>Next, let's define a scene:</p> <pre><code>cfg[\"scene\"] = {\n\"type\": \"Scene\", # (1)!\n\"floor_plane_visible\": True, # (2)!\n}\n</code></pre> <ol> <li>Our configuration gets parsed automatically and generates the appropriate class instance based on <code>type</code> (the string form of the class name). In this case, we're generating the most basic scene, which only consists of a floor plane. Check out all of our available <code>Scene</code> classes!</li> <li>In addition to specifying <code>type</code>, the remaining keyword-arguments get passed directly into the class constructor. So for the base <code>Scene</code> class, you could optionally specify <code>\"use_floor_plane\"</code> and <code>\"floor_plane_visible\"</code>, whereas for the more powerful <code>InteractiveTraversableScene</code> class (which loads a curated, preconfigured scene) you can additionally specify options for filtering objects, such as <code>\"load_object_categories\"</code> and <code>\"load_room_types\"</code>. You can see all available keyword-arguments by viewing the individual <code>Scene</code> class you'd like to load!</li> </ol>"},{"location":"getting_started/quickstart.html#defining-objects","title":"\ud83c\udfbe Defining objects","text":"<p>We can optionally define some objects to load into our scene:</p> <pre><code>cfg[\"objects\"] = [ # (1)!\n{\n\"type\": \"USDObject\", # (2)!\n\"name\": \"ghost_stain\", # (3)!\n\"usd_path\": f\"{gm.ASSET_PATH}/models/stain/stain.usd\",\n\"category\": \"stain\", # (4)!\n\"visual_only\": True, # (5)!\n\"scale\": [2.0, 1.0, 2.0], # (6)!\n\"position\": [3.0, 0, 2.0], # (7)!\n\"orientation\": [0, 0, 0, 1.0], # (8)!\n},\n{\n\"type\": \"DatasetObject\", # (9)!\n\"name\": \"delicious_apple\",\n\"category\": \"apple\",\n\"model\": \"agveuv\", # (10)!\n\"position\": [0, 0, 1.0],\n},\n{\n\"type\": \"PrimitiveObject\", # (11)!\n\"name\": \"incredible_box\",\n\"primitive_type\": \"Cube\", # (12)!\n\"rgba\": [0, 1.0, 1.0, 1.0], # (13)!\n\"scale\": [0.5, 0.5, 0.1],\n\"fixed_base\": True, # (14)!\n\"position\": [-1.0, 0, 1.0],\n\"orientation\": [0, 0, 0.707, 0.707],\n},\n{\n\"type\": \"LightObject\", # (15)!\n\"name\": \"brilliant_light\",\n\"light_type\": \"Sphere\", # (16)!\n\"intensity\": 50000, # (17)!\n\"radius\": 0.1, # (18)!\n\"position\": [3.0, 3.0, 4.0],\n},\n]\n</code></pre> <ol> <li>Unlike the <code>\"scene\"</code> sub-config, we can define an arbitrary number of objects to load, so this is a <code>list</code> of <code>dict</code> istead of a single nested <code>dict</code>.</li> <li><code>OmniGibson</code> supports multiple object classes, and we showcase an instance of each core class here. A <code>USDObject</code> is our most generic object class, and generates an object sourced from the <code>usd_path</code> argument.</li> <li>All objects must define the <code>name</code> argument! This is because <code>OmniGibson</code> enforces a global unique naming scheme, and so any created objects must have unique names assigned to them.</li> <li><code>category</code> is used by all object classes to assign semantic segmentation IDs.</li> <li><code>visual_only</code> is used by all object classes and defines whether the object is subject to both gravity and collisions.</li> <li><code>scale</code> is used by all object classes and defines the global (x,y,z) relative scale of the object.</li> <li><code>position</code> is used by all object classes and defines the initial (x,y,z) position of the object in the global frame.</li> <li><code>orientation</code> is used by all object classes and defines the initial (x,y,z,w) quaternion orientation of the object in the global frame.</li> <li>A <code>DatasetObject</code> is an object pulled directly from our BEHAVIOR dataset. It includes metadata and annotations not found on a generic <code>USDObject</code>. Note that these assets are encrypted, and thus cannot be created via the <code>USDObject</code> class.</li> <li>Instead of explicitly defining the hardcoded path to the dataset USD model, <code>model</code> (in conjunction with <code>category</code>) is used to infer the exact dataset object to load. In this case this is the exact same underlying raw USD asset that was loaded above as a <code>USDObject</code>!</li> <li>A <code>PrimitiveObject</code> is a programmatically generated object defining a convex primitive shape.</li> <li><code>primitive_type</code> defines what primitive shape to load -- see <code>PrimitiveObject</code> for available options!</li> <li>Because this object is programmatically generated, we can also specify the color to assign to this primitive object.</li> <li><code>fixed_base</code> is used by all object classes and determines whether the generated object is fixed relative to the world frame. Useful for fixing in place large objects, such as furniture or structures.</li> <li>A <code>LightObject</code> is a programmatically generated light source. It is used to directly illuminate the given scene.</li> <li><code>light_type</code> defines what light shape to load -- see <code>LightObject</code> for available options!</li> <li><code>intensity</code> defines how bright the generated light source should be.</li> <li><code>radius</code> is used by <code>Sphere</code> lights and determines their relative size.</li> </ol>"},{"location":"getting_started/quickstart.html#defining-robots","title":"\ud83e\udd16 Defining robots","text":"<p>We can also optionally define robots to load into our scene:</p> <pre><code>cfg[\"robots\"] = [ # (1)!\n{\n\"type\": \"Fetch\", # (2)!\n\"name\": \"baby_robot\",\n\"obs_modalities\": [\"scan\", \"rgb\", \"depth\"], # (3)!\n},\n]\n</code></pre> <ol> <li>Like the <code>\"objects\"</code> sub-config, we can define an arbitrary number of robots to load, so this is a <code>list</code> of <code>dict</code>.</li> <li><code>OmniGibson</code> supports multiple robot classes, where each class represents a specific robot model. Check out our <code>robots</code> to view all available robot classes!</li> <li>Execute <code>print(og.ALL_SENSOR_MODALITIES)</code> for a list of all available observation modalities!</li> </ol>"},{"location":"getting_started/quickstart.html#defining-a-task","title":"\ud83d\udccb Defining a task","text":"<p>Lastly, we can optionally define a task to load into our scene. Since we're just getting started, let's load a \"Dummy\" task: (1)</p> <ol> <li>Note: this is the task that is loaded anyways even if we don't explicitly define a task in our config!</li> </ol> <pre><code>cfg[\"task\"] = {\n\"type\": \"DummyTask\", # (1)!\n\"termination_config\": dict(), # (2)!\n\"reward_config\": dict(), # (3)!\n}\n</code></pre> <ol> <li>Check out all of <code>OmniGibson</code>'s available tasks!</li> <li><code>termination_config</code> configures the termination conditions for this task. It maps specific <code>TerminationCondition</code> arguments to their corresponding values to set.</li> <li><code>reward_config</code> configures the reward functions for this task. It maps specific <code>RewardFunction</code> arguments to their corresponding values to set.</li> </ol>"},{"location":"getting_started/quickstart.html#creating-the-environment","title":"\ud83c\udf00 Creating the environment","text":"<p>We're all set! Let's load the config and create our environment:</p> <pre><code>env = og.Environment(cfg)\n</code></pre> <p>Once the environment loads, we can interface with our environment similar to OpenAI's Gym interface:</p> <pre><code>obs, rew, done, info = env.step(env.action_space.sample())\n</code></pre> What happens if we have no robot loaded? <p>Even if we have no robot loaded, we still need to define an \"action\" to pass into the environment. In this case, our action space is 0, so you can simply pass <code>[]</code> or <code>np.array([])</code> into the <code>env.step()</code> call!</p> my_first_env.py <pre><code>import omnigibson as og\ncfg = dict()\n# Define scene\ncfg[\"scene\"] = {\n\"type\": \"Scene\",\n\"floor_plane_visible\": True,\n}\n# Define objects\ncfg[\"objects\"] = [\n{\n\"type\": \"USDObject\",\n\"name\": \"ghost_stain\",\n\"usd_path\": f\"{gm.ASSET_PATH}/models/stain/stain.usd\",\n\"category\": \"stain\",\n\"visual_only\": True,\n\"scale\": [2.0, 1.0, 2.0],\n\"position\": [3.0, 0, 2.0],\n\"orientation\": [0, 0, 0, 1.0],\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"delicious_apple\",\n\"category\": \"apple\",\n\"model\": \"agveuv\",\n\"position\": [0, 0, 1.0],\n},\n{\n\"type\": \"PrimitiveObject\",\n\"name\": \"incredible_box\",\n\"primitive_type\": \"Cube\",\n\"rgba\": [0, 1.0, 1.0, 1.0],\n\"scale\": [0.5, 0.5, 0.1],\n\"fixed_base\": True,\n\"position\": [-1.0, 0, 1.0],\n\"orientation\": [0, 0, 0.707, 0.707],\n},\n{\n\"type\": \"LightObject\",\n\"name\": \"brilliant_light\",\n\"light_type\": \"Sphere\",\n\"intensity\": 50000,\n\"radius\": 0.1,\n\"position\": [3.0, 3.0, 4.0],\n},\n]\n# Define robots\ncfg[\"robots\"] = [\n{\n\"type\": \"Fetch\",\n\"name\": \"skynet_robot\",\n\"obs_modalities\": [\"scan\", \"rgb\", \"depth\"],\n},\n]\n# Define task\ncfg[\"task\"] = {\n\"type\": \"DummyTask\",\n\"termination_config\": dict(),\n\"reward_config\": dict(),\n}\n# Create the environment\nenv = og.Environment(cfg)\n# Allow camera teleoperation\nog.sim.enable_viewer_camera_teleoperation()\n# Step!\nfor _ in range(10000):\nobs, rew, done, info = env.step(env.action_space.sample())\n</code></pre>"},{"location":"getting_started/quickstart.html#looking-around","title":"\ud83d\udc40 Looking around","text":"<p>Look around by:</p> <ul> <li><code>Left-CLICK + Drag</code>: Tilt</li> <li><code>Scroll-Wheel-CLICK + Drag</code>: Pan</li> <li><code>Scroll-Wheel UP / DOWN</code>: Zoom</li> </ul> <p>Interact with objects by:</p> <ul> <li><code>Shift + Left-CLICK + Drag</code>: Apply force on selected object</li> </ul> <p>Or, for more fine-grained control, run: <pre><code>og.sim.enable_viewer_camera_teleoperation() # (1)!\n</code></pre></p> <ol> <li>This allows you to move the camera precisely with your keyboard, record camera poses, and dynamically modify lights!</li> </ol> <p>Or, for programmatic control, directly set the viewer camera's global pose:</p> <pre><code>og.sim.viewer_camera.set_position_orientation(&lt;POSITION&gt;, &lt;ORIENTATION&gt;)\n</code></pre> <p>Next: Check out some of <code>OmniGibson</code>'s breadth of features from our Building Block examples!</p>"},{"location":"reference/SUMMARY.html","title":"API Reference","text":"<ul> <li>controllers<ul> <li>controller_base</li> <li>dd_controller</li> <li>ik_controller</li> <li>joint_controller</li> <li>multi_finger_gripper_controller</li> <li>null_joint_controller</li> </ul> </li> <li>envs<ul> <li>env_base</li> </ul> </li> <li>examples<ul> <li>environments<ul> <li>behavior_env_demo</li> <li>navigation_env_demo</li> </ul> </li> <li>learning<ul> <li>navigation_policy_demo</li> </ul> </li> <li>object_states<ul> <li>attachment_demo</li> <li>dicing_demo</li> <li>folded_unfolded_state_demo</li> <li>heat_source_or_sink_demo</li> <li>heated_state_demo</li> <li>object_state_texture_demo</li> <li>onfire_demo</li> <li>overlaid_demo</li> <li>particle_applier_remover_demo</li> <li>particle_source_sink_demo</li> <li>sample_kinematics_demo</li> <li>slicing_demo</li> <li>temperature_demo</li> </ul> </li> <li>objects<ul> <li>draw_bounding_box</li> <li>highlight_objects</li> <li>load_object_selector</li> <li>visualize_object</li> </ul> </li> <li>renderer_settings<ul> <li>renderer_settings_example</li> </ul> </li> <li>robots<ul> <li>advanced<ul> <li>ik_example</li> </ul> </li> <li>all_robots_visualizer</li> <li>grasping_mode_example</li> <li>robot_control_example</li> </ul> </li> <li>scenes<ul> <li>scene_selector</li> <li>scene_tour_demo</li> <li>traversability_map_example</li> </ul> </li> <li>simulator<ul> <li>sim_save_load_example</li> </ul> </li> </ul> </li> <li>macros</li> <li>maps<ul> <li>map_base</li> <li>segmentation_map</li> <li>traversable_map</li> </ul> </li> <li>object_states<ul> <li>aabb</li> <li>adjacency</li> <li>attached_to</li> <li>burnt</li> <li>contact_bodies</li> <li>contact_particles</li> <li>contact_subscribed_state_mixin</li> <li>cooked</li> <li>covered</li> <li>factory</li> <li>filled</li> <li>folded</li> <li>frozen</li> <li>heat_source_or_sink</li> <li>heated</li> <li>inside</li> <li>joint_break_subscribed_state_mixin</li> <li>kinematics</li> <li>link_based_state_mixin</li> <li>max_temperature</li> <li>next_to</li> <li>object_state_base</li> <li>on_fire</li> <li>on_top</li> <li>open</li> <li>overlaid</li> <li>particle_modifier</li> <li>particle_source_or_sink</li> <li>pose</li> <li>saturated</li> <li>sliced</li> <li>slicer</li> <li>temperature</li> <li>toggle</li> <li>touching</li> <li>under</li> <li>unfolded</li> <li>update_state_mixin</li> <li>water_sink</li> <li>water_source</li> </ul> </li> <li>objects<ul> <li>controllable_object</li> <li>dataset_object</li> <li>light_object</li> <li>object_base</li> <li>primitive_object</li> <li>stateful_object</li> <li>usd_object</li> </ul> </li> <li>prims<ul> <li>cloth_prim</li> <li>entity_prim</li> <li>geom_prim</li> <li>joint_prim</li> <li>material_prim</li> <li>prim_base</li> <li>rigid_prim</li> <li>xform_prim</li> </ul> </li> <li>renderer_settings<ul> <li>common_settings</li> <li>path_tracing_settings</li> <li>post_processing_settings</li> <li>real_time_settings</li> <li>renderer_settings</li> <li>settings_base</li> </ul> </li> <li>reward_functions<ul> <li>collision_reward</li> <li>point_goal_reward</li> <li>potential_reward</li> <li>reaching_goal_reward</li> <li>reward_function_base</li> </ul> </li> <li>robots<ul> <li>active_camera_robot</li> <li>fetch</li> <li>freight</li> <li>husky</li> <li>locobot</li> <li>locomotion_robot</li> <li>manipulation_robot</li> <li>robot_base</li> <li>tiago</li> <li>turtlebot</li> <li>two_wheel_robot</li> </ul> </li> <li>scenes<ul> <li>interactive_traversable_scene</li> <li>scene_base</li> <li>static_traversable_scene</li> <li>traversable_scene</li> </ul> </li> <li>scripts<ul> <li>setup</li> </ul> </li> <li>sensors<ul> <li>dropout_sensor_noise</li> <li>scan_sensor</li> <li>sensor_base</li> <li>sensor_noise_base</li> <li>vision_sensor</li> </ul> </li> <li>simulator</li> <li>systems<ul> <li>macro_particle_system</li> <li>micro_particle_system</li> <li>system_base</li> </ul> </li> <li>tasks<ul> <li>bddl_backend</li> <li>behavior_task</li> <li>dummy_task</li> <li>point_navigation_task</li> <li>point_reaching_task</li> <li>task_base</li> </ul> </li> <li>termination_conditions<ul> <li>falling</li> <li>max_collision</li> <li>point_goal</li> <li>predicate_goal</li> <li>reaching_goal</li> <li>termination_condition_base</li> <li>timeout</li> </ul> </li> <li>transition_rules</li> <li>utils<ul> <li>asset_utils</li> <li>config_utils</li> <li>constants</li> <li>control_utils</li> <li>deprecated_utils</li> <li>geometry_utils</li> <li>git_utils</li> <li>gym_utils</li> <li>object_state_utils</li> <li>physx_utils</li> <li>processing_utils</li> <li>python_utils</li> <li>registry_utils</li> <li>render_utils</li> <li>sampling_utils</li> <li>sim_utils</li> <li>transform_utils</li> <li>ui_utils</li> <li>usd_utils</li> <li>vision_utils</li> </ul> </li> <li>wrappers<ul> <li>wrapper_base</li> </ul> </li> </ul>"},{"location":"reference/macros.html","title":"macros","text":"<p>Set of macros to use globally for OmniGibson. These are generally magic numbers that were tuned heuristically.</p> <p>NOTE: This is generally decentralized -- the monolithic @settings variable is created here with some global values, but submodules within OmniGibson may import this dictionary and add to it dynamically</p>"},{"location":"reference/macros.html#macros.create_module_macros","title":"<code>create_module_macros(module_path)</code>","text":"<p>Creates a dictionary that can be populated with module macros based on the module's @module_path</p> <p>Parameters:</p> Name Type Description Default <code>module_path</code> <code>str</code> <p>Relative path from the package root directory pointing to the module. This will be parsed to generate the appropriate sub-macros dictionary, e.g., for module \"dirty\" in omnigibson/object_states_dirty.py, this would generate a dictionary existing at macros.object_states.dirty</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <p>addict dictionary which can be populated with values</p> Source code in <code>omnigibson/macros.py</code> <pre><code>def create_module_macros(module_path):\n\"\"\"\n    Creates a dictionary that can be populated with module macros based on the module's @module_path\n    Args:\n        module_path (str): Relative path from the package root directory pointing to the module. This will be parsed\n            to generate the appropriate sub-macros dictionary, e.g., for module \"dirty\" in\n            omnigibson/object_states_dirty.py, this would generate a dictionary existing at macros.object_states.dirty\n    Returns:\n        Dict: addict dictionary which can be populated with values\n    \"\"\"\n# Sanity check module path, make sure omnigibson/ is in the path\nmodule_path = pathlib.Path(module_path)\nomnigibson_path = pathlib.Path(__file__).parent\n# Trim the .py, and anything before and including omnigibson/, and split into its appropriate parts\ntry:\nsubsections = module_path.with_suffix(\"\").relative_to(omnigibson_path).parts\nexcept ValueError:\nraise ValueError(\"module_path is expected to be a filepath including the omnigibson root directory, got: {module_path}!\")\n# Create and return the generated sub-dictionary\ndef _recursively_get_or_create_dict(dic, keys):\n# If no entry is in @keys, it returns @dic\n# Otherwise, checks whether the dictionary contains the first entry in @keys, if so, it grabs the\n# corresponding nested dictionary, otherwise, generates a new Dict() as the value\n# It then recurisvely calls this function with the new dic and the remaining keys\nif len(keys) == 0:\nreturn dic\nelse:\nkey = keys[0]\nif key not in dic:\ndic[key] = Dict()\nreturn _recursively_get_or_create_dict(dic=dic[key], keys=keys[1:])\nreturn _recursively_get_or_create_dict(dic=macros, keys=subsections)\n</code></pre>"},{"location":"reference/simulator.html","title":"simulator","text":""},{"location":"reference/simulator.html#simulator.Simulator","title":"<code>Simulator</code>","text":"<p>         Bases: <code>SimulationContext</code>, <code>Serializable</code></p> <p>Simulator class for directly interfacing with the physx physics engine.</p> This is a monolithic class. <p>All created Simulator() instances will reference the same underlying Simulator object</p> <p>Parameters:</p> Name Type Description Default <code>gravity</code> <code>float</code> <p>gravity on z direction.</p> <code>9.81</code> <code>physics_dt</code> <code>float</code> <p>dt between physics steps. Defaults to 1.0 / 60.0.</p> <code>1.0 / 60.0</code> <code>rendering_dt</code> <code>float</code> <p>dt between rendering steps. Note: rendering means rendering a frame of the current application and not only rendering a frame to the viewports/ cameras. So UI elements of Isaac Sim will be refereshed with this dt as well if running non-headless. Defaults to 1.0 / 60.0.</p> <code>1.0 / 60.0</code> <code>stage_units_in_meters</code> <code>float</code> <p>The metric units of assets. This will affect gravity value..etc. Defaults to 0.01.</p> <code>1.0</code> <code>viewer_width</code> <code>int</code> <p>width of the camera image, in pixels</p> <code>gm.DEFAULT_VIEWER_WIDTH</code> <code>viewer_height</code> <code>int</code> <p>height of the camera image, in pixels</p> <code>gm.DEFAULT_VIEWER_HEIGHT</code> <code>device</code> <code>None or str</code> <p>specifies the device to be used if running on the gpu with torch backend</p> <code>None</code> Source code in <code>omnigibson/simulator.py</code> <pre><code>class Simulator(SimulationContext, Serializable):\n\"\"\"\n    Simulator class for directly interfacing with the physx physics engine.\n    NOTE: This is a monolithic class.\n        All created Simulator() instances will reference the same underlying Simulator object\n    Args:\n        gravity (float): gravity on z direction.\n        physics_dt (float): dt between physics steps. Defaults to 1.0 / 60.0.\n        rendering_dt (float): dt between rendering steps. Note: rendering means rendering a frame of the current\n            application and not only rendering a frame to the viewports/ cameras. So UI elements of Isaac Sim will\n            be refereshed with this dt as well if running non-headless. Defaults to 1.0 / 60.0.\n        stage_units_in_meters (float): The metric units of assets. This will affect gravity value..etc.\n            Defaults to 0.01.\n        viewer_width (int): width of the camera image, in pixels\n        viewer_height (int): height of the camera image, in pixels\n        device (None or str): specifies the device to be used if running on the gpu with torch backend\n        \"\"\"\n_world_initialized = False\ndef __init__(\nself,\ngravity=9.81,\nphysics_dt=1.0 / 60.0,\nrendering_dt=1.0 / 60.0,\nstage_units_in_meters=1.0,\nviewer_width=gm.DEFAULT_VIEWER_WIDTH,\nviewer_height=gm.DEFAULT_VIEWER_HEIGHT,\ndevice=None,\n):\nsuper().__init__(\nphysics_dt=physics_dt,\nrendering_dt=rendering_dt,\nstage_units_in_meters=stage_units_in_meters,\ndevice=device,\n)\nif self._world_initialized:\nreturn\nSimulator._world_initialized = True\n# Store other internal vars\nself.gravity = gravity\n# Store other references to variables that will be initialized later\nself._viewer_camera = None\nself._camera_mover = None\nself._scene = None\nself._physx_interface = None\nself._physx_simulation_interface = None\nself._physx_scene_query_interface = None\nself._contact_callback = None\nself._simulation_event_callback = None\n# List of objects that need to be initialized during whenever the next sim step occurs\nself._objects_to_initialize = []\nself._objects_require_contact_callback = False\nself._objects_require_joint_break_callback = False\n# Mapping from link IDs assigned from omni to the object that they reference\nself._link_id_to_objects = dict()\n# Set of categories that can be grasped by assisted grasping\nself.object_state_types = get_states_by_dependency_order()\nself.object_state_types_requiring_update = \\\n            [state for state in self.object_state_types if issubclass(state, UpdateStateMixin)]\nself.object_state_types_on_contact = \\\n            {state for state in self.object_state_types if issubclass(state, ContactSubscribedStateMixin)}\nself.object_state_types_on_joint_break = \\\n            {state for state in self.object_state_types if issubclass(state, JointBreakSubscribedStateMixin)}\n# Set of all non-Omniverse transition rules to apply.\nself._transition_rules = DEFAULT_RULES\nself._transition_object_init_states = dict()    # Maps object to object state to args to pass to state setter\n# Auto-load the dummy stage\nself.clear()\n# Set the viewer dimensions\n# TODO: Make this toggleable so we don't always have a viewer if we don't want to\nself.viewer_width = viewer_width\nself.viewer_height = viewer_height\n# Toggle simulator state once so that downstream omni features can be used without bugs\n# e.g.: particle sampling, which for some reason requires sim.play() to be called at least once\nself.play()\nself.stop()\n# Finally, update the physics settings\n# This needs to be done now, after an initial step + stop for some reason if we want to use GPU\n# dynamics, otherwise we get very strange behavior, e.g., PhysX complains about invalid transforms\n# and crashes\nself._set_physics_engine_settings()\ndef __new__(\ncls,\ngravity=9.81,\nphysics_dt=1.0 / 60.0,\nrendering_dt=1.0 / 60.0,\nstage_units_in_meters=1.0,\nviewer_width=gm.DEFAULT_VIEWER_WIDTH,\nviewer_height=gm.DEFAULT_VIEWER_HEIGHT,\ndevice_idx=0,\n):\n# Overwrite since we have different kwargs\nif Simulator._instance is None:\nSimulator._instance = object.__new__(cls)\nelse:\ncarb.log_info(\"Simulator is defined already, returning the previously defined one\")\nreturn Simulator._instance\ndef _set_viewer_camera(self, prim_path=\"/World/viewer_camera\", viewport_name=\"Viewport\"):\n\"\"\"\n        Creates a camera prim dedicated for this viewer at @prim_path if it doesn't exist,\n        and sets this camera as the active camera for the viewer\n        Args:\n            prim_path (str): Path to check for / create the viewer camera\n            viewport_name (str): Name of the viewport this camera should attach to. Default is \"Viewport\", which is\n                the default viewport's name in Isaac Sim\n        \"\"\"\nself._viewer_camera = VisionSensor(\nprim_path=prim_path,\nname=prim_path.split(\"/\")[-1],                  # Assume name is the lowest-level name in the prim_path\nmodalities=\"rgb\",\nimage_height=self.viewer_height,\nimage_width=self.viewer_width,\nviewport_name=viewport_name,\n)\nif not self._viewer_camera.loaded:\nself._viewer_camera.load()\n# We update its clipping range and focal length so we get a good FOV and so that it doesn't clip\n# nearby objects (default min is 1 m)\nself._viewer_camera.clipping_range = [0.001, 10000000.0]\nself._viewer_camera.focal_length = 17.0\n# Initialize the sensor\nself._viewer_camera.initialize()\n# Also need to potentially update our camera mover if it already exists\nif self._camera_mover is not None:\nself._camera_mover.set_cam(cam=self._viewer_camera)\ndef _set_physics_engine_settings(self):\n\"\"\"\n        Set the physics engine with specified settings\n        \"\"\"\nassert self.is_stopped(), f\"Cannot set simulator physics settings while simulation is playing!\"\nself._physics_context.set_gravity(value=-self.gravity)\n# Also make sure we invert the collision group filter settings so that different collision groups cannot\n# collide with each other, and modify settings for speed optimization\nself._physics_context.set_invert_collision_group_filter(True)\nself._physics_context.enable_ccd(gm.ENABLE_CCD)\nself._physics_context.enable_flatcache(gm.ENABLE_FLATCACHE)\n# Enable GPU dynamics based on whether we need omni particles feature\nif gm.USE_GPU_DYNAMICS:\nself._physics_context.enable_gpu_dynamics(True)\nself._physics_context.set_broadphase_type(\"GPU\")\nelse:\nself._physics_context.enable_gpu_dynamics(False)\nself._physics_context.set_broadphase_type(\"MBP\")\n# Set GPU Pairs capacity and other GPU settings\nself._physics_context.set_gpu_found_lost_pairs_capacity(gm.GPU_PAIRS_CAPACITY)\nself._physics_context.set_gpu_found_lost_aggregate_pairs_capacity(gm.GPU_AGGR_PAIRS_CAPACITY)\nself._physics_context.set_gpu_total_aggregate_pairs_capacity(gm.GPU_AGGR_PAIRS_CAPACITY)\nself._physics_context.set_gpu_max_particle_contacts(gm.GPU_MAX_PARTICLE_CONTACTS)\ndef _set_renderer_settings(self):\n# TODO: For now we are setting these to some reasonable high-performance values but these can be made configurable.\ncarb.settings.get_settings().set_bool(\"/rtx/reflections/enabled\", False)  # Can be True with a 10fps penalty\ncarb.settings.get_settings().set_bool(\"/rtx/indirectDiffuse/enabled\", True)  # Can be False with a 5fps gain\ncarb.settings.get_settings().set_bool(\"/rtx/directLighting/sampledLighting/enabled\", True)\ncarb.settings.get_settings().set_int(\"/rtx/raytracing/showLights\", 1)\ncarb.settings.get_settings().set_float(\"/rtx/sceneDb/ambientLightIntensity\", 0.1)\n# TODO: Think of better setting defaults. Below works well for indoor-only scenes, but if skybox is the only light source then this looks very bad\n# carb.settings.get_settings().set_int(\"/rtx/domeLight/upperLowerStrategy\", 3)  # \"Limited image-based\"\n@property\ndef viewer_visibility(self):\n\"\"\"\n        Returns:\n            bool: Whether the viewer is visible or not\n        \"\"\"\nreturn self._viewer_camera.viewer_visibility\n@viewer_visibility.setter\ndef viewer_visibility(self, visible):\n\"\"\"\n        Sets whether the viewer should be visible or not in the Omni UI\n        Args:\n            visible (bool): Whether the viewer should be visible or not\n        \"\"\"\nself._viewer_camera.viewer_visibility = visible\n@property\ndef viewer_height(self):\n\"\"\"\n        Returns:\n            int: viewer height of this sensor, in pixels\n        \"\"\"\n# If the viewer camera hasn't been created yet, utilize the default width\nreturn gm.DEFAULT_VIEWER_HEIGHT if self._viewer_camera is None else self._viewer_camera.image_height\n@viewer_height.setter\ndef viewer_height(self, height):\n\"\"\"\n        Sets the viewer height @height for this sensor\n        Args:\n            height (int): viewer height, in pixels\n        \"\"\"\nself._viewer_camera.image_height = height\n@property\ndef viewer_width(self):\n\"\"\"\n        Returns:\n            int: viewer width of this sensor, in pixels\n        \"\"\"\n# If the viewer camera hasn't been created yet, utilize the default height\nreturn gm.DEFAULT_VIEWER_WIDTH if self._viewer_camera is None else self._viewer_camera.image_width\n@viewer_width.setter\ndef viewer_width(self, width):\n\"\"\"\n        Sets the viewer width @width for this sensor\n        Args:\n            width (int): viewer width, in pixels\n        \"\"\"\nself._viewer_camera.image_width = width\ndef set_lighting_mode(self, mode):\n\"\"\"\n        Sets the active lighting mode in the current simulator. Valid options are one of LightingMode\n        Args:\n            mode (LightingMode): Lighting mode to set\n        \"\"\"\nomni.kit.commands.execute(\"SetLightingMenuModeCommand\", lighting_mode=mode)\ndef enable_viewer_camera_teleoperation(self):\n\"\"\"\n        Enables keyboard control of the active viewer camera for this simulation\n        \"\"\"\nself._camera_mover = CameraMover(cam=self._viewer_camera)\nself._camera_mover.print_info()\nreturn self._camera_mover\ndef import_scene(self, scene):\n\"\"\"\n        Import a scene into the simulator. A scene could be a synthetic one or a realistic Gibson Environment.\n        Args:\n            scene (Scene): a scene object to load\n        \"\"\"\nassert self.is_stopped(), \"Simulator must be stopped while importing a scene!\"\nassert isinstance(scene, Scene), \"import_scene can only be called with Scene\"\n# Clear the existing scene if any\nself.clear()\nself._scene = scene\nself._scene.load()\n# Make sure simulator is not running, then start it so that we can initialize the scene\nassert self.is_stopped(), \"Simulator must be stopped after importing a scene!\"\nself.play()\n# Initialize the scene\nself._scene.initialize()\n# Need to one more step for particle systems to work\nself.step()\nself.stop()\nlog.info(\"Imported scene.\")\ndef initialize_object_on_next_sim_step(self, obj):\n\"\"\"\n        Initializes the object upon the next simulation step\n        Args:\n            obj (BasePrim): Object to initialize as soon as a new sim step is called\n        \"\"\"\nself._objects_to_initialize.append(obj)\ndef import_object(self, obj, register=True, auto_initialize=True):\n\"\"\"\n        Import an object into the simulator.\n        Args:\n            obj (BaseObject): an object to load\n            register (bool): whether to register this object internally in the scene registry\n            auto_initialize (bool): If True, will auto-initialize the requested object on the next simulation step.\n                Otherwise, we assume that the object will call initialize() on its own!\n        \"\"\"\nassert isinstance(obj, BaseObject), \"import_object can only be called with BaseObject\"\n# Make sure scene is loaded -- objects should not be loaded unless we have a reference to a scene\nassert self.scene is not None, \"import_object needs to be called after import_scene\"\n# Load the object in omniverse by adding it to the scene\nself.scene.add_object(obj, register=register, _is_call_from_simulator=True)\n# Cache the mapping from link IDs to object\nfor link in obj.links.values():\nself._link_id_to_objects[PhysicsSchemaTools.sdfPathToInt(link.prim_path)] = obj\n# Lastly, additionally add this object automatically to be initialized as soon as another simulator step occurs\n# if requested\nif auto_initialize:\nself.initialize_object_on_next_sim_step(obj=obj)\ndef remove_object(self, obj):\n\"\"\"\n        Remove a non-robot object from the simulator.\n        Args:\n            obj (BaseObject): a non-robot object to load\n        \"\"\"\n# pop all link ids\nfor link in obj.links.values():\nself._link_id_to_objects.pop(PhysicsSchemaTools.sdfPathToInt(link.prim_path))\nself._scene.remove_object(obj)\nself.app.update()\ndef _reset_variables(self):\n\"\"\"\n        Reset internal variables when a new stage is loaded\n        \"\"\"\ndef _non_physics_step(self):\n\"\"\"\n        Complete any non-physics steps such as state updates.\n        \"\"\"\nassert not self.is_stopped(), f\"Simulator must not be stopped in order to run non physics step!\"\n# Check to see if any objects should be initialized (only done IF we're playing)\nn_objects_to_initialize = len(self._objects_to_initialize)\nif n_objects_to_initialize &gt; 0 and self.is_playing():\n# We iterate through the objects to initialize\n# Note that we don't explicitly do for obj in self._objects_to_initialize because additional objects\n# may be added mid-iteration!!\n# For this same reason, after we finish the loop, we keep any objects that are yet to be initialized\nfor i in range(n_objects_to_initialize):\nobj = self._objects_to_initialize[i]\nobj.initialize()\nif len(obj.states.keys() &amp; self.object_state_types_on_contact) &gt; 0:\nself._objects_require_contact_callback = True\nif len(obj.states.keys() &amp; self.object_state_types_on_joint_break) &gt; 0:\nself._objects_require_joint_break_callback = True\nself._objects_to_initialize = self._objects_to_initialize[n_objects_to_initialize:]\n# Propagate states if the feature is enabled\nif gm.ENABLE_OBJECT_STATES:\n# Step the object states in global topological order (if the scene exists).\nif self.scene is not None:\nfor state_type in self.object_state_types_requiring_update:\nfor obj in self.scene.get_objects_with_state(state_type):\n# Only update objects that have been initialized so far\nif obj.initialized:\nobj.states[state_type].update()\nfor obj in self.scene.objects:\n# Only update visuals for objects that have been initialized so far\nif isinstance(obj, StatefulObject) and obj.initialized:\nobj.update_visuals()\ndef _omni_update_step(self):\n\"\"\"\n        Step any omni-related things\n        \"\"\"\n# Clear the bounding box cache so that it gets updated during the next time it's called\nBoundingBoxAPI.clear()\ndef _transition_rule_step(self):\n\"\"\"\n        Applies all internal non-Omniverse transition rules.\n        \"\"\"\n# Apply any transiiton object init states from before, and then clear the dictionary\nfor obj, states_info in self._transition_object_init_states.items():\nfor state, args in states_info.items():\nobj.states[state].set_value(*args)\nself._transition_object_init_states = dict()\n# Create a dict from rule to filter to objects we care about.\nobj_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\nfor obj in self.scene.objects:\nfor rule in self._transition_rules:\nfor fname, f in rule.individual_filters.items():\nif f(obj):\nobj_dict[rule][\"individual\"][fname].append(obj)\nfor fname, f in rule.group_filters.items():\nif f(obj):\nobj_dict[rule][\"group\"][fname].append(obj)\n# For each rule, create a subset of the dict and apply it if applicable.\nadded_obj_attrs = []\nremoved_objs = []\nfor rule in self._transition_rules:\n# Skip any rule that has no objects\nif rule not in obj_dict:\ncontinue\n# Skip any rule that has no group filters if it requires group filters\ngroup_f_objs = dict()\nif rule.requires_group_filters:\ngroup_f_objs = obj_dict[rule][\"group\"]\nif len(group_f_objs) == 0:\ncontinue\n# Skip any rule that is missing an individual filter if it requires individual filters\nif rule.requires_individual_filters:\nindividual_f_objs = obj_dict[rule][\"individual\"]\nif not all(fname in individual_f_objs for fname in rule.individual_filters.keys()):\ncontinue\n# Get all cartesian cross product over all individual filter objects, and then attempt the transition rule.\n# If objects are to be added / removed, the transition function is\n# expected to return an instance of TransitionResults containing\n# information about those objects.\n# TODO: Consider optimizing itertools.product.\n# TODO: Track what needs to be added / removed at the Scene object level.\n# Comments from a PR on possible changes:\n# - Addition / removal tracking on the Scene object.\n# - Check if the objects are still in the scene in each step.\nfor obj_tuple in itertools.product(*list(individual_f_objs.values())):\nindividual_objects = {fname: obj for fname, obj in zip(individual_f_objs.keys(), obj_tuple)}\ndid_transition, transition_output = rule.process(individual_objects=individual_objects, group_objects=group_f_objs)\nif transition_output is not None:\n# Transition output is a TransitionResults object\nadded_obj_attrs.extend(transition_output.add)\nremoved_objs.extend(transition_output.remove)\nelse:\n# We try the transition rule once, since there's no cartesian cross product of combinations from the\n# individual filters we need to handle\ndid_transition, transition_output = rule.process(individual_objects=dict(), group_objects=group_f_objs)\nif transition_output is not None:\nadded_obj_attrs.extend(transition_output.add)\nremoved_objs.extend(transition_output.remove)\n# Process all transition results.\nif len(removed_objs) &gt; 0:\ndisclaimer(\nf\"We are attempting to remove objects during the transition rule phase of the simulator step.\\n\"\nf\"However, Omniverse currently has a bug when using GPU dynamics where a segfault will occur if an \"\nf\"object in contact with another object is attempted to be removed.\\n\"\nf\"This bug should be fixed by the next Omniverse release.\\n\"\nf\"In the meantime, we instead teleport these objects to a graveyard location located far outside of \"\nf\"the scene.\"\n)\nfor i, removed_obj in enumerate(removed_objs):\n# TODO: Ideally we want to remove objects, but because of Omniverse's bug on GPU physics, we simply move\n# the objects into a graveyard for now\n# self.remove_object(removed_obj)\nremoved_obj.set_position(np.array(m.OBJECT_GRAVEYARD_POS) + np.ones(3) * i)\nfor added_obj_attr in added_obj_attrs:\nnew_obj = added_obj_attr.obj\nself.import_object(new_obj)\n# By default, added_obj_attr is populated with all Nones -- so these will all be pass-through operations\n# unless pos / orn (or, conversely, bb_pos / bb_orn) is specified\nif added_obj_attr.pos is not None or added_obj_attr.orn is not None:\nnew_obj.set_position_orientation(position=added_obj_attr.pos, orientation=added_obj_attr.orn)\nelif isinstance(new_obj, DatasetObject) and \\\n                    (added_obj_attr.bb_pos is not None or added_obj_attr.bb_orn is not None):\nnew_obj.set_bbox_center_position_orientation(position=added_obj_attr.bb_pos, orientation=added_obj_attr.bb_orn)\n# Additionally record any requested states if specified to be updated during the next transition step\nif added_obj_attr.states is not None:\nself._transition_object_init_states[new_obj] = added_obj_attr.states\ndef play(self):\nif not self.is_playing():\n# Track whether we're starting the simulator fresh -- i.e.: whether we were stopped previously\nwas_stopped = self.is_stopped()\n# Run super first\n# We suppress warnings from omni.usd because it complains about values set in the native USD\n# These warnings occur because the native USD file has some type mismatch in the `scale` property,\n# where the property expects a double but for whatever reason the USD interprets its values as floats\n# We also need to suppress the following error when flat cache is used:\n# [omni.physx.plugin] Transformation change on non-root links is not supported.\nwith suppress_omni_log(channels=[\"omni.usd\", \"omni.physx.plugin\"] if gm.ENABLE_FLATCACHE else [\"omni.usd\"]):\nsuper().play()\n# Take a render step -- this is needed so that certain (unknown, maybe omni internal state?) is populated\n# correctly.\nself.render()\n# Update all object handles\nif self.scene is not None and self.scene.initialized:\nfor obj in self.scene.objects:\n# Only need to update if object is already initialized as well\nif obj.initialized:\nobj.update_handles()\nif was_stopped:\n# We need to update controller mode because kp and kd were set to the original (incorrect) values when\n# sim was stopped. We need to reset them to default_kp and default_kd defined in ControllableObject.\n# We also need to take an additional sim step to make sure simulator is functioning properly.\n# We need to do this because for some reason omniverse exhibits strange behavior if we do certain\n# operations immediately after playing; e.g.: syncing USD poses when flatcache is enabled\nif self.scene is not None and self.scene.initialized:\nfor robot in self.scene.robots:\nif robot.initialized:\nrobot.update_controller_mode()\nself.step_physics()\n# Additionally run non physics things if we have a valid scene\nif self._scene is not None:\nself._omni_update_step()\nself._non_physics_step()\nif gm.ENABLE_TRANSITION_RULES:\nself._transition_rule_step()\ndef pause(self):\nif not self.is_paused():\nsuper().pause()\ndef stop(self):\nif not self.is_stopped():\nsuper().stop()\n# If we're using flatcache, we also need to reset its API\nif gm.ENABLE_FLATCACHE:\nFlatcacheAPI.reset()\n@property\ndef n_physics_timesteps_per_render(self):\n\"\"\"\n        Number of physics timesteps per rendering timestep. rendering_dt has to be a multiple of physics_dt.\n        Returns:\n            int: Discrete number of physics timesteps to take per step\n        \"\"\"\nn_physics_timesteps_per_render = self.get_rendering_dt() / self.get_physics_dt()\nassert n_physics_timesteps_per_render.is_integer(), \"render_timestep must be a multiple of physics_timestep\"\nreturn int(n_physics_timesteps_per_render)\ndef step(self, render=True, force_playing=False):\n\"\"\"\n        Step the simulation at self.render_timestep\n        Args:\n            render (bool): Whether rendering should occur or not\n            force_playing (bool): If True, will force physics to propagate (i.e.: set simulation, if paused / stopped,\n                to \"play\" mode)\n        \"\"\"\n# Possibly force playing\nif force_playing and not self.is_playing():\nself.play()\nif render:\nsuper().step(render=True)\nelse:\nfor i in range(self.n_physics_timesteps_per_render):\nsuper().step(render=False)\n# Additionally run non physics things if we have a valid scene\nif self._scene is not None:\nself._omni_update_step()\nif self.is_playing():\nself._non_physics_step()\nif gm.ENABLE_TRANSITION_RULES:\nself._transition_rule_step()\n# TODO (eric): After stage changes (e.g. pose, texture change), it will take two super().step(render=True) for\n#  the result to propagate to the rendering. We could have called super().render() here but it will introduce\n#  a big performance regression.\ndef step_physics(self):\n\"\"\"\n        Step the physics a single step.\n        \"\"\"\nself._physics_context._step(current_time=self.current_time)\ndef _on_contact(self, contact_headers, contact_data):\n\"\"\"\n        This callback will be invoked after every PHYSICS step if there is any contact.\n        For each of the pair of objects in each contact, we invoke the on_contact function for each of its states\n        that subclass ContactSubscribedStateMixin. These states update based on contact events.\n        \"\"\"\nif gm.ENABLE_OBJECT_STATES and self._objects_require_contact_callback:\nheaders = defaultdict(list)\nfor contact_header in contact_headers:\nactor0_obj = self._link_id_to_objects.get(contact_header.actor0, None)\nactor1_obj = self._link_id_to_objects.get(contact_header.actor1, None)\n# If any of the objects cannot be found, skip\nif actor0_obj is None or actor1_obj is None:\ncontinue\n# If any of the objects is not initialized, skip\nif not actor0_obj.initialized or not actor1_obj.initialized:\ncontinue\n# If any of the objects is not stateful, skip\nif not isinstance(actor0_obj, StatefulObject) or not isinstance(actor1_obj, StatefulObject):\ncontinue\n# If any of the objects doesn't have states that require on_contact callbacks, skip\nif len(actor0_obj.states.keys() &amp; self.object_state_types_on_contact) == 0 or len(actor1_obj.states.keys() &amp; self.object_state_types_on_contact) == 0:\ncontinue\nheaders[tuple(sorted((actor0_obj, actor1_obj), key=lambda x: x.uuid))].append(contact_header)\nfor (actor0_obj, actor1_obj) in headers:\nfor obj0, obj1 in [(actor0_obj, actor1_obj), (actor1_obj, actor0_obj)]:\nfor state_type in self.object_state_types_on_contact:\nif state_type in obj0.states:\nobj0.states[state_type].on_contact(obj1, headers[(actor0_obj, actor1_obj)], contact_data)\ndef _on_simulation_event(self, event):\n\"\"\"\n        This callback will be invoked if there is any simulation event. Currently it only processes JOINT_BREAK event.\n        \"\"\"\nif gm.ENABLE_OBJECT_STATES:\nif event.type == int(SimulationEvent.JOINT_BREAK) and self._objects_require_joint_break_callback:\njoint_path = str(PhysicsSchemaTools.decodeSdfPath(event.payload[\"jointPath\"][0], event.payload[\"jointPath\"][1]))\nobj = None\n# TODO: recursively try to find the parent object of this joint\ntokens = joint_path.split(\"/\")\nfor i in range(2, len(tokens) + 1):\nobj = self._scene.object_registry(\"prim_path\", \"/\".join(tokens[:i]))\nif obj is not None:\nbreak\nif obj is None or not obj.initialized or not isinstance(obj, StatefulObject):\nreturn\nif len(obj.states.keys() &amp; self.object_state_types_on_joint_break) == 0:\nreturn\nfor state_type in self.object_state_types_on_joint_break:\nif state_type in obj.states:\nobj.states[state_type].on_joint_break(joint_path)\ndef is_paused(self):\n\"\"\"\n        Returns:\n            bool: True if the simulator is paused, otherwise False\n        \"\"\"\nreturn not (self.is_stopped() or self.is_playing())\n@contextlib.contextmanager\ndef stopped(self):\n\"\"\"\n        A context scope for making sure the simulator is stopped during execution within this scope.\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n# Infer what state we're currently in, then stop, yield, and then restore the original state\nsim_is_playing, sim_is_paused = self.is_playing(), self.is_paused()\nif sim_is_playing or sim_is_paused:\nself.stop()\nyield\nif sim_is_playing: self.play()\nelif sim_is_paused: self.pause()\n@contextlib.contextmanager\ndef playing(self):\n\"\"\"\n        A context scope for making sure the simulator is playing during execution within this scope.\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n# Infer what state we're currently in, then stop, yield, and then restore the original state\nsim_is_stopped, sim_is_paused = self.is_stopped(), self.is_paused()\nif sim_is_stopped or sim_is_paused:\nself.play()\nyield\nif sim_is_stopped: self.stop()\nelif sim_is_paused: self.pause()\n@contextlib.contextmanager\ndef paused(self):\n\"\"\"\n        A context scope for making sure the simulator is paused during execution within this scope.\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n# Infer what state we're currently in, then stop, yield, and then restore the original state\nsim_is_stopped, sim_is_playing = self.is_stopped(), self.is_playing()\nif sim_is_stopped or sim_is_playing:\nself.pause()\nyield\nif sim_is_stopped: self.stop()\nelif sim_is_playing: self.play()\n@contextlib.contextmanager\ndef slowed(self, dt):\n\"\"\"\n        A context scope for making the simulator simulation dt slowed, e.g.: for taking micro-steps for propagating\n        instantaneous kinematics with minimal impact on physics propagation.\n        NOTE: This will set both the physics dt and rendering dt to the same value during this scope.\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n# Set dt, yield, then restore the original dt\nphysics_dt, rendering_dt = self.get_physics_dt(), self.get_rendering_dt()\nself.set_simulation_dt(physics_dt=dt, rendering_dt=dt)\nyield\nself.set_simulation_dt(physics_dt=physics_dt, rendering_dt=rendering_dt)\n@classmethod\ndef clear_instance(cls):\nSimulationContext.clear_instance()\nSimulator._world_initialized = None\nreturn\ndef __del__(self):\nSimulationContext.__del__(self)\nSimulator._world_initialized = None\nreturn\n@property\ndef dc(self):\n\"\"\"\n        Returns:\n            _dynamic_control.DynamicControl: Dynamic control (dc) interface\n        \"\"\"\nreturn self._dynamic_control\n@property\ndef pi(self):\n\"\"\"\n        Returns:\n            PhysX: Physx Interface (pi) for controlling low-level physx engine\n        \"\"\"\nreturn self._physx_interface\n@property\ndef psi(self):\n\"\"\"\n        Returns:\n            IPhysxSimulation: Physx Simulation Interface (psi) for controlling low-level physx simulation\n        \"\"\"\nreturn self._physx_simulation_interface\n@property\ndef psqi(self):\n\"\"\"\n        Returns:\n            PhysXSceneQuery: Physx Scene Query Interface (psqi) for running low-level scene queries\n        \"\"\"\nreturn self._physx_scene_query_interface\n@property\ndef scene(self):\n\"\"\"\n        Returns:\n            None or Scene: Scene currently loaded in this simulator. If no scene is loaded, returns None\n        \"\"\"\nreturn self._scene\n@property\ndef viewer_camera(self):\n\"\"\"\n        Returns:\n            VisionSensor: Active camera sensor corresponding to the active viewport window instance shown in the omni UI\n        \"\"\"\nreturn self._viewer_camera\n@property\ndef camera_mover(self):\n\"\"\"\n        Returns:\n            None or CameraMover: If enabled, the teleoperation interface for controlling the active viewer camera\n        \"\"\"\nreturn self._camera_mover\n@property\ndef world_prim(self):\n\"\"\"\n        Returns:\n            Usd.Prim: Prim at /World\n        \"\"\"\nreturn get_prim_at_path(prim_path=\"/World\")\ndef clear(self) -&gt; None:\n\"\"\"\n        Clears the stage leaving the PhysicsScene only if under /World.\n        \"\"\"\n# Stop the physics\nself.stop()\n# Clear any pre-existing scene if it exists\nif self._scene is not None:\nself.scene.clear()\nself._scene = None\n# Clear all vision sensors and remove viewer camera reference and camera mover reference\nVisionSensor.clear()\nself._viewer_camera = None\nself._camera_mover = None\n# Clear uniquely named items and other internal states\nclear_pu()\nclear_uu()\nself._objects_to_initialize = []\nself._objects_require_contact_callback = False\nself._objects_require_joint_break_callback = False\nself._link_id_to_objects = dict()\n# Load dummy stage, but don't clear sim to prevent circular loops\nself._load_stage(usd_path=f\"{gm.ASSET_PATH}/models/misc/clear_stage.usd\")\ndef restore(self, json_path):\n\"\"\"\n        Restore a simulation environment from @json_path.\n        Args:\n            json_path (str): Full path of JSON file to load, which contains information\n                to recreate a scene.\n        \"\"\"\nif not json_path.endswith(\".json\"):\nlog.error(f\"You have to define the full json_path to load from. Got: {json_path}\")\nreturn\n# Load the info from the json\nwith open(json_path, \"r\") as f:\nscene_info = json.load(f)\ninit_info = scene_info[\"init_info\"]\nstate = scene_info[\"state\"]\n# Override the init info with our json path\ninit_info[\"args\"][\"scene_file\"] = json_path\n# Also make sure we have any additional modifications necessary from the specific scene\nog.REGISTERED_SCENES[init_info[\"class_name\"]].modify_init_info_for_restoring(init_info=init_info)\n# Recreate and import the saved scene\nog.sim.stop()\nrecreated_scene = create_object_from_init_info(init_info)\nself.import_scene(scene=recreated_scene)\n# Start the simulation and restore the dynamic state of the scene and then pause again\nself.play()\nself.load_state(state, serialized=False)\nlog.info(\"The saved simulation environment loaded.\")\nreturn\ndef save(self, json_path):\n\"\"\"\n        Saves the current simulation environment to @json_path.\n        Args:\n            json_path (str): Full path of JSON file to save (should end with .json), which contains information\n                to recreate the current scene.\n        \"\"\"\n# Make sure the sim is not stopped, since we need to grab joint states\nassert not self.is_stopped(), \"Simulator cannot be stopped when saving to USD!\"\n# Make sure there are no objects in the initialization queue, if not, terminate early and notify user\n# Also run other sanity checks before saving\nif len(self._objects_to_initialize) &gt; 0:\nlog.error(\"There are still objects to initialize! Please take one additional sim step and then save.\")\nreturn\nif not self.scene:\nlog.warning(\"Scene has not been loaded. Nothing to save.\")\nreturn\nif not json_path.endswith(\".json\"):\nlog.error(f\"You have to define the full json_path to save the scene to. Got: {json_path}\")\nreturn\n# Update scene info\nself.scene.update_objects_info()\n# Dump saved current state and also scene init info\nscene_info = {\n\"state\": self.scene.dump_state(serialized=False),\n\"init_info\": self.scene.get_init_info(),\n\"objects_info\": self.scene.get_objects_info(),\n}\n# Write this to the json file\nPath(os.path.dirname(json_path)).mkdir(parents=True, exist_ok=True)\nwith open(json_path, \"w+\") as f:\njson.dump(scene_info, f, cls=NumpyEncoder, indent=4)\nlog.info(\"The current simulation environment saved.\")\ndef _load_stage(self, usd_path):\n\"\"\"\n        Open the stage specified by USD file at @usd_path\n        Args:\n            usd_path (str): Absolute filepath to USD stage that should be loaded\n        \"\"\"\n# Stop the physics if we're playing\nif not self.is_stopped():\nlog.warning(\"Stopping simulation in order to load stage.\")\nself.stop()\n# Store physics dt and rendering dt to reuse later\n# Note that the stage may have been deleted previously; if so, we use the default values\n# of 1/60, 1/60\ntry:\nphysics_dt = self.get_physics_dt()\nexcept:\nprint(\"WARNING: Invalid or non-existent physics scene found. Setting physics dt to 1/60.\")\nphysics_dt = 1/60.\nrendering_dt = self.get_rendering_dt()\n# Open new stage -- suppressing warning that we're opening a new stage\nwith suppress_omni_log(None):\nopen_stage(usd_path=usd_path)\n# Re-initialize necessary internal vars\nself._app = omni.kit.app.get_app_interface()\nself._framework = carb.get_framework()\nself._timeline = omni.timeline.get_timeline_interface()\nself._timeline.set_auto_update(True)\nself._cached_rate_limit_enabled = self._settings.get_as_bool(\"/app/runLoops/main/rateLimitEnabled\")\nself._cached_rate_limit_frequency = self._settings.get_as_int(\"/app/runLoops/main/rateLimitFrequency\")\nself._cached_min_frame_rate = self._settings.get_as_int(\"persistent/simulation/minFrameRate\")\nself._loop_runner = omni_loop.acquire_loop_interface()\n# Initialize stage\nself._init_stage(\nphysics_dt=physics_dt,\nrendering_dt=rendering_dt,\nstage_units_in_meters=self._initial_stage_units_in_meters,\n)\n# Update internal references\nself._dynamic_control = _dynamic_control.acquire_dynamic_control_interface()\nself._physx_interface = get_physx_interface()\nself._physx_simulation_interface = get_physx_simulation_interface()\nself._physx_scene_query_interface = get_physx_scene_query_interface()\n# Update internal settings\nself._set_physics_engine_settings()\nself._set_renderer_settings()\n# Update internal callbacks\nself._setup_default_callback_fns()\nself._stage_open_callback = (\nomni.usd.get_context().get_stage_event_stream().create_subscription_to_pop(self._stage_open_callback_fn)\n)\nself._contact_callback = self._physics_context._physx_sim_interface.subscribe_contact_report_events(self._on_contact)\nself._simulation_event_callback = self._physx_interface.get_simulation_event_stream_v2().create_subscription_to_pop(self._on_simulation_event)\n# Set the lighting mode to be stage by default\nself.set_lighting_mode(mode=LightingMode.STAGE)\n# Set the viewer camera, and then set its default pose\nself._set_viewer_camera()\nself.viewer_camera.set_position_orientation(\nposition=np.array(m.DEFAULT_VIEWER_CAMERA_POS),\norientation=np.array(m.DEFAULT_VIEWER_CAMERA_QUAT),\n)\ndef close(self):\n\"\"\"\n        Shuts down the OmniGibson application\n        \"\"\"\nself._app.shutdown()\n@property\ndef stage_id(self):\n\"\"\"\n        Returns:\n            int: ID of the current active stage\n        \"\"\"\nreturn UsdUtils.StageCache.Get().GetId(self.stage).ToLongInt()\n@property\ndef device(self):\n\"\"\"\n        Returns:\n            device (None or str): Device used in simulation backend\n        \"\"\"\nreturn self._device\n@device.setter\ndef device(self, device):\n\"\"\"\n        Sets the device used for sim backend\n        Args:\n            device (None or str): Device to set for the simulation backend\n        \"\"\"\nself._device = device\nif self._device is not None and \"cuda\" in self._device:\ndevice_id = self._settings.get_as_int(\"/physics/cudaDevice\")\nself._device = f\"cuda:{device_id}\"\n@property\ndef state_size(self):\n# Total state size is the state size of our scene\nreturn self._scene.state_size\ndef _dump_state(self):\n# Default state is from the scene\nreturn self._scene.dump_state(serialized=False)\ndef _load_state(self, state):\n# Default state is from the scene\nself._scene.load_state(state=state, serialized=False)\ndef load_state(self, state, serialized=False):\n# We need to make sure the simulator is playing since joint states only get updated when playing\nassert self.is_playing()\n# Run super\nsuper().load_state(state=state, serialized=serialized)\n# Highlight that at the current step, the non-kinematic states are potentially inaccurate because a sim\n# step is needed to propagate specific states in physics backend\n# TODO: This should be resolved in a future omniverse release!\ndisclaimer(\"Attempting to load simulator state.\\n\"\n\"Currently, omniverse does not support exclusively stepping kinematics, so we cannot update some \"\n\"of our object states relying on updated kinematics until a simulator step is taken!\\n\"\n\"Object states such as OnTop, Inside, etc. relying on relative spatial information will inaccurate\"\n\"until a single sim step is taken.\\n\"\n\"This should be resolved by the next NVIDIA Isaac Sim release.\")\ndef _serialize(self, state):\n# Default state is from the scene\nreturn self._scene.serialize(state=state)\ndef _deserialize(self, state):\n# Default state is from the scene\nreturn self._scene.deserialize(state=state), self._scene.state_size\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.camera_mover","title":"<code>camera_mover</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or CameraMover: If enabled, the teleoperation interface for controlling the active viewer camera</p>"},{"location":"reference/simulator.html#simulator.Simulator.dc","title":"<code>dc</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>_dynamic_control.DynamicControl: Dynamic control (dc) interface</p>"},{"location":"reference/simulator.html#simulator.Simulator.device","title":"<code>device</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>device</code> <code>None or str</code> <p>Device used in simulation backend</p>"},{"location":"reference/simulator.html#simulator.Simulator.n_physics_timesteps_per_render","title":"<code>n_physics_timesteps_per_render</code>  <code>property</code>","text":"<p>Number of physics timesteps per rendering timestep. rendering_dt has to be a multiple of physics_dt.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>Discrete number of physics timesteps to take per step</p>"},{"location":"reference/simulator.html#simulator.Simulator.pi","title":"<code>pi</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>PhysX</code> <p>Physx Interface (pi) for controlling low-level physx engine</p>"},{"location":"reference/simulator.html#simulator.Simulator.psi","title":"<code>psi</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>IPhysxSimulation</code> <p>Physx Simulation Interface (psi) for controlling low-level physx simulation</p>"},{"location":"reference/simulator.html#simulator.Simulator.psqi","title":"<code>psqi</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>PhysXSceneQuery</code> <p>Physx Scene Query Interface (psqi) for running low-level scene queries</p>"},{"location":"reference/simulator.html#simulator.Simulator.scene","title":"<code>scene</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or Scene: Scene currently loaded in this simulator. If no scene is loaded, returns None</p>"},{"location":"reference/simulator.html#simulator.Simulator.stage_id","title":"<code>stage_id</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>ID of the current active stage</p>"},{"location":"reference/simulator.html#simulator.Simulator.viewer_camera","title":"<code>viewer_camera</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>VisionSensor</code> <p>Active camera sensor corresponding to the active viewport window instance shown in the omni UI</p>"},{"location":"reference/simulator.html#simulator.Simulator.viewer_height","title":"<code>viewer_height</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>viewer height of this sensor, in pixels</p>"},{"location":"reference/simulator.html#simulator.Simulator.viewer_visibility","title":"<code>viewer_visibility</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the viewer is visible or not</p>"},{"location":"reference/simulator.html#simulator.Simulator.viewer_width","title":"<code>viewer_width</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>viewer width of this sensor, in pixels</p>"},{"location":"reference/simulator.html#simulator.Simulator.world_prim","title":"<code>world_prim</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>Usd.Prim: Prim at /World</p>"},{"location":"reference/simulator.html#simulator.Simulator.clear","title":"<code>clear()</code>","text":"<p>Clears the stage leaving the PhysicsScene only if under /World.</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>def clear(self) -&gt; None:\n\"\"\"\n    Clears the stage leaving the PhysicsScene only if under /World.\n    \"\"\"\n# Stop the physics\nself.stop()\n# Clear any pre-existing scene if it exists\nif self._scene is not None:\nself.scene.clear()\nself._scene = None\n# Clear all vision sensors and remove viewer camera reference and camera mover reference\nVisionSensor.clear()\nself._viewer_camera = None\nself._camera_mover = None\n# Clear uniquely named items and other internal states\nclear_pu()\nclear_uu()\nself._objects_to_initialize = []\nself._objects_require_contact_callback = False\nself._objects_require_joint_break_callback = False\nself._link_id_to_objects = dict()\n# Load dummy stage, but don't clear sim to prevent circular loops\nself._load_stage(usd_path=f\"{gm.ASSET_PATH}/models/misc/clear_stage.usd\")\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.close","title":"<code>close()</code>","text":"<p>Shuts down the OmniGibson application</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>def close(self):\n\"\"\"\n    Shuts down the OmniGibson application\n    \"\"\"\nself._app.shutdown()\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.enable_viewer_camera_teleoperation","title":"<code>enable_viewer_camera_teleoperation()</code>","text":"<p>Enables keyboard control of the active viewer camera for this simulation</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>def enable_viewer_camera_teleoperation(self):\n\"\"\"\n    Enables keyboard control of the active viewer camera for this simulation\n    \"\"\"\nself._camera_mover = CameraMover(cam=self._viewer_camera)\nself._camera_mover.print_info()\nreturn self._camera_mover\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.import_object","title":"<code>import_object(obj, register=True, auto_initialize=True)</code>","text":"<p>Import an object into the simulator.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>an object to load</p> required <code>register</code> <code>bool</code> <p>whether to register this object internally in the scene registry</p> <code>True</code> <code>auto_initialize</code> <code>bool</code> <p>If True, will auto-initialize the requested object on the next simulation step. Otherwise, we assume that the object will call initialize() on its own!</p> <code>True</code> Source code in <code>omnigibson/simulator.py</code> <pre><code>def import_object(self, obj, register=True, auto_initialize=True):\n\"\"\"\n    Import an object into the simulator.\n    Args:\n        obj (BaseObject): an object to load\n        register (bool): whether to register this object internally in the scene registry\n        auto_initialize (bool): If True, will auto-initialize the requested object on the next simulation step.\n            Otherwise, we assume that the object will call initialize() on its own!\n    \"\"\"\nassert isinstance(obj, BaseObject), \"import_object can only be called with BaseObject\"\n# Make sure scene is loaded -- objects should not be loaded unless we have a reference to a scene\nassert self.scene is not None, \"import_object needs to be called after import_scene\"\n# Load the object in omniverse by adding it to the scene\nself.scene.add_object(obj, register=register, _is_call_from_simulator=True)\n# Cache the mapping from link IDs to object\nfor link in obj.links.values():\nself._link_id_to_objects[PhysicsSchemaTools.sdfPathToInt(link.prim_path)] = obj\n# Lastly, additionally add this object automatically to be initialized as soon as another simulator step occurs\n# if requested\nif auto_initialize:\nself.initialize_object_on_next_sim_step(obj=obj)\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.import_scene","title":"<code>import_scene(scene)</code>","text":"<p>Import a scene into the simulator. A scene could be a synthetic one or a realistic Gibson Environment.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>Scene</code> <p>a scene object to load</p> required Source code in <code>omnigibson/simulator.py</code> <pre><code>def import_scene(self, scene):\n\"\"\"\n    Import a scene into the simulator. A scene could be a synthetic one or a realistic Gibson Environment.\n    Args:\n        scene (Scene): a scene object to load\n    \"\"\"\nassert self.is_stopped(), \"Simulator must be stopped while importing a scene!\"\nassert isinstance(scene, Scene), \"import_scene can only be called with Scene\"\n# Clear the existing scene if any\nself.clear()\nself._scene = scene\nself._scene.load()\n# Make sure simulator is not running, then start it so that we can initialize the scene\nassert self.is_stopped(), \"Simulator must be stopped after importing a scene!\"\nself.play()\n# Initialize the scene\nself._scene.initialize()\n# Need to one more step for particle systems to work\nself.step()\nself.stop()\nlog.info(\"Imported scene.\")\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.initialize_object_on_next_sim_step","title":"<code>initialize_object_on_next_sim_step(obj)</code>","text":"<p>Initializes the object upon the next simulation step</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BasePrim</code> <p>Object to initialize as soon as a new sim step is called</p> required Source code in <code>omnigibson/simulator.py</code> <pre><code>def initialize_object_on_next_sim_step(self, obj):\n\"\"\"\n    Initializes the object upon the next simulation step\n    Args:\n        obj (BasePrim): Object to initialize as soon as a new sim step is called\n    \"\"\"\nself._objects_to_initialize.append(obj)\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.is_paused","title":"<code>is_paused()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>True if the simulator is paused, otherwise False</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>def is_paused(self):\n\"\"\"\n    Returns:\n        bool: True if the simulator is paused, otherwise False\n    \"\"\"\nreturn not (self.is_stopped() or self.is_playing())\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.paused","title":"<code>paused()</code>","text":"<p>A context scope for making sure the simulator is paused during execution within this scope. Upon leaving the scope, the prior simulator state is restored.</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef paused(self):\n\"\"\"\n    A context scope for making sure the simulator is paused during execution within this scope.\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n# Infer what state we're currently in, then stop, yield, and then restore the original state\nsim_is_stopped, sim_is_playing = self.is_stopped(), self.is_playing()\nif sim_is_stopped or sim_is_playing:\nself.pause()\nyield\nif sim_is_stopped: self.stop()\nelif sim_is_playing: self.play()\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.playing","title":"<code>playing()</code>","text":"<p>A context scope for making sure the simulator is playing during execution within this scope. Upon leaving the scope, the prior simulator state is restored.</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef playing(self):\n\"\"\"\n    A context scope for making sure the simulator is playing during execution within this scope.\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n# Infer what state we're currently in, then stop, yield, and then restore the original state\nsim_is_stopped, sim_is_paused = self.is_stopped(), self.is_paused()\nif sim_is_stopped or sim_is_paused:\nself.play()\nyield\nif sim_is_stopped: self.stop()\nelif sim_is_paused: self.pause()\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.remove_object","title":"<code>remove_object(obj)</code>","text":"<p>Remove a non-robot object from the simulator.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>a non-robot object to load</p> required Source code in <code>omnigibson/simulator.py</code> <pre><code>def remove_object(self, obj):\n\"\"\"\n    Remove a non-robot object from the simulator.\n    Args:\n        obj (BaseObject): a non-robot object to load\n    \"\"\"\n# pop all link ids\nfor link in obj.links.values():\nself._link_id_to_objects.pop(PhysicsSchemaTools.sdfPathToInt(link.prim_path))\nself._scene.remove_object(obj)\nself.app.update()\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.restore","title":"<code>restore(json_path)</code>","text":"<p>Restore a simulation environment from @json_path.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str</code> <p>Full path of JSON file to load, which contains information to recreate a scene.</p> required Source code in <code>omnigibson/simulator.py</code> <pre><code>def restore(self, json_path):\n\"\"\"\n    Restore a simulation environment from @json_path.\n    Args:\n        json_path (str): Full path of JSON file to load, which contains information\n            to recreate a scene.\n    \"\"\"\nif not json_path.endswith(\".json\"):\nlog.error(f\"You have to define the full json_path to load from. Got: {json_path}\")\nreturn\n# Load the info from the json\nwith open(json_path, \"r\") as f:\nscene_info = json.load(f)\ninit_info = scene_info[\"init_info\"]\nstate = scene_info[\"state\"]\n# Override the init info with our json path\ninit_info[\"args\"][\"scene_file\"] = json_path\n# Also make sure we have any additional modifications necessary from the specific scene\nog.REGISTERED_SCENES[init_info[\"class_name\"]].modify_init_info_for_restoring(init_info=init_info)\n# Recreate and import the saved scene\nog.sim.stop()\nrecreated_scene = create_object_from_init_info(init_info)\nself.import_scene(scene=recreated_scene)\n# Start the simulation and restore the dynamic state of the scene and then pause again\nself.play()\nself.load_state(state, serialized=False)\nlog.info(\"The saved simulation environment loaded.\")\nreturn\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.save","title":"<code>save(json_path)</code>","text":"<p>Saves the current simulation environment to @json_path.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str</code> <p>Full path of JSON file to save (should end with .json), which contains information to recreate the current scene.</p> required Source code in <code>omnigibson/simulator.py</code> <pre><code>def save(self, json_path):\n\"\"\"\n    Saves the current simulation environment to @json_path.\n    Args:\n        json_path (str): Full path of JSON file to save (should end with .json), which contains information\n            to recreate the current scene.\n    \"\"\"\n# Make sure the sim is not stopped, since we need to grab joint states\nassert not self.is_stopped(), \"Simulator cannot be stopped when saving to USD!\"\n# Make sure there are no objects in the initialization queue, if not, terminate early and notify user\n# Also run other sanity checks before saving\nif len(self._objects_to_initialize) &gt; 0:\nlog.error(\"There are still objects to initialize! Please take one additional sim step and then save.\")\nreturn\nif not self.scene:\nlog.warning(\"Scene has not been loaded. Nothing to save.\")\nreturn\nif not json_path.endswith(\".json\"):\nlog.error(f\"You have to define the full json_path to save the scene to. Got: {json_path}\")\nreturn\n# Update scene info\nself.scene.update_objects_info()\n# Dump saved current state and also scene init info\nscene_info = {\n\"state\": self.scene.dump_state(serialized=False),\n\"init_info\": self.scene.get_init_info(),\n\"objects_info\": self.scene.get_objects_info(),\n}\n# Write this to the json file\nPath(os.path.dirname(json_path)).mkdir(parents=True, exist_ok=True)\nwith open(json_path, \"w+\") as f:\njson.dump(scene_info, f, cls=NumpyEncoder, indent=4)\nlog.info(\"The current simulation environment saved.\")\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.set_lighting_mode","title":"<code>set_lighting_mode(mode)</code>","text":"<p>Sets the active lighting mode in the current simulator. Valid options are one of LightingMode</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>LightingMode</code> <p>Lighting mode to set</p> required Source code in <code>omnigibson/simulator.py</code> <pre><code>def set_lighting_mode(self, mode):\n\"\"\"\n    Sets the active lighting mode in the current simulator. Valid options are one of LightingMode\n    Args:\n        mode (LightingMode): Lighting mode to set\n    \"\"\"\nomni.kit.commands.execute(\"SetLightingMenuModeCommand\", lighting_mode=mode)\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.slowed","title":"<code>slowed(dt)</code>","text":"<p>A context scope for making the simulator simulation dt slowed, e.g.: for taking micro-steps for propagating instantaneous kinematics with minimal impact on physics propagation.</p> <p>NOTE: This will set both the physics dt and rendering dt to the same value during this scope.</p> <p>Upon leaving the scope, the prior simulator state is restored.</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef slowed(self, dt):\n\"\"\"\n    A context scope for making the simulator simulation dt slowed, e.g.: for taking micro-steps for propagating\n    instantaneous kinematics with minimal impact on physics propagation.\n    NOTE: This will set both the physics dt and rendering dt to the same value during this scope.\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n# Set dt, yield, then restore the original dt\nphysics_dt, rendering_dt = self.get_physics_dt(), self.get_rendering_dt()\nself.set_simulation_dt(physics_dt=dt, rendering_dt=dt)\nyield\nself.set_simulation_dt(physics_dt=physics_dt, rendering_dt=rendering_dt)\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.step","title":"<code>step(render=True, force_playing=False)</code>","text":"<p>Step the simulation at self.render_timestep</p> <p>Parameters:</p> Name Type Description Default <code>render</code> <code>bool</code> <p>Whether rendering should occur or not</p> <code>True</code> <code>force_playing</code> <code>bool</code> <p>If True, will force physics to propagate (i.e.: set simulation, if paused / stopped, to \"play\" mode)</p> <code>False</code> Source code in <code>omnigibson/simulator.py</code> <pre><code>def step(self, render=True, force_playing=False):\n\"\"\"\n    Step the simulation at self.render_timestep\n    Args:\n        render (bool): Whether rendering should occur or not\n        force_playing (bool): If True, will force physics to propagate (i.e.: set simulation, if paused / stopped,\n            to \"play\" mode)\n    \"\"\"\n# Possibly force playing\nif force_playing and not self.is_playing():\nself.play()\nif render:\nsuper().step(render=True)\nelse:\nfor i in range(self.n_physics_timesteps_per_render):\nsuper().step(render=False)\n# Additionally run non physics things if we have a valid scene\nif self._scene is not None:\nself._omni_update_step()\nif self.is_playing():\nself._non_physics_step()\nif gm.ENABLE_TRANSITION_RULES:\nself._transition_rule_step()\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.step_physics","title":"<code>step_physics()</code>","text":"<p>Step the physics a single step.</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>def step_physics(self):\n\"\"\"\n    Step the physics a single step.\n    \"\"\"\nself._physics_context._step(current_time=self.current_time)\n</code></pre>"},{"location":"reference/simulator.html#simulator.Simulator.stopped","title":"<code>stopped()</code>","text":"<p>A context scope for making sure the simulator is stopped during execution within this scope. Upon leaving the scope, the prior simulator state is restored.</p> Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef stopped(self):\n\"\"\"\n    A context scope for making sure the simulator is stopped during execution within this scope.\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n# Infer what state we're currently in, then stop, yield, and then restore the original state\nsim_is_playing, sim_is_paused = self.is_playing(), self.is_paused()\nif sim_is_playing or sim_is_paused:\nself.stop()\nyield\nif sim_is_playing: self.play()\nelif sim_is_paused: self.pause()\n</code></pre>"},{"location":"reference/transition_rules.html","title":"transition_rules","text":""},{"location":"reference/transition_rules.html#transition_rules.AbilityFilter","title":"<code>AbilityFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Filter for object abilities.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class AbilityFilter(BaseFilter):\n\"\"\"Filter for object abilities.\"\"\"\ndef __init__(self, ability):\nself.ability = ability\ndef __call__(self, obj):\nreturn self.ability in obj._abilities\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.AndFilter","title":"<code>AndFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Logical-and of a set of filters.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class AndFilter(BaseFilter):\n\"\"\"Logical-and of a set of filters.\"\"\"\ndef __init__(self, filters):\nself.filters = filters\ndef __call__(self, obj):\nreturn all(f(obj) for f in self.filters)\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseFilter","title":"<code>BaseFilter</code>","text":"<p>Defines a filter to apply to objects.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class BaseFilter(metaclass=ABCMeta):\n\"\"\"Defines a filter to apply to objects.\"\"\"\n# Class global variable for maintaining cached state\n# Maps tuple of unique filter inputs to cached output value (T / F)\nstate = None\n@classmethod\ndef __new__(cls, *args, **kwargs):\n\"\"\"\n        Initializes the cached state for this filter if it doesn't already exist\n        \"\"\"\nif cls.state is None:\ncls.state = dict()\nreturn super(BaseFilter, cls).__new__(cls)\n@classmethod\ndef update(cls):\n\"\"\"\n        Updates the internal state by checking the filter status on all filter inputs\n        \"\"\"\nraise NotImplementedError()\n@abstractmethod\ndef __call__(self, obj):\n\"\"\"Returns true if the given object passes the filter.\"\"\"\nreturn False\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseFilter.__call__","title":"<code>__call__(obj)</code>  <code>abstractmethod</code>","text":"<p>Returns true if the given object passes the filter.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef __call__(self, obj):\n\"\"\"Returns true if the given object passes the filter.\"\"\"\nreturn False\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseFilter.__new__","title":"<code>__new__(*args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Initializes the cached state for this filter if it doesn't already exist</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@classmethod\ndef __new__(cls, *args, **kwargs):\n\"\"\"\n    Initializes the cached state for this filter if it doesn't already exist\n    \"\"\"\nif cls.state is None:\ncls.state = dict()\nreturn super(BaseFilter, cls).__new__(cls)\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseFilter.update","title":"<code>update()</code>  <code>classmethod</code>","text":"<p>Updates the internal state by checking the filter status on all filter inputs</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@classmethod\ndef update(cls):\n\"\"\"\n    Updates the internal state by checking the filter status on all filter inputs\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseTransitionRule","title":"<code>BaseTransitionRule</code>","text":"<p>Defines a set of categories of objects and how to transition their states.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class BaseTransitionRule(metaclass=ABCMeta):\n\"\"\"\n    Defines a set of categories of objects and how to transition their states.\n    \"\"\"\n@abstractmethod\ndef __init__(self, individual_filters=None, group_filters=None):\n\"\"\"\n        TransitionRule ctor.\n        Args:\n            individual_filters (None or dict): Individual object filters that this filter cares about.\n                For each name, filter key-value pair, the global transition rule step will produce tuples of valid\n                filtered objects such that the cross product over all individual filter outputs occur.\n                For example, if the individual filters are:\n                    {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n                the transition rule step will produce all 2-tuples of valid (apple, knife) combinations:\n                    {\"apple\": apple_i, \"knife\": knife_j}\n                based on the current instances of each object type in the scene and pass them to @self.condition as the\n                @individual_objects entry.\n                If None is specified, then no filter will be applied\n            group_filters (None or dict): Group object filters that this filter cares about. For each name, filter\n                key-value pair, the global transition rule step will produce a single dictionary of valid filtered\n                objects.\n                For example, if the group filters are:\n                    {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n                the transition rule step will produce the following dictionary:\n                    {\"apple\": [apple0, apple1, ...], \"knife\": [knife0, knife1, ...]}\n                based on the current instances of each object type in the scene and pass them to @self.condition\n                as the @group_objects entry.\n                If None is specified, then no filter will be applied\n        \"\"\"\n# Make sure at least one set of filters is specified -- in general, there should never be a rule\n# where no filter is specified\nassert not (individual_filters is None and group_filters is None),\\\n            \"At least one of individual_filters or group_filters must be specified!\"\n# Store the filters\nself.individual_filters = dict() if individual_filters is None else individual_filters\nself.group_filters = dict() if group_filters is None else group_filters\ndef process(self, individual_objects, group_objects):\n\"\"\"\n        Processes this transition rule at the current simulator step. If @condition evaluates to True, then\n        @transition will be executed.\n        Args:\n            individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n                object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n            group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n                object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n        Returns:\n            2-tuple:\n                - bool: Whether @self.condition is met\n                - None or TransitionResults: Output from @self.transition (None if it was never executed)\n        \"\"\"\nshould_transition = self.condition(individual_objects=individual_objects, group_objects=group_objects)\nreturn should_transition, \\\n            self.transition(individual_objects=individual_objects, group_objects=group_objects) \\\n            if should_transition else None\n@property\ndef requires_individual_filters(self):\n\"\"\"\n        Returns:\n            bool: Whether this transition rule requires any specific filters\n        \"\"\"\nreturn len(self.individual_filters) &gt; 0\n@property\ndef requires_group_filters(self):\n\"\"\"\n        Returns:\n            bool: Whether this transition rule requires any group filters\n        \"\"\"\nreturn len(self.group_filters) &gt; 0\n@abstractmethod\ndef condition(self, individual_objects, group_objects):\n\"\"\"\n        Returns True if the rule applies to the object tuple.\n        Args:\n            individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n                object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n            group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n                object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n        Returns:\n            bool: Whether the condition is met or not\n        \"\"\"\npass\n@abstractmethod\ndef transition(self, individual_objects, group_objects):\n\"\"\"\n        Rule to apply for each set of objects satisfying the condition.\n        Args:\n            individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n                object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n            group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n                object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n        Returns:\n            TransitionResults: results from the executed transition\n        \"\"\"\npass\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.requires_group_filters","title":"<code>requires_group_filters</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this transition rule requires any group filters</p>"},{"location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.requires_individual_filters","title":"<code>requires_individual_filters</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this transition rule requires any specific filters</p>"},{"location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.__init__","title":"<code>__init__(individual_filters=None, group_filters=None)</code>  <code>abstractmethod</code>","text":"<p>TransitionRule ctor.</p> <p>Parameters:</p> Name Type Description Default <code>individual_filters</code> <code>None or dict</code> <p>Individual object filters that this filter cares about. For each name, filter key-value pair, the global transition rule step will produce tuples of valid filtered objects such that the cross product over all individual filter outputs occur. For example, if the individual filters are:</p> <pre><code>{\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n</code></pre> <p>the transition rule step will produce all 2-tuples of valid (apple, knife) combinations:</p> <pre><code>{\"apple\": apple_i, \"knife\": knife_j}\n</code></pre> <p>based on the current instances of each object type in the scene and pass them to @self.condition as the @individual_objects entry. If None is specified, then no filter will be applied</p> <code>None</code> <code>group_filters</code> <code>None or dict</code> <p>Group object filters that this filter cares about. For each name, filter key-value pair, the global transition rule step will produce a single dictionary of valid filtered objects. For example, if the group filters are:</p> <pre><code>{\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n</code></pre> <p>the transition rule step will produce the following dictionary:</p> <pre><code>{\"apple\": [apple0, apple1, ...], \"knife\": [knife0, knife1, ...]}\n</code></pre> <p>based on the current instances of each object type in the scene and pass them to @self.condition as the @group_objects entry. If None is specified, then no filter will be applied</p> <code>None</code> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef __init__(self, individual_filters=None, group_filters=None):\n\"\"\"\n    TransitionRule ctor.\n    Args:\n        individual_filters (None or dict): Individual object filters that this filter cares about.\n            For each name, filter key-value pair, the global transition rule step will produce tuples of valid\n            filtered objects such that the cross product over all individual filter outputs occur.\n            For example, if the individual filters are:\n                {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n            the transition rule step will produce all 2-tuples of valid (apple, knife) combinations:\n                {\"apple\": apple_i, \"knife\": knife_j}\n            based on the current instances of each object type in the scene and pass them to @self.condition as the\n            @individual_objects entry.\n            If None is specified, then no filter will be applied\n        group_filters (None or dict): Group object filters that this filter cares about. For each name, filter\n            key-value pair, the global transition rule step will produce a single dictionary of valid filtered\n            objects.\n            For example, if the group filters are:\n                {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n            the transition rule step will produce the following dictionary:\n                {\"apple\": [apple0, apple1, ...], \"knife\": [knife0, knife1, ...]}\n            based on the current instances of each object type in the scene and pass them to @self.condition\n            as the @group_objects entry.\n            If None is specified, then no filter will be applied\n    \"\"\"\n# Make sure at least one set of filters is specified -- in general, there should never be a rule\n# where no filter is specified\nassert not (individual_filters is None and group_filters is None),\\\n        \"At least one of individual_filters or group_filters must be specified!\"\n# Store the filters\nself.individual_filters = dict() if individual_filters is None else individual_filters\nself.group_filters = dict() if group_filters is None else group_filters\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.condition","title":"<code>condition(individual_objects, group_objects)</code>  <code>abstractmethod</code>","text":"<p>Returns True if the rule applies to the object tuple.</p> <p>Parameters:</p> Name Type Description Default <code>individual_objects</code> <code>dict</code> <p>Dictionary mapping corresponding keys from @individual_filters to individual object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values satisfy the filter, then this will be an empty dictionary</p> required <code>group_objects</code> <code>dict</code> <p>Dictionary mapping corresponding keys from @group_filters to a list of individual object instances where the filter is satisfied. Note: if @self.group_filters is None or no values satisfy the filter, then this will be an empty dictionary</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the condition is met or not</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef condition(self, individual_objects, group_objects):\n\"\"\"\n    Returns True if the rule applies to the object tuple.\n    Args:\n        individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n            object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n        group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n            object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n    Returns:\n        bool: Whether the condition is met or not\n    \"\"\"\npass\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.process","title":"<code>process(individual_objects, group_objects)</code>","text":"<p>Processes this transition rule at the current simulator step. If @condition evaluates to True, then @transition will be executed.</p> <p>Parameters:</p> Name Type Description Default <code>individual_objects</code> <code>dict</code> <p>Dictionary mapping corresponding keys from @individual_filters to individual object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values satisfy the filter, then this will be an empty dictionary</p> required <code>group_objects</code> <code>dict</code> <p>Dictionary mapping corresponding keys from @group_filters to a list of individual object instances where the filter is satisfied. Note: if @self.group_filters is None or no values satisfy the filter, then this will be an empty dictionary</p> required <p>Returns:</p> Type Description <p>2-tuple: - bool: Whether @self.condition is met - None or TransitionResults: Output from @self.transition (None if it was never executed)</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>def process(self, individual_objects, group_objects):\n\"\"\"\n    Processes this transition rule at the current simulator step. If @condition evaluates to True, then\n    @transition will be executed.\n    Args:\n        individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n            object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n        group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n            object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n    Returns:\n        2-tuple:\n            - bool: Whether @self.condition is met\n            - None or TransitionResults: Output from @self.transition (None if it was never executed)\n    \"\"\"\nshould_transition = self.condition(individual_objects=individual_objects, group_objects=group_objects)\nreturn should_transition, \\\n        self.transition(individual_objects=individual_objects, group_objects=group_objects) \\\n        if should_transition else None\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.transition","title":"<code>transition(individual_objects, group_objects)</code>  <code>abstractmethod</code>","text":"<p>Rule to apply for each set of objects satisfying the condition.</p> <p>Parameters:</p> Name Type Description Default <code>individual_objects</code> <code>dict</code> <p>Dictionary mapping corresponding keys from @individual_filters to individual object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values satisfy the filter, then this will be an empty dictionary</p> required <code>group_objects</code> <code>dict</code> <p>Dictionary mapping corresponding keys from @group_filters to a list of individual object instances where the filter is satisfied. Note: if @self.group_filters is None or no values satisfy the filter, then this will be an empty dictionary</p> required <p>Returns:</p> Name Type Description <code>TransitionResults</code> <p>results from the executed transition</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef transition(self, individual_objects, group_objects):\n\"\"\"\n    Rule to apply for each set of objects satisfying the condition.\n    Args:\n        individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n            object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n        group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n            object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n    Returns:\n        TransitionResults: results from the executed transition\n    \"\"\"\npass\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BlenderRule","title":"<code>BlenderRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class BlenderRule(BaseTransitionRule):\ndef __init__(self, output_system, particle_requirements=None, obj_requirements=None):\n\"\"\"\n        Transition rule to apply when objects are blended together\n        Args:\n            output_system (str): Name of the physical particle to generate once all the input ingredients are blended\n            particle_requirements (None or dict): If specified, should map physical particle system name to the minimum\n                number of physical particles required in order to successfully blend\n            obj_requirements (None or dict): If specified, should map object category names to minimum number of that\n                type of object rqeuired in order to successfully blend\n        \"\"\"\n# We want to filter for any object that is included in @obj_requirements and also separately for blender\nindividual_filters = {\"blender\": CategoryFilter(\"blender\")}\ngroup_filters = {category: CategoryFilter(category) for category in obj_requirements.keys()}\n# Store internal variables\nself.output_system = output_system\nself.particle_requirements = particle_requirements\nself.obj_requirements = obj_requirements\n# Store a cached dictionary to check blender volumes so we don't have to do this later\nself._check_in_volume = dict()\n# Call super method\nsuper().__init__(individual_filters=individual_filters, group_filters=group_filters)\ndef condition(self, individual_objects, group_objects):\n# TODO: Check blender if both toggled on and lid is closed!\nblender = individual_objects[\"blender\"]\n# If this blender doesn't exist in our volume checker, we add it\nif blender.name not in self._check_in_volume:\nself._check_in_volume[blender.name] = lambda pos: blender.states[Filled].check_in_volume(pos.reshape(-1, 3))\n# Check to see which objects are inside the blender container\nfor obj_category, objs in group_objects.items():\ninside_objs = []\nfor obj in objs:\nif obj.states[Inside].get_value(blender):\ninside_objs.append(obj)\n# Make sure the number of objects inside meets the required threshold, else we trigger a failure\nif len(inside_objs) &lt; self.obj_requirements[obj_category]:\nreturn False\n# We mutate the group_objects in place so that we only keep the ones inside the blender\ngroup_objects[obj_category] = inside_objs\n# Check whether we have sufficient physical particles as well\nfor system_name, n_min_particles in self.particle_requirements.items():\nif not is_system_active(system_name):\nreturn False\nsystem = get_system(system_name)\nif system.n_particles == 0:\nreturn False\nparticle_positions = np.concatenate([inst.particle_positions for inst in system.particle_instancers.values()], axis=0)\nn_particles_in_volume = np.sum(self._check_in_volume[blender.name](particle_positions))\nif n_particles_in_volume &lt; n_min_particles:\nreturn False\n# Our condition is whether we have sufficient ingredients or not\nreturn True\ndef transition(self, individual_objects, group_objects):\nt_results = TransitionResults()\nblender = individual_objects[\"blender\"]\n# For every object in group_objects, we remove them from the simulator\nfor i, (obj_category, objs) in enumerate(group_objects.items()):\nfor j, obj in enumerate(objs):\nt_results.remove.append(obj)\n# Remove all physical particles that are inside the blender\nfor system_name in self.particle_requirements.keys():\nsystem = get_system(system_name)\n# No need to check for whether particle instancers exist because they must due to @self.condition passing!\nfor inst in system.particle_instancers.values():\nindices = self._check_in_volume[blender.name](inst.particle_positions).nonzero()[0]\ninst.remove_particles(idxs=indices)\n# Spawn in blended physical particles!\nblender.states[Filled].set_value(get_system(self.output_system), True)\nreturn t_results\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.BlenderRule.__init__","title":"<code>__init__(output_system, particle_requirements=None, obj_requirements=None)</code>","text":"<p>Transition rule to apply when objects are blended together</p> <p>Parameters:</p> Name Type Description Default <code>output_system</code> <code>str</code> <p>Name of the physical particle to generate once all the input ingredients are blended</p> required <code>particle_requirements</code> <code>None or dict</code> <p>If specified, should map physical particle system name to the minimum number of physical particles required in order to successfully blend</p> <code>None</code> <code>obj_requirements</code> <code>None or dict</code> <p>If specified, should map object category names to minimum number of that type of object rqeuired in order to successfully blend</p> <code>None</code> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>def __init__(self, output_system, particle_requirements=None, obj_requirements=None):\n\"\"\"\n    Transition rule to apply when objects are blended together\n    Args:\n        output_system (str): Name of the physical particle to generate once all the input ingredients are blended\n        particle_requirements (None or dict): If specified, should map physical particle system name to the minimum\n            number of physical particles required in order to successfully blend\n        obj_requirements (None or dict): If specified, should map object category names to minimum number of that\n            type of object rqeuired in order to successfully blend\n    \"\"\"\n# We want to filter for any object that is included in @obj_requirements and also separately for blender\nindividual_filters = {\"blender\": CategoryFilter(\"blender\")}\ngroup_filters = {category: CategoryFilter(category) for category in obj_requirements.keys()}\n# Store internal variables\nself.output_system = output_system\nself.particle_requirements = particle_requirements\nself.obj_requirements = obj_requirements\n# Store a cached dictionary to check blender volumes so we don't have to do this later\nself._check_in_volume = dict()\n# Call super method\nsuper().__init__(individual_filters=individual_filters, group_filters=group_filters)\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.CategoryFilter","title":"<code>CategoryFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Filter for object categories.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class CategoryFilter(BaseFilter):\n\"\"\"Filter for object categories.\"\"\"\ndef __init__(self, category):\nself.category = category\ndef __call__(self, obj):\nreturn obj.category == self.category\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.ContainerGarbageRule","title":"<code>ContainerGarbageRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>Rule to apply to a container to turn what remain inside into garbage.</p> <p>This rule is used as a catch-all rule for containers to turn objects inside the container that did not match any other legitimate rules all into a single garbage object.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class ContainerGarbageRule(BaseTransitionRule):\n\"\"\"\n    Rule to apply to a container to turn what remain inside into garbage.\n    This rule is used as a catch-all rule for containers to turn objects inside\n    the container that did not match any other legitimate rules all into a\n    single garbage object.\n    \"\"\"\ndef __init__(self, garbage_obj_attrs, container_filter):\n\"\"\"Ctor for ContainerGarbageRule.\n        Args:\n            garbage_obj_attrs: (ObjectAttrs) a namedtuple containing the\n                attributes of garbage objects to be created.\n            container_filter: (BaseFilter) a filter for the container.\n        \"\"\"\nsuper(ContainerGarbageRule, self).__init__((container_filter,))\nself.obj_attrs = garbage_obj_attrs\nself._cached_contained_objs = None\nself._counter = 0\ndef condition(self, container_obj):\nif (\nToggledOn in container_obj.states and\nnot container_obj.states[ToggledOn].get_value()\n):\nreturn False\nself._cached_contained_objs = _contained_objects(og.sim.scene, container_obj)\n# Skip in case only a garbage object is inside the container.\nif len(self._cached_contained_objs) == 1:\ncontained_obj = self._cached_contained_objs[0]\nif (contained_obj.category == self.obj_attrs.category\nand contained_obj.name.startswith(self.obj_attrs.name)):\nreturn False\nreturn bool(self._cached_contained_objs)\ndef transition(self, container_obj):\nt_results = TransitionResults()\n# Create a single garbage object to be added.\nall_pos, all_orn = [], []\nfor contained_obj in self._cached_contained_objs:\npos, orn = contained_obj.get_position_orientation()\nall_pos.append(pos)\nall_orn.append(orn)\ncategory = self.obj_attrs.category\nmodel = self.obj_attrs.model\nname = f\"{self.obj_attrs.name}_{self._counter}\"\nself._counter += 1\nscale = self.obj_attrs.scale\nmodel_root_path = f\"{gm.DATASET_PATH}/objects/{category}/{model}\"\nusd_path = f\"{model_root_path}/usd/{model}.usd\"\ngarbage_obj = DatasetObject(\nprim_path=f\"/World/{name}\",\nusd_path=usd_path,\ncategory=category,\nname=f\"{name}\",\nscale=scale)\ngarbage_obj_attrs = ObjectAttrs(\nobj=garbage_obj, pos=np.mean(all_pos, axis=0), orn=np.mean(all_orn, axis=0))\nt_results.add.append(garbage_obj_attrs)\n# Remove all contained objects.\nfor contained_obj in self._cached_contained_objs:\nt_results.remove.append(contained_obj)\n# Turn off the container after the transition and reset things.\nif ToggledOn in container_obj.states:\ncontainer_obj.states[ToggledOn].set_value(False)\nself._cached_contained_objs = None\nreturn t_results\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.ContainerGarbageRule.__init__","title":"<code>__init__(garbage_obj_attrs, container_filter)</code>","text":"<p>Ctor for ContainerGarbageRule.</p> <p>Parameters:</p> Name Type Description Default <code>garbage_obj_attrs</code> <p>(ObjectAttrs) a namedtuple containing the attributes of garbage objects to be created.</p> required <code>container_filter</code> <p>(BaseFilter) a filter for the container.</p> required Source code in <code>omnigibson/transition_rules.py</code> <pre><code>def __init__(self, garbage_obj_attrs, container_filter):\n\"\"\"Ctor for ContainerGarbageRule.\n    Args:\n        garbage_obj_attrs: (ObjectAttrs) a namedtuple containing the\n            attributes of garbage objects to be created.\n        container_filter: (BaseFilter) a filter for the container.\n    \"\"\"\nsuper(ContainerGarbageRule, self).__init__((container_filter,))\nself.obj_attrs = garbage_obj_attrs\nself._cached_contained_objs = None\nself._counter = 0\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.ContainerRule","title":"<code>ContainerRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>Rule to apply to a container and a set of objects that may be inside.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class ContainerRule(BaseTransitionRule):\n\"\"\"\n    Rule to apply to a container and a set of objects that may be inside.\n    \"\"\"\ndef __init__(self, trigger_steps, final_obj_attrs, container_filter, *contained_filters):\n# Should be in this order to have the container object come first.\nsuper(ContainerRule, self).__init__((container_filter, *contained_filters))\nself.obj_attrs = final_obj_attrs\nself.trigger_steps = trigger_steps\nself._current_steps = 1\nself._counter = 0\ndef condition(self, container_obj, *contained_objs):\nif (\nToggledOn in container_obj.states and\nnot container_obj.states[ToggledOn].get_value()\n):\nreturn False\n# Check all objects inside the container against the expected objects.\nall_contained_objs = _contained_objects(og.sim.scene, container_obj)\ncontained_prim_paths = set(obj.prim_path for obj in contained_objs)\nall_contained_prim_paths = set(obj.prim_path for obj in all_contained_objs)\nif contained_prim_paths != all_contained_prim_paths:\nreturn False\n# Check if the trigger step has been reached.\nif self._current_steps &lt; self.trigger_steps:\nself._current_steps += 1\nreturn False\nself._current_steps = 1\nreturn True\ndef transition(self, container_obj, *contained_objs):\nt_results = TransitionResults()\n# Create a new object to be added.\nall_pos, all_orn = [], []\nfor contained_obj in contained_objs:\npos, orn = contained_obj.get_position_orientation()\nall_pos.append(pos)\nall_orn.append(orn)\ncategory = self.obj_attrs.category\nmodel = self.obj_attrs.model\nname = f\"{self.obj_attrs.name}_{self._counter}\"\nself._counter += 1\nscale = self.obj_attrs.scale\nmodel_root_path = f\"{gm.DATASET_PATH}/objects/{category}/{model}\"\nusd_path = f\"{model_root_path}/usd/{model}.usd\"\nfinal_obj = DatasetObject(\nprim_path=f\"/World/{name}\",\nusd_path=usd_path,\ncategory=category,\nname=f\"{name}\",\nscale=scale)\nfinal_obj_attrs = ObjectAttrs(\nobj=final_obj, pos=np.mean(all_pos, axis=0), orn=np.mean(all_orn, axis=0))\nt_results.add.append(final_obj_attrs)\n# Delete all objects inside the container.\nfor contained_obj in contained_objs:\nt_results.remove.append(contained_obj)\n# Turn off the container, otherwise things would turn into garbage.\nif ToggledOn in container_obj.states:\ncontainer_obj.states[ToggledOn].set_value(False)\nprint(f\"Applied {ContainerRule.__name__} to {container_obj}\")\nreturn t_results\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.DicingRule","title":"<code>DicingRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>Transition rule to apply to diceable / slicer object pairs.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class DicingRule(BaseTransitionRule):\n\"\"\"\n    Transition rule to apply to diceable / slicer object pairs.\n    \"\"\"\ndef __init__(self):\n# Define an individual filter dictionary so we can track all valid combos of slicer - sliceable\nindividual_filters = {ability: AbilityFilter(ability) for ability in (\"diceable\", \"slicer\")}\n# Run super\nsuper().__init__(individual_filters=individual_filters)\ndef condition(self, individual_objects, group_objects):\nslicer_obj, diced_obj = individual_objects[\"slicer\"], individual_objects[\"diceable\"]\nslicer_position = slicer_obj.states[Slicer].link.get_position()\nif slicer_position is None:\nreturn False\ncontact_list = slicer_obj.states[ContactBodies].get_value()\nsliced_links = set(diced_obj.links.values())\nif contact_list.isdisjoint(sliced_links):\nreturn False\n# Return if the diceable object still exists\nreturn True\ndef transition(self, individual_objects, group_objects):\nt_results = TransitionResults()\nslicer_obj, diced_obj = individual_objects[\"slicer\"], individual_objects[\"diceable\"]\nsystem_name = f\"diced_{diced_obj.category}\"\nsystem = get_system(system_name)\nsystem.generate_particles_from_link(diced_obj, diced_obj.root_link, use_visual_meshes=False)\n# Delete original object from stage.\nt_results.remove.append(diced_obj)\nreturn t_results\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.GenericTransitionRule","title":"<code>GenericTransitionRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>A generic transition rule template used typically for simple rules.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class GenericTransitionRule(BaseTransitionRule):\n\"\"\"\n    A generic transition rule template used typically for simple rules.\n    \"\"\"\ndef __init__(self, individual_filters, group_filters, condition_fn, transition_fn):\nsuper(GenericTransitionRule, self).__init__(individual_filters, group_filters)\nself.condition_fn = condition_fn\nself.transition_fn = transition_fn\ndef condition(self, individual_objects, group_objects):\nreturn self.condition_fn(individual_objects, group_objects)\ndef transition(self, individual_objects, group_objects):\nreturn self.transition_fn(individual_objects, group_objects)\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.OrFilter","title":"<code>OrFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Logical-or of a set of filters.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class OrFilter(BaseFilter):\n\"\"\"Logical-or of a set of filters.\"\"\"\ndef __init__(self, filters):\nself.filters = filters\ndef __call__(self, obj):\nreturn any(f(obj) for f in self.filters)\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.SlicingRule","title":"<code>SlicingRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>Transition rule to apply to sliced / slicer object pairs.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class SlicingRule(BaseTransitionRule):\n\"\"\"\n    Transition rule to apply to sliced / slicer object pairs.\n    \"\"\"\ndef __init__(self):\n# Define an individual filter dictionary so we can track all valid combos of slicer - sliceable\nindividual_filters = {ability: AbilityFilter(ability) for ability in (\"sliceable\", \"slicer\")}\n# Run super\nsuper().__init__(individual_filters=individual_filters)\ndef condition(self, individual_objects, group_objects):\nslicer_obj, sliced_obj = individual_objects[\"slicer\"], individual_objects[\"sliceable\"]\ncontact_list = slicer_obj.states[ContactBodies].get_value()\nsliced_links = set(sliced_obj.links.values())\nif contact_list.isdisjoint(sliced_links):\nreturn False\n# Slicer may contact the same body in multiple points, so cut once since removing the object from the simulator\nreturn not sliced_obj.states[Sliced].get_value()\ndef transition(self, individual_objects, group_objects):\nslicer_obj, sliced_obj = individual_objects[\"slicer\"], individual_objects[\"sliceable\"]\n# Object parts offset annotation are w.r.t the base link of the whole object.\nsliced_obj.states[Sliced].set_value(True)\npos, orn = sliced_obj.get_position_orientation()\nt_results = TransitionResults()\n# Load object parts.\nfor part_idx, part in sliced_obj.metadata[\"object_parts\"].items():\n# List of dicts gets replaced by {'0':dict, '1':dict, ...}\n# Get bounding box info\npart_bb_pos = np.array(part[\"bb_pos\"])\npart_bb_orn = np.array(part[\"bb_orn\"])\n# Determine the relative scale to apply to the object part from the original object\n# Note that proper (rotated) scaling can only be applied when the relative orientation of\n# the object part is a multiple of 90 degrees wrt the parent object, so we assert that here\n# Check by making sure the quaternion is some permutation of +/- (1, 0, 0, 0),\n# +/- (0.707, 0.707, 0, 0), or +/- (0.5, 0.5, 0.5, 0.5)\n# Because orientations are all normalized (same L2-norm), every orientation should have a unique L1-norm\n# So we check the L1-norm of the absolute value of the orientation as a proxy for verifying these values\nassert np.any(np.isclose(np.abs(part_bb_orn).sum(), np.array([1.0, 1.414, 2.0]), atol=1e-3)), \\\n                \"Sliceable objects should only have relative object part orientations that are factors of 90 degrees!\"\n# Scale the offset accordingly.\nscale = np.abs(T.quat2mat(part_bb_orn) @ sliced_obj.scale)\n# Calculate global part bounding box pose.\npart_bb_pos = pos + T.quat2mat(orn) @ (part_bb_pos * scale)\npart_bb_orn = T.quat_multiply(orn, part_bb_orn)\n# Avoid circular imports\nfrom omnigibson.objects.dataset_object import DatasetObject\npart_obj_name = f\"{sliced_obj.name}_part_{part_idx}\"\npart_obj = DatasetObject(\nprim_path=f\"/World/{part_obj_name}\",\nname=part_obj_name,\ncategory=part[\"category\"],\nmodel=part[\"model\"],\nbounding_box=part[\"bb_size\"] * scale,   # equiv. to scale=(part[\"bb_size\"] / self.native_bbox) * (scale)\n)\n# Add the new object to the results.\nnew_obj_attrs = ObjectAttrs(\nobj=part_obj,\nbb_pos=part_bb_pos,\nbb_orn=part_bb_orn,\nstates={Sliced: (True,)},\n)\nt_results.add.append(new_obj_attrs)\n# Delete original object from stage.\nt_results.remove.append(sliced_obj)\nreturn t_results\n</code></pre>"},{"location":"reference/transition_rules.html#transition_rules.StateFilter","title":"<code>StateFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Filter for object states.</p> Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class StateFilter(BaseFilter):\n\"\"\"Filter for object states.\"\"\"\ndef __init__(self, state_type, state_value):\nself.state_type = state_type\nself.state_value = state_value\ndef __call__(self, obj):\nif self.state_type not in obj.states:\nreturn False\nreturn obj.states[self.state_type].get_value() == self.state_value\n</code></pre>"},{"location":"reference/controllers/index.html","title":"controllers","text":""},{"location":"reference/controllers/index.html#controllers.create_controller","title":"<code>create_controller(name, **kwargs)</code>","text":"<p>Creates a controller of type @name with corresponding necessary keyword arguments @kwargs</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>type of controller to use (e.g. JointController, InverseKinematicsController, etc.)</p> required <code>**kwargs</code> <p>Any relevant keyword arguments to pass to the controller</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Controller</code> <p>created controller</p> Source code in <code>omnigibson/controllers/__init__.py</code> <pre><code>def create_controller(name, **kwargs):\n\"\"\"\n    Creates a controller of type @name with corresponding necessary keyword arguments @kwargs\n    Args:\n        name (str): type of controller to use (e.g. JointController, InverseKinematicsController, etc.)\n        **kwargs: Any relevant keyword arguments to pass to the controller\n    Returns:\n        Controller: created controller\n    \"\"\"\nassert_valid_key(key=name, valid_keys=REGISTERED_CONTROLLERS, name=\"controller\")\ncontroller_cls = REGISTERED_CONTROLLERS[name]\nreturn controller_cls(**kwargs)\n</code></pre>"},{"location":"reference/controllers/controller_base.html","title":"controller_base","text":""},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController","title":"<code>BaseController</code>","text":"<p>         Bases: <code>Serializable</code>, <code>Registerable</code>, <code>Recreatable</code></p> <p>An abstract class with interface for mapping specific types of commands to deployable control signals.</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>class BaseController(Serializable, Registerable, Recreatable):\n\"\"\"\n    An abstract class with interface for mapping specific types of commands to deployable control signals.\n    \"\"\"\ndef __init__(\nself,\ncontrol_freq,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\n):\n\"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n        \"\"\"\n# Store arguments\nself._control_freq = control_freq\nself._control_limits = {}\nfor motor_type in {\"position\", \"velocity\", \"effort\"}:\nif motor_type not in control_limits:\ncontinue\nself._control_limits[ControlType.get_type(motor_type)] = [\nnp.array(control_limits[motor_type][0]),\nnp.array(control_limits[motor_type][1]),\n]\nassert \"has_limit\" in control_limits, \"Expected has_limit specified in control_limits, but does not exist.\"\nself._dof_has_limits = control_limits[\"has_limit\"]\nself._dof_idx = np.array(dof_idx, dtype=int)\n# Initialize some other variables that will be filled in during runtime\nself._control = None\nself._command = None\nself._command_scale_factor = None\nself._command_output_transform = None\nself._command_input_transform = None\n# Standardize command input / output limits to be (min_array, max_array)\ncommand_input_limits = (-1.0, 1.0) if command_input_limits == \"default\" else command_input_limits\ncommand_output_limits = (\n(\nnp.array(self._control_limits[self.control_type][0])[self.dof_idx],\nnp.array(self._control_limits[self.control_type][1])[self.dof_idx],\n)\nif command_output_limits == \"default\"\nelse command_output_limits\n)\nself._command_input_limits = (\nNone\nif command_input_limits is None\nelse (\nself.nums2array(command_input_limits[0], self.command_dim),\nself.nums2array(command_input_limits[1], self.command_dim),\n)\n)\nself._command_output_limits = (\nNone\nif command_output_limits is None\nelse (\nself.nums2array(command_output_limits[0], self.command_dim),\nself.nums2array(command_output_limits[1], self.command_dim),\n)\n)\ndef _preprocess_command(self, command):\n\"\"\"\n        Clips + scales inputted @command according to self.command_input_limits and self.command_output_limits.\n        If self.command_input_limits is None, then no clipping will occur. If either self.command_input_limits\n        or self.command_output_limits is None, then no scaling will occur.\n        Args:\n            command (Array[float] or float): Inputted command vector\n        Returns:\n            Array[float]: Processed command vector\n        \"\"\"\n# Make sure command is a np.array\ncommand = np.array([command]) if type(command) in {int, float} else np.array(command)\n# We only clip and / or scale if self.command_input_limits exists\nif self._command_input_limits is not None:\n# Clip\ncommand = command.clip(*self._command_input_limits)\nif self._command_output_limits is not None:\n# If we haven't calculated how to scale the command, do that now (once)\nif self._command_scale_factor is None:\nself._command_scale_factor = abs(\nself._command_output_limits[1] - self._command_output_limits[0]\n) / abs(self._command_input_limits[1] - self._command_input_limits[0])\nself._command_output_transform = (\nself._command_output_limits[1] + self._command_output_limits[0]\n) / 2.0\nself._command_input_transform = (self._command_input_limits[1] + self._command_input_limits[0]) / 2.0\n# Scale command\ncommand = (\ncommand - self._command_input_transform\n) * self._command_scale_factor + self._command_output_transform\n# Return processed command\nreturn command\ndef update_command(self, command):\n\"\"\"\n        Updates inputted @command internally.\n        Args:\n            command (Array[float]): inputted command to store internally in this controller\n        \"\"\"\n# Sanity check the command\nassert len(command) == self.command_dim, \"Commands must be dimension {}, got dim {} instead.\".format(\nself.command_dim, len(command)\n)\n# Preprocess and store inputted command\nself._command = self._preprocess_command(np.array(command))\ndef clip_control(self, control):\n\"\"\"\n        Clips the inputted @control signal based on @control_limits.\n        Args:\n            control (Array[float]): control signal to clip\n        Returns:\n            Array[float]: Clipped control signal\n        \"\"\"\nclipped_control = control.clip(\nself._control_limits[self.control_type][0][self.dof_idx],\nself._control_limits[self.control_type][1][self.dof_idx],\n)\nidx = (\nself._dof_has_limits[self.dof_idx]\nif self.control_type == ControlType.POSITION\nelse [True] * self.control_dim\n)\ncontrol[idx] = clipped_control[idx]\nreturn control\ndef step(self, control_dict):\n\"\"\"\n        Take a controller step.\n        Args:\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation\n        Returns:\n            Array[float]: numpy array of outputted control signals\n        \"\"\"\ncontrol = self._command_to_control(command=self._command, control_dict=control_dict)\nself._control = self.clip_control(control=control)\nreturn self._control\ndef reset(self):\n\"\"\"\n        Resets this controller. Should be implemented by subclass.\n        \"\"\"\nraise NotImplementedError\ndef _dump_state(self):\n# Default is no state (empty dict)\nreturn dict()\ndef _load_state(self, state):\n# Default is no state (empty dict), so this is a no-op\npass\ndef _serialize(self, state):\n# Default is no state, so do nothing\nreturn np.array([])\ndef _deserialize(self, state):\n# Default is no state, so do nothing\nreturn dict(), 0\ndef _command_to_control(self, command, control_dict):\n\"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) control signal.\n        Should be implemented by subclass.\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation\n        Returns:\n            Array[float]: outputted (non-clipped!) control signal to deploy\n        \"\"\"\nraise NotImplementedError\n@staticmethod\ndef nums2array(nums, dim):\n\"\"\"\n        Convert input @nums into numpy array of length @dim. If @nums is a single number, broadcasts it to the\n        corresponding dimension size @dim before converting into a numpy array\n        Args:\n            nums (numeric or Iterable): Either single value or array of numbers\n            dim (int): Size of array to broadcast input to\n        Returns:\n            np.array: Array filled with values specified in @nums\n        \"\"\"\n# First run sanity check to make sure no strings are being inputted\nif isinstance(nums, str):\nraise TypeError(\"Error: Only numeric inputs are supported for this function, nums2array!\")\n# Check if input is an Iterable, if so, we simply convert the input to np.array and return\n# Else, input is a single value, so we map to a numpy array of correct size and return\nreturn np.array(nums) if isinstance(nums, Iterable) else np.ones(dim) * nums\n@property\ndef state_size(self):\n# Default is no state, so return 0\nreturn 0\n@property\ndef control(self):\n\"\"\"\n        Returns:\n            n-array: Array of most recent controls deployed by this controller\n        \"\"\"\nreturn self._control\n@property\ndef control_freq(self):\n\"\"\"\n        Returns:\n            float: Control frequency (Hz) of this controller\n        \"\"\"\nreturn self._control_freq\n@property\ndef control_dim(self):\n\"\"\"\n        Returns:\n            int: Expected size of outputted controls\n        \"\"\"\nreturn len(self.dof_idx)\n@property\ndef control_type(self):\n\"\"\"\n        Returns:\n            ControlType: Type of control returned by this controller\n        \"\"\"\nraise NotImplementedError\n@property\ndef command_input_limits(self):\n\"\"\"\n        Returns:\n            None or 2-tuple: If specified, returns (min, max) command input limits for this controller, where\n                @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None\n        \"\"\"\nreturn self._command_input_limits\n@property\ndef command_output_limits(self):\n\"\"\"\n        Returns:\n            None or 2-tuple: If specified, returns (min, max) command output limits for this controller, where\n                @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None\n        \"\"\"\nreturn self._command_output_limits\n@property\ndef command_dim(self):\n\"\"\"\n        Returns:\n            int: Expected size of inputted commands\n        \"\"\"\nraise NotImplementedError\n@property\ndef dof_idx(self):\n\"\"\"\n        Returns:\n            Array[int]: DOF indices corresponding to the specific DOFs being controlled by this robot\n        \"\"\"\nreturn np.array(self._dof_idx)\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseController\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_CONTROLLERS\nreturn REGISTERED_CONTROLLERS\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.command_dim","title":"<code>command_dim</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Expected size of inputted commands</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.command_input_limits","title":"<code>command_input_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or 2-tuple: If specified, returns (min, max) command input limits for this controller, where @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.command_output_limits","title":"<code>command_output_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or 2-tuple: If specified, returns (min, max) command output limits for this controller, where @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control","title":"<code>control</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Array of most recent controls deployed by this controller</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control_dim","title":"<code>control_dim</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Expected size of outputted controls</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control_freq","title":"<code>control_freq</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Control frequency (Hz) of this controller</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control_type","title":"<code>control_type</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>ControlType</code> <p>Type of control returned by this controller</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.dof_idx","title":"<code>dof_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>Array[int]: DOF indices corresponding to the specific DOFs being controlled by this robot</p>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.__init__","title":"<code>__init__(control_freq, control_limits, dof_idx, command_input_limits='default', command_output_limits='default')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>control_freq</code> <code>int</code> <p>controller loop frequency</p> required <code>control_limits</code> <code>Dict[str, Tuple[Array[float], Array[float]]]</code> <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p> required <code>dof_idx</code> <code>Array[int]</code> <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p> required <code>command_input_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p> <code>'default'</code> <code>command_output_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p> <code>'default'</code> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>def __init__(\nself,\ncontrol_freq,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\n):\n\"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n    \"\"\"\n# Store arguments\nself._control_freq = control_freq\nself._control_limits = {}\nfor motor_type in {\"position\", \"velocity\", \"effort\"}:\nif motor_type not in control_limits:\ncontinue\nself._control_limits[ControlType.get_type(motor_type)] = [\nnp.array(control_limits[motor_type][0]),\nnp.array(control_limits[motor_type][1]),\n]\nassert \"has_limit\" in control_limits, \"Expected has_limit specified in control_limits, but does not exist.\"\nself._dof_has_limits = control_limits[\"has_limit\"]\nself._dof_idx = np.array(dof_idx, dtype=int)\n# Initialize some other variables that will be filled in during runtime\nself._control = None\nself._command = None\nself._command_scale_factor = None\nself._command_output_transform = None\nself._command_input_transform = None\n# Standardize command input / output limits to be (min_array, max_array)\ncommand_input_limits = (-1.0, 1.0) if command_input_limits == \"default\" else command_input_limits\ncommand_output_limits = (\n(\nnp.array(self._control_limits[self.control_type][0])[self.dof_idx],\nnp.array(self._control_limits[self.control_type][1])[self.dof_idx],\n)\nif command_output_limits == \"default\"\nelse command_output_limits\n)\nself._command_input_limits = (\nNone\nif command_input_limits is None\nelse (\nself.nums2array(command_input_limits[0], self.command_dim),\nself.nums2array(command_input_limits[1], self.command_dim),\n)\n)\nself._command_output_limits = (\nNone\nif command_output_limits is None\nelse (\nself.nums2array(command_output_limits[0], self.command_dim),\nself.nums2array(command_output_limits[1], self.command_dim),\n)\n)\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.clip_control","title":"<code>clip_control(control)</code>","text":"<p>Clips the inputted @control signal based on @control_limits.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>Array[float]</code> <p>control signal to clip</p> required <p>Returns:</p> Type Description <p>Array[float]: Clipped control signal</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>def clip_control(self, control):\n\"\"\"\n    Clips the inputted @control signal based on @control_limits.\n    Args:\n        control (Array[float]): control signal to clip\n    Returns:\n        Array[float]: Clipped control signal\n    \"\"\"\nclipped_control = control.clip(\nself._control_limits[self.control_type][0][self.dof_idx],\nself._control_limits[self.control_type][1][self.dof_idx],\n)\nidx = (\nself._dof_has_limits[self.dof_idx]\nif self.control_type == ControlType.POSITION\nelse [True] * self.control_dim\n)\ncontrol[idx] = clipped_control[idx]\nreturn control\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.nums2array","title":"<code>nums2array(nums, dim)</code>  <code>staticmethod</code>","text":"<p>Convert input @nums into numpy array of length @dim. If @nums is a single number, broadcasts it to the corresponding dimension size @dim before converting into a numpy array</p> <p>Parameters:</p> Name Type Description Default <code>nums</code> <code>numeric or Iterable</code> <p>Either single value or array of numbers</p> required <code>dim</code> <code>int</code> <p>Size of array to broadcast input to</p> required <p>Returns:</p> Type Description <p>np.array: Array filled with values specified in @nums</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>@staticmethod\ndef nums2array(nums, dim):\n\"\"\"\n    Convert input @nums into numpy array of length @dim. If @nums is a single number, broadcasts it to the\n    corresponding dimension size @dim before converting into a numpy array\n    Args:\n        nums (numeric or Iterable): Either single value or array of numbers\n        dim (int): Size of array to broadcast input to\n    Returns:\n        np.array: Array filled with values specified in @nums\n    \"\"\"\n# First run sanity check to make sure no strings are being inputted\nif isinstance(nums, str):\nraise TypeError(\"Error: Only numeric inputs are supported for this function, nums2array!\")\n# Check if input is an Iterable, if so, we simply convert the input to np.array and return\n# Else, input is a single value, so we map to a numpy array of correct size and return\nreturn np.array(nums) if isinstance(nums, Iterable) else np.ones(dim) * nums\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.reset","title":"<code>reset()</code>","text":"<p>Resets this controller. Should be implemented by subclass.</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>def reset(self):\n\"\"\"\n    Resets this controller. Should be implemented by subclass.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.step","title":"<code>step(control_dict)</code>","text":"<p>Take a controller step.</p> <p>Parameters:</p> Name Type Description Default <code>control_dict</code> <code>Dict[str, Any]</code> <p>dictionary that should include any relevant keyword-mapped states necessary for controller computation</p> required <p>Returns:</p> Type Description <p>Array[float]: numpy array of outputted control signals</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>def step(self, control_dict):\n\"\"\"\n    Take a controller step.\n    Args:\n        control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n            states necessary for controller computation\n    Returns:\n        Array[float]: numpy array of outputted control signals\n    \"\"\"\ncontrol = self._command_to_control(command=self._command, control_dict=control_dict)\nself._control = self.clip_control(control=control)\nreturn self._control\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.update_command","title":"<code>update_command(command)</code>","text":"<p>Updates inputted @command internally.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>Array[float]</code> <p>inputted command to store internally in this controller</p> required Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>def update_command(self, command):\n\"\"\"\n    Updates inputted @command internally.\n    Args:\n        command (Array[float]): inputted command to store internally in this controller\n    \"\"\"\n# Sanity check the command\nassert len(command) == self.command_dim, \"Commands must be dimension {}, got dim {} instead.\".format(\nself.command_dim, len(command)\n)\n# Preprocess and store inputted command\nself._command = self._preprocess_command(np.array(command))\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.ControlType","title":"<code>ControlType</code>","text":"Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>class ControlType:\nNONE = -1\nPOSITION = 0\nVELOCITY = 1\nEFFORT = 2\n_MAPPING = {\n\"none\": NONE,\n\"position\": POSITION,\n\"velocity\": VELOCITY,\n\"effort\": EFFORT,\n}\nVALID_TYPES = set(_MAPPING.values())\nVALID_TYPES_STR = set(_MAPPING.keys())\n@classmethod\ndef get_type(cls, type_str):\n\"\"\"\n        Args:\n            type_str (str): One of \"position\", \"velocity\", or \"effort\" (any case), and maps it\n                to the corresponding type\n        Returns:\n            ControlType: control type corresponding to the associated string\n        \"\"\"\nassert_valid_key(key=type_str.lower(), valid_keys=cls._MAPPING, name=\"control type\")\nreturn cls._MAPPING[type_str.lower()]\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.ControlType.get_type","title":"<code>get_type(type_str)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>type_str</code> <code>str</code> <p>One of \"position\", \"velocity\", or \"effort\" (any case), and maps it to the corresponding type</p> required <p>Returns:</p> Name Type Description <code>ControlType</code> <p>control type corresponding to the associated string</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>@classmethod\ndef get_type(cls, type_str):\n\"\"\"\n    Args:\n        type_str (str): One of \"position\", \"velocity\", or \"effort\" (any case), and maps it\n            to the corresponding type\n    Returns:\n        ControlType: control type corresponding to the associated string\n    \"\"\"\nassert_valid_key(key=type_str.lower(), valid_keys=cls._MAPPING, name=\"control type\")\nreturn cls._MAPPING[type_str.lower()]\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.GripperController","title":"<code>GripperController</code>","text":"<p>         Bases: <code>BaseController</code></p> <p>Controller to control a gripper. All implemented controllers that encompass gripper capabilities should extend from this class.</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>class GripperController(BaseController):\n\"\"\"\n    Controller to control a gripper. All implemented controllers that encompass gripper capabilities\n    should extend from this class.\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\n# Register as part of gripper controllers\nsuper().__init_subclass__(**kwargs)\nregister_gripper_controller(cls)\ndef is_grasping(self):\n\"\"\"\n        Checks whether the current state of this gripper being controlled is in a grasping state.\n        Should be implemented by subclass.\n        Returns:\n            IsGraspingState: Grasping state of gripper\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"GripperController\")\nreturn classes\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.GripperController.is_grasping","title":"<code>is_grasping()</code>","text":"<p>Checks whether the current state of this gripper being controlled is in a grasping state. Should be implemented by subclass.</p> <p>Returns:</p> Name Type Description <code>IsGraspingState</code> <p>Grasping state of gripper</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>def is_grasping(self):\n\"\"\"\n    Checks whether the current state of this gripper being controlled is in a grasping state.\n    Should be implemented by subclass.\n    Returns:\n        IsGraspingState: Grasping state of gripper\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.LocomotionController","title":"<code>LocomotionController</code>","text":"<p>         Bases: <code>BaseController</code></p> <p>Controller to control locomotion. All implemented controllers that encompass locomotion capabilities should extend from this class.</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>class LocomotionController(BaseController):\n\"\"\"\n    Controller to control locomotion. All implemented controllers that encompass locomotion capabilities should extend\n    from this class.\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\n# Register as part of locomotion controllers\nsuper().__init_subclass__(**kwargs)\nregister_locomotion_controller(cls)\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"LocomotionController\")\nreturn classes\n</code></pre>"},{"location":"reference/controllers/controller_base.html#controllers.controller_base.ManipulationController","title":"<code>ManipulationController</code>","text":"<p>         Bases: <code>BaseController</code></p> <p>Controller to control manipulation. All implemented controllers that encompass manipulation capabilities should extend from this class.</p> Source code in <code>omnigibson/controllers/controller_base.py</code> <pre><code>class ManipulationController(BaseController):\n\"\"\"\n    Controller to control manipulation. All implemented controllers that encompass manipulation capabilities\n    should extend from this class.\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\n# Register as part of manipulation controllers\nsuper().__init_subclass__(**kwargs)\nregister_manipulation_controller(cls)\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"ManipulationController\")\nreturn classes\n</code></pre>"},{"location":"reference/controllers/dd_controller.html","title":"dd_controller","text":""},{"location":"reference/controllers/dd_controller.html#controllers.dd_controller.DifferentialDriveController","title":"<code>DifferentialDriveController</code>","text":"<p>         Bases: <code>LocomotionController</code></p> <p>Differential drive (DD) controller for controlling two independently controlled wheeled joints.</p> Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits</li> <li>Convert desired (lin_vel, ang_vel) command into (left, right) wheel joint velocity control signals</li> <li>Clips the resulting command by the joint velocity limits</li> </ol> Source code in <code>omnigibson/controllers/dd_controller.py</code> <pre><code>class DifferentialDriveController(LocomotionController):\n\"\"\"\n    Differential drive (DD) controller for controlling two independently controlled wheeled joints.\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2. Convert desired (lin_vel, ang_vel) command into (left, right) wheel joint velocity control signals\n        3. Clips the resulting command by the joint velocity limits\n    \"\"\"\ndef __init__(\nself,\nwheel_radius,\nwheel_axle_length,\ncontrol_freq,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\n):\n\"\"\"\n        Args:\n            wheel_radius (float): radius of the wheels (both assumed to be same radius)\n            wheel_axle_length (float): perpendicular distance between the two wheels\n            control_freq (int): controller loop frequency\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the maximum linear and angular velocities calculated from @wheel_radius, @wheel_axle_length, and\n                @control_limits velocity limits entry\n        \"\"\"\n# Store internal variables\nself._wheel_radius = wheel_radius\nself._wheel_axle_halflength = wheel_axle_length / 2.0\n# If we're using default command output limits, map this to maximum linear / angular velocities\nif command_output_limits == \"default\":\nmin_vels = control_limits[\"velocity\"][0][dof_idx]\nassert (\nmin_vels[0] == min_vels[1]\n), \"Differential drive requires both wheel joints to have same min velocities!\"\nmax_vels = control_limits[\"velocity\"][1][dof_idx]\nassert (\nmax_vels[0] == max_vels[1]\n), \"Differential drive requires both wheel joints to have same max velocities!\"\nassert abs(min_vels[0]) == abs(\nmax_vels[0]\n), \"Differential drive requires both wheel joints to have same min and max absolute velocities!\"\nmax_lin_vel = max_vels[0] * wheel_radius\nmax_ang_vel = max_lin_vel * 2.0 / wheel_axle_length\ncommand_output_limits = ((-max_lin_vel, -max_ang_vel), (max_lin_vel, max_ang_vel))\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\ndef reset(self):\n# No-op\npass\ndef _command_to_control(self, command, control_dict):\n\"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) joint control signal.\n        This processes converts the desired (lin_vel, ang_vel) command into (left, right) wheel joint velocity control\n        signals.\n        Args:\n            command (Array[float]): desired (already preprocessed) 2D command to convert into control signals\n                Consists of desired (lin_vel, ang_vel) of the controlled body\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n        Returns:\n            Array[float]: outputted (non-clipped!) velocity control signal to deploy\n                to the [left, right] wheel joints\n        \"\"\"\nlin_vel, ang_vel = command\n# Convert to wheel velocities\nleft_wheel_joint_vel = (lin_vel - ang_vel * self._wheel_axle_halflength) / self._wheel_radius\nright_wheel_joint_vel = (lin_vel + ang_vel * self._wheel_axle_halflength) / self._wheel_radius\n# Return desired velocities\nreturn np.array([left_wheel_joint_vel, right_wheel_joint_vel])\n@property\ndef control_type(self):\nreturn ControlType.VELOCITY\n@property\ndef command_dim(self):\n# [lin_vel, ang_vel]\nreturn 2\n</code></pre>"},{"location":"reference/controllers/dd_controller.html#controllers.dd_controller.DifferentialDriveController.__init__","title":"<code>__init__(wheel_radius, wheel_axle_length, control_freq, control_limits, dof_idx, command_input_limits='default', command_output_limits='default')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>wheel_radius</code> <code>float</code> <p>radius of the wheels (both assumed to be same radius)</p> required <code>wheel_axle_length</code> <code>float</code> <p>perpendicular distance between the two wheels</p> required <code>control_freq</code> <code>int</code> <p>controller loop frequency</p> required <code>control_limits</code> <code>Dict[str, Tuple[Array[float], Array[float]]]</code> <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p> required <code>dof_idx</code> <code>Array[int]</code> <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p> required <code>command_input_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p> <code>'default'</code> <code>command_output_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the maximum linear and angular velocities calculated from @wheel_radius, @wheel_axle_length, and @control_limits velocity limits entry</p> <code>'default'</code> Source code in <code>omnigibson/controllers/dd_controller.py</code> <pre><code>def __init__(\nself,\nwheel_radius,\nwheel_axle_length,\ncontrol_freq,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\n):\n\"\"\"\n    Args:\n        wheel_radius (float): radius of the wheels (both assumed to be same radius)\n        wheel_axle_length (float): perpendicular distance between the two wheels\n        control_freq (int): controller loop frequency\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the maximum linear and angular velocities calculated from @wheel_radius, @wheel_axle_length, and\n            @control_limits velocity limits entry\n    \"\"\"\n# Store internal variables\nself._wheel_radius = wheel_radius\nself._wheel_axle_halflength = wheel_axle_length / 2.0\n# If we're using default command output limits, map this to maximum linear / angular velocities\nif command_output_limits == \"default\":\nmin_vels = control_limits[\"velocity\"][0][dof_idx]\nassert (\nmin_vels[0] == min_vels[1]\n), \"Differential drive requires both wheel joints to have same min velocities!\"\nmax_vels = control_limits[\"velocity\"][1][dof_idx]\nassert (\nmax_vels[0] == max_vels[1]\n), \"Differential drive requires both wheel joints to have same max velocities!\"\nassert abs(min_vels[0]) == abs(\nmax_vels[0]\n), \"Differential drive requires both wheel joints to have same min and max absolute velocities!\"\nmax_lin_vel = max_vels[0] * wheel_radius\nmax_ang_vel = max_lin_vel * 2.0 / wheel_axle_length\ncommand_output_limits = ((-max_lin_vel, -max_ang_vel), (max_lin_vel, max_ang_vel))\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\n</code></pre>"},{"location":"reference/controllers/ik_controller.html","title":"ik_controller","text":""},{"location":"reference/controllers/ik_controller.html#controllers.ik_controller.InverseKinematicsController","title":"<code>InverseKinematicsController</code>","text":"<p>         Bases: <code>ManipulationController</code></p> <p>Controller class to convert (delta) EEF commands into joint velocities using Inverse Kinematics (IK).</p> Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits</li> <li>Run Inverse Kinematics to back out joint velocities for a desired task frame command</li> <li>Clips the resulting command by the motor (velocity) limits</li> </ol> Source code in <code>omnigibson/controllers/ik_controller.py</code> <pre><code>class InverseKinematicsController(ManipulationController):\n\"\"\"\n    Controller class to convert (delta) EEF commands into joint velocities using Inverse Kinematics (IK).\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2. Run Inverse Kinematics to back out joint velocities for a desired task frame command\n        3. Clips the resulting command by the motor (velocity) limits\n    \"\"\"\ndef __init__(\nself,\ntask_name,\nrobot_description_path,\nrobot_urdf_path,\neef_name,\ncontrol_freq,\ndefault_joint_pos,          # TODO: Currently doesn't do anything in Lula\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5)),\nmotor_type=\"velocity\",\nkv=2.0,\nmode=\"pose_delta_ori\",\nsmoothing_filter_size=None,\nworkspace_pose_limiter=None,\n):\n\"\"\"\n        Args:\n            task_name (str): name assigned to this task frame for computing IK control. During control calculations,\n                the inputted control_dict should include entries named &lt;@task_name&gt;_pos_relative and\n                &lt;@task_name&gt;_quat_relative. See self._command_to_control() for what these values should entail.\n            robot_description_path (str): path to robot descriptor yaml file\n            robot_urdf_path (str): path to robot urdf file\n            eef_name (str): end effector frame name\n            control_freq (int): controller loop frequency\n            default_joint_pos (Array[float]): default joint positions, used as part of nullspace controller in IK.\n                Note that this should correspond to ALL the joints; the exact indices will be extracted via @dof_idx\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                    control signal. Should specify per-dof type limits, i.e.:\n                    \"position\": [[min], [max]]\n                    \"velocity\": [[min], [max]]\n                    \"effort\": [[min], [max]]\n                    \"has_limit\": [...bool...]\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            motor_type (str): type of motor being controlled, one of {position, velocity}\n            kv (float): Gain applied to error between IK-commanded joint positions and current joint positions if\n                using @motor_type = velocity\n            mode (str): mode to use when computing IK. In all cases, position commands are 3DOF delta (dx,dy,dz)\n                cartesian values, relative to the robot base frame. Valid options are:\n                    - \"pose_absolute_ori\": 6DOF (dx,dy,dz,ax,ay,az) control over pose,\n                        where the orientation is given in absolute axis-angle coordinates\n                    - \"pose_delta_ori\": 6DOF (dx,dy,dz,dax,day,daz) control over pose\n                    - \"position_fixed_ori\": 3DOF (dx,dy,dz) control over position,\n                        with orientation commands being kept as fixed initial absolute orientation\n                    - \"position_compliant_ori\": 3DOF (dx,dy,dz) control over position,\n                        with orientation commands automatically being sent as 0s (so can drift over time)\n            smoothing_filter_size (None or int): if specified, sets the size of a moving average filter to apply\n                on all outputted IK joint positions.\n            workspace_pose_limiter (None or function): if specified, callback method that should clip absolute\n                target (x,y,z) cartesian position and absolute quaternion orientation (x,y,z,w) to a specific workspace\n                range (i.e.: this can be unique to each robot, and implemented by each embodiment).\n                Function signature should be:\n                    def limiter(command_pos: Array[float], command_quat: Array[float], control_dict: Dict[str, Any]) --&gt; Tuple[Array[float], Array[float]]\n                where pos_command is (x,y,z) cartesian position values, command_quat is (x,y,z,w) quarternion orientation\n                values, and the returned tuple is the processed (pos, quat) command.\n        \"\"\"\n# Store arguments\ncontrol_dim = len(dof_idx)\nassert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\nself._motor_type = motor_type.lower()\nself.control_filter = (\nNone\nif smoothing_filter_size in {None, 0}\nelse MovingAverageFilter(obs_dim=control_dim, filter_width=smoothing_filter_size)\n)\nassert mode in IK_MODES, \"Invalid ik mode specified! Valid options are: {IK_MODES}, got: {mode}\"\nself.mode = mode\nself.kv = kv\nself.workspace_pose_limiter = workspace_pose_limiter\nself.task_name = task_name\nself.default_joint_pos = default_joint_pos[dof_idx]\n# Create the lula IKSolver\nself.solver = IKSolver(\nrobot_description_path=robot_description_path,\nrobot_urdf_path=robot_urdf_path,\neef_name=eef_name,\ndefault_joint_pos=default_joint_pos,\n)\n# Other variables that will be filled in at runtime\nself._quat_target = None\n# If the mode is set as absolute orientation and using default config,\n# change input and output limits accordingly.\n# By default, the input limits are set as 1, so we modify this to have a correct range.\n# The output orientation limits are also set to be values assuming delta commands, so those are updated too\nif self.mode == \"pose_absolute_ori\":\nif command_input_limits is not None:\nif command_input_limits == \"default\":\ncommand_input_limits = [\n[-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n[1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n]\nelse:\ncommand_input_limits[0][3:] = -np.pi\ncommand_input_limits[1][3:] = np.pi\nif command_output_limits is not None:\nif command_output_limits == \"default\":\ncommand_output_limits = [\n[-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n[1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n]\nelse:\ncommand_output_limits[0][3:] = -np.pi\ncommand_output_limits[1][3:] = np.pi\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\ndef reset(self):\n# Reset the filter and clear internal control state\nif self.control_filter is not None:\nself.control_filter.reset()\nself._quat_target = None\n@property\ndef state_size(self):\n# Add 4 for internal quat target and the state size from the control filter\nreturn super().state_size + 4 + self.control_filter.state_size\ndef _dump_state(self):\n# Run super first\nstate = super()._dump_state()\n# Add internal quaternion target and filter state\nstate[\"quat_target\"] = self._quat_target\nstate[\"control_filter\"] = self.control_filter.dump_state(serialized=False)\nreturn state\ndef _load_state(self, state):\n# Run super first\nsuper()._load_state(state=state)\n# Load relevant info for this controller\nself._quat_target = state[\"quat_target\"]\nself.control_filter.load_state(state[\"control_filter\"], serialized=False)\ndef _serialize(self, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\n# Serialize state for this controller\nreturn np.concatenate([\nstate_flat,\nnp.zeros(4) if state[\"quat_target\"] is None else state[\"quat_target\"],      # Encode None as zeros for consistent serialization size\nself.control_filter.serialize(state=state[\"control_filter\"]),\n]).astype(float)\ndef _deserialize(self, state):\n# Run super first\nstate_dict, idx = super()._deserialize(state=state)\n# Deserialize state for this controller\nstate_dict[\"quat_target\"] = None if np.all(state[idx: idx + 4] == 0.0) else state[idx: idx + 4]\nstate_dict[\"control_filter\"] = self.control_filter.deserialize(state=state[idx + 4: idx + 4 + self.control_filter.state_size])\nreturn state_dict, idx + 4 + self.control_filter.state_size\ndef _command_to_control(self, command, control_dict):\n\"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) joint control signal.\n        This processes the command based on self.mode, possibly clips the command based on self.workspace_pose_limiter,\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals\n                Is one of:\n                    (dx,dy,dz) - desired delta cartesian position\n                    (dx,dy,dz,dax,day,daz) - desired delta cartesian position and delta axis-angle orientation\n                    (dx,dy,dz,ax,ay,az) - desired delta cartesian position and global axis-angle orientation\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n                    joint_position: Array of current joint positions\n                    base_pos: (x,y,z) cartesian position of the robot's base relative to the static global frame\n                    base_quat: (x,y,z,w) quaternion orientation of the robot's base relative to the static global frame\n                    &lt;@self.task_name&gt;_pos_relative: (x,y,z) relative cartesian position of the desired task frame to\n                        control, computed in its local frame (e.g.: robot base frame)\n                    &lt;@self.task_name&gt;_quat_relative: (x,y,z,w) relative quaternion orientation of the desired task\n                        frame to control, computed in its local frame (e.g.: robot base frame)\n        Returns:\n            Array[float]: outputted (non-clipped!) velocity control signal to deploy\n        \"\"\"\n# Grab important info from control dict\npos_relative = np.array(control_dict[\"{}_pos_relative\".format(self.task_name)])\nquat_relative = np.array(control_dict[\"{}_quat_relative\".format(self.task_name)])\n# The first three values of the command are always the (delta) position, convert to absolute values\ndpos = command[:3]\ntarget_pos = pos_relative + dpos\n# Compute orientation\nif self.mode == \"position_fixed_ori\":\n# We need to grab the current robot orientation as the commanded orientation if there is none saved\nif self._quat_target is None:\nself._quat_target = quat_relative\ntarget_quat = self._quat_target\nelif self.mode == \"position_compliant_ori\":\n# Target quat is simply the current robot orientation\ntarget_quat = quat_relative\nelif self.mode == \"pose_absolute_ori\":\n# Received \"delta\" ori is in fact the desired absolute orientation\ntarget_quat = T.axisangle2quat(command[3:])\nelse:  # pose_delta_ori control\n# Grab dori and compute target ori\ndori = T.quat2mat(T.axisangle2quat(command[3:]))\ntarget_quat = T.mat2quat(dori @ T.quat2mat(quat_relative))\n# Possibly limit to workspace if specified\nif self.workspace_pose_limiter is not None:\ntarget_pos, target_quat = self.workspace_pose_limiter(target_pos, target_quat, control_dict)\n# Calculate and return IK-backed out joint angles\ncurrent_joint_pos = control_dict[\"joint_position\"][self.dof_idx]\ntarget_joint_pos = self.solver.solve(\ntarget_pos=target_pos,\ntarget_quat=target_quat,\ninitial_joint_pos=current_joint_pos,\n)\nif target_joint_pos is None:\n# Print warning that we couldn't find a valid solution, and return the current joint configuration\n# instead so that we execute a no-op control\nlog.warning(f\"Could not find valid IK configuration! Returning no-op control instead.\")\ntarget_joint_pos = current_joint_pos\n# Optionally pass through smoothing filter for better stability\nif self.control_filter is not None:\ntarget_joint_pos = self.control_filter.estimate(target_joint_pos)\n# Grab the resulting error and scale it by the velocity gain, or else simply use the target_joint_pos\nu = -self.kv * (current_joint_pos - target_joint_pos) if \\\n            self.control_type == ControlType.VELOCITY else target_joint_pos\n# Return these commanded velocities (this only includes the relevant dof idx)\nreturn u\n@property\ndef control_type(self):\nreturn ControlType.get_type(type_str=self._motor_type)\n@property\ndef command_dim(self):\nreturn IK_MODE_COMMAND_DIMS[self.mode]\n</code></pre>"},{"location":"reference/controllers/ik_controller.html#controllers.ik_controller.InverseKinematicsController.__init__","title":"<code>__init__(task_name, robot_description_path, robot_urdf_path, eef_name, control_freq, default_joint_pos, control_limits, dof_idx, command_input_limits='default', command_output_limits=((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5)), motor_type='velocity', kv=2.0, mode='pose_delta_ori', smoothing_filter_size=None, workspace_pose_limiter=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>task_name</code> <code>str</code> <p>name assigned to this task frame for computing IK control. During control calculations, the inputted control_dict should include entries named &lt;@task_name&gt;_pos_relative and &lt;@task_name&gt;_quat_relative. See self._command_to_control() for what these values should entail.</p> required <code>robot_description_path</code> <code>str</code> <p>path to robot descriptor yaml file</p> required <code>robot_urdf_path</code> <code>str</code> <p>path to robot urdf file</p> required <code>eef_name</code> <code>str</code> <p>end effector frame name</p> required <code>control_freq</code> <code>int</code> <p>controller loop frequency</p> required <code>default_joint_pos</code> <code>Array[float]</code> <p>default joint positions, used as part of nullspace controller in IK. Note that this should correspond to ALL the joints; the exact indices will be extracted via @dof_idx</p> required <code>control_limits</code> <code>Dict[str, Tuple[Array[float], Array[float]]]</code> <p>The min/max limits to the outputted     control signal. Should specify per-dof type limits, i.e.:</p> <pre><code>\"position\": [[min], [max]]\n\"velocity\": [[min], [max]]\n\"effort\": [[min], [max]]\n\"has_limit\": [...bool...]\n</code></pre> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p> required <code>dof_idx</code> <code>Array[int]</code> <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p> required <code>command_input_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p> <code>'default'</code> <code>command_output_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p> <code>((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5))</code> <code>motor_type</code> <code>str</code> <p>type of motor being controlled, one of {position, velocity}</p> <code>'velocity'</code> <code>kv</code> <code>float</code> <p>Gain applied to error between IK-commanded joint positions and current joint positions if using @motor_type = velocity</p> <code>2.0</code> <code>mode</code> <code>str</code> <p>mode to use when computing IK. In all cases, position commands are 3DOF delta (dx,dy,dz) cartesian values, relative to the robot base frame. Valid options are:     - \"pose_absolute_ori\": 6DOF (dx,dy,dz,ax,ay,az) control over pose,         where the orientation is given in absolute axis-angle coordinates     - \"pose_delta_ori\": 6DOF (dx,dy,dz,dax,day,daz) control over pose     - \"position_fixed_ori\": 3DOF (dx,dy,dz) control over position,         with orientation commands being kept as fixed initial absolute orientation     - \"position_compliant_ori\": 3DOF (dx,dy,dz) control over position,         with orientation commands automatically being sent as 0s (so can drift over time)</p> <code>'pose_delta_ori'</code> <code>smoothing_filter_size</code> <code>None or int</code> <p>if specified, sets the size of a moving average filter to apply on all outputted IK joint positions.</p> <code>None</code> <code>workspace_pose_limiter</code> <code>None or function</code> <p>if specified, callback method that should clip absolute target (x,y,z) cartesian position and absolute quaternion orientation (x,y,z,w) to a specific workspace range (i.e.: this can be unique to each robot, and implemented by each embodiment). Function signature should be:</p> <pre><code>def limiter(command_pos: Array[float], command_quat: Array[float], control_dict: Dict[str, Any]) --&gt; Tuple[Array[float], Array[float]]\n</code></pre> <p>where pos_command is (x,y,z) cartesian position values, command_quat is (x,y,z,w) quarternion orientation values, and the returned tuple is the processed (pos, quat) command.</p> <code>None</code> Source code in <code>omnigibson/controllers/ik_controller.py</code> <pre><code>def __init__(\nself,\ntask_name,\nrobot_description_path,\nrobot_urdf_path,\neef_name,\ncontrol_freq,\ndefault_joint_pos,          # TODO: Currently doesn't do anything in Lula\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5)),\nmotor_type=\"velocity\",\nkv=2.0,\nmode=\"pose_delta_ori\",\nsmoothing_filter_size=None,\nworkspace_pose_limiter=None,\n):\n\"\"\"\n    Args:\n        task_name (str): name assigned to this task frame for computing IK control. During control calculations,\n            the inputted control_dict should include entries named &lt;@task_name&gt;_pos_relative and\n            &lt;@task_name&gt;_quat_relative. See self._command_to_control() for what these values should entail.\n        robot_description_path (str): path to robot descriptor yaml file\n        robot_urdf_path (str): path to robot urdf file\n        eef_name (str): end effector frame name\n        control_freq (int): controller loop frequency\n        default_joint_pos (Array[float]): default joint positions, used as part of nullspace controller in IK.\n            Note that this should correspond to ALL the joints; the exact indices will be extracted via @dof_idx\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        motor_type (str): type of motor being controlled, one of {position, velocity}\n        kv (float): Gain applied to error between IK-commanded joint positions and current joint positions if\n            using @motor_type = velocity\n        mode (str): mode to use when computing IK. In all cases, position commands are 3DOF delta (dx,dy,dz)\n            cartesian values, relative to the robot base frame. Valid options are:\n                - \"pose_absolute_ori\": 6DOF (dx,dy,dz,ax,ay,az) control over pose,\n                    where the orientation is given in absolute axis-angle coordinates\n                - \"pose_delta_ori\": 6DOF (dx,dy,dz,dax,day,daz) control over pose\n                - \"position_fixed_ori\": 3DOF (dx,dy,dz) control over position,\n                    with orientation commands being kept as fixed initial absolute orientation\n                - \"position_compliant_ori\": 3DOF (dx,dy,dz) control over position,\n                    with orientation commands automatically being sent as 0s (so can drift over time)\n        smoothing_filter_size (None or int): if specified, sets the size of a moving average filter to apply\n            on all outputted IK joint positions.\n        workspace_pose_limiter (None or function): if specified, callback method that should clip absolute\n            target (x,y,z) cartesian position and absolute quaternion orientation (x,y,z,w) to a specific workspace\n            range (i.e.: this can be unique to each robot, and implemented by each embodiment).\n            Function signature should be:\n                def limiter(command_pos: Array[float], command_quat: Array[float], control_dict: Dict[str, Any]) --&gt; Tuple[Array[float], Array[float]]\n            where pos_command is (x,y,z) cartesian position values, command_quat is (x,y,z,w) quarternion orientation\n            values, and the returned tuple is the processed (pos, quat) command.\n    \"\"\"\n# Store arguments\ncontrol_dim = len(dof_idx)\nassert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\nself._motor_type = motor_type.lower()\nself.control_filter = (\nNone\nif smoothing_filter_size in {None, 0}\nelse MovingAverageFilter(obs_dim=control_dim, filter_width=smoothing_filter_size)\n)\nassert mode in IK_MODES, \"Invalid ik mode specified! Valid options are: {IK_MODES}, got: {mode}\"\nself.mode = mode\nself.kv = kv\nself.workspace_pose_limiter = workspace_pose_limiter\nself.task_name = task_name\nself.default_joint_pos = default_joint_pos[dof_idx]\n# Create the lula IKSolver\nself.solver = IKSolver(\nrobot_description_path=robot_description_path,\nrobot_urdf_path=robot_urdf_path,\neef_name=eef_name,\ndefault_joint_pos=default_joint_pos,\n)\n# Other variables that will be filled in at runtime\nself._quat_target = None\n# If the mode is set as absolute orientation and using default config,\n# change input and output limits accordingly.\n# By default, the input limits are set as 1, so we modify this to have a correct range.\n# The output orientation limits are also set to be values assuming delta commands, so those are updated too\nif self.mode == \"pose_absolute_ori\":\nif command_input_limits is not None:\nif command_input_limits == \"default\":\ncommand_input_limits = [\n[-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n[1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n]\nelse:\ncommand_input_limits[0][3:] = -np.pi\ncommand_input_limits[1][3:] = np.pi\nif command_output_limits is not None:\nif command_output_limits == \"default\":\ncommand_output_limits = [\n[-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n[1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n]\nelse:\ncommand_output_limits[0][3:] = -np.pi\ncommand_output_limits[1][3:] = np.pi\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\n</code></pre>"},{"location":"reference/controllers/joint_controller.html","title":"joint_controller","text":""},{"location":"reference/controllers/joint_controller.html#controllers.joint_controller.JointController","title":"<code>JointController</code>","text":"<p>         Bases: <code>LocomotionController</code>, <code>ManipulationController</code>, <code>GripperController</code></p> <p>Controller class for joint control. Because omniverse can handle direct position / velocity / effort control signals, this is merely a pass-through operation from command to control (with clipping / scaling built in).</p> Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits 2a. If using delta commands, then adds the command to the current joint state 2b. Clips the resulting command by the motor limits</li> </ol> Source code in <code>omnigibson/controllers/joint_controller.py</code> <pre><code>class JointController(LocomotionController, ManipulationController, GripperController):\n\"\"\"\n    Controller class for joint control. Because omniverse can handle direct position / velocity / effort\n    control signals, this is merely a pass-through operation from command to control (with clipping / scaling built in).\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2a. If using delta commands, then adds the command to the current joint state\n        2b. Clips the resulting command by the motor limits\n    \"\"\"\ndef __init__(\nself,\ncontrol_freq,\nmotor_type,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\nuse_delta_commands=False,\ncompute_delta_in_quat_space=None,\n):\n\"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            motor_type (str): type of motor being controlled, one of {position, velocity, effort}\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            use_delta_commands (bool): whether inputted commands should be interpreted as delta or absolute values\n            compute_delta_in_quat_space (None or List[(rx_idx, ry_idx, rz_idx), ...]): if specified, groups of\n                joints that need to be processed in quaternion space to avoid gimbal lock issues normally faced by\n                3 DOF rotation joints. Each group needs to consist of three idxes corresponding to the indices in\n                the input space. This is only used in the delta_commands mode.\n        \"\"\"\n# Store arguments\nassert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\nself._motor_type = motor_type.lower()\nself._use_delta_commands = use_delta_commands\nself._compute_delta_in_quat_space = [] if compute_delta_in_quat_space is None else compute_delta_in_quat_space\n# When in delta mode, it doesn't make sense to infer output range using the joint limits (since that's an\n# absolute range and our values are relative). So reject the default mode option in that case.\nassert not (\nself._use_delta_commands and command_output_limits == \"default\"\n), \"Cannot use 'default' command output limits in delta commands mode of JointController. Try None instead.\"\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\ndef reset(self):\n# Nothing to reset.\npass\ndef _command_to_control(self, command, control_dict):\n\"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) joint control signal\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n                    joint_position: Array of current joint positions\n                    joint_velocity: Array of current joint velocities\n                    joint_effort: Array of current joint effort\n        Returns:\n            Array[float]: outputted (non-clipped!) control signal to deploy\n        \"\"\"\n# If we're using delta commands, add this value\nif self._use_delta_commands:\n# Compute the base value for the command.\nbase_value = control_dict[\"joint_{}\".format(self._motor_type)][self.dof_idx]\n# Apply the command to the base value.\nu = base_value + command\n# Correct any gimbal lock issues using the compute_delta_in_quat_space group.\nfor rx_ind, ry_ind, rz_ind in self._compute_delta_in_quat_space:\n# Grab the starting rotations of these joints.\nstart_rots = base_value[[rx_ind, ry_ind, rz_ind]]\n# Grab the delta rotations.\ndelta_rots = command[[rx_ind, ry_ind, rz_ind]]\n# Compute the final rotations in the quaternion space.\n_, end_quat = T.pose_transform(np.zeros(3), T.euler2quat(delta_rots),\nnp.zeros(3), T.euler2quat(start_rots))\nend_rots = T.quat2euler(end_quat)\n# Update the command\nu[[rx_ind, ry_ind, rz_ind]] = end_rots\n# Otherwise, control is simply the command itself\nelse:\nu = command\n# Return control\nreturn u\ndef is_grasping(self):\n# No good heuristic to determine grasping, so return UNKNOWN\nreturn IsGraspingState.UNKNOWN\n@property\ndef use_delta_commands(self):\n\"\"\"\n        Returns:\n            bool: Whether this controller is using delta commands or not\n        \"\"\"\nreturn self._use_delta_commands\n@property\ndef control_type(self):\nreturn ControlType.get_type(type_str=self._motor_type)\n@property\ndef command_dim(self):\nreturn len(self.dof_idx)\n</code></pre>"},{"location":"reference/controllers/joint_controller.html#controllers.joint_controller.JointController.use_delta_commands","title":"<code>use_delta_commands</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this controller is using delta commands or not</p>"},{"location":"reference/controllers/joint_controller.html#controllers.joint_controller.JointController.__init__","title":"<code>__init__(control_freq, motor_type, control_limits, dof_idx, command_input_limits='default', command_output_limits='default', use_delta_commands=False, compute_delta_in_quat_space=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>control_freq</code> <code>int</code> <p>controller loop frequency</p> required <code>motor_type</code> <code>str</code> <p>type of motor being controlled, one of {position, velocity, effort}</p> required <code>control_limits</code> <code>Dict[str, Tuple[Array[float], Array[float]]]</code> <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p> required <code>dof_idx</code> <code>Array[int]</code> <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p> required <code>command_input_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p> <code>'default'</code> <code>command_output_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p> <code>'default'</code> <code>use_delta_commands</code> <code>bool</code> <p>whether inputted commands should be interpreted as delta or absolute values</p> <code>False</code> <code>compute_delta_in_quat_space</code> <code>None or List[(rx_idx, ry_idx, rz_idx), ...]</code> <p>if specified, groups of joints that need to be processed in quaternion space to avoid gimbal lock issues normally faced by 3 DOF rotation joints. Each group needs to consist of three idxes corresponding to the indices in the input space. This is only used in the delta_commands mode.</p> <code>None</code> Source code in <code>omnigibson/controllers/joint_controller.py</code> <pre><code>def __init__(\nself,\ncontrol_freq,\nmotor_type,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\nuse_delta_commands=False,\ncompute_delta_in_quat_space=None,\n):\n\"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        motor_type (str): type of motor being controlled, one of {position, velocity, effort}\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        use_delta_commands (bool): whether inputted commands should be interpreted as delta or absolute values\n        compute_delta_in_quat_space (None or List[(rx_idx, ry_idx, rz_idx), ...]): if specified, groups of\n            joints that need to be processed in quaternion space to avoid gimbal lock issues normally faced by\n            3 DOF rotation joints. Each group needs to consist of three idxes corresponding to the indices in\n            the input space. This is only used in the delta_commands mode.\n    \"\"\"\n# Store arguments\nassert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\nself._motor_type = motor_type.lower()\nself._use_delta_commands = use_delta_commands\nself._compute_delta_in_quat_space = [] if compute_delta_in_quat_space is None else compute_delta_in_quat_space\n# When in delta mode, it doesn't make sense to infer output range using the joint limits (since that's an\n# absolute range and our values are relative). So reject the default mode option in that case.\nassert not (\nself._use_delta_commands and command_output_limits == \"default\"\n), \"Cannot use 'default' command output limits in delta commands mode of JointController. Try None instead.\"\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\n</code></pre>"},{"location":"reference/controllers/multi_finger_gripper_controller.html","title":"multi_finger_gripper_controller","text":""},{"location":"reference/controllers/multi_finger_gripper_controller.html#controllers.multi_finger_gripper_controller.MultiFingerGripperController","title":"<code>MultiFingerGripperController</code>","text":"<p>         Bases: <code>GripperController</code></p> <p>Controller class for multi finger gripper control. This either interprets an input as a binary command (open / close), continuous command (open / close with scaled velocities), or per-joint continuous command</p> Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits 2a. Convert command into gripper joint control signals 2b. Clips the resulting control by the motor limits</li> </ol> Source code in <code>omnigibson/controllers/multi_finger_gripper_controller.py</code> <pre><code>class MultiFingerGripperController(GripperController):\n\"\"\"\n    Controller class for multi finger gripper control. This either interprets an input as a binary\n    command (open / close), continuous command (open / close with scaled velocities), or per-joint continuous command\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2a. Convert command into gripper joint control signals\n        2b. Clips the resulting control by the motor limits\n    \"\"\"\ndef __init__(\nself,\ncontrol_freq,\nmotor_type,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\ninverted=False,\nmode=\"binary\",\nlimit_tolerance=0.001,\n):\n\"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            motor_type (str): type of motor being controlled, one of {position, velocity, effort}\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            inverted (bool): whether or not the command direction (grasp is negative) and the control direction are\n                inverted, e.g. to grasp you need to move the joint in the positive direction.\n            mode (str): mode for this controller. Valid options are:\n                \"binary\": 1D command, if preprocessed value &gt; 0 is interpreted as an max open\n                    (send max pos / vel / tor signal), otherwise send max close control signals\n                \"smooth\": 1D command, sends symmetric signal to both finger joints equal to the preprocessed commands\n                \"independent\": 2D command, sends independent signals to each finger joint equal to the preprocessed command\n            limit_tolerance (float): sets the tolerance from the joint limit ends, below which controls will be zeroed\n                out if the control is using velocity or torque control\n        \"\"\"\n# Store arguments\nassert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\nself._motor_type = motor_type.lower()\nassert_valid_key(key=mode, valid_keys=VALID_MODES, name=\"mode for multi finger gripper\")\nself._inverted = inverted\nself._mode = mode\nself._limit_tolerance = limit_tolerance\n# Create other args to be filled in at runtime\nself._is_grasping = IsGraspingState.FALSE\n# If we're using binary signal, we override the command output limits\nif mode == \"binary\":\ncommand_output_limits = (-1.0, 1.0)\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\ndef reset(self):\n# reset grasping state\nself._is_grasping = IsGraspingState.FALSE\ndef _preprocess_command(self, command):\n# We extend this method to make sure command is always 2D\nif self._mode != \"independent\":\ncommand = (\nnp.array([command] * self.command_dim)\nif type(command) in {int, float}\nelse np.array([command[0]] * self.command_dim)\n)\n# Flip the command if the direction is inverted.\nif self._inverted:\ncommand = self._command_input_limits[1] - (command - self._command_input_limits[0])\n# Return from super method\nreturn super()._preprocess_command(command=command)\ndef _command_to_control(self, command, control_dict):\n\"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) gripper\n        joint control signal\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals.\n                This should always be 2D command for each gripper joint\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n                    joint_position: Array of current joint positions\n                    joint_velocity: Array of current joint velocities\n        Returns:\n            Array[float]: outputted (non-clipped!) control signal to deploy\n        \"\"\"\njoint_pos = control_dict[\"joint_position\"][self.dof_idx]\n# Choose what to do based on control mode\nif self._mode == \"binary\":\n# Use max control signal\nu = (\nself._control_limits[ControlType.get_type(self._motor_type)][1][self.dof_idx]\nif command[0] &gt;= 0.0\nelse self._control_limits[ControlType.get_type(self._motor_type)][0][self.dof_idx]\n)\nelse:\n# Use continuous signal\nu = command\n# If we're near the joint limits and we're using velocity / torque control, we zero out the action\nif self._motor_type in {\"velocity\", \"torque\"}:\nviolate_upper_limit = (\njoint_pos &gt; self._control_limits[ControlType.POSITION][1][self.dof_idx] - self._limit_tolerance\n)\nviolate_lower_limit = (\njoint_pos &lt; self._control_limits[ControlType.POSITION][0][self.dof_idx] + self._limit_tolerance\n)\nviolation = np.logical_or(violate_upper_limit * (u &gt; 0), violate_lower_limit * (u &lt; 0))\nu *= ~violation\n# Update whether we're grasping or not\nself._update_grasping_state(control_dict=control_dict)\n# Return control\nreturn u\ndef _update_grasping_state(self, control_dict):\n\"\"\"\n        Updates internal inferred grasping state of the gripper being controlled by this gripper controller\n        Args:\n            control_dict (dict): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n                    joint_position: Array of current joint positions\n                    joint_velocity: Array of current joint velocities\n        \"\"\"\n# Calculate grasping state based on mode of this controller\n# Independent mode of MultiFingerGripperController does not have any good heuristics to determine is_grasping\nif self._mode == \"independent\":\nis_grasping = IsGraspingState.UNKNOWN\n# No control has been issued before -- we assume not grasping\nelif self._control is None:\nis_grasping = IsGraspingState.FALSE\nelse:\nassert np.all(\nself._control == self._control[0]\n), f\"MultiFingerGripperController has different values in the command for non-independent mode: {self._control}\"\nassert m.POS_TOLERANCE &gt; self._limit_tolerance, (\n\"Joint position tolerance for is_grasping heuristics checking is smaller than or equal to the \"\n\"gripper controller's tolerance of zero-ing out velocities, which makes the heuristics invalid.\"\n)\nfinger_pos = control_dict[\"joint_position\"][self.dof_idx]\n# For joint position control, if the desired positions are the same as the current positions, is_grasping unknown\nif (\nself._motor_type == \"position\"\nand np.mean(np.abs(finger_pos - self._control)) &lt; m.POS_TOLERANCE\n):\nis_grasping = IsGraspingState.UNKNOWN\n# For joint velocity / torque control, if the desired velocities / torques are zeros, is_grasping unknown\nelif (\nself._motor_type in {\"velocity\", \"torque\"}\nand np.mean(np.abs(self._control)) &lt; m.VEL_TOLERANCE\n):\nis_grasping = IsGraspingState.UNKNOWN\n# Otherwise, the last control signal intends to \"move\" the gripper\nelse:\nfinger_vel = control_dict[\"joint_velocity\"][self.dof_idx]\nmin_pos = self._control_limits[ControlType.POSITION][0][self.dof_idx]\nmax_pos = self._control_limits[ControlType.POSITION][1][self.dof_idx]\n# Make sure we don't have any invalid values (i.e.: fingers should be within the limits)\nassert np.all(\n(min_pos &lt;= finger_pos) * (finger_pos &lt;= max_pos)\n), f\"Got invalid finger joint positions when checking for grasp! \" \\\n                   f\"min: {min_pos}, max: {max_pos}, finger_pos: {finger_pos}\"\n# Check distance from both ends of the joint limits\ndist_from_lower_limit = finger_pos - min_pos\ndist_from_upper_limit = max_pos - finger_pos\n# If the joint positions are not near the joint limits with some tolerance (m.POS_TOLERANCE)\nvalid_grasp_pos = (\nnp.mean(dist_from_lower_limit) &gt; m.POS_TOLERANCE\nand np.mean(dist_from_upper_limit) &gt; m.POS_TOLERANCE\n)\n# And the joint velocities are close to zero with some tolerance (m.VEL_TOLERANCE)\nvalid_grasp_vel = np.all(np.abs(finger_vel) &lt; m.VEL_TOLERANCE)\n# Then the gripper is grasping something, which stops the gripper from reaching its desired state\nis_grasping = (\nIsGraspingState.TRUE if valid_grasp_pos and valid_grasp_vel else IsGraspingState.FALSE\n)\n# Store calculated state\nself._is_grasping = is_grasping\ndef is_grasping(self):\n# Return cached value\nreturn self._is_grasping\n@property\ndef control_type(self):\nreturn ControlType.get_type(type_str=self._motor_type)\n@property\ndef command_dim(self):\nreturn len(self.dof_idx) if self._mode == \"independent\" else 1\n</code></pre>"},{"location":"reference/controllers/multi_finger_gripper_controller.html#controllers.multi_finger_gripper_controller.MultiFingerGripperController.__init__","title":"<code>__init__(control_freq, motor_type, control_limits, dof_idx, command_input_limits='default', command_output_limits='default', inverted=False, mode='binary', limit_tolerance=0.001)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>control_freq</code> <code>int</code> <p>controller loop frequency</p> required <code>motor_type</code> <code>str</code> <p>type of motor being controlled, one of {position, velocity, effort}</p> required <code>control_limits</code> <code>Dict[str, Tuple[Array[float], Array[float]]]</code> <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p> required <code>dof_idx</code> <code>Array[int]</code> <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p> required <code>command_input_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p> <code>'default'</code> <code>command_output_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p> <code>'default'</code> <code>inverted</code> <code>bool</code> <p>whether or not the command direction (grasp is negative) and the control direction are inverted, e.g. to grasp you need to move the joint in the positive direction.</p> <code>False</code> <code>mode</code> <code>str</code> <p>mode for this controller. Valid options are:</p> <p>\"binary\": 1D command, if preprocessed value &gt; 0 is interpreted as an max open     (send max pos / vel / tor signal), otherwise send max close control signals \"smooth\": 1D command, sends symmetric signal to both finger joints equal to the preprocessed commands \"independent\": 2D command, sends independent signals to each finger joint equal to the preprocessed command</p> <code>'binary'</code> <code>limit_tolerance</code> <code>float</code> <p>sets the tolerance from the joint limit ends, below which controls will be zeroed out if the control is using velocity or torque control</p> <code>0.001</code> Source code in <code>omnigibson/controllers/multi_finger_gripper_controller.py</code> <pre><code>def __init__(\nself,\ncontrol_freq,\nmotor_type,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\ninverted=False,\nmode=\"binary\",\nlimit_tolerance=0.001,\n):\n\"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        motor_type (str): type of motor being controlled, one of {position, velocity, effort}\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        inverted (bool): whether or not the command direction (grasp is negative) and the control direction are\n            inverted, e.g. to grasp you need to move the joint in the positive direction.\n        mode (str): mode for this controller. Valid options are:\n            \"binary\": 1D command, if preprocessed value &gt; 0 is interpreted as an max open\n                (send max pos / vel / tor signal), otherwise send max close control signals\n            \"smooth\": 1D command, sends symmetric signal to both finger joints equal to the preprocessed commands\n            \"independent\": 2D command, sends independent signals to each finger joint equal to the preprocessed command\n        limit_tolerance (float): sets the tolerance from the joint limit ends, below which controls will be zeroed\n            out if the control is using velocity or torque control\n    \"\"\"\n# Store arguments\nassert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\nself._motor_type = motor_type.lower()\nassert_valid_key(key=mode, valid_keys=VALID_MODES, name=\"mode for multi finger gripper\")\nself._inverted = inverted\nself._mode = mode\nself._limit_tolerance = limit_tolerance\n# Create other args to be filled in at runtime\nself._is_grasping = IsGraspingState.FALSE\n# If we're using binary signal, we override the command output limits\nif mode == \"binary\":\ncommand_output_limits = (-1.0, 1.0)\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\n</code></pre>"},{"location":"reference/controllers/null_joint_controller.html","title":"null_joint_controller","text":""},{"location":"reference/controllers/null_joint_controller.html#controllers.null_joint_controller.NullJointController","title":"<code>NullJointController</code>","text":"<p>         Bases: <code>JointController</code></p> <p>Dummy Controller class for a null-type of joint control (i.e.: no control or constant pass-through control). This class has a zero-size command space, and returns either an empty array for control if dof_idx is None else constant values as specified by @default_command (if not specified, uses zeros)</p> Source code in <code>omnigibson/controllers/null_joint_controller.py</code> <pre><code>class NullJointController(JointController):\n\"\"\"\n    Dummy Controller class for a null-type of joint control (i.e.: no control or constant pass-through control).\n    This class has a zero-size command space, and returns either an empty array for control if dof_idx is None\n    else constant values as specified by @default_command (if not specified, uses zeros)\n    \"\"\"\ndef __init__(\nself,\ncontrol_freq,\nmotor_type,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\ndefault_command=None,\n):\n\"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            default_command (None or n-array): if specified, should be the same length as @dof_idx, specifying\n                the default control for this controller to output\n        \"\"\"\n# Store values\nself._default_command = np.zeros(len(dof_idx)) if default_command is None else np.array(default_command)\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\nmotor_type=motor_type,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\ndef _preprocess_command(self, command):\n# Set the command to be internal stored default value\nreturn np.array(self._default_command)\ndef update_default_command(self, command):\n\"\"\"\n        Updates the internal default command value.\n        Args:\n            command (n-array): New default command values to set for this controller.\n                Should be of dimension @command_dim\n        \"\"\"\nassert len(command) == self.command_dim, \\\n            f\"Default control must be length: {self.command_dim}, got length: {len(command)}\"\nself._default_command = np.array(command)\n</code></pre>"},{"location":"reference/controllers/null_joint_controller.html#controllers.null_joint_controller.NullJointController.__init__","title":"<code>__init__(control_freq, motor_type, control_limits, dof_idx, command_input_limits='default', command_output_limits='default', default_command=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>control_freq</code> <code>int</code> <p>controller loop frequency</p> required <code>control_limits</code> <code>Dict[str, Tuple[Array[float], Array[float]]]</code> <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p> required <code>dof_idx</code> <code>Array[int]</code> <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p> required <code>command_input_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p> <code>'default'</code> <code>command_output_limits</code> <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code> <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p> <code>'default'</code> <code>default_command</code> <code>None or n-array</code> <p>if specified, should be the same length as @dof_idx, specifying the default control for this controller to output</p> <code>None</code> Source code in <code>omnigibson/controllers/null_joint_controller.py</code> <pre><code>def __init__(\nself,\ncontrol_freq,\nmotor_type,\ncontrol_limits,\ndof_idx,\ncommand_input_limits=\"default\",\ncommand_output_limits=\"default\",\ndefault_command=None,\n):\n\"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        default_command (None or n-array): if specified, should be the same length as @dof_idx, specifying\n            the default control for this controller to output\n    \"\"\"\n# Store values\nself._default_command = np.zeros(len(dof_idx)) if default_command is None else np.array(default_command)\n# Run super init\nsuper().__init__(\ncontrol_freq=control_freq,\nmotor_type=motor_type,\ncontrol_limits=control_limits,\ndof_idx=dof_idx,\ncommand_input_limits=command_input_limits,\ncommand_output_limits=command_output_limits,\n)\n</code></pre>"},{"location":"reference/controllers/null_joint_controller.html#controllers.null_joint_controller.NullJointController.update_default_command","title":"<code>update_default_command(command)</code>","text":"<p>Updates the internal default command value.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>n-array</code> <p>New default command values to set for this controller. Should be of dimension @command_dim</p> required Source code in <code>omnigibson/controllers/null_joint_controller.py</code> <pre><code>def update_default_command(self, command):\n\"\"\"\n    Updates the internal default command value.\n    Args:\n        command (n-array): New default command values to set for this controller.\n            Should be of dimension @command_dim\n    \"\"\"\nassert len(command) == self.command_dim, \\\n        f\"Default control must be length: {self.command_dim}, got length: {len(command)}\"\nself._default_command = np.array(command)\n</code></pre>"},{"location":"reference/envs/index.html","title":"envs","text":""},{"location":"reference/envs/env_base.html","title":"env_base","text":""},{"location":"reference/envs/env_base.html#envs.env_base.Environment","title":"<code>Environment</code>","text":"<p>         Bases: <code>gym.Env</code>, <code>GymObservable</code>, <code>Recreatable</code></p> <p>Core environment class that handles loading scene, robot(s), and task, following OpenAI Gym interface.</p> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>class Environment(gym.Env, GymObservable, Recreatable):\n\"\"\"\n    Core environment class that handles loading scene, robot(s), and task, following OpenAI Gym interface.\n    \"\"\"\ndef __init__(\nself,\nconfigs,\naction_timestep=1 / 60.0,\nphysics_timestep=1 / 60.0,\ndevice=None,\nautomatic_reset=False,\nflatten_action_space=False,\nflatten_obs_space=False,\n):\n\"\"\"\n        Args:\n            configs (str or dict or list of str or dict): config_file path(s) or raw config dictionaries.\n                If multiple configs are specified, they will be merged sequentially in the order specified.\n                This allows procedural generation of a \"full\" config from small sub-configs.\n            action_timestep (float): environment executes action per action_timestep second\n            physics_timestep: physics timestep for physx\n            device (None or str): specifies the device to be used if running on the gpu with torch backend\n            automatic_reset (bool): whether to automatic reset after an episode finishes\n            flatten_action_space (bool): whether to flatten the action space as a sinle 1D-array\n            flatten_obs_space (bool): whether the observation space should be flattened when generated\n        \"\"\"\n# Call super first\nsuper().__init__()\n# Store settings and other initialized values\nself._automatic_reset = automatic_reset\nself._flatten_action_space = flatten_action_space\nself._flatten_obs_space = flatten_obs_space\nself.action_timestep = action_timestep\n# Initialize other placeholders that will be filled in later\nself._initial_pos_z_offset = None                   # how high to offset object placement to account for one action step of dropping\nself._task = None\nself._loaded = None\nself._current_episode = 0\n# Variables reset at the beginning of each episode\nself._current_step = 0\n# Convert config file(s) into a single parsed dict\nconfigs = configs if isinstance(configs, list) or isinstance(configs, tuple) else [configs]\n# Initial default config\nself.config = self.default_config\n# Merge in specified configs\nfor config in configs:\nmerge_nested_dicts(base_dict=self.config, extra_dict=parse_config(config), inplace=True)\n# Set the simulator settings\nog.sim.set_simulation_dt(physics_dt=physics_timestep, rendering_dt=action_timestep)\nog.sim.viewer_width = self.render_config[\"viewer_width\"]\nog.sim.viewer_height = self.render_config[\"viewer_height\"]\nog.sim.device = device\n# Load this environment\nself.load()\ndef reload(self, configs, overwrite_old=True):\n\"\"\"\n        Reload using another set of config file(s).\n        This allows one to change the configuration and hot-reload the environment on the fly.\n        Args:\n            configs (dict or str or list of dict or list of str): config_file dict(s) or path(s). \n                If multiple configs are specified, they will be merged sequentially in the order specified. \n                This allows procedural generation of a \"full\" config from small sub-configs.\n            overwrite_old (bool): If True, will overwrite the internal self.config with @configs. Otherwise, will\n                merge in the new config(s) into the pre-existing one. Setting this to False allows for minor\n                modifications to be made without having to specify entire configs during each reload.\n        \"\"\"\n# Convert config file(s) into a single parsed dict\nconfigs = [configs] if isinstance(configs, dict) or isinstance(configs, str) else configs\n# Initial default config\nnew_config = self.default_config\n# Merge in specified configs\nfor config in configs:\nmerge_nested_dicts(base_dict=new_config, extra_dict=parse_config(config), inplace=True)\n# Either merge in or overwrite the old config\nif overwrite_old:\nself.config = new_config\nelse:\nmerge_nested_dicts(base_dict=self.config, extra_dict=new_config, inplace=True)\n# Load this environment again\nself.load()\ndef reload_model(self, scene_model):\n\"\"\"\n        Reload another scene model.\n        This allows one to change the scene on the fly.\n        Args:\n            scene_model (str): new scene model to load (eg.: Rs_int)\n        \"\"\"\nself.scene_config[\"model\"] = scene_model\nself.load()\ndef _load_variables(self):\n\"\"\"\n        Load variables from config\n        \"\"\"\n# Store additional variables after config has been loaded fully\nself._initial_pos_z_offset = self.env_config[\"initial_pos_z_offset\"]\n# Reset bookkeeping variables\nself._reset_variables()\nself._current_episode = 0           # Manually set this to 0 since resetting actually increments this\n# - Potentially overwrite the USD entry for the scene if none is specified and we're online sampling -\n# Make sure the requested scene is valid\nscene_type = self.scene_config[\"type\"]\nassert_valid_key(key=scene_type, valid_keys=REGISTERED_SCENES, name=\"scene type\")\n# If we're using a BehaviorTask, we may load a pre-cached scene configuration\nif self.task_config[\"type\"] == \"BehaviorTask\":\nscene_instance, scene_file = self.scene_config[\"scene_instance\"], self.scene_config[\"scene_file\"]\nif scene_file is None and scene_instance is None and not self.task_config[\"online_object_sampling\"]:\nscene_instance = \"{}_task_{}_{}_{}_fixed_furniture_template\".format(\nself.scene_config[\"scene_model\"],\nself.task_config[\"activity_name\"],\nself.task_config[\"activity_definition_id\"],\nself.task_config[\"activity_instance_id\"],\n)\n# Update the value in the scene config\nself.scene_config[\"scene_instance\"] = scene_instance\n# - Additionally run some sanity checks on these values -\n# Check to make sure our z offset is valid -- check that the distance travelled over 1 action timestep is\n# less than the offset we set (dist = 0.5 * gravity * (t^2))\ndrop_distance = 0.5 * 9.8 * (self.action_timestep ** 2)\nassert drop_distance &lt; self._initial_pos_z_offset, \"initial_pos_z_offset is too small for collision checking\"\ndef _load_task(self):\n\"\"\"\n        Load task\n        \"\"\"\n# Sanity check task to make sure it's valid\ntask_type = self.task_config[\"type\"]\nassert_valid_key(key=task_type, valid_keys=REGISTERED_TASKS, name=\"task type\")\n# Grab the kwargs relevant for the specific task and create the task\nself._task = create_class_from_registry_and_config(\ncls_name=self.task_config[\"type\"],\ncls_registry=REGISTERED_TASKS,\ncfg=self.task_config,\ncls_type_descriptor=\"task\",\n)\nassert og.sim.is_stopped(), \"Simulator must be stopped before loading tasks!\"\n# Load task. Should load additional task-relevant objects and configure the scene into its default initial state\nself._task.load(env=self)\nassert og.sim.is_stopped(), \"Simulator must be stopped after loading tasks!\"\ndef _load_scene(self):\n\"\"\"\n        Load the scene and robot specified in the config file.\n        \"\"\"\nassert og.sim.is_stopped(), \"Simulator must be stopped before loading scene!\"\n# Create the scene from our scene config\nscene = create_class_from_registry_and_config(\ncls_name=self.scene_config[\"type\"],\ncls_registry=REGISTERED_SCENES,\ncfg=self.scene_config,\ncls_type_descriptor=\"scene\",\n)\nog.sim.import_scene(scene)\nassert og.sim.is_stopped(), \"Simulator must be stopped after loading scene!\"\ndef _load_robots(self):\n\"\"\"\n        Load robots into the scene\n        \"\"\"\n# Only actually load robots if no robot has been imported from the scene loading directly yet\nif len(self.scene.robots) == 0:\nassert og.sim.is_stopped(), \"Simulator must be stopped before loading robots!\"\n# Iterate over all robots to generate in the robot config\nfor i, robot_config in enumerate(self.robots_config):\n# Add a name for the robot if necessary\nif \"name\" not in robot_config:\nrobot_config[\"name\"] = f\"robot{i}\"\nposition, orientation = robot_config.pop(\"position\", None), robot_config.pop(\"orientation\", None)\n# Make sure robot exists, grab its corresponding kwargs, and create / import the robot\nrobot = create_class_from_registry_and_config(\ncls_name=robot_config[\"type\"],\ncls_registry=REGISTERED_ROBOTS,\ncfg=robot_config,\ncls_type_descriptor=\"robot\",\n)\n# Import the robot into the simulator\nog.sim.import_object(robot)\nrobot.set_position_orientation(position=position, orientation=orientation)\n# Auto-initialize all robots\nog.sim.play()\nself.scene.reset()\nself.scene.update_initial_state()\nog.sim.stop()\nassert og.sim.is_stopped(), \"Simulator must be stopped after loading robots!\"\ndef _load_objects(self):\n\"\"\"\n        Load any additional custom objects into the scene\n        \"\"\"\nassert og.sim.is_stopped(), \"Simulator must be stopped before loading objects!\"\nfor i, obj_config in enumerate(self.objects_config):\n# Add a name for the object if necessary\nif \"name\" not in obj_config:\nobj_config[\"name\"] = f\"obj{i}\"\n# Pop the desired position and orientation\nposition, orientation = obj_config.pop(\"position\", None), obj_config.pop(\"orientation\", None)\n# Make sure robot exists, grab its corresponding kwargs, and create / import the robot\nobj = create_class_from_registry_and_config(\ncls_name=obj_config[\"type\"],\ncls_registry=REGISTERED_OBJECTS,\ncfg=obj_config,\ncls_type_descriptor=\"object\",\n)\n# Import the robot into the simulator and set the pose\nog.sim.import_object(obj)\nobj.set_position_orientation(position=position, orientation=orientation)\n# Auto-initialize all objects\nog.sim.play()\nself.scene.reset()\nself.scene.update_initial_state()\nog.sim.stop()\nassert og.sim.is_stopped(), \"Simulator must be stopped after loading objects!\"\ndef _load_observation_space(self):\n# Grab robot(s) and task obs spaces\nobs_space = dict()\nfor robot in self.robots:\n# Load the observation space for the robot\nobs_space[robot.name] = robot.load_observation_space()\n# Also load the task obs space\nobs_space[\"task\"] = self._task.load_observation_space()\nreturn obs_space\ndef load_observation_space(self):\n# Call super first\nobs_space = super().load_observation_space()\n# If we want to flatten it, modify the observation space by recursively searching through all\nif self._flatten_obs_space:\nself.observation_space = gym.spaces.Dict(recursively_generate_flat_dict(dic=obs_space))\nreturn self.observation_space\ndef _load_action_space(self):\n\"\"\"\n        Load action space for each robot\n        \"\"\"\naction_space = gym.spaces.Dict({robot.name: robot.action_space for robot in self.robots})\n# Convert into flattened 1D Box space if requested\nif self._flatten_action_space:\nlows = []\nhighs = []\nfor space in action_space.values():\nassert isinstance(space, gym.spaces.Box), \\\n                    \"Can only flatten action space where all individual spaces are gym.space.Box instances!\"\nassert len(space.shape) == 1, \\\n                    \"Can only flatten action space where all individual spaces are 1D instances!\"\nlows.append(space.low)\nhighs.append(space.high)\naction_space = gym.spaces.Box(np.concatenate(lows), np.concatenate(highs), dtype=np.float32)\n# Store action space\nself.action_space = action_space\ndef load(self):\n\"\"\"\n        Load the scene and robot specified in the config file.\n        \"\"\"\n# This environment is not loaded\nself._loaded = False\n# Load config variables\nself._load_variables()\n# Load the scene, robots, and task\nself._load_scene()\nself._load_robots()\nself._load_objects()\nself._load_task()\nog.sim.play()\nself.reset()\n# Load the obs / action spaces\nself.load_observation_space()\nself._load_action_space()\n# Denote that the scene is loaded\nself._loaded = True\ndef close(self):\n\"\"\"\n        Clean up the environment and shut down the simulation.\n        \"\"\"\nog.shutdown()\ndef get_obs(self):\n\"\"\"\n        Get the current environment observation.\n        Returns:\n            dict: Keyword-mapped observations, which are possibly nested\n        \"\"\"\nobs = dict()\n# Grab all observations from each robot\nfor robot in self.robots:\nobs[robot.name] = robot.get_obs()\n# Add task observations\nobs[\"task\"] = self._task.get_obs(env=self)\n# Possibly flatten obs if requested\nif self._flatten_obs_space:\nobs = recursively_generate_flat_dict(dic=obs)\nreturn obs\ndef _populate_info(self, info):\n\"\"\"\n        Populate info dictionary with any useful information.\n        Args:\n            info (dict): Information dictionary to populate\n        Returns:\n            dict: Information dictionary with added info\n        \"\"\"\ninfo[\"episode_length\"] = self._current_step\ndef step(self, action):\n\"\"\"\n        Apply robot's action and return the next state, reward, done and info,\n        following OpenAI Gym's convention\n        Args:\n            action (gym.spaces.Dict or dict or np.array): robot actions. If a dict is specified, each entry should\n                map robot name to corresponding action. If a np.array, it should be the flattened, concatenated set\n                of actions\n        Returns:\n            4-tuple:\n                - dict: state, i.e. next observation\n                - float: reward, i.e. reward at this current timestep\n                - bool: done, i.e. whether this episode is terminated\n                - dict: info, i.e. dictionary with any useful information\n        \"\"\"\n# If the action is not a dictionary, convert into a dictionary\nif not isinstance(action, dict) and not isinstance(action, gym.spaces.Dict):\naction_dict = dict()\nidx = 0\nfor robot in self.robots:\naction_dim = robot.action_dim\naction_dict[robot.name] = action[idx: idx + action_dim]\nidx += action_dim\nelse:\n# Our inputted action is the action dictionary\naction_dict = action\n# Iterate over all robots and apply actions\nfor robot in self.robots:\nrobot.apply_action(action_dict[robot.name])\n# Run simulation step\nog.sim.step()\n# Grab observations\nobs = self.get_obs()\n# Grab reward, done, and info, and populate with internal info\nreward, done, info = self.task.step(self, action)\nself._populate_info(info)\nif done and self._automatic_reset:\n# Add lost observation to our information dict, and reset\ninfo[\"last_observation\"] = obs\nobs = self.reset()\n# Increment step\nself._current_step += 1\nreturn obs, reward, done, info\ndef _reset_variables(self):\n\"\"\"\n        Reset bookkeeping variables for the next new episode.\n        \"\"\"\nself._current_episode += 1\nself._current_step = 0\n# TODO: Match super class signature?\ndef reset(self):\n\"\"\"\n        Reset episode.\n        \"\"\"\n# Reset the task\nself.task.reset(self)\n# Reset internal variables\nself._reset_variables()\n# Run a single simulator step to make sure we can grab updated observations\nog.sim.step()\n# Grab and return observations\nobs = self.get_obs()\nif self.observation_space is not None and not self.observation_space.contains(obs):\n# Flatten obs, and print out all keys and values\nlog.error(\"OBSERVATION SPACE:\")\nfor key, value in recursively_generate_flat_dict(dic=self.observation_space):\nlog.error((\"obs_space\", key, value.dtype, value.shape))\nlog.error(\"ACTUAL OBSERVATIONS:\")\nfor key, value in recursively_generate_flat_dict(dic=obs):\nlog.error((\"obs\", key, value.dtype, value.shape))\nraise ValueError(\"Observation space does not match returned observations!\")\nreturn obs\n@property\ndef episode_steps(self):\n\"\"\"\n        Returns:\n            int: Current number of steps in episode\n        \"\"\"\nreturn self._current_step\n@property\ndef initial_pos_z_offset(self):\n\"\"\"\n        Returns:\n            float: how high to offset object placement to test valid pose &amp; account for one action step of dropping\n        \"\"\"\nreturn self._initial_pos_z_offset\n@property\ndef task(self):\n\"\"\"\n        Returns:\n            BaseTask: Active task instance\n        \"\"\"\nreturn self._task\n@property\ndef scene(self):\n\"\"\"\n        Returns:\n            Scene: Active scene in this environment\n        \"\"\"\nreturn og.sim.scene\n@property\ndef robots(self):\n\"\"\"\n        Returns:\n            list of BaseRobot: Robots in the current scene\n        \"\"\"\nreturn self.scene.robots\n@property\ndef env_config(self):\n\"\"\"\n        Returns:\n            dict: Environment-specific configuration kwargs\n        \"\"\"\nreturn self.config[\"env\"]\n@property\ndef render_config(self):\n\"\"\"\n        Returns:\n            dict: Render-specific configuration kwargs\n        \"\"\"\nreturn self.config[\"render\"]\n@property\ndef scene_config(self):\n\"\"\"\n        Returns:\n            dict: Scene-specific configuration kwargs\n        \"\"\"\nreturn self.config[\"scene\"]\n@property\ndef robots_config(self):\n\"\"\"\n        Returns:\n            dict: Robot-specific configuration kwargs\n        \"\"\"\nreturn self.config[\"robots\"]\n@property\ndef objects_config(self):\n\"\"\"\n        Returns:\n            dict: Object-specific configuration kwargs\n        \"\"\"\nreturn self.config[\"objects\"]\n@property\ndef task_config(self):\n\"\"\"\n        Returns:\n            dict: Task-specific configuration kwargs\n        \"\"\"\nreturn self.config[\"task\"]\n@property\ndef default_config(self):\n\"\"\"\n        Returns:\n            dict: Default configuration for this environment. May not be fully specified (i.e.: still requires @config\n                to be specified during environment creation)\n        \"\"\"\nreturn {\n# Environment kwargs\n\"env\": {\n\"initial_pos_z_offset\": 0.1,\n},\n# Rendering kwargs\n\"render\": {\n\"viewer_width\": 1280,\n\"viewer_height\": 720,\n},\n# Scene kwargs\n\"scene\": {\n# Traversibility map kwargs\n\"waypoint_resolution\": 0.2,\n\"num_waypoints\": 10,\n\"build_graph\": True,\n\"trav_map_resolution\": 0.1,\n\"trav_map_erosion\": 2,\n\"trav_map_with_objects\": True,\n\"scene_instance\": None,\n\"scene_file\": None,\n},\n# Robot kwargs\n\"robots\": [],   # no robots by default\n# Object kwargs\n\"objects\": [],  # no objects by default\n# Task kwargs\n\"task\": {\n\"type\": \"DummyTask\",\n# If we're using a BehaviorTask\n\"activity_definition_id\": 0,\n\"activity_instance_id\": 0,\n}\n}\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.default_config","title":"<code>default_config</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Default configuration for this environment. May not be fully specified (i.e.: still requires @config to be specified during environment creation)</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.env_config","title":"<code>env_config</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Environment-specific configuration kwargs</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.episode_steps","title":"<code>episode_steps</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Current number of steps in episode</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.initial_pos_z_offset","title":"<code>initial_pos_z_offset</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>how high to offset object placement to test valid pose &amp; account for one action step of dropping</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.objects_config","title":"<code>objects_config</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Object-specific configuration kwargs</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.render_config","title":"<code>render_config</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Render-specific configuration kwargs</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.robots","title":"<code>robots</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>list of BaseRobot: Robots in the current scene</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.robots_config","title":"<code>robots_config</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Robot-specific configuration kwargs</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.scene","title":"<code>scene</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>Scene</code> <p>Active scene in this environment</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.scene_config","title":"<code>scene_config</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Scene-specific configuration kwargs</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.task","title":"<code>task</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>BaseTask</code> <p>Active task instance</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.task_config","title":"<code>task_config</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Task-specific configuration kwargs</p>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.__init__","title":"<code>__init__(configs, action_timestep=1 / 60.0, physics_timestep=1 / 60.0, device=None, automatic_reset=False, flatten_action_space=False, flatten_obs_space=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>configs</code> <code>str or dict or list of str or dict</code> <p>config_file path(s) or raw config dictionaries. If multiple configs are specified, they will be merged sequentially in the order specified. This allows procedural generation of a \"full\" config from small sub-configs.</p> required <code>action_timestep</code> <code>float</code> <p>environment executes action per action_timestep second</p> <code>1 / 60.0</code> <code>physics_timestep</code> <p>physics timestep for physx</p> <code>1 / 60.0</code> <code>device</code> <code>None or str</code> <p>specifies the device to be used if running on the gpu with torch backend</p> <code>None</code> <code>automatic_reset</code> <code>bool</code> <p>whether to automatic reset after an episode finishes</p> <code>False</code> <code>flatten_action_space</code> <code>bool</code> <p>whether to flatten the action space as a sinle 1D-array</p> <code>False</code> <code>flatten_obs_space</code> <code>bool</code> <p>whether the observation space should be flattened when generated</p> <code>False</code> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def __init__(\nself,\nconfigs,\naction_timestep=1 / 60.0,\nphysics_timestep=1 / 60.0,\ndevice=None,\nautomatic_reset=False,\nflatten_action_space=False,\nflatten_obs_space=False,\n):\n\"\"\"\n    Args:\n        configs (str or dict or list of str or dict): config_file path(s) or raw config dictionaries.\n            If multiple configs are specified, they will be merged sequentially in the order specified.\n            This allows procedural generation of a \"full\" config from small sub-configs.\n        action_timestep (float): environment executes action per action_timestep second\n        physics_timestep: physics timestep for physx\n        device (None or str): specifies the device to be used if running on the gpu with torch backend\n        automatic_reset (bool): whether to automatic reset after an episode finishes\n        flatten_action_space (bool): whether to flatten the action space as a sinle 1D-array\n        flatten_obs_space (bool): whether the observation space should be flattened when generated\n    \"\"\"\n# Call super first\nsuper().__init__()\n# Store settings and other initialized values\nself._automatic_reset = automatic_reset\nself._flatten_action_space = flatten_action_space\nself._flatten_obs_space = flatten_obs_space\nself.action_timestep = action_timestep\n# Initialize other placeholders that will be filled in later\nself._initial_pos_z_offset = None                   # how high to offset object placement to account for one action step of dropping\nself._task = None\nself._loaded = None\nself._current_episode = 0\n# Variables reset at the beginning of each episode\nself._current_step = 0\n# Convert config file(s) into a single parsed dict\nconfigs = configs if isinstance(configs, list) or isinstance(configs, tuple) else [configs]\n# Initial default config\nself.config = self.default_config\n# Merge in specified configs\nfor config in configs:\nmerge_nested_dicts(base_dict=self.config, extra_dict=parse_config(config), inplace=True)\n# Set the simulator settings\nog.sim.set_simulation_dt(physics_dt=physics_timestep, rendering_dt=action_timestep)\nog.sim.viewer_width = self.render_config[\"viewer_width\"]\nog.sim.viewer_height = self.render_config[\"viewer_height\"]\nog.sim.device = device\n# Load this environment\nself.load()\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.close","title":"<code>close()</code>","text":"<p>Clean up the environment and shut down the simulation.</p> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def close(self):\n\"\"\"\n    Clean up the environment and shut down the simulation.\n    \"\"\"\nog.shutdown()\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.get_obs","title":"<code>get_obs()</code>","text":"<p>Get the current environment observation.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped observations, which are possibly nested</p> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def get_obs(self):\n\"\"\"\n    Get the current environment observation.\n    Returns:\n        dict: Keyword-mapped observations, which are possibly nested\n    \"\"\"\nobs = dict()\n# Grab all observations from each robot\nfor robot in self.robots:\nobs[robot.name] = robot.get_obs()\n# Add task observations\nobs[\"task\"] = self._task.get_obs(env=self)\n# Possibly flatten obs if requested\nif self._flatten_obs_space:\nobs = recursively_generate_flat_dict(dic=obs)\nreturn obs\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.load","title":"<code>load()</code>","text":"<p>Load the scene and robot specified in the config file.</p> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def load(self):\n\"\"\"\n    Load the scene and robot specified in the config file.\n    \"\"\"\n# This environment is not loaded\nself._loaded = False\n# Load config variables\nself._load_variables()\n# Load the scene, robots, and task\nself._load_scene()\nself._load_robots()\nself._load_objects()\nself._load_task()\nog.sim.play()\nself.reset()\n# Load the obs / action spaces\nself.load_observation_space()\nself._load_action_space()\n# Denote that the scene is loaded\nself._loaded = True\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.reload","title":"<code>reload(configs, overwrite_old=True)</code>","text":"<p>Reload using another set of config file(s). This allows one to change the configuration and hot-reload the environment on the fly.</p> <p>Parameters:</p> Name Type Description Default <code>configs</code> <code>dict or str or list of dict or list of str</code> <p>config_file dict(s) or path(s).  If multiple configs are specified, they will be merged sequentially in the order specified.  This allows procedural generation of a \"full\" config from small sub-configs.</p> required <code>overwrite_old</code> <code>bool</code> <p>If True, will overwrite the internal self.config with @configs. Otherwise, will merge in the new config(s) into the pre-existing one. Setting this to False allows for minor modifications to be made without having to specify entire configs during each reload.</p> <code>True</code> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def reload(self, configs, overwrite_old=True):\n\"\"\"\n    Reload using another set of config file(s).\n    This allows one to change the configuration and hot-reload the environment on the fly.\n    Args:\n        configs (dict or str or list of dict or list of str): config_file dict(s) or path(s). \n            If multiple configs are specified, they will be merged sequentially in the order specified. \n            This allows procedural generation of a \"full\" config from small sub-configs.\n        overwrite_old (bool): If True, will overwrite the internal self.config with @configs. Otherwise, will\n            merge in the new config(s) into the pre-existing one. Setting this to False allows for minor\n            modifications to be made without having to specify entire configs during each reload.\n    \"\"\"\n# Convert config file(s) into a single parsed dict\nconfigs = [configs] if isinstance(configs, dict) or isinstance(configs, str) else configs\n# Initial default config\nnew_config = self.default_config\n# Merge in specified configs\nfor config in configs:\nmerge_nested_dicts(base_dict=new_config, extra_dict=parse_config(config), inplace=True)\n# Either merge in or overwrite the old config\nif overwrite_old:\nself.config = new_config\nelse:\nmerge_nested_dicts(base_dict=self.config, extra_dict=new_config, inplace=True)\n# Load this environment again\nself.load()\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.reload_model","title":"<code>reload_model(scene_model)</code>","text":"<p>Reload another scene model. This allows one to change the scene on the fly.</p> <p>Parameters:</p> Name Type Description Default <code>scene_model</code> <code>str</code> <p>new scene model to load (eg.: Rs_int)</p> required Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def reload_model(self, scene_model):\n\"\"\"\n    Reload another scene model.\n    This allows one to change the scene on the fly.\n    Args:\n        scene_model (str): new scene model to load (eg.: Rs_int)\n    \"\"\"\nself.scene_config[\"model\"] = scene_model\nself.load()\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.reset","title":"<code>reset()</code>","text":"<p>Reset episode.</p> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def reset(self):\n\"\"\"\n    Reset episode.\n    \"\"\"\n# Reset the task\nself.task.reset(self)\n# Reset internal variables\nself._reset_variables()\n# Run a single simulator step to make sure we can grab updated observations\nog.sim.step()\n# Grab and return observations\nobs = self.get_obs()\nif self.observation_space is not None and not self.observation_space.contains(obs):\n# Flatten obs, and print out all keys and values\nlog.error(\"OBSERVATION SPACE:\")\nfor key, value in recursively_generate_flat_dict(dic=self.observation_space):\nlog.error((\"obs_space\", key, value.dtype, value.shape))\nlog.error(\"ACTUAL OBSERVATIONS:\")\nfor key, value in recursively_generate_flat_dict(dic=obs):\nlog.error((\"obs\", key, value.dtype, value.shape))\nraise ValueError(\"Observation space does not match returned observations!\")\nreturn obs\n</code></pre>"},{"location":"reference/envs/env_base.html#envs.env_base.Environment.step","title":"<code>step(action)</code>","text":"<p>Apply robot's action and return the next state, reward, done and info, following OpenAI Gym's convention</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>gym.spaces.Dict or dict or np.array</code> <p>robot actions. If a dict is specified, each entry should map robot name to corresponding action. If a np.array, it should be the flattened, concatenated set of actions</p> required <p>Returns:</p> Type Description <p>4-tuple: - dict: state, i.e. next observation - float: reward, i.e. reward at this current timestep - bool: done, i.e. whether this episode is terminated - dict: info, i.e. dictionary with any useful information</p> Source code in <code>omnigibson/envs/env_base.py</code> <pre><code>def step(self, action):\n\"\"\"\n    Apply robot's action and return the next state, reward, done and info,\n    following OpenAI Gym's convention\n    Args:\n        action (gym.spaces.Dict or dict or np.array): robot actions. If a dict is specified, each entry should\n            map robot name to corresponding action. If a np.array, it should be the flattened, concatenated set\n            of actions\n    Returns:\n        4-tuple:\n            - dict: state, i.e. next observation\n            - float: reward, i.e. reward at this current timestep\n            - bool: done, i.e. whether this episode is terminated\n            - dict: info, i.e. dictionary with any useful information\n    \"\"\"\n# If the action is not a dictionary, convert into a dictionary\nif not isinstance(action, dict) and not isinstance(action, gym.spaces.Dict):\naction_dict = dict()\nidx = 0\nfor robot in self.robots:\naction_dim = robot.action_dim\naction_dict[robot.name] = action[idx: idx + action_dim]\nidx += action_dim\nelse:\n# Our inputted action is the action dictionary\naction_dict = action\n# Iterate over all robots and apply actions\nfor robot in self.robots:\nrobot.apply_action(action_dict[robot.name])\n# Run simulation step\nog.sim.step()\n# Grab observations\nobs = self.get_obs()\n# Grab reward, done, and info, and populate with internal info\nreward, done, info = self.task.step(self, action)\nself._populate_info(info)\nif done and self._automatic_reset:\n# Add lost observation to our information dict, and reset\ninfo[\"last_observation\"] = obs\nobs = self.reset()\n# Increment step\nself._current_step += 1\nreturn obs, reward, done, info\n</code></pre>"},{"location":"reference/examples/index.html","title":"examples","text":""},{"location":"reference/examples/environments/index.html","title":"environments","text":""},{"location":"reference/examples/environments/behavior_env_demo.html","title":"behavior_env_demo","text":""},{"location":"reference/examples/environments/behavior_env_demo.html#examples.environments.behavior_env_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Generates a BEHAVIOR Task environment in an online fashion.</p> <p>It steps the environment 100 times with random actions sampled from the action space, using the Gym interface, resetting it 10 times.</p> Source code in <code>omnigibson/examples/environments/behavior_env_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Generates a BEHAVIOR Task environment in an online fashion.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Ask the user whether they want online object sampling or not\nsampling_options = {\n# False: \"Use a pre-sampled cached BEHAVIOR activity scene\", # TODO: Add the file needed in dataset\nTrue: \"Sample the BEHAVIOR activity in an online fashion\",\n}\nshould_sample = choose_from_options(options=sampling_options, name=\"online object sampling\", random_selection=random_selection)\n# Load the pre-selected configuration and set the online_sampling flag\nconfig_filename = os.path.join(og.example_config_path, \"fetch_behavior.yaml\")\ncfg = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\ncfg[\"task\"][\"online_object_sampling\"] = should_sample\n# Load the environment\nenv = og.Environment(configs=cfg)\n# Allow user to move camera more easily\nog.sim.enable_viewer_camera_teleoperation()\n# Run a simple loop and reset periodically\nmax_iterations = 10 if not short_exec else 1\nfor j in range(max_iterations):\nog.log.info(\"Resetting environment\")\nenv.reset()\nfor i in range(100):\naction = env.action_space.sample()\nstate, reward, done, info = env.step(action)\nif done:\nog.log.info(\"Episode finished after {} timesteps\".format(i + 1))\nbreak\n# Always close the environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/environments/navigation_env_demo.html","title":"navigation_env_demo","text":""},{"location":"reference/examples/environments/navigation_env_demo.html#examples.environments.navigation_env_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select a type of scene and loads a turtlebot into it, generating a Point-Goal navigation task within the environment.</p> <p>It steps the environment 100 times with random actions sampled from the action space, using the Gym interface, resetting it 10 times.</p> Source code in <code>omnigibson/examples/environments/navigation_env_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select a type of scene and loads a turtlebot into it, generating a Point-Goal navigation\n    task within the environment.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Load the config\nconfig_filename = os.path.join(og.example_config_path, f\"turtlebot_nav.yaml\")\nconfig = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n# check if we want to quick load or full load the scene\nload_options = {\n\"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n\"Full\": \"Load all interactive objects in the scene\",\n}\nload_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\nif load_mode == \"Quick\":\nconfig[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n# Load the environment\nenv = og.Environment(configs=config)\n# Allow user to move camera more easily\nog.sim.enable_viewer_camera_teleoperation()\n# Run a simple loop and reset periodically\nmax_iterations = 10 if not short_exec else 1\nfor j in range(max_iterations):\nog.log.info(\"Resetting environment\")\nenv.reset()\nfor i in range(100):\naction = env.action_space.sample()\nstate, reward, done, info = env.step(action)\nif done:\nog.log.info(\"Episode finished after {} timesteps\".format(i + 1))\nbreak\n# Always close the environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/learning/index.html","title":"learning","text":""},{"location":"reference/examples/learning/navigation_policy_demo.html","title":"navigation_policy_demo","text":"<p>Example training code using stable-baselines3 PPO for one BEHAVIOR activity. Note that due to the sparsity of the reward, this training code will not converge and achieve task success. This only serves as a starting point that users can further build upon.</p>"},{"location":"reference/examples/object_states/index.html","title":"object_states","text":""},{"location":"reference/examples/object_states/attachment_demo.html","title":"attachment_demo","text":""},{"location":"reference/examples/object_states/attachment_demo.html#examples.object_states.attachment_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of attachment of different parts of a shelf</p> Source code in <code>omnigibson/examples/object_states/attachment_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of attachment of different parts of a shelf\n    \"\"\"\ncfg = yaml.load(open(f\"{og.example_config_path}/default_cfg.yaml\", \"r\"), Loader=yaml.FullLoader)\n# Add objects that we want to create\nobj_cfgs = []\nobj_cfgs.append(dict(\ntype=\"LightObject\",\nname=\"light\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=5000,\nposition=[0, 0, 1.0],\n))\nbase_z = 0.2\ndelta_z = 0.01\nidx = 0\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=\"shelf_back_panel\",\ncategory=\"shelf_back_panel\",\nmodel=\"gjsnrt\",\nposition=[0, 0, 0.01],\nabilities={\"attachable\": {}},\n))\nidx += 1\nxs = [-0.4, 0.4]\nfor i in range(2):\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=f\"shelf_side_{i}\",\ncategory=\"shelf_side\",\nmodel=\"bxfkjj\",\nposition=[xs[i], 0, base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\nys = [-0.93, -0.61, -0.29, 0.03, 0.35, 0.68]\nfor i in range(6):\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=f\"shelf_shelf_{i}\",\ncategory=\"shelf_shelf\",\nmodel=\"ymtnqa\",\nposition=[0, ys[i], base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=\"shelf_top_0\",\ncategory=\"shelf_top\",\nmodel=\"pfiole\",\nposition=[0, 1.0, base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\nobj_cfgs.append(dict(\ntype=\"DatasetObject\",\nname=f\"shelf_baseboard\",\ncategory=\"shelf_baseboard\",\nmodel=\"hlhneo\",\nposition=[0, -0.97884506, base_z + delta_z * idx],\nabilities={\"attachable\": {}},\n))\nidx += 1\ncfg[\"objects\"] = obj_cfgs\nenv = og.Environment(configs=cfg)\n# Set viewer camera pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-1.689292, -2.11718198, 0.93332228]),\norientation=np.array([0.57687967, -0.22995655, -0.29022759, 0.72807814]),\n)\nfor _ in range(10):\nenv.step([])\nshelf_baseboard = og.sim.scene.object_registry(\"name\", \"shelf_baseboard\")\nshelf_baseboard.set_position_orientation([0, -0.979, 0.26], [0, 0, 0, 1])\nshelf_baseboard.keep_still()\nshelf_baseboard.set_linear_velocity([-0.2, 0, 0])\ninput(\"Shelf parts fall to their correct poses and get automatically attached to the back panel.\\n\"\n\"You can try to drag the shelf to hit the floor to break it apart. Press [ENTER] to continue.\\n\")\nfor _ in range(1000):\nog.sim.step()\nog.shutdown()\n</code></pre>"},{"location":"reference/examples/object_states/dicing_demo.html","title":"dicing_demo","text":""},{"location":"reference/examples/object_states/dicing_demo.html#examples.object_states.dicing_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of dicing an apple into apple dices</p> Source code in <code>omnigibson/examples/object_states/dicing_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of dicing an apple into apple dices\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene with table, knife, and apple\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"rjgmmy\",\nscale=0.9,\nposition=[0, 0, 0.58],\n)\napple_cfg = dict(\ntype=\"DatasetObject\",\nname=\"apple\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nscale=1.5,\nposition=[0.085, 0,  0.92],\nabilities={\"diceable\": {}}\n)\nknife_cfg = dict(\ntype=\"DatasetObject\",\nname=\"knife\",\ncategory=\"table_knife\",\nmodel=\"lrdmpf\",\nscale=2.5,\nposition=[0, 0, 10.0],\n)\nlight0_cfg = dict(\ntype=\"LightObject\",\nname=\"light0\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=1e7,\nposition=[1.217, -0.848, 1.388],\n)\nlight1_cfg = dict(\ntype=\"LightObject\",\nname=\"light1\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=1e7,\nposition=[-1.217, 0.848, 1.388],\n)\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [table_cfg, apple_cfg, knife_cfg, light0_cfg, light1_cfg]\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Grab reference to apple and knife\napple = env.scene.object_registry(\"name\", \"apple\")\nknife = env.scene.object_registry(\"name\", \"knife\")\n# Update the simulator's viewer camera's pose so it points towards the table\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.544888, -0.412084,  1.11569 ]),\norientation=np.array([0.54757518, 0.27792802, 0.35721896, 0.70378409]),\n)\n# Let apple settle\nfor _ in range(50):\nenv.step(np.array([]))\nknife.keep_still()\nknife.set_position_orientation(\nposition=apple.get_position() + np.array([-0.15, 0.0, 0.2]),\norientation=T.euler2quat([-np.pi / 2, 0, 0]),\n)\ninput(\"The knife will fall on the apple and dice it. Press [ENTER] to continue.\")\n# Step simulation for a bit so that apple is diced\nfor i in range(1000):\nenv.step(np.array([]))\ninput(\"Apple has been diced! Press [ENTER] to terminate the demo.\")\n# Always close environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/folded_unfolded_state_demo.html","title":"folded_unfolded_state_demo","text":""},{"location":"reference/examples/object_states/folded_unfolded_state_demo.html#examples.object_states.folded_unfolded_state_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of cloth objects that can potentially be folded.</p> Source code in <code>omnigibson/examples/object_states/folded_unfolded_state_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of cloth objects that can potentially be folded.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene + custom cloth object\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [\n{\n\"type\": \"DatasetObject\",\n\"name\": \"carpet\",\n\"category\": \"carpet\",\n\"model\": \"ctclvd\",\n\"prim_type\": PrimType.CLOTH,\n\"abilities\": {\"foldable\": {}, \"unfoldable\": {}},\n\"position\": [0, 0, 0.5],\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"dishtowel\",\n\"category\": \"dishtowel\",\n\"model\": \"dtfspn\",\n\"prim_type\": PrimType.CLOTH,\n\"scale\": 5.0,\n\"abilities\": {\"foldable\": {}, \"unfoldable\": {}},\n\"position\": [1, 1, 0.5],\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"shirt\",\n\"category\": \"t_shirt\",\n\"model\": \"kvidcx\",\n\"prim_type\": PrimType.CLOTH,\n\"scale\": 0.05,\n\"abilities\": {\"foldable\": {}, \"unfoldable\": {}},\n\"position\": [-1, 1, 0.5],\n\"orientation\": [0.7071, 0., 0.7071, 0.],\n},\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Grab object references\ncarpet = env.scene.object_registry(\"name\", \"carpet\")\ndishtowel = env.scene.object_registry(\"name\", \"dishtowel\")\nshirt = env.scene.object_registry(\"name\", \"shirt\")\nobjs = [carpet, dishtowel, shirt]\n# Set viewer camera\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([0.46382895, -2.66703958, 1.22616824]),\norientation=np.array([0.58779174, -0.00231237, -0.00318273, 0.80900271]),\n)\ndef print_state():\nfolded = carpet.states[Folded].get_value()\nunfolded = carpet.states[Unfolded].get_value()\ninfo = \"carpet: [folded] %d [unfolded] %d\" % (folded, unfolded)\nfolded = dishtowel.states[Folded].get_value()\nunfolded = dishtowel.states[Unfolded].get_value()\ninfo += \" || dishtowel: [folded] %d [unfolded] %d\" % (folded, unfolded)\nfolded = shirt.states[Folded].get_value()\nunfolded = shirt.states[Unfolded].get_value()\ninfo += \" || tshirt: [folded] %d [unfolded] %d\" % (folded, unfolded)\nprint(f\"{info}{' ' * (110 - len(info))}\", end=\"\\r\")\nfor _ in range(100):\nog.sim.step()\nprint(\"\\nCloth state:\\n\")\nif not short_exec:\n# Fold all three cloths along the x-axis\nfor i in range(3):\nobj = objs[i]\npos = obj.root_link.particle_positions\nx_min, x_max = np.min(pos, axis=0)[0], np.max(pos, axis=0)[0]\nx_extent = x_max - x_min\n# Get indices for the bottom 10 percent vertices in the x-axis\nindices = np.argsort(pos, axis=0)[:, 0][:(pos.shape[0] // 10)]\nstart = np.copy(pos[indices])\n# lift up a bit\nmid = np.copy(start)\nmid[:, 2] += x_extent * 0.2\n# move towards x_max\nend = np.copy(mid)\nend[:, 0] += x_extent * 0.9\nincrements = 25\nfor ctrl_pts in np.concatenate([np.linspace(start, mid, increments), np.linspace(mid, end, increments)]):\npos = obj.root_link.particle_positions\npos[indices] = ctrl_pts\nobj.root_link.particle_positions = pos\nog.sim.step()\nprint_state()\n# Fold the t-shirt twice again along the y-axis\nfor direction in [-1, 1]:\nobj = shirt\npos = obj.root_link.particle_positions\ny_min, y_max = np.min(pos, axis=0)[1], np.max(pos, axis=0)[1]\ny_extent = y_max - y_min\nif direction == 1:\nindices = np.argsort(pos, axis=0)[:, 1][:(pos.shape[0] // 20)]\nelse:\nindices = np.argsort(pos, axis=0)[:, 1][-(pos.shape[0] // 20):]\nstart = np.copy(pos[indices])\n# lift up a bit\nmid = np.copy(start)\nmid[:, 2] += y_extent * 0.2\n# move towards y_max\nend = np.copy(mid)\nend[:, 1] += direction * y_extent * 0.4\nincrements = 25\nfor ctrl_pts in np.concatenate([np.linspace(start, mid, increments), np.linspace(mid, end, increments)]):\npos = obj.root_link.particle_positions\npos[indices] = ctrl_pts\nobj.root_link.particle_positions = pos\nenv.step(np.array([]))\nprint_state()\nwhile True:\nenv.step(np.array([]))\nprint_state()\n# Shut down env at the end\nprint()\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/heat_source_or_sink_demo.html","title":"heat_source_or_sink_demo","text":""},{"location":"reference/examples/object_states/heated_state_demo.html","title":"heated_state_demo","text":""},{"location":"reference/examples/object_states/object_state_texture_demo.html","title":"object_state_texture_demo","text":""},{"location":"reference/examples/object_states/onfire_demo.html","title":"onfire_demo","text":""},{"location":"reference/examples/object_states/onfire_demo.html#examples.object_states.onfire_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of on fire state. Loads a stove (toggled on), and two apples. The first apple will be ignited by the stove first, then the second apple will be ignited by the first apple.</p> Source code in <code>omnigibson/examples/object_states/onfire_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of on fire state.\n    Loads a stove (toggled on), and two apples.\n    The first apple will be ignited by the stove first, then the second apple will be ignited by the first apple.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Define specific objects we want to load in with the scene directly\nobj_configs = []\n# Light\nobj_configs.append(dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"light\",\nradius=0.01,\nintensity=1e8,\nposition=[-2.0, -2.0, 1.0],\n))\n# Stove\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"stove\",\ncategory=\"stove\",\nmodel=\"yhjzwg\",\nposition=[0, 0, 0.69],\n))\n# 2 Apples\nfor i in range(2):\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=f\"apple{i}\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nposition=[0, i * 0.07, 2.0],\nabilities={\"flammable\": {\"ignition_temperature\": 100, \"distance_threshold\": 0.5}},\n))\n# Create the scene config to load -- empty scene with desired objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": obj_configs,\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Get reference to relevant objects\nstove = env.scene.object_registry(\"name\", \"stove\")\napples = list(env.scene.object_registry(\"category\", \"apple\"))\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.42246569, -0.34745704,  1.56810353]),\norientation=np.array([ 0.50083786, -0.10407796, -0.17482619,  0.84128772]),\n)\n# Let objects settle\nfor _ in range(10):\nenv.step(np.array([]))\n# Turn on the stove\nstove.states[object_states.ToggledOn].set_value(True)\n# The first apple will be affected by the stove\napples[0].set_position(stove.states[object_states.HeatSourceOrSink].link.get_position() + np.array([0.11, 0, 0.1]))\n# The second apple will NOT be affected by the stove, but will be affected by the first apple once it's on fire.\napples[1].set_position(stove.states[object_states.HeatSourceOrSink].link.get_position() + np.array([0.32, 0, 0.1]))\nsteps = 0\nmax_steps = -1 if not short_exec else 1000\n# Main recording loop\nwhile steps != max_steps:\nenv.step(np.array([]))\ntemps = [f\"{apple.states[object_states.Temperature].get_value():&gt;20.2f}\" for apple in apples]\nprint(f\"{'Apple temperature:':&lt;20}\", *temps, end=\"\\r\")\nsteps += 1\n# Always close env at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/overlaid_demo.html","title":"overlaid_demo","text":""},{"location":"reference/examples/object_states/overlaid_demo.html#examples.object_states.overlaid_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of cloth objects that can be overlaid on rigid objects.</p> <p>Loads a carpet on top of a table. Initially Overlaid will be True because the carpet largely covers the table. If you drag the carpet off the table or even just fold it into half, Overlaid will become False.</p> Source code in <code>omnigibson/examples/object_states/overlaid_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of cloth objects that can be overlaid on rigid objects.\n    Loads a carpet on top of a table. Initially Overlaid will be True because the carpet largely covers the table.\n    If you drag the carpet off the table or even just fold it into half, Overlaid will become False.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene + custom cloth object + custom rigid object\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [\n{\n\"type\": \"DatasetObject\",\n\"name\": \"carpet\",\n\"category\": \"carpet\",\n\"model\": \"ctclvd\",\n\"prim_type\": PrimType.CLOTH,\n\"abilities\": {\"foldable\": {}},\n\"position\": [0, 0, 1.0],\n\"scale\": [1.5] * 3,\n},\n{\n\"type\": \"DatasetObject\",\n\"name\": \"breakfast_table\",\n\"category\": \"breakfast_table\",\n\"model\": \"rjgmmy\",\n\"prim_type\": PrimType.RIGID,\n\"scale\": 0.9,\n\"position\": [0, 0, 0.58],\n},\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Grab object references\ncarpet = env.scene.object_registry(\"name\", \"carpet\")\nbreakfast_table = env.scene.object_registry(\"name\", \"breakfast_table\")\n# Set camera pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.88215526, -1.40086216,  2.00311063]),\norientation=np.array([0.42013364, 0.12342107, 0.25339685, 0.86258043]),\n)\nmax_steps = 100 if short_exec else -1\nsteps = 0\nprint(\"\\nTry dragging cloth around with CTRL + Left-Click to see the Overlaid state change:\\n\")\nwhile steps != max_steps:\nprint(f\"Overlaid {carpet.states[Overlaid].get_value(breakfast_table)}    \", end=\"\\r\")\nenv.step(np.array([]))\n# Shut down env at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/particle_applier_remover_demo.html","title":"particle_applier_remover_demo","text":""},{"location":"reference/examples/object_states/particle_applier_remover_demo.html#examples.object_states.particle_applier_remover_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of ParticleApplier and ParticleRemover object states, which enable objects to either apply arbitrary particles and remove arbitrary particles from the simulator, respectively.</p> <p>Loads an empty scene with a table, and starts clean to allow particles to be applied or pre-covers the table with particles to be removed. The ParticleApplier / ParticleRemover state is applied to an imported cloth object and allowed to interact with the table, applying / removing particles from the table.</p> <p>NOTE: The key difference between ParticleApplier/Removers and ParticleSource/Sinks is that Applier/Removers requires contact (if using ParticleProjectionMethod.ADJACENCY) or overlap (if using ParticleProjectionMethod.PROJECTION) in order to spawn / remove particles, and generally only spawn particles at the contact points. ParticleSource/Sinks are special cases of ParticleApplier/Removers that always use ParticleProjectionMethod.PROJECTION and always spawn / remove particles within their projection volume, irregardless of overlap with other objects!</p> Source code in <code>omnigibson/examples/object_states/particle_applier_remover_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of ParticleApplier and ParticleRemover object states, which enable objects to either apply arbitrary\n    particles and remove arbitrary particles from the simulator, respectively.\n    Loads an empty scene with a table, and starts clean to allow particles to be applied or pre-covers the table\n    with particles to be removed. The ParticleApplier / ParticleRemover state is applied to an imported cloth object\n    and allowed to interact with the table, applying / removing particles from the table.\n    NOTE: The key difference between ParticleApplier/Removers and ParticleSource/Sinks is that Applier/Removers\n    requires contact (if using ParticleProjectionMethod.ADJACENCY) or overlap\n    (if using ParticleProjectionMethod.PROJECTION) in order to spawn / remove particles, and generally only spawn\n    particles at the contact points. ParticleSource/Sinks are special cases of ParticleApplier/Removers that\n    always use ParticleProjectionMethod.PROJECTION and always spawn / remove particles within their projection volume,\n    irregardless of overlap with other objects!\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose what configuration to load\nmodifier_type = choose_from_options(\noptions={\n\"particleApplier\": \"Demo object's ability to apply particles in the simulator\",\n\"particleRemover\": \"Demo object's ability to remove particles from the simulator\",\n},\nname=\"particle modifier type\",\nrandom_selection=random_selection,\n)\nmodification_metalink = {\n\"particleApplier\": \"particleapplication_link\",\n\"particleRemover\": \"particleremover_link\",\n}\nparticle_types = [\"stain\", \"water\"]\nparticle_type = choose_from_options(\noptions={name: f\"{name} particles will be applied or removed from the simulator\" for name in particle_types},\nname=\"particle type\",\nrandom_selection=random_selection,\n)\nmodification_method = {\n\"Adjacency\": ParticleModifyMethod.ADJACENCY,\n\"Projection\": ParticleModifyMethod.PROJECTION,\n}\nprojection_mesh_params = {\n\"Adjacency\": None,\n\"Projection\": {\n# Either Cone or Cylinder; shape of the projection where particles can be applied / removed\n\"type\": \"Cone\",\n# Size of the cone\n\"extents\": np.array([0.1875, 0.1875, 0.375]),\n\"visualize\": True,\n},\n}\nmethod_type = choose_from_options(\noptions={\n\"Adjacency\": \"Close proximity to the object will be used to determine whether particles can be applied / removed\",\n\"Projection\": \"A Cone or Cylinder shape protruding from the object will be used to determine whether particles can be applied / removed\",\n},\nname=\"modifier method type\",\nrandom_selection=random_selection,\n)\n# Create the ability kwargs to pass to the object state\nabilities = {\nmodifier_type: {\n\"method\": modification_method[method_type],\n\"conditions\": {\n# For a specific particle system, this specifies what conditions are required in order for the\n# particle applier / remover to apply / remover particles associated with that system\n# The list should contain functions with signature condition() --&gt; bool,\n# where True means the condition is satisified\nparticle_type: [],\n},\n\"projection_mesh_params\": projection_mesh_params[method_type],\n}\n}\n# Define objects to load: a light, table, and cloth\nlight_cfg = dict(\ntype=\"LightObject\",\nname=\"light\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=1e8,\nposition=[-2.0, -2.0, 2.0],\n)\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"kwmfdg\",\nscale=[4.0, 4.0, 4.0],\nposition=[0, 0, 0.98],\n)\n# Create the scene config to load -- empty scene with a light and table\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [light_cfg, table_cfg],\n}\n# Sanity check inputs: Remover + Adjacency + Fluid will not work because we are using a visual_only\n# object, so contacts will not be triggered with this object\n# Load the environment, then immediately stop the simulator since we need to add in the modifier object\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\nog.sim.stop()\n# Grab references to table\ntable = env.scene.object_registry(\"name\", \"table\")\n# Set the viewer camera appropriately\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-1.61340969, -1.79803028,  2.53167412]),\norientation=np.array([ 0.46291845, -0.12381886, -0.22679218,  0.84790371]),\n)\n# If we're using a projection volume, we manually add in the required metalink required in order to use the volume\nmodifier = DatasetObject(\nname=\"modifier\",\ncategory=\"dishtowel\",\nmodel=\"dtfspn\",\nscale=np.ones(3) * 2.0,\nvisual_only=method_type == \"Projection\",  # Non-fluid adjacency requires the object to have collision geoms active\nabilities=abilities,\n)\nmodifier_root_link_path = f\"{modifier.prim_path}/base_link\"\nmodifier._prim = modifier._load()\nif method_type == \"Projection\":\nmetalink_path = f\"{modifier.prim_path}/{modification_metalink[modifier_type]}\"\nog.sim.stage.DefinePrim(metalink_path, \"Xform\")\ncreate_joint(\nprim_path=f\"{modifier_root_link_path}/{modification_metalink[modifier_type]}_joint\",\nbody0=modifier_root_link_path,\nbody1=metalink_path,\njoint_type=\"FixedJoint\",\nenabled=True,\n)\nmodifier._post_load()\nmodifier._loaded = True\nog.sim.import_object(modifier)\nmodifier.set_position(np.array([0, 0, 5.0]))\n# Play the simulator and take some environment steps to let the objects settle\nog.sim.play()\nfor _ in range(25):\nenv.step(np.array([]))\n# If we're removing particles, set the table's covered state to be True\nif modifier_type == \"particleRemover\":\ntable.states[Covered].set_value(get_system(particle_type), True)\n# Take a few steps to let particles settle\nfor _ in range(25):\nenv.step(np.array([]))\n# Enable camera teleoperation for convenience\nog.sim.enable_viewer_camera_teleoperation()\n# Set the modifier object to be in position to modify particles\nif method_type == \"Projection\":\n# Higher z to showcase projection volume at work\nz = 1.85\nelif particle_type == \"stain\":\n# Lower z needed to allow for adjacency bounding box to overlap properly\nz = 1.175\nelse:\n# Higher z needed for actual physical interaction to accommodate non-negligible particle radius\nz = 1.22\nmodifier.keep_still()\nmodifier.set_position_orientation(\nposition=np.array([0, 0.3, z]),\norientation=np.array([0, 0, 0, 1.0]),\n)\n# Move object in square around table\ndeltas = [\n[150, np.array([-0.01, 0, 0])],\n[60, np.array([0, -0.01, 0])],\n[150, np.array([0.01, 0, 0])],\n[60, np.array([0, 0.01, 0])],\n]\nfor t, delta in deltas:\nfor i in range(t):\nmodifier.set_position(modifier.get_position() + delta)\nenv.step(np.array([]))\n# Always shut down environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/particle_source_sink_demo.html","title":"particle_source_sink_demo","text":""},{"location":"reference/examples/object_states/particle_source_sink_demo.html#examples.object_states.particle_source_sink_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of ParticleSource and ParticleSink object states, which enable objects to either spawn arbitrary particles and remove arbitrary particles from the simulator, respectively.</p> <p>Loads an empty scene with a sink, which is enabled with both the ParticleSource and ParticleSink states. The sink's particle source is located at the faucet spout and spawns a continuous stream of water particles, which is then destroyed (\"sunk\") by the sink's particle sink located at the drain.</p> <p>NOTE: The key difference between ParticleApplier/Removers and ParticleSource/Sinks is that Applier/Removers requires contact (if using ParticleProjectionMethod.ADJACENCY) or overlap (if using ParticleProjectionMethod.PROJECTION) in order to spawn / remove particles, and generally only spawn particles at the contact points. ParticleSource/Sinks are special cases of ParticleApplier/Removers that always use ParticleProjectionMethod.PROJECTION and always spawn / remove particles within their projection volume, irregardless of overlap with other objects!</p> Source code in <code>omnigibson/examples/object_states/particle_source_sink_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of ParticleSource and ParticleSink object states, which enable objects to either spawn arbitrary\n    particles and remove arbitrary particles from the simulator, respectively.\n    Loads an empty scene with a sink, which is enabled with both the ParticleSource and ParticleSink states.\n    The sink's particle source is located at the faucet spout and spawns a continuous stream of water particles,\n    which is then destroyed (\"sunk\") by the sink's particle sink located at the drain.\n    NOTE: The key difference between ParticleApplier/Removers and ParticleSource/Sinks is that Applier/Removers\n    requires contact (if using ParticleProjectionMethod.ADJACENCY) or overlap\n    (if using ParticleProjectionMethod.PROJECTION) in order to spawn / remove particles, and generally only spawn\n    particles at the contact points. ParticleSource/Sinks are special cases of ParticleApplier/Removers that\n    always use ParticleProjectionMethod.PROJECTION and always spawn / remove particles within their projection volume,\n    irregardless of overlap with other objects!\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n}\n}\ndef check_toggledon(obj):\nreturn obj.states[object_states.ToggledOn].get_value()\n# Define objects to load into the environment\nsink_cfg = dict(\ntype=\"DatasetObject\",\nname=\"sink\",\ncategory=\"sink\",\nmodel=\"yfaufu\",\nscale=[0.8, 0.8, 0.8],\nabilities={\n\"toggleable\": {},\n\"particleSource\": {\n\"conditions\": {\n\"water\": [check_toggledon],   # Must be toggled on for water source to be active\n},\n\"source_radius\": 0.0125,\n\"source_height\": 0.05,\n\"initial_speed\": 0.0,               # Water merely falls out of the spout\n},\n\"particleSink\": {\n\"conditions\": {\n\"water\": None,  # No conditions, always sinking nearby particles\n},\n\"sink_radius\": 0.05,\n\"sink_height\": 0.05,\n},\n},\nposition=[-0.7, 0, 0.56],\n)\ncfg[\"objects\"] = [sink_cfg]\n# Create the environment!\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to ideal angle for viewing objects\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.71452157, -0.88294428,  1.85640559]),\norientation=np.array([ 0.44909348, -0.00142818, -0.00284131,  0.89347912]),\n)\n# Take a few steps to let the objects settle, and then turn on the sink\nfor _ in range(10):\nenv.step(np.array([]))              # Empty action since no robots are in the scene\nsink = env.scene.object_registry(\"name\", \"sink\")\nassert sink.states[object_states.ToggledOn].set_value(True)\n# Take a step, and save the state\nenv.step(np.array([]))\ninitial_state = og.sim.dump_state()\n# Main simulation loop.\nmax_steps = 1000\nmax_iterations = -1 if not short_exec else 1\niteration = 0\ntry:\nwhile iteration != max_iterations:\n# Keep stepping until table or bowl are clean, or we reach 1000 steps\nsteps = 0\nwhile steps != max_steps:\nsteps += 1\nenv.step(np.array([]))\nog.log.info(\"Max steps reached; resetting.\")\n# Reset to the initial state\nog.sim.load_state(initial_state)\niteration += 1\nfinally:\n# Always shut down environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/sample_kinematics_demo.html","title":"sample_kinematics_demo","text":""},{"location":"reference/examples/object_states/sample_kinematics_demo.html#examples.object_states.sample_kinematics_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo to use the raycasting-based sampler to load objects onTop and/or inside another Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet Then loads a shelf and cracker boxes inside of it</p> Source code in <code>omnigibson/examples/object_states/sample_kinematics_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo to use the raycasting-based sampler to load objects onTop and/or inside another\n    Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet\n    Then loads a shelf and cracker boxes inside of it\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n}\n# Define objects we want to sample at runtime\nmicrowave_cfg = dict(\ntype=\"DatasetObject\",\nname=\"microwave\",\ncategory=\"microwave\",\nmodel=\"hjjxmi\",\nscale=0.5,\n)\ncabinet_cfg = dict(\ntype=\"DatasetObject\",\nname=\"cabinet\",\ncategory=\"bottom_cabinet\",\nmodel=\"bamfsz\",\n)\nplate_cfgs = [dict(\ntype=\"DatasetObject\",\nname=f\"plate{i}\",\ncategory=\"plate\",\nmodel=\"iawoof\",\nbounding_box=np.array([0.25, 0.25, 0.05]),\n) for i in range(2)]\napple_cfgs = [dict(\ntype=\"DatasetObject\",\nname=f\"apple{i}\",\ncategory=\"apple\",\nmodel=\"agveuv\",\n) for i in range(4)]\nshelf_cfg = dict(\ntype=\"DatasetObject\",\nname=f\"shelf\",\ncategory=\"shelf\",\nmodel=\"pkgbcp\",\nbounding_box=np.array([1.0, 0.4, 2.0]),\n)\nbox_cfgs = [dict(\ntype=\"DatasetObject\",\nname=f\"box{i}\",\ncategory=\"cracker_box\",\nmodel=\"cmdigf\",\nbounding_box=np.array([0.2, 0.05, 0.3]),\n) for i in range(5)]\n# Compose objects cfg\nobjects_cfg = [\nmicrowave_cfg,\ncabinet_cfg,\n*plate_cfgs,\n*apple_cfgs,\nshelf_cfg,\n*box_cfgs,\n]\n# Update their spawn positions so they don't collide immediately\nfor i, obj_cfg in enumerate(objects_cfg):\nobj_cfg[\"position\"] = [100 + i, 100 + i, 100 + i]\ncfg[\"objects\"] = objects_cfg\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\nenv.step([])\n# Sample microwave and boxes\nsample_boxes_on_shelf(env)\nsample_microwave_plates_apples(env)\nmax_steps = 100 if short_exec else -1\nstep = 0\nwhile step != max_steps:\nenv.step(np.array([]))\nstep += 1\n# Always close environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/slicing_demo.html","title":"slicing_demo","text":""},{"location":"reference/examples/object_states/slicing_demo.html#examples.object_states.slicing_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of slicing an apple into two apple slices</p> Source code in <code>omnigibson/examples/object_states/slicing_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of slicing an apple into two apple slices\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene with table, knife, and apple\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"rjgmmy\",\nscale=0.9,\nposition=[0, 0, 0.58],\n)\napple_cfg = dict(\ntype=\"DatasetObject\",\nname=\"apple\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nscale=1.5,\nposition=[0.085, 0,  0.92],\n)\nknife_cfg = dict(\ntype=\"DatasetObject\",\nname=\"knife\",\ncategory=\"table_knife\",\nmodel=\"lrdmpf\",\nscale=2.5,\nposition=[0, 0, 10.0],\n)\nlight0_cfg = dict(\ntype=\"LightObject\",\nname=\"light0\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=4000.0,\nposition=[1.217, -0.848, 1.388],\n)\nlight1_cfg = dict(\ntype=\"LightObject\",\nname=\"light1\",\nlight_type=\"Sphere\",\nradius=0.01,\nintensity=4000.0,\nposition=[-1.217, 0.848, 1.388],\n)\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [table_cfg, apple_cfg, knife_cfg, light0_cfg, light1_cfg]\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Grab reference to apple and knife\napple = env.scene.object_registry(\"name\", \"apple\")\nknife = env.scene.object_registry(\"name\", \"knife\")\n# Update the simulator's viewer camera's pose so it points towards the table\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.544888, -0.412084,  1.11569 ]),\norientation=np.array([0.54757518, 0.27792802, 0.35721896, 0.70378409]),\n)\n# Let apple settle\nfor _ in range(50):\nenv.step(np.array([]))\nknife.keep_still()\nknife.set_position_orientation(\nposition=apple.get_position() + np.array([-0.15, 0.0, 0.2]),\norientation=T.euler2quat([-np.pi / 2, 0, 0]),\n)\ninput(\"The knife will fall on the apple and slice it. Press [ENTER] to continue.\")\n# Step simulation for a bit so that apple is sliced\nfor i in range(1000):\nenv.step(np.array([]))\ninput(\"Apple has been sliced! Press [ENTER] to terminate the demo.\")\n# Always close environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/object_states/temperature_demo.html","title":"temperature_demo","text":""},{"location":"reference/examples/object_states/temperature_demo.html#examples.object_states.temperature_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of temperature change Loads a stove, a microwave and an oven, all toggled on, and five frozen apples The user can move the apples to see them change from frozen, to normal temperature, to cooked and burnt This demo also shows how to load objects ToggledOn and how to set the initial temperature of an object</p> Source code in <code>omnigibson/examples/object_states/temperature_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Demo of temperature change\n    Loads a stove, a microwave and an oven, all toggled on, and five frozen apples\n    The user can move the apples to see them change from frozen, to normal temperature, to cooked and burnt\n    This demo also shows how to load objects ToggledOn and how to set the initial temperature of an object\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Define specific objects we want to load in with the scene directly\nobj_configs = []\n# Light\nobj_configs.append(dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"light\",\nradius=0.01,\nintensity=1e8,\nposition=[-2.0, -2.0, 1.0],\n))\n# Stove\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"stove\",\ncategory=\"stove\",\nmodel=\"yhjzwg\",\nposition=[0, 0, 0.69],\n))\n# Microwave\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"microwave\",\ncategory=\"microwave\",\nmodel=\"hjjxmi\",\nscale=0.25,\nposition=[2.5, 0, 0.10],\n))\n# Oven\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"oven\",\ncategory=\"oven\",\nmodel=\"wuinhm\",\nposition=[-1.25, 0, 0.88],\n))\n# Tray\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"tray\",\ncategory=\"tray\",\nmodel=\"xzcnjq\",\nscale=0.15,\nposition=[-0.25, -0.12, 1.26],\n))\n# Fridge\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=\"fridge\",\ncategory=\"fridge\",\nmodel=\"hivvdf\",\nabilities={\n\"coldSource\": {\n\"temperature\": -100.0,\n\"requires_inside\": True,\n}\n},\nposition=[1.25, 0, 0.81],\n))\n# 5 Apples\nfor i in range(5):\nobj_configs.append(dict(\ntype=\"DatasetObject\",\nname=f\"apple{i}\",\ncategory=\"apple\",\nmodel=\"agveuv\",\nposition=[0, i * 0.1, 5.0],\n))\n# Create the scene config to load -- empty scene with desired objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": obj_configs,\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Get reference to relevant objects\nstove = env.scene.object_registry(\"name\", \"stove\")\nmicrowave = env.scene.object_registry(\"name\", \"microwave\")\noven = env.scene.object_registry(\"name\", \"oven\")\ntray = env.scene.object_registry(\"name\", \"tray\")\nfridge = env.scene.object_registry(\"name\", \"fridge\")\napples = list(env.scene.object_registry(\"category\", \"apple\"))\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 0.46938863, -3.97887141,  1.64106008]),\norientation=np.array([0.63311689, 0.00127259, 0.00155577, 0.77405359]),\n)\n# Let objects settle\nfor _ in range(25):\nenv.step(np.array([]))\n# Turn on all scene objects\nstove.states[object_states.ToggledOn].set_value(True)\nmicrowave.states[object_states.ToggledOn].set_value(True)\noven.states[object_states.ToggledOn].set_value(True)\n# Set initial temperature of the apples to -50 degrees Celsius, and move the apples to different objects\nfor apple in apples:\napple.states[object_states.Temperature].set_value(-50)\napples[0].states[object_states.Inside].set_value(oven, True)\napples[1].set_position(stove.states[object_states.HeatSourceOrSink].link.get_position() + np.array([0, 0, 0.1]))\napples[2].states[object_states.OnTop].set_value(tray, True)\napples[3].states[object_states.Inside].set_value(fridge, True)\napples[4].states[object_states.Inside].set_value(microwave, True)\nsteps = 0\nmax_steps = -1 if not short_exec else 1000\n# Main recording loop\nlocations = [f'{loc:&gt;20}' for loc in [\"Inside oven\", \"On stove\", \"On tray\", \"Inside fridge\", \"Inside microwave\"]]\nprint()\nprint(f\"{'Apple location:':&lt;20}\", *locations)\nwhile steps != max_steps:\nenv.step(np.array([]))\ntemps = [f\"{apple.states[object_states.Temperature].get_value():&gt;20.2f}\" for apple in apples]\nprint(f\"{'Apple temperature:':&lt;20}\", *temps, end=\"\\r\")\nsteps += 1\n# Always close env at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/objects/index.html","title":"objects","text":""},{"location":"reference/examples/objects/draw_bounding_box.html","title":"draw_bounding_box","text":""},{"location":"reference/examples/objects/draw_bounding_box.html#examples.objects.draw_bounding_box.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Shows how to obtain the bounding box of an articulated object. Draws the bounding box around the loaded object, a cabinet, and writes the visualized image to disk at the current directory named 'bbox_2d_[loose / tight]_img.png'.</p> <p>NOTE: In the GUI, bounding boxes can be natively viewed by clicking on the sensor ((*)) icon at the top, and then selecting the appropriate bounding box modalities, and clicking \"Show\". See:</p> <p>https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator/visualization.html#the-visualizer</p> Source code in <code>omnigibson/examples/objects/draw_bounding_box.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Shows how to obtain the bounding box of an articulated object.\n    Draws the bounding box around the loaded object, a cabinet, and writes the visualized image to disk at the\n    current directory named 'bbox_2d_[loose / tight]_img.png'.\n    NOTE: In the GUI, bounding boxes can be natively viewed by clicking on the sensor ((*)) icon at the top,\n    and then selecting the appropriate bounding box modalities, and clicking \"Show\". See:\n    https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator/visualization.html#the-visualizer\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Specify objects to load\nbanana_cfg = dict(\ntype=\"DatasetObject\",\nname=\"banana\",\ncategory=\"banana\",\nmodel=\"vvyyyv\",\nscale=[3.0, 5.0, 2.0],\nposition=[-0.906661, -0.545106,  0.136824],\norientation=[0, 0, 0.76040583, -0.6494482 ],\n)\ndoor_cfg = dict(\ntype=\"DatasetObject\",\nname=\"door\",\ncategory=\"door\",\nmodel=\"ohagsq\",\nposition=[-2.0, 0, 0.70000001],\norientation=[0, 0, -0.38268343,  0.92387953],\n)\n# Create the scene config to load -- empty scene with a few objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [banana_cfg, door_cfg],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to appropriate viewing pose\ncam = og.sim.viewer_camera\ncam.set_position_orientation(\nposition=np.array([-4.62785 , -0.418575,  0.933943]),\norientation=np.array([ 0.52196595, -0.4231939 , -0.46640436,  0.5752612 ]),\n)\n# Add bounding boxes to camera sensor\nbbox_modalities = [\"bbox_3d\", \"bbox_2d_loose\", \"bbox_2d_tight\"]\nfor bbox_modality in bbox_modalities:\ncam.add_modality(bbox_modality)\n# Take a few steps to let objects settle\nfor i in range(100):\nenv.step(np.array([]))\n# Grab observations from viewer camera and write them to disk\nobs = cam.get_obs()\nfor bbox_modality in bbox_modalities:\n# Print out each of the modalities\nog.log.info(f\"Observation modality {bbox_modality}:\\n{obs[bbox_modality]}\")\n# Also write the 2d loose bounding box to disk\nif \"3d\" not in bbox_modality:\ncolorized_img = colorize_bboxes(bboxes_2d_data=obs[bbox_modality], bboxes_2d_rgb=obs[\"rgb\"], num_channels=4)\nfpath = f\"{bbox_modality}_img.png\"\nplt.imsave(fpath, colorized_img)\nog.log.info(f\"Saving modality [{bbox_modality}] image to: {fpath}\")\n# Always close environment down at end\nenv.close()\n</code></pre>"},{"location":"reference/examples/objects/highlight_objects.html","title":"highlight_objects","text":""},{"location":"reference/examples/objects/highlight_objects.html#examples.objects.highlight_objects.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Highlights visually all object instances of windows and then removes the highlighting It also demonstrates how to apply an action on all instances of objects of a given category</p> Source code in <code>omnigibson/examples/objects/highlight_objects.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Highlights visually all object instances of windows and then removes the highlighting\n    It also demonstrates how to apply an action on all instances of objects of a given category\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"InteractiveTraversableScene\",\n\"scene_model\": \"Rs_int\",\n}\n}\n# Create the environment\nenv = og.Environment(configs=cfg)\n# Grab all window objects\nwindows = og.sim.scene.object_registry(\"category\", \"window\")\n# Step environment while toggling window highlighting\ni = 0\nhighlighted = False\nmax_steps = -1 if not short_exec else 1000\nwhile i != max_steps:\nenv.step(np.array([]))\nif i % 50 == 0:\nhighlighted = not highlighted\nog.log.info(f\"Toggling window highlight to: {highlighted}\")\nfor window in windows:\n# Note that this property is R/W!\nwindow.highlighted = highlighted\ni += 1\n# Always close the environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/objects/load_object_selector.html","title":"load_object_selector","text":""},{"location":"reference/examples/objects/load_object_selector.html#examples.objects.load_object_selector.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>This demo shows how to load any scaled objects from the OG object model dataset The user selects an object model to load The objects can be loaded into an empty scene or an interactive scene (OG) The example also shows how to use the Environment API or directly the Simulator API, loading objects and robots and executing actions</p> Source code in <code>omnigibson/examples/objects/load_object_selector.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    This demo shows how to load any scaled objects from the OG object model dataset\n    The user selects an object model to load\n    The objects can be loaded into an empty scene or an interactive scene (OG)\n    The example also shows how to use the Environment API or directly the Simulator API, loading objects and robots\n    and executing actions\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\nscene_options = [\"Scene\", \"InteractiveTraversableScene\"]\nscene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n# -- Choose the object to load --\n# Select a category to load\navailable_obj_categories = get_all_object_categories()\nobj_category = choose_from_options(options=available_obj_categories, name=\"object category\", random_selection=random_selection)\n# Select a model to load\navailable_obj_models = get_object_models_of_category(obj_category)\nobj_model = choose_from_options(options=available_obj_models, name=\"object model\", random_selection=random_selection)\n# Load the specs of the object categories, e.g., common scaling factor\navg_category_spec = get_og_avg_category_specs()\n# Create and load this object into the simulator\nobj_cfg = dict(\ntype=\"DatasetObject\",\nname=\"obj\",\ncategory=obj_category,\nmodel=obj_model,\nbounding_box=avg_category_spec.get(obj_category),\nfit_avg_dim_volume=True,\nposition=[0, 0, 50.0],\n)\ncfg = {\n\"scene\": {\n\"type\": scene_type,\n},\n\"objects\": [obj_cfg],\n}\nif scene_type == \"InteractiveTraversableScene\":\ncfg[\"scene\"][\"scene_model\"] = \"Rs_int\"\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n# Place the object so it rests on the floor\nobj = env.scene.object_registry(\"name\", \"obj\")\ncenter_offset = obj.get_position() - obj.aabb_center + np.array([0, 0, obj.aabb_extent[2] / 2.0])\nobj.set_position(center_offset)\n# Step through the environment\nmax_steps = 100 if short_exec else 10000\nfor i in range(max_steps):\nenv.step(np.array([]))\n# Always close the environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/objects/visualize_object.html","title":"visualize_object","text":""},{"location":"reference/examples/objects/visualize_object.html#examples.objects.visualize_object.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Visualizes object as specified by its USD path, @usd_path. If None if specified, will instead result in an object selection from OmniGibson's object dataset</p> Source code in <code>omnigibson/examples/objects/visualize_object.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Visualizes object as specified by its USD path, @usd_path. If None if specified, will instead\n    result in an object selection from OmniGibson's object dataset\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Assuming that if random_selection=True, headless=True, short_exec=True, we are calling it from tests and we\n# do not want to parse args (it would fail because the calling function is pytest \"testfile.py\")\nusd_path = None\nif not (random_selection and headless and short_exec):\nparser = argparse.ArgumentParser()\nparser.add_argument(\n\"--usd_path\",\ndefault=None,\nhelp=\"USD Model to load\",\n)\nargs = parser.parse_args()\nusd_path = args.usd_path\n# Define objects to load\nlight0_cfg = dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"sphere_light0\",\nradius=0.01,\nintensity=1e5,\nposition=[-2.0, -2.0, 2.0],\n)\nlight1_cfg = dict(\ntype=\"LightObject\",\nlight_type=\"Sphere\",\nname=\"sphere_light1\",\nradius=0.01,\nintensity=1e5,\nposition=[-2.0, 2.0, 2.0],\n)\n# Make sure we have a valid usd path\nif usd_path is None:\n# Select a category to load\navailable_obj_categories = get_all_object_categories()\nobj_category = choose_from_options(options=available_obj_categories, name=\"object category\",\nrandom_selection=random_selection)\n# Select a model to load\navailable_obj_models = get_object_models_of_category(obj_category)\nobj_model = choose_from_options(options=available_obj_models, name=\"object model\",\nrandom_selection=random_selection)\nkwargs = {\n\"type\": \"DatasetObject\",\n\"category\": obj_category,\n\"model\": obj_model,\n}\nelse:\nkwargs = {\n\"type\": \"USDObject\",\n\"usd_path\": usd_path,\n}\n# Import the desired object\nobj_cfg = dict(\n**kwargs,\nname=\"obj\",\nusd_path=usd_path,\nvisual_only=True,\nposition=[0, 0, 10.0],\n)\n# Create the scene config to load -- empty scene\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [light0_cfg, light1_cfg, obj_cfg],\n}\n# Create the environment\nenv = og.Environment(configs=cfg)\n# Set camera to appropriate viewing pose\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.00913503, -1.95750906,  1.36407314]),\norientation=np.array([0.6350064 , 0.        , 0.        , 0.77250687]),\n)\n# Grab the object references\nobj = env.scene.object_registry(\"name\", \"obj\")\n# Standardize the scale of the object so it fits in a [1,1,1] box -- note that we have to stop the simulator\n# in order to set the scale\nextents = obj.aabb_extent\nog.sim.stop()\nobj.scale = (np.ones(3) / extents).min()\nog.sim.play()\nenv.step(np.array([]))\n# Move the object so that its center is at [0, 0, 1]\ncenter_offset = obj.get_position() - obj.aabb_center + np.array([0, 0, 1.0])\nobj.set_position(center_offset)\n# Allow the user to easily move the camera around\nog.sim.enable_viewer_camera_teleoperation()\n# Rotate the object in place\nsteps_per_rotate = 360\nsteps_per_joint = steps_per_rotate / 10\nmax_steps = 100 if short_exec else 10000\nfor i in range(max_steps):\nz_angle = (2 * np.pi * (i % steps_per_rotate) / steps_per_rotate)\nquat = T.euler2quat(np.array([0, 0, z_angle]))\npos = T.quat2mat(quat) @ center_offset\nif obj.n_dof &gt; 0:\nfrac = (i % steps_per_joint) / steps_per_joint\nj_frac = -1.0 + 2.0 * frac if (i // steps_per_joint) % 2 == 0 else 1.0 - 2.0 * frac\nobj.set_joint_positions(positions=j_frac * np.ones(obj.n_dof), normalized=True, drive=False)\nobj.keep_still()\nobj.set_position_orientation(position=pos, orientation=quat)\nenv.step(np.array([]))\n# Shut down at the end\nog.shutdown()\n</code></pre>"},{"location":"reference/examples/renderer_settings/index.html","title":"renderer_settings","text":""},{"location":"reference/examples/renderer_settings/renderer_settings_example.html","title":"renderer_settings_example","text":""},{"location":"reference/examples/renderer_settings/renderer_settings_example.html#examples.renderer_settings.renderer_settings_example.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Shows how to use RendererSettings class</p> Source code in <code>omnigibson/examples/renderer_settings/renderer_settings_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Shows how to use RendererSettings class\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Specify objects to load\nbanana_cfg = dict(\ntype=\"DatasetObject\",\nname=\"banana\",\ncategory=\"banana\",\nmodel=\"vvyyyv\",\nscale=[3.0, 5.0, 2.0],\nposition=[-0.906661, -0.545106,  0.136824],\norientation=[0, 0, 0.76040583, -0.6494482 ],\n)\ndoor_cfg = dict(\ntype=\"DatasetObject\",\nname=\"door\",\ncategory=\"door\",\nmodel=\"ohagsq\",\nposition=[-2.0, 0, 0.70000001],\norientation=[0, 0, -0.38268343,  0.92387953],\n)\n# Create the scene config to load -- empty scene with a few objects\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n},\n\"objects\": [banana_cfg, door_cfg],\n}\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Set camera to appropriate viewing pose\ncam = og.sim.viewer_camera\ncam.set_position_orientation(\nposition=np.array([-4.62785 , -0.418575,  0.933943]),\norientation=np.array([ 0.52196595, -0.4231939 , -0.46640436,  0.5752612 ]),\n)\ndef steps(n):\nfor _ in range(n):\nenv.step(np.array([]))\n# Take a few steps to let objects settle\nsteps(25)\n# Create renderer settings object.\nrenderer_setting = RendererSettings()\n# RendererSettings is a singleton.\nrenderer_setting2 = RendererSettings()\nassert renderer_setting == renderer_setting2\n# Set current renderer.\ninput(\"Setting renderer to Real-Time. Press [ENTER] to continue.\")\nrenderer_setting.set_current_renderer(\"Real-Time\")\nassert renderer_setting.get_current_renderer() == \"Real-Time\"\nsteps(5)\ninput(\"Setting renderer to Interactive (Path Tracing). Press [ENTER] to continue.\")\nrenderer_setting.set_current_renderer(\"Interactive (Path Tracing)\")\nassert renderer_setting.get_current_renderer() == \"Interactive (Path Tracing)\"\nsteps(5)\n# Get all available settings.\nprint(renderer_setting.settings.keys())\ninput(\"Showcasing how to use RendererSetting APIs. Please see example script for more information. \"\n\"Press [ENTER] to continue.\")\n# Set setting (2 lines below are equivalent).\nrenderer_setting.set_setting(path=\"/app/renderer/skipMaterialLoading\", value=True)\nrenderer_setting.common_settings.materials_settings.skip_material_loading.set(True)\n# Get setting (3 lines below are equivalent).\nassert renderer_setting.get_setting_from_path(path=\"/app/renderer/skipMaterialLoading\") == True\nassert renderer_setting.common_settings.materials_settings.skip_material_loading.value == True\nassert renderer_setting.common_settings.materials_settings.skip_material_loading.get() == True\n# Reset setting (2 lines below are equivalent).\nrenderer_setting.reset_setting(path=\"/app/renderer/skipMaterialLoading\")\nrenderer_setting.common_settings.materials_settings.skip_material_loading.reset()\nassert renderer_setting.get_setting_from_path(path=\"/app/renderer/skipMaterialLoading\") == False\n# Set setting to an unallowed value using top-level method.\n# Examples below will use the \"top-level\" setting method.\ntry:\nrenderer_setting.set_setting(path=\"/app/renderer/skipMaterialLoading\", value=\"foo\")\nexcept AssertionError as e:\nprint(e)  # All good. We got an AssertionError.\n# Set setting to a value out-of-range.\ntry:\nrenderer_setting.set_setting(path=\"/rtx/fog/fogColorIntensity\", value=0.0)\nexcept AssertionError as e:\nprint(e)  # All good. We got an AssertionError.\n# Set unallowed setting.\ntry:\nrenderer_setting.set_setting(path=\"foo\", value=\"bar\")\nexcept NotImplementedError as e:\nprint(e)  # All good. We got a NotImplementedError.\n# Set setting but the setting group is not enabled.\n# Setting is successful but there will be a warning message printed.\nrenderer_setting.set_setting(path=\"/rtx/fog/fogColorIntensity\", value=1.0)\n# Shutdown sim\ninput(\"Completed demo. Press [ENTER] to shutdown simulation.\")\nog.shutdown()\n</code></pre>"},{"location":"reference/examples/robots/index.html","title":"robots","text":""},{"location":"reference/examples/robots/all_robots_visualizer.html","title":"all_robots_visualizer","text":""},{"location":"reference/examples/robots/all_robots_visualizer.html#examples.robots.all_robots_visualizer.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Robot demo Loads all robots in an empty scene, generate random actions</p> Source code in <code>omnigibson/examples/robots/all_robots_visualizer.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Robot demo\n    Loads all robots in an empty scene, generate random actions\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Create empty scene with no robots in it initially\ncfg = {\n\"scene\": {\n\"type\": \"Scene\",\n}\n}\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Iterate over all robots and demo their motion\nfor robot_name, robot_cls in REGISTERED_ROBOTS.items():\n# Create and import robot\nrobot = robot_cls(\nprim_path=f\"/World/{robot_name}\",\nname=robot_name,\nobs_modalities=[],              # We're just moving robots around so don't load any observation modalities\n)\nog.sim.import_object(robot)\n# At least one step is always needed while sim is playing for any imported object to be fully initialized\nog.sim.play()\nog.sim.step()\n# Reset robot and make sure it's not moving\nrobot.reset()\nrobot.keep_still()\n# Log information\nog.log.info(f\"Loaded {robot_name}\")\nog.log.info(f\"Moving {robot_name}\")\nif not headless:\n# Set viewer in front facing robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([ 2.69918369, -3.63686664,  4.57894564]),\norientation=np.array([0.39592411, 0.1348514 , 0.29286304, 0.85982   ]),\n)\nog.sim.enable_viewer_camera_teleoperation()\n# Hold still briefly so viewer can see robot\nfor _ in range(100):\nog.sim.step()\n# Then apply random actions for a bit\nfor _ in range(30):\naction = np.random.uniform(-1, 1, robot.action_dim)\nfor _ in range(10):\nenv.step(action)\n# Stop the simulator and remove the robot\nog.sim.stop()\nog.sim.remove_object(obj=robot)\n# Always shut down the environment cleanly at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/robots/grasping_mode_example.html","title":"grasping_mode_example","text":"<p>Example script demo'ing robot manipulation control with grasping.</p>"},{"location":"reference/examples/robots/grasping_mode_example.html#examples.robots.grasping_mode_example.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Robot grasping mode demo with selection Queries the user to select a type of grasping mode</p> Source code in <code>omnigibson/examples/robots/grasping_mode_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Robot grasping mode demo with selection\n    Queries the user to select a type of grasping mode\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose type of grasping\ngrasping_mode = choose_from_options(options=GRASPING_MODES, name=\"grasping mode\", random_selection=random_selection)\n# Create environment configuration to use\nscene_cfg = dict(type=\"Scene\")\nrobot0_cfg = dict(\ntype=\"Fetch\",\nobs_modalities=[\"rgb\"],     # we're just doing a grasping demo so we don't need all observation modalities\naction_type=\"continuous\",\naction_normalize=True,\ngrasping_mode=grasping_mode,\n)\n# Define objects to load\ntable_cfg = dict(\ntype=\"DatasetObject\",\nname=\"table\",\ncategory=\"breakfast_table\",\nmodel=\"lcsizg\",\nbounding_box=[0.5, 0.5, 0.8],\nfit_avg_dim_volume=False,\nfixed_base=True,\nposition=[0.7, -0.1, 0.6],\norientation=[0, 0, 0.707, 0.707],\n)\nchair_cfg = dict(\ntype=\"DatasetObject\",\nname=\"chair\",\ncategory=\"straight_chair\",\nmodel=\"amgwaw\",\nbounding_box=None,\nfit_avg_dim_volume=True,\nfixed_base=False,\nposition=[0.45, 0.65, 0.425],\norientation=[0, 0, -0.9990215, -0.0442276],\n)\nbox_cfg = dict(\ntype=\"PrimitiveObject\",\nname=\"box\",\nprimitive_type=\"Cube\",\nrgba=[1.0, 0, 0, 1.0],\nsize=0.05,\nposition=[0.53, -0.1, 0.97],\n)\n# Compile config\ncfg = dict(scene=scene_cfg, robots=[robot0_cfg], objects=[table_cfg, chair_cfg, box_cfg])\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Reset the robot\nrobot = env.robots[0]\nrobot.set_position([0, 0, 0])\nrobot.reset()\nrobot.keep_still()\n# Make the robot's camera(s) high-res\nfor sensor in robot.sensors.values():\nif isinstance(sensor, VisionSensor):\nsensor.image_height = 720\nsensor.image_width = 720\n# Update the simulator's viewer camera's pose so it points towards the robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-2.39951,  2.26469,  2.66227]),\norientation=np.array([-0.23898481,  0.48475231,  0.75464013, -0.37204802]),\n)\n# Create teleop controller\naction_generator = KeyboardRobotController(robot=robot)\n# Print out relevant keyboard info if using keyboard teleop\naction_generator.print_keyboard_teleop_info()\n# Other helpful user info\nprint(\"Running demo with grasping mode {}.\".format(grasping_mode))\nprint(\"Press ESC to quit\")\n# Loop control until user quits\nmax_steps = -1 if not short_exec else 100\nstep = 0\nwhile step != max_steps:\naction = action_generator.get_random_action() if random_selection else action_generator.get_teleop_action()\nfor _ in range(10):\nenv.step(action)\nstep += 1\n# Always shut down the environment cleanly at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/robots/robot_control_example.html","title":"robot_control_example","text":"<p>Example script demo'ing robot control.</p> <p>Options for random actions, as well as selection of robot action space</p>"},{"location":"reference/examples/robots/robot_control_example.html#examples.robots.robot_control_example.choose_controllers","title":"<code>choose_controllers(robot, random_selection=False)</code>","text":"<p>For a given robot, iterates over all components of the robot, and returns the requested controller type for each component.</p> <p>:param robot: BaseRobot, robot class from which to infer relevant valid controller options :param random_selection: bool, if the selection is random (for automatic demo execution). Default False</p> <p>:return dict: Mapping from individual robot component (e.g.: base, arm, etc.) to selected controller names</p> Source code in <code>omnigibson/examples/robots/robot_control_example.py</code> <pre><code>def choose_controllers(robot, random_selection=False):\n\"\"\"\n    For a given robot, iterates over all components of the robot, and returns the requested controller type for each\n    component.\n    :param robot: BaseRobot, robot class from which to infer relevant valid controller options\n    :param random_selection: bool, if the selection is random (for automatic demo execution). Default False\n    :return dict: Mapping from individual robot component (e.g.: base, arm, etc.) to selected controller names\n    \"\"\"\n# Create new dict to store responses from user\ncontroller_choices = dict()\n# Grab the default controller config so we have the registry of all possible controller options\ndefault_config = robot._default_controller_config\n# Iterate over all components in robot\nfor component, controller_options in default_config.items():\n# Select controller\noptions = list(sorted(controller_options.keys()))\nchoice = choose_from_options(\noptions=options, name=\"{} controller\".format(component), random_selection=random_selection\n)\n# Add to user responses\ncontroller_choices[component] = choice\nreturn controller_choices\n</code></pre>"},{"location":"reference/examples/robots/robot_control_example.html#examples.robots.robot_control_example.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Robot control demo with selection Queries the user to select a robot, the controllers, a scene and a type of input (random actions or teleop)</p> Source code in <code>omnigibson/examples/robots/robot_control_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Robot control demo with selection\n    Queries the user to select a robot, the controllers, a scene and a type of input (random actions or teleop)\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose scene to load\nscene_model = choose_from_options(options=SCENES, name=\"scene\", random_selection=random_selection)\n# Choose robot to create\nrobot_name = choose_from_options(\noptions=list(sorted(REGISTERED_ROBOTS.keys())), name=\"robot\", random_selection=random_selection\n)\n# Create the config for generating the environment we want\nscene_cfg = dict()\nif scene_model == \"empty\":\nscene_cfg[\"type\"] = \"Scene\"\nelse:\nscene_cfg[\"type\"] = \"InteractiveTraversableScene\"\nscene_cfg[\"scene_model\"] = scene_model\n# Add the robot we want to load\nrobot0_cfg = dict()\nrobot0_cfg[\"type\"] = robot_name\nrobot0_cfg[\"obs_modalities\"] = [\"rgb\", \"depth\", \"seg_instance\", \"normal\", \"scan\", \"occupancy_grid\"]\nrobot0_cfg[\"action_type\"] = \"continuous\"\nrobot0_cfg[\"action_normalize\"] = True\n# Compile config\ncfg = dict(scene=scene_cfg, robots=[robot0_cfg])\n# Create the environment\nenv = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n# Choose robot controller to use\nrobot = env.robots[0]\ncontroller_choices = choose_controllers(robot=robot, random_selection=random_selection)\n# Choose control mode\nif random_selection:\ncontrol_mode = \"random\"\nelse:\ncontrol_mode = choose_from_options(options=CONTROL_MODES, name=\"control mode\")\n# Update the control mode of the robot\ncontroller_config = {component: {\"name\": name} for component, name in controller_choices.items()}\nrobot.reload_controllers(controller_config=controller_config)\n# Update the simulator's viewer camera's pose so it points towards the robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([1.46949, -3.97358, 2.21529]),\norientation=np.array([0.56829048, 0.09569975, 0.13571846, 0.80589577]),\n)\n# Reset environment\nenv.reset()\n# Create teleop controller\naction_generator = KeyboardRobotController(robot=robot)\n# Print out relevant keyboard info if using keyboard teleop\nif control_mode == \"teleop\":\naction_generator.print_keyboard_teleop_info()\n# Other helpful user info\nprint(\"Running demo.\")\nprint(\"Press ESC to quit\")\n# Loop control until user quits\nmax_steps = -1 if not short_exec else 100\nstep = 0\nwhile step != max_steps:\naction = action_generator.get_random_action() if control_mode == \"random\" else action_generator.get_teleop_action()\nfor _ in range(10):\nenv.step(action=action)\nstep += 1\n# Always shut down the environment cleanly at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/robots/advanced/index.html","title":"advanced","text":""},{"location":"reference/examples/robots/advanced/ik_example.html","title":"ik_example","text":""},{"location":"reference/examples/robots/advanced/ik_example.html#examples.robots.advanced.ik_example.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Minimal example of usage of inverse kinematics solver</p> <p>This example showcases how to construct your own IK functionality using omniverse's native lula library without explicitly utilizing all of OmniGibson's class abstractions, and also showcases how to manipulate the simulator at a lower-level than the main Environment entry point.</p> Source code in <code>omnigibson/examples/robots/advanced/ik_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Minimal example of usage of inverse kinematics solver\n    This example showcases how to construct your own IK functionality using omniverse's native lula library\n    without explicitly utilizing all of OmniGibson's class abstractions, and also showcases how to manipulate\n    the simulator at a lower-level than the main Environment entry point.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Assuming that if random_selection=True, headless=True, short_exec=True, we are calling it from tests and we\n# do not want to parse args (it would fail because the calling function is pytest \"testfile.py\")\nif not (random_selection and headless and short_exec):\nparser = argparse.ArgumentParser()\nparser.add_argument(\n\"--programmatic\",\n\"-p\",\ndest=\"programmatic_pos\",\naction=\"store_true\",\nhelp=\"if the IK solvers should be used with the GUI or programmatically\",\n)\nargs = parser.parse_args()\nprogrammatic_pos = args.programmatic_pos\nelse:\nprogrammatic_pos = True\n# Import scene and robot (Fetch)\nscene = Scene()\nog.sim.import_scene(scene)\n# Update the viewer camera's pose so that it points towards the robot\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([4.32248, -5.74338, 6.85436]),\norientation=np.array([0.39592, 0.13485, 0.29286, 0.85982]),\n)\n# Create Fetch robot\n# Note that since we only care about IK functionality, we fix the base (this also makes the robot more stable)\n# (any object can also have its fixed_base attribute set to True!)\n# Note that since we're going to be setting joint position targets, we also need to make sure the robot's arm joints\n# (which includes the trunk) are being controlled using joint positions\nrobot = Fetch(\nprim_path=\"/World/robot\",\nname=\"robot\",\nfixed_base=True,\ncontroller_config={\n\"arm_0\": {\n\"name\": \"JointController\",\n\"motor_type\": \"position\",\n}\n}\n)\nog.sim.import_object(robot)\n# Set robot base at the origin\nrobot.set_position_orientation(np.array([0, 0, 0]), np.array([0, 0, 0, 1]))\n# At least one simulation step while the simulator is playing must occur for the robot (or in general, any object)\n# to be fully initialized after it is imported into the simulator\nog.sim.play()\nog.sim.step()\n# Make sure none of the joints are moving\nrobot.keep_still()\n# Create the IK solver -- note that we are controlling both the trunk and the arm since both are part of the\n# controllable kinematic chain for the end-effector!\ncontrol_idx = np.concatenate([robot.trunk_control_idx, robot.arm_control_idx[robot.default_arm]])\nik_solver = IKSolver(\nrobot_description_path=robot.robot_arm_descriptor_yamls[robot.default_arm],\nrobot_urdf_path=robot.urdf_path,\ndefault_joint_pos=robot.get_joint_positions()[control_idx],\neef_name=robot.eef_link_names[robot.default_arm],\n)\n# Define a helper function for executing specific end-effector commands using the ik solver\ndef execute_ik(pos, quat=None, max_iter=100):\nog.log.info(\"Querying joint configuration to current marker position\")\n# Grab the joint positions in order to reach the desired pose target\njoint_pos = ik_solver.solve(\ntarget_pos=pos,\ntarget_quat=quat,\nmax_iterations=max_iter,\n)\nif joint_pos is not None:\nog.log.info(\"Solution found. Setting new arm configuration.\")\nrobot.set_joint_positions(joint_pos, indices=control_idx, drive=True)\nelse:\nog.log.info(\"EE position not reachable.\")\nog.sim.step()\nif programmatic_pos or headless:\n# Sanity check IK using pre-defined hardcoded positions\nquery_positions = [[1, 0, 0.8], [1, 1, 1], [0.5, 0.5, 0], [0.5, 0.5, 0.5]]\nfor query_pos in query_positions:\nexecute_ik(query_pos)\ntime.sleep(2)\nelse:\n# Create a visual marker to be moved by the user, representing desired end-effector position\nmarker = PrimitiveObject(\nprim_path=f\"/World/marker\",\nname=\"marker\",\nprimitive_type=\"Sphere\",\nradius=0.03,\nvisual_only=True,\nrgba=[1.0, 0, 0, 1.0],\n)\nog.sim.import_object(marker)\n# Get initial EE position and set marker to that location\ncommand = robot.get_eef_position()\nmarker.set_position(command)\nog.sim.step()\n# Setup callbacks for grabbing keyboard inputs from omni\nexit_now = False\ndef keyboard_event_handler(event, *args, **kwargs):\nnonlocal command, exit_now\n# Check if we've received a key press or repeat\nif event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                    or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\nif event.input == carb.input.KeyboardInput.ENTER:\n# Execute the command\nexecute_ik(pos=command)\nelif event.input == carb.input.KeyboardInput.ESCAPE:\n# Quit\nog.log.info(\"Quit.\")\nexit_now = True\nelse:\n# We see if we received a valid delta command, and if so, we update our command and visualized\n# marker position\ndelta_cmd = input_to_xyz_delta_command(inp=event.input)\nif delta_cmd is not None:\ncommand = command + delta_cmd\nmarker.set_position(command)\nog.sim.step()\n# Callback must return True if valid\nreturn True\n# Hook up the callback function with omni's user interface\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\nsub_keyboard = input_interface.subscribe_to_keyboard_events(keyboard, keyboard_event_handler)\n# Print out helpful information to the user\nprint_message()\n# Loop until the user requests an exit\nwhile not exit_now:\nog.sim.step()\n# Always shut the simulation down cleanly at the end\nog.app.close()\n</code></pre>"},{"location":"reference/examples/scenes/index.html","title":"scenes","text":""},{"location":"reference/examples/scenes/scene_selector.html","title":"scene_selector","text":""},{"location":"reference/examples/scenes/scene_selector.html#examples.scenes.scene_selector.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select any available interactive scene and loads a turtlebot into it. It steps the environment 100 times with random actions sampled from the action space, using the Gym interface, resetting it 10 times.</p> Source code in <code>omnigibson/examples/scenes/scene_selector.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select any available interactive scene and loads a turtlebot into it.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Choose the scene type to load\nscene_options = {\n\"InteractiveTraversableScene\": \"Procedurally generated scene with fully interactive objects\",\n# \"StaticTraversableScene\": \"Monolithic scene mesh with no interactive objects\",\n}\nscene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n# Choose the scene model to load\nscenes = get_available_og_scenes() if scene_type == \"InteractiveTraversableScene\" else get_available_g_scenes()\nscene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\ncfg = {\n\"scene\": {\n\"type\": scene_type,\n\"scene_model\": scene_model,\n},\n\"robots\": [\n{\n\"type\": \"Turtlebot\",\n\"obs_modalities\": [\"scan\", \"rgb\", \"depth\"],\n\"action_type\": \"continuous\",\n\"action_normalize\": True,\n},\n],\n}\n# If the scene type is interactive, also check if we want to quick load or full load the scene\nif scene_type == \"InteractiveTraversableScene\":\nload_options = {\n\"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n\"Full\": \"Load all interactive objects in the scene\",\n}\nload_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\nif load_mode == \"Quick\":\ncfg[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n# Load the environment\nenv = og.Environment(configs=cfg)\n# Allow user to move camera more easily\nif not gm.HEADLESS:\nog.sim.enable_viewer_camera_teleoperation()\n# Run a simple loop and reset periodically\nmax_iterations = 10 if not short_exec else 1\nfor j in range(max_iterations):\nog.log.info(\"Resetting environment\")\nenv.reset()\nfor i in range(100):\naction = env.action_space.sample()\nstate, reward, done, info = env.step(action)\nif done:\nog.log.info(\"Episode finished after {} timesteps\".format(i + 1))\nbreak\n# Always close the environment at the end\nenv.close()\n</code></pre>"},{"location":"reference/examples/scenes/scene_tour_demo.html","title":"scene_tour_demo","text":""},{"location":"reference/examples/scenes/scene_tour_demo.html#examples.scenes.scene_tour_demo.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select any available interactive scene and loads it.</p> <p>It sets the camera to various poses and records images, and then generates a trajectory from a set of waypoints and records the resulting video.</p> Source code in <code>omnigibson/examples/scenes/scene_tour_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select any available interactive scene and loads it.\n    It sets the camera to various poses and records images, and then generates a trajectory from a set of waypoints\n    and records the resulting video.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\n# Make sure the example is not being run headless. If so, terminate early\nif gm.HEADLESS:\nprint(\"This demo should only be run not headless! Exiting early.\")\nog.shutdown()\n# Choose the scene type to load\nscene_options = {\n\"InteractiveTraversableScene\": \"Procedurally generated scene with fully interactive objects\",\n# \"StaticTraversableScene\": \"Monolithic scene mesh with no interactive objects\",\n}\nscene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n# Choose the scene model to load\nscenes = get_available_og_scenes() if scene_type == \"InteractiveTraversableScene\" else get_available_g_scenes()\nscene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\nprint(f\"scene model: {scene_model}\")\ncfg = {\n\"scene\": {\n\"type\": scene_type,\n\"scene_model\": scene_model,\n},\n}\n# If the scene type is interactive, also check if we want to quick load or full load the scene\nif scene_type == \"InteractiveTraversableScene\":\nload_options = {\n\"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n\"Full\": \"Load all interactive objects in the scene\",\n}\nload_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\nif load_mode == \"Quick\":\ncfg[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n# Load the environment\nenv = og.Environment(configs=cfg)\n# Allow user to teleoperate the camera\ncam_mover = og.sim.enable_viewer_camera_teleoperation()\n# Create a keyboard event handler for generating waypoints\nwaypoints = []\ndef add_waypoint():\nnonlocal waypoints\npos = cam_mover.cam.get_position()\nprint(f\"Added waypoint at {pos}\")\nwaypoints.append(pos)\ndef clear_waypoints():\nnonlocal waypoints\nprint(f\"Cleared all waypoints!\")\nwaypoints = []\nKeyboardEventHandler.initialize()\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.X,\ncallback_fn=add_waypoint,\n)\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.C,\ncallback_fn=clear_waypoints,\n)\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.J,\ncallback_fn=lambda: cam_mover.record_trajectory_from_waypoints(\nwaypoints=np.array(waypoints),\nper_step_distance=0.02,\nfps=30,\nsteps_per_frame=1,\nfpath=None,             # This corresponds to the default path inferred from cam_mover.save_dir\n),\n)\nKeyboardEventHandler.add_keyboard_callback(\nkey=carb.input.KeyboardInput.ESCAPE,\ncallback_fn=lambda: env.close(),\n)\n# Print out additional keyboard commands\nprint(f\"\\t X: Save the current camera pose as a waypoint\")\nprint(f\"\\t C: Clear all waypoints\")\nprint(f\"\\t J: Record the camera trajectory from the current set of waypoints\")\nprint(f\"\\t ESC: Terminate the demo\")\n# Loop indefinitely\nwhile True:\nenv.step([])\n</code></pre>"},{"location":"reference/examples/scenes/traversability_map_example.html","title":"traversability_map_example","text":""},{"location":"reference/examples/scenes/traversability_map_example.html#examples.scenes.traversability_map_example.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Traversable map demo Loads the floor plan and obstacles for the requested scene, and overlays them in a visual figure such that the highlighted area reflects the traversable (free-space) area</p> Source code in <code>omnigibson/examples/scenes/traversability_map_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Traversable map demo\n    Loads the floor plan and obstacles for the requested scene, and overlays them in a visual figure such that the\n    highlighted area reflects the traversable (free-space) area\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\nscenes = get_available_og_scenes()\nscene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\nprint(f\"Generating traversability map for scene {scene_model}\")\ntrav_map_size = 200\ntrav_map_erosion = 2\ntrav_map = Image.open(os.path.join(get_og_scene_path(scene_model), \"layout\", \"floor_trav_0.png\"))\ntrav_map = np.array(trav_map.resize((trav_map_size, trav_map_size)))\ntrav_map = cv2.erode(trav_map, np.ones((trav_map_erosion, trav_map_erosion)))\nif not headless:\nplt.figure(figsize=(12, 12))\nplt.imshow(trav_map)\nplt.title(f\"Traversable area of {scene_model} scene\")\nif not headless:\nplt.show()\n# Shut down omnigibson at the end\nog.shutdown()\n</code></pre>"},{"location":"reference/examples/simulator/index.html","title":"simulator","text":""},{"location":"reference/examples/simulator/sim_save_load_example.html","title":"sim_save_load_example","text":""},{"location":"reference/examples/simulator/sim_save_load_example.html#examples.simulator.sim_save_load_example.main","title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select whether they are saving or loading an environment, and interactively shows how an environment can be saved or restored.</p> Source code in <code>omnigibson/examples/simulator/sim_save_load_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n\"\"\"\n    Prompts the user to select whether they are saving or loading an environment, and interactively\n    shows how an environment can be saved or restored.\n    \"\"\"\nog.log.info(f\"Demo {__file__}\\n    \" + \"*\" * 80 + \"\\n    Description:\\n\" + main.__doc__ + \"*\" * 80)\ncfg = {\n\"scene\": {\n\"type\": \"InteractiveTraversableScene\",\n\"scene_model\": \"Rs_int\",\n\"load_object_categories\": [\"floors\", \"walls\", \"bed\", \"bottom_cabinet\", \"chair\"],\n},\n\"robots\": [\n{\n\"type\": \"Turtlebot\",\n\"obs_modalities\": [\"rgb\", \"depth\"],\n},\n],\n}\n# Create the environment\nenv = og.Environment(configs=cfg)\n# Set the camera to a good angle\ndef set_camera_pose():\nog.sim.viewer_camera.set_position_orientation(\nposition=np.array([-0.229375, -3.40576 ,  7.26143 ]),\norientation=np.array([ 0.27619733, -0.00230233, -0.00801152,  0.9610648 ]),\n)\nset_camera_pose()\n# Give user instructions, and then loop until completed\ncompleted = short_exec\nif not short_exec and not random_selection:\n# Notify user to manipulate environment until ready, then press Z to exit\nprint()\nprint(\"Modify the scene by SHIFT + left clicking objects and dragging them. Once finished, press Z.\")\n# Register callback so user knows to press space once they're done manipulating the scene\ndef complete_loop():\nnonlocal completed\ncompleted = True\nKeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\nwhile not completed:\nenv.step(np.random.uniform(-1, 1, env.robots[0].action_dim))\nprint(\"Completed scene modification, saving scene...\")\nsave_path = os.path.join(TEST_OUT_PATH, \"saved_stage.json\")\nog.sim.save(json_path=save_path)\nprint(\"Re-loading scene...\")\nog.sim.restore(json_path=save_path)\n# Take a sim step and play\nog.sim.step()\nog.sim.play()\nset_camera_pose()\n# Loop until user terminates\ncompleted = short_exec\nif not short_exec and not random_selection:\n# Notify user to manipulate environment until ready, then press Z to exit\nprint()\nprint(\"View reloaded scene. Once finished, press Z.\")\n# Register callback so user knows to press space once they're done manipulating the scene\nKeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\nwhile not completed:\nenv.step(np.zeros(env.robots[0].action_dim))\n# Shutdown omnigibson at the end\nog.shutdown()\n</code></pre>"},{"location":"reference/maps/index.html","title":"maps","text":""},{"location":"reference/maps/map_base.html","title":"map_base","text":""},{"location":"reference/maps/map_base.html#maps.map_base.BaseMap","title":"<code>BaseMap</code>","text":"<p>Base map class. Contains basic interface for converting from map to world frame, and vise-versa</p> Source code in <code>omnigibson/maps/map_base.py</code> <pre><code>class BaseMap:\n\"\"\"\n    Base map class.\n    Contains basic interface for converting from map to world frame, and vise-versa\n    \"\"\"\ndef __init__(\nself,\nmap_resolution=0.1,\n):\n\"\"\"\n        Args:\n            map_resolution (float): map resolution\n        \"\"\"\n# Set internal values\nself.map_resolution = map_resolution\nself.map_size = None\ndef load_map(self, *args, **kwargs):\n\"\"\"\n        Load's this map internally\n        \"\"\"\n# Run internal method and store map size\nself.map_size = self._load_map(*args, **kwargs)\ndef _load_map(self, *args, **kwargs):\n\"\"\"\n        Arbitrary function to load this map. Should be implemented by subclass\n        Returns:\n            int: Size of the loaded map\n        \"\"\"\nraise NotImplementedError()\ndef map_to_world(self, xy):\n\"\"\"\n        Transforms a 2D point in map reference frame into world (simulator) reference frame\n        Args:\n            xy (2-array or (N, 2)-array): 2D location(s) in map reference frame (in image pixel space)\n        Returns:\n            2-array or (N, 2)-array: 2D location(s) in world reference frame (in metric space)\n        \"\"\"\naxis = 0 if len(xy.shape) == 1 else 1\nreturn np.flip((xy - self.map_size / 2.0) * self.map_resolution, axis=axis)\ndef world_to_map(self, xy):\n\"\"\"\n        Transforms a 2D point in world (simulator) reference frame into map reference frame\n            xy: 2D location in world reference frame (metric)\n        :return: 2D location in map reference frame (image)\n        \"\"\"\nreturn np.flip((np.array(xy) / self.map_resolution + self.map_size / 2.0)).astype(np.int)\n</code></pre>"},{"location":"reference/maps/map_base.html#maps.map_base.BaseMap.__init__","title":"<code>__init__(map_resolution=0.1)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>map_resolution</code> <code>float</code> <p>map resolution</p> <code>0.1</code> Source code in <code>omnigibson/maps/map_base.py</code> <pre><code>def __init__(\nself,\nmap_resolution=0.1,\n):\n\"\"\"\n    Args:\n        map_resolution (float): map resolution\n    \"\"\"\n# Set internal values\nself.map_resolution = map_resolution\nself.map_size = None\n</code></pre>"},{"location":"reference/maps/map_base.html#maps.map_base.BaseMap.load_map","title":"<code>load_map(*args, **kwargs)</code>","text":"<p>Load's this map internally</p> Source code in <code>omnigibson/maps/map_base.py</code> <pre><code>def load_map(self, *args, **kwargs):\n\"\"\"\n    Load's this map internally\n    \"\"\"\n# Run internal method and store map size\nself.map_size = self._load_map(*args, **kwargs)\n</code></pre>"},{"location":"reference/maps/map_base.html#maps.map_base.BaseMap.map_to_world","title":"<code>map_to_world(xy)</code>","text":"<p>Transforms a 2D point in map reference frame into world (simulator) reference frame</p> <p>Parameters:</p> Name Type Description Default <code>xy</code> <code>2-array or (N, 2)-array</code> <p>2D location(s) in map reference frame (in image pixel space)</p> required <p>Returns:</p> Type Description <p>2-array or (N, 2)-array: 2D location(s) in world reference frame (in metric space)</p> Source code in <code>omnigibson/maps/map_base.py</code> <pre><code>def map_to_world(self, xy):\n\"\"\"\n    Transforms a 2D point in map reference frame into world (simulator) reference frame\n    Args:\n        xy (2-array or (N, 2)-array): 2D location(s) in map reference frame (in image pixel space)\n    Returns:\n        2-array or (N, 2)-array: 2D location(s) in world reference frame (in metric space)\n    \"\"\"\naxis = 0 if len(xy.shape) == 1 else 1\nreturn np.flip((xy - self.map_size / 2.0) * self.map_resolution, axis=axis)\n</code></pre>"},{"location":"reference/maps/map_base.html#maps.map_base.BaseMap.world_to_map","title":"<code>world_to_map(xy)</code>","text":"<p>Transforms a 2D point in world (simulator) reference frame into map reference frame</p> <pre><code>xy: 2D location in world reference frame (metric)\n</code></pre> <p>:return: 2D location in map reference frame (image)</p> Source code in <code>omnigibson/maps/map_base.py</code> <pre><code>def world_to_map(self, xy):\n\"\"\"\n    Transforms a 2D point in world (simulator) reference frame into map reference frame\n        xy: 2D location in world reference frame (metric)\n    :return: 2D location in map reference frame (image)\n    \"\"\"\nreturn np.flip((np.array(xy) / self.map_resolution + self.map_size / 2.0)).astype(np.int)\n</code></pre>"},{"location":"reference/maps/segmentation_map.html","title":"segmentation_map","text":""},{"location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap","title":"<code>SegmentationMap</code>","text":"<p>         Bases: <code>BaseMap</code></p> <p>Segmentation map for computing connectivity within the scene</p> Source code in <code>omnigibson/maps/segmentation_map.py</code> <pre><code>class SegmentationMap(BaseMap):\n\"\"\"\n    Segmentation map for computing connectivity within the scene\n    \"\"\"\ndef __init__(\nself,\nscene_dir,\nmap_resolution=0.1,\nfloor_heights=(0.0,),\n):\n\"\"\"\n        Args:\n            scene_dir (str): path to the scene directory from which segmentation info will be extracted\n            map_resolution (float): map resolution\n            floor_heights (list of float): heights of the floors for this segmentation map\n        \"\"\"\n# Store internal values\nself.scene_dir = scene_dir\nself.map_default_resolution = 0.01\nself.floor_heights = floor_heights\n# Other values that will be loaded at runtime\nself.room_sem_name_to_sem_id = None\nself.room_sem_id_to_sem_name = None\nself.room_ins_name_to_ins_id = None\nself.room_ins_id_to_ins_name = None\nself.room_sem_name_to_ins_name = None\nself.room_ins_map = None\nself.room_sem_map = None\n# Run super call\nsuper().__init__(map_resolution=map_resolution)\n# Load the map\nself.load_map()\ndef _load_map(self):\nlayout_dir = os.path.join(self.scene_dir, \"layout\")\nroom_seg_imgs = os.path.join(layout_dir, \"floor_insseg_0.png\")\nimg_ins = Image.open(room_seg_imgs)\nroom_seg_imgs = os.path.join(layout_dir, \"floor_semseg_0.png\")\nimg_sem = Image.open(room_seg_imgs)\nheight, width = img_ins.size\nassert height == width, \"room seg map is not a square\"\nassert img_ins.size == img_sem.size, \"semantic and instance seg maps have different sizes\"\nmap_size = int(height * self.map_default_resolution / self.map_resolution)\nimg_ins = np.array(img_ins.resize((map_size, map_size), Image.NEAREST))\nimg_sem = np.array(img_sem.resize((map_size, map_size), Image.NEAREST))\nroom_categories = os.path.join(gm.DATASET_PATH, \"metadata\", \"room_categories.txt\")\nwith open(room_categories, \"r\") as fp:\nroom_cats = [line.rstrip() for line in fp.readlines()]\nsem_id_to_ins_id = {}\nunique_ins_ids = np.unique(img_ins)\nunique_ins_ids = np.delete(unique_ins_ids, 0)\nfor ins_id in unique_ins_ids:\n# find one pixel for each ins id\nx, y = np.where(img_ins == ins_id)\n# retrieve the correspounding sem id\nsem_id = img_sem[x[0], y[0]]\nif sem_id not in sem_id_to_ins_id:\nsem_id_to_ins_id[sem_id] = []\nsem_id_to_ins_id[sem_id].append(ins_id)\nroom_sem_name_to_sem_id = {}\nroom_ins_name_to_ins_id = {}\nroom_sem_name_to_ins_name = {}\nfor sem_id, ins_ids in sem_id_to_ins_id.items():\nsem_name = room_cats[sem_id - 1]\nroom_sem_name_to_sem_id[sem_name] = sem_id\nfor i, ins_id in enumerate(ins_ids):\n# valid class start from 1\nins_name = \"{}_{}\".format(sem_name, i)\nroom_ins_name_to_ins_id[ins_name] = ins_id\nif sem_name not in room_sem_name_to_ins_name:\nroom_sem_name_to_ins_name[sem_name] = []\nroom_sem_name_to_ins_name[sem_name].append(ins_name)\nself.room_sem_name_to_sem_id = room_sem_name_to_sem_id\nself.room_sem_id_to_sem_name = {value: key for key, value in room_sem_name_to_sem_id.items()}\nself.room_ins_name_to_ins_id = room_ins_name_to_ins_id\nself.room_ins_id_to_ins_name = {value: key for key, value in room_ins_name_to_ins_id.items()}\nself.room_sem_name_to_ins_name = room_sem_name_to_ins_name\nself.room_ins_map = img_ins\nself.room_sem_map = img_sem\nreturn map_size\ndef get_random_point_by_room_type(self, room_type):\n\"\"\"\n        Sample a random point on the given a specific room type @room_type.\n        Args:\n            room_type (str): Room type to sample random point (e.g.: \"bathroom\")\n        Returns:\n            2-tuple:\n                - int: floor number. This is always 0\n                - 3-array: (x,y,z) randomly sampled point in a room of type @room_type\n        \"\"\"\nif room_type not in self.room_sem_name_to_sem_id:\nlog.warning(\"room_type [{}] does not exist.\".format(room_type))\nreturn None, None\nsem_id = self.room_sem_name_to_sem_id[room_type]\nvalid_idx = np.array(np.where(self.room_sem_map == sem_id))\nrandom_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\nx, y = self.map_to_world(random_point_map)\n# assume only 1 floor\nfloor = 0\nz = self.floor_heights[floor]\nreturn floor, np.array([x, y, z])\ndef get_random_point_by_room_instance(self, room_instance):\n\"\"\"\n        Sample a random point on the given a specific room instance @room_instance.\n        Args:\n            room_instance (str): Room instance to sample random point (e.g.: \"bathroom_1\")\n        Returns:\n            2-tuple:\n                - int: floor number. This is always 0\n                - 3-array: (x,y,z) randomly sampled point in room @room_instance\n        \"\"\"\nif room_instance not in self.room_ins_name_to_ins_id:\nlog.warning(\"room_instance [{}] does not exist.\".format(room_instance))\nreturn None, None\nins_id = self.room_ins_name_to_ins_id[room_instance]\nvalid_idx = np.array(np.where(self.room_ins_map == ins_id))\nrandom_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\nx, y = self.map_to_world(random_point_map)\n# assume only 1 floor\nfloor = 0\nz = self.floor_heights[floor]\nreturn floor, np.array([x, y, z])\ndef get_room_type_by_point(self, xy):\n\"\"\"\n        Return the room type given a point\n        Args:\n            xy (2-array): 2D location in world reference frame (in metric space)\n        Returns:\n            None or str: room type that this point is in or None, if this point is not on the room segmentation map\n        \"\"\"\nx, y = self.world_to_map(xy)\nif x &lt; 0 or x &gt;= self.room_sem_map.shape[0] or y &lt; 0 or y &gt;= self.room_sem_map.shape[1]:\nreturn None\nsem_id = self.room_sem_map[x, y]\n# room boundary\nif sem_id == 0:\nreturn None\nelse:\nreturn self.room_sem_id_to_sem_name[sem_id]\ndef get_room_instance_by_point(self, xy):\n\"\"\"\n        Return the room type given a point\n        Args:\n            xy (2-array): 2D location in world reference frame (in metric space)\n        Returns:\n            None or str: room instance that this point is in or None, if this point is not on the room segmentation map\n        \"\"\"\nx, y = self.world_to_map(xy)\nif x &lt; 0 or x &gt;= self.room_ins_map.shape[0] or y &lt; 0 or y &gt;= self.room_ins_map.shape[1]:\nreturn None\nins_id = self.room_ins_map[x, y]\n# room boundary\nif ins_id == 0:\nreturn None\nelse:\nreturn self.room_ins_id_to_ins_name[ins_id]\n</code></pre>"},{"location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.__init__","title":"<code>__init__(scene_dir, map_resolution=0.1, floor_heights=(0.0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>scene_dir</code> <code>str</code> <p>path to the scene directory from which segmentation info will be extracted</p> required <code>map_resolution</code> <code>float</code> <p>map resolution</p> <code>0.1</code> <code>floor_heights</code> <code>list of float</code> <p>heights of the floors for this segmentation map</p> <code>(0.0)</code> Source code in <code>omnigibson/maps/segmentation_map.py</code> <pre><code>def __init__(\nself,\nscene_dir,\nmap_resolution=0.1,\nfloor_heights=(0.0,),\n):\n\"\"\"\n    Args:\n        scene_dir (str): path to the scene directory from which segmentation info will be extracted\n        map_resolution (float): map resolution\n        floor_heights (list of float): heights of the floors for this segmentation map\n    \"\"\"\n# Store internal values\nself.scene_dir = scene_dir\nself.map_default_resolution = 0.01\nself.floor_heights = floor_heights\n# Other values that will be loaded at runtime\nself.room_sem_name_to_sem_id = None\nself.room_sem_id_to_sem_name = None\nself.room_ins_name_to_ins_id = None\nself.room_ins_id_to_ins_name = None\nself.room_sem_name_to_ins_name = None\nself.room_ins_map = None\nself.room_sem_map = None\n# Run super call\nsuper().__init__(map_resolution=map_resolution)\n# Load the map\nself.load_map()\n</code></pre>"},{"location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_random_point_by_room_instance","title":"<code>get_random_point_by_room_instance(room_instance)</code>","text":"<p>Sample a random point on the given a specific room instance @room_instance.</p> <p>Parameters:</p> Name Type Description Default <code>room_instance</code> <code>str</code> <p>Room instance to sample random point (e.g.: \"bathroom_1\")</p> required <p>Returns:</p> Type Description <p>2-tuple: - int: floor number. This is always 0 - 3-array: (x,y,z) randomly sampled point in room @room_instance</p> Source code in <code>omnigibson/maps/segmentation_map.py</code> <pre><code>def get_random_point_by_room_instance(self, room_instance):\n\"\"\"\n    Sample a random point on the given a specific room instance @room_instance.\n    Args:\n        room_instance (str): Room instance to sample random point (e.g.: \"bathroom_1\")\n    Returns:\n        2-tuple:\n            - int: floor number. This is always 0\n            - 3-array: (x,y,z) randomly sampled point in room @room_instance\n    \"\"\"\nif room_instance not in self.room_ins_name_to_ins_id:\nlog.warning(\"room_instance [{}] does not exist.\".format(room_instance))\nreturn None, None\nins_id = self.room_ins_name_to_ins_id[room_instance]\nvalid_idx = np.array(np.where(self.room_ins_map == ins_id))\nrandom_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\nx, y = self.map_to_world(random_point_map)\n# assume only 1 floor\nfloor = 0\nz = self.floor_heights[floor]\nreturn floor, np.array([x, y, z])\n</code></pre>"},{"location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_random_point_by_room_type","title":"<code>get_random_point_by_room_type(room_type)</code>","text":"<p>Sample a random point on the given a specific room type @room_type.</p> <p>Parameters:</p> Name Type Description Default <code>room_type</code> <code>str</code> <p>Room type to sample random point (e.g.: \"bathroom\")</p> required <p>Returns:</p> Type Description <p>2-tuple: - int: floor number. This is always 0 - 3-array: (x,y,z) randomly sampled point in a room of type @room_type</p> Source code in <code>omnigibson/maps/segmentation_map.py</code> <pre><code>def get_random_point_by_room_type(self, room_type):\n\"\"\"\n    Sample a random point on the given a specific room type @room_type.\n    Args:\n        room_type (str): Room type to sample random point (e.g.: \"bathroom\")\n    Returns:\n        2-tuple:\n            - int: floor number. This is always 0\n            - 3-array: (x,y,z) randomly sampled point in a room of type @room_type\n    \"\"\"\nif room_type not in self.room_sem_name_to_sem_id:\nlog.warning(\"room_type [{}] does not exist.\".format(room_type))\nreturn None, None\nsem_id = self.room_sem_name_to_sem_id[room_type]\nvalid_idx = np.array(np.where(self.room_sem_map == sem_id))\nrandom_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\nx, y = self.map_to_world(random_point_map)\n# assume only 1 floor\nfloor = 0\nz = self.floor_heights[floor]\nreturn floor, np.array([x, y, z])\n</code></pre>"},{"location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_room_instance_by_point","title":"<code>get_room_instance_by_point(xy)</code>","text":"<p>Return the room type given a point</p> <p>Parameters:</p> Name Type Description Default <code>xy</code> <code>2-array</code> <p>2D location in world reference frame (in metric space)</p> required <p>Returns:</p> Type Description <p>None or str: room instance that this point is in or None, if this point is not on the room segmentation map</p> Source code in <code>omnigibson/maps/segmentation_map.py</code> <pre><code>def get_room_instance_by_point(self, xy):\n\"\"\"\n    Return the room type given a point\n    Args:\n        xy (2-array): 2D location in world reference frame (in metric space)\n    Returns:\n        None or str: room instance that this point is in or None, if this point is not on the room segmentation map\n    \"\"\"\nx, y = self.world_to_map(xy)\nif x &lt; 0 or x &gt;= self.room_ins_map.shape[0] or y &lt; 0 or y &gt;= self.room_ins_map.shape[1]:\nreturn None\nins_id = self.room_ins_map[x, y]\n# room boundary\nif ins_id == 0:\nreturn None\nelse:\nreturn self.room_ins_id_to_ins_name[ins_id]\n</code></pre>"},{"location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_room_type_by_point","title":"<code>get_room_type_by_point(xy)</code>","text":"<p>Return the room type given a point</p> <p>Parameters:</p> Name Type Description Default <code>xy</code> <code>2-array</code> <p>2D location in world reference frame (in metric space)</p> required <p>Returns:</p> Type Description <p>None or str: room type that this point is in or None, if this point is not on the room segmentation map</p> Source code in <code>omnigibson/maps/segmentation_map.py</code> <pre><code>def get_room_type_by_point(self, xy):\n\"\"\"\n    Return the room type given a point\n    Args:\n        xy (2-array): 2D location in world reference frame (in metric space)\n    Returns:\n        None or str: room type that this point is in or None, if this point is not on the room segmentation map\n    \"\"\"\nx, y = self.world_to_map(xy)\nif x &lt; 0 or x &gt;= self.room_sem_map.shape[0] or y &lt; 0 or y &gt;= self.room_sem_map.shape[1]:\nreturn None\nsem_id = self.room_sem_map[x, y]\n# room boundary\nif sem_id == 0:\nreturn None\nelse:\nreturn self.room_sem_id_to_sem_name[sem_id]\n</code></pre>"},{"location":"reference/maps/traversable_map.html","title":"traversable_map","text":""},{"location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap","title":"<code>TraversableMap</code>","text":"<p>         Bases: <code>BaseMap</code></p> <p>Traversable scene class. Contains the functionalities for navigation such as shortest path computation</p> Source code in <code>omnigibson/maps/traversable_map.py</code> <pre><code>class TraversableMap(BaseMap):\n\"\"\"\n    Traversable scene class.\n    Contains the functionalities for navigation such as shortest path computation\n    \"\"\"\ndef __init__(\nself,\nmap_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\n):\n\"\"\"\n        Args:\n            map_resolution (float): map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n        \"\"\"\n# Set internal values\nself.map_default_resolution = 0.01  # each pixel represents 0.01m\nself.trav_map_erosion = trav_map_erosion\nself.trav_map_with_objects = trav_map_with_objects\nself.build_graph = build_graph\nself.num_waypoints = num_waypoints\nself.waypoint_interval = int(waypoint_resolution / map_resolution)\n# Values loaded at runtime\nself.trav_map_original_size = None\nself.trav_map_size = None\nself.mesh_body_id = None\nself.floor_heights = None\nself.floor_map = None\nself.floor_graph = None\n# Run super method\nsuper().__init__(map_resolution=map_resolution)\ndef _load_map(self, maps_path, floor_heights=(0.0,)):\n\"\"\"\n        Loads the traversability maps for all floors\n        Args:\n            maps_path (str): Path to the folder containing the traversability maps\n            floor_heights (n-array): Height(s) of the floors for this map\n        Returns:\n            int: Size of the loaded map\n        \"\"\"\nif not os.path.exists(maps_path):\nlog.warning(\"trav map does not exist: {}\".format(maps_path))\nreturn\nself.floor_heights = floor_heights\nself.floor_map = []\nmap_size = None\nfor floor in range(len(self.floor_heights)):\nif self.trav_map_with_objects:\n# TODO: Shouldn't this be generated dynamically?\ntrav_map = np.array(Image.open(os.path.join(maps_path, \"floor_trav_{}.png\".format(floor))))\nelse:\ntrav_map = np.array(Image.open(os.path.join(maps_path, \"floor_trav_no_obj_{}.png\".format(floor))))\n# If we do not initialize the original size of the traversability map, we obtain it from the image\n# Then, we compute the final map size as the factor of scaling (default_resolution/resolution) times the\n# original map size\nif self.trav_map_original_size is None:\nheight, width = trav_map.shape\nassert height == width, \"trav map is not a square\"\nself.trav_map_original_size = height\nmap_size = int(\nself.trav_map_original_size * self.map_default_resolution / self.map_resolution\n)\n# We resize the traversability map to the new size computed before\ntrav_map = cv2.resize(trav_map, (map_size, map_size))\n# We then erode the image. This is needed because the code that computes shortest path uses the global map\n# and a point robot\nif self.trav_map_erosion != 0:\ntrav_map = cv2.erode(trav_map, np.ones((self.trav_map_erosion, self.trav_map_erosion)))\n# We make the pixels of the image to be either 0 or 255\ntrav_map[trav_map &lt; 255] = 0\n# We search for the largest connected areas\nif self.build_graph:\n# Directly set map siz\nself.floor_graph = self.build_trav_graph(map_size, maps_path, floor, trav_map)\nself.floor_map.append(trav_map)\nreturn map_size\n# TODO: refactor into C++ for speedup\n@staticmethod\ndef build_trav_graph(map_size, maps_path, floor, trav_map):\n\"\"\"\n        Build traversibility graph and only take the largest connected component\n        Args:\n            map_size (int): Size of the map being generated\n            maps_path (str): Path to the folder containing the traversability maps\n            floor (int): floor number\n            trav_map ((H, W)-array): traversability map in image form\n        \"\"\"\nfloor_graph = []\ngraph_file = os.path.join(\nmaps_path, \"floor_trav_{}_py{}{}.p\".format(floor, sys.version_info.major, sys.version_info.minor)\n)\nif os.path.isfile(graph_file):\nlog.info(\"Loading traversable graph\")\nwith open(graph_file, \"rb\") as pfile:\ng = pickle.load(pfile)\nelse:\nlog.info(\"Building traversable graph\")\ng = nx.Graph()\nfor i in range(map_size):\nfor j in range(map_size):\nif trav_map[i, j] == 0:\ncontinue\ng.add_node((i, j))\n# 8-connected graph\nneighbors = [(i - 1, j - 1), (i, j - 1), (i + 1, j - 1), (i - 1, j)]\nfor n in neighbors:\nif (\n0 &lt;= n[0] &lt; map_size\nand 0 &lt;= n[1] &lt; map_size\nand trav_map[n[0], n[1]] &gt; 0\n):\ng.add_edge(n, (i, j), weight=T.l2_distance(n, (i, j)))\n# only take the largest connected component\nlargest_cc = max(nx.connected_components(g), key=len)\ng = g.subgraph(largest_cc).copy()\nwith open(graph_file, \"wb\") as pfile:\npickle.dump(g, pfile)\nfloor_graph.append(g)\n# update trav_map accordingly\n# This overwrites the traversability map loaded before\n# It sets everything to zero, then only sets to one the points where we have graph nodes\n# Dangerous! if the traversability graph is not computed from the loaded map but from a file, it could overwrite\n# it silently.\ntrav_map[:, :] = 0\nfor node in g.nodes:\ntrav_map[node[0], node[1]] = 255\nreturn floor_graph\n@property\ndef n_floors(self):\n\"\"\"\n        Returns:\n            int: Number of floors belonging to this map's associated scene\n        \"\"\"\nreturn len(self.floor_heights)\ndef get_random_point(self, floor=None):\n\"\"\"\n        Sample a random point on the given floor number. If not given, sample a random floor number.\n        Args:\n            floor (None or int): floor number. None means the floor is randomly sampled\n        Returns:\n            2-tuple:\n                - int: floor number. This is the sampled floor number if @floor is None\n                - 3-array: (x,y,z) randomly sampled point\n        \"\"\"\nif floor is None:\nfloor = np.random.randint(0, self.n_floors)\ntrav = self.floor_map[floor]\ntrav_space = np.where(trav == 255)\nidx = np.random.randint(0, high=trav_space[0].shape[0])\nxy_map = np.array([trav_space[0][idx], trav_space[1][idx]])\nx, y = self.map_to_world(xy_map)\nz = self.floor_heights[floor]\nreturn floor, np.array([x, y, z])\ndef has_node(self, floor, world_xy):\n\"\"\"\n        Return whether the traversability graph contains a point\n            floor: floor number\n            world_xy: 2D location in world reference frame (metric)\n        \"\"\"\nmap_xy = tuple(self.world_to_map(world_xy))\ng = self.floor_graph[floor]\nreturn g.has_node(map_xy)\ndef get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n\"\"\"\n        Get the shortest path from one point to another point.\n        If any of the given point is not in the graph, add it to the graph and\n        create an edge between it to its closest node.\n        Args:\n            floor (int): floor number\n            source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n            target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n            entire_path (bool): whether to return the entire path\n        Returns:\n            2-tuple:\n                - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n                - float: geodesic distance of the path\n        \"\"\"\nassert self.build_graph, \"cannot get shortest path without building the graph\"\nsource_map = tuple(self.world_to_map(source_world))\ntarget_map = tuple(self.world_to_map(target_world))\ng = self.floor_graph[floor]\nif not g.has_node(target_map):\nnodes = np.array(g.nodes)\nclosest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - target_map, axis=1))])\ng.add_edge(closest_node, target_map, weight=T.l2_distance(closest_node, target_map))\nif not g.has_node(source_map):\nnodes = np.array(g.nodes)\nclosest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - source_map, axis=1))])\ng.add_edge(closest_node, source_map, weight=T.l2_distance(closest_node, source_map))\npath_map = np.array(nx.astar_path(g, source_map, target_map, heuristic=T.l2_distance))\npath_world = self.map_to_world(path_map)\ngeodesic_distance = np.sum(np.linalg.norm(path_world[1:] - path_world[:-1], axis=1))\npath_world = path_world[:: self.waypoint_interval]\nif not entire_path:\npath_world = path_world[: self.num_waypoints]\nnum_remaining_waypoints = self.num_waypoints - path_world.shape[0]\nif num_remaining_waypoints &gt; 0:\nremaining_waypoints = np.tile(target_world, (num_remaining_waypoints, 1))\npath_world = np.concatenate((path_world, remaining_waypoints), axis=0)\nreturn path_world, geodesic_distance\n</code></pre>"},{"location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.n_floors","title":"<code>n_floors</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of floors belonging to this map's associated scene</p>"},{"location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.__init__","title":"<code>__init__(map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>map_resolution</code> <code>float</code> <p>map resolution</p> <code>0.1</code> <code>trav_map_erosion</code> <code>float</code> <p>erosion radius of traversability areas, should be robot footprint radius</p> <code>2</code> <code>trav_map_with_objects</code> <code>bool</code> <p>whether to use objects or not when constructing graph</p> <code>True</code> <code>build_graph</code> <code>bool</code> <p>build connectivity graph</p> <code>True</code> <code>num_waypoints</code> <code>int</code> <p>number of way points returned</p> <code>10</code> <code>waypoint_resolution</code> <code>float</code> <p>resolution of adjacent way points</p> <code>0.2</code> Source code in <code>omnigibson/maps/traversable_map.py</code> <pre><code>def __init__(\nself,\nmap_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\n):\n\"\"\"\n    Args:\n        map_resolution (float): map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n    \"\"\"\n# Set internal values\nself.map_default_resolution = 0.01  # each pixel represents 0.01m\nself.trav_map_erosion = trav_map_erosion\nself.trav_map_with_objects = trav_map_with_objects\nself.build_graph = build_graph\nself.num_waypoints = num_waypoints\nself.waypoint_interval = int(waypoint_resolution / map_resolution)\n# Values loaded at runtime\nself.trav_map_original_size = None\nself.trav_map_size = None\nself.mesh_body_id = None\nself.floor_heights = None\nself.floor_map = None\nself.floor_graph = None\n# Run super method\nsuper().__init__(map_resolution=map_resolution)\n</code></pre>"},{"location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.build_trav_graph","title":"<code>build_trav_graph(map_size, maps_path, floor, trav_map)</code>  <code>staticmethod</code>","text":"<p>Build traversibility graph and only take the largest connected component</p> <p>Parameters:</p> Name Type Description Default <code>map_size</code> <code>int</code> <p>Size of the map being generated</p> required <code>maps_path</code> <code>str</code> <p>Path to the folder containing the traversability maps</p> required <code>floor</code> <code>int</code> <p>floor number</p> required <code>trav_map</code> <code>H, W)-array</code> <p>traversability map in image form</p> required Source code in <code>omnigibson/maps/traversable_map.py</code> <pre><code>@staticmethod\ndef build_trav_graph(map_size, maps_path, floor, trav_map):\n\"\"\"\n    Build traversibility graph and only take the largest connected component\n    Args:\n        map_size (int): Size of the map being generated\n        maps_path (str): Path to the folder containing the traversability maps\n        floor (int): floor number\n        trav_map ((H, W)-array): traversability map in image form\n    \"\"\"\nfloor_graph = []\ngraph_file = os.path.join(\nmaps_path, \"floor_trav_{}_py{}{}.p\".format(floor, sys.version_info.major, sys.version_info.minor)\n)\nif os.path.isfile(graph_file):\nlog.info(\"Loading traversable graph\")\nwith open(graph_file, \"rb\") as pfile:\ng = pickle.load(pfile)\nelse:\nlog.info(\"Building traversable graph\")\ng = nx.Graph()\nfor i in range(map_size):\nfor j in range(map_size):\nif trav_map[i, j] == 0:\ncontinue\ng.add_node((i, j))\n# 8-connected graph\nneighbors = [(i - 1, j - 1), (i, j - 1), (i + 1, j - 1), (i - 1, j)]\nfor n in neighbors:\nif (\n0 &lt;= n[0] &lt; map_size\nand 0 &lt;= n[1] &lt; map_size\nand trav_map[n[0], n[1]] &gt; 0\n):\ng.add_edge(n, (i, j), weight=T.l2_distance(n, (i, j)))\n# only take the largest connected component\nlargest_cc = max(nx.connected_components(g), key=len)\ng = g.subgraph(largest_cc).copy()\nwith open(graph_file, \"wb\") as pfile:\npickle.dump(g, pfile)\nfloor_graph.append(g)\n# update trav_map accordingly\n# This overwrites the traversability map loaded before\n# It sets everything to zero, then only sets to one the points where we have graph nodes\n# Dangerous! if the traversability graph is not computed from the loaded map but from a file, it could overwrite\n# it silently.\ntrav_map[:, :] = 0\nfor node in g.nodes:\ntrav_map[node[0], node[1]] = 255\nreturn floor_graph\n</code></pre>"},{"location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.get_random_point","title":"<code>get_random_point(floor=None)</code>","text":"<p>Sample a random point on the given floor number. If not given, sample a random floor number.</p> <p>Parameters:</p> Name Type Description Default <code>floor</code> <code>None or int</code> <p>floor number. None means the floor is randomly sampled</p> <code>None</code> <p>Returns:</p> Type Description <p>2-tuple: - int: floor number. This is the sampled floor number if @floor is None - 3-array: (x,y,z) randomly sampled point</p> Source code in <code>omnigibson/maps/traversable_map.py</code> <pre><code>def get_random_point(self, floor=None):\n\"\"\"\n    Sample a random point on the given floor number. If not given, sample a random floor number.\n    Args:\n        floor (None or int): floor number. None means the floor is randomly sampled\n    Returns:\n        2-tuple:\n            - int: floor number. This is the sampled floor number if @floor is None\n            - 3-array: (x,y,z) randomly sampled point\n    \"\"\"\nif floor is None:\nfloor = np.random.randint(0, self.n_floors)\ntrav = self.floor_map[floor]\ntrav_space = np.where(trav == 255)\nidx = np.random.randint(0, high=trav_space[0].shape[0])\nxy_map = np.array([trav_space[0][idx], trav_space[1][idx]])\nx, y = self.map_to_world(xy_map)\nz = self.floor_heights[floor]\nreturn floor, np.array([x, y, z])\n</code></pre>"},{"location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.get_shortest_path","title":"<code>get_shortest_path(floor, source_world, target_world, entire_path=False)</code>","text":"<p>Get the shortest path from one point to another point. If any of the given point is not in the graph, add it to the graph and create an edge between it to its closest node.</p> <p>Parameters:</p> Name Type Description Default <code>floor</code> <code>int</code> <p>floor number</p> required <code>source_world</code> <code>2-array</code> <p>(x,y) 2D source location in world reference frame (metric)</p> required <code>target_world</code> <code>2-array</code> <p>(x,y) 2D target location in world reference frame (metric)</p> required <code>entire_path</code> <code>bool</code> <p>whether to return the entire path</p> <code>False</code> <p>Returns:</p> Type Description <p>2-tuple: - (N, 2) array: array of path waypoints, where N is the number of generated waypoints - float: geodesic distance of the path</p> Source code in <code>omnigibson/maps/traversable_map.py</code> <pre><code>def get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n\"\"\"\n    Get the shortest path from one point to another point.\n    If any of the given point is not in the graph, add it to the graph and\n    create an edge between it to its closest node.\n    Args:\n        floor (int): floor number\n        source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n        target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n        entire_path (bool): whether to return the entire path\n    Returns:\n        2-tuple:\n            - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n            - float: geodesic distance of the path\n    \"\"\"\nassert self.build_graph, \"cannot get shortest path without building the graph\"\nsource_map = tuple(self.world_to_map(source_world))\ntarget_map = tuple(self.world_to_map(target_world))\ng = self.floor_graph[floor]\nif not g.has_node(target_map):\nnodes = np.array(g.nodes)\nclosest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - target_map, axis=1))])\ng.add_edge(closest_node, target_map, weight=T.l2_distance(closest_node, target_map))\nif not g.has_node(source_map):\nnodes = np.array(g.nodes)\nclosest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - source_map, axis=1))])\ng.add_edge(closest_node, source_map, weight=T.l2_distance(closest_node, source_map))\npath_map = np.array(nx.astar_path(g, source_map, target_map, heuristic=T.l2_distance))\npath_world = self.map_to_world(path_map)\ngeodesic_distance = np.sum(np.linalg.norm(path_world[1:] - path_world[:-1], axis=1))\npath_world = path_world[:: self.waypoint_interval]\nif not entire_path:\npath_world = path_world[: self.num_waypoints]\nnum_remaining_waypoints = self.num_waypoints - path_world.shape[0]\nif num_remaining_waypoints &gt; 0:\nremaining_waypoints = np.tile(target_world, (num_remaining_waypoints, 1))\npath_world = np.concatenate((path_world, remaining_waypoints), axis=0)\nreturn path_world, geodesic_distance\n</code></pre>"},{"location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.has_node","title":"<code>has_node(floor, world_xy)</code>","text":"<p>Return whether the traversability graph contains a point</p> <pre><code>floor: floor number\nworld_xy: 2D location in world reference frame (metric)\n</code></pre> Source code in <code>omnigibson/maps/traversable_map.py</code> <pre><code>def has_node(self, floor, world_xy):\n\"\"\"\n    Return whether the traversability graph contains a point\n        floor: floor number\n        world_xy: 2D location in world reference frame (metric)\n    \"\"\"\nmap_xy = tuple(self.world_to_map(world_xy))\ng = self.floor_graph[floor]\nreturn g.has_node(map_xy)\n</code></pre>"},{"location":"reference/object_states/index.html","title":"object_states","text":""},{"location":"reference/object_states/aabb.html","title":"aabb","text":""},{"location":"reference/object_states/adjacency.html","title":"adjacency","text":""},{"location":"reference/object_states/adjacency.html#object_states.adjacency.HorizontalAdjacency","title":"<code>HorizontalAdjacency</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code></p> <p>State representing the object's horizontal adjacencies in a preset number of directions.</p> <p>The HorizontalAdjacency state returns adjacency lists for equally spaced coordinate planes. Each plane consists of 2 orthogonal axes, and adjacencies are checked for both the positive and negative directions of each axis.</p> <p>The value of the state is List[List[AxisAdjacencyList]], where the list dimensions are m.HORIZONTAL_AXIS_COUNT and 2. The first index is used to choose between the different planes, the second index to choose between the orthogonal axes of that plane. Given a plane/axis combo, the item in the list is a AxisAdjacencyList containing adjacencies in both directions of the axis.</p> <p>If the idea of orthogonal bases is not relevant (and your use case simply requires checking adjacencies in each direction), the flatten_planes() function can be used on the state value to reduce the output to List[AxisAdjacencyList], a list of adjacency lists for all 2 * m.HORIZONTAL_AXIS_COUNT directions.</p> Source code in <code>omnigibson/object_states/adjacency.py</code> <pre><code>class HorizontalAdjacency(AbsoluteObjectState):\n\"\"\"\n    State representing the object's horizontal adjacencies in a preset number of directions.\n    The HorizontalAdjacency state returns adjacency lists for equally spaced coordinate planes.\n    Each plane consists of 2 orthogonal axes, and adjacencies are checked for both the positive\n    and negative directions of each axis.\n    The value of the state is List[List[AxisAdjacencyList]], where the list dimensions are\n    m.HORIZONTAL_AXIS_COUNT and 2. The first index is used to choose between the different planes,\n    the second index to choose between the orthogonal axes of that plane. Given a plane/axis combo,\n    the item in the list is a AxisAdjacencyList containing adjacencies in both directions of the\n    axis.\n    If the idea of orthogonal bases is not relevant (and your use case simply requires checking\n    adjacencies in each direction), the flatten_planes() function can be used on the state value\n    to reduce the output to List[AxisAdjacencyList], a list of adjacency lists for all\n    2 * m.HORIZONTAL_AXIS_COUNT directions.\n    \"\"\"\ndef _get_value(self):\ncoordinate_planes = get_equidistant_coordinate_planes(m.HORIZONTAL_AXIS_COUNT)\n# Flatten the axis dimension and input into compute_adjacencies.\nbodies_by_axis = compute_adjacencies(self.obj, coordinate_planes.reshape(-1, 3), m.MAX_DISTANCE_HORIZONTAL)\n# Now reshape the bodies_by_axis to group by coordinate planes.\nbodies_by_plane = list(zip(bodies_by_axis[::2], bodies_by_axis[1::2]))\n# Return the adjacencies.\nreturn bodies_by_plane\ndef _set_value(self, new_value):\nraise NotImplementedError(\"HorizontalAdjacency state currently does not support setting.\")\n@staticmethod\ndef get_dependencies():\nreturn AbsoluteObjectState.get_dependencies() + [AABB]\n# Nothing needs to be done to save/load adjacency since it will happen due to pose caching.\n</code></pre>"},{"location":"reference/object_states/adjacency.html#object_states.adjacency.VerticalAdjacency","title":"<code>VerticalAdjacency</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code></p> <p>State representing the object's vertical adjacencies. Value is a AxisAdjacencyList object.</p> Source code in <code>omnigibson/object_states/adjacency.py</code> <pre><code>class VerticalAdjacency(AbsoluteObjectState):\n\"\"\"\n    State representing the object's vertical adjacencies.\n    Value is a AxisAdjacencyList object.\n    \"\"\"\ndef _get_value(self):\n# Call the adjacency computation with th Z axis.\nbodies_by_axis = compute_adjacencies(self.obj, np.array([[0, 0, 1]]), m.MAX_DISTANCE_VERTICAL)\n# Return the adjacencies from the only axis we passed in.\nreturn bodies_by_axis[0]\ndef _set_value(self, new_value):\nraise NotImplementedError(\"VerticalAdjacency state currently does not support setting.\")\n@staticmethod\ndef get_dependencies():\nreturn AbsoluteObjectState.get_dependencies() + [AABB]\n</code></pre>"},{"location":"reference/object_states/adjacency.html#object_states.adjacency.compute_adjacencies","title":"<code>compute_adjacencies(obj, axes, max_distance)</code>","text":"<p>Given an object and a list of axes, find the adjacent objects in the axes' positive and negative directions.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>The object to check adjacencies of.</p> required <code>axes</code> <code>2D-array</code> <p>(n_axes, 3) array defining the axes to check in. Note that each axis will be checked in both its positive and negative direction.</p> required <p>Returns:</p> Type Description <p>list of AxisAdjacencyList: List of length len(axes) containing the adjacencies.</p> Source code in <code>omnigibson/object_states/adjacency.py</code> <pre><code>def compute_adjacencies(obj, axes, max_distance):\n\"\"\"\n    Given an object and a list of axes, find the adjacent objects in the axes'\n    positive and negative directions.\n    Args:\n        obj (StatefulObject): The object to check adjacencies of.\n        axes (2D-array): (n_axes, 3) array defining the axes to check in.\n            Note that each axis will be checked in both its positive and negative direction.\n    Returns:\n        list of AxisAdjacencyList: List of length len(axes) containing the adjacencies.\n    \"\"\"\n# Get vectors for each of the axes' directions.\n# The ordering is axes1+, axis1-, axis2+, axis2- etc.\ndirections = np.empty((len(axes) * 2, 3))\ndirections[0::2] = axes\ndirections[1::2] = -axes\n# Prepare this object's info for ray casting.\n# Use AABB center instead of position because we cannot get valid position\n# for fixed objects if fixed links are merged.\naabb_lower, aabb_higher = obj.states[AABB].get_value()\nobject_position = (aabb_lower + aabb_higher) / 2.0\nprim_paths = obj.link_prim_paths\n# Prepare the rays to cast.\nray_starts = np.tile(object_position, (len(directions), 1))\nray_endpoints = ray_starts + (directions * max_distance)\n# Cast time.\nray_results = raytest_batch(\nray_starts,\nray_endpoints,\nonly_closest=False,\nignore_bodies=prim_paths,\nignore_collisions=prim_paths\n)\n# Add the results to the appropriate lists\n# For now, we keep our result in the dimensionality of (direction, hit_object_order).\n# We convert the hit link into unique objects encountered\nobjs_by_direction = []\nfor results in ray_results:\nunique_objs = set()\nfor result in results:\n# Check if the inferred hit object is not None, we add it to our set\nobj_prim_path = \"/\".join(result[\"rigidBody\"].split(\"/\")[:-1])\nobj = og.sim.scene.object_registry(\"prim_path\", obj_prim_path, None)\nif obj is not None:\nunique_objs.add(obj)\nobjs_by_direction.append(unique_objs)\n# Reshape so that these have the following indices:\n# (axis_idx, direction-one-or-zero, hit_idx)\nobjs_by_axis = [\nAxisAdjacencyList(positive_neighbors, negative_neighbors)\nfor positive_neighbors, negative_neighbors in zip(objs_by_direction[::2], objs_by_direction[1::2])\n]\nreturn objs_by_axis\n</code></pre>"},{"location":"reference/object_states/adjacency.html#object_states.adjacency.get_equidistant_coordinate_planes","title":"<code>get_equidistant_coordinate_planes(n_planes)</code>","text":"<p>Given a number, sample that many equally spaced coordinate planes.</p> <p>The samples will cover all 360 degrees (although rotational symmetry is assumed, e.g. if you take into account the axis index and the positive/negative directions, only 1/4 of the possible coordinate (1 quadrant, np.pi / 2.0) planes will be sampled: the ones where the first axis' positive direction is in the first quadrant).</p> <p>Parameters:</p> Name Type Description Default <code>n_planes</code> <code>int</code> <p>number of planes to sample</p> required <p>Returns:</p> Type Description <p>3D-array: (n_planes, 2, 3) array where the first dimension is the sampled plane index, the second dimension is the axis index (0/1), and the third dimension is the 3-D world-coordinate vector corresponding to the axis.</p> Source code in <code>omnigibson/object_states/adjacency.py</code> <pre><code>def get_equidistant_coordinate_planes(n_planes):\n\"\"\"Given a number, sample that many equally spaced coordinate planes.\n    The samples will cover all 360 degrees (although rotational symmetry\n    is assumed, e.g. if you take into account the axis index and the\n    positive/negative directions, only 1/4 of the possible coordinate (1 quadrant, np.pi / 2.0)\n    planes will be sampled: the ones where the first axis' positive direction\n    is in the first quadrant).\n    Args:\n        n_planes (int): number of planes to sample\n    Returns:\n        3D-array: (n_planes, 2, 3) array where the first dimension\n            is the sampled plane index, the second dimension is the axis index\n            (0/1), and the third dimension is the 3-D world-coordinate vector\n            corresponding to the axis.\n    \"\"\"\n# Compute the positive directions of the 1st axis of each plane.\nfirst_axis_angles = np.linspace(0, np.pi / 2, n_planes)\nfirst_axes = np.stack(\n[np.cos(first_axis_angles), np.sin(first_axis_angles), np.zeros_like(first_axis_angles)], axis=1\n)\n# Compute the positive directions of the 2nd axes. These axes are\n# orthogonal to both their corresponding first axes and to the Z axis.\nsecond_axes = np.cross([0, 0, 1], first_axes)\n# Return the axes in the shape (n_planes, 2, 3)\nreturn np.stack([first_axes[:, None, :], second_axes[:, None, :]], axis=1)\n</code></pre>"},{"location":"reference/object_states/attached_to.html","title":"attached_to","text":""},{"location":"reference/object_states/attached_to.html#object_states.attached_to.AttachedTo","title":"<code>AttachedTo</code>","text":"<p>         Bases: <code>RelativeObjectState</code>, <code>BooleanState</code>, <code>ContactSubscribedStateMixin</code>, <code>JointBreakSubscribedStateMixin</code>, <code>LinkBasedStateMixin</code></p> <p>Handles attachment between two rigid objects, by creating a fixed/spherical joint between self.obj (child) and other (parent). At any given moment, an object can only be attached to at most one other object, i.e. a parent can have multiple children, but a child can only have one parent. Note that generally speaking only child.states[AttachedTo].get_value(parent) will return True. One of the child's male meta links will be attached to one of the parent's female meta links.</p> <p>Subclasses ContactSubscribedStateMixin, JointBreakSubscribedStateMixin on_contact function attempts to attach self.obj to other when a CONTACT_FOUND event happens on_joint_break function breaks the current attachment</p> Source code in <code>omnigibson/object_states/attached_to.py</code> <pre><code>class AttachedTo(RelativeObjectState, BooleanState, ContactSubscribedStateMixin, JointBreakSubscribedStateMixin, LinkBasedStateMixin):\n\"\"\"\n        Handles attachment between two rigid objects, by creating a fixed/spherical joint between self.obj (child) and\n        other (parent). At any given moment, an object can only be attached to at most one other object, i.e.\n        a parent can have multiple children, but a child can only have one parent.\n        Note that generally speaking only child.states[AttachedTo].get_value(parent) will return True.\n        One of the child's male meta links will be attached to one of the parent's female meta links.\n        Subclasses ContactSubscribedStateMixin, JointBreakSubscribedStateMixin\n        on_contact function attempts to attach self.obj to other when a CONTACT_FOUND event happens\n        on_joint_break function breaks the current attachment\n    \"\"\"\n@classproperty\ndef metalink_prefix(cls):\n\"\"\"\n        Returns:\n            str: Unique keyword that defines the metalink associated with this object state\n        \"\"\"\nreturn m.ATTACHMENT_LINK_PREFIX\n@staticmethod\ndef get_dependencies():\nreturn RelativeObjectState.get_dependencies() + [ContactBodies]\ndef _initialize(self):\nsuper()._initialize()\nself.initialize_link_mixin()\n# Reference to the parent object (DatasetObject)\nself.parent = None\n# Reference to the female meta link of the parent object (RigidPrim)\nself.parent_link = None\n# Mapping from the female meta link names of self.obj to their children (Dict[str, Optional[DatasetObject] = None])\nself.children = {link_name: None for link_name in self.links if link_name.split(\"_\")[1].endswith(\"F\")}\n# Cache of parent link candidates for other objects (Dict[DatasetObject, Dict[str, str]])\n# @other -&gt; (the male meta link names of @self.obj -&gt; the correspounding female meta link names of @other))\nself.parent_link_candidates = dict()\ndef on_joint_break(self, joint_prim_path):\n# Note that when this function is invoked when a joint break event happens, @self.obj is the parent of the\n# attachment joint, not the child. We access the child of the broken joint, and call the setter with False\nchild = self.children[joint_prim_path.split(\"/\")[-2]]\nchild.states[AttachedTo].set_value(self.obj, False)\n# Attempts to attach two objects when a CONTACT_FOUND event happens\ndef on_contact(self, other, contact_headers, contact_data):\nfor contact_header in contact_headers:\nif contact_header.type == ContactEventType.CONTACT_FOUND:\n# If it has successfully attached to something, break.\nif self.set_value(other, True):\nbreak\ndef _set_value(self, other, new_value, bypass_alignment_checking=False):\n# Attempt to attach\nif new_value:\nif self.parent == other:\n# Already attached to this object. Do nothing.\nreturn True\nelif self.parent is None:\n# Find attachment links that satisfy the proximity requirements\nchild_link, parent_link = self._find_attachment_links(other, bypass_alignment_checking)\nif child_link is not None:\nself._attach(other, child_link, parent_link)\nreturn True\nelse:\nreturn False\nelse:\nlog.debug(f\"Trying to attach object {self.obj.name} to object {other.name},\"\nf\"but it is already attached to object {self.parent.name}. Try detaching first.\")\nreturn False\n# Attempt to detach\nelse:\nif self.parent == other:\nself._detach()\n# Wake up objects so that passive forces like gravity can be applied.\nself.obj.wake()\nother.wake()\nreturn True\ndef _get_value(self, other):\n# Simply return if the current parent matches other\nreturn other == self.parent\ndef _find_attachment_links(self,\nother,\nbypass_alignment_checking=False,\npos_thresh=m.DEFAULT_POSITION_THRESHOLD,\norn_thresh=m.DEFAULT_ORIENTATION_THRESHOLD):\n\"\"\"\n        Args:\n            other (DatasetObject): parent object to find potential attachment links.\n            bypass_alignment_checking (bool): whether to bypass alignment checking when finding attachment links.\n                Normally when finding attachment links, we check if the child and parent links have aligned positions\n                or poses. This flag allows users to bypass this check and find attachment links solely based on the\n                attachment meta link types. Default is False.\n            pos_thresh (float): position difference threshold to activate attachment, in meters.\n            orn_thresh (float): orientation difference threshold to activate attachment, in radians.\n        Returns:\n            2-tuple:\n                - RigidPrim or None: link belonging to @self.obj that should be aligned to that corresponding link of @other\n                - RigidPrim or None: the corresponding link of @other\n        \"\"\"\nparent_candidates = self._get_parent_candidates(other)\nif not parent_candidates:\nreturn None, None\nfor child_link_name, parent_link_names in parent_candidates.items():\nchild_link = self.links[child_link_name]\nfor parent_link_name in parent_link_names:\nparent_link = other.states[AttachedTo].links[parent_link_name]\nif other.states[AttachedTo].children[parent_link_name] is None:\nif bypass_alignment_checking:\nreturn child_link, parent_link\npos_diff = np.linalg.norm(child_link.get_position() - parent_link.get_position())\norn_diff = T.get_orientation_diff_in_radian(child_link.get_orientation(), parent_link.get_orientation())\nif pos_diff &lt; pos_thresh and orn_diff &lt; orn_thresh:\nreturn child_link, parent_link\nreturn None, None\ndef _get_parent_candidates(self, other):\n\"\"\"\n        Helper function to return the parent link candidates for @other\n        Returns:\n            Dict[str, str] or None: mapping from the male meta link names of self.obj to the correspounding female meta\n            link names of @other. Returns None if @other does not have the AttachedTo state.\n        \"\"\"\nif AttachedTo not in other.states:\nreturn None\nif other not in self.parent_link_candidates:\nparent_link_names = defaultdict(set)\nfor child_link_name, child_link in self.links.items():\nchild_category = child_link_name.split(\"_\")[1]\nif child_category.endswith(\"F\"):\ncontinue\nassert child_category.endswith(\"M\")\nparent_category = child_category[:-1] + \"F\"\nfor parent_link_name, parent_link in other.states[AttachedTo].links.items():\nif parent_category in parent_link_name:\nparent_link_names[child_link_name].add(parent_link_name)\nself.parent_link_candidates[other] = parent_link_names\nreturn self.parent_link_candidates[other]\n@property\ndef attachment_joint_prim_path(self):\nreturn f\"{self.parent_link.prim_path}/{self.obj.name}_attachment_joint\" if self.parent_link is not None else None\ndef _attach(self, other, child_link, parent_link, joint_type=m.DEFAULT_JOINT_TYPE, break_force=m.DEFAULT_BREAK_FORCE, break_torque=m.DEFAULT_BREAK_TORQUE):\n\"\"\"\n        Creates a fixed or spherical joint between a male meta link of self.obj (@child_link) and a female meta link of\n         @other (@parent_link) with a given @joint_type, @break_force and @break_torque\n         Args:\n            other (DatasetObject): parent object to attach to.\n            child_link (RigidPrim): male meta link of @self.obj.\n            parent_link (RigidPrim): female meta link of @other.\n            joint_type (JointType): joint type of the attachment, {JointType.JOINT_FIXED, JointType.JOINT_SPHERICAL}\n            break_force (float or None): break force for linear dofs, unit is Newton.\n            break_torque (float or None): break torque for angular dofs, unit is Newton-meter.\n        \"\"\"\nassert joint_type in {JointType.JOINT_FIXED, JointType.JOINT_SPHERICAL}, f\"Unsupported joint type {joint_type}\"\n# Set the parent references\nself.parent = other\nself.parent_link = parent_link\n# Set the child reference for @other\nother.states[AttachedTo].children[parent_link.body_name] = self.obj\n# Set pose for self.obj so that child_link and parent_link align (6dof alignment for FixedJoint and 3dof alignment for SphericalJoint)\nparent_pos, parent_quat = parent_link.get_position_orientation()\nchild_pos, child_quat = child_link.get_position_orientation()\nchild_root_pos, child_root_quat = self.obj.get_position_orientation()\nif joint_type == JointType.JOINT_FIXED:\n# For FixedJoint: find the relation transformation of the two frames and apply it to self.obj.\nrel_pos, rel_quat = T.mat2pose(T.pose2mat((parent_pos, parent_quat)) @ T.pose_inv(T.pose2mat((child_pos, child_quat))))\nnew_child_root_pos, new_child_root_quat = T.pose_transform(rel_pos, rel_quat, child_root_pos, child_root_quat)\nelse:\n# For SphericalJoint: move the position of self.obj to align the two frames and keep the rotation unchanged.\nnew_child_root_pos = child_root_pos + (parent_pos - child_pos)\nnew_child_root_quat = child_root_quat\n# Actually move the object and also keep it still for stability purposes.\nself.obj.set_position_orientation(new_child_root_pos, new_child_root_quat)\nself.obj.keep_still()\nif joint_type == JointType.JOINT_FIXED:\n# FixedJoint: the parent link, the child link and the joint frame all align.\nparent_local_quat = np.array([0.0, 0.0, 0.0, 1.0])\nelse:\n# SphericalJoint: the same except that the rotation of the parent link doesn't align with the joint frame.\n# The child link and the joint frame still align.\n_, parent_local_quat = T.relative_pose_transform([0, 0, 0], child_quat, [0, 0, 0], parent_quat)\n# Create the joint\ncreate_joint(\nprim_path=self.attachment_joint_prim_path,\njoint_type=joint_type,\nbody0=f\"{parent_link.prim_path}\",\nbody1=f\"{child_link.prim_path}\",\njoint_frame_in_parent_frame_pos=np.zeros(3),\njoint_frame_in_parent_frame_quat=parent_local_quat,\njoint_frame_in_child_frame_pos=np.zeros(3),\njoint_frame_in_child_frame_quat=np.array([0.0, 0.0, 0.0, 1.0]),\nbreak_force=break_force,\nbreak_torque=break_torque,\n)\ndef _detach(self):\n\"\"\"\n        Removes the current attachment joint\n        \"\"\"\n# Remove the attachment joint prim from the stage\nog.sim.stage.RemovePrim(self.attachment_joint_prim_path)\n# Remove child reference from the parent object\nself.parent.states[AttachedTo].children[self.parent_link.body_name] = None\n# Remove reference to the parent object and link\nself.parent = None\nself.parent_link = None\n@property\ndef settable(self):\nreturn True\n@property\ndef state_size(self):\nreturn 1\ndef _dump_state(self):\nreturn dict(attached_obj_uuid=-1 if self.parent is None else self.parent.uuid)\ndef _load_state(self, state):\nuuid = state[\"attached_obj_uuid\"]\nif uuid == -1:\nattached_obj = None\nelse:\nattached_obj = og.sim.scene.object_registry(\"uuid\", uuid)\nassert attached_obj is not None, \"attached_obj_uuid does not match any object in the scene.\"\n# If it's currently attached to something, detach.\nif self.parent is not None:\nself.set_value(self.parent, False)\nassert self.parent is None, \"parent reference is not cleared after detachment\"\n# If the loaded state requires attachment, attach.\nif attached_obj is not None:\nself.set_value(attached_obj, True)\nassert self.parent == attached_obj, \"parent reference is not updated after attachment\"\ndef _serialize(self, state):\nreturn np.array([state[\"attached_obj_uuid\"]], dtype=float)\ndef _deserialize(self, state):\nreturn dict(attached_obj_uuid=int(state[0])), 1\n</code></pre>"},{"location":"reference/object_states/attached_to.html#object_states.attached_to.AttachedTo.metalink_prefix","title":"<code>metalink_prefix()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Unique keyword that defines the metalink associated with this object state</p> Source code in <code>omnigibson/object_states/attached_to.py</code> <pre><code>@classproperty\ndef metalink_prefix(cls):\n\"\"\"\n    Returns:\n        str: Unique keyword that defines the metalink associated with this object state\n    \"\"\"\nreturn m.ATTACHMENT_LINK_PREFIX\n</code></pre>"},{"location":"reference/object_states/burnt.html","title":"burnt","text":""},{"location":"reference/object_states/contact_bodies.html","title":"contact_bodies","text":""},{"location":"reference/object_states/contact_particles.html","title":"contact_particles","text":""},{"location":"reference/object_states/contact_particles.html#object_states.contact_particles.ContactParticles","title":"<code>ContactParticles</code>","text":"<p>         Bases: <code>RelativeObjectState</code>, <code>KinematicsMixin</code></p> <p>Object state that handles contact checking between rigid bodies and individual particles.</p> Source code in <code>omnigibson/object_states/contact_particles.py</code> <pre><code>class ContactParticles(RelativeObjectState, KinematicsMixin):\n\"\"\"\n    Object state that handles contact checking between rigid bodies and individual particles.\n    \"\"\"\ndef __init__(self, obj):\nsuper().__init__(obj=obj)\ndef _get_value(self, system, link=None):\n# Make sure system is valid\nassert issubclass(system, PhysicalParticleSystem), \"Can only get ContactParticles for a PhysicalParticleSystem!\"\n# Create contacts dictionary, mapping instancer to set of particle IDs in contact\ncontacts = defaultdict(set)\n# Variables to update mid-iteration\ninst = None\nidx = 0\n# Define callback function to use for omni's overlap_sphere() call\ndef report_hit(hit):\nnonlocal link, inst, idx\nlink_name = None if link is None else link.prim_path.split(\"/\")[-1]\nbase, body = \"/\".join(hit.rigid_body.split(\"/\")[:-1]), hit.rigid_body.split(\"/\")[-1]\ncontinue_traversal = True\n# If no links are specified, then we assume checking contact with any link owned by this object\n# Otherwise, we check for exact match of link name\nif (link is None and base == self.obj.prim_path) or (link is not None and link_name == body):\n# Add to contacts and terminate early\ncontacts[inst].add(idx)\ncontinue_traversal = False\nreturn continue_traversal\n# Grab the relaxed AABB of this object or its link for coarse filtering of particles to ignore checking\nlower, upper = self.obj.states[AABB].get_value() if link is None else link.aabb\n# Add margin for filtering inbound\nlower = lower - (system.particle_contact_offset + 0.001)\nupper = upper + (system.particle_contact_offset + 0.001)\n# Iterate over all instancers and aggregate contacts\nfor inst in system.particle_instancers.values():\npositions = inst.particle_positions\n# Only check positions that are within the relaxed AABB of this object\ninbound_idxs = ((lower &lt; positions) &amp; (positions &lt; upper)).all(axis=-1).nonzero()[0]\nfor idx in inbound_idxs:\nog.sim.psqi.overlap_sphere(system.particle_contact_offset, positions[idx], report_hit, False)\n# Return contacts\nreturn contacts\ndef _set_value(self, system, new_value):\nraise NotImplementedError(\"ContactParticles state currently does not support setting.\")\n# TODO: investigate whether this caching actually makes things faster because we hypothesize that it will be very\n# rare for all the particles to be still.\n# def cache_info(self, get_value_args):\n#     # Run super first\n#     info = super().cache_info(get_value_args=get_value_args)\n#\n#     # Store the system's particle positions for each instancer\n#     for arg in get_value_args:\n#         if inspect.isclass(arg) and issubclass(arg, PhysicalParticleSystem):\n#             info[arg] = {instancer: instancer.particle_positions for instancer in arg.particle_instancers.values()}\n#\n#     return info\n#\n# def _cache_is_valid(self, get_value_args):\n#     # Run super first\n#     is_valid = super()._cache_is_valid(get_value_args=get_value_args)\n#\n#     if not is_valid:\n#         return False\n#\n#     for arg, info in self._cache[get_value_args][\"info\"].items():\n#         if inspect.isclass(arg) and issubclass(arg, PhysicalParticleSystem):\n#             # TODO: adopt the has_changed mechanism in object_state_base\n#             # Check if the particle positions have changed\n#\n#             # If the instancers don't match, return False\n#             if list(arg.particle_instancers.values()) != list(info.keys()):\n#                 return False\n#\n#             # If there are no instancers, skip\n#             if len(info.keys()) == 0:\n#                 continue\n#\n#             arg_pos= np.vstack([instancer.particle_positions for instancer in arg.particle_instancers.values()])\n#             info_pos = np.vstack([particle_positions for particle_positions in info.values()])\n#\n#             # If any of the particles moved, return False\n#             if np.any(np.linalg.norm(arg_pos - info_pos, axis=1) &gt;= m.POSITIONAL_VALIDATION_EPSILON):\n#                 return False\n#\n#     return True\n</code></pre>"},{"location":"reference/object_states/contact_subscribed_state_mixin.html","title":"contact_subscribed_state_mixin","text":""},{"location":"reference/object_states/contact_subscribed_state_mixin.html#object_states.contact_subscribed_state_mixin.ContactSubscribedStateMixin","title":"<code>ContactSubscribedStateMixin</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Handles contact events (including CONTACT_FOUND, CONTACT_PERSIST, and CONTACT_LOST). The subclass should implement its own on_contact method</p> Source code in <code>omnigibson/object_states/contact_subscribed_state_mixin.py</code> <pre><code>class ContactSubscribedStateMixin(ABC):\n\"\"\"\n    Handles contact events (including CONTACT_FOUND, CONTACT_PERSIST, and CONTACT_LOST).\n    The subclass should implement its own on_contact method\n    \"\"\"\n@abstractmethod\ndef on_contact(self, other, contact_headers, contact_data):\nraise NotImplementedError(\"Subclasses of ContactSubscribedStateMixin should implement the on_contact method.\")\n</code></pre>"},{"location":"reference/object_states/cooked.html","title":"cooked","text":""},{"location":"reference/object_states/covered.html","title":"covered","text":""},{"location":"reference/object_states/covered.html#object_states.covered.Covered","title":"<code>Covered</code>","text":"<p>         Bases: <code>RelativeObjectState</code>, <code>BooleanState</code></p> Source code in <code>omnigibson/object_states/covered.py</code> <pre><code>class Covered(RelativeObjectState, BooleanState):\ndef __init__(self, obj):\n# Run super first\nsuper().__init__(obj)\n# Set internal values\nself._visual_particle_group = None\nself._n_initial_visual_particles = None\n@staticmethod\ndef get_dependencies():\n# AABB needed for sampling visual particles on an object\nreturn RelativeObjectState.get_dependencies() + [AABB, ContactParticles]\ndef remove(self):\nif self._initialized:\nself._clear_attachment_groups()\ndef _clear_attachment_groups(self):\n\"\"\"\n        Utility function to destroy all corresponding attachment groups for this object\n        \"\"\"\nfor system in VisualParticleSystem.get_active_systems().values():\nif self._visual_particle_group in system.groups:\nsystem.remove_attachment_group(self._visual_particle_group)\ndef _initialize(self):\nsuper()._initialize()\n# Grab group name\nself._visual_particle_group = VisualParticleSystem.get_group_name(obj=self.obj)\ndef _get_value(self, system):\n# Value is false by default\nvalue = False\n# First, we check what type of system\n# Currently, we support VisualParticleSystems and PhysicalParticleSystems\nif issubclass(system, VisualParticleSystem):\nif self._visual_particle_group in system.groups:\n# We check whether the current number of particles assigned to the group is greater than the threshold\nvalue = system.num_group_particles(group=self._visual_particle_group) &gt;= m.VISUAL_PARTICLE_THRESHOLD\nelif issubclass(system, PhysicalParticleSystem):\n# We only check if we have particle instancers currently\nif len(system.particle_instancers) &gt; 0:\n# We've already cached particle contacts, so we merely search through them to see if any particles are\n# touching the object and are visible (the non-visible ones are considered already \"removed\")\nn_near_particles = np.sum([len(idxs) for idxs in self.obj.states[ContactParticles].get_value(system).values()])\n# Heuristic: If the number of near particles is above the threshold, we consdier this covered\nvalue = n_near_particles &gt;= m.PHYSICAL_PARTICLE_THRESHOLD\nelse:\nraise ValueError(f\"Invalid system {system} received for getting Covered state!\"\nf\"Currently, only VisualParticleSystems and PhysicalParticleSystems are supported.\")\nreturn value\ndef _set_value(self, system, new_value):\n# Default success value is True\nsuccess = True\n# First, we check what type of system\n# Currently, we support VisualParticleSystems and PhysicalParticleSystems\nif issubclass(system, VisualParticleSystem):\n# Create the group if it doesn't exist already\nif self._visual_particle_group not in system.groups:\nsystem.create_attachment_group(obj=self.obj)\n# Check current state and only do something if we're changing state\nif self.get_value(system) != new_value:\nif new_value:\n# Generate particles\nsuccess = system.generate_group_particles_on_object(\ngroup=self._visual_particle_group,\nmax_samples=m.MAX_VISUAL_PARTICLES,\nmin_samples_for_success=m.VISUAL_PARTICLE_THRESHOLD,\n)\nelse:\n# We remove all of this group's particles\nsystem.remove_all_group_particles(group=self._visual_particle_group)\nelif issubclass(system, PhysicalParticleSystem):\n# Check current state and only do something if we're changing state\nif self.get_value(system) != new_value:\nif new_value:\n# Sample particles on top of the object\nsuccess = system.generate_particles_on_object(\nobj=self.obj,\nmax_samples=m.MAX_PHYSICAL_PARTICLES,\nmin_samples_for_success=m.PHYSICAL_PARTICLE_THRESHOLD,\n)\nelse:\n# We delete all particles touching this object\nfor inst, particle_idxs in self.obj.states[ContactParticles].get_value(system).items():\ninst.remove_particles(idxs=list(particle_idxs))\nelse:\nraise ValueError(f\"Invalid system {system} received for setting Covered state!\"\nf\"Currently, only VisualParticleSystems and PhysicalParticleSystems are supported.\")\nreturn success\n</code></pre>"},{"location":"reference/object_states/factory.html","title":"factory","text":""},{"location":"reference/object_states/factory.html#object_states.factory.get_object_state_instance","title":"<code>get_object_state_instance(state_class, obj, params=None)</code>","text":"<p>Create an BaseObjectState child class instance for a given object &amp; state.</p> <p>The parameters passed in as a dictionary through params are passed as kwargs to the object state class constructor.</p> <p>Parameters:</p> Name Type Description Default <code>state_class</code> <code>BaseObjectState</code> <p>The state name from the state name dictionary.</p> required <code>obj</code> <code>StatefulObject</code> <p>The object for which the state is being constructed.</p> required <code>params</code> <code>dict</code> <p>Dictionary of {param: value} corresponding to the state's params.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BaseObjectState</code> <p>The constructed state object</p> Source code in <code>omnigibson/object_states/factory.py</code> <pre><code>def get_object_state_instance(state_class, obj, params=None):\n\"\"\"\n    Create an BaseObjectState child class instance for a given object &amp; state.\n    The parameters passed in as a dictionary through params are passed as\n    kwargs to the object state class constructor.\n    Args:\n        state_class (BaseObjectState): The state name from the state name dictionary.\n        obj (StatefulObject): The object for which the state is being constructed.\n        params (dict): Dictionary of {param: value} corresponding to the state's params.\n    Returns:\n        BaseObjectState: The constructed state object\n    \"\"\"\nif not issubclass(state_class, BaseObjectState):\nassert False, \"unknown state class: {}\".format(state_class)\nif params is None:\nparams = {}\nreturn state_class(obj, **params)\n</code></pre>"},{"location":"reference/object_states/factory.html#object_states.factory.get_state_dependency_graph","title":"<code>get_state_dependency_graph()</code>","text":"<p>Returns:</p> Type Description <p>nx.DiGraph: State dependency graph of supported object states</p> Source code in <code>omnigibson/object_states/factory.py</code> <pre><code>def get_state_dependency_graph():\n\"\"\"\n    Returns:\n        nx.DiGraph: State dependency graph of supported object states\n    \"\"\"\ndependencies = {state: state.get_dependencies() + state.get_optional_dependencies() for state in get_all_states()}\nreturn nx.DiGraph(dependencies)\n</code></pre>"},{"location":"reference/object_states/factory.html#object_states.factory.get_states_by_dependency_order","title":"<code>get_states_by_dependency_order()</code>","text":"<p>Returns:</p> Name Type Description <code>list</code> <p>all states in topological order of dependency</p> Source code in <code>omnigibson/object_states/factory.py</code> <pre><code>def get_states_by_dependency_order():\n\"\"\"\n    Returns:\n        list: all states in topological order of dependency\n    \"\"\"\nreturn list(reversed(list(nx.algorithms.topological_sort(get_state_dependency_graph()))))\n</code></pre>"},{"location":"reference/object_states/filled.html","title":"filled","text":""},{"location":"reference/object_states/folded.html","title":"folded","text":""},{"location":"reference/object_states/frozen.html","title":"frozen","text":""},{"location":"reference/object_states/heat_source_or_sink.html","title":"heat_source_or_sink","text":""},{"location":"reference/object_states/heat_source_or_sink.html#object_states.heat_source_or_sink.HeatSourceOrSink","title":"<code>HeatSourceOrSink</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>LinkBasedStateMixin</code></p> <p>This state indicates the heat source or heat sink state of the object.</p> <p>Currently, if the object is not an active heat source/sink, this returns (False, None). Otherwise, it returns True and the position of the heat source element, or (True, None) if the heat source has no heating element / only checks for Inside. E.g. on a stove object, True and the coordinates of the heating element will be returned. on a microwave object, True and None will be returned.</p> Source code in <code>omnigibson/object_states/heat_source_or_sink.py</code> <pre><code>class HeatSourceOrSink(AbsoluteObjectState, LinkBasedStateMixin):\n\"\"\"\n    This state indicates the heat source or heat sink state of the object.\n    Currently, if the object is not an active heat source/sink, this returns (False, None).\n    Otherwise, it returns True and the position of the heat source element, or (True, None) if the heat source has no\n    heating element / only checks for Inside.\n    E.g. on a stove object, True and the coordinates of the heating element will be returned.\n    on a microwave object, True and None will be returned.\n    \"\"\"\ndef __init__(\nself,\nobj,\ntemperature=m.DEFAULT_TEMPERATURE,\nheating_rate=m.DEFAULT_HEATING_RATE,\ndistance_threshold=m.DEFAULT_DISTANCE_THRESHOLD,\nrequires_toggled_on=False,\nrequires_closed=False,\nrequires_inside=False,\n):\n\"\"\"\n        Args:\n            obj (StatefulObject): The object with the heat source ability.\n            temperature (float): The temperature of the heat source.\n            heating_rate (float): Fraction in [0, 1] of the temperature difference with the\n                heat source temperature should be received every step, per second.\n            distance_threshold (float): The distance threshold which an object needs\n                to be closer than in order to receive heat from this heat source.\n            requires_toggled_on (bool): Whether the heat source object needs to be\n                toggled on to emit heat. Requires toggleable ability if set to True.\n            requires_closed (bool): Whether the heat source object needs to be\n                closed (e.g. in terms of the joints) to emit heat. Requires openable\n                ability if set to True.\n            requires_inside (bool): Whether an object needs to be `inside` the\n                heat source to receive heat. See the Inside state for details. This\n                will mean that the \"heating element\" link for the object will be\n                ignored.\n        \"\"\"\nsuper(HeatSourceOrSink, self).__init__(obj)\nself._temperature = temperature\nself._heating_rate = heating_rate\nself.distance_threshold = distance_threshold\n# If the heat source needs to be toggled on, we assert the presence\n# of that ability.\nif requires_toggled_on:\nassert ToggledOn in self.obj.states\nself.requires_toggled_on = requires_toggled_on\n# If the heat source needs to be closed, we assert the presence\n# of that ability.\nif requires_closed:\nassert Open in self.obj.states\nself.requires_closed = requires_closed\n# If the heat source needs to contain an object inside to heat it,\n# we record that for use in the heat transfer process.\nself.requires_inside = requires_inside\n@classproperty\ndef metalink_prefix(cls):\nreturn m.HEATSOURCE_LINK_PREFIX\n@property\ndef _default_link(self):\n# Only supported if we require inside\nreturn self.obj.root_link if self.requires_inside else super()._default_link\n@property\ndef heating_rate(self):\n\"\"\"\n        Returns:\n            float: Temperature changing rate of this heat source / sink\n        \"\"\"\nreturn self._heating_rate\n@property\ndef temperature(self):\n\"\"\"\n        Returns:\n            float: Temperature of this heat source / sink\n        \"\"\"\nreturn self._temperature\n@staticmethod\ndef get_dependencies():\nreturn AbsoluteObjectState.get_dependencies() + [AABB, Inside]\n@staticmethod\ndef get_optional_dependencies():\nreturn AbsoluteObjectState.get_optional_dependencies() + [ToggledOn, Open]\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\nself.initialize_link_mixin()\ndef _get_value(self):\n# Check the toggle state.\nif self.requires_toggled_on and not self.obj.states[ToggledOn].get_value():\nreturn False\n# Check the open state.\nif self.requires_closed and self.obj.states[Open].get_value():\nreturn False\nreturn True\ndef _set_value(self, new_value):\nraise NotImplementedError(\"Setting heat source capability is not supported.\")\ndef affects_obj(self, obj):\n\"\"\"\n        Computes whether this heat source or sink object is affecting object @obj\n        Computes the temperature delta that may be applied to object @obj. NOTE: This value is agnostic to simulation\n        stepping speed, and should be scaled accordingly\n        Args:\n            obj (StatefulObject): Object whose temperature delta should be computed\n        Returns:\n            bool: Whether this heat source or sink is currently affecting @obj's temperature\n        \"\"\"\n# No change if we're not on\nif not self.get_value():\nreturn False\n# Otherwise, check for other edge cases\n# If we require the object to be inside, make sure the object is inside, otherwise, we return 0\n# Otherwise, make sure the object is within close proximity of this heat source\nif self.requires_inside:\nif not obj.states[Inside].get_value(self.obj):\nreturn False\nelse:\naabb_lower, aabb_upper = obj.states[AABB].get_value()\nobj_pos = (aabb_lower + aabb_upper) / 2.0\n# Position is either the AABB center of the default link or the metalink position itself\nheat_source_pos = self.link.aabb_center if self.link == self._default_link else self.link.get_position()\nif T.l2_distance(heat_source_pos, obj_pos) &gt; self.distance_threshold:\nreturn False\n# If all checks pass, we're actively influencing the object!\nreturn True\n# Nothing needs to be done to save/load HeatSource\n</code></pre>"},{"location":"reference/object_states/heat_source_or_sink.html#object_states.heat_source_or_sink.HeatSourceOrSink.heating_rate","title":"<code>heating_rate</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Temperature changing rate of this heat source / sink</p>"},{"location":"reference/object_states/heat_source_or_sink.html#object_states.heat_source_or_sink.HeatSourceOrSink.temperature","title":"<code>temperature</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Temperature of this heat source / sink</p>"},{"location":"reference/object_states/heat_source_or_sink.html#object_states.heat_source_or_sink.HeatSourceOrSink.__init__","title":"<code>__init__(obj, temperature=m.DEFAULT_TEMPERATURE, heating_rate=m.DEFAULT_HEATING_RATE, distance_threshold=m.DEFAULT_DISTANCE_THRESHOLD, requires_toggled_on=False, requires_closed=False, requires_inside=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>The object with the heat source ability.</p> required <code>temperature</code> <code>float</code> <p>The temperature of the heat source.</p> <code>m.DEFAULT_TEMPERATURE</code> <code>heating_rate</code> <code>float</code> <p>Fraction in [0, 1] of the temperature difference with the heat source temperature should be received every step, per second.</p> <code>m.DEFAULT_HEATING_RATE</code> <code>distance_threshold</code> <code>float</code> <p>The distance threshold which an object needs to be closer than in order to receive heat from this heat source.</p> <code>m.DEFAULT_DISTANCE_THRESHOLD</code> <code>requires_toggled_on</code> <code>bool</code> <p>Whether the heat source object needs to be toggled on to emit heat. Requires toggleable ability if set to True.</p> <code>False</code> <code>requires_closed</code> <code>bool</code> <p>Whether the heat source object needs to be closed (e.g. in terms of the joints) to emit heat. Requires openable ability if set to True.</p> <code>False</code> <code>requires_inside</code> <code>bool</code> <p>Whether an object needs to be <code>inside</code> the heat source to receive heat. See the Inside state for details. This will mean that the \"heating element\" link for the object will be ignored.</p> <code>False</code> Source code in <code>omnigibson/object_states/heat_source_or_sink.py</code> <pre><code>def __init__(\nself,\nobj,\ntemperature=m.DEFAULT_TEMPERATURE,\nheating_rate=m.DEFAULT_HEATING_RATE,\ndistance_threshold=m.DEFAULT_DISTANCE_THRESHOLD,\nrequires_toggled_on=False,\nrequires_closed=False,\nrequires_inside=False,\n):\n\"\"\"\n    Args:\n        obj (StatefulObject): The object with the heat source ability.\n        temperature (float): The temperature of the heat source.\n        heating_rate (float): Fraction in [0, 1] of the temperature difference with the\n            heat source temperature should be received every step, per second.\n        distance_threshold (float): The distance threshold which an object needs\n            to be closer than in order to receive heat from this heat source.\n        requires_toggled_on (bool): Whether the heat source object needs to be\n            toggled on to emit heat. Requires toggleable ability if set to True.\n        requires_closed (bool): Whether the heat source object needs to be\n            closed (e.g. in terms of the joints) to emit heat. Requires openable\n            ability if set to True.\n        requires_inside (bool): Whether an object needs to be `inside` the\n            heat source to receive heat. See the Inside state for details. This\n            will mean that the \"heating element\" link for the object will be\n            ignored.\n    \"\"\"\nsuper(HeatSourceOrSink, self).__init__(obj)\nself._temperature = temperature\nself._heating_rate = heating_rate\nself.distance_threshold = distance_threshold\n# If the heat source needs to be toggled on, we assert the presence\n# of that ability.\nif requires_toggled_on:\nassert ToggledOn in self.obj.states\nself.requires_toggled_on = requires_toggled_on\n# If the heat source needs to be closed, we assert the presence\n# of that ability.\nif requires_closed:\nassert Open in self.obj.states\nself.requires_closed = requires_closed\n# If the heat source needs to contain an object inside to heat it,\n# we record that for use in the heat transfer process.\nself.requires_inside = requires_inside\n</code></pre>"},{"location":"reference/object_states/heat_source_or_sink.html#object_states.heat_source_or_sink.HeatSourceOrSink.affects_obj","title":"<code>affects_obj(obj)</code>","text":"<p>Computes whether this heat source or sink object is affecting object @obj Computes the temperature delta that may be applied to object @obj. NOTE: This value is agnostic to simulation stepping speed, and should be scaled accordingly</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>Object whose temperature delta should be computed</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this heat source or sink is currently affecting @obj's temperature</p> Source code in <code>omnigibson/object_states/heat_source_or_sink.py</code> <pre><code>def affects_obj(self, obj):\n\"\"\"\n    Computes whether this heat source or sink object is affecting object @obj\n    Computes the temperature delta that may be applied to object @obj. NOTE: This value is agnostic to simulation\n    stepping speed, and should be scaled accordingly\n    Args:\n        obj (StatefulObject): Object whose temperature delta should be computed\n    Returns:\n        bool: Whether this heat source or sink is currently affecting @obj's temperature\n    \"\"\"\n# No change if we're not on\nif not self.get_value():\nreturn False\n# Otherwise, check for other edge cases\n# If we require the object to be inside, make sure the object is inside, otherwise, we return 0\n# Otherwise, make sure the object is within close proximity of this heat source\nif self.requires_inside:\nif not obj.states[Inside].get_value(self.obj):\nreturn False\nelse:\naabb_lower, aabb_upper = obj.states[AABB].get_value()\nobj_pos = (aabb_lower + aabb_upper) / 2.0\n# Position is either the AABB center of the default link or the metalink position itself\nheat_source_pos = self.link.aabb_center if self.link == self._default_link else self.link.get_position()\nif T.l2_distance(heat_source_pos, obj_pos) &gt; self.distance_threshold:\nreturn False\n# If all checks pass, we're actively influencing the object!\nreturn True\n# Nothing needs to be done to save/load HeatSource\n</code></pre>"},{"location":"reference/object_states/heated.html","title":"heated","text":""},{"location":"reference/object_states/inside.html","title":"inside","text":""},{"location":"reference/object_states/joint_break_subscribed_state_mixin.html","title":"joint_break_subscribed_state_mixin","text":""},{"location":"reference/object_states/joint_break_subscribed_state_mixin.html#object_states.joint_break_subscribed_state_mixin.JointBreakSubscribedStateMixin","title":"<code>JointBreakSubscribedStateMixin</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Handles JOINT_BREAK event. The subclass should implement its own on_joint_break method</p> Source code in <code>omnigibson/object_states/joint_break_subscribed_state_mixin.py</code> <pre><code>class JointBreakSubscribedStateMixin(ABC):\n\"\"\"\n    Handles JOINT_BREAK event.\n    The subclass should implement its own on_joint_break method\n    \"\"\"\n@abstractmethod\ndef on_joint_break(self, joint_prim_path):\nraise NotImplementedError(\"Subclasses of JointBreakSubscribedStateMixin should implement the on_joint_break method.\")\n</code></pre>"},{"location":"reference/object_states/kinematics.html","title":"kinematics","text":""},{"location":"reference/object_states/kinematics.html#object_states.kinematics.KinematicsMixin","title":"<code>KinematicsMixin</code>","text":"<p>         Bases: <code>BaseObjectState</code></p> <p>This class is a subclass of BaseObjectState that adds dependencies on the default kinematics states.</p> Source code in <code>omnigibson/object_states/kinematics.py</code> <pre><code>class KinematicsMixin(BaseObjectState):\n\"\"\"\n    This class is a subclass of BaseObjectState that adds dependencies\n    on the default kinematics states.\n    \"\"\"\n@staticmethod\ndef get_dependencies():\nreturn BaseObjectState.get_dependencies() + [Pose, AABB, ContactBodies]\ndef cache_info(self, get_value_args):\n# Import here to avoid circular imports\nfrom omnigibson.objects.stateful_object import StatefulObject\n# Run super first\ninfo = super().cache_info(get_value_args=get_value_args)\n# Store this object as well as any other objects from @get_value_args\ninfo[self.obj] = self.obj.states[Pose].get_value()\nfor arg in get_value_args:\nif isinstance(arg, StatefulObject):\ninfo[arg] = arg.states[Pose].get_value()\nreturn info\ndef _cache_is_valid(self, get_value_args):\n# Import here to avoid circular imports\nfrom omnigibson.objects.stateful_object import StatefulObject\n# Cache is valid if and only if all of our cached objects have not changed\nt = self._cache[get_value_args][\"t\"]\nfor obj, pose in self._cache[get_value_args][\"info\"].items():\nif isinstance(obj, StatefulObject):\nif obj.states[Pose].has_changed(get_value_args=(), value=pose, info={}, t=t):\nreturn False\nreturn True\n</code></pre>"},{"location":"reference/object_states/link_based_state_mixin.html","title":"link_based_state_mixin","text":""},{"location":"reference/object_states/link_based_state_mixin.html#object_states.link_based_state_mixin.LinkBasedStateMixin","title":"<code>LinkBasedStateMixin</code>","text":"Source code in <code>omnigibson/object_states/link_based_state_mixin.py</code> <pre><code>class LinkBasedStateMixin:\ndef __init__(self):\nsuper().__init__()\nself._link = None\nself._links = dict()\n@classproperty\ndef metalink_prefix(cls):\n\"\"\"\n        Returns:\n            str: Unique keyword that defines the metalink associated with this object state\n        \"\"\"\nNotImplementedError()\n@property\ndef link(self):\n\"\"\"\n        Returns:\n            None or RigidPrim: The link associated with this link-based state, if it exists\n        \"\"\"\nreturn self._default_link if self._link is None else self._link\n@property\ndef links(self):\n\"\"\"\n        Returns:\n            dict: mapping from link names to links that match the metalink_prefix\n        \"\"\"\nreturn self._links\n@property\ndef _default_link(self):\n\"\"\"\n        Returns:\n            None or RigidPrim: If supported, the fallback link associated with this link-based state if\n                no valid metalink is found\n        \"\"\"\n# No default link by default\n# TODO: Make NotImplementedError() and force downstream Object states to implement, once\n# assets are fully updated\nreturn self.obj.root_link\ndef initialize_link_mixin(self):\nassert not self._initialized\n# TODO: Extend logic to account for multiple instances of the same metalink? e.g: _0, _1, ... suffixes\nfor name, link in self.obj.links.items():\nif self.metalink_prefix in name:\nself._links[name] = link\nassert np.allclose(link.scale, self.obj.scale), \\\n                    f\"the meta link {name} has a inconsistent scale with the object {self.obj.name}\"\nif len(self._links) &gt; 0:\nself._link = list(self._links.values())[0]\n# Raise an error if we did not find a valid link\n# Note that we check the public accessor for self.link because a subclass might implement a fallback\n# default_link to use\nif self.link is None:\nraise ValueError(f\"Error: failed to initialize LinkBasedStateMixin {self.__class__.__name__} for object \"\nf\"{self.obj.name}; no metalink with prefix {self.metalink_prefix} found!\")\n</code></pre>"},{"location":"reference/object_states/link_based_state_mixin.html#object_states.link_based_state_mixin.LinkBasedStateMixin.link","title":"<code>link</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or RigidPrim: The link associated with this link-based state, if it exists</p>"},{"location":"reference/object_states/link_based_state_mixin.html#object_states.link_based_state_mixin.LinkBasedStateMixin.links","title":"<code>links</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>mapping from link names to links that match the metalink_prefix</p>"},{"location":"reference/object_states/link_based_state_mixin.html#object_states.link_based_state_mixin.LinkBasedStateMixin.metalink_prefix","title":"<code>metalink_prefix()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Unique keyword that defines the metalink associated with this object state</p> Source code in <code>omnigibson/object_states/link_based_state_mixin.py</code> <pre><code>@classproperty\ndef metalink_prefix(cls):\n\"\"\"\n    Returns:\n        str: Unique keyword that defines the metalink associated with this object state\n    \"\"\"\nNotImplementedError()\n</code></pre>"},{"location":"reference/object_states/max_temperature.html","title":"max_temperature","text":""},{"location":"reference/object_states/max_temperature.html#object_states.max_temperature.MaxTemperature","title":"<code>MaxTemperature</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>UpdateStateMixin</code></p> <p>This state remembers the highest temperature reached by an object.</p> Source code in <code>omnigibson/object_states/max_temperature.py</code> <pre><code>class MaxTemperature(AbsoluteObjectState, UpdateStateMixin):\n\"\"\"\n    This state remembers the highest temperature reached by an object.\n    \"\"\"\n@staticmethod\ndef get_dependencies():\nreturn AbsoluteObjectState.get_dependencies() + [Temperature]\ndef __init__(self, obj):\nsuper(MaxTemperature, self).__init__(obj)\nself.value = float(\"-inf\")\ndef _get_value(self):\nreturn self.value\ndef _set_value(self, new_value):\nself.value = new_value\nreturn True\ndef _update(self):\nself.value = max(self.obj.states[Temperature].get_value(), self.value)\n@property\ndef state_size(self):\nreturn 1\ndef _dump_state(self):\nreturn dict(max_temperature=self.value)\ndef _load_state(self, state):\nself.value = state[\"max_temperature\"]\ndef _serialize(self, state):\nreturn np.array([state[\"max_temperature\"]], dtype=float)\ndef _deserialize(self, state):\nreturn dict(max_temperature=state[0]), 1\n</code></pre>"},{"location":"reference/object_states/next_to.html","title":"next_to","text":""},{"location":"reference/object_states/object_state_base.html","title":"object_state_base","text":""},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.AbsoluteObjectState","title":"<code>AbsoluteObjectState</code>","text":"<p>         Bases: <code>BaseObjectState</code></p> <p>This class is used to track object states that are absolute, e.g. do not require a second object to compute the value.</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>class AbsoluteObjectState(BaseObjectState):\n\"\"\"\n    This class is used to track object states that are absolute, e.g. do not require a second object to compute\n    the value.\n    \"\"\"\n@abstractmethod\ndef _get_value(self):\nraise NotImplementedError()\n@abstractmethod\ndef _set_value(self, new_value):\nraise NotImplementedError()\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"AbsoluteObjectState\")\nreturn classes\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState","title":"<code>BaseObjectState</code>","text":"<p>         Bases: <code>Serializable</code>, <code>Registerable</code>, <code>Recreatable</code>, <code>ABC</code></p> <p>Base ObjectState class. Do NOT inherit from this class directly - use either AbsoluteObjectState or RelativeObjectState.</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>class BaseObjectState(Serializable, Registerable, Recreatable, ABC):\n\"\"\"\n    Base ObjectState class. Do NOT inherit from this class directly - use either AbsoluteObjectState or\n    RelativeObjectState.\n    \"\"\"\n@staticmethod\ndef get_dependencies():\n\"\"\"\n        Get the dependency states for this state, e.g. states that need to be explicitly enabled on the current object\n        before the current state is usable. States listed here will be enabled for all objects that have this current\n        state, and all dependency states will be processed on *all* objects prior to this state being processed on\n        *any* object.\n        Returns:\n            list of str: List of strings corresponding to state keys.\n        \"\"\"\nreturn []\n@staticmethod\ndef get_optional_dependencies():\n\"\"\"\n        Get states that should be processed prior to this state if they are already enabled. These states will not be\n        enabled because of this state's dependency on them, but if they are already enabled for another reason (e.g.\n        because of an ability or another state's dependency etc.), they will be processed on *all* objects prior to this\n        state being processed on *any* object.\n        Returns:\n            list of str: List of strings corresponding to state keys.\n        \"\"\"\nreturn []\ndef __init__(self, obj):\nsuper().__init__()\nself.obj = obj\nself._initialized = False\nself._cache = None\nself._changed = None\nself._last_t_updated = -1               # Last timestep when this state was updated\n@property\ndef stateful(self):\n\"\"\"\n        Returns:\n            bool: True if this object has a state that can be directly dumped / loaded via dump_state() and\n                load_state(), otherwise, returns False. Note that any sub object states that are NOT stateful do\n                not need to implement any of _dump_state(), _load_state(), _serialize(), or _deserialize()!\n        \"\"\"\n# Default is whether state size &gt; 0\nreturn self.state_size &gt; 0\n@property\ndef state_size(self):\nreturn 0\n@property\ndef cache(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping specific argument combinations from @self.get_value() to cached values and\n                information stored for that specific combination\n        \"\"\"\nreturn self._cache\ndef _initialize(self):\n\"\"\"\n        This function will be called once; should be used for any object state-related objects have been loaded.\n        \"\"\"\npass\ndef initialize(self):\n\"\"\"\n        Initialize this object state\n        \"\"\"\nassert not self._initialized, \"State is already initialized.\"\nself._initialize()\nself._initialized = True\ndef clear_cache(self):\n\"\"\"\n        Clears the internal cache\n        \"\"\"\n# Clear all entries\nself._cache = dict()\nself._changed = dict()\nself._last_t_updated = -1\ndef update_cache(self, get_value_args):\n\"\"\"\n        Updates the internal cached value based on the evaluation of @self._get_value(*get_value_args)\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value / @self._get_value\n        \"\"\"\nt = og.sim.current_time_step_index\n# Compute value and update cache\nval = self._get_value(*get_value_args)\nself._cache[get_value_args] = dict(value=val, info=self.cache_info(get_value_args=get_value_args), t=t)\ndef cache_info(self, get_value_args):\n\"\"\"\n        Helper function to cache relevant information at the current timestep.\n        Stores it under @self._cache[&lt;KEY&gt;][\"info\"]\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value whose caching information should be computed\n        Returns:\n            dict: Any caching information to include at the current timestep when this state's value is computed\n        \"\"\"\n# Default is an empty dictionary\nreturn dict()\ndef cache_is_valid(self, get_value_args):\n\"\"\"\n        Helper function to check whether the current cached value is valid or not at the current timestep.\n        Default is False unless we're at the current timestep.\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value whose cached values should be validated\n        Returns:\n            bool: True if the cache is valid, else False\n        \"\"\"\n# If t == the current timestep, then our cache is obviously valid otherwise we assume it isn't\nreturn True if self._cache[get_value_args][\"t\"] == og.sim.current_time_step_index else \\\n            self._cache_is_valid(get_value_args=get_value_args)\ndef _cache_is_valid(self, get_value_args):\n\"\"\"\n        Helper function to check whether the current cached value is valid or not at the current timestep.\n        Default is False. Subclasses should implement special logic otherwise.\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value whose cached values should be validated\n        Returns:\n            bool: True if the cache is valid, else False\n        \"\"\"\nreturn False\ndef has_changed(self, get_value_args, value, info, t):\n\"\"\"\n        A helper function to query whether this object state has changed between the current timestep and an arbitrary\n        previous timestep @t with the corresponding cached value @value and cache information @info\n        Note that this may require some non-trivial compute, so we leverage @t, in addition to @get_value_args,\n        as a unique key into an internal dictionary, such that specific @t will result in a computation conducted\n        exactly once.\n        This is done for performance reasons; so that multiple states relying on the same state dependency can all\n        query whether that state has changed between the same timesteps with only a single computation.\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value\n            value (any): Cached value computed at timestep @t for this object state\n            info (dict): Information calculated at timestep @t when computing this state's value\n            t (int): Initial timestep to compare against. This should be an index of the steps taken,\n                i.e. a value queried from og.sim.current_time_step_index at some point in time. It is assumed @value\n                and @info were computed at this timestep\n        Returns:\n            bool: Whether this object state has changed between @t and the current timestep index for the specific\n                @get_value_args\n        \"\"\"\n# Check current sim step index; if it doesn't match the internal value, we need to clear the changed history\ncurrent_t = og.sim.current_time_step_index\nif self._last_t_updated != current_t:\nself._changed = dict()\nself._last_t_updated = current_t\n# Compile t, args, and kwargs deterministically\nhistory_key = (t, *get_value_args)\n# If t == the current timestep, then we obviously haven't changed so our value is False\nif t == current_t:\nval = False\n# Otherwise, check if it already exists in our has changed dictionary; we return that value if so\nelif history_key in self._changed:\nval = self._changed[history_key]\n# Otherwise, we calculate the value and store it in our changed dictionary\nelse:\nval = self._has_changed(get_value_args=get_value_args, value=value, info=info)\nself._changed[history_key] = val\nreturn val\ndef _has_changed(self, get_value_args, value, info):\n\"\"\"\n        Checks whether the previous value evaluated at time @t has changed with the current timestep.\n        By default, it returns True.\n        Any custom checks should be overridden by subclass.\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value\n            value (any): Cached value computed at timestep @t for this object state\n            info (dict): Information calculated at timestep @t when computing this state's value\n        Returns:\n            bool: Whether the value has changed between @value and @info and the coresponding value and info computed\n                at the current timestep\n        \"\"\"\nreturn True\ndef get_value(self, *args, **kwargs):\n\"\"\"\n        Get this state's value\n        Returns:\n            any: Object state value given input @args and @kwargs\n        \"\"\"\nassert self._initialized\n# Compile args and kwargs deterministically\nkey = (*args, *tuple(kwargs.values()))\n# We need to see if we need to update our cache -- we do so if and only if one of the following conditions are met:\n# (a) key is NOT in the cache\n# (b) Our cache is not valid\nif key not in self._cache or not self.cache_is_valid(get_value_args=key):\n# Update the cache\nself.update_cache(get_value_args=key)\n# Value is the cached value\nval = self._cache[key][\"value\"]\nreturn val\ndef _get_value(self, *args, **kwargs):\nraise NotImplementedError\ndef set_value(self, *args, **kwargs):\n\"\"\"\n        Set this state's value\n        Returns:\n            bool: True if setting the value was successful, otherwise False\n        \"\"\"\nassert self._initialized\n# Clear cache because the state may be changed\nself.clear_cache()\n# Set the value\nval = self._set_value(*args, **kwargs)\nreturn val\ndef _set_value(self, *args, **kwargs):\nraise NotImplementedError\ndef remove(self):\n\"\"\"\n        Any cleanup functionality to deploy when @self.obj is removed from the simulator\n        \"\"\"\npass\ndef dump_state(self, serialized=False):\nassert self._initialized\nassert self.stateful\nreturn super().dump_state(serialized=serialized)\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseObjectState\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_OBJECT_STATES\nreturn REGISTERED_OBJECT_STATES\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.cache","title":"<code>cache</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping specific argument combinations from @self.get_value() to cached values and information stored for that specific combination</p>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.stateful","title":"<code>stateful</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>True if this object has a state that can be directly dumped / loaded via dump_state() and load_state(), otherwise, returns False. Note that any sub object states that are NOT stateful do not need to implement any of _dump_state(), _load_state(), _serialize(), or _deserialize()!</p>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.cache_info","title":"<code>cache_info(get_value_args)</code>","text":"<p>Helper function to cache relevant information at the current timestep. Stores it under @self._cache <p>Parameters:</p> Name Type Description Default <code>get_value_args</code> <code>tuple</code> <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value whose caching information should be computed</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Any caching information to include at the current timestep when this state's value is computed</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def cache_info(self, get_value_args):\n\"\"\"\n    Helper function to cache relevant information at the current timestep.\n    Stores it under @self._cache[&lt;KEY&gt;][\"info\"]\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value whose caching information should be computed\n    Returns:\n        dict: Any caching information to include at the current timestep when this state's value is computed\n    \"\"\"\n# Default is an empty dictionary\nreturn dict()\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.cache_is_valid","title":"<code>cache_is_valid(get_value_args)</code>","text":"<p>Helper function to check whether the current cached value is valid or not at the current timestep. Default is False unless we're at the current timestep.</p> <p>Parameters:</p> Name Type Description Default <code>get_value_args</code> <code>tuple</code> <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value whose cached values should be validated</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the cache is valid, else False</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def cache_is_valid(self, get_value_args):\n\"\"\"\n    Helper function to check whether the current cached value is valid or not at the current timestep.\n    Default is False unless we're at the current timestep.\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value whose cached values should be validated\n    Returns:\n        bool: True if the cache is valid, else False\n    \"\"\"\n# If t == the current timestep, then our cache is obviously valid otherwise we assume it isn't\nreturn True if self._cache[get_value_args][\"t\"] == og.sim.current_time_step_index else \\\n        self._cache_is_valid(get_value_args=get_value_args)\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.clear_cache","title":"<code>clear_cache()</code>","text":"<p>Clears the internal cache</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def clear_cache(self):\n\"\"\"\n    Clears the internal cache\n    \"\"\"\n# Clear all entries\nself._cache = dict()\nself._changed = dict()\nself._last_t_updated = -1\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.get_dependencies","title":"<code>get_dependencies()</code>  <code>staticmethod</code>","text":"<p>Get the dependency states for this state, e.g. states that need to be explicitly enabled on the current object before the current state is usable. States listed here will be enabled for all objects that have this current state, and all dependency states will be processed on all objects prior to this state being processed on any object.</p> <p>Returns:</p> Type Description <p>list of str: List of strings corresponding to state keys.</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>@staticmethod\ndef get_dependencies():\n\"\"\"\n    Get the dependency states for this state, e.g. states that need to be explicitly enabled on the current object\n    before the current state is usable. States listed here will be enabled for all objects that have this current\n    state, and all dependency states will be processed on *all* objects prior to this state being processed on\n    *any* object.\n    Returns:\n        list of str: List of strings corresponding to state keys.\n    \"\"\"\nreturn []\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.get_optional_dependencies","title":"<code>get_optional_dependencies()</code>  <code>staticmethod</code>","text":"<p>Get states that should be processed prior to this state if they are already enabled. These states will not be enabled because of this state's dependency on them, but if they are already enabled for another reason (e.g. because of an ability or another state's dependency etc.), they will be processed on all objects prior to this state being processed on any object.</p> <p>Returns:</p> Type Description <p>list of str: List of strings corresponding to state keys.</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>@staticmethod\ndef get_optional_dependencies():\n\"\"\"\n    Get states that should be processed prior to this state if they are already enabled. These states will not be\n    enabled because of this state's dependency on them, but if they are already enabled for another reason (e.g.\n    because of an ability or another state's dependency etc.), they will be processed on *all* objects prior to this\n    state being processed on *any* object.\n    Returns:\n        list of str: List of strings corresponding to state keys.\n    \"\"\"\nreturn []\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.get_value","title":"<code>get_value(*args, **kwargs)</code>","text":"<p>Get this state's value</p> <p>Returns:</p> Name Type Description <code>any</code> <p>Object state value given input @args and @kwargs</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def get_value(self, *args, **kwargs):\n\"\"\"\n    Get this state's value\n    Returns:\n        any: Object state value given input @args and @kwargs\n    \"\"\"\nassert self._initialized\n# Compile args and kwargs deterministically\nkey = (*args, *tuple(kwargs.values()))\n# We need to see if we need to update our cache -- we do so if and only if one of the following conditions are met:\n# (a) key is NOT in the cache\n# (b) Our cache is not valid\nif key not in self._cache or not self.cache_is_valid(get_value_args=key):\n# Update the cache\nself.update_cache(get_value_args=key)\n# Value is the cached value\nval = self._cache[key][\"value\"]\nreturn val\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.has_changed","title":"<code>has_changed(get_value_args, value, info, t)</code>","text":"<p>A helper function to query whether this object state has changed between the current timestep and an arbitrary previous timestep @t with the corresponding cached value @value and cache information @info</p> <p>Note that this may require some non-trivial compute, so we leverage @t, in addition to @get_value_args, as a unique key into an internal dictionary, such that specific @t will result in a computation conducted exactly once. This is done for performance reasons; so that multiple states relying on the same state dependency can all query whether that state has changed between the same timesteps with only a single computation.</p> <p>Parameters:</p> Name Type Description Default <code>get_value_args</code> <code>tuple</code> <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value</p> required <code>value</code> <code>any</code> <p>Cached value computed at timestep @t for this object state</p> required <code>info</code> <code>dict</code> <p>Information calculated at timestep @t when computing this state's value</p> required <code>t</code> <code>int</code> <p>Initial timestep to compare against. This should be an index of the steps taken, i.e. a value queried from og.sim.current_time_step_index at some point in time. It is assumed @value and @info were computed at this timestep</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this object state has changed between @t and the current timestep index for the specific @get_value_args</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def has_changed(self, get_value_args, value, info, t):\n\"\"\"\n    A helper function to query whether this object state has changed between the current timestep and an arbitrary\n    previous timestep @t with the corresponding cached value @value and cache information @info\n    Note that this may require some non-trivial compute, so we leverage @t, in addition to @get_value_args,\n    as a unique key into an internal dictionary, such that specific @t will result in a computation conducted\n    exactly once.\n    This is done for performance reasons; so that multiple states relying on the same state dependency can all\n    query whether that state has changed between the same timesteps with only a single computation.\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value\n        value (any): Cached value computed at timestep @t for this object state\n        info (dict): Information calculated at timestep @t when computing this state's value\n        t (int): Initial timestep to compare against. This should be an index of the steps taken,\n            i.e. a value queried from og.sim.current_time_step_index at some point in time. It is assumed @value\n            and @info were computed at this timestep\n    Returns:\n        bool: Whether this object state has changed between @t and the current timestep index for the specific\n            @get_value_args\n    \"\"\"\n# Check current sim step index; if it doesn't match the internal value, we need to clear the changed history\ncurrent_t = og.sim.current_time_step_index\nif self._last_t_updated != current_t:\nself._changed = dict()\nself._last_t_updated = current_t\n# Compile t, args, and kwargs deterministically\nhistory_key = (t, *get_value_args)\n# If t == the current timestep, then we obviously haven't changed so our value is False\nif t == current_t:\nval = False\n# Otherwise, check if it already exists in our has changed dictionary; we return that value if so\nelif history_key in self._changed:\nval = self._changed[history_key]\n# Otherwise, we calculate the value and store it in our changed dictionary\nelse:\nval = self._has_changed(get_value_args=get_value_args, value=value, info=info)\nself._changed[history_key] = val\nreturn val\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.initialize","title":"<code>initialize()</code>","text":"<p>Initialize this object state</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def initialize(self):\n\"\"\"\n    Initialize this object state\n    \"\"\"\nassert not self._initialized, \"State is already initialized.\"\nself._initialize()\nself._initialized = True\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.remove","title":"<code>remove()</code>","text":"<p>Any cleanup functionality to deploy when @self.obj is removed from the simulator</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def remove(self):\n\"\"\"\n    Any cleanup functionality to deploy when @self.obj is removed from the simulator\n    \"\"\"\npass\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.set_value","title":"<code>set_value(*args, **kwargs)</code>","text":"<p>Set this state's value</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if setting the value was successful, otherwise False</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def set_value(self, *args, **kwargs):\n\"\"\"\n    Set this state's value\n    Returns:\n        bool: True if setting the value was successful, otherwise False\n    \"\"\"\nassert self._initialized\n# Clear cache because the state may be changed\nself.clear_cache()\n# Set the value\nval = self._set_value(*args, **kwargs)\nreturn val\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.update_cache","title":"<code>update_cache(get_value_args)</code>","text":"<p>Updates the internal cached value based on the evaluation of @self._get_value(*get_value_args)</p> <p>Parameters:</p> Name Type Description Default <code>get_value_args</code> <code>tuple</code> <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value / @self._get_value</p> required Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>def update_cache(self, get_value_args):\n\"\"\"\n    Updates the internal cached value based on the evaluation of @self._get_value(*get_value_args)\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value / @self._get_value\n    \"\"\"\nt = og.sim.current_time_step_index\n# Compute value and update cache\nval = self._get_value(*get_value_args)\nself._cache[get_value_args] = dict(value=val, info=self.cache_info(get_value_args=get_value_args), t=t)\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.BooleanState","title":"<code>BooleanState</code>","text":"<p>This class is a mixin used to indicate that a state has a boolean value.</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>class BooleanState:\n\"\"\"\n    This class is a mixin used to indicate that a state has a boolean value.\n    \"\"\"\npass\n</code></pre>"},{"location":"reference/object_states/object_state_base.html#object_states.object_state_base.RelativeObjectState","title":"<code>RelativeObjectState</code>","text":"<p>         Bases: <code>BaseObjectState</code></p> <p>This class is used to track object states that are relative, e.g. require two objects to compute a value. Note that subclasses will typically compute values on-the-fly.</p> Source code in <code>omnigibson/object_states/object_state_base.py</code> <pre><code>class RelativeObjectState(BaseObjectState):\n\"\"\"\n    This class is used to track object states that are relative, e.g. require two objects to compute a value.\n    Note that subclasses will typically compute values on-the-fly.\n    \"\"\"\n@abstractmethod\ndef _get_value(self, other):\nraise NotImplementedError()\n@abstractmethod\ndef _set_value(self, other, new_value):\nraise NotImplementedError()\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"RelativeObjectState\")\nreturn classes\n</code></pre>"},{"location":"reference/object_states/on_fire.html","title":"on_fire","text":""},{"location":"reference/object_states/on_fire.html#object_states.on_fire.OnFire","title":"<code>OnFire</code>","text":"<p>         Bases: <code>HeatSourceOrSink</code>, <code>UpdateStateMixin</code></p> <p>This state indicates the heat source is currently on fire.</p> <p>Once the temperature is above ignition_temperature, OnFire will become True and stay True. Its temperature will further raise to fire_temperature, and start heating other objects around it. It may include a heatsource_link annotation (e.g. candle wick), in which case the fire visualization will be placed under that meta link. Otherwise (e.g. charcoal), the fire visualization will be placed under the root link.</p> Source code in <code>omnigibson/object_states/on_fire.py</code> <pre><code>class OnFire(HeatSourceOrSink, UpdateStateMixin):\n\"\"\"\n    This state indicates the heat source is currently on fire.\n    Once the temperature is above ignition_temperature, OnFire will become True and stay True.\n    Its temperature will further raise to fire_temperature, and start heating other objects around it.\n    It may include a heatsource_link annotation (e.g. candle wick), in which case the fire visualization will be placed\n    under that meta link. Otherwise (e.g. charcoal), the fire visualization will be placed under the root link.\n    \"\"\"\ndef __init__(\nself,\nobj,\nignition_temperature=m.DEFAULT_IGNITION_TEMPERATURE,\nfire_temperature=m.DEFAULT_FIRE_TEMPERATURE,\nheating_rate=m.DEFAULT_HEATING_RATE,\ndistance_threshold=m.DEFAULT_DISTANCE_THRESHOLD,\n):\n\"\"\"\n        Args:\n            obj (StatefulObject): The object with the heat source ability.\n            ignition_temperature (float): The temperature threshold above which on fire will become true.\n            fire_temperature (float): The temperature of the fire (heat source) once on fire is true.\n            heating_rate (float): Fraction in [0, 1] of the temperature difference with the\n                heat source temperature should be received every step, per second.\n            distance_threshold (float): The distance threshold which an object needs\n                to be closer than in order to receive heat from this heat source.\n        \"\"\"\nassert fire_temperature &gt; ignition_temperature, \"fire temperature should be higher than ignition temperature.\"\nsuper().__init__(\nobj,\ntemperature=fire_temperature,\nheating_rate=heating_rate,\ndistance_threshold=distance_threshold,\nrequires_toggled_on=False,\nrequires_closed=False,\nrequires_inside=False,\n)\nself.ignition_temperature = ignition_temperature\n@staticmethod\ndef get_dependencies():\nreturn HeatSourceOrSink.get_dependencies() + [Temperature]\ndef _update(self):\n# If it's on fire, maintain the fire temperature\nif self.get_value():\nself.obj.states[Temperature].set_value(self.temperature)\ndef _get_value(self):\nreturn self.obj.states[Temperature].get_value() &gt;= self.ignition_temperature\ndef _set_value(self, new_value):\nif new_value:\nreturn self.obj.states[Temperature].set_value(self.temperature)\nelse:\n# We'll set the temperature just one degree below ignition.\nreturn self.obj.states[Temperature].set_value(self.ignition_temperature - 1)\n# Nothing needs to be done to save/load OnFire\n</code></pre>"},{"location":"reference/object_states/on_fire.html#object_states.on_fire.OnFire.__init__","title":"<code>__init__(obj, ignition_temperature=m.DEFAULT_IGNITION_TEMPERATURE, fire_temperature=m.DEFAULT_FIRE_TEMPERATURE, heating_rate=m.DEFAULT_HEATING_RATE, distance_threshold=m.DEFAULT_DISTANCE_THRESHOLD)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>The object with the heat source ability.</p> required <code>ignition_temperature</code> <code>float</code> <p>The temperature threshold above which on fire will become true.</p> <code>m.DEFAULT_IGNITION_TEMPERATURE</code> <code>fire_temperature</code> <code>float</code> <p>The temperature of the fire (heat source) once on fire is true.</p> <code>m.DEFAULT_FIRE_TEMPERATURE</code> <code>heating_rate</code> <code>float</code> <p>Fraction in [0, 1] of the temperature difference with the heat source temperature should be received every step, per second.</p> <code>m.DEFAULT_HEATING_RATE</code> <code>distance_threshold</code> <code>float</code> <p>The distance threshold which an object needs to be closer than in order to receive heat from this heat source.</p> <code>m.DEFAULT_DISTANCE_THRESHOLD</code> Source code in <code>omnigibson/object_states/on_fire.py</code> <pre><code>def __init__(\nself,\nobj,\nignition_temperature=m.DEFAULT_IGNITION_TEMPERATURE,\nfire_temperature=m.DEFAULT_FIRE_TEMPERATURE,\nheating_rate=m.DEFAULT_HEATING_RATE,\ndistance_threshold=m.DEFAULT_DISTANCE_THRESHOLD,\n):\n\"\"\"\n    Args:\n        obj (StatefulObject): The object with the heat source ability.\n        ignition_temperature (float): The temperature threshold above which on fire will become true.\n        fire_temperature (float): The temperature of the fire (heat source) once on fire is true.\n        heating_rate (float): Fraction in [0, 1] of the temperature difference with the\n            heat source temperature should be received every step, per second.\n        distance_threshold (float): The distance threshold which an object needs\n            to be closer than in order to receive heat from this heat source.\n    \"\"\"\nassert fire_temperature &gt; ignition_temperature, \"fire temperature should be higher than ignition temperature.\"\nsuper().__init__(\nobj,\ntemperature=fire_temperature,\nheating_rate=heating_rate,\ndistance_threshold=distance_threshold,\nrequires_toggled_on=False,\nrequires_closed=False,\nrequires_inside=False,\n)\nself.ignition_temperature = ignition_temperature\n</code></pre>"},{"location":"reference/object_states/on_top.html","title":"on_top","text":""},{"location":"reference/object_states/open.html","title":"open","text":""},{"location":"reference/object_states/open.html#object_states.open.Open","title":"<code>Open</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>BooleanState</code></p> Source code in <code>omnigibson/object_states/open.py</code> <pre><code>class Open(AbsoluteObjectState, BooleanState):\ndef __init__(self, obj):\nself.relevant_joints_info = None\n# Run super method\nsuper().__init__(obj=obj)\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Check the metadata info to get relevant joints information\nself.relevant_joints_info = _get_relevant_joints(self.obj)\ndef _get_value(self):\nboth_sides, relevant_joints, joint_directions = self.relevant_joints_info\nif not relevant_joints:\nreturn False\n# The \"sides\" variable is used to check open/closed state for objects whose joints can switch\n# positions. These objects are annotated with the both_sides annotation and the idea is that switching\n# the directions of *all* of the joints results in a similarly valid checkable state. As a result, to check\n# each \"side\", we multiply *all* of the joint directions with the coefficient belonging to that side, which\n# may be 1 or -1.\nsides = [1, -1] if both_sides else [1]\nsides_openness = []\nfor side in sides:\n# Compute a boolean openness state for each joint by comparing positions to thresholds.\njoint_thresholds = (\n_compute_joint_threshold(joint, joint_direction * side)\nfor joint, joint_direction in zip(relevant_joints, joint_directions)\n)\njoint_positions = [joint.get_state()[0] for joint in relevant_joints]\njoint_openness = (\n_is_in_range(position, threshold, open_end)\nfor position, (threshold, open_end, closed_end) in zip(joint_positions, joint_thresholds)\n)\n# Looking from this side, the object is open if any of its joints is open.\nsides_openness.append(any(joint_openness))\n# The object is open only if it's open from all of its sides.\nreturn all(sides_openness)\ndef _set_value(self, new_value, fully=False):\n\"\"\"\n        Set the openness state, either to a random joint position satisfying the new value, or fully open/closed.\n        @param new_value: bool value for the openness state of the object.\n        @param fully: whether the object should be fully opened/closed (e.g. all relevant joints to 0/1).\n        @return: bool indicating setter success. Failure may happen due to unannotated objects.\n        \"\"\"\nboth_sides, relevant_joints, joint_directions = self.relevant_joints_info\nif not relevant_joints:\nreturn False\n# The \"sides\" variable is used to check open/closed state for objects whose joints can switch\n# positions. These objects are annotated with the both_sides annotation and the idea is that switching\n# the directions of *all* of the joints results in a similarly valid checkable state. We want our object to be\n# open from *both* of the two sides, and I was too lazy to implement the logic for this without rejection\n# sampling, so that's what we do.\n# TODO: Implement a sampling method that's guaranteed to be correct, ditch the rejection method.\nsides = [1, -1] if both_sides else [1]\nfor _ in range(m.OPEN_SAMPLING_ATTEMPTS):\nside = random.choice(sides)\n# All joints are relevant if we are closing, but if we are opening let's sample a subset.\nif new_value and not fully:\nnum_to_open = random.randint(1, len(relevant_joints))\nrelevant_joints = random.sample(relevant_joints, num_to_open)\n# Go through the relevant joints &amp; set random positions.\nfor joint, joint_direction in zip(relevant_joints, joint_directions):\nthreshold, open_end, closed_end = _compute_joint_threshold(joint, joint_direction * side)\n# Get the range\nif new_value:\njoint_range = (threshold, open_end)\nelse:\njoint_range = (threshold, closed_end)\nif fully:\njoint_pos = joint_range[1]\nelse:\n# Convert the range to the format numpy accepts.\nlow = min(joint_range)\nhigh = max(joint_range)\n# Sample a position.\njoint_pos = random.uniform(low, high)\n# Save sampled position.\njoint.set_pos(joint_pos)\n# If we succeeded, return now.\nif self._get_value() == new_value:\nreturn True\n# We exhausted our attempts and could not find a working sample.\nreturn False\n# We don't need to load / save anything since the joints are saved elsewhere\n</code></pre>"},{"location":"reference/object_states/overlaid.html","title":"overlaid","text":""},{"location":"reference/object_states/overlaid.html#object_states.overlaid.Overlaid","title":"<code>Overlaid</code>","text":"<p>         Bases: <code>KinematicsMixin</code>, <code>RelativeObjectState</code>, <code>BooleanState</code></p> Source code in <code>omnigibson/object_states/overlaid.py</code> <pre><code>class Overlaid(KinematicsMixin, RelativeObjectState, BooleanState):\n@staticmethod\ndef get_dependencies():\nreturn KinematicsMixin.get_dependencies() + RelativeObjectState.get_dependencies() + [Touching]\ndef _set_value(self, other, new_value):\nif not new_value:\nraise NotImplementedError(\"Overlaid does not support set_value(False)\")\nif not (self.obj.prim_type == PrimType.CLOTH and other.prim_type == PrimType.RIGID):\nraise ValueError(\"Overlaid state requires obj1 is cloth and obj2 is rigid.\")\nstate = og.sim.dump_state(serialized=False)\n# Get the top center of the object below\naabb_low, aabb_hi = other.states[AABB].get_value()\ntop_center = np.array([(aabb_low[0] + aabb_hi[0]) / 2.0, (aabb_low[1] + aabb_hi[1]) / 2.0, aabb_hi[2]])\n# Reset the cloth\nself.obj.root_link.reset()\n# Add the half-extent of the object on top in the z-axis with additional offset\naabb_low, aabb_hi = self.obj.states[AABB].get_value()\npos = top_center + np.array([0., 0., (aabb_hi - aabb_low)[2] / 2.0 + m.SAMPLING_Z_OFFSET])\nfor _ in range(10):\n# Use a random orientation in the z-axis\norn = T.euler2quat(np.array([0., 0., np.random.uniform(0, np.pi * 2)]))\nself.obj.set_position_orientation(pos, orn)\nself.obj.root_link.reset()\nself.obj.keep_still()\n# Let it fall for 0.2 second\nfor _ in range(int(0.2 / og.sim.get_physics_dt())):\nog.sim.step_physics()\nif len(self.obj.states[ContactBodies].get_value()) &gt; 0:\nbreak\nself.obj.keep_still()\nif self.get_value(other) == new_value:\nreturn True\nelse:\nog.sim.load_state(state, serialized=False)\nreturn False\ndef _get_value(self, other):\n\"\"\"\n        Check whether the (cloth) object is overlaid on the other (rigid) object.\n        First, the two objects need to be Touching.\n        Then, the convex hull of the particles of the cloth object needs to cover a decent percentage of the\n        base aligned bounding box of the other rigid object.\n        \"\"\"\nif not (self.obj.prim_type == PrimType.CLOTH and other.prim_type == PrimType.RIGID):\nraise ValueError(\"Overlaid state requires obj1 is cloth and obj2 is rigid.\")\n# Make sure the two objects are touching.\ntouching = self.obj.states[Touching].get_value(other)\nif not touching:\nreturn False\n# Compute the convex hull of the particles of the cloth object.\npoints = self.obj.root_link.keypoint_particle_positions[:, :2]\ncloth_hull = ConvexHull(points)\n# Compute the base aligned bounding box of the rigid object.\nbbox_center, bbox_orn, bbox_extent, _ = other.get_base_aligned_bbox(xy_aligned=True)\nvertices_local = np.array(list(itertools.product((1, -1), repeat=3))) * (bbox_extent / 2)\nvertices = trimesh.transformations.transform_points(vertices_local, T.pose2mat((bbox_center, bbox_orn)))\nrigid_hull = ConvexHull(vertices[:, :2])\n# The goal is to find the intersection of the convex hull and the bounding box.\n# We can do so with HalfspaceIntersection, which takes as input a list of equations that define the half spaces,\n# and an interior point. We assume the center of the bounding box is an interior point.\ninterior_pt = vertices.mean(axis=0)[:2]\nhalf_spaces = np.vstack((cloth_hull.equations, rigid_hull.equations))\ntry:\nhalf_space_intersection = HalfspaceIntersection(half_spaces, interior_pt)\nexcept QhullError:\n# The bbox center of the rigid body does not lie in the intersection, return False.\nreturn False\n# Compute the ratio between the intersection area and the bounding box area in the x-y plane.\n# When input points are 2-dimensional, this is the area of the convex hull.\n# Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html\nintersection_area = ConvexHull(half_space_intersection.intersections).volume\nrigid_xy_area = bbox_extent[0] * bbox_extent[1]\nreturn (intersection_area / rigid_xy_area) &gt; m.OVERLAP_AREA_PERCENTAGE\n</code></pre>"},{"location":"reference/object_states/particle_modifier.html","title":"particle_modifier","text":""},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleApplier","title":"<code>ParticleApplier</code>","text":"<p>         Bases: <code>ParticleModifier</code></p> <p>ParticleModifier where the modification results in potentially adding particles into the simulation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>Object to which this state will be applied</p> required <code>method</code> <code>ParticleModifyMethod</code> <p>Method to modify particles. Current options supported are: ADJACENCY (i.e.: \"touching\" particles) PROJECTION (i.e.: \"spraying\" particles)</p> required <code>conditions</code> <code>dict</code> <p>Dictionary mapping ParticleSystem to None or corresponding condition / list of conditions (where None represents no conditions) necessary in order for this particle modifier to be able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature is as follows:</p> <pre><code>def condition(obj) --&gt; bool\n</code></pre> <p>Where @obj is the specific object that this ParticleModifier state belongs to. For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within this particle modifier area, then we potentially modify those particles</p> required <code>projection_mesh_params</code> <code>None or dict</code> <p>If specified and @method is ParticleModifyMethod.PROJECTION, manually overrides any metadata found from @obj.metadata to infer what projection volume to generate for this particle modifier. Expected entries are as follows:</p> <pre><code>\"type\": (str), one of {\"Cylinder\", \"Cone\", \"Sphere\"}\n\"extents\": (3-array), the (x,y,z) extents of the generated volume (specified in local link frame!)\n\"visualize\": (bool), whether to visualize this projection or not\n</code></pre> <p>If None, information found from @obj.metadata will be used instead.</p> <code>None</code> <code>sample_with_raycast</code> <code>bool</code> <p>If True, will only sample particles at raycast hits. Otherwise, will bypass sampling and immediately sample particles at the sampled particle locations. Note that this will only work for PhysicalParticleSystem-based ParticleAppliers that use the Projection method!</p> <code>True</code> <code>initial_speed</code> <code>float</code> <p>For physical particles, the initial speed for generated particles. Note that the direction of the velocity is inferred from the particle sampling process.</p> <code>0.0</code> Source code in <code>omnigibson/object_states/particle_modifier.py</code> <pre><code>class ParticleApplier(ParticleModifier):\n\"\"\"\n    ParticleModifier where the modification results in potentially adding particles into the simulation.\n    Args:\n        obj (StatefulObject): Object to which this state will be applied\n        method (ParticleModifyMethod): Method to modify particles. Current options supported are:\n            ADJACENCY (i.e.: \"touching\" particles)\n            PROJECTION (i.e.: \"spraying\" particles)\n        conditions (dict): Dictionary mapping ParticleSystem to None or corresponding condition / list of conditions\n            (where None represents no conditions) necessary in order for this particle modifier to be able to\n            modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature\n            is as follows:\n                def condition(obj) --&gt; bool\n            Where @obj is the specific object that this ParticleModifier state belongs to.\n            For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within\n            this particle modifier area, then we potentially modify those particles\n        projection_mesh_params (None or dict): If specified and @method is ParticleModifyMethod.PROJECTION,\n            manually overrides any metadata found from @obj.metadata to infer what projection volume to generate\n            for this particle modifier. Expected entries are as follows:\n                \"type\": (str), one of {\"Cylinder\", \"Cone\", \"Sphere\"}\n                \"extents\": (3-array), the (x,y,z) extents of the generated volume (specified in local link frame!)\n                \"visualize\": (bool), whether to visualize this projection or not\n            If None, information found from @obj.metadata will be used instead.\n        sample_with_raycast (bool): If True, will only sample particles at raycast hits. Otherwise, will bypass sampling\n            and immediately sample particles at the sampled particle locations. Note that this will only work\n            for PhysicalParticleSystem-based ParticleAppliers that use the Projection method!\n        initial_speed (float): For physical particles, the initial speed for generated particles. Note that the\n            direction of the velocity is inferred from the particle sampling process.\n        \"\"\"\ndef __init__(self, obj, method, conditions, projection_mesh_params=None, sample_with_raycast=True, initial_speed=0.0):\n# Store internal value\nself._sample_particle_locations = None\nself._sample_with_raycast = sample_with_raycast\nself._initial_speed = initial_speed\n# Pre-cached values for where particles should be spawned, and in what direction, when this state is\n# initialized so we can quickly spawn them at runtime\nself._in_mesh_local_particle_positions = None\nself._in_mesh_local_particle_directions = None\n# Run super\nsuper().__init__(obj=obj, method=method, conditions=conditions, projection_mesh_params=projection_mesh_params)\ndef _initialize(self):\n# First, sanity check to make sure only one system is being applied, since unlike a ParticleRemover, which\n# can potentially remove multiple types of particles, a ParticleApplier should only apply one type of particle\nassert len(self.conditions) == 1, f\"A ParticleApplier can only have a single ParticleSystem associated \" \\\n                                          f\"with it! Got: {[system_name for system_name in self.conditions.keys()]}\"\n# Run super\nsuper()._initialize()\nsystem_name = list(self.conditions.keys())[0]\n# get_system will initialize the system if it's not initialized already.\nsystem = get_system(system_name)\nif self.method == ParticleModifyMethod.PROJECTION and self._projection_mesh_params[\"visualize\"]:\nradius, height = self._projection_mesh_params[\"extents\"][0] / 2.0, self._projection_mesh_params[\"extents\"][2]\n# Generate the projection visualization\nparticle_radius = m.VISUAL_PARTICLE_PROJECTION_PARTICLE_RADIUS if issubclass(system, VisualParticleSystem) else system.particle_radius\nparticle_material = system.particle_object.material if issubclass(system, VisualParticleSystem) else system.material\nname_prefix = f\"{self.obj.name}_{self.__class__.__name__}\"\n# Create the projection visualization if it doesn't already exist, otherwise we reference it directly\nprojection_name = f\"{name_prefix}_projection_visualization\"\nprojection_path = f\"/OmniGraph/{projection_name}\"\nprojection_visualization_path = f\"{self.link.prim_path}/projection_visualization\"\nif is_prim_path_valid(projection_path):\nself.projection_system = get_prim_at_path(projection_path)\nself.projection_emitter = get_prim_at_path(f\"{projection_path}/emitter\")\nelse:\nself.projection_system, self.projection_emitter = create_projection_visualization(\nprim_path=projection_visualization_path,\nshape=self._projection_mesh_params[\"type\"],\nprojection_name=projection_name,\nprojection_radius=radius,\nprojection_height=height,\nparticle_radius=particle_radius,\nmaterial=particle_material,\n)\n# Create the visual geom instance referencing the generated source mesh prim, and then hide it\nself.projection_source_sphere = VisualGeomPrim(prim_path=projection_visualization_path, name=f\"{name_prefix}_projection_source_sphere\")\nself.projection_source_sphere.initialize()\nself.projection_source_sphere.visible = False\n# Rotate by 90 degrees in y-axis so that the projection visualization aligns with the projection mesh\nself.projection_source_sphere.set_orientation(T.euler2quat([0, np.pi / 2, 0]))\n# Store which method to use for sampling particle locations\nif self._sample_with_raycast:\nif self.method == ParticleModifyMethod.PROJECTION:\nself._sample_particle_locations = self._sample_particle_locations_from_projection_volume\nelif self.method == ParticleModifyMethod.ADJACENCY:\nself._sample_particle_locations = self._sample_particle_locations_from_adjacency_area\nelse:\nraise ValueError(f\"Unsupported ParticleModifyMethod: {self.method}!\")\nelse:\n# Make sure we're only using a physical particle system and the projection method\nassert issubclass(system, PhysicalParticleSystem), \\\n                \"If not sampling with raycast, ParticleApplier only supports PhysicalParticleSystems!\"\nassert self.method == ParticleModifyMethod.PROJECTION, \\\n                \"If not sampling with raycast, ParticleApplier only supports ParticleModifyMethod.PROJECTION method!\"\n# Override the check overlap function -- this now always returns True because we don't require contact with\n# anything in order to generate particles\nself._check_overlap = lambda: True\n# Compute particle spawning information once\nself._compute_particle_spawn_information(system=system)\ndef _compute_particle_spawn_information(self, system):\n\"\"\"\n        Helper function to compute where particles should be spawned. This is to save computation time at runtime\n        if @self._sample_with_raycast is False, meaning that we were deterministically sample particles.\n        Args:\n            system (ParticleSystem): Particle system whose particles will be spawned from this ParticleApplier\n        \"\"\"\n# We now pre-compute local particle positions that are within the projection mesh used to infer spawn pos\n# We sample the range of each extent minus the particle radius\nsampling_distance = 2 * system.particle_radius\nextent = np.array(self._projection_mesh_params[\"extents\"])\nh = extent[2]\nlow = np.array([-extent[0] / 2, -extent[1] / 2, -h])\nhigh = np.array([extent[0] / 2, extent[1] / 2, 0])\nn_particles_per_axis = (extent / sampling_distance).astype(int)\nassert np.all(n_particles_per_axis), f\"link {self.link.name} is too small to sample any particle of radius {system.particle_radius}.\"\n# 1e-10 is added because the extent might be an exact multiple of particle radius\narrs = [np.arange(lo + system.particle_radius, hi - system.particle_radius + 1e-10, system.particle_radius * 2)\nfor lo, hi, n in zip(low, high, n_particles_per_axis)]\n# Generate 3D-rectangular grid of points, and only keep the ones inside the mesh\npoints = np.stack([arr.flatten() for arr in np.meshgrid(*arrs)]).T\npos, quat = self.link.get_position_orientation()\npoints_in_world_frame = get_particle_positions_from_frame(\npos=pos,\nquat=quat,\nscale=self.obj.scale,\nparticle_positions=points,\n)\npoints = points[np.where(self._check_in_mesh(points_in_world_frame))[0]]\nn_max_particles = self._get_max_particles_limit_per_step(system=system)\n# Potentially sub-sample points based on max particle limit per step\nself._in_mesh_local_particle_positions = points if n_max_particles &gt; len(points) else \\\n            points[np.random.choice(len(points), n_max_particles, replace=False)]\n# Also programmatically compute the directions of each particle position -- this is the normalized\n# vector pointing from source to the particle\nprojection_type = self._projection_mesh_params[\"type\"]\nif projection_type == \"Cone\":\n# Particles point from source ([0, 0, 0]) to point location\ndirections = np.copy(self._in_mesh_local_particle_positions)\nelif projection_type == \"Cylinder\":\n# All particle points in the same parallel direction towards the -z direction\ndirections = np.zeros_like(self._in_mesh_local_particle_positions)\ndirections[:, 2] = -h\nelse:\nraise ValueError(\n\"If not sampling with raycast, ParticleApplier only supports `Cone` or `Cylinder` projection types!\")\nself._in_mesh_local_particle_directions = directions / np.linalg.norm(directions, axis=-1).reshape(-1, 1)\ndef _modify_particles(self, system):\n# If at the limit, don't modify anything\nif self.check_at_limit(system=system):\nreturn\nif self._sample_with_raycast:\n# Sample potential locations to apply particles, and then apply them\nstart_points, end_points = self._sample_particle_locations(system=system)\nn_samples = len(start_points)\nif issubclass(system, VisualParticleSystem):\ngroup = system.get_group_name(obj=self.obj)\n# Create an attachment group if necessary\nif group not in system.groups:\nsystem.create_attachment_group(obj=self.obj)\navg_scale = np.cbrt(np.product(self.obj.scale))\nscales = system.sample_scales(group=group, n=len(start_points))\ncuboid_dimensions = scales * system.particle_object.aabb_extent.reshape(1, 3) * avg_scale\nelse:\nscales = None\ncuboid_dimensions = np.zeros(3)\n# Sample the rays to see where particle can be generated\nresults = sample_cuboid_on_object(\nobj=None,\nstart_points=start_points.reshape(n_samples, 1, 3),\nend_points=end_points.reshape(n_samples, 1, 3),\ncuboid_dimensions=cuboid_dimensions,\nignore_objs=[self.obj],\nhit_proportion=0.0,             # We want all hits\ncuboid_bottom_padding=system.particle_radius if issubclass(system, PhysicalParticleSystem) else\nmacros.utils.sampling_utils.DEFAULT_CUBOID_BOTTOM_PADDING,\nundo_cuboid_bottom_padding=issubclass(system, VisualParticleSystem),      # micro particles have zero cuboid dimensions so we need to maintain padding\nverify_cuboid_empty=False,\n)\nhits = [result for result in results if result[0] is not None]\nscales = [scale for scale, result in zip(scales, results) if result[0] is not None] if scales is not None else scales\nself._apply_particles_at_raycast_hits(system=system, hits=hits, scales=scales)\nelse:\nself._apply_particles_in_projection_volume(system=system)\ndef _apply_particles_at_raycast_hits(self, system, hits, scales=None):\n\"\"\"\n        Helper function to apply particles from system @system given raycast hits @hits,\n        which are the filtered results from omnigibson.utils.sampling_utils.raytest_batch that include only\n        the results with a valid hit\n        Args:\n            system (ParticleSystem): System to apply particles from\n            hits (list of dict): Valid hit results from a batched raycast representing locations for sampling particles\n            scales (list of numpy arrays or None): None or scales of the particles that should be sampled, same length as hits\n        \"\"\"\nassert system.name in self.conditions, f\"System {system.name} is not defined in the conditions.\"\n# Check the system\nif issubclass(system, VisualParticleSystem):\nassert scales is not None, \"applying visual particles at raycast hits requires scales.\"\nassert len(hits) == len(scales), \"length of hits and scales are different when spawning visual particles.\"\n# Sample potential application points\nz_up = np.zeros(3)\nz_up[-1] = 1.0\nn_particles = min(len(hits), m.VISUAL_PARTICLES_APPLICATION_LIMIT - self.modified_particle_count[system.name])\n# Generate particle info -- maps group name to particle info for that group,\n# i.e.: positions, orientations, and link_prim_paths\nparticles_info = defaultdict(lambda: defaultdict(lambda: []))\nfor hit, scale in zip(hits[:n_particles], scales[:n_particles]):\n# Infer which object was hit\nhit_obj = og.sim.scene.object_registry(\"prim_path\", \"/\".join(hit[3].split(\"/\")[:-1]), None)\nif hit_obj is not None:\n# Create an attachment group if necessary\ngroup = system.get_group_name(obj=hit_obj)\nif group not in system.groups:\nsystem.create_attachment_group(obj=hit_obj)\n# Add to info\nparticles_info[group][\"positions\"].append(hit[0])\nparticles_info[group][\"orientations\"].append(hit[2])\nparticles_info[group][\"scales\"].append(scale)\nparticles_info[group][\"link_prim_paths\"].append(hit[3])\n# Generate all the particles for each group\nfor group, particle_info in particles_info.items():\n# Generate particles for this group\nsystem.generate_group_particles(\ngroup=group,\npositions=np.array(particle_info[\"positions\"]),\norientations=np.array(particle_info[\"orientations\"]),\nscales=np.array(particles_info[group][\"scales\"]),\nlink_prim_paths=particle_info[\"link_prim_paths\"],\n)\n# Update our particle count\nself.modified_particle_count[system.name] += len(particle_info[\"link_prim_paths\"])\nelif issubclass(system, PhysicalParticleSystem):\n# Compile the particle poses to generate and sample the particles\nn_particles = min(len(hits), m.PHYSICAL_PARTICLES_APPLICATION_LIMIT - self.modified_particle_count[system.name])\n# Generate particles\nif n_particles &gt; 0:\nvelocities = None if self._initial_speed == 0 else -self._initial_speed * np.array([hit[1] for hit in hits[:n_particles]])\nsystem.default_particle_instancer.add_particles(\npositions=np.array([hit[0] for hit in hits[:n_particles]]),\nvelocities=velocities,\n)\n# Update our particle count\nself.modified_particle_count[system.name] += n_particles\ndef _apply_particles_in_projection_volume(self, system):\n\"\"\"\n        Helper function to apply particles form system @system within the projection volume owned by this\n        ParticleApplier.\n        NOTE: This function only supports PhysicalParticleSystems and ParticleModifyMethod.PROJECTION method, which\n        should have been asserted during this ParticleApplier's initialize() call\n        Args:\n            system (ParticleSystem): System to apply particles from\n        \"\"\"\nassert self.method == ParticleModifyMethod.PROJECTION, \\\n            \"Can only apply particles within projection volume if ParticleModifyMethod.PROJECTION method is used!\"\nassert issubclass(system, PhysicalParticleSystem), \\\n            \"Can only apply particles within projection volume if system is PhysicalParticleSystem!\"\n# Transform pre-cached particle positions into the world frame\npos, quat = self.link.get_position_orientation()\npoints = get_particle_positions_from_frame(\npos=pos,\nquat=quat,\nscale=self.obj.scale,\nparticle_positions=self._in_mesh_local_particle_positions,\n)\ndirections = self._in_mesh_local_particle_directions @ T.quat2mat(quat).T\n# Compile the particle poses to generate and sample the particles\nn_particles = min(len(points), m.PHYSICAL_PARTICLES_APPLICATION_LIMIT - self.modified_particle_count[system.name])\n# Generate particles\nif n_particles &gt; 0:\nvelocities = None if self._initial_speed == 0 else self._initial_speed * directions[:n_particles]\nsystem.default_particle_instancer.add_particles(\npositions=points[:n_particles],\nvelocities=velocities,\n)\n# Update our particle count\nself.modified_particle_count[system.name] += n_particles\ndef _sample_particle_locations_from_projection_volume(self, system):\n\"\"\"\n        Helper function for generating potential particle locations from projection volume\n        Args:\n            system (ParticleSystem): System to sample potential particle positions for\n        Returns:\n            2-tuple:\n                - (n, 3) array: Ray start points to sample\n                - (n, 3) array: Ray end points to sample\n        \"\"\"\n# Randomly sample end points from the base of the cone / cylinder\nn_samples = self._get_max_particles_limit_per_step(system=system)\nr, h = self._projection_mesh_params[\"extents\"][0] / 2, self._projection_mesh_params[\"extents\"][2]\nsampled_r_theta = np.random.rand(n_samples, 2)\nsampled_r_theta = sampled_r_theta * np.array([r, np.pi * 2]).reshape(1, 2)\n# Get start, end points in local link frame, start points to end points along the -z direction\nend_points = np.stack([\nsampled_r_theta[:, 0] * np.cos(sampled_r_theta[:, 1]),\nsampled_r_theta[:, 0] * np.sin(sampled_r_theta[:, 1]),\n-h * np.ones(n_samples),\n], axis=1)\nprojection_type = self._projection_mesh_params[\"type\"]\nif projection_type == \"Cone\":\n# All start points are the cone tip, which is the local link origin\nstart_points = np.zeros((n_samples, 3))\nelif projection_type == \"Cylinder\":\n# All start points are the parallel point for their corresponding end point\n# i.e.: (x, y, 0)\nstart_points = end_points + np.array([0, 0, h]).reshape(1, 3)\nelse:\n# Other types not supported\nraise ValueError(f\"Unsupported projection mesh type: {projection_type}!\")\n# Convert sampled normalized radius and angle into 3D points\n# We convert r, theta --&gt; 3D point in local link frame --&gt; 3D point in global world frame\n# We also combine start and end points for efficiency when doing the transform, then split them up again\npoints = np.concatenate([start_points, end_points], axis=0)\npos, quat = self.link.get_position_orientation()\npoints = get_particle_positions_from_frame(\npos=pos,\nquat=quat,\nscale=self.obj.scale,\nparticle_positions=points,\n)\nreturn points[:n_samples, :], points[n_samples:, :]\ndef _sample_particle_locations_from_adjacency_area(self, system):\n\"\"\"\n        Helper function for generating potential particle locations from adjacency area\n        Args:\n            system (ParticleSystem): System to sample potential particle positions for\n        Returns:\n            2-tuple:\n                - (n, 3) array: Ray start points to sample\n                - (n, 3) array: Ray end points to sample\n        \"\"\"\n# Randomly sample end points from within the object's AABB\nn_samples = self._get_max_particles_limit_per_step(system=system)\nlower, upper = self.link.aabb\nlower = lower.reshape(1, 3) - m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\nupper = upper.reshape(1, 3) + m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\nlower_upper = np.concatenate([lower, upper], axis=0)\n# Sample in all directions, shooting from the center of the link / object frame\npos = self.link.get_position()\nstart_points = np.ones((n_samples, 3)) * pos.reshape(1, 3)\nend_points = np.random.uniform(low=lower, high=upper, size=(n_samples, 3))\nsides, axes = np.random.randint(2, size=(n_samples,)), np.random.randint(3, size=(n_samples,))\nend_points[np.arange(n_samples), axes] = lower_upper[sides, axes]\nreturn start_points, end_points\ndef _get_max_particles_limit_per_step(self, system):\n\"\"\"\n        Helper function for grabbing the maximum particle limit per step\n        Args:\n            system (ParticleSystem): System for which to get max particle limit per step\n        Returns:\n            int: Maximum particles to apply per step for the given system @system\n        \"\"\"\nassert system.name in self.conditions, f\"System {system.name} is not defined in the conditions.\"\n# Check the system\nif issubclass(system, VisualParticleSystem):\nval = m.MAX_VISUAL_PARTICLES_APPLIED_PER_STEP\nelif issubclass(system, PhysicalParticleSystem):\nval = m.MAX_PHYSICAL_PARTICLES_APPLIED_PER_STEP\nreturn val\n@classproperty\ndef metalink_prefix(cls):\nreturn m.APPLICATION_LINK_PREFIX\n@property\ndef _default_link(self):\n# Only supported for adjacency, NOT projection\nreturn self.obj.root_link if self.method == ParticleModifyMethod.ADJACENCY else None\n@property\ndef n_steps_per_modification(self):\nreturn m.N_STEPS_PER_APPLICATION\n@property\ndef visual_particle_modification_limit(self):\nreturn m.VISUAL_PARTICLES_APPLICATION_LIMIT\n@property\ndef physical_particle_modification_limit(self):\nreturn m.PHYSICAL_PARTICLES_APPLICATION_LIMIT\n</code></pre>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier","title":"<code>ParticleModifier</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>LinkBasedStateMixin</code>, <code>UpdateStateMixin</code></p> <p>Object state representing an object that has the ability to modify visual and / or physical particles within the active simulation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>Object to which this state will be applied</p> required <code>method</code> <code>ParticleModifyMethod</code> <p>Method to modify particles. Current options supported are ADJACENCY (i.e.: \"touching\" particles) or PROJECTION (i.e.: \"spraying\" particles)</p> required <code>conditions</code> <code>dict</code> <p>Dictionary mapping the names of ParticleSystem (str) to None or the corresponding condition / list of conditions (where None represents no conditions) necessary in order for this particle modifier to be able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature is as follows:</p> <pre><code>def condition(obj) --&gt; bool\n</code></pre> <p>Where @obj is the specific object that this ParticleModifier state belongs to. For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within this particle modifier area, then we potentially modify those particles</p> required <code>projection_mesh_params</code> <code>None or dict</code> <p>If specified and @method is ParticleModifyMethod.PROJECTION, manually overrides any metadata found from @obj.metadata to infer what projection volume to generate for this particle modifier. Expected entries are as follows:</p> <pre><code>\"type\": (str), one of {\"Cylinder\", \"Cone\"}\n\"extents\": (3-array), the (x,y,z) extents of the generated volume (specified in local link frame!)\n\"visualize\": (bool), whether to visualize this projection or not\n</code></pre> <p>If None, information found from @obj.metadata will be used instead. NOTE: x-direction should align with the projection mesh's height (i.e.: z) parameter in @extents!</p> <code>None</code> Source code in <code>omnigibson/object_states/particle_modifier.py</code> <pre><code>class ParticleModifier(AbsoluteObjectState, LinkBasedStateMixin, UpdateStateMixin):\n\"\"\"\n    Object state representing an object that has the ability to modify visual and / or physical particles within the\n    active simulation.\n    Args:\n        obj (StatefulObject): Object to which this state will be applied\n        method (ParticleModifyMethod): Method to modify particles. Current options supported are ADJACENCY (i.e.:\n            \"touching\" particles) or PROJECTION (i.e.: \"spraying\" particles)\n        conditions (dict): Dictionary mapping the names of ParticleSystem (str) to None or the corresponding condition /\n            list of conditions (where None represents no conditions) necessary in order for this particle modifier to be\n            able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature\n            is as follows:\n                def condition(obj) --&gt; bool\n            Where @obj is the specific object that this ParticleModifier state belongs to.\n            For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within\n            this particle modifier area, then we potentially modify those particles\n        projection_mesh_params (None or dict): If specified and @method is ParticleModifyMethod.PROJECTION,\n            manually overrides any metadata found from @obj.metadata to infer what projection volume to generate\n            for this particle modifier. Expected entries are as follows:\n                \"type\": (str), one of {\"Cylinder\", \"Cone\"}\n                \"extents\": (3-array), the (x,y,z) extents of the generated volume (specified in local link frame!)\n                \"visualize\": (bool), whether to visualize this projection or not\n            If None, information found from @obj.metadata will be used instead.\n            NOTE: x-direction should align with the projection mesh's height (i.e.: z) parameter in @extents!\n    \"\"\"\ndef __init__(self, obj, method, conditions, projection_mesh_params=None):\n# Store internal variables\nself.method = method\nself.conditions = conditions\nself.projection_source_sphere = None\nself.projection_mesh = None\nself.projection_system = None\nself.projection_emitter = None\nself._check_in_mesh = None\nself._check_overlap = None\nself._link_prim_paths = None\nself._current_step = None\nself._projection_mesh_params = projection_mesh_params\n# Map of system to number of modified particles (only include systems specified in the conditions)\nself.modified_particle_count = dict([(system_name, 0) for system_name in self.conditions])\n# Standardize the conditions (make sure every system has at least one condition, which to make sure\n# the particle modifier isn't already limited with the specific number of particles)\nfor system_name, conds in conditions.items():\n# Make sure the system is supported\nassert is_visual_particle_system(system_name) or is_physical_particle_system(system_name), f\"Unsupported system for ParticleModifier {system_name}\"\n# Make sure conds isn't empty and is a list\nconds = [] if conds is None else list(conds)\n# Add the condition to avoid limits\nconds.append(self._generate_limit_condition(system_name))\nconditions[system_name] = conds\n# Run super method\nsuper().__init__(obj)\ndef _initialize(self):\nsuper()._initialize()\n# Run link initialization\nself.initialize_link_mixin()\n# Initialize internal variables\nself._current_step = 0\n# Grab link prim paths and potentially update projection mesh params\nself._link_prim_paths = set(self.obj.link_prim_paths)\n# Define callback used during overlap method\n# We want to ignore any hits that are with this object itself\nvalid_hit = False\ndef overlap_callback(hit):\nnonlocal valid_hit\nvalid_hit = hit.rigid_body not in self._link_prim_paths\n# Continue traversal only if we don't have a valid hit yet\nreturn not valid_hit\n# Possibly create a projection volume if we're using the projection method\nif self.method == ParticleModifyMethod.PROJECTION:\n# Construct naming prefix to apply to generated prims\nname_prefix = f\"{self.obj.name}_{self.__class__.__name__}\"\n# Make sure projection mesh params are specified\n# Import here to avoid circular imports\nfrom omnigibson.objects.dataset_object import DatasetObject\nif self._projection_mesh_params is None and isinstance(self.obj, DatasetObject):\n# We try to grab metadata for this object\nself._projection_mesh_params = self.obj.metadata.get(\"meta_links\", dict()).get(m.LINK_NAME, None)\n# Sanity check to make sure projection mesh params is not None\nassert self._projection_mesh_params is not None, \\\n                f\"Projection mesh params must be specified for {self.obj.name}'s {self.__class__.__name__} state \" \\\n                f\"when method=ParticleModifyMethod.PROJECTION!\"\nmesh_prim_path = f\"{self.link.prim_path}/projection_mesh\"\n# Create a primitive shape if it doesn't already exist\nradius, height = self._projection_mesh_params[\"extents\"][0] / 2.0, self._projection_mesh_params[\"extents\"][2]\nif not get_prim_at_path(mesh_prim_path):\nmesh = UsdGeom.__dict__[self._projection_mesh_params[\"type\"]].Define(og.sim.stage, mesh_prim_path).GetPrim()\nmesh.GetAttribute(\"height\").Set(height)\nmesh.GetAttribute(\"radius\").Set(radius)\n# Create the visual geom instance referencing the generated mesh prim, and then hide it\nself.projection_mesh = VisualGeomPrim(prim_path=mesh_prim_path, name=f\"{name_prefix}_projection_mesh\")\nself.projection_mesh.initialize()\nself.projection_mesh.visible = False\n# Make sure the object updates its meshes\nself.link.update_meshes()\n# Make sure the mesh is translated so that its tip lies at the metalink origin, and rotated so the vector\n# from tip to tail faces the positive x axis\nz_offset = self._projection_mesh_params[\"extents\"][2] if self._projection_mesh_params[\"type\"] == \"Cone\" \\\n                else self._projection_mesh_params[\"extents\"][2] / 2\nself.projection_mesh.set_local_pose(\ntranslation=np.array([0, 0, -z_offset]),\norientation=T.euler2quat([0, 0, 0]),\n)\n# Generate the function for checking whether points are within the projection mesh\nself._check_in_mesh, _ = generate_points_in_volume_checker_function(\nobj=self.obj,\nvolume_link=self.link,\nmesh_name_prefixes=\"projection\",\n)\n# Store the projection mesh's IDs\nprojection_mesh_ids = PhysicsSchemaTools.encodeSdfPath(self.projection_mesh.prim_path)\n# We also generate the function for checking overlaps at runtime\ndef check_overlap():\nnonlocal valid_hit\nvalid_hit = False\nog.sim.psqi.overlap_shape(*projection_mesh_ids, reportFn=overlap_callback)\nreturn valid_hit\nelif self.method == ParticleModifyMethod.ADJACENCY:\n# Define the function for checking whether points are within the adjacency mesh\ndef check_in_adjacency_mesh(particle_positions):\n# Define the AABB bounds\nlower, upper = self.link.aabb\n# Add the margin\nlower -= m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\nupper += m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\nreturn ((lower &lt; particle_positions) &amp; (particle_positions &lt; upper)).all(axis=-1)\nself._check_in_mesh = check_in_adjacency_mesh\n# Define the function for checking overlaps at runtime\ndef check_overlap():\nnonlocal valid_hit\nvalid_hit = False\naabb = self.link.aabb\nog.sim.psqi.overlap_box(\nhalfExtent=(aabb[1] - aabb[0]) / 2.0 + m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN,\npos=(aabb[1] + aabb[0]) / 2.0,\nrot=np.array([0, 0, 0, 1.0]),\nreportFn=overlap_callback,\n)\nreturn valid_hit\nelse:\nraise ValueError(f\"Unsupported ParticleModifyMethod: {self.method}!\")\n# Store check overlap function\nself._check_overlap = check_overlap\n@abstractmethod\ndef _modify_particles(self, system):\n\"\"\"\n        Helper function to modify any particles belonging to @system.\n        NOTE: This should handle both cases for @self.method:\n            ParticleModifyMethod.ADJACENCY: modify any particles that are overlapping within the relaxed AABB\n                defining adjacency to this object's modification link.\n            ParticleModifyMethod.PROJECTION: modify any particles that are overlapping within the projection mesh.\n        Must be implemented by subclass.\n        Args:\n            system (ParticleSystem): Particle system whose corresponding particles will be checked for modification\n        \"\"\"\nraise NotImplementedError()\ndef _generate_limit_condition(self, system_name):\n\"\"\"\n        Generates a limit function condition for specific system of name @system_name\n        Args:\n             system_name (str): Name of the particle system for which to generate a limit checker function\n        Returns:\n            function: Limit checker function, with signature condition(obj) --&gt; bool, where @obj is the specific object\n                that this ParticleModifier state belongs to\n        \"\"\"\nassert system_name in self.conditions, f\"System {system_name} is not defined in the conditions.\"\nif is_visual_particle_system(system_name):\ndef condition(obj):\nreturn self.modified_particle_count[system_name] &lt; self.visual_particle_modification_limit\nelif is_physical_particle_system(system_name):\ndef condition(obj):\nreturn self.modified_particle_count[system_name] &lt; self.physical_particle_modification_limit\nreturn condition\ndef _update(self):\n# If we're using projection method and flatcache, we need to manually update this object's transforms on the USD\n# so the corresponding visualization and overlap meshes are updated properly\nif self.method == ParticleModifyMethod.PROJECTION and gm.ENABLE_FLATCACHE:\nFlatcacheAPI.sync_raw_object_transforms_in_usd(prim=self.obj)\n# Check if there's any overlap and if we're at the correct step\nif self._current_step == 0 and self._check_overlap():\n# Iterate over all owned systems for this particle modifier\nfor system_name, conditions in self.conditions.items():\n# Check if the system is active (for ParticleApplier, the system is always active)\nif is_system_active(system_name):\n# Check if all conditions are met\nif np.all([condition(self.obj) for condition in conditions]):\nsystem = get_system(system_name)\n# Sanity check for oversaturation\nself.check_at_limit(system=system, verify_not_over_limit=True)\n# Potentially modify particles within the volume\nself._modify_particles(system=system)\n# Update the current step\nself._current_step = (self._current_step + 1) % self.n_steps_per_modification\ndef _set_value(self, new_value):\nraise ValueError(f\"Cannot set valueless state {self.__class__.__name__}.\")\ndef _get_value(self):\npass\ndef remove(self):\n# We need to remove the generated particle system if we've created one\nif self.method == ParticleModifyMethod.PROJECTION:\ndelete_prim(self.projection_system.GetPrimPath().pathString)\n@staticmethod\ndef get_dependencies():\nreturn AbsoluteObjectState.get_dependencies() + [AABB]\n@staticmethod\ndef get_optional_dependencies():\nreturn AbsoluteObjectState.get_optional_dependencies() + [Covered, ToggledOn, ContactBodies, ContactParticles]\ndef check_at_limit(self, system, verify_not_over_limit=False):\n\"\"\"\n        Checks whether this object is fully limited with particles modified from particle system @system. Also,\n        potentially sanity checks whether the object is over the limit, if @verify_not_over_limit is True\n        Args:\n            system (ParticleSystem): System to check for particle limitations within this object\n            verify_not_over_limit (bool): Whether to sanity check whether this object is over the limit with particles\n                from @system\n        Returns:\n            bool: True if the object has reached its limit with objects from @system, otherwise False\n        \"\"\"\nassert system.name in self.conditions, f\"System {system.name} is not defined in the conditions.\"\nif issubclass(system, VisualParticleSystem):\nlimit = self.visual_particle_modification_limit\nelif issubclass(system, PhysicalParticleSystem):\nlimit = self.physical_particle_modification_limit\n# If requested, run sanity check to make sure we're not over the limit with this system's particles\nif verify_not_over_limit:\nassert self.modified_particle_count[system.name] &lt;= limit, \\\n                f\"{self.__class__.__name__} should not be over the limit! \" \\\n                f\"Max: {limit}, got: {self.modified_particle_count[system.name]}\"\nreturn self.modified_particle_count[system.name] == limit\ndef set_at_limit(self, system, value):\n\"\"\"\n        Sets whether this particle modifier is at its limit for system @system\n        Args:\n            system (ParticleSystem): System to set corresponding absorbed particle count limit level for\n            value (bool): Whether to set the particle limit level to be at its limit or not\n        \"\"\"\nassert system.name in self.conditions, f\"System {system.name} is not defined in the conditions.\"\nn_particles = 0\nif value:\nif issubclass(system, VisualParticleSystem):\nn_particles = self.visual_particle_modification_limit\nelif issubclass(system, PhysicalParticleSystem):\nn_particles = self.physical_particle_modification_limit\nself.modified_particle_count[system.name] = n_particles\n@classproperty\ndef supported_active_systems(cls):\n\"\"\"\n        Returns:\n            list: All systems used in this state that are active, dynamic across time\n        \"\"\"\nreturn list(VisualParticleSystem.get_active_systems().values()) + list(PhysicalParticleSystem.get_active_systems().values())\n@property\ndef n_steps_per_modification(self):\n\"\"\"\n        Returns:\n            int: How many steps to take in between potentially modifying particles within the simulation\n        \"\"\"\nraise NotImplementedError()\n@property\ndef visual_particle_modification_limit(self):\n\"\"\"\n        Returns:\n            int: Maximum number of visual particles from a specific system that can be modified by this object\n        \"\"\"\nraise NotImplementedError()\n@property\ndef physical_particle_modification_limit(self):\n\"\"\"\n        Returns:\n            int: Maximum number of physical particles from a specific system that can be modified by this object\n        \"\"\"\nraise NotImplementedError()\n@property\ndef state_size(self):\n# One entry per system plus the current_step\nreturn len(self.modified_particle_count) + 1\ndef _dump_state(self):\nsystems_dict = dict()\nfor system_name, val in self.modified_particle_count.items():\nsystems_dict[system_name] = val\nreturn dict(current_step=self._current_step, systems=systems_dict)\ndef _load_state(self, state):\nfor system_name in self.modified_particle_count:\nself.modified_particle_count[system_name] = state[\"systems\"][system_name]\nself._current_step = state[\"current_step\"]\ndef _serialize(self, state):\nreturn np.concatenate([\n[state[\"current_step\"]],\nlist(state[\"systems\"].values())\n]).astype(float)\ndef _deserialize(self, state):\ncurrent_step = int(state[0])\nsystems_dict = dict()\nfor i, system_name in enumerate(self.modified_particle_count):\nsystems_dict[system_name] = int(state[1 + i])  # system particle count starts from idx 1\nstate_dict = dict(current_step=current_step, systems=systems_dict)\nreturn state_dict, len(self.modified_particle_count) + 1\n</code></pre>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.n_steps_per_modification","title":"<code>n_steps_per_modification</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>How many steps to take in between potentially modifying particles within the simulation</p>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.physical_particle_modification_limit","title":"<code>physical_particle_modification_limit</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Maximum number of physical particles from a specific system that can be modified by this object</p>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.visual_particle_modification_limit","title":"<code>visual_particle_modification_limit</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Maximum number of visual particles from a specific system that can be modified by this object</p>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.check_at_limit","title":"<code>check_at_limit(system, verify_not_over_limit=False)</code>","text":"<p>Checks whether this object is fully limited with particles modified from particle system @system. Also, potentially sanity checks whether the object is over the limit, if @verify_not_over_limit is True</p> <p>Parameters:</p> Name Type Description Default <code>system</code> <code>ParticleSystem</code> <p>System to check for particle limitations within this object</p> required <code>verify_not_over_limit</code> <code>bool</code> <p>Whether to sanity check whether this object is over the limit with particles from @system</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the object has reached its limit with objects from @system, otherwise False</p> Source code in <code>omnigibson/object_states/particle_modifier.py</code> <pre><code>def check_at_limit(self, system, verify_not_over_limit=False):\n\"\"\"\n    Checks whether this object is fully limited with particles modified from particle system @system. Also,\n    potentially sanity checks whether the object is over the limit, if @verify_not_over_limit is True\n    Args:\n        system (ParticleSystem): System to check for particle limitations within this object\n        verify_not_over_limit (bool): Whether to sanity check whether this object is over the limit with particles\n            from @system\n    Returns:\n        bool: True if the object has reached its limit with objects from @system, otherwise False\n    \"\"\"\nassert system.name in self.conditions, f\"System {system.name} is not defined in the conditions.\"\nif issubclass(system, VisualParticleSystem):\nlimit = self.visual_particle_modification_limit\nelif issubclass(system, PhysicalParticleSystem):\nlimit = self.physical_particle_modification_limit\n# If requested, run sanity check to make sure we're not over the limit with this system's particles\nif verify_not_over_limit:\nassert self.modified_particle_count[system.name] &lt;= limit, \\\n            f\"{self.__class__.__name__} should not be over the limit! \" \\\n            f\"Max: {limit}, got: {self.modified_particle_count[system.name]}\"\nreturn self.modified_particle_count[system.name] == limit\n</code></pre>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.set_at_limit","title":"<code>set_at_limit(system, value)</code>","text":"<p>Sets whether this particle modifier is at its limit for system @system</p> <p>Parameters:</p> Name Type Description Default <code>system</code> <code>ParticleSystem</code> <p>System to set corresponding absorbed particle count limit level for</p> required <code>value</code> <code>bool</code> <p>Whether to set the particle limit level to be at its limit or not</p> required Source code in <code>omnigibson/object_states/particle_modifier.py</code> <pre><code>def set_at_limit(self, system, value):\n\"\"\"\n    Sets whether this particle modifier is at its limit for system @system\n    Args:\n        system (ParticleSystem): System to set corresponding absorbed particle count limit level for\n        value (bool): Whether to set the particle limit level to be at its limit or not\n    \"\"\"\nassert system.name in self.conditions, f\"System {system.name} is not defined in the conditions.\"\nn_particles = 0\nif value:\nif issubclass(system, VisualParticleSystem):\nn_particles = self.visual_particle_modification_limit\nelif issubclass(system, PhysicalParticleSystem):\nn_particles = self.physical_particle_modification_limit\nself.modified_particle_count[system.name] = n_particles\n</code></pre>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.supported_active_systems","title":"<code>supported_active_systems()</code>","text":"<p>Returns:</p> Name Type Description <code>list</code> <p>All systems used in this state that are active, dynamic across time</p> Source code in <code>omnigibson/object_states/particle_modifier.py</code> <pre><code>@classproperty\ndef supported_active_systems(cls):\n\"\"\"\n    Returns:\n        list: All systems used in this state that are active, dynamic across time\n    \"\"\"\nreturn list(VisualParticleSystem.get_active_systems().values()) + list(PhysicalParticleSystem.get_active_systems().values())\n</code></pre>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleRemover","title":"<code>ParticleRemover</code>","text":"<p>         Bases: <code>ParticleModifier</code></p> <p>ParticleModifier where the modification results in potentially removing particles from the simulation.</p> Source code in <code>omnigibson/object_states/particle_modifier.py</code> <pre><code>class ParticleRemover(ParticleModifier):\n\"\"\"\n    ParticleModifier where the modification results in potentially removing particles from the simulation.\n    \"\"\"\ndef _modify_particles(self, system):\n# If at the limit, return\nif self.check_at_limit(system=system):\nreturn\n# If the system has no particles, return\nif system.n_particles == 0:\nreturn\n# Check the system\nif issubclass(system, VisualParticleSystem):\n# Iterate over all particles and remove any that are within the relaxed AABB of the remover volume\nparticle_names = list(system.particles.keys())\nparticle_positions = system.get_particles_position_orientation()[0]\ninbound_idxs = self._check_in_mesh(particle_positions).nonzero()[0]\nmax_particle_absorbed = self.visual_particle_modification_limit - self.modified_particle_count[system.name]\nfor idx in inbound_idxs[:max_particle_absorbed]:\nsystem.remove_particle(particle_names[idx])\nself.modified_particle_count[system.name] += min(len(inbound_idxs), max_particle_absorbed)\nelif issubclass(system, PhysicalParticleSystem):\ninstancer_to_particle_idxs = {}\n# If the object is a cloth, we have to use check_in_mesh with the relaxed AABB since we can't detect\n# collisions via scene query interface. Alternatively, if we're using the projection method,\n# we also need to use check_in_mesh to check for overlap with the projection mesh.\nif self.obj.prim_type == PrimType.CLOTH or self.method == ParticleModifyMethod.PROJECTION:\nfor inst in system.particle_instancers.values():\ninbound_idxs = self._check_in_mesh(inst.particle_positions).nonzero()[0]\ninstancer_to_particle_idxs[inst] = inbound_idxs\n# Otherwise, we can simply use the ContactParticle state to infer contacts\nelse:\ninstancer_to_particle_idxs = self.obj.states[ContactParticles].get_value(system, self.link)\n# Iterate over all particles and hide any that are detected to be removed\nfor inst, particle_idxs in instancer_to_particle_idxs.items():\n# If at the limit, stop absorbing\nif self.check_at_limit(system=system):\nbreak\nmax_particle_absorbed = self.physical_particle_modification_limit - \\\n                                        self.modified_particle_count[system.name]\nparticles_to_absorb = min(len(particle_idxs), max_particle_absorbed)\nparticle_idxs_to_absorb = list(particle_idxs)[:particles_to_absorb]\n# Remove these particles from the instancer\ninst.remove_particles(idxs=particle_idxs_to_absorb)\n# Keep track of the particles that have been absorbed\nself.modified_particle_count[system.name] += particles_to_absorb\n@classproperty\ndef metalink_prefix(cls):\nreturn m.REMOVAL_LINK_PREFIX\n@property\ndef _default_link(self):\n# Only supported for adjacency, NOT projection\nreturn self.obj.root_link if self.method == ParticleModifyMethod.ADJACENCY else None\n@property\ndef n_steps_per_modification(self):\nreturn m.N_STEPS_PER_REMOVAL\n@property\ndef visual_particle_modification_limit(self):\nreturn m.VISUAL_PARTICLES_REMOVAL_LIMIT\n@property\ndef physical_particle_modification_limit(self):\nreturn m.PHYSICAL_PARTICLES_REMOVAL_LIMIT\n</code></pre>"},{"location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.create_projection_visualization","title":"<code>create_projection_visualization(prim_path, shape, projection_name, projection_radius, projection_height, particle_radius, material=None)</code>","text":"<p>Helper function to generate a projection visualization using Omniverse's particle visualization system</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Stage location for where to generate the projection visualization</p> required <code>shape</code> <code>str</code> <p>Shape of the projection to generate. Valid options are: {Sphere, Cone}</p> required <code>projection_name</code> <code>str</code> <p>Name associated with this projection visualization. Should be unique!</p> required <code>projection_radius</code> <code>float</code> <p>Radius of the generated projection visualization overall volume</p> required <code>projection_height</code> <code>float</code> <p>Height of the generated projection visualization overall volume</p> required <code>particle_radius</code> <code>float</code> <p>Radius of the particles composing the projection visualization</p> required <code>material</code> <code>None or MaterialPrim</code> <p>If specified, specifies the material to associate with the generated particles within the projection visualization</p> <code>None</code> <p>Returns:</p> Type Description <p>2-tuple: - UsdPrim: Generated ParticleSystem (ComputeGraph) prim generated - UsdPrim: Generated Emitter (ComputeGraph) prim generated</p> Source code in <code>omnigibson/object_states/particle_modifier.py</code> <pre><code>def create_projection_visualization(\nprim_path,\nshape,\nprojection_name,\nprojection_radius,\nprojection_height,\nparticle_radius,\nmaterial=None,\n):\n\"\"\"\n    Helper function to generate a projection visualization using Omniverse's particle visualization system\n    Args:\n        prim_path (str): Stage location for where to generate the projection visualization\n        shape (str): Shape of the projection to generate. Valid options are: {Sphere, Cone}\n        projection_name (str): Name associated with this projection visualization. Should be unique!\n        projection_radius (float): Radius of the generated projection visualization overall volume\n        projection_height (float): Height of the generated projection visualization overall volume\n        particle_radius (float): Radius of the particles composing the projection visualization\n        material (None or MaterialPrim): If specified, specifies the material to associate with the generated\n            particles within the projection visualization\n    Returns:\n        2-tuple:\n            - UsdPrim: Generated ParticleSystem (ComputeGraph) prim generated\n            - UsdPrim: Generated Emitter (ComputeGraph) prim generated\n    \"\"\"\n# Create the desired shape which will be used as the source input prim into the generated projection visualization\nsource = UsdGeom.Sphere.Define(og.sim.stage, Sdf.Path(prim_path))\n# Modify the radius according to the desired @shape (and also infer the desired spread values)\nif shape == \"Cylinder\":\nsource_radius = projection_radius\nspread = np.zeros(3)\nelif shape == \"Cone\":\n# Default to close to singular point otherwise\nsource_radius = m.PROJECTION_VISUALIZATION_CONE_TIP_RADIUS\nspread_ratio = projection_radius * 2.0 / projection_height\nspread = np.ones(3) * spread_ratio * m.PROJECTION_VISUALIZATION_SPREAD_FACTOR\nelse:\nraise ValueError(f\"Invalid shape specified for projection visualization! Valid options are: [Sphere, Cylinder], got: {shape}\")\n# Set the radius\nsource.GetRadiusAttr().Set(source_radius)\n# Also make the prim invisible\nUsdGeom.Imageable(source.GetPrim()).MakeInvisible()\n# Generate the ComputeGraph nodes to render the projection\ncore = Core(lambda val: None, particle_system_name=projection_name)\n# Suppress omni warnings here -- we don't have control over this API, but omni likes to complain about this\nwith suppress_omni_log(channels=[\"omni.graph.core.plugin\", \"omni.usd\", \"rtx.neuraylib.plugin\"]):\nsystem_path, _, emitter_path, vis_path, instancer_path, sprite_path, mat_path, output_path = \\\n            core.create_particle_system(display=\"point_instancer\", paths=[prim_path])\n# Override the prototype with our own sphere with optional material\nprototype_path = \"/\".join(sprite_path.split(\"/\")[:-1]) + \"/prototype\"\ncreate_primitive_mesh(prototype_path, primitive_type=\"Sphere\")\nprototype = VisualGeomPrim(prim_path=prototype_path, name=f\"{projection_name}_prototype\")\nprototype.initialize()\n# Set the scale (native scaling --&gt; radius 0.5) and possibly update the material\nprototype.scale = particle_radius * 2.0\nif material is not None:\nprototype.material = material\n# Override the prototype used by the instancer\ninstancer_prim = get_prim_at_path(instancer_path)\ninstancer_prim.GetProperty(\"inputs:prototypes\").SetTargets([prototype_path])\n# Destroy the old mat path since we don't use the sprites\ndelete_prim(mat_path)\n# Modify the settings of the emitter to match the desired shape from inputs\nemitter_prim = get_prim_at_path(emitter_path)\nemitter_prim.GetProperty(\"inputs:active\").Set(True)\nemitter_prim.GetProperty(\"inputs:rate\").Set(m.PROJECTION_VISUALIZATION_RATE)\nemitter_prim.GetProperty(\"inputs:lifespan\").Set(projection_height / m.PROJECTION_VISUALIZATION_SPEED)\nemitter_prim.GetProperty(\"inputs:speed\").Set(m.PROJECTION_VISUALIZATION_SPEED)\nemitter_prim.GetProperty(\"inputs:alongAxis\").Set(m.PROJECTION_VISUALIZATION_ORIENTATION_BIAS)\nemitter_prim.GetProperty(\"inputs:scale\").Set(Gf.Vec3f(1.0, 1.0, 1.0))\nemitter_prim.GetProperty(\"inputs:directionRandom\").Set(Gf.Vec3f(*spread))\nemitter_prim.GetProperty(\"inputs:addSourceVelocity\").Set(1.0)\n# Make sure we render 4 times to fully propagate changes (validated empirically)\n# Omni likes to complain here again, but we have no control over the low-level information, so we suppress warnings\nwith suppress_omni_log(channels=[\"omni.particle.system.core.plugin\", \"omni.hydra.scene_delegate.plugin\", \"omni.usd\"]):\nfor i in range(4):\nog.sim.render()\n# Return the particle system prim which \"owns\" everything\nreturn get_prim_at_path(system_path), emitter_prim\n</code></pre>"},{"location":"reference/object_states/particle_source_or_sink.html","title":"particle_source_or_sink","text":""},{"location":"reference/object_states/particle_source_or_sink.html#object_states.particle_source_or_sink.ParticleSink","title":"<code>ParticleSink</code>","text":"<p>         Bases: <code>ParticleRemover</code></p> <p>ParticleRemover where physical particles are removed continuously within a cylindrical volume located at the metalink pose.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>Object to which this state will be applied</p> required <code>conditions</code> <code>dict</code> <p>Dictionary mapping the names of ParticleSystem (str) to None or the corresponding condition / list of conditions (where None represents no conditions) necessary in order for this particle modifier to be able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature is as follows:</p> <pre><code>def condition(obj) --&gt; bool\n</code></pre> <p>Where @obj is the specific object that this ParticleModifier state belongs to. For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within this particle modifier area, then we potentially modify those particles</p> required <code>sink_radius</code> <code>float</code> <p>Radius of the cylinder representing particles' sinking volume</p> required <code>sink_height</code> <code>float</code> <p>Height of the cylinder representing particles' sinking volume</p> required Source code in <code>omnigibson/object_states/particle_source_or_sink.py</code> <pre><code>class ParticleSink(ParticleRemover):\n\"\"\"\n        ParticleRemover where physical particles are removed continuously within a cylindrical volume located\n        at the metalink pose.\n        Args:\n            obj (StatefulObject): Object to which this state will be applied\n            conditions (dict): Dictionary mapping the names of ParticleSystem (str) to None or the corresponding condition /\n                list of conditions (where None represents no conditions) necessary in order for this particle modifier to be\n                able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature\n                is as follows:\n                    def condition(obj) --&gt; bool\n                Where @obj is the specific object that this ParticleModifier state belongs to.\n                For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within\n                this particle modifier area, then we potentially modify those particles\n            sink_radius (float): Radius of the cylinder representing particles' sinking volume\n            sink_height (float): Height of the cylinder representing particles' sinking volume\n            \"\"\"\ndef __init__(self, obj, conditions, sink_radius, sink_height):\n# Initialize variables that will be filled in at runtime\nself._n_steps_per_modification = None\n# Convert inputs into arguments to pass to particle applier class\nsuper().__init__(\nobj=obj,\nmethod=ParticleModifyMethod.PROJECTION,\nconditions=conditions,\n# TODO: Discuss how this will sync with new asset metalinks\nprojection_mesh_params={\n\"type\": \"Cylinder\",\n\"extents\": [sink_radius * 2, sink_radius * 2, sink_height],\n\"visualize\": False,\n},\n)\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Override check overlap such that it always returns True (since we are ignoring overlaps and directly\n# removing particles\nself._check_overlap = lambda: True\ndef _get_max_particles_limit_per_step(self, system):\n# Check the system\nassert issubclass(system, PhysicalParticleSystem), \"ParticleSink only supports PhysicalParticleSystem\"\nreturn m.MAX_PHYSICAL_PARTICLES_SOURCED_PER_STEP\n@classproperty\ndef metalink_prefix(cls):\nreturn m.SINK_LINK_PREFIX\n@property\ndef n_steps_per_modification(self):\nreturn m.N_STEPS_PER_SINK\n@property\ndef physical_particle_modification_limit(self):\nreturn m.SINK_PARTICLES_LIMIT\n</code></pre>"},{"location":"reference/object_states/particle_source_or_sink.html#object_states.particle_source_or_sink.ParticleSource","title":"<code>ParticleSource</code>","text":"<p>         Bases: <code>ParticleApplier</code></p> <p>ParticleApplier where physical particles are spawned continuously in a cylindrical fashion from the metalink pose.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>StatefulObject</code> <p>Object to which this state will be applied</p> required <code>conditions</code> <code>dict</code> <p>Dictionary mapping the names of ParticleSystem (str) to None or the corresponding condition / list of conditions (where None represents no conditions) necessary in order for this particle modifier to be able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature is as follows:</p> <pre><code>def condition(obj) --&gt; bool\n</code></pre> <p>Where @obj is the specific object that this ParticleModifier state belongs to. For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within this particle modifier area, then we potentially modify those particles</p> required <code>source_radius</code> <code>float</code> <p>Radius of the cylinder representing particles' spawning volume</p> required <code>source_height</code> <code>float</code> <p>Height of the cylinder representing particles' spawning volume</p> required <code>initial_speed</code> <code>float</code> <p>The initial speed for generated particles. Note that the direction of the velocity is inferred from the particle sampling process</p> <code>0.0</code> Source code in <code>omnigibson/object_states/particle_source_or_sink.py</code> <pre><code>class ParticleSource(ParticleApplier):\n\"\"\"\n        ParticleApplier where physical particles are spawned continuously in a cylindrical fashion from the\n        metalink pose.\n        Args:\n            obj (StatefulObject): Object to which this state will be applied\n            conditions (dict): Dictionary mapping the names of ParticleSystem (str) to None or the corresponding condition /\n                list of conditions (where None represents no conditions) necessary in order for this particle modifier to be\n                able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature\n                is as follows:\n                    def condition(obj) --&gt; bool\n                Where @obj is the specific object that this ParticleModifier state belongs to.\n                For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within\n                this particle modifier area, then we potentially modify those particles\n            source_radius (float): Radius of the cylinder representing particles' spawning volume\n            source_height (float): Height of the cylinder representing particles' spawning volume\n            initial_speed (float): The initial speed for generated particles. Note that the\n                direction of the velocity is inferred from the particle sampling process\n            \"\"\"\ndef __init__(self, obj, conditions, source_radius, source_height, initial_speed=0.0):\n# Initialize variables that will be filled in at runtime\nself._n_steps_per_modification = None\n# Convert inputs into arguments to pass to particle applier class\nsuper().__init__(\nobj=obj,\nmethod=ParticleModifyMethod.PROJECTION,\nconditions=conditions,\nprojection_mesh_params={\n\"type\": \"Cylinder\",\n\"extents\": [source_radius * 2, source_radius * 2, source_height],\n\"visualize\": False,\n},\nsample_with_raycast=False,\ninitial_speed=initial_speed,\n)\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Calculate how many steps we need in between particle cluster spawnings\n# This is equivalent to the time it takes for a generated particle to travel @source_height distance\n# Note that object state steps are discretized by og.sim.render_step\n# Note: t derived from quadratic formula: height = 0.5 g t^2 + v0 t\nt = (-self._initial_speed + np.sqrt(self._initial_speed ** 2 + 2 * og.sim.gravity * self._projection_mesh_params[\"extents\"][2])) / og.sim.gravity\nself._n_steps_per_modification = np.ceil(1 + t / og.sim.get_rendering_dt()).astype(int)\ndef _get_max_particles_limit_per_step(self, system):\n# Check the system\nassert issubclass(system, PhysicalParticleSystem), \"ParticleSource only supports PhysicalParticleSystem\"\nreturn m.MAX_SOURCE_PARTICLES_PER_STEP\n@classproperty\ndef metalink_prefix(cls):\nreturn m.SOURCE_LINK_PREFIX\n@property\ndef n_steps_per_modification(self):\nreturn self._n_steps_per_modification\n@property\ndef physical_particle_modification_limit(self):\nreturn m.SOURCE_PARTICLES_LIMIT\n</code></pre>"},{"location":"reference/object_states/pose.html","title":"pose","text":""},{"location":"reference/object_states/saturated.html","title":"saturated","text":""},{"location":"reference/object_states/sliced.html","title":"sliced","text":""},{"location":"reference/object_states/slicer.html","title":"slicer","text":""},{"location":"reference/object_states/temperature.html","title":"temperature","text":""},{"location":"reference/object_states/toggle.html","title":"toggle","text":""},{"location":"reference/object_states/touching.html","title":"touching","text":""},{"location":"reference/object_states/under.html","title":"under","text":""},{"location":"reference/object_states/unfolded.html","title":"unfolded","text":""},{"location":"reference/object_states/update_state_mixin.html","title":"update_state_mixin","text":""},{"location":"reference/object_states/update_state_mixin.html#object_states.update_state_mixin.UpdateStateMixin","title":"<code>UpdateStateMixin</code>","text":"<p>A state-mixin that allows for per-sim-step updates via the update() call</p> Source code in <code>omnigibson/object_states/update_state_mixin.py</code> <pre><code>class UpdateStateMixin:\n\"\"\"\n    A state-mixin that allows for per-sim-step updates via the update() call\n    \"\"\"\ndef update(self):\n\"\"\"\n        Updates the object state. This function will be called for every simulator step\n        \"\"\"\nassert self._initialized, \"Cannot update uninitialized state.\"\nreturn self._update()\ndef _update(self):\n\"\"\"\n        This function will be called once for every simulator step. Must be implemented by subclass.\n        \"\"\"\n# Explicitly raise not implemented error to avoid silent bugs -- update should never be called otherwise\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/object_states/update_state_mixin.html#object_states.update_state_mixin.UpdateStateMixin.update","title":"<code>update()</code>","text":"<p>Updates the object state. This function will be called for every simulator step</p> Source code in <code>omnigibson/object_states/update_state_mixin.py</code> <pre><code>def update(self):\n\"\"\"\n    Updates the object state. This function will be called for every simulator step\n    \"\"\"\nassert self._initialized, \"Cannot update uninitialized state.\"\nreturn self._update()\n</code></pre>"},{"location":"reference/object_states/water_sink.html","title":"water_sink","text":""},{"location":"reference/object_states/water_source.html","title":"water_source","text":""},{"location":"reference/objects/index.html","title":"objects","text":""},{"location":"reference/objects/controllable_object.html","title":"controllable_object","text":""},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject","title":"<code>ControllableObject</code>","text":"<p>         Bases: <code>BaseObject</code></p> <p>Simple class that extends object functionality for controlling joints -- this assumes that at least some joints are motorized (i.e.: non-zero low-level simulator joint motor gains) and intended to be controlled, e.g.: a conveyor belt or a robot agent</p> Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>class ControllableObject(BaseObject):\n\"\"\"\n    Simple class that extends object functionality for controlling joints -- this assumes that at least some joints\n    are motorized (i.e.: non-zero low-level simulator joint motor gains) and intended to be controlled,\n    e.g.: a conveyor belt or a robot agent\n    \"\"\"\ndef __init__(\nself,\nname,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Store inputs\nself._control_freq = control_freq\nself._controller_config = controller_config\nself._reset_joint_pos = reset_joint_pos if reset_joint_pos is None else np.array(reset_joint_pos)\n# Make sure action type is valid, and also save\nassert_valid_key(key=action_type, valid_keys={\"discrete\", \"continuous\"}, name=\"action type\")\nself._action_type = action_type\nself._action_normalize = action_normalize\n# Store internal placeholders that will be filled in later\nself._dof_to_joints = None          # dict that will map DOF indices to JointPrims\nself._last_action = None\nself._controllers = None\nself.dof_names_ordered = None\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\nload_config=load_config,\n**kwargs,\n)\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Fill in the DOF to joint mapping\nself._dof_to_joints = dict()\nidx = 0\nfor joint in self._joints.values():\nfor _ in range(joint.n_dof):\nself._dof_to_joints[idx] = joint\nidx += 1\n# Update the reset joint pos\nif self._reset_joint_pos is None:\nself._reset_joint_pos = self.default_joint_pos\n# Load controllers\nself._load_controllers()\n# Setup action space\nself._action_space = self._create_discrete_action_space() if self._action_type == \"discrete\" \\\n            else self._create_continuous_action_space()\n# Reset the object and keep all joints still after loading\nself.reset()\nself.keep_still()\ndef load(self):\n# Run super first\nprim = super().load()\n# Set the control frequency if one was not provided.\nexpected_control_freq = 1.0 / og.sim.get_rendering_dt()\nif self._control_freq is None:\nlog.info(\n\"Control frequency is None - being set to default of 1 / render_timestep: %.4f\", expected_control_freq\n)\nself._control_freq = expected_control_freq\nelse:\nassert np.isclose(\nexpected_control_freq, self._control_freq\n), \"Stored control frequency does not match environment's render timestep.\"\nreturn prim\ndef _load_controllers(self):\n\"\"\"\n        Loads controller(s) to map inputted actions into executable (pos, vel, and / or effort) signals on this object.\n        Stores created controllers as dictionary mapping controller names to specific controller\n        instances used by this object.\n        \"\"\"\n# Generate the controller config\nself._controller_config = self._generate_controller_config(custom_config=self._controller_config)\n# Store dof idx mapping to dof name\nself.dof_names_ordered = list(self._joints.keys())\n# Initialize controllers to create\nself._controllers = dict()\n# Loop over all controllers, in the order corresponding to @action dim\nfor name in self.controller_order:\nassert_valid_key(key=name, valid_keys=self._controller_config, name=\"controller name\")\ncfg = self._controller_config[name]\n# If we're using normalized action space, override the inputs for all controllers\nif self._action_normalize:\ncfg[\"command_input_limits\"] = \"default\"  # default is normalized (-1, 1)\n# Create the controller\nself._controllers[name] = create_controller(**cfg)\ncontroller = create_controller(**cfg)\n# Verify the controller's DOFs can all be driven\nfor idx in controller.dof_idx:\nassert self._joints[self.dof_names_ordered[idx]].driven, \"Controllers should only control driveable joints!\"\nself.update_controller_mode()\ndef update_controller_mode(self):\n\"\"\"\n        Helper function to force the joints to use the internal specified control mode and gains\n        \"\"\"\n# Update the control modes of each joint based on the outputted control from the controllers\nfor name in self._controllers:\nfor dof in self._controllers[name].dof_idx:\ncontrol_type = self._controllers[name].control_type\nself._joints[self.dof_names_ordered[dof]].set_control_type(\ncontrol_type=control_type,\nkp=self.default_kp if control_type == ControlType.POSITION else None,\nkd=self.default_kd if control_type == ControlType.VELOCITY else None,\n)\ndef _generate_controller_config(self, custom_config=None):\n\"\"\"\n        Generates a fully-populated controller config, overriding any default values with the corresponding values\n        specified in @custom_config\n        Args:\n            custom_config (None or Dict[str, ...]): nested dictionary mapping controller name(s) to specific custom\n                controller configurations for this object. This will override any default values specified by this class\n        Returns:\n            dict: Fully-populated nested dictionary mapping controller name(s) to specific controller configurations for\n                this object\n        \"\"\"\ncontroller_config = {} if custom_config is None else deepcopy(custom_config)\n# Update the configs\nfor group in self.controller_order:\ngroup_controller_name = (\ncontroller_config[group][\"name\"]\nif group in controller_config and \"name\" in controller_config[group]\nelse self._default_controllers[group]\n)\ncontroller_config[group] = merge_nested_dicts(\nbase_dict=self._default_controller_config[group][group_controller_name],\nextra_dict=controller_config.get(group, {}),\n)\nreturn controller_config\ndef reload_controllers(self, controller_config=None):\n\"\"\"\n        Reloads controllers based on the specified new @controller_config\n        Args:\n            controller_config (None or Dict[str, ...]): nested dictionary mapping controller name(s) to specific\n                controller configurations for this object. This will override any default values specified by this class.\n        \"\"\"\nself._controller_config = {} if controller_config is None else controller_config\n# (Re-)load controllers\nself._load_controllers()\n# (Re-)create the action space\nself._action_space = self._create_discrete_action_space() if self._action_type == \"discrete\" \\\n            else self._create_continuous_action_space()\ndef reset(self):\n# Make sure simulation is playing, otherwise, we cannot reset because DC requires active running\n# simulation in order to set joints\nassert og.sim.is_playing(), \"Simulator must be playing in order to reset controllable object's joints!\"\n# Additionally set the joint states based on the reset values\nself.set_joint_positions(positions=self._reset_joint_pos, drive=False)\nself.set_joint_velocities(velocities=np.zeros(self.n_dof), drive=False)\n# Reset all controllers\nfor controller in self._controllers.values():\ncontroller.reset()\n@abstractmethod\ndef _create_discrete_action_space(self):\n\"\"\"\n        Create a discrete action space for this object. Should be implemented by the subclass (if a subclass does not\n        support this type of action space, it should raise an error).\n        Returns:\n            gym.space: Object-specific discrete action space\n        \"\"\"\nraise NotImplementedError\ndef _create_continuous_action_space(self):\n\"\"\"\n        Create a continuous action space for this object. By default, this loops over all controllers and\n        appends their respective input command limits to set the action space.\n        Any custom behavior should be implemented by the subclass (e.g.: if a subclass does not\n        support this type of action space, it should raise an error).\n        Returns:\n            gym.space.Box: Object-specific continuous action space\n        \"\"\"\n# Action space is ordered according to the order in _default_controller_config control\nlow, high = [], []\nfor controller in self._controllers.values():\nlimits = controller.command_input_limits\nlow.append(np.array([-np.inf] * controller.command_dim) if limits is None else limits[0])\nhigh.append(np.array([np.inf] * controller.command_dim) if limits is None else limits[1])\nreturn gym.spaces.Box(shape=(self.action_dim,), low=np.concatenate(low), high=np.concatenate(high), dtype=float)\ndef apply_action(self, action):\n\"\"\"\n        Converts inputted actions into low-level control signals and deploys them on the object\n        Args:\n            n_array: n-DOF length array of actions to convert and deploy on the object\n        \"\"\"\n# Store last action as the current action being applied\nself._last_action = action\n# If we're using discrete action space, we grab the specific action and use that to convert to control\nif self._action_type == \"discrete\":\naction = np.array(self.discrete_action_list[action])\n# Check if the input action's length matches the action dimension\nassert len(action) == self.action_dim, \"Action must be dimension {}, got dim {} instead.\".format(\nself.action_dim, len(action)\n)\n# Run convert actions to controls\ncontrol, control_type = self._actions_to_control(action=action)\n# Deploy control signals\nself.deploy_control(control=control, control_type=control_type, indices=None, normalized=False)\ndef _actions_to_control(self, action):\n\"\"\"\n        Converts inputted @action into low level control signals to deploy directly on the object.\n        This returns two arrays: the converted low level control signals and an array corresponding\n        to the specific ControlType for each signal.\n        Args:\n            action (n-array): n-DOF length array of actions to convert and deploy on the object\n        Returns:\n            2-tuple:\n                - n-array: raw control signals to send to the object's joints\n                - list: control types for each joint\n        \"\"\"\n# First, loop over all controllers, and calculate the computed control\ncontrol = dict()\nidx = 0\n# Compose control_dict\ncontrol_dict = self.get_control_dict()\nfor name, controller in self._controllers.items():\n# Set command, then take a controller step\ncontroller.update_command(command=action[idx : idx + controller.command_dim])\ncontrol[name] = {\n\"value\": controller.step(control_dict=control_dict),\n\"type\": controller.control_type,\n}\n# Update idx\nidx += controller.command_dim\n# Compose controls\nu_vec = np.zeros(self.n_dof)\n# By default, the control type is None and the control value is 0 (np.zeros) - i.e. no control applied\nu_type_vec = np.array([ControlType.NONE] * self.n_dof)\nfor group, ctrl in control.items():\nidx = self._controllers[group].dof_idx\nu_vec[idx] = ctrl[\"value\"]\nu_type_vec[idx] = ctrl[\"type\"]\n# Return control\nreturn u_vec, u_type_vec\ndef deploy_control(self, control, control_type, indices=None, normalized=False):\n\"\"\"\n        Deploys control signals @control with corresponding @control_type on this entity.\n        Note: This is DIFFERENT than self.set_joint_positions/velocities/efforts, because in this case we are only\n            setting target values (i.e.: we subject this entity to physical dynamics in order to reach the desired\n            @control setpoints), compared to set_joint_XXXX which manually sets the actual state of the joints.\n            This function is intended to be used with motorized entities, e.g.: robot agents or machines (e.g.: a\n            conveyor belt) to simulation physical control of these entities.\n            In contrast, use set_joint_XXXX for simulation-specific logic, such as simulator resetting or \"magic\"\n            action implementations.\n        Args:\n            control (k- or n-array): control signals to deploy. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @control must\n                be the same length as @indices!\n            control_type (k- or n-array): control types for each DOF. Each entry should be one of ControlType.\n                 This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific\n                 indices are being set. In this case, the length of @control must be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF controls to deploy.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool or array of bool): Whether the inputted joint controls should be interpreted as normalized\n                values. A single bool can be specified for the entire @control, or an array can be specified for\n                individual values. Default is False, corresponding to all @control assumed to be not normalized\n        \"\"\"\n# Run sanity check\nif indices is None:\nassert len(control) == len(control_type) == self.n_dof, (\n\"Control signals, control types, and number of DOF should all be the same!\"\n\"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), self.n_dof)\n)\n# Set indices manually so that we're standardized\nindices = np.arange(self.n_dof)\nelse:\nassert len(control) == len(control_type) == len(indices), (\n\"Control signals, control types, and indices should all be the same!\"\n\"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), len(indices))\n)\n# Standardize normalized input\nn_indices = len(indices)\nnormalized = normalized if isinstance(normalized, Iterable) else [normalized] * n_indices\n# Loop through controls and deploy\n# We have to use delicate logic to account for the edge cases where a single joint may contain &gt; 1 DOF\n# (e.g.: spherical joint)\ncur_indices_idx = 0\nwhile cur_indices_idx != n_indices:\n# Grab the current DOF index we're controlling and find the corresponding joint\njoint = self._dof_to_joints[indices[cur_indices_idx]]\ncur_ctrl_idx = indices[cur_indices_idx]\njoint_dof = joint.n_dof\nif joint_dof &gt; 1:\n# Run additional sanity checks since the joint has more than one DOF to make sure our controls,\n# control types, and indices all match as expected\n# Make sure the indices are mapped correctly\nassert indices[cur_indices_idx + joint_dof] == cur_ctrl_idx + joint_dof, \\\n                    \"Got mismatched control indices for a single joint!\"\n# Check to make sure all joints, control_types, and normalized as all the same over n-DOF for the joint\nfor group_name, group in zip(\n(\"joints\", \"control_types\", \"normalized\"),\n(self._dof_to_joints, control_type, normalized),\n):\nassert len({group[indices[cur_indices_idx + i]] for i in range(joint_dof)}) == 1, \\\n                        f\"Not all {group_name} were the same when trying to deploy control for a single joint!\"\n# Assuming this all passes, we grab the control subvector, type, and normalized value accordingly\nctrl = control[cur_ctrl_idx: cur_ctrl_idx + joint_dof]\nelse:\n# Grab specific control. No need to do checks since this is a single value\nctrl = control[cur_ctrl_idx]\n# Deploy control based on type\nctrl_type, norm = control_type[cur_ctrl_idx], normalized[cur_ctrl_idx]       # In multi-DOF joint case all values were already checked to be the same\nif ctrl_type == ControlType.EFFORT:\njoint.set_effort(ctrl, normalized=norm)\nelif ctrl_type == ControlType.VELOCITY:\njoint.set_vel(ctrl, normalized=norm, drive=True)\nelif ctrl_type == ControlType.POSITION:\njoint.set_pos(ctrl, normalized=norm, drive=True)\nelif ctrl_type == ControlType.NONE:\n# Do nothing\npass\nelse:\nraise ValueError(\"Invalid control type specified: {}\".format(ctrl_type))\n# Finally, increment the current index based on how many DOFs were just controlled\ncur_indices_idx += joint_dof\ndef get_control_dict(self):\n\"\"\"\n        Grabs all relevant information that should be passed to each controller during each controller step.\n        Returns:\n            dict: Keyword-mapped control values for this object, mapping names to n-arrays.\n                By default, returns the following:\n                - joint_position: (n_dof,) joint positions\n                - joint_velocity: (n_dof,) joint velocities\n                - joint_effort: (n_dof,) joint efforts\n                - root_pos: (3,) (x,y,z) global cartesian position of the object's root link\n                - root_quat: (4,) (x,y,z,w) global cartesian orientation of ths object's root link\n        \"\"\"\npos, ori = self.get_position_orientation()\nreturn dict(\njoint_position=self.get_joint_positions(normalized=False),\njoint_velocity=self.get_joint_velocities(normalized=False),\njoint_effort=self.get_joint_efforts(normalized=False),\nroot_pos=pos,\nroot_quat=ori,\n)\ndef dump_action(self):\n\"\"\"\n        Dump the last action applied to this object. For use in demo collection.\n        \"\"\"\nreturn self._last_action\n@property\ndef state_size(self):\n# Grab size from super and add in controller state sizes\nsize = super().state_size\nreturn size + sum([c.state_size for c in self._controllers.values()])\ndef _dump_state(self):\n# Grab super state\nstate = super()._dump_state()\n# Add in controller states\ncontroller_states = dict()\nfor controller_name, controller in self._controllers.items():\ncontroller_states[controller_name] = controller.dump_state()\nstate[\"controllers\"] = controller_states\nreturn state\ndef _load_state(self, state):\n# Run super first\nsuper()._load_state(state=state)\n# Load controller states\ncontroller_states = state[\"controllers\"]\nfor controller_name, controller in self._controllers.items():\ncontroller.load_state(state=controller_states[controller_name])\ndef _serialize(self, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\n# Serialize the controller states sequentially\ncontroller_states_flat = np.concatenate([\nc.serialize(state=state[\"controllers\"][c_name]) for c_name, c in self._controllers.items()\n])\n# Concatenate and return\nreturn np.concatenate([state_flat, controller_states_flat]).astype(float)\ndef _deserialize(self, state):\n# Run super first\nstate_dict, idx = super()._deserialize(state=state)\n# Deserialize the controller states sequentially\ncontroller_states = dict()\nfor c_name, c in self._controllers.items():\nstate_size = c.state_size\ncontroller_states[c_name] = c.deserialize(state=state[idx: idx + state_size])\nidx += state_size\nstate_dict[\"controllers\"] = controller_states\nreturn state_dict, idx\n@property\ndef action_dim(self):\n\"\"\"\n        Returns:\n            int: Dimension of action space for this object. By default,\n                is the sum over all controller action dimensions\n        \"\"\"\nreturn sum([controller.command_dim for controller in self._controllers.values()])\n@property\ndef action_space(self):\n\"\"\"\n        Action space for this object.\n        Returns:\n            gym.space: Action space, either discrete (Discrete) or continuous (Box)\n        \"\"\"\nreturn deepcopy(self._action_space)\n@property\ndef discrete_action_list(self):\n\"\"\"\n        Discrete choices for actions for this object. Only needs to be implemented if the object supports discrete\n        actions.\n        Returns:\n            dict: Mapping from single action identifier (e.g.: a string, or a number) to array of continuous\n                actions to deploy via this object's controllers.\n        \"\"\"\nraise NotImplementedError()\n@property\ndef controllers(self):\n\"\"\"\n        Returns:\n            dict: Controllers owned by this object, mapping controller name to controller object\n        \"\"\"\nreturn self._controllers\n@property\n@abstractmethod\ndef controller_order(self):\n\"\"\"\n        Returns:\n            list: Ordering of the actions, corresponding to the controllers. e.g., [\"base\", \"arm\", \"gripper\"],\n                to denote that the action vector should be interpreted as first the base action, then arm command, then\n                gripper command\n        \"\"\"\nraise NotImplementedError\n@property\ndef controller_action_idx(self):\n\"\"\"\n        Returns:\n            dict: Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding\n                indices (list) in the action vector\n        \"\"\"\ndic = {}\nidx = 0\nfor controller in self.controller_order:\ncmd_dim = self._controllers[controller].command_dim\ndic[controller] = np.arange(idx, idx + cmd_dim)\nidx += cmd_dim\nreturn dic\n@property\ndef controller_joint_idx(self):\n\"\"\"\n        Returns:\n            dict: Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding\n                indices (list) of the joint state vector controlled by each controller\n        \"\"\"\ndic = {}\nfor controller in self.controller_order:\ndic[controller] = self._controllers[controller].dof_idx\nreturn dic\n@property\ndef control_limits(self):\n\"\"\"\n        Returns:\n            dict: Keyword-mapped limits for this object. Dict contains:\n                position: (min, max) joint limits, where min and max are N-DOF arrays\n                velocity: (min, max) joint velocity limits, where min and max are N-DOF arrays\n                effort: (min, max) joint effort limits, where min and max are N-DOF arrays\n                has_limit: (n_dof,) array where each element is True if that corresponding joint has a position limit\n                    (otherwise, joint is assumed to be limitless)\n        \"\"\"\nreturn {\n\"position\": (self.joint_lower_limits, self.joint_upper_limits),\n\"velocity\": (-self.max_joint_velocities, self.max_joint_velocities),\n\"effort\": (-self.max_joint_efforts, self.max_joint_efforts),\n\"has_limit\": self.joint_has_limits,\n}\n@property\ndef default_kp(self):\n\"\"\"\n        Returns:\n            float: Default kp gain to apply to any DOF when switching control modes (e.g.: switching from a\n                velocity control mode to a position control mode)\n        \"\"\"\nreturn 1e7\n@property\ndef default_kd(self):\n\"\"\"\n        Returns:\n            float: Default kd gain to apply to any DOF when switching control modes (e.g.: switching from a\n                position control mode to a velocity control mode)\n        \"\"\"\nreturn 1e5\n@property\n@abstractmethod\ndef default_joint_pos(self):\n\"\"\"\n        Returns:\n            n-array: Default joint positions for this robot\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef _default_controller_config(self):\n\"\"\"\n        Returns:\n            dict: default nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. Note that the order specifies the sequence of actions to be received\n                from the environment.\n                Expected structure is as follows:\n                    group1:\n                        controller_name1:\n                            controller_name1_params\n                            ...\n                        controller_name2:\n                            ...\n                    group2:\n                        ...\n                The @group keys specify the control type for various aspects of the object,\n                e.g.: \"head\", \"arm\", \"base\", etc. @controller_name keys specify the supported controllers for\n                that group. A default specification MUST be specified for each controller_name.\n                e.g.: IKController, DifferentialDriveController, JointController, etc.\n        \"\"\"\nreturn {}\n@property\n@abstractmethod\ndef _default_controllers(self):\n\"\"\"\n        Returns:\n            dict: Maps object group (e.g. base, arm, etc.) to default controller class name to use\n            (e.g. IKController, JointController, etc.)\n        \"\"\"\nreturn {}\n</code></pre>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.action_dim","title":"<code>action_dim</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Dimension of action space for this object. By default, is the sum over all controller action dimensions</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.action_space","title":"<code>action_space</code>  <code>property</code>","text":"<p>Action space for this object.</p> <p>Returns:</p> Type Description <p>gym.space: Action space, either discrete (Discrete) or continuous (Box)</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.control_limits","title":"<code>control_limits</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped limits for this object. Dict contains: position: (min, max) joint limits, where min and max are N-DOF arrays velocity: (min, max) joint velocity limits, where min and max are N-DOF arrays effort: (min, max) joint effort limits, where min and max are N-DOF arrays has_limit: (n_dof,) array where each element is True if that corresponding joint has a position limit     (otherwise, joint is assumed to be limitless)</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controller_action_idx","title":"<code>controller_action_idx</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding indices (list) in the action vector</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controller_joint_idx","title":"<code>controller_joint_idx</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding indices (list) of the joint state vector controlled by each controller</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controller_order","title":"<code>controller_order</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>list</code> <p>Ordering of the actions, corresponding to the controllers. e.g., [\"base\", \"arm\", \"gripper\"], to denote that the action vector should be interpreted as first the base action, then arm command, then gripper command</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controllers","title":"<code>controllers</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Controllers owned by this object, mapping controller name to controller object</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.default_joint_pos","title":"<code>default_joint_pos</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Default joint positions for this robot</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.default_kd","title":"<code>default_kd</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Default kd gain to apply to any DOF when switching control modes (e.g.: switching from a position control mode to a velocity control mode)</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.default_kp","title":"<code>default_kp</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Default kp gain to apply to any DOF when switching control modes (e.g.: switching from a velocity control mode to a position control mode)</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.discrete_action_list","title":"<code>discrete_action_list</code>  <code>property</code>","text":"<p>Discrete choices for actions for this object. Only needs to be implemented if the object supports discrete actions.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Mapping from single action identifier (e.g.: a string, or a number) to array of continuous actions to deploy via this object's controllers.</p>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.__init__","title":"<code>__init__(name, prim_path=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> <code>'object'</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> <code>PrimType.RIGID</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>control_freq</code> <code>float</code> <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p> <code>None</code> <code>controller_config</code> <code>None or dict</code> <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p> <code>None</code> <code>action_type</code> <code>str</code> <p>one of {discrete, continuous} - what type of action space to use</p> <code>'continuous'</code> <code>action_normalize</code> <code>bool</code> <p>whether to normalize inputted actions. This will override any default values specified by this class.</p> <code>True</code> <code>reset_joint_pos</code> <code>None or n-array</code> <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>def __init__(\nself,\nname,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Store inputs\nself._control_freq = control_freq\nself._controller_config = controller_config\nself._reset_joint_pos = reset_joint_pos if reset_joint_pos is None else np.array(reset_joint_pos)\n# Make sure action type is valid, and also save\nassert_valid_key(key=action_type, valid_keys={\"discrete\", \"continuous\"}, name=\"action type\")\nself._action_type = action_type\nself._action_normalize = action_normalize\n# Store internal placeholders that will be filled in later\nself._dof_to_joints = None          # dict that will map DOF indices to JointPrims\nself._last_action = None\nself._controllers = None\nself.dof_names_ordered = None\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\nload_config=load_config,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.apply_action","title":"<code>apply_action(action)</code>","text":"<p>Converts inputted actions into low-level control signals and deploys them on the object</p> <p>Parameters:</p> Name Type Description Default <code>n_array</code> <p>n-DOF length array of actions to convert and deploy on the object</p> required Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>def apply_action(self, action):\n\"\"\"\n    Converts inputted actions into low-level control signals and deploys them on the object\n    Args:\n        n_array: n-DOF length array of actions to convert and deploy on the object\n    \"\"\"\n# Store last action as the current action being applied\nself._last_action = action\n# If we're using discrete action space, we grab the specific action and use that to convert to control\nif self._action_type == \"discrete\":\naction = np.array(self.discrete_action_list[action])\n# Check if the input action's length matches the action dimension\nassert len(action) == self.action_dim, \"Action must be dimension {}, got dim {} instead.\".format(\nself.action_dim, len(action)\n)\n# Run convert actions to controls\ncontrol, control_type = self._actions_to_control(action=action)\n# Deploy control signals\nself.deploy_control(control=control, control_type=control_type, indices=None, normalized=False)\n</code></pre>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.deploy_control","title":"<code>deploy_control(control, control_type, indices=None, normalized=False)</code>","text":"<p>Deploys control signals @control with corresponding @control_type on this entity.</p> This is DIFFERENT than self.set_joint_positions/velocities/efforts, because in this case we are only <p>setting target values (i.e.: we subject this entity to physical dynamics in order to reach the desired @control setpoints), compared to set_joint_XXXX which manually sets the actual state of the joints.</p> <p>This function is intended to be used with motorized entities, e.g.: robot agents or machines (e.g.: a conveyor belt) to simulation physical control of these entities.</p> <p>In contrast, use set_joint_XXXX for simulation-specific logic, such as simulator resetting or \"magic\" action implementations.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>k- or n-array</code> <p>control signals to deploy. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @control must be the same length as @indices!</p> required <code>control_type</code> <code>k- or n-array</code> <p>control types for each DOF. Each entry should be one of ControlType.  This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific  indices are being set. In this case, the length of @control must be the same length as @indices!</p> required <code>indices</code> <code>None or k-array</code> <p>If specified, should be k (k &lt; n) length array of specific DOF controls to deploy. Default is None, which assumes that all joints are being set.</p> <code>None</code> <code>normalized</code> <code>bool or array of bool</code> <p>Whether the inputted joint controls should be interpreted as normalized values. A single bool can be specified for the entire @control, or an array can be specified for individual values. Default is False, corresponding to all @control assumed to be not normalized</p> <code>False</code> Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>def deploy_control(self, control, control_type, indices=None, normalized=False):\n\"\"\"\n    Deploys control signals @control with corresponding @control_type on this entity.\n    Note: This is DIFFERENT than self.set_joint_positions/velocities/efforts, because in this case we are only\n        setting target values (i.e.: we subject this entity to physical dynamics in order to reach the desired\n        @control setpoints), compared to set_joint_XXXX which manually sets the actual state of the joints.\n        This function is intended to be used with motorized entities, e.g.: robot agents or machines (e.g.: a\n        conveyor belt) to simulation physical control of these entities.\n        In contrast, use set_joint_XXXX for simulation-specific logic, such as simulator resetting or \"magic\"\n        action implementations.\n    Args:\n        control (k- or n-array): control signals to deploy. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @control must\n            be the same length as @indices!\n        control_type (k- or n-array): control types for each DOF. Each entry should be one of ControlType.\n             This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific\n             indices are being set. In this case, the length of @control must be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF controls to deploy.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool or array of bool): Whether the inputted joint controls should be interpreted as normalized\n            values. A single bool can be specified for the entire @control, or an array can be specified for\n            individual values. Default is False, corresponding to all @control assumed to be not normalized\n    \"\"\"\n# Run sanity check\nif indices is None:\nassert len(control) == len(control_type) == self.n_dof, (\n\"Control signals, control types, and number of DOF should all be the same!\"\n\"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), self.n_dof)\n)\n# Set indices manually so that we're standardized\nindices = np.arange(self.n_dof)\nelse:\nassert len(control) == len(control_type) == len(indices), (\n\"Control signals, control types, and indices should all be the same!\"\n\"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), len(indices))\n)\n# Standardize normalized input\nn_indices = len(indices)\nnormalized = normalized if isinstance(normalized, Iterable) else [normalized] * n_indices\n# Loop through controls and deploy\n# We have to use delicate logic to account for the edge cases where a single joint may contain &gt; 1 DOF\n# (e.g.: spherical joint)\ncur_indices_idx = 0\nwhile cur_indices_idx != n_indices:\n# Grab the current DOF index we're controlling and find the corresponding joint\njoint = self._dof_to_joints[indices[cur_indices_idx]]\ncur_ctrl_idx = indices[cur_indices_idx]\njoint_dof = joint.n_dof\nif joint_dof &gt; 1:\n# Run additional sanity checks since the joint has more than one DOF to make sure our controls,\n# control types, and indices all match as expected\n# Make sure the indices are mapped correctly\nassert indices[cur_indices_idx + joint_dof] == cur_ctrl_idx + joint_dof, \\\n                \"Got mismatched control indices for a single joint!\"\n# Check to make sure all joints, control_types, and normalized as all the same over n-DOF for the joint\nfor group_name, group in zip(\n(\"joints\", \"control_types\", \"normalized\"),\n(self._dof_to_joints, control_type, normalized),\n):\nassert len({group[indices[cur_indices_idx + i]] for i in range(joint_dof)}) == 1, \\\n                    f\"Not all {group_name} were the same when trying to deploy control for a single joint!\"\n# Assuming this all passes, we grab the control subvector, type, and normalized value accordingly\nctrl = control[cur_ctrl_idx: cur_ctrl_idx + joint_dof]\nelse:\n# Grab specific control. No need to do checks since this is a single value\nctrl = control[cur_ctrl_idx]\n# Deploy control based on type\nctrl_type, norm = control_type[cur_ctrl_idx], normalized[cur_ctrl_idx]       # In multi-DOF joint case all values were already checked to be the same\nif ctrl_type == ControlType.EFFORT:\njoint.set_effort(ctrl, normalized=norm)\nelif ctrl_type == ControlType.VELOCITY:\njoint.set_vel(ctrl, normalized=norm, drive=True)\nelif ctrl_type == ControlType.POSITION:\njoint.set_pos(ctrl, normalized=norm, drive=True)\nelif ctrl_type == ControlType.NONE:\n# Do nothing\npass\nelse:\nraise ValueError(\"Invalid control type specified: {}\".format(ctrl_type))\n# Finally, increment the current index based on how many DOFs were just controlled\ncur_indices_idx += joint_dof\n</code></pre>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.dump_action","title":"<code>dump_action()</code>","text":"<p>Dump the last action applied to this object. For use in demo collection.</p> Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>def dump_action(self):\n\"\"\"\n    Dump the last action applied to this object. For use in demo collection.\n    \"\"\"\nreturn self._last_action\n</code></pre>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.get_control_dict","title":"<code>get_control_dict()</code>","text":"<p>Grabs all relevant information that should be passed to each controller during each controller step.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped control values for this object, mapping names to n-arrays. By default, returns the following:</p> <ul> <li>joint_position: (n_dof,) joint positions</li> <li>joint_velocity: (n_dof,) joint velocities</li> <li>joint_effort: (n_dof,) joint efforts</li> <li>root_pos: (3,) (x,y,z) global cartesian position of the object's root link</li> <li>root_quat: (4,) (x,y,z,w) global cartesian orientation of ths object's root link</li> </ul> Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>def get_control_dict(self):\n\"\"\"\n    Grabs all relevant information that should be passed to each controller during each controller step.\n    Returns:\n        dict: Keyword-mapped control values for this object, mapping names to n-arrays.\n            By default, returns the following:\n            - joint_position: (n_dof,) joint positions\n            - joint_velocity: (n_dof,) joint velocities\n            - joint_effort: (n_dof,) joint efforts\n            - root_pos: (3,) (x,y,z) global cartesian position of the object's root link\n            - root_quat: (4,) (x,y,z,w) global cartesian orientation of ths object's root link\n    \"\"\"\npos, ori = self.get_position_orientation()\nreturn dict(\njoint_position=self.get_joint_positions(normalized=False),\njoint_velocity=self.get_joint_velocities(normalized=False),\njoint_effort=self.get_joint_efforts(normalized=False),\nroot_pos=pos,\nroot_quat=ori,\n)\n</code></pre>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.reload_controllers","title":"<code>reload_controllers(controller_config=None)</code>","text":"<p>Reloads controllers based on the specified new @controller_config</p> <p>Parameters:</p> Name Type Description Default <code>controller_config</code> <code>None or Dict[str, ...]</code> <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p> <code>None</code> Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>def reload_controllers(self, controller_config=None):\n\"\"\"\n    Reloads controllers based on the specified new @controller_config\n    Args:\n        controller_config (None or Dict[str, ...]): nested dictionary mapping controller name(s) to specific\n            controller configurations for this object. This will override any default values specified by this class.\n    \"\"\"\nself._controller_config = {} if controller_config is None else controller_config\n# (Re-)load controllers\nself._load_controllers()\n# (Re-)create the action space\nself._action_space = self._create_discrete_action_space() if self._action_type == \"discrete\" \\\n        else self._create_continuous_action_space()\n</code></pre>"},{"location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.update_controller_mode","title":"<code>update_controller_mode()</code>","text":"<p>Helper function to force the joints to use the internal specified control mode and gains</p> Source code in <code>omnigibson/objects/controllable_object.py</code> <pre><code>def update_controller_mode(self):\n\"\"\"\n    Helper function to force the joints to use the internal specified control mode and gains\n    \"\"\"\n# Update the control modes of each joint based on the outputted control from the controllers\nfor name in self._controllers:\nfor dof in self._controllers[name].dof_idx:\ncontrol_type = self._controllers[name].control_type\nself._joints[self.dof_names_ordered[dof]].set_control_type(\ncontrol_type=control_type,\nkp=self.default_kp if control_type == ControlType.POSITION else None,\nkd=self.default_kd if control_type == ControlType.VELOCITY else None,\n)\n</code></pre>"},{"location":"reference/objects/dataset_object.html","title":"dataset_object","text":""},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject","title":"<code>DatasetObject</code>","text":"<p>         Bases: <code>USDObject</code></p> <p>DatasetObjects are instantiated from a USD file. It is an object that is assumed to come from an iG-supported dataset. These objects should contain additional metadata, including aggregate statistics across the object's category, e.g., avg dims, bounding boxes, masses, etc.</p> Source code in <code>omnigibson/objects/dataset_object.py</code> <pre><code>class DatasetObject(USDObject):\n\"\"\"\n    DatasetObjects are instantiated from a USD file. It is an object that is assumed to come from an iG-supported\n    dataset. These objects should contain additional metadata, including aggregate statistics across the\n    object's category, e.g., avg dims, bounding boxes, masses, etc.\n    \"\"\"\ndef __init__(\nself,\nname,\nusd_path=None,\nprim_path=None,\ncategory=\"object\",\nmodel=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\nbounding_box=None,\nfit_avg_dim_volume=False,\nin_rooms=None,\nbddl_object_scope=None,\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            usd_path (None or str): If specified, global path to the USD file to load. Note that this will override\n                @category + @model!\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            model (None or str): if @usd_path is not specified, then this must be specified in conjunction with\n                @category to infer the usd filepath to load for this object, which evaluates to the following:\n                    {og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            bounding_box (None or 3-array): If specified, will scale this object such that it fits in the desired\n                (x,y,z) object-aligned bounding box. Note that EITHER @bounding_box or @scale may be specified\n                -- not both!\n            fit_avg_dim_volume (bool): whether to fit the object to have the same volume as the average dimension\n                while keeping the aspect ratio. Note that if this is set, it will override both @scale and @bounding_box\n            in_rooms (None or list): If specified, sets the rooms that this object should belong to\n            bddl_object_scope (None or str): If specified, should set the BDDL object scope name, e.g. chip.n.04_2\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Store variables\nself._in_rooms = in_rooms\nself._bddl_object_scope = bddl_object_scope\n# Info that will be filled in at runtime\nself.supporting_surfaces = None             # Dictionary mapping link names to surfaces represented by links\n# Make sure only one of bounding_box and scale are specified\nif bounding_box is not None and scale is not None:\nraise Exception(\"You cannot define both scale and bounding box size for an DatasetObject\")\n# Add info to load config\nload_config = dict() if load_config is None else load_config\nload_config[\"bounding_box\"] = bounding_box\nload_config[\"fit_avg_dim_volume\"] = fit_avg_dim_volume\n# Infer the correct usd path to use\nif usd_path is None:\nassert model is not None, f\"Either usd_path or model and category must be specified in order to create a\" \\\n                                      f\"DatasetObject!\"\nusd_path = f\"{gm.DATASET_PATH}/objects/{category}/{model}/usd/{model}.usd\"\n# Post-process the usd path if we're generating a cloth object\nif prim_type == PrimType.CLOTH:\nassert usd_path.endswith(\".usd\"), f\"usd_path [{usd_path}] is invalid.\"\nusd_path = usd_path[:-4] + \"_cloth.usd\"\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nusd_path=usd_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\ndef load_supporting_surfaces(self):\n# Initialize dict of supporting surface info\nself.supporting_surfaces = {}\n# See if we have any height info -- if not, we can immediately return\nheights_info = self.heights_per_link\nif heights_info is None:\nreturn\n# TODO: Integrate images directly into usd file?\n# We loop over all the predicates and corresponding supported links in our heights info\nusd_dir = os.path.dirname(self._usd_path)\nfor predicate, links in heights_info.items():\nheight_maps = {}\nfor link_name, heights in links.items():\nheight_maps[link_name] = []\nfor i, z_value in enumerate(heights):\n# Get boolean birds-eye view xy-mask image for this surface\nimg_fname = os.path.join(usd_dir, \"../misc\", \"height_maps_per_link\", predicate, link_name, f\"{i}.png\")\nxy_map = cv2.imread(img_fname, 0)\n# Add this map to the supporting surfaces for this link and predicate combination\nheight_maps[link_name].append((z_value, xy_map))\n# Add this heights map to the overall supporting surfaces\nself.supporting_surfaces[predicate] = height_maps\ndef sample_orientation(self):\n\"\"\"\n        Samples an orientation in quaternion (x,y,z,w) form\n        Returns:\n            4-array: (x,y,z,w) sampled quaternion orientation for this object, based on self.orientations\n        \"\"\"\nif self.orientations is None:\nraise ValueError(\"No orientation probabilities set\")\nif len(self.orientations) == 0:\n# Set default value\nchosen_orientation = np.array([0, 0, 0, 1.0])\nelse:\nprobabilities = [o[\"prob\"] for o in self.orientations.values()]\nprobabilities = np.array(probabilities) / np.sum(probabilities)\nchosen_orientation = np.array(np.random.choice(list(self.orientations.values()), p=probabilities)[\"rotation\"])\n# Randomize yaw from -pi to pi\nrot_num = np.random.uniform(-1, 1)\nrot_matrix = np.array(\n[\n[math.cos(math.pi * rot_num), -math.sin(math.pi * rot_num), 0.0],\n[math.sin(math.pi * rot_num), math.cos(math.pi * rot_num), 0.0],\n[0.0, 0.0, 1.0],\n]\n)\nrotated_quat = T.mat2quat(rot_matrix @ T.quat2mat(chosen_orientation))\nreturn rotated_quat\ndef _initialize(self):\n# Run super method first\nsuper()._initialize()\n# Apply any forced light intensity updates.\nif gm.FORCE_LIGHT_INTENSITY is not None:\ndef recursive_light_update(child_prim):\nif \"Light\" in child_prim.GetPrimTypeInfo().GetTypeName():\nchild_prim.GetAttribute(\"intensity\").Set(gm.FORCE_LIGHT_INTENSITY)\nfor child_child_prim in child_prim.GetChildren():\nrecursive_light_update(child_child_prim)\nrecursive_light_update(self._prim)\n# Apply any forced roughness updates\nfor material in self.materials:\nmaterial.reflection_roughness_texture_influence = 0.0\nmaterial.reflection_roughness_constant = gm.FORCE_ROUGHNESS\n# Set the joint frictions based on category\nfriction = SPECIAL_JOINT_FRICTIONS.get(self.category, DEFAULT_JOINT_FRICTION)\nfor joint in self._joints.values():\nif joint.joint_type != JointType.JOINT_FIXED:\njoint.friction = friction\ndef _load(self):\nif gm.USE_ENCRYPTED_ASSETS:\n# Create a temporary file to store the decrytped asset, load it, and then delete it.\noriginal_usd_path = self._usd_path\nencrypted_filename = original_usd_path.replace(\".usd\", \".encrypted.usd\")\ndecrypted_fd, decrypted_filename = tempfile.mkstemp(os.path.basename(original_usd_path), dir=og.tempdir)\ndecrypt_file(encrypted_filename, decrypted_filename)\nself._usd_path = decrypted_filename\nprim = super()._load()\nos.close(decrypted_fd)\n# On Windows, Isaac Sim won't let go of the file until the prim is removed, so we can't delete it.\nif os.name == \"posix\":\nos.remove(decrypted_filename)\nself._usd_path = original_usd_path\nreturn prim\nelse:\nreturn super()._load()\ndef _post_load(self):\n# We run this post loading first before any others because we're modifying the load config that will be used\n# downstream\n# Set the scale of this prim according to its bounding box\nif self._load_config[\"fit_avg_dim_volume\"]:\n# By default, we assume scale does not change if no avg obj specs are given, otherwise, scale accordingly\nscale = np.ones(3)\nif self.avg_obj_dims is not None and self.avg_obj_dims[\"size\"] is not None:\n# Find the average volume, and scale accordingly relative to the native volume based on the bbox\nvolume_ratio = np.product(self.avg_obj_dims[\"size\"]) / np.product(self.native_bbox)\nsize_ratio = np.cbrt(volume_ratio)\nscale *= size_ratio\n# Otherwise, if manual bounding box is specified, scale based on ratio between that and the native bbox\nelif self._load_config[\"bounding_box\"] is not None:\nscale = self._load_config[\"bounding_box\"] / self.native_bbox\nelse:\nscale = np.ones(3) if self._load_config[\"scale\"] is None else self._load_config[\"scale\"]\n# Set this scale in the load config -- it will automatically scale the object during self.initialize()\nself._load_config[\"scale\"] = scale\n# Load any supporting surfaces belonging to this object\nself.load_supporting_surfaces()\n# Run super last\nsuper()._post_load()\nif gm.USE_ENCRYPTED_ASSETS:\n# The loaded USD is from an already-deleted temporary file, so the asset paths for texture maps are wrong.\n# We explicitly provide the root_path to update all the asset paths: the asset paths are relative to the\n# original USD folder, i.e. &lt;category&gt;/&lt;model&gt;/usd.\nroot_path = os.path.dirname(self._usd_path)\nfor material in self.materials:\nmaterial.shader_update_asset_paths_with_root_path(root_path)\n# Assign realistic density and mass based on average object category spec\nif self.avg_obj_dims is not None and self.avg_obj_dims[\"size\"] is not None and self.avg_obj_dims[\"mass\"] is not None:\n# Assume each link has the same density\nv_ratio = (np.product(self.native_bbox) * np.product(self.scale)) / np.product(self.avg_obj_dims[\"size\"])\nmass = self.avg_obj_dims[\"mass\"] * v_ratio\nif self._prim_type == PrimType.RIGID:\ndensity = mass / self.volume\nfor link in self._links.values():\n# If not a meta (virtual) link, set the density based on avg_obj_dims and a zero mass (ignored)\nif link.has_collision_meshes:\nlink.mass = 0.0\nlink.density = density\nelif self._prim_type == PrimType.CLOTH:\n# Cloth cannot set density. Internally omni evenly distributes the mass to each particle\nmass = self.avg_obj_dims[\"mass\"] * v_ratio\nself._links[\"base_link\"].mass = mass\ndef _update_texture_change(self, object_state):\n\"\"\"\n        Update the texture based on the given object_state. E.g. if object_state is Frozen, update the diffuse color\n        to match the frozen state. If object_state is None, update the diffuse color to the default value. It attempts\n        to load the cached texture map named DIFFUSE/albedo_[STATE_NAME].png. If the cached texture map does not exist,\n        it modifies the current albedo map by adding and scaling the values. See @self._update_albedo_value for details.\n        Args:\n            object_state (BooleanState or None): the object state that the diffuse color should match to\n        \"\"\"\n# TODO: uncomment these once our dataset has the object state-conditioned texture maps\n# DEFAULT_ALBEDO_MAP_SUFFIX = frozenset({\"DIFFUSE\", \"COMBINED\", \"albedo\"})\n# state_name = object_state.__class__.__name__ if object_state is not None else None\nfor material in self.materials:\n# texture_path = material.diffuse_texture\n# assert texture_path is not None, f\"DatasetObject [{self.prim_path}] has invalid diffuse texture map.\"\n#\n# # Get updated texture file path for state.\n# texture_path_split = texture_path.split(\"/\")\n# filedir, filename = \"/\".join(texture_path_split[:-1]), texture_path_split[-1]\n# assert filename[-4:] == \".png\", f\"Texture file {filename} does not end with .png\"\n#\n# filename_split = filename[:-4].split(\"_\")\n# # Check all three file names for backward compatibility.\n# if len(filename_split) &gt; 0 and filename_split[-1] not in DEFAULT_ALBEDO_MAP_SUFFIX:\n#     filename_split.pop()\n# target_texture_path = f\"{filedir}/{'_'.join(filename_split)}\"\n# target_texture_path += f\"_{state_name}.png\" if state_name is not None else \".png\"\n#\n# if os.path.exists(target_texture_path):\n#     # Since we are loading a pre-cached texture map, we need to reset the albedo value to the default\n#     self._update_albedo_value(None, material)\n#     if material.diffuse_texture != target_texture_path:\n#         material.diffuse_texture = target_texture_path\n# else:\n#     print(f\"Warning: DatasetObject [{self.prim_path}] does not have texture map: \"\n#           f\"[{target_texture_path}]. Falling back to directly updating albedo value.\")\nself._update_albedo_value(object_state, material)\ndef set_bbox_center_position_orientation(self, position=None, orientation=None):\n\"\"\"\n        Sets the center of the object's bounding box with respect to the world's frame.\n        Args:\n            position (None or 3-array): The desired global (x,y,z) position. None means it will not be changed\n            orientation (None or 4-array): The desired global (x,y,z,w) quaternion orientation.\n                None means it will not be changed\n        \"\"\"\nif orientation is None:\norientation = self.get_orientation()\nif position is not None:\nrotated_offset = T.pose_transform([0, 0, 0], orientation,\nself.scaled_bbox_center_in_base_frame, [0, 0, 0, 1])[0]\nposition = position + rotated_offset\nself.set_position_orientation(position, orientation)\n@property\ndef in_rooms(self):\n\"\"\"\n        Returns:\n            None or list of str: If specified, room(s) that this object should belong to\n        \"\"\"\nreturn self._in_rooms\n@in_rooms.setter\ndef in_rooms(self, rooms):\n\"\"\"\n        Sets which room(s) this object should belong to. If no rooms, then should set to None\n        Args:\n            rooms (None or list of str): If specified, the room(s) this object should belong to\n        \"\"\"\n# Store the value to the internal variable and also update the init kwargs accordingly\nself._init_info[\"args\"][\"in_rooms\"] = rooms\nself._in_rooms = rooms\n@property\ndef bddl_object_scope(self):\n\"\"\"\n        Returns:\n            None or str: If specified, BDDL object scope name (e.g. chip.n.04_2) to assign to this object\n        \"\"\"\nreturn self._bddl_object_scope\n@bddl_object_scope.setter\ndef bddl_object_scope(self, name):\n\"\"\"\n        Sets which BDDL object scope name for this object. If no name, then should set to None\n        Args:\n            name (None or str): If specified, BDDL object scope name (e.g. chip.n.04_2) to assign to this object\n        \"\"\"\n# Store the value to the internal variable and also update the init kwargs accordingly\nself._init_info[\"args\"][\"bddl_object_scope\"] = name\nself._bddl_object_scope = name\n@property\ndef native_bbox(self):\n\"\"\"\n        Get this object's native bounding box\n        Returns:\n            3-array: (x,y,z) bounding box\n        \"\"\"\nassert \"ig:nativeBB\" in self.property_names, \\\n            f\"This dataset object '{self.name}' is expected to have native_bbox specified, but found none!\"\nreturn np.array(self.get_attribute(attr=\"ig:nativeBB\"))\n@property\ndef base_link_offset(self):\n\"\"\"\n        Get this object's native base link offset\n        Returns:\n            3-array: (x,y,z) base link offset if it exists\n        \"\"\"\nreturn np.array(self.get_attribute(attr=\"ig:offsetBaseLink\"))\n@property\ndef metadata(self):\n\"\"\"\n        Gets this object's metadata, if it exists\n        Returns:\n            None or dict: Nested dictionary of object's metadata if it exists, else None\n        \"\"\"\nreturn self.get_custom_data().get(\"metadata\", None)\n@property\ndef heights_per_link(self):\n\"\"\"\n        Gets this object's heights per link information, if it exists\n        Returns:\n            None or dict: Nested dictionary of object's height per link information if it exists, else None\n        \"\"\"\nreturn self.get_custom_data().get(\"heights_per_link\", None)\n@property\ndef orientations(self):\n\"\"\"\n        Returns:\n            None or dict: Possible orientation information for this object, if it exists. Otherwise, returns None\n        \"\"\"\nmetadata = self.metadata\nreturn None if metadata is None else metadata.get(\"orientations\", None)\n@property\ndef scaled_bbox_center_in_base_frame(self):\n\"\"\"\n        where the base_link origin is wrt. the bounding box center. This allows us to place the model correctly\n        since the joint transformations given in the scene USD are wrt. the bounding box center.\n        We need to scale this offset as well.\n        Returns:\n            3-array: (x,y,z) location of bounding box, with respet to the base link's coordinate frame\n        \"\"\"\nreturn -self.scale * self.base_link_offset\n@property\ndef native_link_bboxes(self):\n\"\"\"\n        Returns:\n             dict: Keyword-mapped native bounding boxes for each link of this object\n        \"\"\"\nreturn None if self.metadata is None else self.metadata.get(\"link_bounding_boxes\", None)\n@property\ndef scales_in_link_frame(self):\n\"\"\"\n        Returns:\n        dict: Keyword-mapped relative scales for each link of this object\n        \"\"\"\nscales = {self.root_link.body_name: self.scale}\n# We iterate through all links in this object, and check for any joint prims that exist\n# We traverse manually this way instead of accessing the self._joints dictionary, because\n# the dictionary only includes articulated joints and not fixed joints!\nfor link in self._links.values():\nfor prim in link.prim.GetChildren():\nif \"joint\" in prim.GetTypeName().lower():\n# Grab relevant joint information\nparent_name = prim.GetProperty(\"physics:body0\").GetTargets()[0].pathString.split(\"/\")[-1]\nchild_name = prim.GetProperty(\"physics:body1\").GetTargets()[0].pathString.split(\"/\")[-1]\nif parent_name in scales and child_name not in scales:\nscale_in_parent_lf = scales[parent_name]\n# The location of the joint frame is scaled using the scale in the parent frame\nquat0 = gf_quat_to_np_array(prim.GetAttribute(\"physics:localRot0\").Get())[[1, 2, 3, 0]]\nquat1 = gf_quat_to_np_array(prim.GetAttribute(\"physics:localRot1\").Get())[[1, 2, 3, 0]]\n# Invert the child link relationship, and multiply the two rotations together to get the final rotation\nlocal_ori = T.quat_multiply(quaternion1=T.quat_inverse(quat1), quaternion0=quat0)\njnt_frame_rot = T.quat2mat(local_ori)\nscale_in_child_lf = np.absolute(jnt_frame_rot.T @ np.array(scale_in_parent_lf))\nscales[child_name] = scale_in_child_lf\nreturn scales\ndef get_base_aligned_bbox(self, link_name=None, visual=False, xy_aligned=False, fallback_to_aabb=False, link_bbox_type=\"axis_aligned\"):\n\"\"\"\n        Get a bounding box for this object that's axis-aligned in the object's base frame.\n        Args:\n            link_name (None or str): If specified, only get the bbox for the given link\n            visual (bool): Whether to aggregate the bounding boxes from the visual meshes. Otherwise, will use\n                collision meshes\n            xy_aligned (bool): Whether to align the bounding box to the global XY-plane\n            fallback_to_aabb (bool): If set and a link's info is not found, the (global-frame) AABB will be\n                dynamically computed directly from omniverse\n            link_bbox_type (str): Which type of link bbox to use, \"axis_aligned\" means the bounding box is axis-aligned\n                to the link frame, \"oriented\" means the bounding box has the minimum volume\n        Returns:\n            4-tuple:\n                - 3-array: (x,y,z) bbox center position in world frame\n                - 3-array: (x,y,z,w) bbox quaternion orientation in world frame\n                - 3-array: (x,y,z) bbox extent in world frame\n                - 3-array: (x,y,z) bbox center in desired frame\n        \"\"\"\nassert self.prim_type == PrimType.RIGID, \"get_base_aligned_bbox is only supported for rigid objects.\"\nbbox_type = \"visual\" if visual else \"collision\"\n# Get the base position transform.\npos, orn = self.get_position_orientation()\nbase_frame_to_world = T.pose2mat((pos, orn))\n# Compute the world-to-base frame transform.\nworld_to_base_frame = trimesh.transformations.inverse_matrix(base_frame_to_world)\n# Grab the corners of all the different links' bounding boxes. We will later fit a bounding box to\n# this set of points to get our final, base-frame bounding box.\npoints = []\nlinks = {link_name: self._links[link_name]} if link_name is not None else self._links\nfor link_name, link in links.items():\n# If the link has no visual or collision meshes, we skip over it (based on the @visual flag)\nmeshes = link.visual_meshes if visual else link.collision_meshes\nif len(meshes) == 0:\ncontinue\n# If the link has a bounding box annotation.\nif self.native_link_bboxes is not None and link_name in self.native_link_bboxes:\n# If a visual bounding box does not exist in the dictionary, try switching to collision.\n# We expect that every link has its collision bb annotated (or set to None if none exists).\nif bbox_type == \"visual\" and \"visual\" not in self.native_link_bboxes[link_name]:\nlog.debug(\n\"Falling back to collision bbox for object %s link %s since no visual bbox exists.\",\nself.name,\nlink_name,\n)\nbbox_type = \"collision\"\n# Check if the annotation is still missing.\nif bbox_type not in self.native_link_bboxes[link_name]:\nraise ValueError(\n\"Could not find %s bounding box for object %s link %s\" % (bbox_type, self.name, link_name)\n)\n# Check if a mesh exists for this link. If None, the link is meshless, so we continue to the next link.\n# TODO: Because of encoding, may need to be UsdTokens.none, not None\nif self.native_link_bboxes[link_name][bbox_type] is None:\ncontinue\n# Get the extent and transform.\nbb_data = self.native_link_bboxes[link_name][bbox_type][link_bbox_type]\nextent_in_bbox_frame = np.array(bb_data[\"extent\"])\nbbox_to_link_origin = np.array(bb_data[\"transform\"])\n# # Get the link's pose in the base frame.\nlink_frame_to_world = T.pose2mat(link.get_position_orientation())\nlink_frame_to_base_frame = world_to_base_frame @ link_frame_to_world\n# Scale the bounding box in link origin frame. Here we create a transform that first puts the bounding\n# box's vertices into the link frame, and then scales them to match the scale applied to this object.\n# Note that once scaled, the vertices of the bounding box do not necessarily form a cuboid anymore but\n# instead a parallelepiped. This is not a problem because we later fit a bounding box to the points,\n# this time in the object's base link frame.\nscale_in_link_frame = np.diag(np.concatenate([self.scales_in_link_frame[link_name], [1]]))\nbbox_to_scaled_link_origin = np.dot(scale_in_link_frame, bbox_to_link_origin)\n# Compute the bounding box vertices in the base frame.\n# bbox_to_link_com = np.dot(link_origin_to_link_com, bbox_to_scaled_link_origin)\nbbox_center_in_base_frame = np.dot(link_frame_to_base_frame, bbox_to_scaled_link_origin)\nvertices_in_base_frame = np.array(list(itertools.product((1, -1), repeat=3))) * (extent_in_bbox_frame / 2)\n# Add the points to our collection of points.\npoints.extend(trimesh.transformations.transform_points(vertices_in_base_frame, bbox_center_in_base_frame))\nelif fallback_to_aabb:\n# If no BB annotation is available, get the AABB for this link.\naabb_center, aabb_extent = BoundingBoxAPI.compute_center_extent(prim_path=link.prim_path)\naabb_vertices_in_world = aabb_center + np.array(list(itertools.product((1, -1), repeat=3))) * (\naabb_extent / 2\n)\naabb_vertices_in_base_frame = trimesh.transformations.transform_points(\naabb_vertices_in_world, world_to_base_frame\n)\npoints.extend(aabb_vertices_in_base_frame)\nelse:\nraise ValueError(\n\"Bounding box annotation missing for link: %s. Use fallback_to_aabb=True if you're okay with using \"\n\"AABB as fallback.\" % link_name\n)\nif xy_aligned:\n# If the user requested an XY-plane aligned bbox, convert everything to that frame.\n# The desired frame is same as the base_com frame with its X/Y rotations removed.\ntranslate = trimesh.transformations.translation_from_matrix(base_frame_to_world)\n# To find the rotation that this transform does around the Z axis, we rotate the [1, 0, 0] vector by it\n# and then take the arctangent of its projection onto the XY plane.\nrotated_X_axis = base_frame_to_world[:3, 0]\nrotation_around_Z_axis = np.arctan2(rotated_X_axis[1], rotated_X_axis[0])\nxy_aligned_base_com_to_world = trimesh.transformations.compose_matrix(\ntranslate=translate, angles=[0, 0, rotation_around_Z_axis]\n)\n# We want to move our points to this frame as well.\nworld_to_xy_aligned_base_com = trimesh.transformations.inverse_matrix(xy_aligned_base_com_to_world)\nbase_com_to_xy_aligned_base_com = np.dot(world_to_xy_aligned_base_com, base_frame_to_world)\npoints = trimesh.transformations.transform_points(points, base_com_to_xy_aligned_base_com)\n# Finally update our desired frame.\ndesired_frame_to_world = xy_aligned_base_com_to_world\nelse:\n# Default desired frame is base CoM frame.\ndesired_frame_to_world = base_frame_to_world\n# TODO: Implement logic to allow tight bounding boxes that don't necessarily have to match the base frame.\n# All points are now in the desired frame: either the base CoM or the xy-plane-aligned base CoM.\n# Now fit a bounding box to all the points by taking the minimum/maximum in the desired frame.\naabb_min_in_desired_frame = np.amin(points, axis=0)\naabb_max_in_desired_frame = np.amax(points, axis=0)\nbbox_center_in_desired_frame = (aabb_min_in_desired_frame + aabb_max_in_desired_frame) / 2\nbbox_extent_in_desired_frame = aabb_max_in_desired_frame - aabb_min_in_desired_frame\n# Transform the center to the world frame.\nbbox_center_in_world = trimesh.transformations.transform_points(\n[bbox_center_in_desired_frame], desired_frame_to_world\n)[0]\nbbox_orn_in_world = Rotation.from_matrix(desired_frame_to_world[:3, :3]).as_quat()\nreturn bbox_center_in_world, bbox_orn_in_world, bbox_extent_in_desired_frame, bbox_center_in_desired_frame\n@property\ndef avg_obj_dims(self):\n\"\"\"\n        Get the average object dimensions for this object, based on its category\n        Returns:\n            None or dict: Average object information based on its category\n        \"\"\"\nreturn AVERAGE_CATEGORY_SPECS.get(self.category, None)\ndef _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n# Add additional kwargs (fit_avg_dim_volume and bounding_box are already captured in load_config)\nreturn self.__class__(\nprim_path=prim_path,\nusd_path=self._usd_path,\nname=name,\ncategory=self.category,\nclass_id=self.class_id,\nscale=self.scale,\nvisible=self.visible,\nfixed_base=self.fixed_base,\nvisual_only=self._visual_only,\nprim_type=self._prim_type,\nload_config=load_config,\nabilities=self._abilities,\nin_rooms=self.in_rooms,\nbddl_object_scope=self.bddl_object_scope,\n)\n</code></pre>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.avg_obj_dims","title":"<code>avg_obj_dims</code>  <code>property</code>","text":"<p>Get the average object dimensions for this object, based on its category</p> <p>Returns:</p> Type Description <p>None or dict: Average object information based on its category</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.base_link_offset","title":"<code>base_link_offset</code>  <code>property</code>","text":"<p>Get this object's native base link offset</p> <p>Returns:</p> Type Description <p>3-array: (x,y,z) base link offset if it exists</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.bddl_object_scope","title":"<code>bddl_object_scope</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: If specified, BDDL object scope name (e.g. chip.n.04_2) to assign to this object</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.heights_per_link","title":"<code>heights_per_link</code>  <code>property</code>","text":"<p>Gets this object's heights per link information, if it exists</p> <p>Returns:</p> Type Description <p>None or dict: Nested dictionary of object's height per link information if it exists, else None</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.in_rooms","title":"<code>in_rooms</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or list of str: If specified, room(s) that this object should belong to</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.metadata","title":"<code>metadata</code>  <code>property</code>","text":"<p>Gets this object's metadata, if it exists</p> <p>Returns:</p> Type Description <p>None or dict: Nested dictionary of object's metadata if it exists, else None</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.native_bbox","title":"<code>native_bbox</code>  <code>property</code>","text":"<p>Get this object's native bounding box</p> <p>Returns:</p> Type Description <p>3-array: (x,y,z) bounding box</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.native_link_bboxes","title":"<code>native_link_bboxes</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped native bounding boxes for each link of this object</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.orientations","title":"<code>orientations</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or dict: Possible orientation information for this object, if it exists. Otherwise, returns None</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.scaled_bbox_center_in_base_frame","title":"<code>scaled_bbox_center_in_base_frame</code>  <code>property</code>","text":"<p>where the base_link origin is wrt. the bounding box center. This allows us to place the model correctly since the joint transformations given in the scene USD are wrt. the bounding box center. We need to scale this offset as well.</p> <p>Returns:</p> Type Description <p>3-array: (x,y,z) location of bounding box, with respet to the base link's coordinate frame</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.scales_in_link_frame","title":"<code>scales_in_link_frame</code>  <code>property</code>","text":"<p>dict: Keyword-mapped relative scales for each link of this object</p>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.__init__","title":"<code>__init__(name, usd_path=None, prim_path=None, category='object', model=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, bounding_box=None, fit_avg_dim_volume=False, in_rooms=None, bddl_object_scope=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>usd_path</code> <code>None or str</code> <p>If specified, global path to the USD file to load. Note that this will override @category + @model!</p> <code>None</code> <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> <code>'object'</code> <code>model</code> <code>None or str</code> <p>if @usd_path is not specified, then this must be specified in conjunction with @category to infer the usd filepath to load for this object, which evaluates to the following:</p> <pre><code>{og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\n</code></pre> <code>None</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> <code>PrimType.RIGID</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>include_default_states</code> <code>bool</code> <p>whether to include the default object states from @get_default_states</p> <code>True</code> <code>bounding_box</code> <code>None or 3-array</code> <p>If specified, will scale this object such that it fits in the desired (x,y,z) object-aligned bounding box. Note that EITHER @bounding_box or @scale may be specified -- not both!</p> <code>None</code> <code>fit_avg_dim_volume</code> <code>bool</code> <p>whether to fit the object to have the same volume as the average dimension while keeping the aspect ratio. Note that if this is set, it will override both @scale and @bounding_box</p> <code>False</code> <code>in_rooms</code> <code>None or list</code> <p>If specified, sets the rooms that this object should belong to</p> <code>None</code> <code>bddl_object_scope</code> <code>None or str</code> <p>If specified, should set the BDDL object scope name, e.g. chip.n.04_2</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/objects/dataset_object.py</code> <pre><code>def __init__(\nself,\nname,\nusd_path=None,\nprim_path=None,\ncategory=\"object\",\nmodel=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\nbounding_box=None,\nfit_avg_dim_volume=False,\nin_rooms=None,\nbddl_object_scope=None,\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        usd_path (None or str): If specified, global path to the USD file to load. Note that this will override\n            @category + @model!\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        model (None or str): if @usd_path is not specified, then this must be specified in conjunction with\n            @category to infer the usd filepath to load for this object, which evaluates to the following:\n                {og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        bounding_box (None or 3-array): If specified, will scale this object such that it fits in the desired\n            (x,y,z) object-aligned bounding box. Note that EITHER @bounding_box or @scale may be specified\n            -- not both!\n        fit_avg_dim_volume (bool): whether to fit the object to have the same volume as the average dimension\n            while keeping the aspect ratio. Note that if this is set, it will override both @scale and @bounding_box\n        in_rooms (None or list): If specified, sets the rooms that this object should belong to\n        bddl_object_scope (None or str): If specified, should set the BDDL object scope name, e.g. chip.n.04_2\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Store variables\nself._in_rooms = in_rooms\nself._bddl_object_scope = bddl_object_scope\n# Info that will be filled in at runtime\nself.supporting_surfaces = None             # Dictionary mapping link names to surfaces represented by links\n# Make sure only one of bounding_box and scale are specified\nif bounding_box is not None and scale is not None:\nraise Exception(\"You cannot define both scale and bounding box size for an DatasetObject\")\n# Add info to load config\nload_config = dict() if load_config is None else load_config\nload_config[\"bounding_box\"] = bounding_box\nload_config[\"fit_avg_dim_volume\"] = fit_avg_dim_volume\n# Infer the correct usd path to use\nif usd_path is None:\nassert model is not None, f\"Either usd_path or model and category must be specified in order to create a\" \\\n                                  f\"DatasetObject!\"\nusd_path = f\"{gm.DATASET_PATH}/objects/{category}/{model}/usd/{model}.usd\"\n# Post-process the usd path if we're generating a cloth object\nif prim_type == PrimType.CLOTH:\nassert usd_path.endswith(\".usd\"), f\"usd_path [{usd_path}] is invalid.\"\nusd_path = usd_path[:-4] + \"_cloth.usd\"\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nusd_path=usd_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.get_base_aligned_bbox","title":"<code>get_base_aligned_bbox(link_name=None, visual=False, xy_aligned=False, fallback_to_aabb=False, link_bbox_type='axis_aligned')</code>","text":"<p>Get a bounding box for this object that's axis-aligned in the object's base frame.</p> <p>Parameters:</p> Name Type Description Default <code>link_name</code> <code>None or str</code> <p>If specified, only get the bbox for the given link</p> <code>None</code> <code>visual</code> <code>bool</code> <p>Whether to aggregate the bounding boxes from the visual meshes. Otherwise, will use collision meshes</p> <code>False</code> <code>xy_aligned</code> <code>bool</code> <p>Whether to align the bounding box to the global XY-plane</p> <code>False</code> <code>fallback_to_aabb</code> <code>bool</code> <p>If set and a link's info is not found, the (global-frame) AABB will be dynamically computed directly from omniverse</p> <code>False</code> <code>link_bbox_type</code> <code>str</code> <p>Which type of link bbox to use, \"axis_aligned\" means the bounding box is axis-aligned to the link frame, \"oriented\" means the bounding box has the minimum volume</p> <code>'axis_aligned'</code> <p>Returns:</p> Type Description <p>4-tuple: - 3-array: (x,y,z) bbox center position in world frame - 3-array: (x,y,z,w) bbox quaternion orientation in world frame - 3-array: (x,y,z) bbox extent in world frame - 3-array: (x,y,z) bbox center in desired frame</p> Source code in <code>omnigibson/objects/dataset_object.py</code> <pre><code>def get_base_aligned_bbox(self, link_name=None, visual=False, xy_aligned=False, fallback_to_aabb=False, link_bbox_type=\"axis_aligned\"):\n\"\"\"\n    Get a bounding box for this object that's axis-aligned in the object's base frame.\n    Args:\n        link_name (None or str): If specified, only get the bbox for the given link\n        visual (bool): Whether to aggregate the bounding boxes from the visual meshes. Otherwise, will use\n            collision meshes\n        xy_aligned (bool): Whether to align the bounding box to the global XY-plane\n        fallback_to_aabb (bool): If set and a link's info is not found, the (global-frame) AABB will be\n            dynamically computed directly from omniverse\n        link_bbox_type (str): Which type of link bbox to use, \"axis_aligned\" means the bounding box is axis-aligned\n            to the link frame, \"oriented\" means the bounding box has the minimum volume\n    Returns:\n        4-tuple:\n            - 3-array: (x,y,z) bbox center position in world frame\n            - 3-array: (x,y,z,w) bbox quaternion orientation in world frame\n            - 3-array: (x,y,z) bbox extent in world frame\n            - 3-array: (x,y,z) bbox center in desired frame\n    \"\"\"\nassert self.prim_type == PrimType.RIGID, \"get_base_aligned_bbox is only supported for rigid objects.\"\nbbox_type = \"visual\" if visual else \"collision\"\n# Get the base position transform.\npos, orn = self.get_position_orientation()\nbase_frame_to_world = T.pose2mat((pos, orn))\n# Compute the world-to-base frame transform.\nworld_to_base_frame = trimesh.transformations.inverse_matrix(base_frame_to_world)\n# Grab the corners of all the different links' bounding boxes. We will later fit a bounding box to\n# this set of points to get our final, base-frame bounding box.\npoints = []\nlinks = {link_name: self._links[link_name]} if link_name is not None else self._links\nfor link_name, link in links.items():\n# If the link has no visual or collision meshes, we skip over it (based on the @visual flag)\nmeshes = link.visual_meshes if visual else link.collision_meshes\nif len(meshes) == 0:\ncontinue\n# If the link has a bounding box annotation.\nif self.native_link_bboxes is not None and link_name in self.native_link_bboxes:\n# If a visual bounding box does not exist in the dictionary, try switching to collision.\n# We expect that every link has its collision bb annotated (or set to None if none exists).\nif bbox_type == \"visual\" and \"visual\" not in self.native_link_bboxes[link_name]:\nlog.debug(\n\"Falling back to collision bbox for object %s link %s since no visual bbox exists.\",\nself.name,\nlink_name,\n)\nbbox_type = \"collision\"\n# Check if the annotation is still missing.\nif bbox_type not in self.native_link_bboxes[link_name]:\nraise ValueError(\n\"Could not find %s bounding box for object %s link %s\" % (bbox_type, self.name, link_name)\n)\n# Check if a mesh exists for this link. If None, the link is meshless, so we continue to the next link.\n# TODO: Because of encoding, may need to be UsdTokens.none, not None\nif self.native_link_bboxes[link_name][bbox_type] is None:\ncontinue\n# Get the extent and transform.\nbb_data = self.native_link_bboxes[link_name][bbox_type][link_bbox_type]\nextent_in_bbox_frame = np.array(bb_data[\"extent\"])\nbbox_to_link_origin = np.array(bb_data[\"transform\"])\n# # Get the link's pose in the base frame.\nlink_frame_to_world = T.pose2mat(link.get_position_orientation())\nlink_frame_to_base_frame = world_to_base_frame @ link_frame_to_world\n# Scale the bounding box in link origin frame. Here we create a transform that first puts the bounding\n# box's vertices into the link frame, and then scales them to match the scale applied to this object.\n# Note that once scaled, the vertices of the bounding box do not necessarily form a cuboid anymore but\n# instead a parallelepiped. This is not a problem because we later fit a bounding box to the points,\n# this time in the object's base link frame.\nscale_in_link_frame = np.diag(np.concatenate([self.scales_in_link_frame[link_name], [1]]))\nbbox_to_scaled_link_origin = np.dot(scale_in_link_frame, bbox_to_link_origin)\n# Compute the bounding box vertices in the base frame.\n# bbox_to_link_com = np.dot(link_origin_to_link_com, bbox_to_scaled_link_origin)\nbbox_center_in_base_frame = np.dot(link_frame_to_base_frame, bbox_to_scaled_link_origin)\nvertices_in_base_frame = np.array(list(itertools.product((1, -1), repeat=3))) * (extent_in_bbox_frame / 2)\n# Add the points to our collection of points.\npoints.extend(trimesh.transformations.transform_points(vertices_in_base_frame, bbox_center_in_base_frame))\nelif fallback_to_aabb:\n# If no BB annotation is available, get the AABB for this link.\naabb_center, aabb_extent = BoundingBoxAPI.compute_center_extent(prim_path=link.prim_path)\naabb_vertices_in_world = aabb_center + np.array(list(itertools.product((1, -1), repeat=3))) * (\naabb_extent / 2\n)\naabb_vertices_in_base_frame = trimesh.transformations.transform_points(\naabb_vertices_in_world, world_to_base_frame\n)\npoints.extend(aabb_vertices_in_base_frame)\nelse:\nraise ValueError(\n\"Bounding box annotation missing for link: %s. Use fallback_to_aabb=True if you're okay with using \"\n\"AABB as fallback.\" % link_name\n)\nif xy_aligned:\n# If the user requested an XY-plane aligned bbox, convert everything to that frame.\n# The desired frame is same as the base_com frame with its X/Y rotations removed.\ntranslate = trimesh.transformations.translation_from_matrix(base_frame_to_world)\n# To find the rotation that this transform does around the Z axis, we rotate the [1, 0, 0] vector by it\n# and then take the arctangent of its projection onto the XY plane.\nrotated_X_axis = base_frame_to_world[:3, 0]\nrotation_around_Z_axis = np.arctan2(rotated_X_axis[1], rotated_X_axis[0])\nxy_aligned_base_com_to_world = trimesh.transformations.compose_matrix(\ntranslate=translate, angles=[0, 0, rotation_around_Z_axis]\n)\n# We want to move our points to this frame as well.\nworld_to_xy_aligned_base_com = trimesh.transformations.inverse_matrix(xy_aligned_base_com_to_world)\nbase_com_to_xy_aligned_base_com = np.dot(world_to_xy_aligned_base_com, base_frame_to_world)\npoints = trimesh.transformations.transform_points(points, base_com_to_xy_aligned_base_com)\n# Finally update our desired frame.\ndesired_frame_to_world = xy_aligned_base_com_to_world\nelse:\n# Default desired frame is base CoM frame.\ndesired_frame_to_world = base_frame_to_world\n# TODO: Implement logic to allow tight bounding boxes that don't necessarily have to match the base frame.\n# All points are now in the desired frame: either the base CoM or the xy-plane-aligned base CoM.\n# Now fit a bounding box to all the points by taking the minimum/maximum in the desired frame.\naabb_min_in_desired_frame = np.amin(points, axis=0)\naabb_max_in_desired_frame = np.amax(points, axis=0)\nbbox_center_in_desired_frame = (aabb_min_in_desired_frame + aabb_max_in_desired_frame) / 2\nbbox_extent_in_desired_frame = aabb_max_in_desired_frame - aabb_min_in_desired_frame\n# Transform the center to the world frame.\nbbox_center_in_world = trimesh.transformations.transform_points(\n[bbox_center_in_desired_frame], desired_frame_to_world\n)[0]\nbbox_orn_in_world = Rotation.from_matrix(desired_frame_to_world[:3, :3]).as_quat()\nreturn bbox_center_in_world, bbox_orn_in_world, bbox_extent_in_desired_frame, bbox_center_in_desired_frame\n</code></pre>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.sample_orientation","title":"<code>sample_orientation()</code>","text":"<p>Samples an orientation in quaternion (x,y,z,w) form</p> <p>Returns:</p> Type Description <p>4-array: (x,y,z,w) sampled quaternion orientation for this object, based on self.orientations</p> Source code in <code>omnigibson/objects/dataset_object.py</code> <pre><code>def sample_orientation(self):\n\"\"\"\n    Samples an orientation in quaternion (x,y,z,w) form\n    Returns:\n        4-array: (x,y,z,w) sampled quaternion orientation for this object, based on self.orientations\n    \"\"\"\nif self.orientations is None:\nraise ValueError(\"No orientation probabilities set\")\nif len(self.orientations) == 0:\n# Set default value\nchosen_orientation = np.array([0, 0, 0, 1.0])\nelse:\nprobabilities = [o[\"prob\"] for o in self.orientations.values()]\nprobabilities = np.array(probabilities) / np.sum(probabilities)\nchosen_orientation = np.array(np.random.choice(list(self.orientations.values()), p=probabilities)[\"rotation\"])\n# Randomize yaw from -pi to pi\nrot_num = np.random.uniform(-1, 1)\nrot_matrix = np.array(\n[\n[math.cos(math.pi * rot_num), -math.sin(math.pi * rot_num), 0.0],\n[math.sin(math.pi * rot_num), math.cos(math.pi * rot_num), 0.0],\n[0.0, 0.0, 1.0],\n]\n)\nrotated_quat = T.mat2quat(rot_matrix @ T.quat2mat(chosen_orientation))\nreturn rotated_quat\n</code></pre>"},{"location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.set_bbox_center_position_orientation","title":"<code>set_bbox_center_position_orientation(position=None, orientation=None)</code>","text":"<p>Sets the center of the object's bounding box with respect to the world's frame.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>None or 3-array</code> <p>The desired global (x,y,z) position. None means it will not be changed</p> <code>None</code> <code>orientation</code> <code>None or 4-array</code> <p>The desired global (x,y,z,w) quaternion orientation. None means it will not be changed</p> <code>None</code> Source code in <code>omnigibson/objects/dataset_object.py</code> <pre><code>def set_bbox_center_position_orientation(self, position=None, orientation=None):\n\"\"\"\n    Sets the center of the object's bounding box with respect to the world's frame.\n    Args:\n        position (None or 3-array): The desired global (x,y,z) position. None means it will not be changed\n        orientation (None or 4-array): The desired global (x,y,z,w) quaternion orientation.\n            None means it will not be changed\n    \"\"\"\nif orientation is None:\norientation = self.get_orientation()\nif position is not None:\nrotated_offset = T.pose_transform([0, 0, 0], orientation,\nself.scaled_bbox_center_in_base_frame, [0, 0, 0, 1])[0]\nposition = position + rotated_offset\nself.set_position_orientation(position, orientation)\n</code></pre>"},{"location":"reference/objects/light_object.html","title":"light_object","text":""},{"location":"reference/objects/light_object.html#objects.light_object.LightObject","title":"<code>LightObject</code>","text":"<p>         Bases: <code>StatefulObject</code></p> <p>LightObjects are objects that generate light in the simulation</p> Source code in <code>omnigibson/objects/light_object.py</code> <pre><code>class LightObject(StatefulObject):\n\"\"\"\n    LightObjects are objects that generate light in the simulation\n    \"\"\"\nLIGHT_TYPES = {\n\"Cylinder\",\n\"Disk\",\n\"Distant\",\n\"Dome\",\n\"Geometry\",\n\"Rect\",\n\"Sphere\",\n}\ndef __init__(\nself,\nname,\nlight_type,\nprim_path=None,\ncategory=\"light\",\nclass_id=None,\nuuid=None,\nscale=None,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\nradius=1.0,\nintensity=50000.0,\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            light_type (str): Type of light to create. Valid options are LIGHT_TYPES\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            radius (float): Radius for this light.\n            intensity (float): Intensity for this light.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Compose load config and add rgba values\nload_config = dict() if load_config is None else load_config\nload_config[\"scale\"] = scale\nload_config[\"intensity\"] = intensity\nload_config[\"radius\"] = radius if light_type in {\"Cylinder\", \"Disk\", \"Sphere\"} else None\n# Make sure primitive type is valid\nassert_valid_key(key=light_type, valid_keys=self.LIGHT_TYPES, name=\"light_type\")\nself.light_type = light_type\n# Other attributes to be filled in at runtime\nself._light_link = None\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=True,\nfixed_base=False,\nvisual_only=True,\nself_collisions=False,\nprim_type=PrimType.RIGID,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\ndef _load(self):\n# Define XForm and base link for this light\nprim = og.sim.stage.DefinePrim(self._prim_path, \"Xform\")\nbase_link = og.sim.stage.DefinePrim(f\"{self._prim_path}/base_link\", \"Xform\")\n# Define the actual light link\nlight_prim = UsdLux.__dict__[f\"{self.light_type}Light\"].Define(og.sim.stage, f\"{self._prim_path}/base_link/light\").GetPrim()\nreturn prim\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Grab reference to light link\nself._light_link = XFormPrim(prim_path=f\"{self._prim_path}/base_link/light\", name=f\"{self.name}:light_link\")\n# Apply Shaping API and set default cone angle attribute\nshaping_api = UsdLux.ShapingAPI.Apply(self._light_link.prim).GetShapingConeAngleAttr().Set(180.0)\n# Optionally set the intensity\nif self._load_config.get(\"intensity\", None) is not None:\nself.intensity = self._load_config[\"intensity\"]\n# Optionally set the radius\nif self._load_config.get(\"radius\", None) is not None:\nself.radius = self._load_config[\"radius\"]\ndef _initialize(self):\n# Run super\nsuper()._initialize()\n# Initialize light link\nself._light_link.initialize()\n@property\ndef light_link(self):\n\"\"\"\n        Returns:\n            XFormPrim: Link corresponding to the light prim itself\n        \"\"\"\nreturn self._light_link\n@property\ndef radius(self):\n\"\"\"\n        Gets this light's radius\n        Returns:\n            float: radius for this light\n        \"\"\"\nreturn self._light_link.get_attribute(\"radius\")\n@radius.setter\ndef radius(self, radius):\n\"\"\"\n        Sets this light's radius\n        Args:\n            radius (float): radius to set\n        \"\"\"\nself._light_link.set_attribute(\"radius\", radius)\n@property\ndef intensity(self):\n\"\"\"\n        Gets this joint's intensity\n        Returns:\n            float: intensity for this light\n        \"\"\"\nreturn self._light_link.get_attribute(\"intensity\")\n@intensity.setter\ndef intensity(self, intensity):\n\"\"\"\n        Sets this joint's intensity\n        Args:\n            intensity (float): intensity to set\n        \"\"\"\nself._light_link.set_attribute(\"intensity\", intensity)\ndef _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n# Add additional kwargs (fit_avg_dim_volume and bounding_box are already captured in load_config)\nreturn self.__class__(\nprim_path=prim_path,\nlight_type=self.light_type,\nname=name,\nintensity=self.intensity,\nload_config=load_config,\n)\n</code></pre>"},{"location":"reference/objects/light_object.html#objects.light_object.LightObject.intensity","title":"<code>intensity</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's intensity</p> <p>Returns:</p> Name Type Description <code>float</code> <p>intensity for this light</p>"},{"location":"reference/objects/light_object.html#objects.light_object.LightObject.light_link","title":"<code>light_link</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>XFormPrim</code> <p>Link corresponding to the light prim itself</p>"},{"location":"reference/objects/light_object.html#objects.light_object.LightObject.radius","title":"<code>radius</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this light's radius</p> <p>Returns:</p> Name Type Description <code>float</code> <p>radius for this light</p>"},{"location":"reference/objects/light_object.html#objects.light_object.LightObject.__init__","title":"<code>__init__(name, light_type, prim_path=None, category='light', class_id=None, uuid=None, scale=None, load_config=None, abilities=None, include_default_states=True, radius=1.0, intensity=50000.0, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>light_type</code> <code>str</code> <p>Type of light to create. Valid options are LIGHT_TYPES</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> <code>'light'</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> required <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> required <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> required <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> required <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>include_default_states</code> <code>bool</code> <p>whether to include the default object states from @get_default_states</p> <code>True</code> <code>radius</code> <code>float</code> <p>Radius for this light.</p> <code>1.0</code> <code>intensity</code> <code>float</code> <p>Intensity for this light.</p> <code>50000.0</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/objects/light_object.py</code> <pre><code>def __init__(\nself,\nname,\nlight_type,\nprim_path=None,\ncategory=\"light\",\nclass_id=None,\nuuid=None,\nscale=None,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\nradius=1.0,\nintensity=50000.0,\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        light_type (str): Type of light to create. Valid options are LIGHT_TYPES\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        radius (float): Radius for this light.\n        intensity (float): Intensity for this light.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Compose load config and add rgba values\nload_config = dict() if load_config is None else load_config\nload_config[\"scale\"] = scale\nload_config[\"intensity\"] = intensity\nload_config[\"radius\"] = radius if light_type in {\"Cylinder\", \"Disk\", \"Sphere\"} else None\n# Make sure primitive type is valid\nassert_valid_key(key=light_type, valid_keys=self.LIGHT_TYPES, name=\"light_type\")\nself.light_type = light_type\n# Other attributes to be filled in at runtime\nself._light_link = None\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=True,\nfixed_base=False,\nvisual_only=True,\nself_collisions=False,\nprim_type=PrimType.RIGID,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/objects/object_base.html","title":"object_base","text":""},{"location":"reference/objects/object_base.html#objects.object_base.BaseObject","title":"<code>BaseObject</code>","text":"<p>         Bases: <code>EntityPrim</code>, <code>Registerable</code></p> <p>This is the interface that all OmniGibson objects must implement.</p> Source code in <code>omnigibson/objects/object_base.py</code> <pre><code>class BaseObject(EntityPrim, Registerable, metaclass=ABCMeta):\n\"\"\"This is the interface that all OmniGibson objects must implement.\"\"\"\ndef __init__(\nself,\nname,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n                Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n                that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n        \"\"\"\n# Generate default prim path if none is specified\nprim_path = f\"/World/{name}\" if prim_path is None else prim_path\n# Store values\nself.uuid = get_uuid(name) if uuid is None else uuid\nassert len(str(self.uuid)) &lt;= 8, f\"UUID for this object must be at max 8-digits, got: {self.uuid}\"\nself.category = category\nself.fixed_base = fixed_base\n# This sets the collision group of the object. In omnigibson, objects are only permitted to be part of a single\n# collision group, e.g. collisions are only enabled within a single group\nself.collision_group = SPECIAL_COLLISION_GROUPS.get(self.category, DEFAULT_COLLISION_GROUP)\n# Infer class ID if not specified\nif class_id is None:\nclass_id = CLASS_NAME_TO_CLASS_ID.get(category, SemanticClass.USER_ADDED_OBJS)\nself.class_id = class_id\n# Values to be created at runtime\nself._highlight_cached_values = None\nself._highlighted = None\n# Create load config from inputs\nload_config = dict() if load_config is None else load_config\nload_config[\"scale\"] = scale\nload_config[\"visible\"] = visible\nload_config[\"visual_only\"] = visual_only\nload_config[\"self_collisions\"] = self_collisions\nload_config[\"prim_type\"] = prim_type\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\n# TODO: Super hacky, think of a better way to preserve this info\n# Update init info for this\nself._init_info[\"args\"][\"name\"] = self.name\nself._init_info[\"args\"][\"uuid\"] = self.uuid\ndef load(self):\n# Run super method ONLY if we're not loaded yet\nif self.loaded:\nprim = self._prim\nelse:\nprim = super().load()\nlog.info(f\"Loaded {self.name} at {self.prim_path}\")\nreturn prim\ndef remove(self):\n# Run super first\nsuper().remove()\n# Notify user that the object was removed\nlog.info(f\"Removed {self.name} from {self.prim_path}\")\ndef _post_load(self):\n# Run super first\nsuper()._post_load()\n# Set visibility\nif \"visible\" in self._load_config and self._load_config[\"visible\"] is not None:\nself.visible = self._load_config[\"visible\"]\n# First, remove any articulation root API that already exists at the object-level prim\nif self._prim.HasAPI(UsdPhysics.ArticulationRootAPI):\nself._prim.RemoveAPI(UsdPhysics.ArticulationRootAPI)\nself._prim.RemoveAPI(PhysxSchema.PhysxArticulationAPI)\n# Add fixed joint if we're fixing the base\nif self.fixed_base:\n# For optimization purposes, if we only have a single rigid body that has either\n# (no custom scaling OR no fixed joints), we assume this is not an articulated object so we\n# merely set this to be a static collider, i.e.: kinematic-only\n# The custom scaling / fixed joints requirement is needed because omniverse complains about scaling that\n# occurs with respect to fixed joints, as omni will \"snap\" bodies together otherwise\nif self.n_joints == 0 and (np.all(np.isclose(self.scale, 1.0, atol=1e-3)) or self.n_fixed_joints == 0):\nself.kinematic_only = True\nelse:\n# Create fixed joint, and set Body0 to be this object's root prim\ncreate_joint(\nprim_path=f\"{self._prim_path}/rootJoint\",\njoint_type=\"FixedJoint\",\nbody1=f\"{self._prim_path}/{self._root_link_name}\",\n)\n# Potentially add articulation root APIs and also set self collisions\nroot_prim = None if self.articulation_root_path is None else get_prim_at_path(self.articulation_root_path)\nif root_prim is not None:\nUsdPhysics.ArticulationRootAPI.Apply(root_prim)\nPhysxSchema.PhysxArticulationAPI.Apply(root_prim)\nself.self_collisions = self._load_config[\"self_collisions\"]\n# TODO: Do we need to explicitly add all links? or is adding articulation root itself sufficient?\n# Set the collision group\nCollisionAPI.add_to_collision_group(\ncol_group=self.collision_group,\nprim_path=self.prim_path,\ncreate_if_not_exist=True,\n)\n# Update semantics\nadd_update_semantics(\nprim=self._prim,\nsemantic_label=self.category,\ntype_label=\"class\",\n)\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Iterate over all links and grab their relevant material info for highlighting (i.e.: emissivity info)\nself._highlighted = False\nself._highlight_cached_values = dict()\nfor material in self.materials:\nself._highlight_cached_values[material] = {\n\"enable_emission\": material.enable_emission,\n\"emissive_color\": material.emissive_color,\n\"emissive_intensity\": material.emissive_intensity,\n}\n@property\ndef articulation_root_path(self):\nhas_articulated_joints, has_fixed_joints = self.n_joints &gt; 0, self.n_fixed_joints &gt; 0\nif self.kinematic_only or ((not has_articulated_joints) and (not has_fixed_joints)):\n# Kinematic only, or non-jointed single body objects\nreturn None\nelif not self.fixed_base:\n# This is all remaining non-fixed objects\n# This is a bit hacky because omniverse is buggy\n# Articulation roots mess up the joint order if it's on a non-fixed base robot, e.g. a\n# mobile manipulator. So if we have to move it to the actual root link of the robot instead.\n# See https://forums.developer.nvidia.com/t/inconsistent-values-from-isaacsims-dc-get-joint-parent-child-body/201452/2\n# for more info\nreturn f\"{self._prim_path}/{self.root_link_name}\"\nelse:\n# Fixed objects that are not kinematic only, or non-fixed objects that have no articulated joints but do\n# have fixed joints\nreturn self._prim_path\n@property\ndef mass(self):\n\"\"\"\n        Returns:\n             float: Cumulative mass of this potentially articulated object.\n        \"\"\"\nmass = 0.0\nfor link in self._links.values():\nmass += link.mass\nreturn mass\n@mass.setter\ndef mass(self, mass):\nraise NotImplementedError(\"Cannot set mass directly for an object!\")\n@property\ndef volume(self):\n\"\"\"\n        Returns:\n             float: Cumulative volume of this potentially articulated object.\n        \"\"\"\nvolume = 0.0\nfor link in self._links.values():\nvolume += link.volume\nreturn volume\n@volume.setter\ndef volume(self, volume):\nraise NotImplementedError(\"Cannot set volume directly for an object!\")\n@property\ndef link_prim_paths(self):\nreturn [link.prim_path for link in self._links.values()]\n@property\ndef highlighted(self):\n\"\"\"\n        Returns:\n            bool: Whether the object is highlighted or not\n        \"\"\"\nreturn self._highlighted\n@highlighted.setter\ndef highlighted(self, enabled):\n\"\"\"\n        Iterates over all owned links, and modifies their materials with emissive colors so that the object is\n        highlighted (magenta by default)\n        Args:\n            enabled (bool): whether the object should be highlighted or not\n        \"\"\"\n# Return early if the set value matches the internal value\nif enabled == self._highlighted:\nreturn\nfor material in self.materials:\nif enabled:\n# Store values before swapping\nself._highlight_cached_values[material] = {\n\"enable_emission\": material.enable_emission,\n\"emissive_color\": material.emissive_color,\n\"emissive_intensity\": material.emissive_intensity,\n}\nmaterial.enable_emission = True if enabled else self._highlight_cached_values[material][\"enable_emission\"]\nmaterial.emissive_color = m.HIGHLIGHT_RGB if enabled else self._highlight_cached_values[material][\"emissive_color\"]\nmaterial.emissive_intensity = m.HIGHLIGHT_INTENSITY if enabled else self._highlight_cached_values[material][\"emissive_intensity\"]\n# Update internal value\nself._highlighted = enabled\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseObject\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global robot registry\nglobal REGISTERED_OBJECTS\nreturn REGISTERED_OBJECTS\n</code></pre>"},{"location":"reference/objects/object_base.html#objects.object_base.BaseObject.highlighted","title":"<code>highlighted</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the object is highlighted or not</p>"},{"location":"reference/objects/object_base.html#objects.object_base.BaseObject.mass","title":"<code>mass</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Cumulative mass of this potentially articulated object.</p>"},{"location":"reference/objects/object_base.html#objects.object_base.BaseObject.volume","title":"<code>volume</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Cumulative volume of this potentially articulated object.</p>"},{"location":"reference/objects/object_base.html#objects.object_base.BaseObject.__init__","title":"<code>__init__(name, prim_path=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> <code>'object'</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> <code>PrimType.RIGID</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject). Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).</p> <code>{}</code> Source code in <code>omnigibson/objects/object_base.py</code> <pre><code>def __init__(\nself,\nname,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n            Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n            that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n    \"\"\"\n# Generate default prim path if none is specified\nprim_path = f\"/World/{name}\" if prim_path is None else prim_path\n# Store values\nself.uuid = get_uuid(name) if uuid is None else uuid\nassert len(str(self.uuid)) &lt;= 8, f\"UUID for this object must be at max 8-digits, got: {self.uuid}\"\nself.category = category\nself.fixed_base = fixed_base\n# This sets the collision group of the object. In omnigibson, objects are only permitted to be part of a single\n# collision group, e.g. collisions are only enabled within a single group\nself.collision_group = SPECIAL_COLLISION_GROUPS.get(self.category, DEFAULT_COLLISION_GROUP)\n# Infer class ID if not specified\nif class_id is None:\nclass_id = CLASS_NAME_TO_CLASS_ID.get(category, SemanticClass.USER_ADDED_OBJS)\nself.class_id = class_id\n# Values to be created at runtime\nself._highlight_cached_values = None\nself._highlighted = None\n# Create load config from inputs\nload_config = dict() if load_config is None else load_config\nload_config[\"scale\"] = scale\nload_config[\"visible\"] = visible\nload_config[\"visual_only\"] = visual_only\nload_config[\"self_collisions\"] = self_collisions\nload_config[\"prim_type\"] = prim_type\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\n# TODO: Super hacky, think of a better way to preserve this info\n# Update init info for this\nself._init_info[\"args\"][\"name\"] = self.name\nself._init_info[\"args\"][\"uuid\"] = self.uuid\n</code></pre>"},{"location":"reference/objects/primitive_object.html","title":"primitive_object","text":""},{"location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject","title":"<code>PrimitiveObject</code>","text":"<p>         Bases: <code>StatefulObject</code></p> <p>PrimitiveObjects are objects defined by a single geom, e.g: sphere, mesh, cube, etc.</p> Source code in <code>omnigibson/objects/primitive_object.py</code> <pre><code>class PrimitiveObject(StatefulObject):\n\"\"\"\n    PrimitiveObjects are objects defined by a single geom, e.g: sphere, mesh, cube, etc.\n    \"\"\"\ndef __init__(\nself,\nname,\nprimitive_type,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\nrgba=(0.5, 0.5, 0.5, 1.0),\nradius=None,\nheight=None,\nsize=None,\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            primitive_type (str): type of primitive object to create. Should be one of:\n                {\"Cone\", \"Cube\", \"Cylinder\", \"Disk\", \"Plane\", \"Sphere\", \"Torus\"}\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.rgba (4-array): (R, G, B, A) values to set for this object\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            radius (None or float): If specified, sets the radius for this object. This value is scaled by @scale\n                Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n            height (None or float): If specified, sets the height for this object. This value is scaled by @scale\n                Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\"}\n            size (None or float): If specified, sets the size for this object. This value is scaled by @scale\n                Note: Should only be specified if the @primitive_type is one of {\"Cube\", \"Torus\"}\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Compose load config and add rgba values\nload_config = dict() if load_config is None else load_config\nload_config[\"color\"] = np.array(rgba[:3])\nload_config[\"opacity\"] = rgba[3]\nload_config[\"radius\"] = radius\nload_config[\"height\"] = height\nload_config[\"size\"] = size\n# Initialize other internal variables\nself._vis_geom = None\nself._col_geom = None\nself._extents = np.ones(3)            # (x,y,z extents)\n# Make sure primitive type is valid\nassert_valid_key(key=primitive_type, valid_keys=PRIMITIVE_MESH_TYPES, name=\"primitive mesh type\")\nself._primitive_type = primitive_type\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\ndef _load(self):\n# Define an Xform at the specified path\nprim = og.sim.stage.DefinePrim(self._prim_path, \"Xform\")\nif self._prim_type == PrimType.RIGID:\n# Define a nested mesh corresponding to the root link for this prim\nbase_link = og.sim.stage.DefinePrim(f\"{self._prim_path}/base_link\", \"Xform\")\nself._vis_geom = create_primitive_mesh(prim_path=f\"{self._prim_path}/base_link/visuals\", primitive_type=self._primitive_type)\nself._col_geom = create_primitive_mesh(prim_path=f\"{self._prim_path}/base_link/collisions\", primitive_type=self._primitive_type)\n# Add collision API to collision geom\nUsdPhysics.CollisionAPI.Apply(self._col_geom.GetPrim())\nUsdPhysics.MeshCollisionAPI.Apply(self._col_geom.GetPrim())\nPhysxSchema.PhysxCollisionAPI.Apply(self._col_geom.GetPrim())\nelif self._prim_type == PrimType.CLOTH:\n# For Cloth, the base link itself is a cloth mesh\n# TODO (eric): configure u_patches and v_patches\nself._vis_geom = create_primitive_mesh(\nprim_path=f\"{self._prim_path}/base_link\",\nprimitive_type=self._primitive_type,\nu_patches=None,\nv_patches=None,\n)\nself._col_geom = None\n# Create a material for this object for the base link\nog.sim.stage.DefinePrim(f\"{self._prim_path}/Looks\", \"Scope\")\nmat_path = f\"{self._prim_path}/Looks/default\"\nmat = create_pbr_material(prim_path=mat_path)\nbind_material(prim_path=self._vis_geom.GetPrim().GetPrimPath().pathString, material_path=mat_path)\nreturn prim\ndef _post_load(self):\n# Run super first\nsuper()._post_load()\n# Set the collision approximation appropriately\nif self._primitive_type == \"Sphere\":\ncol_approximation = \"boundingSphere\"\nelif self._primitive_type == \"Cube\":\ncol_approximation = \"boundingCube\"\nelse:\ncol_approximation = \"convexHull\"\nself.root_link.collision_meshes[\"collisions\"].set_collision_approximation(col_approximation)\n# Possibly set scalings (only if the scale value is not set)\nif self._load_config[\"scale\"] is not None:\nlog.warning(\"Custom scale specified for primitive object, so ignoring radius, height, and size arguments!\")\nelse:\nif self._load_config[\"radius\"] is not None:\nself.radius = self._load_config[\"radius\"]\nif self._load_config[\"height\"] is not None:\nself.height = self._load_config[\"height\"]\nif self._load_config[\"size\"] is not None:\nself.size = self._load_config[\"size\"]\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Set color and opacity\nif self._prim_type == PrimType.RIGID:\nvisual_geom_prim = list(self.links[\"base_link\"].visual_meshes.values())[0]\nelif self._prim_type == PrimType.CLOTH:\nvisual_geom_prim = self.links[\"base_link\"]\nelse:\nraise ValueError(\"Prim type must either be PrimType.RIGID or PrimType.CLOTH for loading a primitive object\")\nvisual_geom_prim.color = self._load_config[\"color\"]\nvisual_geom_prim.opacity = self._load_config[\"opacity\"]\n@property\ndef radius(self):\n\"\"\"\n        Gets this object's radius, if it exists.\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n        Returns:\n            float: radius for this object\n        \"\"\"\nassert_valid_key(key=self._primitive_type, valid_keys=VALID_RADIUS_OBJECTS, name=\"primitive object with radius\")\nreturn self._extents[0] / 2.0\n@radius.setter\ndef radius(self, radius):\n\"\"\"\n        Sets this object's radius\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n        Args:\n            radius (float): radius to set\n        \"\"\"\nassert_valid_key(key=self._primitive_type, valid_keys=VALID_RADIUS_OBJECTS, name=\"primitive object with radius\")\n# Update the extents variable\noriginal_extent = np.array(self._extents)\nself._extents = np.ones(3) * radius * 2.0 if self._primitive_type == \"Sphere\" else \\\n            np.array([radius * 2.0, radius * 2.0, self._extents[2]])\nattr_pairs = []\nfor geom in self._vis_geom, self._col_geom:\nif geom is not None:\nfor attr in (geom.GetPointsAttr(), geom.GetNormalsAttr()):\nvals = np.array(attr.Get()).astype(np.float64)\nattr_pairs.append([attr, vals])\ngeom.GetExtentAttr().Set(Vt.Vec3fArray([Gf.Vec3f(*(-self._extents / 2.0)), Gf.Vec3f(*(self._extents / 2.0))]))\n# Calculate how much to scale extents by and then modify the points / normals accordingly\nscaling_factor = 2.0 * radius / original_extent[0]\nfor attr, vals in attr_pairs:\n# If this is a sphere, modify all 3 axes\nif self._primitive_type == \"Sphere\":\nvals = vals * scaling_factor\n# Otherwise, just modify the first two dimensions\nelse:\nvals[:, :2] = vals[:, :2] * scaling_factor\n# Set the value\nattr.Set(Vt.Vec3fArray([Gf.Vec3f(*v) for v in vals]))\n@property\ndef height(self):\n\"\"\"\n        Gets this object's height, if it exists.\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\"}\n        Returns:\n            float: height for this object\n        \"\"\"\nassert_valid_key(key=self._primitive_type, valid_keys=VALID_HEIGHT_OBJECTS, name=\"primitive object with height\")\nreturn self._extents[2]\n@height.setter\ndef height(self, height):\n\"\"\"\n        Sets this object's height\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\"}\n        Args:\n            height (float): height to set\n        \"\"\"\nassert_valid_key(key=self._primitive_type, valid_keys=VALID_HEIGHT_OBJECTS, name=\"primitive object with height\")\n# Update the extents variable\noriginal_extent = np.array(self._extents)\nself._extents[2] = height\n# Calculate the correct scaling factor and scale the points and normals appropriately\nscaling_factor = height / original_extent[2]\nfor geom in self._vis_geom, self._col_geom:\nif geom is not None:\nfor attr in (geom.GetPointsAttr(), geom.GetNormalsAttr()):\nvals = np.array(attr.Get()).astype(np.float64)\n# Scale the z axis by the scaling factor\nvals[:, 2] = vals[:, 2] * scaling_factor\nattr.Set(Vt.Vec3fArray([Gf.Vec3f(*v) for v in vals]))\ngeom.GetExtentAttr().Set(Vt.Vec3fArray([Gf.Vec3f(*(-self._extents / 2.0)), Gf.Vec3f(*(self._extents / 2.0))]))\n@property\ndef size(self):\n\"\"\"\n        Gets this object's size, if it exists.\n        Note: Can only be called if the primitive type is one of {\"Cube\", \"Torus\"}\n        Returns:\n            float: size for this object\n        \"\"\"\nassert_valid_key(key=self._primitive_type, valid_keys=VALID_SIZE_OBJECTS, name=\"primitive object with size\")\nreturn self._extents[0]\n@size.setter\ndef size(self, size):\n\"\"\"\n        Sets this object's size\n        Note: Can only be called if the primitive type is one of {\"Cube\", \"Torus\"}\n        Args:\n            size (float): size to set\n        \"\"\"\nassert_valid_key(key=self._primitive_type, valid_keys=VALID_SIZE_OBJECTS, name=\"primitive object with size\")\n# Update the extents variable\noriginal_extent = np.array(self._extents)\nself._extents = np.ones(3) * size\n# Calculate the correct scaling factor and scale the points and normals appropriately\nscaling_factor = size / original_extent[0]\nfor geom in self._vis_geom, self._col_geom:\nif geom is not None:\nfor attr in (geom.GetPointsAttr(), geom.GetNormalsAttr()):\n# Scale all three axes by the scaling factor\nvals = np.array(attr.Get()).astype(np.float64) * scaling_factor\nattr.Set(Vt.Vec3fArray([Gf.Vec3f(*v) for v in vals]))\ngeom.GetExtentAttr().Set(Vt.Vec3fArray([Gf.Vec3f(*(-self._extents / 2.0)), Gf.Vec3f(*(self._extents / 2.0))]))\ndef _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n# Add additional kwargs (fit_avg_dim_volume and bounding_box are already captured in load_config)\nreturn self.__class__(\nprim_path=prim_path,\nprimitive_type=self._primitive_type,\nname=name,\ncategory=self.category,\nclass_id=self.class_id,\nscale=self.scale,\nvisible=self.visible,\nfixed_base=self.fixed_base,\nprim_type=self._prim_type,\nload_config=load_config,\nabilities=self._abilities,\nvisual_only=self._visual_only,\n)\ndef _dump_state(self):\nstate = super()._dump_state()\n# state[\"extents\"] = self._extents\nstate[\"radius\"] = self.radius if self._primitive_type in VALID_RADIUS_OBJECTS else -1\nstate[\"height\"] = self.height if self._primitive_type in VALID_HEIGHT_OBJECTS else -1\nstate[\"size\"] = self.size if self._primitive_type in VALID_SIZE_OBJECTS else -1\nreturn state\ndef _load_state(self, state):\nsuper()._load_state(state=state)\n# self._extents = np.array(state[\"extents\"])\nif self._primitive_type in VALID_RADIUS_OBJECTS:\nself.radius = state[\"radius\"]\nif self._primitive_type in VALID_HEIGHT_OBJECTS:\nself.height = state[\"height\"]\nif self._primitive_type in VALID_SIZE_OBJECTS:\nself.size = state[\"size\"]\ndef _deserialize(self, state):\nstate_dict, idx = super()._deserialize(state=state)\n# state_dict[\"extents\"] = state[idx: idx + 3]\nstate_dict[\"radius\"] = state[idx]\nstate_dict[\"height\"] = state[idx + 1]\nstate_dict[\"size\"] = state[idx + 2]\nreturn state_dict, idx + 3\ndef _serialize(self, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\nreturn np.concatenate([\nstate_flat,\nnp.array([state[\"radius\"], state[\"height\"], state[\"size\"]]),\n]).astype(float)\n</code></pre>"},{"location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.height","title":"<code>height</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this object's height, if it exists.</p> <p>Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\"}</p> <p>Returns:</p> Name Type Description <code>float</code> <p>height for this object</p>"},{"location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.radius","title":"<code>radius</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this object's radius, if it exists.</p> <p>Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}</p> <p>Returns:</p> Name Type Description <code>float</code> <p>radius for this object</p>"},{"location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.size","title":"<code>size</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this object's size, if it exists.</p> <p>Note: Can only be called if the primitive type is one of {\"Cube\", \"Torus\"}</p> <p>Returns:</p> Name Type Description <code>float</code> <p>size for this object</p>"},{"location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.__init__","title":"<code>__init__(name, primitive_type, prim_path=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, rgba=(0.5, 0.5, 0.5, 1.0), radius=None, height=None, size=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>primitive_type</code> <code>str</code> <p>type of primitive object to create. Should be one of:</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> <code>'object'</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> <code>PrimType.RIGID</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.rgba (4-array): (R, G, B, A) values to set for this object</p> <code>None</code> <code>include_default_states</code> <code>bool</code> <p>whether to include the default object states from @get_default_states</p> <code>True</code> <code>radius</code> <code>None or float</code> <p>If specified, sets the radius for this object. This value is scaled by @scale Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}</p> <code>None</code> <code>height</code> <code>None or float</code> <p>If specified, sets the height for this object. This value is scaled by @scale Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\"}</p> <code>None</code> <code>size</code> <code>None or float</code> <p>If specified, sets the size for this object. This value is scaled by @scale Note: Should only be specified if the @primitive_type is one of {\"Cube\", \"Torus\"}</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/objects/primitive_object.py</code> <pre><code>def __init__(\nself,\nname,\nprimitive_type,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\nrgba=(0.5, 0.5, 0.5, 1.0),\nradius=None,\nheight=None,\nsize=None,\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        primitive_type (str): type of primitive object to create. Should be one of:\n            {\"Cone\", \"Cube\", \"Cylinder\", \"Disk\", \"Plane\", \"Sphere\", \"Torus\"}\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.rgba (4-array): (R, G, B, A) values to set for this object\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        radius (None or float): If specified, sets the radius for this object. This value is scaled by @scale\n            Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n        height (None or float): If specified, sets the height for this object. This value is scaled by @scale\n            Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\"}\n        size (None or float): If specified, sets the size for this object. This value is scaled by @scale\n            Note: Should only be specified if the @primitive_type is one of {\"Cube\", \"Torus\"}\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Compose load config and add rgba values\nload_config = dict() if load_config is None else load_config\nload_config[\"color\"] = np.array(rgba[:3])\nload_config[\"opacity\"] = rgba[3]\nload_config[\"radius\"] = radius\nload_config[\"height\"] = height\nload_config[\"size\"] = size\n# Initialize other internal variables\nself._vis_geom = None\nself._col_geom = None\nself._extents = np.ones(3)            # (x,y,z extents)\n# Make sure primitive type is valid\nassert_valid_key(key=primitive_type, valid_keys=PRIMITIVE_MESH_TYPES, name=\"primitive mesh type\")\nself._primitive_type = primitive_type\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/objects/stateful_object.html","title":"stateful_object","text":""},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject","title":"<code>StatefulObject</code>","text":"<p>         Bases: <code>BaseObject</code></p> <p>Objects that support object states.</p> Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>class StatefulObject(BaseObject):\n\"\"\"Objects that support object states.\"\"\"\ndef __init__(\nself,\nname,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Values that will be filled later\nself._states = None\nself._emitters = dict()\nself._visual_states = None\nself._current_texture_state = None\n# Load abilities from taxonomy if needed &amp; possible\nif abilities is None:\nabilities = {}\nif OBJECT_TAXONOMY is not None:\n# TODO! Update!!\ntaxonomy_class = OBJECT_TAXONOMY.get_class_name_from_igibson_category(category)\nif taxonomy_class is not None:\nabilities = OBJECT_TAXONOMY.get_abilities(taxonomy_class)\nassert isinstance(abilities, dict), \"Object abilities must be in dictionary form.\"\nself._abilities = abilities\nself.prepare_object_states(abilities=abilities, include_default_states=include_default_states)\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\nload_config=load_config,\n**kwargs,\n)\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Initialize all states\nfor state in self._states.values():\nstate.initialize()\n# Check whether this object requires any visual updates\nstates_set = set(self.states)\nself._visual_states = states_set &amp; get_visual_states()\n# If we require visual updates, possibly create additional APIs\nif len(self._visual_states) &gt; 0:\nif len(states_set &amp; get_steam_states()) &gt; 0:\nself._create_emitter_apis(EmitterType.STEAM)\nif len(states_set &amp; get_fire_states()) &gt; 0:\nself._create_emitter_apis(EmitterType.FIRE)\ndef add_state(self, state):\n\"\"\"\n        Adds state @state with name @name to self.states.\n        Args:\n            state (ObjectStateBase): Object state instance to add to this object\n        \"\"\"\nassert self._states is not None, \"Cannot add state since states have not been initialized yet!\"\nassert state.__class__ not in self._states, f\"State {state.__class__.__name__} \" \\\n                                                    f\"has already been added to this object!\"\nself._states[state.__class__] = state\n@property\ndef states(self):\n\"\"\"\n        Get the current states of this object.\n        Returns:\n            dict: Keyword-mapped states for this object\n        \"\"\"\nreturn self._states\n@property\ndef abilities(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping ability name to ability arguments for this object\n        \"\"\"\nreturn self._abilities\ndef prepare_object_states(self, abilities=None, include_default_states=True):\n\"\"\"\n        Prepare the state dictionary for an object by generating the appropriate\n        object state instances.\n        This uses the abilities of the object and the state dependency graph to\n        find &amp; instantiate all relevant states.\n        Args:\n            abilities (None or dict): If specified, dict in the form of {ability: {param: value}} containing\n                object abilities and parameters.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n        \"\"\"\nif abilities is None:\nabilities = {}\nstate_types_and_params = [(state, {}) for state in get_default_states()] if include_default_states else []\n# Map the ability params to the states immediately imported by the abilities\nfor ability, params in abilities.items():\nstate_types_and_params.extend((state_name, params) for state_name in get_states_for_ability(ability))\n# Add the dependencies into the list, too.\nfor state_type, _ in state_types_and_params:\n# Add each state's dependencies, too. Note that only required dependencies are added.\nfor dependency in state_type.get_dependencies():\nif all(other_state != dependency for other_state, _ in state_types_and_params):\nstate_types_and_params.append((dependency, {}))\n# Now generate the states in topological order.\nself._states = dict()\nfor state_type, params in reversed(state_types_and_params):\nself._states[state_type] = get_object_state_instance(state_type, self, params)\ndef _create_emitter_apis(self, emitter_type):\n\"\"\"\n        Create necessary prims and apis for steam effects.\n        Args:\n            emitter_type (EmitterType): Emitter to create\n        \"\"\"\n# Make sure that flow setting is enabled.\nrenderer_setting = RendererSettings()\nrenderer_setting.common_settings.flow_settings.enable()\n# Specify emitter config.\nemitter_config = {}\nbbox_extent_local = self.native_bbox if hasattr(self, \"native_bbox\") else self.aabb_extent / self.scale\nif emitter_type == EmitterType.FIRE:\nfire_at_metalink = True\nif OnFire in self.states:\n# Note whether the heat source link is explicitly set\nlink = self.states[OnFire].link\nfire_at_metalink = link != self.root_link\nelif HeatSourceOrSink in self.states:\n# Only apply fire to non-root-link (i.e.: explicitly specified) heat source links\n# Otherwise, immediately return\nlink = self.states[HeatSourceOrSink].link\nif link == self.root_link:\nreturn\nelse:\nraise ValueError(\"Unknown fire state\")\nemitter_config[\"name\"] = \"flowEmitterSphere\"\nemitter_config[\"type\"] = \"FlowEmitterSphere\"\nemitter_config[\"position\"] = (0.0, 0.0, 0.0) if fire_at_metalink \\\n                else (0.0, 0.0, bbox_extent_local[2] * m.FIRE_EMITTER_HEIGHT_RATIO)\nemitter_config[\"fuel\"] = 0.6\nemitter_config[\"coupleRateFuel\"] = 1.2\nemitter_config[\"buoyancyPerTemp\"] = 0.04\nemitter_config[\"burnPerTemp\"] = 4\nemitter_config[\"gravity\"] = (0, 0, -60.0)\nemitter_config[\"constantMask\"] = 5.0\nemitter_config[\"attenuation\"] = 0.5\nelif emitter_type == EmitterType.STEAM:\nlink = self.root_link\nemitter_config[\"name\"] = \"flowEmitterBox\"\nemitter_config[\"type\"] = \"FlowEmitterBox\"\nemitter_config[\"position\"] = (0.0, 0.0, bbox_extent_local[2] * m.STEAM_EMITTER_HEIGHT_RATIO)\nemitter_config[\"fuel\"] = 1.0\nemitter_config[\"coupleRateFuel\"] = 0.5\nemitter_config[\"buoyancyPerTemp\"] = 0.05\nemitter_config[\"burnPerTemp\"] = 0.5\nemitter_config[\"gravity\"] = (0, 0, -50.0)\nemitter_config[\"constantMask\"] = 10.0\nemitter_config[\"attenuation\"] = 1.5\nelse:\nraise ValueError(\"Currently, only EmitterTypes FIRE and STEAM are supported!\")\n# Define prim paths.\n# The flow system is created under the root link so that it automatically updates its pose as the object moves\nflowEmitter_prim_path = f\"{link.prim_path}/{emitter_config['name']}\"\nflowSimulate_prim_path = f\"{link.prim_path}/flowSimulate\"\nflowOffscreen_prim_path = f\"{link.prim_path}/flowOffscreen\"\nflowRender_prim_path = f\"{link.prim_path}/flowRender\"\n# Define prims.\nstage = og.sim.stage\nemitter = stage.DefinePrim(flowEmitter_prim_path, emitter_config[\"type\"])\nsimulate = stage.DefinePrim(flowSimulate_prim_path, \"FlowSimulate\")\noffscreen = stage.DefinePrim(flowOffscreen_prim_path, \"FlowOffscreen\")\nrenderer = stage.DefinePrim(flowRender_prim_path, \"FlowRender\")\nadvection = stage.DefinePrim(flowSimulate_prim_path + \"/advection\", \"FlowAdvectionCombustionParams\")\nsmoke = stage.DefinePrim(flowSimulate_prim_path + \"/advection/smoke\", \"FlowAdvectionCombustionParams\")\nvorticity = stage.DefinePrim(flowSimulate_prim_path + \"/vorticity\", \"FlowVorticityParams\")\nrayMarch = stage.DefinePrim(flowRender_prim_path + \"/rayMarch\", \"FlowRayMarchParams\")\ncolormap = stage.DefinePrim(flowOffscreen_prim_path + \"/colormap\", \"FlowRayMarchColormapParams\")\nself._emitters[emitter_type] = emitter\n# Update emitter general settings.\nemitter.CreateAttribute(\"enabled\", VT.Bool, False).Set(False)\nemitter.CreateAttribute(\"position\", VT.Float3, False).Set(emitter_config[\"position\"])\nemitter.CreateAttribute(\"fuel\", VT.Float, False).Set(emitter_config[\"fuel\"])\nemitter.CreateAttribute(\"coupleRateFuel\", VT.Float, False).Set(emitter_config[\"coupleRateFuel\"])\nemitter.CreateAttribute(\"coupleRateVelocity\", VT.Float, False).Set(2.0)\nemitter.CreateAttribute(\"velocity\", VT.Float3, False).Set((0, 0, 0))\nadvection.CreateAttribute(\"buoyancyPerTemp\", VT.Float, False).Set(emitter_config[\"buoyancyPerTemp\"])\nadvection.CreateAttribute(\"burnPerTemp\", VT.Float, False).Set(emitter_config[\"burnPerTemp\"])\nadvection.CreateAttribute(\"gravity\", VT.Float3, False).Set(emitter_config[\"gravity\"])\nvorticity.CreateAttribute(\"constantMask\", VT.Float, False).Set(emitter_config[\"constantMask\"])\nrayMarch.CreateAttribute(\"attenuation\", VT.Float, False).Set(emitter_config[\"attenuation\"])\n# Update emitter unique settings.\nif emitter_type == EmitterType.FIRE:\n# Radius is in the absolute world coordinate even though the fire is under the link frame.\n# In other words, scaling the object doesn't change the fire radius.\nif fire_at_metalink:\n# TODO: get radius of heat_source_link from metadata.\nradius = 0.05\nelse:\nbbox_extent_world = self.native_bbox * self.scale if hasattr(self, \"native_bbox\") else self.aabb_extent\n# Radius is the average x-y half-extent of the object\nradius = float(np.mean(bbox_extent_world[:2]) / 2.0)\nemitter.CreateAttribute(\"radius\", VT.Float, False).Set(radius)\nsimulate.CreateAttribute(\"densityCellSize\", VT.Float, False).Set(radius*0.2)\nsmoke.CreateAttribute(\"fade\", Sdf.ValueTypeNames.Float, False).Set(2.0)\n# Set fire colormap.\nrgbaPoints = []\nrgbaPoints.append(Gf.Vec4f(0.0154, 0.0177, 0.0154, 0.004902))\nrgbaPoints.append(Gf.Vec4f(0.03575, 0.03575, 0.03575, 0.504902))\nrgbaPoints.append(Gf.Vec4f(0.03575, 0.03575, 0.03575, 0.504902))\nrgbaPoints.append(Gf.Vec4f(1, 0.1594, 0.0134, 0.8))\nrgbaPoints.append(Gf.Vec4f(13.53, 2.99, 0.12599, 0.8))\nrgbaPoints.append(Gf.Vec4f(78, 39, 6.1, 0.7))\ncolormap.CreateAttribute(\"rgbaPoints\", Sdf.ValueTypeNames.Float4Array, False).Set(rgbaPoints)\nelif emitter_type == EmitterType.STEAM:\nemitter.CreateAttribute(\"halfSize\", VT.Float3, False).Set(\ntuple(bbox_extent_local * np.array(m.STEAM_EMITTER_SIZE_RATIO) / 2.0))\nsimulate.CreateAttribute(\"densityCellSize\", VT.Float, False).Set(bbox_extent_local[2] * m.STEAM_EMITTER_DENSITY_CELL_RATIO)\ndef set_emitter_enabled(self, emitter_type, value):\n\"\"\"\n        Enable/disable the emitter prim for fire/steam effect.\n        Args:\n            emitter_type (EmitterType): Emitter to set\n            value (bool): Value to set\n        \"\"\"\nif emitter_type not in self._emitters:\nreturn\nif value != self._emitters[emitter_type].GetAttribute(\"enabled\").Get():\nself._emitters[emitter_type].GetAttribute(\"enabled\").Set(value)\ndef get_textures(self):\n\"\"\"\n        Gets prim's texture files.\n        Returns:\n            list of str: List of texture file paths\n        \"\"\"\nreturn [material.diffuse_texture for material in self.materials if material.diffuse_texture is not None]\ndef update_visuals(self):\n\"\"\"\n        Update the prim's visuals (texture change, steam/fire effects, etc).\n        Should be called after all the states are updated.\n        \"\"\"\nif len(self._visual_states) &gt; 0:\ntexture_change_states = []\nemitter_enabled = defaultdict(bool)\nfor state_type in self._visual_states:\nstate = self.states[state_type]\nif state_type in get_texture_change_states():\nif state_type == Saturated:\nfor particle_system in ParticleRemover.supported_active_systems:\nif state.get_value(particle_system):\ntexture_change_states.append(state)\n# Only need to do this once, since soaked handles all fluid systems\nbreak\nelif state.get_value():\ntexture_change_states.append(state)\nif state_type in get_steam_states():\nemitter_enabled[EmitterType.STEAM] |= state.get_value()\nif state_type in get_fire_states():\nemitter_enabled[EmitterType.FIRE] |= state.get_value()\nfor emitter_type in emitter_enabled:\nself.set_emitter_enabled(emitter_type, emitter_enabled[emitter_type])\ntexture_change_states.sort(key=lambda s: get_texture_change_priority()[s.__class__])\nobject_state = texture_change_states[-1] if len(texture_change_states) &gt; 0 else None\n# Only update our texture change if it's a different object state than the one we already have\nif object_state != self._current_texture_state:\nself._update_texture_change(object_state)\nself._current_texture_state = object_state\ndef _update_texture_change(self, object_state):\n\"\"\"\n        Update the texture based on the given object_state. E.g. if object_state is Frozen, update the diffuse color\n        to match the frozen state. If object_state is None, update the diffuse color to the default value. It modifies\n        the current albedo map by adding and scaling the values. See @self._update_albedo_value for details.\n        Args:\n            object_state (BooleanState or None): the object state that the diffuse color should match to\n        \"\"\"\nfor material in self.materials:\nself._update_albedo_value(object_state, material)\n@staticmethod\ndef _update_albedo_value(object_state, material):\n\"\"\"\n        Update the albedo value based on the given object_state. The final albedo value is\n        albedo_value = diffuse_tint * (albedo_value + albedo_add)\n        Args:\n            object_state (BooleanState or None): the object state that the diffuse color should match to\n            material (MaterialPrim): the material to use to update the albedo value\n        \"\"\"\nif object_state is None:\n# This restore the albedo map to its original value\nalbedo_add = 0.0\ndiffuse_tint = (1.0, 1.0, 1.0)\nelse:\n# Query the object state for the parameters\nalbedo_add, diffuse_tint = object_state.get_texture_change_params()\nif material.albedo_add != albedo_add:\nmaterial.albedo_add = albedo_add\nif not np.allclose(material.diffuse_tint, diffuse_tint):\nmaterial.diffuse_tint = diffuse_tint\ndef remove(self):\n\"\"\"\n        Removes this prim from omniverse stage\n        \"\"\"\n# Iterate over all states and run their remove call\nfor state_instance in self._states.values():\nstate_instance.remove()\n# Run super\nsuper().remove()\ndef _dump_state(self):\n# Grab state from super class\nstate = super()._dump_state()\n# Also add non-kinematic states\nnon_kin_states = dict()\nfor state_type, state_instance in self._states.items():\nif state_instance.stateful:\nnon_kin_states[get_state_name(state_type)] = state_instance.dump_state(serialized=False)\nstate[\"non_kin\"] = non_kin_states\nreturn state\ndef _load_state(self, state):\n# Call super method first\nsuper()._load_state(state=state)\n# Load all states that are stateful\nfor state_type, state_instance in self._states.items():\nstate_name = get_state_name(state_type)\nif state_instance.stateful:\nif state_name in state[\"non_kin\"]:\nstate_instance.load_state(state=state[\"non_kin\"][state_name], serialized=False)\nelse:\nlog.warning(\"Missing object state [{}] in the state dump\".format(state_name))\n# Clear cache after loading state\nself.clear_states_cache()\ndef _serialize(self, state):\n# Call super method first\nstate_flat = super()._serialize(state=state)\n# Iterate over all states and serialize them individually\nnon_kin_state_flat = np.concatenate([\nself._states[REGISTERED_OBJECT_STATES[state_name]].serialize(state_dict)\nfor state_name, state_dict in state[\"non_kin\"].items()\n]) if len(state[\"non_kin\"]) &gt; 0 else np.array([])\n# Combine these two arrays\nreturn np.concatenate([state_flat, non_kin_state_flat]).astype(float)\ndef _deserialize(self, state):\n# Call super method first\nstate_dic, idx = super()._deserialize(state=state)\n# Iterate over all states and deserialize their states if they're stateful\nnon_kin_state_dic = dict()\nfor state_type, state_instance in self._states.items():\nstate_name = get_state_name(state_type)\nif state_instance.stateful:\nnon_kin_state_dic[state_name] = state_instance.deserialize(state[idx:idx+state_instance.state_size])\nidx += state_instance.state_size\nstate_dic[\"non_kin\"] = non_kin_state_dic\nreturn state_dic, idx\ndef clear_states_cache(self):\n\"\"\"\n        Clears the internal cache from all owned states\n        \"\"\"\n# Check self._states just in case states have not been initialized yet.\nif not self._states:\nreturn\nfor _, obj_state in self._states.items():\nobj_state.clear_cache()\nBoundingBoxAPI.clear()\ndef set_position_orientation(self, position=None, orientation=None):\nsuper().set_position_orientation(position=position, orientation=orientation)\nself.clear_states_cache()\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"StatefulObject\")\nreturn classes\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.abilities","title":"<code>abilities</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping ability name to ability arguments for this object</p>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.states","title":"<code>states</code>  <code>property</code>","text":"<p>Get the current states of this object.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped states for this object</p>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.__init__","title":"<code>__init__(name, prim_path=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> <code>'object'</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> <code>PrimType.RIGID</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>include_default_states</code> <code>bool</code> <p>whether to include the default object states from @get_default_states</p> <code>True</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def __init__(\nself,\nname,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Values that will be filled later\nself._states = None\nself._emitters = dict()\nself._visual_states = None\nself._current_texture_state = None\n# Load abilities from taxonomy if needed &amp; possible\nif abilities is None:\nabilities = {}\nif OBJECT_TAXONOMY is not None:\n# TODO! Update!!\ntaxonomy_class = OBJECT_TAXONOMY.get_class_name_from_igibson_category(category)\nif taxonomy_class is not None:\nabilities = OBJECT_TAXONOMY.get_abilities(taxonomy_class)\nassert isinstance(abilities, dict), \"Object abilities must be in dictionary form.\"\nself._abilities = abilities\nself.prepare_object_states(abilities=abilities, include_default_states=include_default_states)\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\nload_config=load_config,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.add_state","title":"<code>add_state(state)</code>","text":"<p>Adds state @state with name @name to self.states.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ObjectStateBase</code> <p>Object state instance to add to this object</p> required Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def add_state(self, state):\n\"\"\"\n    Adds state @state with name @name to self.states.\n    Args:\n        state (ObjectStateBase): Object state instance to add to this object\n    \"\"\"\nassert self._states is not None, \"Cannot add state since states have not been initialized yet!\"\nassert state.__class__ not in self._states, f\"State {state.__class__.__name__} \" \\\n                                                f\"has already been added to this object!\"\nself._states[state.__class__] = state\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.clear_states_cache","title":"<code>clear_states_cache()</code>","text":"<p>Clears the internal cache from all owned states</p> Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def clear_states_cache(self):\n\"\"\"\n    Clears the internal cache from all owned states\n    \"\"\"\n# Check self._states just in case states have not been initialized yet.\nif not self._states:\nreturn\nfor _, obj_state in self._states.items():\nobj_state.clear_cache()\nBoundingBoxAPI.clear()\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.get_textures","title":"<code>get_textures()</code>","text":"<p>Gets prim's texture files.</p> <p>Returns:</p> Type Description <p>list of str: List of texture file paths</p> Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def get_textures(self):\n\"\"\"\n    Gets prim's texture files.\n    Returns:\n        list of str: List of texture file paths\n    \"\"\"\nreturn [material.diffuse_texture for material in self.materials if material.diffuse_texture is not None]\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.prepare_object_states","title":"<code>prepare_object_states(abilities=None, include_default_states=True)</code>","text":"<p>Prepare the state dictionary for an object by generating the appropriate object state instances.</p> <p>This uses the abilities of the object and the state dependency graph to find &amp; instantiate all relevant states.</p> <p>Parameters:</p> Name Type Description Default <code>abilities</code> <code>None or dict</code> <p>If specified, dict in the form of {ability: {param: value}} containing object abilities and parameters.</p> <code>None</code> <code>include_default_states</code> <code>bool</code> <p>whether to include the default object states from @get_default_states</p> <code>True</code> Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def prepare_object_states(self, abilities=None, include_default_states=True):\n\"\"\"\n    Prepare the state dictionary for an object by generating the appropriate\n    object state instances.\n    This uses the abilities of the object and the state dependency graph to\n    find &amp; instantiate all relevant states.\n    Args:\n        abilities (None or dict): If specified, dict in the form of {ability: {param: value}} containing\n            object abilities and parameters.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n    \"\"\"\nif abilities is None:\nabilities = {}\nstate_types_and_params = [(state, {}) for state in get_default_states()] if include_default_states else []\n# Map the ability params to the states immediately imported by the abilities\nfor ability, params in abilities.items():\nstate_types_and_params.extend((state_name, params) for state_name in get_states_for_ability(ability))\n# Add the dependencies into the list, too.\nfor state_type, _ in state_types_and_params:\n# Add each state's dependencies, too. Note that only required dependencies are added.\nfor dependency in state_type.get_dependencies():\nif all(other_state != dependency for other_state, _ in state_types_and_params):\nstate_types_and_params.append((dependency, {}))\n# Now generate the states in topological order.\nself._states = dict()\nfor state_type, params in reversed(state_types_and_params):\nself._states[state_type] = get_object_state_instance(state_type, self, params)\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.remove","title":"<code>remove()</code>","text":"<p>Removes this prim from omniverse stage</p> Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def remove(self):\n\"\"\"\n    Removes this prim from omniverse stage\n    \"\"\"\n# Iterate over all states and run their remove call\nfor state_instance in self._states.values():\nstate_instance.remove()\n# Run super\nsuper().remove()\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.set_emitter_enabled","title":"<code>set_emitter_enabled(emitter_type, value)</code>","text":"<p>Enable/disable the emitter prim for fire/steam effect.</p> <p>Parameters:</p> Name Type Description Default <code>emitter_type</code> <code>EmitterType</code> <p>Emitter to set</p> required <code>value</code> <code>bool</code> <p>Value to set</p> required Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def set_emitter_enabled(self, emitter_type, value):\n\"\"\"\n    Enable/disable the emitter prim for fire/steam effect.\n    Args:\n        emitter_type (EmitterType): Emitter to set\n        value (bool): Value to set\n    \"\"\"\nif emitter_type not in self._emitters:\nreturn\nif value != self._emitters[emitter_type].GetAttribute(\"enabled\").Get():\nself._emitters[emitter_type].GetAttribute(\"enabled\").Set(value)\n</code></pre>"},{"location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.update_visuals","title":"<code>update_visuals()</code>","text":"<p>Update the prim's visuals (texture change, steam/fire effects, etc). Should be called after all the states are updated.</p> Source code in <code>omnigibson/objects/stateful_object.py</code> <pre><code>def update_visuals(self):\n\"\"\"\n    Update the prim's visuals (texture change, steam/fire effects, etc).\n    Should be called after all the states are updated.\n    \"\"\"\nif len(self._visual_states) &gt; 0:\ntexture_change_states = []\nemitter_enabled = defaultdict(bool)\nfor state_type in self._visual_states:\nstate = self.states[state_type]\nif state_type in get_texture_change_states():\nif state_type == Saturated:\nfor particle_system in ParticleRemover.supported_active_systems:\nif state.get_value(particle_system):\ntexture_change_states.append(state)\n# Only need to do this once, since soaked handles all fluid systems\nbreak\nelif state.get_value():\ntexture_change_states.append(state)\nif state_type in get_steam_states():\nemitter_enabled[EmitterType.STEAM] |= state.get_value()\nif state_type in get_fire_states():\nemitter_enabled[EmitterType.FIRE] |= state.get_value()\nfor emitter_type in emitter_enabled:\nself.set_emitter_enabled(emitter_type, emitter_enabled[emitter_type])\ntexture_change_states.sort(key=lambda s: get_texture_change_priority()[s.__class__])\nobject_state = texture_change_states[-1] if len(texture_change_states) &gt; 0 else None\n# Only update our texture change if it's a different object state than the one we already have\nif object_state != self._current_texture_state:\nself._update_texture_change(object_state)\nself._current_texture_state = object_state\n</code></pre>"},{"location":"reference/objects/usd_object.html","title":"usd_object","text":""},{"location":"reference/objects/usd_object.html#objects.usd_object.USDObject","title":"<code>USDObject</code>","text":"<p>         Bases: <code>StatefulObject</code></p> <p>USDObjects are instantiated from a USD file. They can be composed of one or more links and joints. They may or may not be passive.</p> Source code in <code>omnigibson/objects/usd_object.py</code> <pre><code>class USDObject(StatefulObject):\n\"\"\"\n    USDObjects are instantiated from a USD file. They can be composed of one\n    or more links and joints. They may or may not be passive.\n    \"\"\"\ndef __init__(\nself,\nname,\nusd_path,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            usd_path (str): global path to the USD file to load\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n                Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n                that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n        \"\"\"\nself._usd_path = usd_path\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\ndef _load(self):\n\"\"\"\n        Load the object into pybullet and set it to the correct pose\n        \"\"\"\nreturn add_asset_to_stage(asset_path=self._usd_path, prim_path=self._prim_path)\ndef _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n# Add additional kwargs\nreturn self.__class__(\nprim_path=prim_path,\nusd_path=self._usd_path,\nname=name,\ncategory=self.category,\nclass_id=self.class_id,\nscale=self.scale,\nvisible=self.visible,\nfixed_base=self.fixed_base,\nvisual_only=self._visual_only,\nprim_type=self._prim_type,\nload_config=load_config,\nabilities=self._abilities,\n)\n@property\ndef usd_path(self):\n\"\"\"\n        Returns:\n            str: absolute path to this model's USD file. By default, this is the loaded usd path\n                passed in as an argument\n        \"\"\"\nreturn self._usd_path\n</code></pre>"},{"location":"reference/objects/usd_object.html#objects.usd_object.USDObject.usd_path","title":"<code>usd_path</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>absolute path to this model's USD file. By default, this is the loaded usd path passed in as an argument</p>"},{"location":"reference/objects/usd_object.html#objects.usd_object.USDObject.__init__","title":"<code>__init__(name, usd_path, prim_path=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>usd_path</code> <code>str</code> <p>global path to the USD file to load</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> <code>'object'</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> <code>PrimType.RIGID</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>include_default_states</code> <code>bool</code> <p>whether to include the default object states from @get_default_states</p> <code>True</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject). Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).</p> <code>{}</code> Source code in <code>omnigibson/objects/usd_object.py</code> <pre><code>def __init__(\nself,\nname,\nusd_path,\nprim_path=None,\ncategory=\"object\",\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nprim_type=PrimType.RIGID,\nload_config=None,\nabilities=None,\ninclude_default_states=True,\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        usd_path (str): global path to the USD file to load\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n            Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n            that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n    \"\"\"\nself._usd_path = usd_path\nsuper().__init__(\nprim_path=prim_path,\nname=name,\ncategory=category,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=prim_type,\ninclude_default_states=include_default_states,\nload_config=load_config,\nabilities=abilities,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/prims/index.html","title":"prims","text":""},{"location":"reference/prims/cloth_prim.html","title":"cloth_prim","text":""},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim","title":"<code>ClothPrim</code>","text":"<p>         Bases: <code>GeomPrim</code></p> <p>Provides high level functions to deal with a cloth prim and its attributes/ properties. If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created.</p> if the prim does not already have a cloth api applied to it before it is loaded, <p>it will apply it.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be specified:</p> <p>scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds     to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling. mass (None or float): If specified, mass of this body in kg</p> <code>None</code> Source code in <code>omnigibson/prims/cloth_prim.py</code> <pre><code>class ClothPrim(GeomPrim):\n\"\"\"\n    Provides high level functions to deal with a cloth prim and its attributes/ properties.\n    If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created.\n    Notes: if the prim does not already have a cloth api applied to it before it is loaded,\n        it will apply it.\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be\n            specified:\n            scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds\n                to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.\n            mass (None or float): If specified, mass of this body in kg\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\n# Internal vars stored\nself._keypoint_idx = None\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Make sure flatcache is not being used -- if so, raise an error, since we lose most of our needed functionality\n# (such as R/W to specific particle states) when flatcache is enabled\nassert not gm.ENABLE_FLATCACHE, \"Cannot use flatcache with ClothPrim!\"\nself._mass_api = UsdPhysics.MassAPI(self._prim) if self._prim.HasAPI(UsdPhysics.MassAPI) else \\\n            UsdPhysics.MassAPI.Apply(self._prim)\n# Possibly set the mass / density\nif \"mass\" in self._load_config and self._load_config[\"mass\"] is not None:\nself.mass = self._load_config[\"mass\"]\nparticleUtils.add_physx_particle_cloth(\nstage=og.sim.stage,\npath=self.prim_path,\ndynamic_mesh_path=None,\nparticle_system_path=ClothPrim.cloth_system.system_prim_path,\nspring_stretch_stiffness=m.CLOTH_STRETCH_STIFFNESS,\nspring_bend_stiffness=m.CLOTH_BEND_STIFFNESS,\nspring_shear_stiffness=m.CLOTH_SHEAR_STIFFNESS,\nspring_damping=m.CLOTH_DAMPING,\nself_collision=True,\nself_collision_filter=True,\n)\npositions = self.particle_positions\nself._n_particles = len(positions)\n# Deterministically sample keypoints and sanity check the AABB of these subsampled points vs. the actual points\nnp.random.seed(0)\nself._keypoint_idx = np.random.randint(0, self._n_particles, m.N_CLOTH_KEYPOINTS) if \\\n            self._n_particles &gt; m.N_CLOTH_KEYPOINTS else np.arange(self._n_particles)\nkeypoint_positions = positions[self._keypoint_idx]\nkeypoint_aabb = keypoint_positions.min(axis=0), keypoint_positions.max(axis=0)\ntrue_aabb = positions.min(axis=0), positions.max(axis=0)\noverlap_vol = max(min(true_aabb[1][0], keypoint_aabb[1][0]) - max(true_aabb[0][0], keypoint_aabb[0][0]), 0) * \\\n            max(min(true_aabb[1][1], keypoint_aabb[1][1]) - max(true_aabb[0][1], keypoint_aabb[0][1]), 0) * \\\n            max(min(true_aabb[1][2], keypoint_aabb[1][2]) - max(true_aabb[0][2], keypoint_aabb[0][2]), 0)\ntrue_vol = np.product(true_aabb[1] - true_aabb[0])\nassert overlap_vol / true_vol &gt; m.KEYPOINT_COVERAGE_THRESHOLD, \\\n            f\"Did not adequately subsample keypoints for cloth {self.name}!\"\ndef _initialize(self):\nsuper()._initialize()\n# TODO (eric): hacky way to get cloth rendering to work (otherwise, there exist some rendering artifacts).\nself._prim.CreateAttribute(\"primvars:isVolume\", VT.Bool, False).Set(True)\nself._prim.GetAttribute(\"primvars:isVolume\").Set(False)\n# Store the default position of the points in the local frame\nself._default_positions = np.array(self.get_attribute(attr=\"points\"))\n@classproperty\ndef cloth_system(cls):\nreturn get_system(\"cloth\")\n@property\ndef n_particles(self):\n\"\"\"\n        Returns:\n            int: Number of particles owned by this cloth prim\n        \"\"\"\nreturn self._n_particles\n@property\ndef kinematic_only(self):\n\"\"\"\n        Returns:\n            bool: Whether this object is a kinematic-only object. For ClothPrim, always return False.\n        \"\"\"\nreturn False\ndef _compute_particle_positions(self, keypoints_only=False):\n\"\"\"\n        Compute individual particle positions for this cloth prim\n        Args:\n            keypoints_only (bool): If True, will only return the keypoint particle state\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z)\n                cartesian coordinates relative to the world frame\n        \"\"\"\nr = T.quat2mat(self.get_orientation())\nt = self.get_position()\ns = self.scale\np_local = np.array(self.get_attribute(attr=\"points\"))\np_local = p_local[self._keypoint_idx] if keypoints_only else p_local\np_world = (r @ (p_local * s).T).T + t\nreturn p_world\n@property\ndef keypoint_particle_positions(self):\n\"\"\"\n        Grabs individual keypoint particle positions for this cloth prim.\n        Total number of keypoints is m.N_CLOTH_KEYPOINTS\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N keypoint particles' positions are expressed in (x,y,z)\n                cartesian coordinates relative to the world frame\n        \"\"\"\nreturn self._compute_particle_positions(keypoints_only=True)\n@property\ndef particle_positions(self):\n\"\"\"\n        Grabs individual particle positions for this cloth prim\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z)\n                cartesian coordinates relative to the world frame\n        \"\"\"\nreturn self._compute_particle_positions(keypoints_only=False)\n@particle_positions.setter\ndef particle_positions(self, pos):\n\"\"\"\n        Set the particle positions of this cloth\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired positions are expressed in (x,y,z)\n                cartesian coordinates relative to the world frame\n        \"\"\"\nassert pos.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {pos.shape[0]}, vs. number of particles {self._n_particles}!\"\nr = T.quat2mat(self.get_orientation())\nt = self.get_position()\ns = self.scale\np_local = (r.T @ (pos - t).T).T / s\nself.set_attribute(attr=\"points\", val=Vt.Vec3fArray.FromNumpy(p_local))\n@property\ndef particle_velocities(self):\n\"\"\"\n        Grabs individual particle velocities for this cloth prim\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' velocities are expressed in (x,y,z)\n                cartesian coordinates with respect to the world frame.\n        \"\"\"\n# the velocities attribute is w.r.t the world frame already\nreturn np.array(self.get_attribute(attr=\"velocities\"))\n@particle_velocities.setter\ndef particle_velocities(self, vel):\n\"\"\"\n        Set the particle velocities of this cloth\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' velocities are expressed in (x,y,z)\n                cartesian coordinates with respect to the world frame\n        \"\"\"\nassert vel.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {vel.shape[0]}, vs. number of particles {self._n_particles}!\"\n# the velocities attribute is w.r.t the world frame already\nself.set_attribute(attr=\"velocities\", val=Vt.Vec3fArray.FromNumpy(vel))\ndef contact_list(self, keypoints_only=True):\n\"\"\"\n        Get list of all current contacts with this cloth body\n        Args:\n            keypoints_only (bool): If True, will only check contact with this cloth's keypoints\n        Returns:\n            list of CsRawData: raw contact info for this cloth body\n        \"\"\"\ncontacts = []\ndef report_hit(hit):\ncontacts.append(CsRawData(\ntime=0.0,  # dummy value\ndt=0.0,  # dummy value\nbody0=self.prim_path,\nbody1=hit.rigid_body,\nposition=pos,\nnormal=np.zeros(3),  # dummy value\nimpulse=np.zeros(3),  # dummy value\n))\nreturn True\npositions = self.keypoint_particle_positions if keypoints_only else self.particle_positions\nfor pos in positions:\nog.sim.psqi.overlap_sphere(ClothPrim.cloth_system.particle_contact_offset, pos, report_hit, False)\nreturn contacts\ndef update_handles(self):\n# no handles to update\npass\n@property\ndef volume(self):\nmesh = self.prim\nmesh_type = mesh.GetPrimTypeInfo().GetTypeName()\nassert mesh_type in GEOM_TYPES, f\"Invalid collision mesh type: {mesh_type}\"\nif mesh_type == \"Mesh\":\n# We construct a trimesh object from this mesh in order to infer its volume\ntrimesh_mesh = mesh_prim_to_trimesh_mesh(mesh)\nmesh_volume = trimesh_mesh.volume if trimesh_mesh.is_volume else trimesh_mesh.convex_hull.volume\nelif mesh_type == \"Sphere\":\nmesh_volume = 4 / 3 * np.pi * (mesh.GetAttribute(\"radius\").Get() ** 3)\nelif mesh_type == \"Cube\":\nmesh_volume = mesh.GetAttribute(\"size\").Get() ** 3\nelif mesh_type == \"Cone\":\nmesh_volume = np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get() / 3\nelif mesh_type == \"Cylinder\":\nmesh_volume = np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get()\nelse:\nraise ValueError(f\"Cannot compute volume for mesh of type: {mesh_type}\")\nmesh_volume *= np.product(self.get_world_scale())\nreturn mesh_volume\n@volume.setter\ndef volume(self, volume):\nraise NotImplementedError(\"Cannot set volume directly for a link!\")\n@property\ndef mass(self):\n\"\"\"\n        Returns:\n            float: mass of the rigid body in kg.\n        \"\"\"\n# We have to read the mass directly in the cloth prim\nreturn self._mass_api.GetMassAttr().Get()\n@mass.setter\ndef mass(self, mass):\n\"\"\"\n        Args:\n            mass (float): mass of the rigid body in kg.\n        \"\"\"\n# We have to set the mass directly in the cloth prim\nself._mass_api.GetMassAttr().Set(mass)\n@property\ndef density(self):\nraise NotImplementedError(\"Cannot get density for ClothPrim\")\n@density.setter\ndef density(self, density):\nraise NotImplementedError(\"Cannot set density for ClothPrim\")\n@property\ndef body_name(self):\n\"\"\"\n        Returns:\n            str: Name of this body\n        \"\"\"\nreturn self.prim_path.split(\"/\")[-1]\ndef get_linear_velocity(self):\n\"\"\"\n        Returns:\n            np.ndarray: current average linear velocity of the particles of the cloth prim. Shape (3,).\n        \"\"\"\nreturn np.array(self._prim.GetAttribute(\"velocities\").Get()).mean(axis=0)\ndef get_angular_velocity(self):\n\"\"\"\n        Returns:\n            np.ndarray: zero vector as a placeholder because a cloth prim doesn't have an angular velocity. Shape (3,).\n        \"\"\"\nreturn np.zeros(3)\ndef set_linear_velocity(self, velocity):\n\"\"\"\n        Sets the linear velocity of all the particles of the cloth prim.\n        Args:\n            velocity (np.ndarray): linear velocity to set all the particles of the cloth prim to. Shape (3,).\n        \"\"\"\nvel = self.particle_velocities\nvel[:] = velocity\nself.particle_velocities = vel\ndef set_angular_velocity(self, velocity):\n\"\"\"\n        Simply returns because a cloth prim doesn't have an angular velocity\n        Args:\n            velocity (np.ndarray): linear velocity to set all the particles of the cloth prim to. Shape (3,).\n        \"\"\"\nreturn\ndef wake(self):\n# TODO (eric): Just a pass through for now.\nreturn\n@property\ndef bend_stiffness(self):\n\"\"\"\n        Returns:\n            float: spring bend stiffness of the particle system\n        \"\"\"\nreturn self.get_attribute(\"physxAutoParticleCloth:springBendStiffness\")\n@bend_stiffness.setter\ndef bend_stiffness(self, bend_stiffness):\n\"\"\"\n        Args:\n            bend_stiffness (float): spring bend stiffness of the particle system\n        \"\"\"\nself.set_attribute(\"physxAutoParticleCloth:springBendStiffness\", bend_stiffness)\n@property\ndef damping(self):\n\"\"\"\n        Returns:\n            float: spring damping of the particle system\n        \"\"\"\nreturn self.get_attribute(\"physxAutoParticleCloth:springDamping\")\n@damping.setter\ndef damping(self, damping):\n\"\"\"\n        Args:\n            damping (float): spring damping of the particle system\n        \"\"\"\nself.set_attribute(\"physxAutoParticleCloth:springDamping\", damping)\n@property\ndef shear_stiffness(self):\n\"\"\"\n        Returns:\n            float: spring shear_stiffness of the particle system\n        \"\"\"\nreturn self.get_attribute(\"physxAutoParticleCloth:springShearStiffness\")\n@shear_stiffness.setter\ndef shear_stiffness(self, shear_stiffness):\n\"\"\"\n        Args:\n            shear_stiffness (float): spring shear_stiffness of the particle system\n        \"\"\"\nself.set_attribute(\"physxAutoParticleCloth:springShearStiffness\", shear_stiffness)\n@property\ndef stretch_stiffness(self):\n\"\"\"\n        Returns:\n            float: spring stretch_stiffness of the particle system\n        \"\"\"\nreturn self.get_attribute(\"physxAutoParticleCloth:springStretchStiffness\")\n@stretch_stiffness.setter\ndef stretch_stiffness(self, stretch_stiffness):\n\"\"\"\n        Args:\n            stretch_stiffness (float): spring stretch_stiffness of the particle system\n        \"\"\"\nself.set_attribute(\"physxAutoParticleCloth:springStretchStiffness\", stretch_stiffness)\n@property\ndef particle_group(self):\n\"\"\"\n        Returns:\n            int: Particle group this instancer belongs to\n        \"\"\"\nreturn self.get_attribute(attr=\"physxParticle:particleGroup\")\n@particle_group.setter\ndef particle_group(self, group):\n\"\"\"\n        Args:\n            group (int): Particle group this instancer belongs to\n        \"\"\"\nreturn self.set_attribute(attr=\"physxParticle:particleGroup\", val=group)\ndef _dump_state(self):\n# Run super first\nstate = super()._dump_state()\nstate[\"particle_group\"] = self.particle_group\nstate[\"n_particles\"] = self.n_particles\nstate[\"particle_positions\"] = self.particle_positions\nstate[\"particle_velocities\"] = self.particle_velocities\nreturn state\ndef _load_state(self, state):\n# Run super first\nsuper()._load_state(state=state)\n# Sanity check the identification number and particle group\nassert self.particle_group == state[\"particle_group\"], f\"Got mismatch in particle group for this cloth \" \\\n            f\"when loading state! Should be: {self.particle_group}, got: {state['particle_group']}.\"\n# Set values appropriately\nself._n_particles = state[\"n_particles\"]\nfor attr in (\"positions\", \"velocities\"):\nattr_name = f\"particle_{attr}\"\n# Make sure the loaded state is a numpy array, it could have been accidentally casted into a list during\n# JSON-serialization\nattr_val = np.array(state[attr_name]) if not isinstance(attr_name, np.ndarray) else state[attr_name]\nsetattr(self, attr_name, attr_val)\ndef _serialize(self, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\nreturn np.concatenate([\nstate_flat,\n[state[\"particle_group\"], state[\"n_particles\"]],\nstate[\"particle_positions\"].reshape(-1),\nstate[\"particle_velocities\"].reshape(-1),\n]).astype(float)\ndef _deserialize(self, state):\n# Run super first\nstate_dict, idx = super()._deserialize(state=state)\nparticle_group = int(state[idx])\nn_particles = int(state[idx + 1])\n# Sanity check the identification number\nassert self.particle_group == particle_group, f\"Got mismatch in particle group for this particle \" \\\n            f\"instancer when deserializing state! Should be: {self.particle_group}, got: {particle_group}.\"\n# De-compress from 1D array\nstate_dict[\"particle_group\"] = particle_group\nstate_dict[\"n_particles\"] = n_particles\n# Process remaining keys and reshape automatically\nkeys = (\"particle_positions\", \"particle_velocities\")\nsizes = ((n_particles, 3), (n_particles, 3))\nidx += 2\nfor key, size in zip(keys, sizes):\nlength = np.product(size)\nstate_dict[key] = state[idx: idx + length].reshape(size)\nidx += length\nreturn state_dict, idx\ndef reset(self):\n\"\"\"\n        Reset the points to their default positions in the local frame\n        \"\"\"\nif self.initialized:\nself.set_attribute(attr=\"points\", val=Vt.Vec3fArray.FromNumpy(self._default_positions))\n</code></pre>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.bend_stiffness","title":"<code>bend_stiffness</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>spring bend stiffness of the particle system</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.body_name","title":"<code>body_name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this body</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.damping","title":"<code>damping</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>spring damping of the particle system</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.keypoint_particle_positions","title":"<code>keypoint_particle_positions</code>  <code>property</code>","text":"<p>Grabs individual keypoint particle positions for this cloth prim. Total number of keypoints is m.N_CLOTH_KEYPOINTS</p> <p>Returns:</p> Type Description <p>np.array: (N, 3) numpy array, where each of the N keypoint particles' positions are expressed in (x,y,z) cartesian coordinates relative to the world frame</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.kinematic_only","title":"<code>kinematic_only</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this object is a kinematic-only object. For ClothPrim, always return False.</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.mass","title":"<code>mass</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>mass of the rigid body in kg.</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.n_particles","title":"<code>n_particles</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of particles owned by this cloth prim</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.particle_group","title":"<code>particle_group</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Particle group this instancer belongs to</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.particle_positions","title":"<code>particle_positions</code>  <code>property</code> <code>writable</code>","text":"<p>Grabs individual particle positions for this cloth prim</p> <p>Returns:</p> Type Description <p>np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z) cartesian coordinates relative to the world frame</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.particle_velocities","title":"<code>particle_velocities</code>  <code>property</code> <code>writable</code>","text":"<p>Grabs individual particle velocities for this cloth prim</p> <p>Returns:</p> Type Description <p>np.array: (N, 3) numpy array, where each of the N particles' velocities are expressed in (x,y,z) cartesian coordinates with respect to the world frame.</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.shear_stiffness","title":"<code>shear_stiffness</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>spring shear_stiffness of the particle system</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.stretch_stiffness","title":"<code>stretch_stiffness</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>spring stretch_stiffness of the particle system</p>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.contact_list","title":"<code>contact_list(keypoints_only=True)</code>","text":"<p>Get list of all current contacts with this cloth body</p> <p>Parameters:</p> Name Type Description Default <code>keypoints_only</code> <code>bool</code> <p>If True, will only check contact with this cloth's keypoints</p> <code>True</code> <p>Returns:</p> Type Description <p>list of CsRawData: raw contact info for this cloth body</p> Source code in <code>omnigibson/prims/cloth_prim.py</code> <pre><code>def contact_list(self, keypoints_only=True):\n\"\"\"\n    Get list of all current contacts with this cloth body\n    Args:\n        keypoints_only (bool): If True, will only check contact with this cloth's keypoints\n    Returns:\n        list of CsRawData: raw contact info for this cloth body\n    \"\"\"\ncontacts = []\ndef report_hit(hit):\ncontacts.append(CsRawData(\ntime=0.0,  # dummy value\ndt=0.0,  # dummy value\nbody0=self.prim_path,\nbody1=hit.rigid_body,\nposition=pos,\nnormal=np.zeros(3),  # dummy value\nimpulse=np.zeros(3),  # dummy value\n))\nreturn True\npositions = self.keypoint_particle_positions if keypoints_only else self.particle_positions\nfor pos in positions:\nog.sim.psqi.overlap_sphere(ClothPrim.cloth_system.particle_contact_offset, pos, report_hit, False)\nreturn contacts\n</code></pre>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.get_angular_velocity","title":"<code>get_angular_velocity()</code>","text":"<p>Returns:</p> Type Description <p>np.ndarray: zero vector as a placeholder because a cloth prim doesn't have an angular velocity. Shape (3,).</p> Source code in <code>omnigibson/prims/cloth_prim.py</code> <pre><code>def get_angular_velocity(self):\n\"\"\"\n    Returns:\n        np.ndarray: zero vector as a placeholder because a cloth prim doesn't have an angular velocity. Shape (3,).\n    \"\"\"\nreturn np.zeros(3)\n</code></pre>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.get_linear_velocity","title":"<code>get_linear_velocity()</code>","text":"<p>Returns:</p> Type Description <p>np.ndarray: current average linear velocity of the particles of the cloth prim. Shape (3,).</p> Source code in <code>omnigibson/prims/cloth_prim.py</code> <pre><code>def get_linear_velocity(self):\n\"\"\"\n    Returns:\n        np.ndarray: current average linear velocity of the particles of the cloth prim. Shape (3,).\n    \"\"\"\nreturn np.array(self._prim.GetAttribute(\"velocities\").Get()).mean(axis=0)\n</code></pre>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.reset","title":"<code>reset()</code>","text":"<p>Reset the points to their default positions in the local frame</p> Source code in <code>omnigibson/prims/cloth_prim.py</code> <pre><code>def reset(self):\n\"\"\"\n    Reset the points to their default positions in the local frame\n    \"\"\"\nif self.initialized:\nself.set_attribute(attr=\"points\", val=Vt.Vec3fArray.FromNumpy(self._default_positions))\n</code></pre>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.set_angular_velocity","title":"<code>set_angular_velocity(velocity)</code>","text":"<p>Simply returns because a cloth prim doesn't have an angular velocity</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>np.ndarray</code> <p>linear velocity to set all the particles of the cloth prim to. Shape (3,).</p> required Source code in <code>omnigibson/prims/cloth_prim.py</code> <pre><code>def set_angular_velocity(self, velocity):\n\"\"\"\n    Simply returns because a cloth prim doesn't have an angular velocity\n    Args:\n        velocity (np.ndarray): linear velocity to set all the particles of the cloth prim to. Shape (3,).\n    \"\"\"\nreturn\n</code></pre>"},{"location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.set_linear_velocity","title":"<code>set_linear_velocity(velocity)</code>","text":"<p>Sets the linear velocity of all the particles of the cloth prim.</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>np.ndarray</code> <p>linear velocity to set all the particles of the cloth prim to. Shape (3,).</p> required Source code in <code>omnigibson/prims/cloth_prim.py</code> <pre><code>def set_linear_velocity(self, velocity):\n\"\"\"\n    Sets the linear velocity of all the particles of the cloth prim.\n    Args:\n        velocity (np.ndarray): linear velocity to set all the particles of the cloth prim to. Shape (3,).\n    \"\"\"\nvel = self.particle_velocities\nvel[:] = velocity\nself.particle_velocities = vel\n</code></pre>"},{"location":"reference/prims/entity_prim.html","title":"entity_prim","text":""},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim","title":"<code>EntityPrim</code>","text":"<p>         Bases: <code>XFormPrim</code></p> <p>Provides high level functions to deal with an articulation prim and its attributes/ properties. Note that this type of prim cannot be created from scratch, and assumes there is already a pre-existing prim tree that should be converted into an articulation!</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that by default, this assumes an articulation already exists (i.e.: load() will raise NotImplementedError)! Subclasses must implement _load() for this prim to be able to be dynamically loaded after this class is created.</p> <p>visual_only (None or bool): If specified, whether this prim should include collisions or not.         Default is True.</p> <code>None</code> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>class EntityPrim(XFormPrim):\n\"\"\"\n    Provides high level functions to deal with an articulation prim and its attributes/ properties. Note that this\n    type of prim cannot be created from scratch, and assumes there is already a pre-existing prim tree that should\n    be converted into an articulation!\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that by default, this assumes an articulation already exists (i.e.:\n            load() will raise NotImplementedError)! Subclasses must implement _load() for this prim to be able to be\n            dynamically loaded after this class is created.\n            visual_only (None or bool): If specified, whether this prim should include collisions or not.\n                    Default is True.\n        \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\n# Other values that will be filled in at runtime\nself._dc = None                         # Dynamics control interface\nself._handle = None                     # Handle to this articulation\nself._root_handle = None                # Handle to the root rigid body of this articulation\nself._root_link_name = None             # Name of the root link\nself._dofs_infos = None\nself._n_dof = None                      # dof with dynamic control\nself._links = None\nself._joints = None\nself._materials = None\nself._visual_only = None\n# This needs to be initialized to be used for _load() of PrimitiveObject\nself._prim_type = load_config[\"prim_type\"] if \"prim_type\" in load_config else PrimType.RIGID\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _initialize(self):\n# Run super method\nsuper()._initialize()\n# Force populate inputs and outputs of the shaders of all materials\n# We suppress errors from omni.hydra if we're using encrypted assets, because we're loading from tmp location,\n# not the original location\nwith suppress_omni_log(channels=[\"omni.hydra\"] if gm.USE_ENCRYPTED_ASSETS else []):\nfor material in self.materials:\nmaterial.shader_force_populate(render=False)\n# Initialize all the links\n# This must happen BEFORE the handle is generated for this prim, because things changing in the RigidPrims may\n# cause the handle to change!\nfor link in self._links.values():\nlink.initialize()\n# Get dynamic control info\nself._dc = _dynamic_control.acquire_dynamic_control_interface()\n# Update joint information\nself.update_joints()\ndef _load(self):\n# By default, this prim cannot be instantiated from scratch!\nraise NotImplementedError(\"By default, an entity prim cannot be created from scratch.\")\ndef _post_load(self):\n# Setup links info FIRST before running any other post loading behavior\nself.update_links()\n# Set visual only flag\n# This automatically handles setting collisions / gravity appropriately per-link\nself.visual_only = self._load_config[\"visual_only\"] if \\\n            \"visual_only\" in self._load_config and self._load_config[\"visual_only\"] is not None else False\nif self._prim_type == PrimType.CLOTH:\nassert not self._visual_only, \"Cloth cannot be visual-only.\"\nassert len(self._links) == 1, f\"Cloth entity prim can only have one link; got: {len(self._links)}\"\nif gm.AG_CLOTH:\nself.create_attachment_point_link()\n# Disable any requested collision pairs\nfor a_name, b_name in self.disabled_collision_pairs:\nlink_a, link_b = self._links[a_name], self._links[b_name]\nlink_a.add_filtered_collision_pair(prim=link_b)\n# Run super\nsuper()._post_load()\n# Cache material information\nmaterials = set()\nmaterial_paths = set()\nfor link in self._links.values():\nxforms = [link] + list(link.visual_meshes.values()) if self.prim_type == PrimType.RIGID else [link]\nfor xform in xforms:\nif xform.has_material():\nmat_path = xform.material.prim_path\nif mat_path not in material_paths:\nmaterials.add(xform.material)\nmaterial_paths.add(mat_path)\nself._materials = materials\ndef update_links(self):\n\"\"\"\n        Helper function to refresh owned joints. Useful for synchronizing internal data if\n        additional bodies are added manually\n        \"\"\"\n# Make sure to clean up all pre-existing names for all links\nif self._links is not None:\nfor link in self._links.values():\nlink.remove_names()\n# We iterate over all children of this object's prim,\n# and grab any that are presumed to be rigid bodies (i.e.: other Xforms)\nself._links = dict()\njoint_children = set()\nfor prim in self._prim.GetChildren():\nlink = None\nlink_name = prim.GetName()\nif self._prim_type == PrimType.RIGID and prim.GetPrimTypeInfo().GetTypeName() == \"Xform\":\n# For rigid body object, process prims that are Xforms (e.g. rigid links)\nlink = RigidPrim(\nprim_path=prim.GetPrimPath().__str__(),\nname=f\"{self._name}:{link_name}\",\n)\n# Also iterate through all children to infer joints and determine the children of those joints\n# We will use this info to infer which link is the base link!\nfor child_prim in prim.GetChildren():\nif \"joint\" in child_prim.GetPrimTypeInfo().GetTypeName().lower():\n# Store the child target of this joint\nrelationships = {r.GetName(): r for r in child_prim.GetRelationships()}\n# Only record if this is NOT a fixed link tying us to the world (i.e.: no target for body0)\nif len(relationships[\"physics:body0\"].GetTargets()) &gt; 0:\njoint_children.add(relationships[\"physics:body1\"].GetTargets()[0].pathString.split(\"/\")[-1])\nif self._prim_type == PrimType.CLOTH and prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\n# For cloth object, process prims that belong to any of the GEOM_TYPES (e.g. Cube, Mesh, etc)\nlink = ClothPrim(\nprim_path=prim.GetPrimPath().__str__(),\nname=f\"{self._name}:{link_name}\",\n)\nif link is not None:\nself._links[link_name] = link\n# Infer the correct root link name -- this corresponds to whatever link does not have any joint existing\n# in the children joints\nvalid_root_links = list(set(self._links.keys()) - joint_children)\n# TODO: Uncomment safety check here after we figure out how to handle legacy multi-bodied assets like bed with pillow\n# assert len(valid_root_links) == 1, f\"Only a single root link should have been found for this entity prim, \" \\\n#                                    f\"but found multiple instead: {valid_root_links}\"\nself._root_link_name = valid_root_links[0] if len(valid_root_links) == 1 else \"base_link\"\ndef update_joints(self):\n\"\"\"\n        Helper function to refresh owned joints. Useful for synchronizing internal data if\n        additional bodies are added manually\n        \"\"\"\n# Make sure to clean up all pre-existing names for all joints\nif self._joints is not None:\nfor joint in self._joints.values():\njoint.remove_names()\n# Initialize joints dictionary\nself._joints = dict()\nself.update_handles()\n# Handle case separately based on whether the handle is valid (i.e.: whether we are actually articulated or not)\nif (not self.kinematic_only) and self._handle is not None:\nroot_prim = get_prim_at_path(self._dc.get_rigid_body_path(self._root_handle))\nn_dof = self._dc.get_articulation_dof_count(self._handle)\n# Additionally grab DOF info if we have non-fixed joints\nif n_dof &gt; 0:\nself._dofs_infos = dict()\n# Grab DOF info\nfor index in range(n_dof):\ndof_handle = self._dc.get_articulation_dof(self._handle, index)\ndof_name = self._dc.get_dof_name(dof_handle)\n# add dof to list\nprim_path = self._dc.get_dof_path(dof_handle)\nself._dofs_infos[dof_name] = DOFInfo(prim_path=prim_path, handle=dof_handle, prim=self.prim,\nindex=index)\nfor i in range(self._dc.get_articulation_joint_count(self._handle)):\njoint_handle = self._dc.get_articulation_joint(self._handle, i)\njoint_name = self._dc.get_joint_name(joint_handle)\njoint_path = self._dc.get_joint_path(joint_handle)\njoint_prim = get_prim_at_path(joint_path)\n# Only add the joint if it's not fixed (i.e.: it has DOFs &gt; 0)\nif self._dc.get_joint_dof_count(joint_handle) &gt; 0:\njoint = JointPrim(\nprim_path=joint_path,\nname=f\"{self._name}:joint_{joint_name}\",\narticulation=self._handle,\n)\njoint.initialize()\nself._joints[joint_name] = joint\nelse:\n# TODO: May need to extend to clusters of rigid bodies, that aren't exactly joined\n# We assume this object contains a single rigid body\nbody_path = f\"{self._prim_path}/{self.root_link_name}\"\nroot_prim = get_prim_at_path(body_path)\nn_dof = 0\n# Make sure root prim stored is the same as the one found during initialization\nassert self.root_prim == root_prim, \\\n            f\"Mismatch in root prims! Original was {self.root_prim.GetPrimPath()}, \" \\\n            f\"initialized is {root_prim.GetPrimPath()}!\"\n# Store values internally\nself._n_dof = n_dof\n@property\ndef prim_type(self):\n\"\"\"\n        Returns:\n            str: Type of this entity prim, one of omnigibson.utils.constants.PrimType\n        \"\"\"\nreturn self._prim_type\n@property\ndef articulated(self):\n\"\"\"\n        Returns:\n             bool: Whether this prim is articulated or not\n        \"\"\"\n# An invalid handle implies that there is no articulation available for this object\nreturn self._handle is not None or self.articulation_root_path is not None\n@property\ndef articulation_root_path(self):\n\"\"\"\n        Returns:\n            None or str: Absolute USD path to the expected prim that represents the articulation root, if it exists. By default,\n                this corresponds to self.prim_path\n        \"\"\"\nreturn self._prim_path if self.n_joints &gt; 0 else None\n@property\ndef root_link_name(self):\n\"\"\"\n        Returns:\n            str: Name of this entity's root link\n        \"\"\"\nreturn self._root_link_name\n@property\ndef root_link(self):\n\"\"\"\n        Returns:\n            RigidPrim: Root link of this object prim\n        \"\"\"\nreturn self._links[self.root_link_name]\n@property\ndef root_prim(self):\n\"\"\"\n        Returns:\n            UsdPrim: Root prim object associated with the root link of this object prim\n        \"\"\"\n# The root prim belongs to the link with name root_link_name\nreturn self._links[self.root_link_name].prim\n@property\ndef handle(self):\n\"\"\"\n        Returns:\n            None or int: ID (articulation) handle assigned to this prim from dynamic_control interface. Note that\n                if this prim is not an articulation, it is None\n        \"\"\"\nreturn self._handle\n@property\ndef root_handle(self):\n\"\"\"\n        Handle used by Isaac Sim's dynamic control module to reference the root body in this object.\n        Note: while self.handle may be 0 (i.e.: invalid articulation, i.e.: object with no joints), root_handle should\n            always be non-zero (i.e.: valid) if this object is initialized!\n        Returns:\n            int: ID handle assigned to this prim's root prim from dynamic_control interface\n        \"\"\"\nreturn self._root_handle\n@property\ndef n_dof(self):\n\"\"\"\n        Returns:\n            int: number of DoFs of the object\n        \"\"\"\nreturn self._n_dof\n@property\ndef n_joints(self):\n\"\"\"\n        Returns:\n            int: Number of joints owned by this articulation\n        \"\"\"\nif self.initialized:\nnum = len(list(self._joints.keys()))\nelse:\n# Manually iterate over all links and check for any joints that are not fixed joints!\nnum = 0\nfor link in self._links.values():\nfor child_prim in link.prim.GetChildren():\nprim_type = child_prim.GetPrimTypeInfo().GetTypeName().lower()\nif \"joint\" in prim_type and \"fixed\" not in prim_type:\nnum += 1\nreturn num\n@property\ndef n_fixed_joints(self):\n\"\"\"\n        Returns:\n        int: Number of fixed joints owned by this articulation\n        \"\"\"\n# Manually iterate over all links and check for any joints that are not fixed joints!\nnum = 0\nfor link in self._links.values():\nfor child_prim in link.prim.GetChildren():\nprim_type = child_prim.GetPrimTypeInfo().GetTypeName().lower()\nif \"joint\" in prim_type and \"fixed\" in prim_type:\nnum += 1\nreturn num\n@property\ndef n_links(self):\n\"\"\"\n        Returns:\n            int: Number of links owned by this articulation\n        \"\"\"\nreturn len(list(self._links.keys()))\n@property\ndef joints(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping joint names (str) to joint prims (JointPrim) owned by this articulation\n        \"\"\"\nreturn self._joints\n@property\ndef links(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping link names (str) to link prims (RigidPrim) owned by this articulation\n        \"\"\"\nreturn self._links\n@property\ndef materials(self):\n\"\"\"\n        Loop through each link and their visual meshes to gather all the materials that belong to this object\n        Returns:\n            set of MaterialPrim: a set of MaterialPrim that belongs to this object\n        \"\"\"\nreturn self._materials\n@property\ndef dof_properties(self):\n\"\"\"\n        Returns:\n            n-array: Array of DOF properties assigned to this articulation's DoFs.\n        \"\"\"\nreturn self._dc.get_articulation_dof_properties(self._handle)\n@property\ndef visual_only(self):\n\"\"\"\n        Returns:\n            bool: Whether this link is a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\nreturn self._visual_only\n@visual_only.setter\ndef visual_only(self, val):\n\"\"\"\n        Sets the visaul only state of this link\n        Args:\n            val (bool): Whether this link should be a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\n# Iterate over all owned links and set their respective visual-only properties accordingly\nfor link in self._links.values():\nlink.visual_only = val\n# Also set the internal value\nself._visual_only = val\ndef contact_list(self):\n\"\"\"\n        Get list of all current contacts with this object prim\n        Returns:\n            list of CsRawData: raw contact info for this rigid body\n        \"\"\"\ncontacts = []\nfor link in self._links.values():\ncontacts += link.contact_list()\nreturn contacts\ndef enable_gravity(self) -&gt; None:\n\"\"\"\n        Enables gravity for this entity\n        \"\"\"\nfor link in self._links.values():\nlink.enable_gravity()\ndef disable_gravity(self) -&gt; None:\n\"\"\"\n        Disables gravity for this entity\n        \"\"\"\nfor link in self._links.values():\nlink.disable_gravity()\ndef set_joint_positions(self, positions, indices=None, normalized=False, drive=False):\n\"\"\"\n        Set the joint positions (both actual value and target values) in simulation. Note: only works if the simulator\n        is actively running!\n        Args:\n            positions (np.ndarray): positions to set. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @positions must\n                be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF positions to set.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool): Whether the inputted joint positions should be interpreted as normalized values. Default\n                is False\n            drive (bool): Whether the positions being set are values that should be driven naturally by this entity's\n                motors or manual values to immediately set. Default is False, corresponding to an instantaneous\n                setting of the positions\n        \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\n# Possibly de-normalize the inputs\nif normalized:\npositions = self._denormalize_positions(positions=positions, indices=indices)\n# Grab current DOF states\ndof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)\n# Possibly set specific values in the array if indies are specified\nif indices is None:\nassert len(positions) == self._n_dof, \\\n                \"set_joint_positions called without specifying indices, but the desired positions do not match n_dof.\"\nnew_positions = positions\nelse:\nnew_positions = dof_states[\"pos\"]\nnew_positions[indices] = positions\n# Set the DOF states\ndof_states[\"pos\"] = new_positions\nif not drive:\nself._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_POS)\n# Also set the target\nself._dc.set_articulation_dof_position_targets(self._handle, new_positions.astype(np.float32))\ndef set_joint_velocities(self, velocities, indices=None, normalized=False, drive=False):\n\"\"\"\n        Set the joint velocities (both actual value and target values) in simulation. Note: only works if the simulator\n        is actively running!\n        Args:\n            velocities (np.ndarray): velocities to set. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @velocities must\n                be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF velocities to set.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool): Whether the inputted joint velocities should be interpreted as normalized values. Default\n                is False\n            drive (bool): Whether the velocities being set are values that should be driven naturally by this entity's\n                motors or manual values to immediately set. Default is False, corresponding to an instantaneous\n                setting of the velocities\n        \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\n# Possibly de-normalize the inputs\nif normalized:\nvelocities = self._denormalize_velocities(velocities=velocities, indices=indices)\n# Grab current DOF states\ndof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)\n# Possibly set specific values in the array if indies are specified\nif indices is None:\nnew_velocities = velocities\nelse:\nnew_velocities = dof_states[\"vel\"]\nnew_velocities[indices] = velocities\n# Set the DOF states\ndof_states[\"vel\"] = new_velocities\nif not drive:\nself._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_VEL)\n# Also set the target\nself._dc.set_articulation_dof_velocity_targets(self._handle, new_velocities.astype(np.float32))\ndef set_joint_efforts(self, efforts, indices=None, normalized=False):\n\"\"\"\n        Set the joint efforts (both actual value and target values) in simulation. Note: only works if the simulator\n        is actively running!\n        Args:\n            efforts (np.ndarray): efforts to set. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @efforts must\n                be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF efforts to set.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool): Whether the inputted joint efforts should be interpreted as normalized values. Default\n                is False\n        \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\n# Possibly de-normalize the inputs\nif normalized:\nefforts = self._denormalize_efforts(efforts=efforts, indices=indices)\n# Grab current DOF states\ndof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)\n# Possibly set specific values in the array if indies are specified\nif indices is None:\nnew_efforts = efforts\nelse:\nnew_efforts = dof_states[\"effort\"]\nnew_efforts[indices] = efforts\n# Set the DOF states\ndof_states[\"effort\"] = new_efforts\nself._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_EFFORT)\ndef _normalize_positions(self, positions, indices=None):\n\"\"\"\n        Normalizes raw joint positions @positions\n        Args:\n            positions (n- or k-array): n-DOF raw positions to normalize, or k (k &lt; n) specific positions to normalize.\n                In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                positions to normalize. Default is None, which assumes the positions correspond to all DOF being\n                normalized.\n        Returns:\n            n- or k-array: normalized positions in range [-1, 1] for the specified DOFs\n        \"\"\"\nlow, high = self.joint_lower_limits, self.joint_upper_limits\nmean = (low + high) / 2.0\nmagnitude = (high - low) / 2.0\nreturn (positions - mean) / magnitude if indices is None else (positions - mean[indices]) / magnitude[indices]\ndef _denormalize_positions(self, positions, indices=None):\n\"\"\"\n        De-normalizes joint positions @positions\n        Args:\n            positions (n- or k-array): n-DOF normalized positions or k (k &lt; n) specific positions in range [-1, 1]\n                to de-normalize. In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                positions to de-normalize. Default is None, which assumes the positions correspond to all DOF being\n                de-normalized.\n        Returns:\n            n- or k-array: de-normalized positions for the specified DOFs\n        \"\"\"\nlow, high = self.joint_lower_limits, self.joint_upper_limits\nmean = (low + high) / 2.0\nmagnitude = (high - low) / 2.0\nreturn positions * magnitude + mean if indices is None else positions * magnitude[indices] + mean[indices]\ndef _normalize_velocities(self, velocities, indices=None):\n\"\"\"\n        Normalizes raw joint velocities @velocities\n        Args:\n            velocities (n- or k-array): n-DOF raw velocities to normalize, or k (k &lt; n) specific velocities to normalize.\n                In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                velocities to normalize. Default is None, which assumes the velocities correspond to all DOF being\n                normalized.\n        Returns:\n            n- or k-array: normalized velocities in range [-1, 1] for the specified DOFs\n        \"\"\"\nreturn velocities / self.max_joint_velocities if indices is None else \\\n            velocities / self.max_joint_velocities[indices]\ndef _denormalize_velocities(self, velocities, indices=None):\n\"\"\"\n        De-normalizes joint velocities @velocities\n        Args:\n            velocities (n- or k-array): n-DOF normalized velocities or k (k &lt; n) specific velocities in range [-1, 1]\n                to de-normalize. In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                velocities to de-normalize. Default is None, which assumes the velocities correspond to all DOF being\n                de-normalized.\n        Returns:\n            n- or k-array: de-normalized velocities for the specified DOFs\n        \"\"\"\nreturn velocities * self.max_joint_velocities if indices is None else \\\n            velocities * self.max_joint_velocities[indices]\ndef _normalize_efforts(self, efforts, indices=None):\n\"\"\"\n        Normalizes raw joint efforts @efforts\n        Args:\n            efforts (n- or k-array): n-DOF raw efforts to normalize, or k (k &lt; n) specific efforts to normalize.\n                In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                efforts to normalize. Default is None, which assumes the efforts correspond to all DOF being\n                normalized.\n        Returns:\n            n- or k-array: normalized efforts in range [-1, 1] for the specified DOFs\n        \"\"\"\nreturn efforts / self.max_joint_efforts if indices is None else efforts / self.max_joint_efforts[indices]\ndef _denormalize_efforts(self, efforts, indices=None):\n\"\"\"\n        De-normalizes joint efforts @efforts\n        Args:\n            efforts (n- or k-array): n-DOF normalized efforts or k (k &lt; n) specific efforts in range [-1, 1]\n                to de-normalize. In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                efforts to de-normalize. Default is None, which assumes the efforts correspond to all DOF being\n                de-normalized.\n        Returns:\n            n- or k-array: de-normalized efforts for the specified DOFs\n        \"\"\"\nreturn efforts * self.max_joint_efforts if indices is None else efforts * self.max_joint_efforts[indices]\ndef update_handles(self):\n\"\"\"\n        Updates all internal handles for this prim, in case they change since initialization\n        \"\"\"\nassert og.sim.is_playing(), \"Simulator must be playing if updating handles!\"\n# Grab the handle -- we know it might not return a valid value, so we suppress omni's warning here\nself._handle = None if self.articulation_root_path is None else \\\n            self._dc.get_articulation(self.articulation_root_path)\n# Sanity check -- make sure handle is not invalid handle -- it should only ever be None or a valid integer\nassert self._handle != _dynamic_control.INVALID_HANDLE, \\\n            f\"Got invalid articulation handle for entity at {self.articulation_root_path}\"\n# We only have a root handle if we're not a cloth prim\nif self._prim_type != PrimType.CLOTH:\nself._root_handle = self._dc.get_articulation_root_body(self._handle) if \\\n                self._handle is not None else self.root_link.handle\n# Update all links and joints as well\nfor link in self._links.values():\nif not link.initialized:\nlink.initialize()\nlink.update_handles()\nfor joint in self._joints.values():\nif not joint.initialized:\njoint.initialize()\njoint.update_handles()\ndef get_joint_positions(self, normalized=False):\n\"\"\"\n        Grabs this entity's joint positions\n        Args:\n            normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n        Returns:\n            n-array: n-DOF length array of positions\n        \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\njoint_positions = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)[\"pos\"]\n# Possibly normalize values when returning\nreturn self._normalize_positions(positions=joint_positions) if normalized else joint_positions\ndef get_joint_velocities(self, normalized=False):\n\"\"\"\n        Grabs this entity's joint velocities\n        Args:\n            normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n        Returns:\n            n-array: n-DOF length array of velocities\n        \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\njoint_velocities = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)[\"vel\"]\n# Possibly normalize values when returning\nreturn self._normalize_velocities(velocities=joint_velocities) if normalized else joint_velocities\ndef get_joint_efforts(self, normalized=False):\n\"\"\"\n        Grabs this entity's joint efforts\n        Args:\n            normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n        Returns:\n            n-array: n-DOF length array of efforts\n        \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\njoint_efforts = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)[\"effort\"]\n# Possibly normalize values when returning\nreturn self._normalize_efforts(efforts=joint_efforts) if normalized else joint_efforts\ndef set_linear_velocity(self, velocity: np.ndarray):\n\"\"\"\n        Sets the linear velocity of the root prim in stage.\n        Args:\n            velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\nself.root_link.set_linear_velocity(velocity)\ndef get_linear_velocity(self):\n\"\"\"\n        Gets the linear velocity of the root prim in stage.\n        Returns:\n            velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\nreturn self.root_link.get_linear_velocity()\ndef set_angular_velocity(self, velocity):\n\"\"\"\n        Sets the angular velocity of the root prim in stage.\n        Args:\n            velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\nself.root_link.set_angular_velocity(velocity)\ndef get_angular_velocity(self):\n\"\"\"Gets the angular velocity of the root prim in stage.\n        Returns:\n            velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\nreturn self.root_link.get_angular_velocity()\ndef set_position_orientation(self, position=None, orientation=None):\ncurrent_position, current_orientation = self.get_position_orientation()\nif position is None:\nposition = current_position\nif orientation is None:\norientation = current_orientation\nif self._prim_type == PrimType.CLOTH:\nif self._dc is not None and self._dc.is_simulating():\nself.root_link.set_position_orientation(position, orientation)\nelse:\nsuper().set_position_orientation(position, orientation)\nelse:\nif self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\nself.root_link.set_position_orientation(position, orientation)\nelse:\nsuper().set_position_orientation(position=position, orientation=orientation)\ndef get_position_orientation(self):\nif self._prim_type == PrimType.CLOTH:\nif self._dc is not None and self._dc.is_simulating():\nreturn self.root_link.get_position_orientation()\nelse:\nreturn super().get_position_orientation()\nelse:\nif self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\nreturn self.root_link.get_position_orientation()\nelse:\nreturn super().get_position_orientation()\ndef _set_local_pose_when_simulating(self, translation=None, orientation=None):\n\"\"\"\n        Sets prim's pose with respect to the local frame (the prim's parent frame) when simulation is running.\n        Args:\n            translation (None or 3-array): if specified, (x,y,z) translation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n            orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n        \"\"\"\ncurrent_translation, current_orientation = self.get_local_pose()\nif translation is None:\ntranslation = current_translation\nif orientation is None:\norientation = current_orientation\norientation = orientation[[3, 0, 1, 2]]\nlocal_transform = tf_matrix_from_pose(translation=translation, orientation=orientation)\nparent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\nUsd.TimeCode.Default()\n)\nmy_world_transform = np.matmul(parent_world_tf, local_transform)\ntransform = Gf.Transform()\ntransform.SetMatrix(Gf.Matrix4d(np.transpose(my_world_transform)))\ncalculated_position = transform.GetTranslation()\ncalculated_orientation = transform.GetRotation().GetQuat()\nself.set_position_orientation(\nposition=np.array(calculated_position),\norientation=gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]],\n)\ndef set_local_pose(self, translation=None, orientation=None):\nif self._prim_type == PrimType.CLOTH:\nif self._dc is not None and self._dc.is_simulating():\nself._set_local_pose_when_simulating(translation=translation, orientation=orientation)\nelse:\nsuper().set_local_pose(translation=translation, orientation=orientation)\nelse:\nif self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\nself._set_local_pose_when_simulating(translation=translation, orientation=orientation)\nelse:\nsuper().set_local_pose(translation=translation, orientation=orientation)\ndef _get_local_pose_when_simulating(self):\n\"\"\"\n        Gets prim's pose with respect to the prim's local frame (it's parent frame) when simulation is running\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) position in the local frame\n                - 4-array: (x,y,z,w) quaternion orientation in the local frame\n        \"\"\"\nparent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\nUsd.TimeCode.Default()\n)\nworld_position, world_orientation = self.get_position_orientation()\nmy_world_transform = tf_matrix_from_pose(translation=world_position,\norientation=world_orientation[[3, 0, 1, 2]])\nlocal_transform = np.matmul(np.linalg.inv(np.transpose(parent_world_tf)), my_world_transform)\ntransform = Gf.Transform()\ntransform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\ncalculated_translation = transform.GetTranslation()\ncalculated_orientation = transform.GetRotation().GetQuat()\nreturn np.array(calculated_translation), gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]]\ndef get_local_pose(self):\nif self._prim_type == PrimType.CLOTH:\nif self._dc is not None and self._dc.is_simulating():\nreturn self._get_local_pose_when_simulating()\nelse:\nreturn super().get_local_pose()\nelse:\nif self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\nreturn self._get_local_pose_when_simulating()\nelse:\nreturn super().get_local_pose()\n# TODO: Is the omni joint damping (used for driving motors) same as dissipative joint damping (what we had in pb)?\n@property\ndef joint_damping(self):\n\"\"\"\n        Returns:\n            n-array: joint damping values for this prim\n        \"\"\"\nreturn np.concatenate([joint.damping for joint in self._joints.values()])\n@property\ndef joint_lower_limits(self):\n\"\"\"\n        Returns:\n            n-array: minimum values for this robot's joints. If joint does not have a range, returns -1000\n                for that joint\n        \"\"\"\nreturn np.array([joint.lower_limit for joint in self._joints.values()])\n@property\ndef joint_upper_limits(self):\n\"\"\"\n        Returns:\n            n-array: maximum values for this robot's joints. If joint does not have a range, returns 1000\n                for that joint\n        \"\"\"\nreturn np.array([joint.upper_limit for joint in self._joints.values()])\n@property\ndef joint_range(self):\n\"\"\"\n        Returns:\n            n-array: joint range values for this robot's joints\n        \"\"\"\nreturn self.joint_upper_limits - self.joint_lower_limits\n@property\ndef max_joint_velocities(self):\n\"\"\"\n        Returns:\n            n-array: maximum velocities for this robot's joints\n        \"\"\"\nreturn np.array([joint.max_velocity for joint in self._joints.values()])\n@property\ndef max_joint_efforts(self):\n\"\"\"\n        Returns:\n            n-array: maximum efforts for this robot's joints\n        \"\"\"\nreturn np.array([joint.max_effort for joint in self._joints.values()])\n@property\ndef joint_position_limits(self):\n\"\"\"\n        Returns:\n            2-tuple:\n                - n-array: min joint position limits, where each is an n-DOF length array\n                - n-array: max joint position limits, where each is an n-DOF length array\n        \"\"\"\nreturn self.joint_lower_limits, self.joint_upper_limits\n@property\ndef joint_velocity_limits(self):\n\"\"\"\n        Returns:\n            2-tuple:\n                - n-array: min joint velocity limits, where each is an n-DOF length array\n                - n-array: max joint velocity limits, where each is an n-DOF length array\n        \"\"\"\nreturn -self.max_joint_velocities, self.max_joint_velocities\n@property\ndef joint_effort_limits(self):\n\"\"\"\n        Returns:\n            2-tuple:\n                - n-array: min joint effort limits, where each is an n-DOF length array\n                - n-array: max joint effort limits, where each is an n-DOF length array\n        \"\"\"\nreturn -self.max_joint_efforts, self.max_joint_efforts\n@property\ndef joint_at_limits(self):\n\"\"\"\n        Returns:\n            n-array: n-DOF length array specifying whether joint is at its limit,\n                with 1.0 --&gt; at limit, otherwise 0.0\n        \"\"\"\nreturn 1.0 * (np.abs(self.get_joint_positions(normalized=True)) &gt; 0.99)\n@property\ndef joint_has_limits(self):\n\"\"\"\n        Returns:\n            n-array: n-DOF length array specifying whether joint has a limit or not\n        \"\"\"\nreturn np.array([j.has_limit for j in self._joints.values()])\n@property\ndef disabled_collision_pairs(self):\n\"\"\"\n        Returns:\n            list of (str, str): List of rigid body collision pairs to disable within this object prim.\n                Default is an empty list (no pairs)\n        \"\"\"\nreturn []\n@property\ndef scale(self):\n# Since all rigid bodies owned by this object prim have the same scale, we simply grab it from the root prim\nreturn self.root_link.scale\n@scale.setter\ndef scale(self, scale):\n# We iterate over all rigid bodies owned by this object prim and set their individual scales\n# We do this because omniverse cannot scale orientation of an articulated prim, so we get mesh mismatches as\n# they rotate in the world\nfor link in self._links.values():\nlink.scale = scale\n@property\ndef solver_position_iteration_count(self):\n\"\"\"\n        Returns:\n            int: How many position iterations to take per physics step by the physx solver\n        \"\"\"\nreturn get_prim_property(self.articulation_root_path, \"physxArticulation:solverPositionIterationCount\") if \\\n            self.articulated else self.root_link.solver_position_iteration_count\n@solver_position_iteration_count.setter\ndef solver_position_iteration_count(self, count):\n\"\"\"\n        Sets how many position iterations to take per physics step by the physx solver\n        Args:\n            count (int): How many position iterations to take per physics step by the physx solver\n        \"\"\"\nif self.articulated:\nset_prim_property(self.articulation_root_path, \"physxArticulation:solverPositionIterationCount\", count)\nelse:\nfor link in self._links.values():\nlink.solver_position_iteration_count = count\n@property\ndef solver_velocity_iteration_count(self):\n\"\"\"\n        Returns:\n            int: How many velocity iterations to take per physics step by the physx solver\n        \"\"\"\nreturn get_prim_property(self.articulation_root_path, \"physxArticulation:solverVelocityIterationCount\") if \\\n            self.articulated else self.root_link.solver_velocity_iteration_count\n@solver_velocity_iteration_count.setter\ndef solver_velocity_iteration_count(self, count):\n\"\"\"\n        Sets how many velocity iterations to take per physics step by the physx solver\n        Args:\n            count (int): How many velocity iterations to take per physics step by the physx solver\n        \"\"\"\nif self.articulated:\nset_prim_property(self.articulation_root_path, \"physxArticulation:solverVelocityIterationCount\", count)\nelse:\nfor link in self._links.values():\nlink.solver_velocity_iteration_count = count\n@property\ndef stabilization_threshold(self):\n\"\"\"\n        Returns:\n            float: threshold for stabilizing this articulation\n        \"\"\"\nreturn get_prim_property(self.articulation_root_path, \"physxArticulation:stabilizationThreshold\") if \\\n            self.articulated else self.root_link.stabilization_threshold\n@stabilization_threshold.setter\ndef stabilization_threshold(self, threshold):\n\"\"\"\n        Sets threshold for stabilizing this articulation\n        Args:\n            threshold (float): Stabilization threshold\n        \"\"\"\nif self.articulated:\nset_prim_property(self.articulation_root_path, \"physxArticulation:stabilizationThreshold\", threshold)\nelse:\nfor link in self._links.values():\nlink.stabilization_threshold = threshold\n@property\ndef sleep_threshold(self):\n\"\"\"\n        Returns:\n            float: threshold for sleeping this articulation\n        \"\"\"\nreturn get_prim_property(self.articulation_root_path, \"physxArticulation:sleepThreshold\") if \\\n            self.articulated else self.root_link.sleep_threshold\n@sleep_threshold.setter\ndef sleep_threshold(self, threshold):\n\"\"\"\n        Sets threshold for sleeping this articulation\n        Args:\n            threshold (float): Sleeping threshold\n        \"\"\"\nif self.articulated:\nset_prim_property(self.articulation_root_path, \"physxArticulation:sleepThreshold\", threshold)\nelse:\nfor link in self._links.values():\nlink.sleep_threshold = threshold\n@property\ndef self_collisions(self):\n\"\"\"\n        Returns:\n            bool: Whether self-collisions are enabled for this prim or not\n        \"\"\"\nassert self.articulated, \"Cannot get self-collision for non-articulated EntityPrim!\"\nreturn get_prim_property(self.articulation_root_path, \"physxArticulation:enabledSelfCollisions\")\n@self_collisions.setter\ndef self_collisions(self, flag):\n\"\"\"\n        Sets whether self-collisions are enabled for this prim or not\n        Args:\n            flag (bool): Whether self collisions are enabled for this prim or not\n        \"\"\"\nassert self.articulated, \"Cannot set self-collision for non-articulated EntityPrim!\"\nset_prim_property(self.articulation_root_path, \"physxArticulation:enabledSelfCollisions\", flag)\n@property\ndef kinematic_only(self):\n\"\"\"\n        Returns:\n            bool: Whether this object is a kinematic-only object (otherwise, it is a rigid body). A kinematic-only\n                object is not subject to simulator dynamics, and remains fixed unless the user explicitly sets the\n                body's pose / velocities. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html?highlight=rigid%20body%20enabled#kinematic-rigid-bodies\n                for more information\n        \"\"\"\nreturn self.root_link.kinematic_only\n@kinematic_only.setter\ndef kinematic_only(self, val):\n\"\"\"\n        Args:\n            val (bool): Whether this object is a kinematic-only object (otherwise, it is a rigid body). A kinematic-only\n                object is not subject to simulator dynamics, and remains fixed unless the user explicitly sets the\n                body's pose / velocities. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html?highlight=rigid%20body%20enabled#kinematic-rigid-bodies\n                for more information\n        \"\"\"\nself.root_link.kinematic_only = val\ndef wake(self):\n\"\"\"\n        Enable physics for this articulation\n        \"\"\"\nif self.articulated:\nself._dc.wake_up_articulation(self._handle)\nelse:\nfor link in self._links.values():\nlink.wake()\ndef sleep(self):\n\"\"\"\n        Disable physics for this articulation\n        \"\"\"\nif self.articulated:\nself._dc.sleep_articulation(self._handle)\nelse:\nfor link in self._links.values():\nlink.sleep()\ndef keep_still(self):\n\"\"\"\n        Zero out all velocities for this prim\n        \"\"\"\nself.set_linear_velocity(velocity=np.zeros(3))\nself.set_angular_velocity(velocity=np.zeros(3))\nfor joint in self._joints.values():\njoint.keep_still()\ndef create_attachment_point_link(self):\n\"\"\"\n        Create a collision-free, invisible attachment point link for the cloth object, and create an attachment between\n        the ClothPrim and this attachment point link (RigidPrim).\n        One use case for this is that we can create a fixed joint between this link and the world to enable AG fo cloth.\n        During simulation, this joint will move and match the robot gripper frame, which will then drive the cloth.\n        \"\"\"\nassert self._prim_type == PrimType.CLOTH, \"create_attachment_point_link should only be called for Cloth\"\nlink_name = \"attachment_point\"\nstage = get_current_stage()\nlink_prim = stage.DefinePrim(f\"{self._prim_path}/{link_name}\", \"Xform\")\nvis_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/visuals\").GetPrim()\ncol_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/collisions\").GetPrim()\n# Set the radius to be 0.03m. In theory, we want this radius to be as small as possible. Otherwise, the cloth\n# dynamics will be unrealistic. However, in practice, if the radius is too small, the attachment becomes very\n# unstable. Empirically 0.03m works reasonably well.\nvis_prim.GetAttribute(\"radius\").Set(0.03)\ncol_prim.GetAttribute(\"radius\").Set(0.03)\n# Need to sync the extents\nextent = vis_prim.GetAttribute(\"extent\").Get()\nextent[0] = Gf.Vec3f(-0.03, -0.03, -0.03)\nextent[1] = Gf.Vec3f(0.03, 0.03, 0.03)\nvis_prim.GetAttribute(\"extent\").Set(extent)\ncol_prim.GetAttribute(\"extent\").Set(extent)\n# Add collision API to collision geom\nUsdPhysics.CollisionAPI.Apply(col_prim)\nUsdPhysics.MeshCollisionAPI.Apply(col_prim)\nPhysxSchema.PhysxCollisionAPI.Apply(col_prim)\n# Create a attachment point link\nlink = RigidPrim(\nprim_path=link_prim.GetPrimPath().__str__(),\nname=f\"{self._name}:{link_name}\",\n)\nlink.disable_collisions()\n# TODO (eric): Should we disable gravity for this link?\n# link.disable_gravity()\nlink.visible = False\n# Set a very small mass\nlink.mass = 1e-6\nself._links[link_name] = link\n# Create an attachment between the root link (ClothPrim) and the newly created attachment point link (RigidPrim)\nattachment_path = self.root_link.prim.GetPath().AppendElementString(\"attachment\")\nomni.kit.commands.execute(\"CreatePhysicsAttachment\", target_attachment_path=attachment_path,\nactor0_path=self.root_link.prim.GetPath(), actor1_path=link.prim.GetPath())\ndef _dump_state(self):\n# We don't call super, instead, this state is simply the root link state and all joint states\nstate = dict(root_link=self.root_link._dump_state())\njoint_state = dict()\nfor prim_name, prim in self._joints.items():\njoint_state[prim_name] = prim._dump_state()\nstate[\"joints\"] = joint_state\nreturn state\ndef _load_state(self, state):\n# Load base link state and joint states\nself.root_link._load_state(state=state[\"root_link\"])\nfor joint_name, joint_state in state[\"joints\"].items():\nself._joints[joint_name]._load_state(state=joint_state)\ndef _serialize(self, state):\n# We serialize by first flattening the root link state and then iterating over all joints and\n# adding them to the a flattened array\nstate_flat = [self.root_link.serialize(state=state[\"root_link\"])]\nif self.n_joints &gt; 0:\nstate_flat.append(\nnp.concatenate(\n[prim.serialize(state=state[\"joints\"][prim_name]) for prim_name, prim in self._joints.items()]\n)\n)\nreturn np.concatenate(state_flat).astype(float)\ndef _deserialize(self, state):\n# We deserialize by first de-flattening the root link state and then iterating over all joints and\n# sequentially grabbing from the flattened state array, incrementing along the way\nidx = self.root_link.state_size\nstate_dict = dict(root_link=self.root_link.deserialize(state=state[:idx]))\njoint_state_dict = dict()\nfor prim_name, prim in self._joints.items():\njoint_state_dict[prim_name] = prim.deserialize(state=state[idx:idx+prim.state_size])\nidx += prim.state_size\nstate_dict[\"joints\"] = joint_state_dict\nreturn state_dict, idx\ndef _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n# Subclass must implement this method for duplication functionality\nraise NotImplementedError(\"Subclass must implement _create_prim_with_same_kwargs() to enable duplication \"\n\"functionality for EntityPrim!\")\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.articulated","title":"<code>articulated</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this prim is articulated or not</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.articulation_root_path","title":"<code>articulation_root_path</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or str: Absolute USD path to the expected prim that represents the articulation root, if it exists. By default, this corresponds to self.prim_path</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.disabled_collision_pairs","title":"<code>disabled_collision_pairs</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>list of (str, str): List of rigid body collision pairs to disable within this object prim. Default is an empty list (no pairs)</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.dof_properties","title":"<code>dof_properties</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Array of DOF properties assigned to this articulation's DoFs.</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.handle","title":"<code>handle</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or int: ID (articulation) handle assigned to this prim from dynamic_control interface. Note that if this prim is not an articulation, it is None</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_at_limits","title":"<code>joint_at_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: n-DOF length array specifying whether joint is at its limit, with 1.0 --&gt; at limit, otherwise 0.0</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_damping","title":"<code>joint_damping</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: joint damping values for this prim</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_effort_limits","title":"<code>joint_effort_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>2-tuple: - n-array: min joint effort limits, where each is an n-DOF length array - n-array: max joint effort limits, where each is an n-DOF length array</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_has_limits","title":"<code>joint_has_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: n-DOF length array specifying whether joint has a limit or not</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_lower_limits","title":"<code>joint_lower_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: minimum values for this robot's joints. If joint does not have a range, returns -1000 for that joint</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_position_limits","title":"<code>joint_position_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>2-tuple: - n-array: min joint position limits, where each is an n-DOF length array - n-array: max joint position limits, where each is an n-DOF length array</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_range","title":"<code>joint_range</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: joint range values for this robot's joints</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_upper_limits","title":"<code>joint_upper_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: maximum values for this robot's joints. If joint does not have a range, returns 1000 for that joint</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_velocity_limits","title":"<code>joint_velocity_limits</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>2-tuple: - n-array: min joint velocity limits, where each is an n-DOF length array - n-array: max joint velocity limits, where each is an n-DOF length array</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joints","title":"<code>joints</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping joint names (str) to joint prims (JointPrim) owned by this articulation</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.kinematic_only","title":"<code>kinematic_only</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this object is a kinematic-only object (otherwise, it is a rigid body). A kinematic-only object is not subject to simulator dynamics, and remains fixed unless the user explicitly sets the body's pose / velocities. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html?highlight=rigid%20body%20enabled#kinematic-rigid-bodies for more information</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.links","title":"<code>links</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping link names (str) to link prims (RigidPrim) owned by this articulation</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.materials","title":"<code>materials</code>  <code>property</code>","text":"<p>Loop through each link and their visual meshes to gather all the materials that belong to this object</p> <p>Returns:</p> Type Description <p>set of MaterialPrim: a set of MaterialPrim that belongs to this object</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.max_joint_efforts","title":"<code>max_joint_efforts</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: maximum efforts for this robot's joints</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.max_joint_velocities","title":"<code>max_joint_velocities</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: maximum velocities for this robot's joints</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.n_dof","title":"<code>n_dof</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>number of DoFs of the object</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.n_fixed_joints","title":"<code>n_fixed_joints</code>  <code>property</code>","text":"<p>int: Number of fixed joints owned by this articulation</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.n_joints","title":"<code>n_joints</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of joints owned by this articulation</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.n_links","title":"<code>n_links</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of links owned by this articulation</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.prim_type","title":"<code>prim_type</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Type of this entity prim, one of omnigibson.utils.constants.PrimType</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_handle","title":"<code>root_handle</code>  <code>property</code>","text":"<p>Handle used by Isaac Sim's dynamic control module to reference the root body in this object.</p> while self.handle may be 0 (i.e.: invalid articulation, i.e.: object with no joints), root_handle should <p>always be non-zero (i.e.: valid) if this object is initialized!</p> <p>Returns:</p> Name Type Description <code>int</code> <p>ID handle assigned to this prim's root prim from dynamic_control interface</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_link","title":"<code>root_link</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>RigidPrim</code> <p>Root link of this object prim</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_link_name","title":"<code>root_link_name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this entity's root link</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_prim","title":"<code>root_prim</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>UsdPrim</code> <p>Root prim object associated with the root link of this object prim</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.self_collisions","title":"<code>self_collisions</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether self-collisions are enabled for this prim or not</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.sleep_threshold","title":"<code>sleep_threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>threshold for sleeping this articulation</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.solver_position_iteration_count","title":"<code>solver_position_iteration_count</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>How many position iterations to take per physics step by the physx solver</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.solver_velocity_iteration_count","title":"<code>solver_velocity_iteration_count</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>How many velocity iterations to take per physics step by the physx solver</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.stabilization_threshold","title":"<code>stabilization_threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>threshold for stabilizing this articulation</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.visual_only","title":"<code>visual_only</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this link is a visual-only link (i.e.: no gravity or collisions applied)</p>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.contact_list","title":"<code>contact_list()</code>","text":"<p>Get list of all current contacts with this object prim</p> <p>Returns:</p> Type Description <p>list of CsRawData: raw contact info for this rigid body</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def contact_list(self):\n\"\"\"\n    Get list of all current contacts with this object prim\n    Returns:\n        list of CsRawData: raw contact info for this rigid body\n    \"\"\"\ncontacts = []\nfor link in self._links.values():\ncontacts += link.contact_list()\nreturn contacts\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.create_attachment_point_link","title":"<code>create_attachment_point_link()</code>","text":"<p>Create a collision-free, invisible attachment point link for the cloth object, and create an attachment between the ClothPrim and this attachment point link (RigidPrim).</p> <p>One use case for this is that we can create a fixed joint between this link and the world to enable AG fo cloth. During simulation, this joint will move and match the robot gripper frame, which will then drive the cloth.</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def create_attachment_point_link(self):\n\"\"\"\n    Create a collision-free, invisible attachment point link for the cloth object, and create an attachment between\n    the ClothPrim and this attachment point link (RigidPrim).\n    One use case for this is that we can create a fixed joint between this link and the world to enable AG fo cloth.\n    During simulation, this joint will move and match the robot gripper frame, which will then drive the cloth.\n    \"\"\"\nassert self._prim_type == PrimType.CLOTH, \"create_attachment_point_link should only be called for Cloth\"\nlink_name = \"attachment_point\"\nstage = get_current_stage()\nlink_prim = stage.DefinePrim(f\"{self._prim_path}/{link_name}\", \"Xform\")\nvis_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/visuals\").GetPrim()\ncol_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/collisions\").GetPrim()\n# Set the radius to be 0.03m. In theory, we want this radius to be as small as possible. Otherwise, the cloth\n# dynamics will be unrealistic. However, in practice, if the radius is too small, the attachment becomes very\n# unstable. Empirically 0.03m works reasonably well.\nvis_prim.GetAttribute(\"radius\").Set(0.03)\ncol_prim.GetAttribute(\"radius\").Set(0.03)\n# Need to sync the extents\nextent = vis_prim.GetAttribute(\"extent\").Get()\nextent[0] = Gf.Vec3f(-0.03, -0.03, -0.03)\nextent[1] = Gf.Vec3f(0.03, 0.03, 0.03)\nvis_prim.GetAttribute(\"extent\").Set(extent)\ncol_prim.GetAttribute(\"extent\").Set(extent)\n# Add collision API to collision geom\nUsdPhysics.CollisionAPI.Apply(col_prim)\nUsdPhysics.MeshCollisionAPI.Apply(col_prim)\nPhysxSchema.PhysxCollisionAPI.Apply(col_prim)\n# Create a attachment point link\nlink = RigidPrim(\nprim_path=link_prim.GetPrimPath().__str__(),\nname=f\"{self._name}:{link_name}\",\n)\nlink.disable_collisions()\n# TODO (eric): Should we disable gravity for this link?\n# link.disable_gravity()\nlink.visible = False\n# Set a very small mass\nlink.mass = 1e-6\nself._links[link_name] = link\n# Create an attachment between the root link (ClothPrim) and the newly created attachment point link (RigidPrim)\nattachment_path = self.root_link.prim.GetPath().AppendElementString(\"attachment\")\nomni.kit.commands.execute(\"CreatePhysicsAttachment\", target_attachment_path=attachment_path,\nactor0_path=self.root_link.prim.GetPath(), actor1_path=link.prim.GetPath())\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.disable_gravity","title":"<code>disable_gravity()</code>","text":"<p>Disables gravity for this entity</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def disable_gravity(self) -&gt; None:\n\"\"\"\n    Disables gravity for this entity\n    \"\"\"\nfor link in self._links.values():\nlink.disable_gravity()\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.enable_gravity","title":"<code>enable_gravity()</code>","text":"<p>Enables gravity for this entity</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def enable_gravity(self) -&gt; None:\n\"\"\"\n    Enables gravity for this entity\n    \"\"\"\nfor link in self._links.values():\nlink.enable_gravity()\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_angular_velocity","title":"<code>get_angular_velocity()</code>","text":"<p>Gets the angular velocity of the root prim in stage.</p> <p>Returns:</p> Name Type Description <code>velocity</code> <code>np.ndarray</code> <p>angular velocity to set the rigid prim to, in the world frame. Shape (3,).</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def get_angular_velocity(self):\n\"\"\"Gets the angular velocity of the root prim in stage.\n    Returns:\n        velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\nreturn self.root_link.get_angular_velocity()\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_joint_efforts","title":"<code>get_joint_efforts(normalized=False)</code>","text":"<p>Grabs this entity's joint efforts</p> <p>Parameters:</p> Name Type Description Default <code>normalized</code> <code>bool</code> <p>Whether returned values should be normalized to range [-1, 1] based on limits or not.</p> <code>False</code> <p>Returns:</p> Type Description <p>n-array: n-DOF length array of efforts</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def get_joint_efforts(self, normalized=False):\n\"\"\"\n    Grabs this entity's joint efforts\n    Args:\n        normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n    Returns:\n        n-array: n-DOF length array of efforts\n    \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\njoint_efforts = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)[\"effort\"]\n# Possibly normalize values when returning\nreturn self._normalize_efforts(efforts=joint_efforts) if normalized else joint_efforts\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_joint_positions","title":"<code>get_joint_positions(normalized=False)</code>","text":"<p>Grabs this entity's joint positions</p> <p>Parameters:</p> Name Type Description Default <code>normalized</code> <code>bool</code> <p>Whether returned values should be normalized to range [-1, 1] based on limits or not.</p> <code>False</code> <p>Returns:</p> Type Description <p>n-array: n-DOF length array of positions</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def get_joint_positions(self, normalized=False):\n\"\"\"\n    Grabs this entity's joint positions\n    Args:\n        normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n    Returns:\n        n-array: n-DOF length array of positions\n    \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\njoint_positions = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)[\"pos\"]\n# Possibly normalize values when returning\nreturn self._normalize_positions(positions=joint_positions) if normalized else joint_positions\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_joint_velocities","title":"<code>get_joint_velocities(normalized=False)</code>","text":"<p>Grabs this entity's joint velocities</p> <p>Parameters:</p> Name Type Description Default <code>normalized</code> <code>bool</code> <p>Whether returned values should be normalized to range [-1, 1] based on limits or not.</p> <code>False</code> <p>Returns:</p> Type Description <p>n-array: n-DOF length array of velocities</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def get_joint_velocities(self, normalized=False):\n\"\"\"\n    Grabs this entity's joint velocities\n    Args:\n        normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n    Returns:\n        n-array: n-DOF length array of velocities\n    \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\njoint_velocities = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)[\"vel\"]\n# Possibly normalize values when returning\nreturn self._normalize_velocities(velocities=joint_velocities) if normalized else joint_velocities\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_linear_velocity","title":"<code>get_linear_velocity()</code>","text":"<p>Gets the linear velocity of the root prim in stage.</p> <p>Returns:</p> Name Type Description <code>velocity</code> <code>np.ndarray</code> <p>linear velocity to set the rigid prim to, in the world frame. Shape (3,).</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def get_linear_velocity(self):\n\"\"\"\n    Gets the linear velocity of the root prim in stage.\n    Returns:\n        velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\nreturn self.root_link.get_linear_velocity()\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.keep_still","title":"<code>keep_still()</code>","text":"<p>Zero out all velocities for this prim</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def keep_still(self):\n\"\"\"\n    Zero out all velocities for this prim\n    \"\"\"\nself.set_linear_velocity(velocity=np.zeros(3))\nself.set_angular_velocity(velocity=np.zeros(3))\nfor joint in self._joints.values():\njoint.keep_still()\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_angular_velocity","title":"<code>set_angular_velocity(velocity)</code>","text":"<p>Sets the angular velocity of the root prim in stage.</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>np.ndarray</code> <p>angular velocity to set the rigid prim to, in the world frame. Shape (3,).</p> required Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def set_angular_velocity(self, velocity):\n\"\"\"\n    Sets the angular velocity of the root prim in stage.\n    Args:\n        velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\nself.root_link.set_angular_velocity(velocity)\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_joint_efforts","title":"<code>set_joint_efforts(efforts, indices=None, normalized=False)</code>","text":"<p>Set the joint efforts (both actual value and target values) in simulation. Note: only works if the simulator is actively running!</p> <p>Parameters:</p> Name Type Description Default <code>efforts</code> <code>np.ndarray</code> <p>efforts to set. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @efforts must be the same length as @indices!</p> required <code>indices</code> <code>None or k-array</code> <p>If specified, should be k (k &lt; n) length array of specific DOF efforts to set. Default is None, which assumes that all joints are being set.</p> <code>None</code> <code>normalized</code> <code>bool</code> <p>Whether the inputted joint efforts should be interpreted as normalized values. Default is False</p> <code>False</code> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def set_joint_efforts(self, efforts, indices=None, normalized=False):\n\"\"\"\n    Set the joint efforts (both actual value and target values) in simulation. Note: only works if the simulator\n    is actively running!\n    Args:\n        efforts (np.ndarray): efforts to set. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @efforts must\n            be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF efforts to set.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool): Whether the inputted joint efforts should be interpreted as normalized values. Default\n            is False\n    \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\n# Possibly de-normalize the inputs\nif normalized:\nefforts = self._denormalize_efforts(efforts=efforts, indices=indices)\n# Grab current DOF states\ndof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)\n# Possibly set specific values in the array if indies are specified\nif indices is None:\nnew_efforts = efforts\nelse:\nnew_efforts = dof_states[\"effort\"]\nnew_efforts[indices] = efforts\n# Set the DOF states\ndof_states[\"effort\"] = new_efforts\nself._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_EFFORT)\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_joint_positions","title":"<code>set_joint_positions(positions, indices=None, normalized=False, drive=False)</code>","text":"<p>Set the joint positions (both actual value and target values) in simulation. Note: only works if the simulator is actively running!</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>np.ndarray</code> <p>positions to set. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @positions must be the same length as @indices!</p> required <code>indices</code> <code>None or k-array</code> <p>If specified, should be k (k &lt; n) length array of specific DOF positions to set. Default is None, which assumes that all joints are being set.</p> <code>None</code> <code>normalized</code> <code>bool</code> <p>Whether the inputted joint positions should be interpreted as normalized values. Default is False</p> <code>False</code> <code>drive</code> <code>bool</code> <p>Whether the positions being set are values that should be driven naturally by this entity's motors or manual values to immediately set. Default is False, corresponding to an instantaneous setting of the positions</p> <code>False</code> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def set_joint_positions(self, positions, indices=None, normalized=False, drive=False):\n\"\"\"\n    Set the joint positions (both actual value and target values) in simulation. Note: only works if the simulator\n    is actively running!\n    Args:\n        positions (np.ndarray): positions to set. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @positions must\n            be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF positions to set.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool): Whether the inputted joint positions should be interpreted as normalized values. Default\n            is False\n        drive (bool): Whether the positions being set are values that should be driven naturally by this entity's\n            motors or manual values to immediately set. Default is False, corresponding to an instantaneous\n            setting of the positions\n    \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\n# Possibly de-normalize the inputs\nif normalized:\npositions = self._denormalize_positions(positions=positions, indices=indices)\n# Grab current DOF states\ndof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)\n# Possibly set specific values in the array if indies are specified\nif indices is None:\nassert len(positions) == self._n_dof, \\\n            \"set_joint_positions called without specifying indices, but the desired positions do not match n_dof.\"\nnew_positions = positions\nelse:\nnew_positions = dof_states[\"pos\"]\nnew_positions[indices] = positions\n# Set the DOF states\ndof_states[\"pos\"] = new_positions\nif not drive:\nself._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_POS)\n# Also set the target\nself._dc.set_articulation_dof_position_targets(self._handle, new_positions.astype(np.float32))\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_joint_velocities","title":"<code>set_joint_velocities(velocities, indices=None, normalized=False, drive=False)</code>","text":"<p>Set the joint velocities (both actual value and target values) in simulation. Note: only works if the simulator is actively running!</p> <p>Parameters:</p> Name Type Description Default <code>velocities</code> <code>np.ndarray</code> <p>velocities to set. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @velocities must be the same length as @indices!</p> required <code>indices</code> <code>None or k-array</code> <p>If specified, should be k (k &lt; n) length array of specific DOF velocities to set. Default is None, which assumes that all joints are being set.</p> <code>None</code> <code>normalized</code> <code>bool</code> <p>Whether the inputted joint velocities should be interpreted as normalized values. Default is False</p> <code>False</code> <code>drive</code> <code>bool</code> <p>Whether the velocities being set are values that should be driven naturally by this entity's motors or manual values to immediately set. Default is False, corresponding to an instantaneous setting of the velocities</p> <code>False</code> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def set_joint_velocities(self, velocities, indices=None, normalized=False, drive=False):\n\"\"\"\n    Set the joint velocities (both actual value and target values) in simulation. Note: only works if the simulator\n    is actively running!\n    Args:\n        velocities (np.ndarray): velocities to set. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @velocities must\n            be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF velocities to set.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool): Whether the inputted joint velocities should be interpreted as normalized values. Default\n            is False\n        drive (bool): Whether the velocities being set are values that should be driven naturally by this entity's\n            motors or manual values to immediately set. Default is False, corresponding to an instantaneous\n            setting of the velocities\n    \"\"\"\n# Run sanity checks -- make sure our handle is initialized and that we are articulated\nassert self._handle is not None, \"handles are not initialized yet!\"\nassert self.n_joints &gt; 0, \"Tried to call method not intended for entity prim with no joints!\"\n# Possibly de-normalize the inputs\nif normalized:\nvelocities = self._denormalize_velocities(velocities=velocities, indices=indices)\n# Grab current DOF states\ndof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)\n# Possibly set specific values in the array if indies are specified\nif indices is None:\nnew_velocities = velocities\nelse:\nnew_velocities = dof_states[\"vel\"]\nnew_velocities[indices] = velocities\n# Set the DOF states\ndof_states[\"vel\"] = new_velocities\nif not drive:\nself._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_VEL)\n# Also set the target\nself._dc.set_articulation_dof_velocity_targets(self._handle, new_velocities.astype(np.float32))\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_linear_velocity","title":"<code>set_linear_velocity(velocity)</code>","text":"<p>Sets the linear velocity of the root prim in stage.</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>np.ndarray</code> <p>linear velocity to set the rigid prim to, in the world frame. Shape (3,).</p> required Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def set_linear_velocity(self, velocity: np.ndarray):\n\"\"\"\n    Sets the linear velocity of the root prim in stage.\n    Args:\n        velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\nself.root_link.set_linear_velocity(velocity)\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.sleep","title":"<code>sleep()</code>","text":"<p>Disable physics for this articulation</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def sleep(self):\n\"\"\"\n    Disable physics for this articulation\n    \"\"\"\nif self.articulated:\nself._dc.sleep_articulation(self._handle)\nelse:\nfor link in self._links.values():\nlink.sleep()\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.update_handles","title":"<code>update_handles()</code>","text":"<p>Updates all internal handles for this prim, in case they change since initialization</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def update_handles(self):\n\"\"\"\n    Updates all internal handles for this prim, in case they change since initialization\n    \"\"\"\nassert og.sim.is_playing(), \"Simulator must be playing if updating handles!\"\n# Grab the handle -- we know it might not return a valid value, so we suppress omni's warning here\nself._handle = None if self.articulation_root_path is None else \\\n        self._dc.get_articulation(self.articulation_root_path)\n# Sanity check -- make sure handle is not invalid handle -- it should only ever be None or a valid integer\nassert self._handle != _dynamic_control.INVALID_HANDLE, \\\n        f\"Got invalid articulation handle for entity at {self.articulation_root_path}\"\n# We only have a root handle if we're not a cloth prim\nif self._prim_type != PrimType.CLOTH:\nself._root_handle = self._dc.get_articulation_root_body(self._handle) if \\\n            self._handle is not None else self.root_link.handle\n# Update all links and joints as well\nfor link in self._links.values():\nif not link.initialized:\nlink.initialize()\nlink.update_handles()\nfor joint in self._joints.values():\nif not joint.initialized:\njoint.initialize()\njoint.update_handles()\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.update_joints","title":"<code>update_joints()</code>","text":"<p>Helper function to refresh owned joints. Useful for synchronizing internal data if additional bodies are added manually</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def update_joints(self):\n\"\"\"\n    Helper function to refresh owned joints. Useful for synchronizing internal data if\n    additional bodies are added manually\n    \"\"\"\n# Make sure to clean up all pre-existing names for all joints\nif self._joints is not None:\nfor joint in self._joints.values():\njoint.remove_names()\n# Initialize joints dictionary\nself._joints = dict()\nself.update_handles()\n# Handle case separately based on whether the handle is valid (i.e.: whether we are actually articulated or not)\nif (not self.kinematic_only) and self._handle is not None:\nroot_prim = get_prim_at_path(self._dc.get_rigid_body_path(self._root_handle))\nn_dof = self._dc.get_articulation_dof_count(self._handle)\n# Additionally grab DOF info if we have non-fixed joints\nif n_dof &gt; 0:\nself._dofs_infos = dict()\n# Grab DOF info\nfor index in range(n_dof):\ndof_handle = self._dc.get_articulation_dof(self._handle, index)\ndof_name = self._dc.get_dof_name(dof_handle)\n# add dof to list\nprim_path = self._dc.get_dof_path(dof_handle)\nself._dofs_infos[dof_name] = DOFInfo(prim_path=prim_path, handle=dof_handle, prim=self.prim,\nindex=index)\nfor i in range(self._dc.get_articulation_joint_count(self._handle)):\njoint_handle = self._dc.get_articulation_joint(self._handle, i)\njoint_name = self._dc.get_joint_name(joint_handle)\njoint_path = self._dc.get_joint_path(joint_handle)\njoint_prim = get_prim_at_path(joint_path)\n# Only add the joint if it's not fixed (i.e.: it has DOFs &gt; 0)\nif self._dc.get_joint_dof_count(joint_handle) &gt; 0:\njoint = JointPrim(\nprim_path=joint_path,\nname=f\"{self._name}:joint_{joint_name}\",\narticulation=self._handle,\n)\njoint.initialize()\nself._joints[joint_name] = joint\nelse:\n# TODO: May need to extend to clusters of rigid bodies, that aren't exactly joined\n# We assume this object contains a single rigid body\nbody_path = f\"{self._prim_path}/{self.root_link_name}\"\nroot_prim = get_prim_at_path(body_path)\nn_dof = 0\n# Make sure root prim stored is the same as the one found during initialization\nassert self.root_prim == root_prim, \\\n        f\"Mismatch in root prims! Original was {self.root_prim.GetPrimPath()}, \" \\\n        f\"initialized is {root_prim.GetPrimPath()}!\"\n# Store values internally\nself._n_dof = n_dof\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.update_links","title":"<code>update_links()</code>","text":"<p>Helper function to refresh owned joints. Useful for synchronizing internal data if additional bodies are added manually</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def update_links(self):\n\"\"\"\n    Helper function to refresh owned joints. Useful for synchronizing internal data if\n    additional bodies are added manually\n    \"\"\"\n# Make sure to clean up all pre-existing names for all links\nif self._links is not None:\nfor link in self._links.values():\nlink.remove_names()\n# We iterate over all children of this object's prim,\n# and grab any that are presumed to be rigid bodies (i.e.: other Xforms)\nself._links = dict()\njoint_children = set()\nfor prim in self._prim.GetChildren():\nlink = None\nlink_name = prim.GetName()\nif self._prim_type == PrimType.RIGID and prim.GetPrimTypeInfo().GetTypeName() == \"Xform\":\n# For rigid body object, process prims that are Xforms (e.g. rigid links)\nlink = RigidPrim(\nprim_path=prim.GetPrimPath().__str__(),\nname=f\"{self._name}:{link_name}\",\n)\n# Also iterate through all children to infer joints and determine the children of those joints\n# We will use this info to infer which link is the base link!\nfor child_prim in prim.GetChildren():\nif \"joint\" in child_prim.GetPrimTypeInfo().GetTypeName().lower():\n# Store the child target of this joint\nrelationships = {r.GetName(): r for r in child_prim.GetRelationships()}\n# Only record if this is NOT a fixed link tying us to the world (i.e.: no target for body0)\nif len(relationships[\"physics:body0\"].GetTargets()) &gt; 0:\njoint_children.add(relationships[\"physics:body1\"].GetTargets()[0].pathString.split(\"/\")[-1])\nif self._prim_type == PrimType.CLOTH and prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\n# For cloth object, process prims that belong to any of the GEOM_TYPES (e.g. Cube, Mesh, etc)\nlink = ClothPrim(\nprim_path=prim.GetPrimPath().__str__(),\nname=f\"{self._name}:{link_name}\",\n)\nif link is not None:\nself._links[link_name] = link\n# Infer the correct root link name -- this corresponds to whatever link does not have any joint existing\n# in the children joints\nvalid_root_links = list(set(self._links.keys()) - joint_children)\n# TODO: Uncomment safety check here after we figure out how to handle legacy multi-bodied assets like bed with pillow\n# assert len(valid_root_links) == 1, f\"Only a single root link should have been found for this entity prim, \" \\\n#                                    f\"but found multiple instead: {valid_root_links}\"\nself._root_link_name = valid_root_links[0] if len(valid_root_links) == 1 else \"base_link\"\n</code></pre>"},{"location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.wake","title":"<code>wake()</code>","text":"<p>Enable physics for this articulation</p> Source code in <code>omnigibson/prims/entity_prim.py</code> <pre><code>def wake(self):\n\"\"\"\n    Enable physics for this articulation\n    \"\"\"\nif self.articulated:\nself._dc.wake_up_articulation(self._handle)\nelse:\nfor link in self._links.values():\nlink.wake()\n</code></pre>"},{"location":"reference/prims/geom_prim.html","title":"geom_prim","text":""},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim","title":"<code>CollisionGeomPrim</code>","text":"<p>         Bases: <code>GeomPrim</code></p> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>class CollisionGeomPrim(GeomPrim):\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\n# Store values created at runtime\nself._collision_api = None\nself._mesh_collision_api = None\nself._physx_collision_api = None\nself._applied_physics_material = None\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# By default, CollisionGeomPrim does not show up in the rendering.\nself.purpose = \"guide\"\n# Create API references\nself._collision_api = UsdPhysics.CollisionAPI(self._prim) if \\\n            self._prim.HasAPI(UsdPhysics.CollisionAPI) else UsdPhysics.CollisionAPI.Apply(self._prim)\nself._physx_collision_api = PhysxSchema.PhysxCollisionAPI(self._prim) if \\\n            self._prim.HasAPI(PhysxSchema.PhysxCollisionAPI) else PhysxSchema.PhysxCollisionAPI.Apply(self._prim)\n# Optionally add mesh collision API if this is a mesh\nif self._prim.GetPrimTypeInfo().GetTypeName() == \"Mesh\":\nself._mesh_collision_api = UsdPhysics.MeshCollisionAPI(self._prim) if \\\n                self._prim.HasAPI(UsdPhysics.MeshCollisionAPI) else UsdPhysics.MeshCollisionAPI.Apply(self._prim)\n# Set the approximation to be convex hull by default\nself.set_collision_approximation(approximation_type=\"convexHull\")\n@property\ndef collision_enabled(self):\n\"\"\"\n        Returns:\n            bool: Whether collisions are enabled for this collision mesh\n        \"\"\"\nreturn self.get_attribute(\"physics:collisionEnabled\")\n@collision_enabled.setter\ndef collision_enabled(self, enabled):\n\"\"\"\n        Sets whether collisions are enabled for this mesh\n        Args:\n            enabled (bool): Whether collisions should be enabled for this mesh\n        \"\"\"\n# Currently, trying to toggle while simulator is playing while using GPU dynamics results in a crash, so we\n# assert that the sim is stopped here\nif self._initialized and gm.USE_GPU_DYNAMICS:\nassert og.sim.is_stopped(), \"Cannot toggle collisions while using GPU dynamics unless simulator is stopped!\"\nself.set_attribute(\"physics:collisionEnabled\", enabled)\n# TODO: Maybe this should all be added to RigidPrim instead?\ndef set_contact_offset(self, offset):\n\"\"\"\n        Args:\n            offset (float): Contact offset of a collision shape. Allowed range [maximum(0, rest_offset), 0].\n                            Default value is -inf, means default is picked by simulation based on the shape extent.\n        \"\"\"\nself._physx_collision_api.GetContactOffsetAttr().Set(offset)\nreturn\ndef get_contact_offset(self):\n\"\"\"\n        Returns:\n            float: contact offset of the collision shape.\n        \"\"\"\nreturn self._physx_collision_api.GetContactOffsetAttr().Get()\ndef set_rest_offset(self, offset):\n\"\"\"\n        Args:\n            offset (float): Rest offset of a collision shape. Allowed range [-max_float, contact_offset.\n                            Default value is -inf, means default is picked by simulatiion. For rigid bodies its zero.\n        \"\"\"\nself._physx_collision_api.GetRestOffsetAttr().Set(offset)\nreturn\ndef get_rest_offset(self):\n\"\"\"\n        Returns:\n            float: rest offset of the collision shape.\n        \"\"\"\nreturn self._physx_collision_api.GetRestOffsetAttr().Get()\ndef set_torsional_patch_radius(self, radius):\n\"\"\"\n        Args:\n            radius (float): radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\nself._physx_collision_api.GetTorsionalPatchRadiusAttr().Set(radius)\nreturn\ndef get_torsional_patch_radius(self):\n\"\"\"\n        Returns:\n            float: radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\nreturn self._physx_collision_api.GetTorsionalPatchRadiusAttr().Get()\ndef set_min_torsional_patch_radius(self, radius):\n\"\"\"\n        Args:\n            radius (float): minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\nself._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Set(radius)\nreturn\ndef get_min_torsional_patch_radius(self):\n\"\"\"\n        Returns:\n            float: minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\nreturn self._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Get()\ndef set_collision_approximation(self, approximation_type):\n\"\"\"\n        Args:\n            approximation_type (str): approximation used for collision.\n                Can be one of: {\"none\", \"convexHull\", \"convexDecomposition\", \"meshSimplification\", \"sdf\",\n                    \"boundingSphere\", \"boundingCube\"}\n                If None, the approximation will use the underlying triangle mesh.\n        \"\"\"\nassert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\nassert_valid_key(\nkey=approximation_type,\nvalid_keys={\"none\", \"convexHull\", \"convexDecomposition\", \"meshSimplification\", \"sdf\", \"boundingSphere\", \"boundingCube\"},\nname=\"collision approximation type\",\n)\n# Make sure to add the appropriate API if we're setting certain values\nif approximation_type == \"convexHull\" and not self._prim.HasAPI(PhysxSchema.PhysxConvexHullCollisionAPI):\nPhysxSchema.PhysxConvexHullCollisionAPI.Apply(self._prim)\nelif approximation_type == \"convexDecomposition\" and not self._prim.HasAPI(PhysxSchema.PhysxConvexDecompositionCollisionAPI):\nPhysxSchema.PhysxConvexDecompositionCollisionAPI.Apply(self._prim)\nelif approximation_type == \"meshSimplification\" and not self._prim.HasAPI(PhysxSchema.PhysxTriangleMeshSimplificationCollisionAPI):\nPhysxSchema.PhysxTriangleMeshSimplificationCollisionAPI.Apply(self._prim)\nelif approximation_type == \"sdf\" and not self._prim.HasAPI(PhysxSchema.PhysxSDFMeshCollisionAPI):\nPhysxSchema.PhysxSDFMeshCollisionAPI.Apply(self._prim)\nelif approximation_type == \"none\" and not self._prim.HasAPI(PhysxSchema.PhysxTriangleMeshCollisionAPI):\nPhysxSchema.PhysxTriangleMeshCollisionAPI.Apply(self._prim)\nif approximation_type == \"convexHull\":\npch_api = PhysxSchema.PhysxConvexHullCollisionAPI(self._prim)\n# Also make sure the maximum vertex count is 60 (max number compatible with GPU)\n# https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html#collision-settings\nif pch_api.GetHullVertexLimitAttr().Get() is None:\npch_api.CreateHullVertexLimitAttr()\npch_api.GetHullVertexLimitAttr().Set(60)\nself._mesh_collision_api.GetApproximationAttr().Set(approximation_type)\ndef get_collision_approximation(self):\n\"\"\"\n        Returns:\n            str: approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"\n        \"\"\"\nassert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\nreturn self._mesh_collision_api.GetApproximationAttr().Get()\ndef apply_physics_material(self, physics_material, weaker_than_descendants=False):\n\"\"\"\n        Used to apply physics material to the held prim and optionally its descendants.\n        Args:\n            physics_material (PhysicsMaterial): physics material to be applied to the held prim. This where you want to\n                                                define friction, restitution..etc. Note: if a physics material is not\n                                                defined, the defaults will be used from PhysX.\n            weaker_than_descendants (bool, optional): True if the material shouldn't override the descendants\n                                                      materials, otherwise False. Defaults to False.\n        \"\"\"\nif self._binding_api is None:\nif self._prim.HasAPI(UsdShade.MaterialBindingAPI):\nself._binding_api = UsdShade.MaterialBindingAPI(self.prim)\nelse:\nself._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\nif weaker_than_descendants:\nself._binding_api.Bind(\nphysics_material.material,\nbindingStrength=UsdShade.Tokens.weakerThanDescendants,\nmaterialPurpose=\"physics\",\n)\nelse:\nself._binding_api.Bind(\nphysics_material.material,\nbindingStrength=UsdShade.Tokens.strongerThanDescendants,\nmaterialPurpose=\"physics\",\n)\nself._applied_physics_material = physics_material\nreturn\ndef get_applied_physics_material(self):\n\"\"\"\n        Returns the current applied physics material in case it was applied using apply_physics_material or not.\n        Returns:\n            PhysicsMaterial: the current applied physics material.\n        \"\"\"\nif self._binding_api is None:\nif self._prim.HasAPI(UsdShade.MaterialBindingAPI):\nself._binding_api = UsdShade.MaterialBindingAPI(self.prim)\nelse:\nself._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\nif self._applied_physics_material is not None:\nreturn self._applied_physics_material\nelse:\nphysics_binding = self._binding_api.GetDirectBinding(materialPurpose=\"physics\")\npath = physics_binding.GetMaterialPath()\nif path == \"\":\nreturn None\nelse:\nself._applied_physics_material = PhysicsMaterial(prim_path=path)\nreturn self._applied_physics_material\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.collision_enabled","title":"<code>collision_enabled</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether collisions are enabled for this collision mesh</p>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.apply_physics_material","title":"<code>apply_physics_material(physics_material, weaker_than_descendants=False)</code>","text":"<p>Used to apply physics material to the held prim and optionally its descendants.</p> <p>Parameters:</p> Name Type Description Default <code>physics_material</code> <code>PhysicsMaterial</code> <p>physics material to be applied to the held prim. This where you want to                                 define friction, restitution..etc. Note: if a physics material is not                                 defined, the defaults will be used from PhysX.</p> required <code>weaker_than_descendants</code> <code>bool</code> <p>True if the material shouldn't override the descendants                                       materials, otherwise False. Defaults to False.</p> <code>False</code> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def apply_physics_material(self, physics_material, weaker_than_descendants=False):\n\"\"\"\n    Used to apply physics material to the held prim and optionally its descendants.\n    Args:\n        physics_material (PhysicsMaterial): physics material to be applied to the held prim. This where you want to\n                                            define friction, restitution..etc. Note: if a physics material is not\n                                            defined, the defaults will be used from PhysX.\n        weaker_than_descendants (bool, optional): True if the material shouldn't override the descendants\n                                                  materials, otherwise False. Defaults to False.\n    \"\"\"\nif self._binding_api is None:\nif self._prim.HasAPI(UsdShade.MaterialBindingAPI):\nself._binding_api = UsdShade.MaterialBindingAPI(self.prim)\nelse:\nself._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\nif weaker_than_descendants:\nself._binding_api.Bind(\nphysics_material.material,\nbindingStrength=UsdShade.Tokens.weakerThanDescendants,\nmaterialPurpose=\"physics\",\n)\nelse:\nself._binding_api.Bind(\nphysics_material.material,\nbindingStrength=UsdShade.Tokens.strongerThanDescendants,\nmaterialPurpose=\"physics\",\n)\nself._applied_physics_material = physics_material\nreturn\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_applied_physics_material","title":"<code>get_applied_physics_material()</code>","text":"<p>Returns the current applied physics material in case it was applied using apply_physics_material or not.</p> <p>Returns:</p> Name Type Description <code>PhysicsMaterial</code> <p>the current applied physics material.</p> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def get_applied_physics_material(self):\n\"\"\"\n    Returns the current applied physics material in case it was applied using apply_physics_material or not.\n    Returns:\n        PhysicsMaterial: the current applied physics material.\n    \"\"\"\nif self._binding_api is None:\nif self._prim.HasAPI(UsdShade.MaterialBindingAPI):\nself._binding_api = UsdShade.MaterialBindingAPI(self.prim)\nelse:\nself._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\nif self._applied_physics_material is not None:\nreturn self._applied_physics_material\nelse:\nphysics_binding = self._binding_api.GetDirectBinding(materialPurpose=\"physics\")\npath = physics_binding.GetMaterialPath()\nif path == \"\":\nreturn None\nelse:\nself._applied_physics_material = PhysicsMaterial(prim_path=path)\nreturn self._applied_physics_material\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_collision_approximation","title":"<code>get_collision_approximation()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"</p> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def get_collision_approximation(self):\n\"\"\"\n    Returns:\n        str: approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"\n    \"\"\"\nassert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\nreturn self._mesh_collision_api.GetApproximationAttr().Get()\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_contact_offset","title":"<code>get_contact_offset()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>contact offset of the collision shape.</p> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def get_contact_offset(self):\n\"\"\"\n    Returns:\n        float: contact offset of the collision shape.\n    \"\"\"\nreturn self._physx_collision_api.GetContactOffsetAttr().Get()\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_min_torsional_patch_radius","title":"<code>get_min_torsional_patch_radius()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def get_min_torsional_patch_radius(self):\n\"\"\"\n    Returns:\n        float: minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\nreturn self._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Get()\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_rest_offset","title":"<code>get_rest_offset()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>rest offset of the collision shape.</p> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def get_rest_offset(self):\n\"\"\"\n    Returns:\n        float: rest offset of the collision shape.\n    \"\"\"\nreturn self._physx_collision_api.GetRestOffsetAttr().Get()\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_torsional_patch_radius","title":"<code>get_torsional_patch_radius()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def get_torsional_patch_radius(self):\n\"\"\"\n    Returns:\n        float: radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\nreturn self._physx_collision_api.GetTorsionalPatchRadiusAttr().Get()\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_collision_approximation","title":"<code>set_collision_approximation(approximation_type)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>approximation_type</code> <code>str</code> <p>approximation used for collision. Can be one of: {\"none\", \"convexHull\", \"convexDecomposition\", \"meshSimplification\", \"sdf\",     \"boundingSphere\", \"boundingCube\"} If None, the approximation will use the underlying triangle mesh.</p> required Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def set_collision_approximation(self, approximation_type):\n\"\"\"\n    Args:\n        approximation_type (str): approximation used for collision.\n            Can be one of: {\"none\", \"convexHull\", \"convexDecomposition\", \"meshSimplification\", \"sdf\",\n                \"boundingSphere\", \"boundingCube\"}\n            If None, the approximation will use the underlying triangle mesh.\n    \"\"\"\nassert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\nassert_valid_key(\nkey=approximation_type,\nvalid_keys={\"none\", \"convexHull\", \"convexDecomposition\", \"meshSimplification\", \"sdf\", \"boundingSphere\", \"boundingCube\"},\nname=\"collision approximation type\",\n)\n# Make sure to add the appropriate API if we're setting certain values\nif approximation_type == \"convexHull\" and not self._prim.HasAPI(PhysxSchema.PhysxConvexHullCollisionAPI):\nPhysxSchema.PhysxConvexHullCollisionAPI.Apply(self._prim)\nelif approximation_type == \"convexDecomposition\" and not self._prim.HasAPI(PhysxSchema.PhysxConvexDecompositionCollisionAPI):\nPhysxSchema.PhysxConvexDecompositionCollisionAPI.Apply(self._prim)\nelif approximation_type == \"meshSimplification\" and not self._prim.HasAPI(PhysxSchema.PhysxTriangleMeshSimplificationCollisionAPI):\nPhysxSchema.PhysxTriangleMeshSimplificationCollisionAPI.Apply(self._prim)\nelif approximation_type == \"sdf\" and not self._prim.HasAPI(PhysxSchema.PhysxSDFMeshCollisionAPI):\nPhysxSchema.PhysxSDFMeshCollisionAPI.Apply(self._prim)\nelif approximation_type == \"none\" and not self._prim.HasAPI(PhysxSchema.PhysxTriangleMeshCollisionAPI):\nPhysxSchema.PhysxTriangleMeshCollisionAPI.Apply(self._prim)\nif approximation_type == \"convexHull\":\npch_api = PhysxSchema.PhysxConvexHullCollisionAPI(self._prim)\n# Also make sure the maximum vertex count is 60 (max number compatible with GPU)\n# https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html#collision-settings\nif pch_api.GetHullVertexLimitAttr().Get() is None:\npch_api.CreateHullVertexLimitAttr()\npch_api.GetHullVertexLimitAttr().Set(60)\nself._mesh_collision_api.GetApproximationAttr().Set(approximation_type)\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_contact_offset","title":"<code>set_contact_offset(offset)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>offset</code> <code>float</code> <p>Contact offset of a collision shape. Allowed range [maximum(0, rest_offset), 0].             Default value is -inf, means default is picked by simulation based on the shape extent.</p> required Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def set_contact_offset(self, offset):\n\"\"\"\n    Args:\n        offset (float): Contact offset of a collision shape. Allowed range [maximum(0, rest_offset), 0].\n                        Default value is -inf, means default is picked by simulation based on the shape extent.\n    \"\"\"\nself._physx_collision_api.GetContactOffsetAttr().Set(offset)\nreturn\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_min_torsional_patch_radius","title":"<code>set_min_torsional_patch_radius(radius)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>radius</code> <code>float</code> <p>minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p> required Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def set_min_torsional_patch_radius(self, radius):\n\"\"\"\n    Args:\n        radius (float): minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\nself._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Set(radius)\nreturn\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_rest_offset","title":"<code>set_rest_offset(offset)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>offset</code> <code>float</code> <p>Rest offset of a collision shape. Allowed range [-max_float, contact_offset.             Default value is -inf, means default is picked by simulatiion. For rigid bodies its zero.</p> required Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def set_rest_offset(self, offset):\n\"\"\"\n    Args:\n        offset (float): Rest offset of a collision shape. Allowed range [-max_float, contact_offset.\n                        Default value is -inf, means default is picked by simulatiion. For rigid bodies its zero.\n    \"\"\"\nself._physx_collision_api.GetRestOffsetAttr().Set(offset)\nreturn\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_torsional_patch_radius","title":"<code>set_torsional_patch_radius(radius)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>radius</code> <code>float</code> <p>radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p> required Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>def set_torsional_patch_radius(self, radius):\n\"\"\"\n    Args:\n        radius (float): radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\nself._physx_collision_api.GetTorsionalPatchRadiusAttr().Set(radius)\nreturn\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim","title":"<code>GeomPrim</code>","text":"<p>         Bases: <code>XFormPrim</code></p> <p>Provides high level functions to deal with a geom prim and its attributes / properties. If there is an geom prim present at the path, it will use it. By default, a geom prim cannot be directly created from scratch.at</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. For this mesh prim, the below values can be specified:</p> <code>None</code> Source code in <code>omnigibson/prims/geom_prim.py</code> <pre><code>class GeomPrim(XFormPrim):\n\"\"\"\n    Provides high level functions to deal with a geom prim and its attributes / properties.\n    If there is an geom prim present at the path, it will use it. By default, a geom prim cannot be directly\n    created from scratch.at\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. For this mesh prim, the below values can be specified:\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _load(self):\n# This should not be called, because this prim cannot be instantiated from scratch!\nraise NotImplementedError(\"By default, a geom prim cannot be created from scratch.\")\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# By default, GeomPrim shows up in the rendering.\nself.purpose = \"default\"\ndef duplicate(self, prim_path):\n# Cannot directly duplicate a mesh prim\nraise NotImplementedError(\"Cannot directly duplicate a geom prim!\")\n@property\ndef purpose(self):\n\"\"\"\n        Returns:\n            str: the purpose used for this geom, one of {\"default\", \"render\", \"proxy\", \"guide\"}\n        \"\"\"\nreturn self.get_attribute(\"purpose\")\n@purpose.setter\ndef purpose(self, purpose):\n\"\"\"\n        Sets the purpose of this geom\n        Args:\n            purpose (str): the purpose used for this geom, one of {\"default\", \"render\", \"proxy\", \"guide\"}\n        \"\"\"\nself.set_attribute(\"purpose\", purpose)\n@property\ndef color(self):\n\"\"\"\n        Returns:\n            None or 3-array: If set, the default RGB color used for this visual geom\n        \"\"\"\nif self.has_material():\nreturn self.material.diffuse_color_constant\nelse:\ncolor = self.get_attribute(\"primvars:displayColor\")\nreturn None if color is None else np.array(color)[0]\n@color.setter\ndef color(self, rgb):\n\"\"\"\n        Sets the RGB color of this visual mesh\n        Args:\n            3-array: The default RGB color used for this visual geom\n        \"\"\"\nif self.has_material():\nself.material.diffuse_color_constant = rgb\nelse:\nself.set_attribute(\"primvars:displayColor\", np.array(rgb))\n@property\ndef opacity(self):\n\"\"\"\n        Returns:\n            None or float: If set, the default opacity used for this visual geom\n        \"\"\"\nif self.has_material():\nreturn self.material.opacity_constant\nelse:\nopacity = self.get_attribute(\"primvars:displayOpacity\")\nreturn None if opacity is None else np.array(opacity)[0]\n@opacity.setter\ndef opacity(self, opacity):\n\"\"\"\n        Sets the opacity of this visual mesh\n        Args:\n            opacity: The default opacity used for this visual geom\n        \"\"\"\nif self.has_material():\nself.material.opacity_constant = opacity\nelse:\nself.set_attribute(\"primvars:displayOpacity\", np.array([opacity]))\n</code></pre>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim.color","title":"<code>color</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or 3-array: If set, the default RGB color used for this visual geom</p>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim.opacity","title":"<code>opacity</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or float: If set, the default opacity used for this visual geom</p>"},{"location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim.purpose","title":"<code>purpose</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>the purpose used for this geom, one of {\"default\", \"render\", \"proxy\", \"guide\"}</p>"},{"location":"reference/prims/joint_prim.html","title":"joint_prim","text":""},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim","title":"<code>JointPrim</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Provides high level functions to deal with a joint prim and its attributes/ properties. If there is an joint prim present at the path, it will use it. Otherwise, a new joint prim at the specified prim path will be created when self.load(...) is called.</p> the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init, <p>unless it is a non-root articulation link.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. For this joint prim, the below values can be specified:</p> <p>joint_type (str): If specified, should be the joint type to create. Valid options are:     {\"Joint\", \"FixedJoint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"}     (equivalently, one of JointType) body0 (None or str): If specified, should be the absolute prim path to the parent body that this joint     is connected to. None can also be valid, which corresponds to cases where only a single body may be     specified (e.g.: fixed joints) body1 (None or str): If specified, should be the absolute prim path to the child body that this joint     is connected to. None can also be valid, which corresponds to cases where only a single body may be     specified (e.g.: fixed joints)</p> <code>None</code> <code>articulation</code> <code>None or int</code> <p>if specified, should be handle to pre-existing articulation. This will enable additional features for this joint prim, e.g.: polling / setting this joint's state. Note that in this case, the joint must already exist prior to this class instance. Default is None, which corresponds to a non-articulated joint.</p> <code>None</code> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>class JointPrim(BasePrim):\n\"\"\"\n    Provides high level functions to deal with a joint prim and its attributes/ properties.\n    If there is an joint prim present at the path, it will use it. Otherwise, a new joint prim at\n    the specified prim path will be created when self.load(...) is called.\n    Note: the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init,\n            unless it is a non-root articulation link.\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. For this joint prim, the below values can be specified:\n            joint_type (str): If specified, should be the joint type to create. Valid options are:\n                {\"Joint\", \"FixedJoint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"}\n                (equivalently, one of JointType)\n            body0 (None or str): If specified, should be the absolute prim path to the parent body that this joint\n                is connected to. None can also be valid, which corresponds to cases where only a single body may be\n                specified (e.g.: fixed joints)\n            body1 (None or str): If specified, should be the absolute prim path to the child body that this joint\n                is connected to. None can also be valid, which corresponds to cases where only a single body may be\n                specified (e.g.: fixed joints)\n        articulation (None or int): if specified, should be handle to pre-existing articulation. This will enable\n            additional features for this joint prim, e.g.: polling / setting this joint's state. Note that in this\n            case, the joint must already exist prior to this class instance. Default is None,\n            which corresponds to a non-articulated joint.\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\narticulation=None,\n):\n# Grab dynamic control reference and set properties\nself._art = articulation\n# Other values that will be filled in at runtime\nself._joint_type = None\nself._control_type = None\nself._dof_properties = None\nself._joint_state_api = None\nself._driven = None\n# The following values will only be valid if this joint is part of an articulation\nself._dc = None\nself._handle = None\nself._n_dof = None\nself._joint_name = None\nself._dof_handles = None\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _load(self):\n# Make sure this joint isn't articulated\nassert not self.articulated, \"Joint cannot be created, since this is an articulated joint! We are assuming\" \\\n                                     \"the joint already exists in the stage.\"\n# Define a joint prim at the current stage\nprim = create_joint(\nprim_path=self._prim_path,\njoint_type=self._load_config.get(\"joint_type\", JointType.JOINT),\n)\nreturn prim\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Check whether this joint is driven or not\nself._driven = self._prim.HasAPI(UsdPhysics.DriveAPI)\n# Add joint state API if this is a revolute or prismatic joint\nself._joint_type = JointType.get_type(self._prim.GetTypeName().split(\"Physics\")[-1])\nif self.is_single_dof:\nstate_type = \"angular\" if self._joint_type == JointType.JOINT_REVOLUTE else \"linear\"\n# We MUST already have the joint state API defined beforehand in the USD\n# This is because dc complains if we try to add physx APIs AFTER a simulation step occurs, which\n# happens because joint prims are usually created externally during an EntityPrim's initialization phase\nassert self._prim.HasAPI(PhysxSchema.JointStateAPI), \\\n                \"Revolute or Prismatic joints must already have JointStateAPI added!\"\nself._joint_state_api = PhysxSchema.JointStateAPI(self._prim, state_type)\n# Possibly set the bodies\nif \"body0\" in self._load_config and self._load_config[\"body0\"] is not None:\nself.body0 = self._load_config[\"body0\"]\nif \"body1\" in self._load_config and self._load_config[\"body1\"] is not None:\nself.body1 = self._load_config[\"body1\"]\ndef _initialize(self):\n# Always run super first\nsuper()._initialize()\n# Initialize dynamic control references if this joint is articulated\nif self.articulated:\nself._dc = _dynamic_control.acquire_dynamic_control_interface()\n# TODO: A bit hacky way to get the joint handle, ideally we'd simply do dc.get_joint(), but this doesn't seem to work as expected?\nfor i in range(self._dc.get_articulation_joint_count(self._art)):\njoint_handle = self._dc.get_articulation_joint(self._art, i)\njoint_path = self._dc.get_joint_path(joint_handle)\nif joint_path == self._prim_path:\nself._handle = joint_handle\nbreak\nassert self._handle is not None, f\"Did not find valid articulated joint with path: {self._prim_path}\"\n# Grab DOF info / handles\nself._joint_name = self._dc.get_joint_name(self._handle)\nself._n_dof = self._dc.get_joint_dof_count(self._handle)\nself._dof_handles = []\nself._dof_properties = []\ncontrol_types = []\nfor i in range(self._n_dof):\ndof_handle = self._dc.get_joint_dof(self._handle, i)\ndof_props = self._dc.get_dof_properties(dof_handle)\nself._dof_handles.append(dof_handle)\nself._dof_properties.append(dof_props)\n# Infer control type based on whether kp and kd are 0 or not\nkp, kd = dof_props.stiffness, dof_props.damping\nif kp == 0.0:\ncontrol_type = ControlType.EFFORT if kd == 0.0 else ControlType.VELOCITY\nelse:\ncontrol_type = ControlType.POSITION\ncontrol_types.append(control_type)\n# Make sure all the control types are the same -- if not, we had something go wrong!\nassert len(set(control_types)) == 1, f\"Got multiple control types for this single joint: {control_types}\"\nself._control_type = control_types[0]\ndef update_handles(self):\n\"\"\"\n        Updates all internal handles for this prim, in case they change since initialization\n        \"\"\"\n# TODO: A bit hacky way to get the joint handle, ideally we'd simply do dc.get_joint(), but this doesn't seem to work as expected?\nself._handle = None\nfor i in range(self._dc.get_articulation_joint_count(self._art)):\njoint_handle = self._dc.get_articulation_joint(self._art, i)\njoint_path = self._dc.get_joint_path(joint_handle)\nif joint_path == self._prim_path:\nself._handle = joint_handle\nbreak\ndef set_control_type(self, control_type, kp=None, kd=None):\n\"\"\"\n        Sets the control type for this joint.\n        Args:\n            control_type (ControlType): What type of control to use for this joint.\n                Valid options are: {ControlType.POSITION, ControlType.VELOCITY, ControlType.EFFORT}\n            kp (None or float): If specified, sets the kp gain value for this joint. Should only be set if\n                setting ControlType.POSITION\n            kd (None or float): If specified, sets the kd gain value for this joint. Should only be set if\n                setting ControlType.VELOCITY\n        \"\"\"\n# Sanity check inputs\nassert_valid_key(key=control_type, valid_keys=ControlType.VALID_TYPES, name=\"control type\")\nif control_type == ControlType.POSITION:\nassert kp is not None, \"kp gain must be specified for setting POSITION control!\"\nassert kd is None, \"kd gain must not be specified for setting POSITION control!\"\nkd = 0.0\nelif control_type == ControlType.VELOCITY:\nassert kp is None, \"kp gain must not be specified for setting VELOCITY control!\"\nassert kd is not None, \"kd gain must be specified for setting VELOCITY control!\"\nkp = 0.0\nelse:   # Efforts\nassert kp is None, \"kp gain must not be specified for setting EFFORT control!\"\nassert kd is None, \"kd gain must not be specified for setting EFFORT control!\"\nkp, kd = 0.0, 0.0\n# Set values\nif self._dc:\nfor dof_handle, dof_property in zip(self._dof_handles, self._dof_properties):\ndof_property.stiffness = kp\ndof_property.damping = kd\nself._dc.set_dof_properties(dof_handle, dof_property)\n# Update control type\nself._control_type = control_type\n@property\ndef body0(self):\n\"\"\"\n        Gets this joint's body0 relationship.\n        Returns:\n            None or str: Absolute prim path to the body prim to set as this joint's parent link, or None if there is\n                no body0 specified.\n        \"\"\"\ntargets = self._prim.GetRelationship(\"physics:body0\").GetTargets()\nreturn targets[0].__str__() if len(targets) &gt; 0 else None\n@body0.setter\ndef body0(self, body0):\n\"\"\"\n        Sets this joint's body0 relationship.\n        Args:\n            body0 (str): Absolute prim path to the body prim to set as this joint's parent link.\n        \"\"\"\n# Make sure prim path is valid\nassert is_prim_path_valid(body0), f\"Invalid body0 path specified: {body0}\"\nself._prim.GetRelationship(\"physics:body0\").SetTargets([Sdf.Path(body0)])\n@property\ndef body1(self):\n\"\"\"\n        Gets this joint's body1 relationship.\n        Returns:\n            None or str: Absolute prim path to the body prim to set as this joint's child link, or None if there is\n                no body1 specified.\n        \"\"\"\ntargets = self._prim.GetRelationship(\"physics:body1\").GetTargets()\nreturn targets[0].__str__()\n@body1.setter\ndef body1(self, body1):\n\"\"\"\n        Sets this joint's body1 relationship.\n        Args:\n            body1 (str): Absolute prim path to the body prim to set as this joint's child link.\n        \"\"\"\n# Make sure prim path is valid\nassert is_prim_path_valid(body1), f\"Invalid body1 path specified: {body1}\"\nself._prim.GetRelationship(\"physics:body1\").SetTargets([Sdf.Path(body1)])\n@property\ndef parent_name(self):\n\"\"\"\n        Gets this joint's parent body name, if it exists\n        Returns:\n            str: Joint's parent body name\n        \"\"\"\nreturn self._dc.get_rigid_body_name(self._dc.get_joint_parent_body(self._handle))\n@property\ndef child_name(self):\n\"\"\"\n        Gets this joint's child body name, if it exists\n        Returns:\n            str: Joint's child body name\n        \"\"\"\nreturn self._dc.get_rigid_body_name(self._dc.get_joint_child_body(self._handle))\n@property\ndef local_orientation(self):\n\"\"\"\n        Returns:\n            4-array: (x,y,z,w) local quaternion orientation of this joint, relative to the parent link\n        \"\"\"\n# Grab local rotation to parent and child links\nquat0 = gf_quat_to_np_array(self.get_attribute(\"physics:localRot0\"))[[1, 2, 3, 0]]\nquat1 = gf_quat_to_np_array(self.get_attribute(\"physics:localRot1\"))[[1, 2, 3, 0]]\n# Invert the child link relationship, and multiply the two rotations together to get the final rotation\nreturn T.quat_multiply(quaternion1=T.quat_inverse(quat1), quaternion0=quat0)\n@property\ndef joint_name(self):\n\"\"\"\n        Returns:\n            str: Name of this joint\n        \"\"\"\nreturn self._joint_name\n@property\ndef joint_type(self):\n\"\"\"\n        Gets this joint's type (ignoring the \"Physics\" prefix)\n        Returns:\n            JointType: Joint's type. Should be one corresponding to:\n                {JOINT_PRISMATIC, JOINT_REVOLUTE, JOINT_FIXED, JOINT_SPHERICAL}\n        \"\"\"\nreturn self._joint_type\n@property\ndef driven(self):\n\"\"\"\n        Returns:\n            bool: Whether this joint can be driven by a motor or not\n        \"\"\"\nreturn self._driven\n@property\ndef control_type(self):\n\"\"\"\n        Gets the control types for this joint\n        Returns:\n            ControlType: control type for this joint\n        \"\"\"\nreturn self._control_type\n@property\ndef dof_properties(self):\n\"\"\"\n        Returns:\n            list of DOFProperties: Per-DOF properties for this joint.\n                See https://docs.omniverse.nvidia.com/py/isaacsim/source/extensions/omni.isaac.dynamic_control/docs/index.html#omni.isaac.dynamic_control._dynamic_control.DofProperties\n                for more information.\n        \"\"\"\nreturn self._dof_properties\n@property\ndef max_velocity(self):\n\"\"\"\n        Gets this joint's maximum velocity\n        Returns:\n            float: maximum velocity for this joint\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n# We either return the raw value or a default value if there is no max specified\nraw_vel = self._dof_properties[0].max_velocity\ndefault_max_vel = m.DEFAULT_MAX_REVOLUTE_VEL if self.joint_type == JointType.JOINT_REVOLUTE else m.DEFAULT_MAX_PRISMATIC_VEL\nreturn default_max_vel if raw_vel is None or np.abs(raw_vel) &gt; m.INF_VEL_THRESHOLD else raw_vel\n@max_velocity.setter\ndef max_velocity(self, vel):\n\"\"\"\n        Sets this joint's maximum velocity\n        Args:\n            vel (float): Velocity to set\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\nself._dof_properties[0].max_velocity = vel\nself._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n@property\ndef max_effort(self):\n\"\"\"\n        Gets this joint's maximum effort\n        Returns:\n            float: maximum force for this joint\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n# We either return the raw value or a default value if there is no max specified\nraw_force = self._dof_properties[0].max_effort\nreturn m.DEFAULT_MAX_EFFORT if raw_force is None or np.abs(raw_force) &gt; m.INF_EFFORT_THRESHOLD else raw_force\n@max_effort.setter\ndef max_effort(self, force):\n\"\"\"\n        Sets this joint's maximum effort\n        Args:\n            force (float): Force to set\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\nself._dof_properties[0].max_effort = force\nself._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n@property\ndef stiffness(self):\n\"\"\"\n        Gets this joint's stiffness\n        Returns:\n            float: stiffness for this joint\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\nreturn self._dof_properties[0].stiffness\n@stiffness.setter\ndef stiffness(self, stiffness):\n\"\"\"\n        Sets this joint's stiffness\n        Args:\n            stiffness (float): stiffness to set\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\nself._dof_properties[0].stiffness = stiffness\nself._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n@property\ndef damping(self):\n\"\"\"\n        Gets this joint's damping\n        Returns:\n            float: damping for this joint\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\nreturn self._dof_properties[0].damping\n@damping.setter\ndef damping(self, damping):\n\"\"\"\n        Sets this joint's damping\n        Args:\n            damping (float): damping to set\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\nself._dof_properties[0].damping = damping\nself._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n@property\ndef friction(self):\n\"\"\"\n        Gets this joint's friction\n        Returns:\n            float: friction for this joint\n        \"\"\"\nreturn self.get_attribute(\"physxJoint:jointFriction\")\n@friction.setter\ndef friction(self, friction):\n\"\"\"\n        Sets this joint's friction\n        Args:\n            friction (float): friction to set\n        \"\"\"\nself.set_attribute(\"physxJoint:jointFriction\", friction)\n@property\ndef lower_limit(self):\n\"\"\"\n        Gets this joint's lower_limit\n        Returns:\n            float: lower_limit for this joint\n        \"\"\"\n# TODO: Add logic for non Prismatic / Revolute joints (D6, spherical)\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n# We either return the raw value or a default value if there is no max specified\nraw_pos_lower, raw_pos_upper = self._dof_properties[0].lower, self._dof_properties[0].upper\nreturn -m.DEFAULT_MAX_POS \\\n            if raw_pos_lower is None or raw_pos_lower == raw_pos_upper or np.abs(raw_pos_lower) &gt; m.INF_POS_THRESHOLD \\\n            else raw_pos_lower\n@lower_limit.setter\ndef lower_limit(self, lower_limit):\n\"\"\"\n        Sets this joint's lower_limit\n        Args:\n            lower_limit (float): lower_limit to set\n        \"\"\"\n# Can't use DC because it's read only property\nlower_limit = T.rad2deg(lower_limit) if self.is_revolute else lower_limit\nself.set_attribute(\"physics:lowerLimit\", lower_limit)\n@property\ndef upper_limit(self):\n\"\"\"\n        Gets this joint's upper_limit\n        Returns:\n            float: upper_limit for this joint\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n# We either return the raw value or a default value if there is no max specified\nraw_pos_lower, raw_pos_upper = self._dof_properties[0].lower, self._dof_properties[0].upper\nreturn m.DEFAULT_MAX_POS \\\n            if raw_pos_upper is None or raw_pos_lower == raw_pos_upper or np.abs(raw_pos_upper) &gt; m.INF_POS_THRESHOLD \\\n            else raw_pos_upper\n@upper_limit.setter\ndef upper_limit(self, upper_limit):\n\"\"\"\n        Sets this joint's upper_limit\n        Args:\n            upper_limit (float): upper_limit to set\n        \"\"\"\n# Can't use DC because it's read only property\nupper_limit = T.rad2deg(upper_limit) if self.is_revolute else upper_limit\nself.set_attribute(\"physics:upperLimit\", upper_limit)\n@property\ndef has_limit(self):\n\"\"\"\n        Returns:\n            bool: True if this joint has a limit, else False\n        \"\"\"\n# Only support revolute and prismatic joints for now\nassert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n# We either return the raw value or a default value if there is no max specified\nreturn self._dof_properties[0].has_limits\n@property\ndef n_dof(self):\n\"\"\"\n        Returns:\n            int: Number of degrees of freedom this joint has\n        \"\"\"\nreturn self._n_dof\n@property\ndef articulated(self):\n\"\"\"\n        Returns:\n             bool: Whether this joint is articulated or not\n        \"\"\"\nreturn self._art is not None\n@property\ndef is_revolute(self):\n\"\"\"\n        Returns:\n            bool: Whether this joint is revolute or  not\n        \"\"\"\nreturn self._joint_type == JointType.JOINT_REVOLUTE\n@property\ndef is_single_dof(self):\n\"\"\"\n        Returns:\n            bool: Whether this joint has a single DOF or not\n        \"\"\"\nreturn self._joint_type in {JointType.JOINT_REVOLUTE, JointType.JOINT_PRISMATIC}\ndef assert_articulated(self):\n\"\"\"\n        Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended\n        behavior (e.g.: trying to grab this joint's state if it's not articulated)\n        \"\"\"\nassert self.articulated, \"Tried to call method not intended for non-articulated joint!\"\ndef get_state(self, normalized=False):\n\"\"\"\n        (pos, vel, effort) state of this joint\n        Args:\n            normalized (bool): If True, will return normalized state of this joint, where pos, vel, and effort values\n                are in range [-1, 1].\n        Returns:\n            3-tuple:\n                - n-array: position of this joint, where n = number of DOF for this joint\n                - n-array: velocity of this joint, where n = number of DOF for this joint\n                - n-array: effort of this joint, where n = number of DOF for this joint\n        \"\"\"\n# Make sure we only call this if we're an articulated joint\nself.assert_articulated()\n# Grab raw states\npos, vel, effort = np.zeros(self.n_dof), np.zeros(self.n_dof), np.zeros(self.n_dof)\nfor i, dof_handle in enumerate(self._dof_handles):\ndof_state = self._dc.get_dof_state(dof_handle, _dynamic_control.STATE_ALL)\npos[i] = dof_state.pos\nvel[i] = dof_state.vel\neffort[i] = dof_state.effort\n# Potentially normalize if requested\nif normalized:\npos, vel, effort = self._normalize_pos(pos), self._normalize_vel(vel), self._normalize_effort(effort)\nreturn pos, vel, effort\ndef get_target(self, normalized=False):\n\"\"\"\n        (pos, vel) target of this joint\n        Args:\n            normalized (bool): If True, will return normalized target of this joint\n        Returns:\n            2-tuple:\n                - n-array: target position of this joint, where n = number of DOF for this joint\n                - n-array: target velocity of this joint, where n = number of DOF for this joint\n        \"\"\"\n# Make sure we only call this if we're an articulated joint\nself.assert_articulated()\n# Grab raw states\npos, vel = np.zeros(self.n_dof), np.zeros(self.n_dof)\nfor i, dof_handle in enumerate(self._dof_handles):\npos[i] = self._dc.get_dof_position_target(dof_handle)\nvel[i] = self._dc.get_dof_velocity_target(dof_handle)\n# Potentially normalize if requested\nif normalized:\npos, vel = self._normalize_pos(pos), self._normalize_vel(vel)\nreturn pos, vel\ndef _normalize_pos(self, pos):\n\"\"\"\n        Normalizes raw joint positions @pos\n        Args:\n            pos (n-array): n-DOF raw positions to normalize\n        Returns:\n            n-array: n-DOF normalized positions in range [-1, 1]\n        \"\"\"\nlow, high = self.lower_limit, self.upper_limit\nmean = (low + high) / 2.0\nmagnitude = (high - low) / 2.0\npos = (pos - mean) / magnitude\nreturn pos\ndef _denormalize_pos(self, pos):\n\"\"\"\n        De-normalizes joint positions @pos\n        Args:\n            pos (n-array): n-DOF normalized positions in range [-1, 1]\n        Returns:\n            n-array: n-DOF de-normalized positions\n        \"\"\"\nlow, high = self.lower_limit, self.upper_limit\nmean = (low + high) / 2.0\nmagnitude = (high - low) / 2.0\npos = pos * magnitude + mean\nreturn pos\ndef _normalize_vel(self, vel):\n\"\"\"\n        Normalizes raw joint velocities @vel\n        Args:\n            vel (n-array): n-DOF raw velocities to normalize\n        Returns:\n            n-array: n-DOF normalized velocities in range [-1, 1]\n        \"\"\"\nreturn vel / self.max_velocity\ndef _denormalize_vel(self, vel):\n\"\"\"\n        De-normalizes joint velocities @vel\n        Args:\n            vel (n-array): n-DOF normalized velocities in range [-1, 1]\n        Returns:\n            n-array: n-DOF de-normalized velocities\n        \"\"\"\nreturn vel * self.max_velocity\ndef _normalize_effort(self, effort):\n\"\"\"\n        Normalizes raw joint effort @effort\n        Args:\n            effort (n-array): n-DOF raw effort to normalize\n        Returns:\n            n-array: n-DOF normalized effort in range [-1, 1]\n        \"\"\"\nreturn effort / self.max_effort\ndef _denormalize_effort(self, effort):\n\"\"\"\n        De-normalizes joint effort @effort\n        Args:\n            effort (n-array): n-DOF normalized effort in range [-1, 1]\n        Returns:\n            n-array: n-DOF de-normalized effort\n        \"\"\"\nreturn effort * self.max_effort\ndef set_pos(self, pos, normalized=False, drive=False):\n\"\"\"\n        Set the position of this joint in metric space\n        Args:\n            pos (float or n-array of float): Set the position(s) for this joint. Can be a single float or 1-array of\n                float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n            normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n                de-normalized first before being executed). Default is False\n            drive (bool): Whether the joint should be driven naturally via its motor to the position being set or\n                whether it should be instantaneously set. Default is False, corresponding to an\n                instantaneous setting of the position\n        \"\"\"\n# Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\nself.assert_articulated()\nif drive:\nassert self._driven, \"Can only use set_pos with drive=True if this joint is driven!\"\nassert self._control_type == ControlType.POSITION, \\\n                \"Trying to set joint position target, but control type is not position!\"\n# Standardize input\npos = np.array([pos]) if self._n_dof == 1 and not isinstance(pos, Iterable) else np.array(pos)\n# Potentially de-normalize if the input is normalized\nif normalized:\npos = self._denormalize_pos(pos)\n# Set the DOF(s) in this joint\nfor dof_handle, p in zip(self._dof_handles, pos):\nif not drive:\nself._dc.set_dof_position(dof_handle, p)\n# We set the position target in either case\nself._dc.set_dof_position_target(dof_handle, p)\ndef set_vel(self, vel, normalized=False, drive=False):\n\"\"\"\n        Set the velocity of this joint in metric space\n        Args:\n            vel (float or n-array of float): Set the velocity(s) for this joint. Can be a single float or 1-array of\n                float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n            normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n                de-normalized first before being executed). Default is False\n            drive (bool): Whether the joint should be driven naturally via its motor to the velocity being set or\n                whether it should be instantaneously set. Default is False, corresponding to an\n                instantaneous setting of the velocity\n        \"\"\"\n# Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\nself.assert_articulated()\nif drive:\nassert self._driven, \"Can only use set_vel with drive=True if this joint is driven!\"\nassert self._control_type == ControlType.VELOCITY, \\\n                f\"Trying to set joint velocity target for joint {self.name}, but control type is not velocity!\"\n# Standardize input\nvel = np.array([vel]) if self._n_dof == 1 and not isinstance(vel, Iterable) else np.array(vel)\n# Potentially de-normalize if the input is normalized\nif normalized:\nvel = self._denormalize_vel(vel)\n# Set the DOF(s) in this joint\nfor dof_handle, v in zip(self._dof_handles, vel):\nif not drive:\nself._dc.set_dof_velocity(dof_handle, v)\n# We set the target in either case\nself._dc.set_dof_velocity_target(dof_handle, v)\ndef set_effort(self, effort, normalized=False):\n\"\"\"\n        Set the effort of this joint in metric space\n        Args:\n            effort (float or n-array of float): Set the effort(s) for this joint. Can be a single float or 1-array of\n                float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n            normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n                de-normalized first before being executed). Default is False\n        \"\"\"\n# Sanity checks -- make sure that we're articulated (no control type check like position and velocity\n# because we can't set effort targets) and that we're driven\nself.assert_articulated()\nassert self._driven, \"Cannot set efforts for joint that is not driven!\"\n# Standardize input\neffort = np.array([effort]) if self._n_dof == 1 and not isinstance(effort, Iterable) else np.array(effort)\n# Potentially de-normalize if the input is normalized\nif normalized:\neffort = self._denormalize_effort(effort)\n# Set the DOF(s) in this joint\nfor dof_handle, e in zip(self._dof_handles, effort):\nself._dc.set_dof_effort(dof_handle, e)\ndef keep_still(self):\n\"\"\"\n        Zero out all velocities for this prim\n        \"\"\"\nself.set_vel(np.zeros(self.n_dof))\ndef _dump_state(self):\npos, vel, effort = self.get_state() if self.articulated else (np.array([]), np.array([]), np.array([]))\ntarget_pos, target_vel = self.get_target() if self.articulated else (np.array([]), np.array([]))\nreturn dict(\npos=pos,\nvel=vel,\neffort=effort,\ntarget_pos=target_pos,\ntarget_vel=target_vel,\n)\ndef _load_state(self, state):\nif self.articulated:\nself.set_pos(state[\"pos\"], drive=False)\nself.set_vel(state[\"vel\"], drive=False)\nif self._driven:\nself.set_effort(state[\"effort\"])\nif self._control_type == ControlType.POSITION:\nself.set_pos(state[\"target_pos\"], drive=True)\nelif self._control_type == ControlType.VELOCITY:\nself.set_vel(state[\"target_vel\"], drive=True)\ndef _serialize(self, state):\nreturn np.concatenate([\nstate[\"pos\"],\nstate[\"vel\"],\nstate[\"effort\"],\nstate[\"target_pos\"],\nstate[\"target_vel\"],\n]).astype(float)\ndef _deserialize(self, state):\n# We deserialize deterministically by knowing the order of values -- pos, vel, effort\nreturn dict(\npos=state[0:self.n_dof],\nvel=state[self.n_dof:2*self.n_dof],\neffort=state[2*self.n_dof:3*self.n_dof],\ntarget_pos=state[3*self.n_dof:4*self.n_dof],\ntarget_vel=state[4*self.n_dof:5*self.n_dof],\n), 5*self.n_dof\ndef duplicate(self, prim_path):\n# Cannot directly duplicate a joint prim\nraise NotImplementedError(\"Cannot directly duplicate a joint prim!\")\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.articulated","title":"<code>articulated</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this joint is articulated or not</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.body0","title":"<code>body0</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's body0 relationship.</p> <p>Returns:</p> Type Description <p>None or str: Absolute prim path to the body prim to set as this joint's parent link, or None if there is no body0 specified.</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.body1","title":"<code>body1</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's body1 relationship.</p> <p>Returns:</p> Type Description <p>None or str: Absolute prim path to the body prim to set as this joint's child link, or None if there is no body1 specified.</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.child_name","title":"<code>child_name</code>  <code>property</code>","text":"<p>Gets this joint's child body name, if it exists</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Joint's child body name</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.control_type","title":"<code>control_type</code>  <code>property</code>","text":"<p>Gets the control types for this joint</p> <p>Returns:</p> Name Type Description <code>ControlType</code> <p>control type for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.damping","title":"<code>damping</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's damping</p> <p>Returns:</p> Name Type Description <code>float</code> <p>damping for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.dof_properties","title":"<code>dof_properties</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>list of DOFProperties: Per-DOF properties for this joint. See https://docs.omniverse.nvidia.com/py/isaacsim/source/extensions/omni.isaac.dynamic_control/docs/index.html#omni.isaac.dynamic_control._dynamic_control.DofProperties for more information.</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.driven","title":"<code>driven</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this joint can be driven by a motor or not</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.friction","title":"<code>friction</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's friction</p> <p>Returns:</p> Name Type Description <code>float</code> <p>friction for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.has_limit","title":"<code>has_limit</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>True if this joint has a limit, else False</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.is_revolute","title":"<code>is_revolute</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this joint is revolute or  not</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.is_single_dof","title":"<code>is_single_dof</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this joint has a single DOF or not</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.joint_name","title":"<code>joint_name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.joint_type","title":"<code>joint_type</code>  <code>property</code>","text":"<p>Gets this joint's type (ignoring the \"Physics\" prefix)</p> <p>Returns:</p> Name Type Description <code>JointType</code> <p>Joint's type. Should be one corresponding to:</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.local_orientation","title":"<code>local_orientation</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>4-array: (x,y,z,w) local quaternion orientation of this joint, relative to the parent link</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.lower_limit","title":"<code>lower_limit</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's lower_limit</p> <p>Returns:</p> Name Type Description <code>float</code> <p>lower_limit for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.max_effort","title":"<code>max_effort</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's maximum effort</p> <p>Returns:</p> Name Type Description <code>float</code> <p>maximum force for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.max_velocity","title":"<code>max_velocity</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's maximum velocity</p> <p>Returns:</p> Name Type Description <code>float</code> <p>maximum velocity for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.n_dof","title":"<code>n_dof</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of degrees of freedom this joint has</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.parent_name","title":"<code>parent_name</code>  <code>property</code>","text":"<p>Gets this joint's parent body name, if it exists</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Joint's parent body name</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.stiffness","title":"<code>stiffness</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's stiffness</p> <p>Returns:</p> Name Type Description <code>float</code> <p>stiffness for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.upper_limit","title":"<code>upper_limit</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this joint's upper_limit</p> <p>Returns:</p> Name Type Description <code>float</code> <p>upper_limit for this joint</p>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.assert_articulated","title":"<code>assert_articulated()</code>","text":"<p>Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended behavior (e.g.: trying to grab this joint's state if it's not articulated)</p> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def assert_articulated(self):\n\"\"\"\n    Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended\n    behavior (e.g.: trying to grab this joint's state if it's not articulated)\n    \"\"\"\nassert self.articulated, \"Tried to call method not intended for non-articulated joint!\"\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.get_state","title":"<code>get_state(normalized=False)</code>","text":"<p>(pos, vel, effort) state of this joint</p> <p>Parameters:</p> Name Type Description Default <code>normalized</code> <code>bool</code> <p>If True, will return normalized state of this joint, where pos, vel, and effort values are in range [-1, 1].</p> <code>False</code> <p>Returns:</p> Type Description <p>3-tuple: - n-array: position of this joint, where n = number of DOF for this joint - n-array: velocity of this joint, where n = number of DOF for this joint - n-array: effort of this joint, where n = number of DOF for this joint</p> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def get_state(self, normalized=False):\n\"\"\"\n    (pos, vel, effort) state of this joint\n    Args:\n        normalized (bool): If True, will return normalized state of this joint, where pos, vel, and effort values\n            are in range [-1, 1].\n    Returns:\n        3-tuple:\n            - n-array: position of this joint, where n = number of DOF for this joint\n            - n-array: velocity of this joint, where n = number of DOF for this joint\n            - n-array: effort of this joint, where n = number of DOF for this joint\n    \"\"\"\n# Make sure we only call this if we're an articulated joint\nself.assert_articulated()\n# Grab raw states\npos, vel, effort = np.zeros(self.n_dof), np.zeros(self.n_dof), np.zeros(self.n_dof)\nfor i, dof_handle in enumerate(self._dof_handles):\ndof_state = self._dc.get_dof_state(dof_handle, _dynamic_control.STATE_ALL)\npos[i] = dof_state.pos\nvel[i] = dof_state.vel\neffort[i] = dof_state.effort\n# Potentially normalize if requested\nif normalized:\npos, vel, effort = self._normalize_pos(pos), self._normalize_vel(vel), self._normalize_effort(effort)\nreturn pos, vel, effort\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.get_target","title":"<code>get_target(normalized=False)</code>","text":"<p>(pos, vel) target of this joint</p> <p>Parameters:</p> Name Type Description Default <code>normalized</code> <code>bool</code> <p>If True, will return normalized target of this joint</p> <code>False</code> <p>Returns:</p> Type Description <p>2-tuple: - n-array: target position of this joint, where n = number of DOF for this joint - n-array: target velocity of this joint, where n = number of DOF for this joint</p> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def get_target(self, normalized=False):\n\"\"\"\n    (pos, vel) target of this joint\n    Args:\n        normalized (bool): If True, will return normalized target of this joint\n    Returns:\n        2-tuple:\n            - n-array: target position of this joint, where n = number of DOF for this joint\n            - n-array: target velocity of this joint, where n = number of DOF for this joint\n    \"\"\"\n# Make sure we only call this if we're an articulated joint\nself.assert_articulated()\n# Grab raw states\npos, vel = np.zeros(self.n_dof), np.zeros(self.n_dof)\nfor i, dof_handle in enumerate(self._dof_handles):\npos[i] = self._dc.get_dof_position_target(dof_handle)\nvel[i] = self._dc.get_dof_velocity_target(dof_handle)\n# Potentially normalize if requested\nif normalized:\npos, vel = self._normalize_pos(pos), self._normalize_vel(vel)\nreturn pos, vel\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.keep_still","title":"<code>keep_still()</code>","text":"<p>Zero out all velocities for this prim</p> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def keep_still(self):\n\"\"\"\n    Zero out all velocities for this prim\n    \"\"\"\nself.set_vel(np.zeros(self.n_dof))\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_control_type","title":"<code>set_control_type(control_type, kp=None, kd=None)</code>","text":"<p>Sets the control type for this joint.</p> <p>Parameters:</p> Name Type Description Default <code>control_type</code> <code>ControlType</code> <p>What type of control to use for this joint. Valid options are: {ControlType.POSITION, ControlType.VELOCITY, ControlType.EFFORT}</p> required <code>kp</code> <code>None or float</code> <p>If specified, sets the kp gain value for this joint. Should only be set if setting ControlType.POSITION</p> <code>None</code> <code>kd</code> <code>None or float</code> <p>If specified, sets the kd gain value for this joint. Should only be set if setting ControlType.VELOCITY</p> <code>None</code> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def set_control_type(self, control_type, kp=None, kd=None):\n\"\"\"\n    Sets the control type for this joint.\n    Args:\n        control_type (ControlType): What type of control to use for this joint.\n            Valid options are: {ControlType.POSITION, ControlType.VELOCITY, ControlType.EFFORT}\n        kp (None or float): If specified, sets the kp gain value for this joint. Should only be set if\n            setting ControlType.POSITION\n        kd (None or float): If specified, sets the kd gain value for this joint. Should only be set if\n            setting ControlType.VELOCITY\n    \"\"\"\n# Sanity check inputs\nassert_valid_key(key=control_type, valid_keys=ControlType.VALID_TYPES, name=\"control type\")\nif control_type == ControlType.POSITION:\nassert kp is not None, \"kp gain must be specified for setting POSITION control!\"\nassert kd is None, \"kd gain must not be specified for setting POSITION control!\"\nkd = 0.0\nelif control_type == ControlType.VELOCITY:\nassert kp is None, \"kp gain must not be specified for setting VELOCITY control!\"\nassert kd is not None, \"kd gain must be specified for setting VELOCITY control!\"\nkp = 0.0\nelse:   # Efforts\nassert kp is None, \"kp gain must not be specified for setting EFFORT control!\"\nassert kd is None, \"kd gain must not be specified for setting EFFORT control!\"\nkp, kd = 0.0, 0.0\n# Set values\nif self._dc:\nfor dof_handle, dof_property in zip(self._dof_handles, self._dof_properties):\ndof_property.stiffness = kp\ndof_property.damping = kd\nself._dc.set_dof_properties(dof_handle, dof_property)\n# Update control type\nself._control_type = control_type\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_effort","title":"<code>set_effort(effort, normalized=False)</code>","text":"<p>Set the effort of this joint in metric space</p> <p>Parameters:</p> Name Type Description Default <code>effort</code> <code>float or n-array of float</code> <p>Set the effort(s) for this joint. Can be a single float or 1-array of float if the joint only has a single DOF, otherwise it should be an n-array of floats.</p> required <code>normalized</code> <code>bool</code> <p>Whether the input is normalized to [-1, 1] (in this case, the values will be de-normalized first before being executed). Default is False</p> <code>False</code> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def set_effort(self, effort, normalized=False):\n\"\"\"\n    Set the effort of this joint in metric space\n    Args:\n        effort (float or n-array of float): Set the effort(s) for this joint. Can be a single float or 1-array of\n            float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n        normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n            de-normalized first before being executed). Default is False\n    \"\"\"\n# Sanity checks -- make sure that we're articulated (no control type check like position and velocity\n# because we can't set effort targets) and that we're driven\nself.assert_articulated()\nassert self._driven, \"Cannot set efforts for joint that is not driven!\"\n# Standardize input\neffort = np.array([effort]) if self._n_dof == 1 and not isinstance(effort, Iterable) else np.array(effort)\n# Potentially de-normalize if the input is normalized\nif normalized:\neffort = self._denormalize_effort(effort)\n# Set the DOF(s) in this joint\nfor dof_handle, e in zip(self._dof_handles, effort):\nself._dc.set_dof_effort(dof_handle, e)\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_pos","title":"<code>set_pos(pos, normalized=False, drive=False)</code>","text":"<p>Set the position of this joint in metric space</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>float or n-array of float</code> <p>Set the position(s) for this joint. Can be a single float or 1-array of float if the joint only has a single DOF, otherwise it should be an n-array of floats.</p> required <code>normalized</code> <code>bool</code> <p>Whether the input is normalized to [-1, 1] (in this case, the values will be de-normalized first before being executed). Default is False</p> <code>False</code> <code>drive</code> <code>bool</code> <p>Whether the joint should be driven naturally via its motor to the position being set or whether it should be instantaneously set. Default is False, corresponding to an instantaneous setting of the position</p> <code>False</code> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def set_pos(self, pos, normalized=False, drive=False):\n\"\"\"\n    Set the position of this joint in metric space\n    Args:\n        pos (float or n-array of float): Set the position(s) for this joint. Can be a single float or 1-array of\n            float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n        normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n            de-normalized first before being executed). Default is False\n        drive (bool): Whether the joint should be driven naturally via its motor to the position being set or\n            whether it should be instantaneously set. Default is False, corresponding to an\n            instantaneous setting of the position\n    \"\"\"\n# Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\nself.assert_articulated()\nif drive:\nassert self._driven, \"Can only use set_pos with drive=True if this joint is driven!\"\nassert self._control_type == ControlType.POSITION, \\\n            \"Trying to set joint position target, but control type is not position!\"\n# Standardize input\npos = np.array([pos]) if self._n_dof == 1 and not isinstance(pos, Iterable) else np.array(pos)\n# Potentially de-normalize if the input is normalized\nif normalized:\npos = self._denormalize_pos(pos)\n# Set the DOF(s) in this joint\nfor dof_handle, p in zip(self._dof_handles, pos):\nif not drive:\nself._dc.set_dof_position(dof_handle, p)\n# We set the position target in either case\nself._dc.set_dof_position_target(dof_handle, p)\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_vel","title":"<code>set_vel(vel, normalized=False, drive=False)</code>","text":"<p>Set the velocity of this joint in metric space</p> <p>Parameters:</p> Name Type Description Default <code>vel</code> <code>float or n-array of float</code> <p>Set the velocity(s) for this joint. Can be a single float or 1-array of float if the joint only has a single DOF, otherwise it should be an n-array of floats.</p> required <code>normalized</code> <code>bool</code> <p>Whether the input is normalized to [-1, 1] (in this case, the values will be de-normalized first before being executed). Default is False</p> <code>False</code> <code>drive</code> <code>bool</code> <p>Whether the joint should be driven naturally via its motor to the velocity being set or whether it should be instantaneously set. Default is False, corresponding to an instantaneous setting of the velocity</p> <code>False</code> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def set_vel(self, vel, normalized=False, drive=False):\n\"\"\"\n    Set the velocity of this joint in metric space\n    Args:\n        vel (float or n-array of float): Set the velocity(s) for this joint. Can be a single float or 1-array of\n            float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n        normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n            de-normalized first before being executed). Default is False\n        drive (bool): Whether the joint should be driven naturally via its motor to the velocity being set or\n            whether it should be instantaneously set. Default is False, corresponding to an\n            instantaneous setting of the velocity\n    \"\"\"\n# Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\nself.assert_articulated()\nif drive:\nassert self._driven, \"Can only use set_vel with drive=True if this joint is driven!\"\nassert self._control_type == ControlType.VELOCITY, \\\n            f\"Trying to set joint velocity target for joint {self.name}, but control type is not velocity!\"\n# Standardize input\nvel = np.array([vel]) if self._n_dof == 1 and not isinstance(vel, Iterable) else np.array(vel)\n# Potentially de-normalize if the input is normalized\nif normalized:\nvel = self._denormalize_vel(vel)\n# Set the DOF(s) in this joint\nfor dof_handle, v in zip(self._dof_handles, vel):\nif not drive:\nself._dc.set_dof_velocity(dof_handle, v)\n# We set the target in either case\nself._dc.set_dof_velocity_target(dof_handle, v)\n</code></pre>"},{"location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.update_handles","title":"<code>update_handles()</code>","text":"<p>Updates all internal handles for this prim, in case they change since initialization</p> Source code in <code>omnigibson/prims/joint_prim.py</code> <pre><code>def update_handles(self):\n\"\"\"\n    Updates all internal handles for this prim, in case they change since initialization\n    \"\"\"\n# TODO: A bit hacky way to get the joint handle, ideally we'd simply do dc.get_joint(), but this doesn't seem to work as expected?\nself._handle = None\nfor i in range(self._dc.get_articulation_joint_count(self._art)):\njoint_handle = self._dc.get_articulation_joint(self._art, i)\njoint_path = self._dc.get_joint_path(joint_handle)\nif joint_path == self._prim_path:\nself._handle = joint_handle\nbreak\n</code></pre>"},{"location":"reference/prims/material_prim.html","title":"material_prim","text":""},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim","title":"<code>MaterialPrim</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Provides high level functions to deal with a material prim and its attributes/ properties.</p> <p>If there is a material prim present at the path, it will use it. Otherwise, a new material prim at the specified prim path will be created.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected for their class. For this material prim, the below values can be specified:</p> <p>mdl_name (None or str): If specified, should be the name of the mdl preset to load (including .mdl).     None results in default, \"OmniPBR.mdl\" mtl_name (None or str): If specified, should be the name of the mtl preset to load.     None results in default, \"OmniPBR\"</p> <code>None</code> Source code in <code>omnigibson/prims/material_prim.py</code> <pre><code>class MaterialPrim(BasePrim):\n\"\"\"\n    Provides high level functions to deal with a material prim and its attributes/ properties.\n    If there is a material prim present at the path, it will use it. Otherwise, a new material prim at\n    the specified prim path will be created.\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected\n            for their class. For this material prim, the below values can be specified:\n            mdl_name (None or str): If specified, should be the name of the mdl preset to load (including .mdl).\n                None results in default, \"OmniPBR.mdl\"\n            mtl_name (None or str): If specified, should be the name of the mtl preset to load.\n                None results in default, \"OmniPBR\"\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\n# Other values that will be filled in at runtime\nself._shader = None\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _load(self):\n# We create a new material at the specified path\nmtl_created = []\nomni.kit.commands.execute(\n\"CreateAndBindMdlMaterialFromLibrary\",\nmdl_name=\"OmniPBR.mdl\" if self._load_config.get(\"mdl_name\", None) is None else self._load_config[\"mdl_name\"],\nmtl_name=\"OmniPBR\" if self._load_config.get(\"mtl_name\", None) is None else self._load_config[\"mtl_name\"],\nmtl_created_list=mtl_created,\n)\nmaterial_path = mtl_created[0]\n# Move prim to desired location\nomni.kit.commands.execute(\"MovePrim\", path_from=material_path, path_to=self._prim_path)\n# Return generated material\nreturn get_prim_at_path(self._prim_path)\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Generate shader reference\nself._shader = get_shader_from_material(self._prim)\ndef bind(self, target_prim_path):\n\"\"\"\n        Bind this material to an arbitrary prim (usually a visual mesh prim)\n        Args:\n            target_prim_path (str): prim path of the Prim to bind to\n        \"\"\"\nbind_material(prim_path=target_prim_path, material_path=self.prim_path)\nasync def _load_mdl_parameters(self, render=True):\n\"\"\"\n        Loads MDL parameters internally so they can be accessed by our class instance\n        Args:\n            render (bool): If True, takes a rendering step before loading the mdl parameters.\n                Note that a rendering step is necessary to load these parameters, though if a step has already\n                occurred externally, no additional rendering step is needed\n        \"\"\"\nif render:\nog.sim.render()\nawait omni.usd.get_context().load_mdl_parameters_for_prim_async(self._shader)\ndef shader_force_populate(self, render=True):\n\"\"\"\n        Force populate inputs and outputs of the shader\n        Args:\n            render (bool): If True, takes a rendering step before force populating the inputs and outputs.\n                Note that a rendering step is necessary to load these I/Os, though if a step has already\n                occurred externally, no additional rendering step is needed\n        \"\"\"\nassert self._shader is not None\nasyncio.run(self._load_mdl_parameters(render=render))\ndef shader_update_asset_paths_with_root_path(self, root_path):\n\"\"\"\n        Similar to @shader_update_asset_paths, except in this case, root_path is explicitly provided by the caller.\n        Args:\n            root_path (str): root to be pre-appended to the original asset paths\n        \"\"\"\nfor inp_name in self.shader_input_names_by_type(\"SdfAssetPath\"):\ninp = self.get_input(inp_name)\n# If the input doesn't have any path, skip\nif inp is None:\ncontinue\noriginal_path = inp.path if inp.resolvedPath == \"\" else inp.resolvedPath\n# If the input has an empty path, skip\nif original_path == \"\":\ncontinue\nnew_path = os.path.join(root_path, original_path)\nself.set_input(inp_name, new_path)\ndef get_input(self, inp):\n\"\"\"\n        Grabs the input with corresponding name @inp associated with this material and shader\n        Args:\n            inp (str): Name of the shader input whose value will be grabbed\n        Returns:\n            any: value of the requested @inp\n        \"\"\"\nreturn self._shader.GetInput(inp).Get()\ndef set_input(self, inp, val):\n\"\"\"\n        Sets the input with corresponding name @inp associated with this material and shader\n        Args:\n            inp (str): Name of the shader input whose value will be set\n            val (any): Value to set for the input. This should be the valid type for that attribute.\n        \"\"\"\n# Make sure the input exists first, so we avoid segfaults with \"invalid null prim\"\nassert inp in self.shader_input_names, \\\n            f\"Got invalid shader input to set! Current inputs are: {self.shader_input_names}. Got: {inp}\"\nself._shader.GetInput(inp).Set(val)\n@property\ndef shader(self):\n\"\"\"\n        Returns:\n            Usd.Shade: Shader associated with this material\n        \"\"\"\nreturn self._shader\n@property\ndef shader_input_names(self):\n\"\"\"\n        Returns:\n            set: All the shader input names associated with this material\n        \"\"\"\nreturn {inp.GetBaseName() for inp in self._shader.GetInputs()}\ndef shader_input_names_by_type(self, input_type):\n\"\"\"\n        Args:\n            input_type (str): input type\n        Returns:\n            set: All the shader input names associated with this material that match the given input type\n        \"\"\"\nreturn {inp.GetBaseName() for inp in self._shader.GetInputs() if inp.GetTypeName().cppTypeName == input_type}\n@property\ndef diffuse_color_constant(self):\n\"\"\"\n        Returns:\n            3-array: this material's applied (R,G,B) color\n        \"\"\"\nreturn np.array(self.get_input(inp=\"diffuse_color_constant\"))\n@diffuse_color_constant.setter\ndef diffuse_color_constant(self, color):\n\"\"\"\n        Args:\n             color (3-array): this material's applied (R,G,B) color\n        \"\"\"\nself.set_input(inp=\"diffuse_color_constant\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n@property\ndef diffuse_texture(self):\n\"\"\"\n        Returns:\n            str: this material's applied diffuse_texture filepath\n        \"\"\"\nreturn self.get_input(inp=\"diffuse_texture\").resolvedPath\n@diffuse_texture.setter\ndef diffuse_texture(self, fpath):\n\"\"\"\n        Args:\n            str: this material's applied diffuse_texture filepath\n        \"\"\"\nself.set_input(inp=\"diffuse_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef albedo_desaturation(self):\n\"\"\"\n        Returns:\n            float: this material's applied albedo_desaturation\n        \"\"\"\nreturn self.get_input(inp=\"albedo_desaturation\")\n@albedo_desaturation.setter\ndef albedo_desaturation(self, desaturation):\n\"\"\"\n        Args:\n             desaturation (float): this material's applied albedo_desaturation\n        \"\"\"\nself.set_input(inp=\"albedo_desaturation\", val=desaturation)\n@property\ndef albedo_add(self):\n\"\"\"\n        Returns:\n            float: this material's applied albedo_add\n        \"\"\"\nreturn self.get_input(inp=\"albedo_add\")\n@albedo_add.setter\ndef albedo_add(self, add):\n\"\"\"\n        Args:\n             add (float): this material's applied albedo_add\n        \"\"\"\nself.set_input(inp=\"albedo_add\", val=add)\n@property\ndef albedo_brightness(self):\n\"\"\"\n        Returns:\n            float: this material's applied albedo_brightness\n        \"\"\"\nreturn self.get_input(inp=\"albedo_brightness\")\n@albedo_brightness.setter\ndef albedo_brightness(self, brightness):\n\"\"\"\n        Args:\n             brightness (float): this material's applied albedo_brightness\n        \"\"\"\nself.set_input(inp=\"albedo_brightness\", val=brightness)\n@property\ndef diffuse_tint(self):\n\"\"\"\n        Returns:\n            3-array: this material's applied (R,G,B) diffuse_tint\n        \"\"\"\nreturn np.array(self.get_input(inp=\"diffuse_tint\"))\n@diffuse_tint.setter\ndef diffuse_tint(self, color):\n\"\"\"\n        Args:\n             color (3-array): this material's applied (R,G,B) diffuse_tint\n        \"\"\"\nself.set_input(inp=\"diffuse_tint\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n@property\ndef reflection_roughness_constant(self):\n\"\"\"\n        Returns:\n            float: this material's applied reflection_roughness_constant\n        \"\"\"\nreturn self.get_input(inp=\"reflection_roughness_constant\")\n@reflection_roughness_constant.setter\ndef reflection_roughness_constant(self, roughness):\n\"\"\"\n        Args:\n             roughness (float): this material's applied reflection_roughness_constant\n        \"\"\"\nself.set_input(inp=\"reflection_roughness_constant\", val=roughness)\n@property\ndef reflection_roughness_texture_influence(self):\n\"\"\"\n        Returns:\n            float: this material's applied reflection_roughness_texture_influence\n        \"\"\"\nreturn self.get_input(inp=\"reflection_roughness_texture_influence\")\n@reflection_roughness_texture_influence.setter\ndef reflection_roughness_texture_influence(self, prop):\n\"\"\"\n        Args:\n             prop (float): this material's applied reflection_roughness_texture_influence proportion\n        \"\"\"\nself.set_input(inp=\"reflection_roughness_texture_influence\", val=prop)\n@property\ndef reflectionroughness_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied reflectionroughness_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"reflectionroughness_texture\")\nreturn None if inp is None else inp.resolvedPath\n@reflectionroughness_texture.setter\ndef reflectionroughness_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied reflectionroughness_texture fpath\n        \"\"\"\nself.set_input(inp=\"reflectionroughness_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef metallic_constant(self):\n\"\"\"\n        Returns:\n            float: this material's applied metallic_constant\n        \"\"\"\nreturn self.get_input(inp=\"metallic_constant\")\n@metallic_constant.setter\ndef metallic_constant(self, constant):\n\"\"\"\n        Args:\n             constant (float): this material's applied metallic_constant\n        \"\"\"\nself.set_input(inp=\"metallic_constant\", val=constant)\n@property\ndef metallic_texture_influence(self):\n\"\"\"\n        Returns:\n            float: this material's applied metallic_texture_influence\n        \"\"\"\nreturn self.get_input(inp=\"metallic_texture_influence\")\n@metallic_texture_influence.setter\ndef metallic_texture_influence(self, prop):\n\"\"\"\n        Args:\n             prop (float): this material's applied metallic_texture_influence\n        \"\"\"\nself.set_input(inp=\"metallic_texture_influence\", val=prop)\n@property\ndef metallic_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied metallic_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"metallic_texture\")\nreturn None if inp is None else inp.resolvedPath\n@metallic_texture.setter\ndef metallic_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied metallic_texture fpath\n        \"\"\"\nself.set_input(inp=\"metallic_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef specular_level(self):\n\"\"\"\n        Returns:\n            float: this material's applied specular_level\n        \"\"\"\nreturn self.get_input(inp=\"specular_level\")\n@specular_level.setter\ndef specular_level(self, level):\n\"\"\"\n        Args:\n             level (float): this material's applied specular_level\n        \"\"\"\nself.set_input(inp=\"specular_level\", val=level)\n@property\ndef enable_ORM_texture(self):\n\"\"\"\n        Returns:\n            bool: this material's applied enable_ORM_texture\n        \"\"\"\nreturn self.get_input(inp=\"enable_ORM_texture\")\n@enable_ORM_texture.setter\ndef enable_ORM_texture(self, enabled):\n\"\"\"\n        Args:\n             enabled (bool): this material's applied enable_ORM_texture\n        \"\"\"\nself.set_input(inp=\"enable_ORM_texture\", val=enabled)\n@property\ndef ORM_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied ORM_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"ORM_texture\")\nreturn None if inp is None else inp.resolvedPath\n@ORM_texture.setter\ndef ORM_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied ORM_texture fpath\n        \"\"\"\nself.set_input(inp=\"ORM_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef ao_to_diffuse(self):\n\"\"\"\n        Returns:\n            float: this material's applied ao_to_diffuse\n        \"\"\"\nreturn self.get_input(inp=\"ao_to_diffuse\")\n@ao_to_diffuse.setter\ndef ao_to_diffuse(self, val):\n\"\"\"\n        Args:\n             val (float): this material's applied ao_to_diffuse\n        \"\"\"\nself.set_input(inp=\"ao_to_diffuse\", val=val)\n@property\ndef ao_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied ao_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"ao_texture\")\nreturn None if inp is None else inp.resolvedPath\n@ao_texture.setter\ndef ao_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied ao_texture fpath\n        \"\"\"\nself.set_input(inp=\"ao_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef enable_emission(self):\n\"\"\"\n        Returns:\n            bool: this material's applied enable_emission\n        \"\"\"\nreturn self.get_input(inp=\"enable_emission\")\n@enable_emission.setter\ndef enable_emission(self, enabled):\n\"\"\"\n        Args:\n             enabled (bool): this material's applied enable_emission\n        \"\"\"\nself.set_input(inp=\"enable_emission\", val=enabled)\n@property\ndef emissive_color(self):\n\"\"\"\n        Returns:\n            3-array: this material's applied (R,G,B) emissive_color\n        \"\"\"\nreturn np.array(self.get_input(inp=\"emissive_color\"))\n@emissive_color.setter\ndef emissive_color(self, color):\n\"\"\"\n        Args:\n             color (3-array): this material's applied emissive_color\n        \"\"\"\nself.set_input(inp=\"emissive_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n@property\ndef emissive_color_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied emissive_color_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"emissive_color_texture\")\nreturn None if inp is None else inp.resolvedPath\n@emissive_color_texture.setter\ndef emissive_color_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied emissive_color_texture fpath\n        \"\"\"\nself.set_input(inp=\"emissive_color_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef emissive_mask_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied emissive_mask_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"emissive_mask_texture\")\nreturn None if inp is None else inp.resolvedPath\n@emissive_mask_texture.setter\ndef emissive_mask_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied emissive_mask_texture fpath\n        \"\"\"\nself.set_input(inp=\"emissive_mask_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef emissive_intensity(self):\n\"\"\"\n        Returns:\n            float: this material's applied emissive_intensity\n        \"\"\"\nreturn self.get_input(inp=\"emissive_intensity\")\n@emissive_intensity.setter\ndef emissive_intensity(self, intensity):\n\"\"\"\n        Args:\n             intensity (float): this material's applied emissive_intensity\n        \"\"\"\nself.set_input(inp=\"emissive_intensity\", val=intensity)\n@property\ndef enable_opacity(self):\n\"\"\"\n        Returns:\n            bool: this material's applied enable_opacity\n        \"\"\"\nreturn self.get_input(inp=\"enable_opacity\")\n@enable_opacity.setter\ndef enable_opacity(self, enabled):\n\"\"\"\n        Args:\n             enabled (bool): this material's applied enable_opacity\n        \"\"\"\nself.set_input(inp=\"enable_opacity\", val=enabled)\n@property\ndef enable_opacity_texture(self):\n\"\"\"\n        Returns:\n            bool: this material's applied enable_opacity_texture\n        \"\"\"\nreturn self.get_input(inp=\"enable_opacity_texture\")\n@enable_opacity_texture.setter\ndef enable_opacity_texture(self, enabled):\n\"\"\"\n        Args:\n             enabled (bool): this material's applied enable_opacity_texture\n        \"\"\"\nself.set_input(inp=\"enable_opacity_texture\", val=enabled)\n@property\ndef opacity_constant(self):\n\"\"\"\n        Returns:\n            float: this material's applied opacity_constant\n        \"\"\"\nreturn self.get_input(inp=\"opacity_constant\")\n@opacity_constant.setter\ndef opacity_constant(self, constant):\n\"\"\"\n        Args:\n             constant (float): this material's applied opacity_constant\n        \"\"\"\nself.set_input(inp=\"opacity_constant\", val=constant)\n@property\ndef opacity_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied opacity_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"opacity_texture\")\nreturn None if inp is None else inp.resolvedPath\n@opacity_texture.setter\ndef opacity_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied opacity_texture fpath\n        \"\"\"\nself.set_input(inp=\"opacity_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef opacity_mode(self):\n\"\"\"\n        Returns:\n            int: this material's applied opacity_mode\n        \"\"\"\nreturn self.get_input(inp=\"opacity_mode\")\n@opacity_mode.setter\ndef opacity_mode(self, mode):\n\"\"\"\n        Args:\n             mode (int): this material's applied opacity_mode\n        \"\"\"\nself.set_input(inp=\"opacity_mode\", val=mode)\n@property\ndef opacity_threshold(self):\n\"\"\"\n        Returns:\n            float: this material's applied opacity_threshold\n        \"\"\"\nreturn self.get_input(inp=\"opacity_threshold\")\n@opacity_threshold.setter\ndef opacity_threshold(self, threshold):\n\"\"\"\n        Args:\n             threshold (float): this material's applied opacity_threshold\n        \"\"\"\nself.set_input(inp=\"opacity_threshold\", val=threshold)\n@property\ndef bump_factor(self):\n\"\"\"\n        Returns:\n            float: this material's applied bump_factor\n        \"\"\"\nreturn self.get_input(inp=\"bump_factor\")\n@bump_factor.setter\ndef bump_factor(self, factor):\n\"\"\"\n        Args:\n             factor (float): this material's applied bump_factor\n        \"\"\"\nself.set_input(inp=\"bump_factor\", val=factor)\n@property\ndef normalmap_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied normalmap_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"normalmap_texture\")\nreturn None if inp is None else inp.resolvedPath\n@normalmap_texture.setter\ndef normalmap_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied normalmap_texture fpath\n        \"\"\"\nself.set_input(inp=\"normalmap_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef detail_bump_factor(self):\n\"\"\"\n        Returns:\n            float: this material's applied detail_bump_factor\n        \"\"\"\nreturn self.get_input(inp=\"detail_bump_factor\")\n@detail_bump_factor.setter\ndef detail_bump_factor(self, factor):\n\"\"\"\n        Args:\n             factor (float): this material's applied detail_bump_factor\n        \"\"\"\nself.set_input(inp=\"detail_bump_factor\", val=factor)\n@property\ndef detail_normalmap_texture(self):\n\"\"\"\n        Returns:\n            None or str: this material's applied detail_normalmap_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\ninp = self.get_input(inp=\"detail_normalmap_texture\")\nreturn None if inp is None else inp.resolvedPath\n@detail_normalmap_texture.setter\ndef detail_normalmap_texture(self, fpath):\n\"\"\"\n        Args:\n             fpath (str): this material's applied detail_normalmap_texture fpath\n        \"\"\"\nself.set_input(inp=\"detail_normalmap_texture\", val=Sdf.AssetPath(fpath))\n@property\ndef flip_tangent_u(self):\n\"\"\"\n        Returns:\n            bool: this material's applied flip_tangent_u\n        \"\"\"\nreturn self.get_input(inp=\"flip_tangent_u\")\n@flip_tangent_u.setter\ndef flip_tangent_u(self, flipped):\n\"\"\"\n        Args:\n             flipped (bool): this material's applied flip_tangent_u\n        \"\"\"\nself.set_input(inp=\"flip_tangent_u\", val=flipped)\n@property\ndef flip_tangent_v(self):\n\"\"\"\n        Returns:\n            bool: this material's applied flip_tangent_v\n        \"\"\"\nreturn self.get_input(inp=\"flip_tangent_v\")\n@flip_tangent_v.setter\ndef flip_tangent_v(self, flipped):\n\"\"\"\n        Args:\n             flipped (bool): this material's applied flip_tangent_v\n        \"\"\"\nself.set_input(inp=\"flip_tangent_v\", val=flipped)\n@property\ndef project_uvw(self):\n\"\"\"\n        Returns:\n            bool: this material's applied project_uvw\n        \"\"\"\nreturn self.get_input(inp=\"project_uvw\")\n@project_uvw.setter\ndef project_uvw(self, projected):\n\"\"\"\n        Args:\n             projected (bool): this material's applied project_uvw\n        \"\"\"\nself.set_input(inp=\"project_uvw\", val=projected)\n@property\ndef world_or_object(self):\n\"\"\"\n        Returns:\n            bool: this material's applied world_or_object\n        \"\"\"\nreturn self.get_input(inp=\"world_or_object\")\n@world_or_object.setter\ndef world_or_object(self, val):\n\"\"\"\n        Args:\n             val (bool): this material's applied world_or_object\n        \"\"\"\nself.set_input(inp=\"world_or_object\", val=val)\n@property\ndef uv_space_index(self):\n\"\"\"\n        Returns:\n            int: this material's applied uv_space_index\n        \"\"\"\nreturn self.get_input(inp=\"uv_space_index\")\n@uv_space_index.setter\ndef uv_space_index(self, index):\n\"\"\"\n        Args:\n             index (int): this material's applied uv_space_index\n        \"\"\"\nself.set_input(inp=\"uv_space_index\", val=index)\n@property\ndef texture_translate(self):\n\"\"\"\n        Returns:\n            2-array: this material's applied texture_translate\n        \"\"\"\nreturn np.array(self.get_input(inp=\"texture_translate\"))\n@texture_translate.setter\ndef texture_translate(self, translate):\n\"\"\"\n        Args:\n             translate (2-array): this material's applied (x,y) texture_translate\n        \"\"\"\nself.set_input(inp=\"texture_translate\", val=Gf.Vec2f(*np.array(translate, dtype=float)))\n@property\ndef texture_rotate(self):\n\"\"\"\n        Returns:\n            float: this material's applied texture_rotate\n        \"\"\"\nreturn self.get_input(inp=\"texture_rotate\")\n@texture_rotate.setter\ndef texture_rotate(self, rotate):\n\"\"\"\n        Args:\n             rotate (float): this material's applied texture_rotate\n        \"\"\"\nself.set_input(inp=\"texture_rotate\", val=rotate)\n@property\ndef texture_scale(self):\n\"\"\"\n        Returns:\n            2-array: this material's applied texture_scale\n        \"\"\"\nreturn np.array(self.get_input(inp=\"texture_scale\"))\n@texture_scale.setter\ndef texture_scale(self, scale):\n\"\"\"\n        Args:\n             scale (2-array): this material's applied (x,y) texture_scale\n        \"\"\"\nself.set_input(inp=\"texture_scale\", val=Gf.Vec2f(*np.array(scale, dtype=float)))\n@property\ndef detail_texture_translate(self):\n\"\"\"\n        Returns:\n            2-array: this material's applied detail_texture_translate\n        \"\"\"\nreturn np.array(self.get_input(inp=\"detail_texture_translate\"))\n@detail_texture_translate.setter\ndef detail_texture_translate(self, translate):\n\"\"\"\n        Args:\n             translate (2-array): this material's applied detail_texture_translate\n        \"\"\"\nself.set_input(inp=\"detail_texture_translate\", val=Gf.Vec2f(*np.array(translate, dtype=float)))\n@property\ndef detail_texture_rotate(self):\n\"\"\"\n        Returns:\n            float: this material's applied detail_texture_rotate\n        \"\"\"\nreturn self.get_input(inp=\"detail_texture_rotate\")\n@detail_texture_rotate.setter\ndef detail_texture_rotate(self, rotate):\n\"\"\"\n        Args:\n             rotate (float): this material's applied detail_texture_rotate\n        \"\"\"\nself.set_input(inp=\"detail_texture_rotate\", val=rotate)\n@property\ndef detail_texture_scale(self):\n\"\"\"\n        Returns:\n            2-array: this material's applied detail_texture_scale\n        \"\"\"\nreturn np.array(self.get_input(inp=\"detail_texture_scale\"))\n@detail_texture_scale.setter\ndef detail_texture_scale(self, scale):\n\"\"\"\n        Args:\n             scale (2-array): this material's applied detail_texture_scale\n        \"\"\"\nself.set_input(inp=\"detail_texture_scale\", val=Gf.Vec2f(*np.array(scale, dtype=float)))\n@property\ndef exclude_from_white_mode(self):\n\"\"\"\n        Returns:\n            bool: this material's applied excludeFromWhiteMode\n        \"\"\"\nreturn self.get_input(inp=\"excludeFromWhiteMode\")\n@exclude_from_white_mode.setter\ndef exclude_from_white_mode(self, exclude):\n\"\"\"\n        Args:\n             exclude (bool): this material's applied excludeFromWhiteMode\n        \"\"\"\nself.set_input(inp=\"excludeFromWhiteMode\", val=exclude)\n@property\ndef diffuse_reflection_weight(self):\n\"\"\"\n        Returns:\n            float: this material's applied diffuse_reflection_weight\n        \"\"\"\nreturn self.get_input(inp=\"diffuse_reflection_weight\")\n@diffuse_reflection_weight.setter\ndef diffuse_reflection_weight(self, weight):\n\"\"\"\n        Args:\n             weight (float): this material's applied diffuse_reflection_weight\n        \"\"\"\nself.set_input(inp=\"diffuse_reflection_weight\", val=weight)\n@property\ndef enable_specular_transmission(self):\n\"\"\"\n        Returns:\n            bool: this material's applied enable_specular_transmission\n        \"\"\"\nreturn self.get_input(inp=\"enable_specular_transmission\")\n@enable_specular_transmission.setter\ndef enable_specular_transmission(self, enabled):\n\"\"\"\n        Args:\n             enabled (bool): this material's applied enable_specular_transmission\n        \"\"\"\nself.set_input(inp=\"enable_specular_transmission\", val=enabled)\n@property\ndef specular_transmission_weight(self):\n\"\"\"\n        Returns:\n            float: this material's applied specular_transmission_weight\n        \"\"\"\nreturn self.get_input(inp=\"specular_transmission_weight\")\n@specular_transmission_weight.setter\ndef specular_transmission_weight(self, weight):\n\"\"\"\n        Args:\n             weight (float): this material's applied specular_transmission_weight\n        \"\"\"\nself.set_input(inp=\"specular_transmission_weight\", val=weight)\n@property\ndef diffuse_reflection_color(self):\n\"\"\"\n        Returns:\n            3-array: this material's diffuse_reflection_color in (R,G,B)\n        \"\"\"\nreturn np.array(self.get_input(inp=\"diffuse_reflection_color\"))\n@diffuse_reflection_color.setter\ndef diffuse_reflection_color(self, color):\n\"\"\"\n        Args:\n             color (3-array): this material's diffuse_reflection_color in (R,G,B)\n        \"\"\"\nself.set_input(inp=\"diffuse_reflection_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n@property\ndef specular_reflection_color(self):\n\"\"\"\n        Returns:\n            3-array: this material's specular_reflection_color in (R,G,B)\n        \"\"\"\nreturn np.array(self.get_input(inp=\"specular_reflection_color\"))\n@specular_reflection_color.setter\ndef specular_reflection_color(self, color):\n\"\"\"\n        Args:\n             color (3-array): this material's specular_reflection_color in (R,G,B)\n        \"\"\"\nself.set_input(inp=\"specular_reflection_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n@property\ndef specular_transmission_color(self):\n\"\"\"\n        Returns:\n            3-array: this material's specular_transmission_color in (R,G,B)\n        \"\"\"\nreturn np.array(self.get_input(inp=\"specular_transmission_color\"))\n@specular_transmission_color.setter\ndef specular_transmission_color(self, color):\n\"\"\"\n        Args:\n             color (3-array): this material's specular_transmission_color in (R,G,B)\n        \"\"\"\nself.set_input(inp=\"specular_transmission_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n@property\ndef specular_transmission_scattering_color(self):\n\"\"\"\n        Returns:\n            3-array: this material's specular_transmission_scattering_color in (R,G,B)\n        \"\"\"\nreturn np.array(self.get_input(inp=\"specular_transmission_scattering_color\"))\n@specular_transmission_scattering_color.setter\ndef specular_transmission_scattering_color(self, color):\n\"\"\"\n        Args:\n             color (3-array): this material's specular_transmission_scattering_color in (R,G,B)\n        \"\"\"\nself.set_input(inp=\"specular_transmission_scattering_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n</code></pre>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.ORM_texture","title":"<code>ORM_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied ORM_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.albedo_add","title":"<code>albedo_add</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied albedo_add</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.albedo_brightness","title":"<code>albedo_brightness</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied albedo_brightness</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.albedo_desaturation","title":"<code>albedo_desaturation</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied albedo_desaturation</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.ao_texture","title":"<code>ao_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied ao_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.ao_to_diffuse","title":"<code>ao_to_diffuse</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied ao_to_diffuse</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.bump_factor","title":"<code>bump_factor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied bump_factor</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_bump_factor","title":"<code>detail_bump_factor</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied detail_bump_factor</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_normalmap_texture","title":"<code>detail_normalmap_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied detail_normalmap_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_texture_rotate","title":"<code>detail_texture_rotate</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied detail_texture_rotate</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_texture_scale","title":"<code>detail_texture_scale</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>2-array: this material's applied detail_texture_scale</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_texture_translate","title":"<code>detail_texture_translate</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>2-array: this material's applied detail_texture_translate</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_color_constant","title":"<code>diffuse_color_constant</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>3-array: this material's applied (R,G,B) color</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_reflection_color","title":"<code>diffuse_reflection_color</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>3-array: this material's diffuse_reflection_color in (R,G,B)</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_reflection_weight","title":"<code>diffuse_reflection_weight</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied diffuse_reflection_weight</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_texture","title":"<code>diffuse_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>this material's applied diffuse_texture filepath</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_tint","title":"<code>diffuse_tint</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>3-array: this material's applied (R,G,B) diffuse_tint</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_color","title":"<code>emissive_color</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>3-array: this material's applied (R,G,B) emissive_color</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_color_texture","title":"<code>emissive_color_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied emissive_color_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_intensity","title":"<code>emissive_intensity</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied emissive_intensity</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_mask_texture","title":"<code>emissive_mask_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied emissive_mask_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_ORM_texture","title":"<code>enable_ORM_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied enable_ORM_texture</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_emission","title":"<code>enable_emission</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied enable_emission</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_opacity","title":"<code>enable_opacity</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied enable_opacity</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_opacity_texture","title":"<code>enable_opacity_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied enable_opacity_texture</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_specular_transmission","title":"<code>enable_specular_transmission</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied enable_specular_transmission</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.exclude_from_white_mode","title":"<code>exclude_from_white_mode</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied excludeFromWhiteMode</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.flip_tangent_u","title":"<code>flip_tangent_u</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied flip_tangent_u</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.flip_tangent_v","title":"<code>flip_tangent_v</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied flip_tangent_v</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.metallic_constant","title":"<code>metallic_constant</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied metallic_constant</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.metallic_texture","title":"<code>metallic_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied metallic_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.metallic_texture_influence","title":"<code>metallic_texture_influence</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied metallic_texture_influence</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.normalmap_texture","title":"<code>normalmap_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied normalmap_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_constant","title":"<code>opacity_constant</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied opacity_constant</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_mode","title":"<code>opacity_mode</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>this material's applied opacity_mode</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_texture","title":"<code>opacity_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied opacity_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_threshold","title":"<code>opacity_threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied opacity_threshold</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.project_uvw","title":"<code>project_uvw</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied project_uvw</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.reflection_roughness_constant","title":"<code>reflection_roughness_constant</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied reflection_roughness_constant</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.reflection_roughness_texture_influence","title":"<code>reflection_roughness_texture_influence</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied reflection_roughness_texture_influence</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.reflectionroughness_texture","title":"<code>reflectionroughness_texture</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or str: this material's applied reflectionroughness_texture fpath if there is a texture applied, else None</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader","title":"<code>shader</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>Usd.Shade: Shader associated with this material</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_input_names","title":"<code>shader_input_names</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>set</code> <p>All the shader input names associated with this material</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_level","title":"<code>specular_level</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied specular_level</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_reflection_color","title":"<code>specular_reflection_color</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>3-array: this material's specular_reflection_color in (R,G,B)</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_transmission_color","title":"<code>specular_transmission_color</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>3-array: this material's specular_transmission_color in (R,G,B)</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_transmission_scattering_color","title":"<code>specular_transmission_scattering_color</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>3-array: this material's specular_transmission_scattering_color in (R,G,B)</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_transmission_weight","title":"<code>specular_transmission_weight</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied specular_transmission_weight</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.texture_rotate","title":"<code>texture_rotate</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>this material's applied texture_rotate</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.texture_scale","title":"<code>texture_scale</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>2-array: this material's applied texture_scale</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.texture_translate","title":"<code>texture_translate</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>2-array: this material's applied texture_translate</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.uv_space_index","title":"<code>uv_space_index</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>this material's applied uv_space_index</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.world_or_object","title":"<code>world_or_object</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>this material's applied world_or_object</p>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.bind","title":"<code>bind(target_prim_path)</code>","text":"<p>Bind this material to an arbitrary prim (usually a visual mesh prim)</p> <p>Parameters:</p> Name Type Description Default <code>target_prim_path</code> <code>str</code> <p>prim path of the Prim to bind to</p> required Source code in <code>omnigibson/prims/material_prim.py</code> <pre><code>def bind(self, target_prim_path):\n\"\"\"\n    Bind this material to an arbitrary prim (usually a visual mesh prim)\n    Args:\n        target_prim_path (str): prim path of the Prim to bind to\n    \"\"\"\nbind_material(prim_path=target_prim_path, material_path=self.prim_path)\n</code></pre>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.get_input","title":"<code>get_input(inp)</code>","text":"<p>Grabs the input with corresponding name @inp associated with this material and shader</p> <p>Parameters:</p> Name Type Description Default <code>inp</code> <code>str</code> <p>Name of the shader input whose value will be grabbed</p> required <p>Returns:</p> Name Type Description <code>any</code> <p>value of the requested @inp</p> Source code in <code>omnigibson/prims/material_prim.py</code> <pre><code>def get_input(self, inp):\n\"\"\"\n    Grabs the input with corresponding name @inp associated with this material and shader\n    Args:\n        inp (str): Name of the shader input whose value will be grabbed\n    Returns:\n        any: value of the requested @inp\n    \"\"\"\nreturn self._shader.GetInput(inp).Get()\n</code></pre>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.set_input","title":"<code>set_input(inp, val)</code>","text":"<p>Sets the input with corresponding name @inp associated with this material and shader</p> <p>Parameters:</p> Name Type Description Default <code>inp</code> <code>str</code> <p>Name of the shader input whose value will be set</p> required <code>val</code> <code>any</code> <p>Value to set for the input. This should be the valid type for that attribute.</p> required Source code in <code>omnigibson/prims/material_prim.py</code> <pre><code>def set_input(self, inp, val):\n\"\"\"\n    Sets the input with corresponding name @inp associated with this material and shader\n    Args:\n        inp (str): Name of the shader input whose value will be set\n        val (any): Value to set for the input. This should be the valid type for that attribute.\n    \"\"\"\n# Make sure the input exists first, so we avoid segfaults with \"invalid null prim\"\nassert inp in self.shader_input_names, \\\n        f\"Got invalid shader input to set! Current inputs are: {self.shader_input_names}. Got: {inp}\"\nself._shader.GetInput(inp).Set(val)\n</code></pre>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_force_populate","title":"<code>shader_force_populate(render=True)</code>","text":"<p>Force populate inputs and outputs of the shader</p> <p>Parameters:</p> Name Type Description Default <code>render</code> <code>bool</code> <p>If True, takes a rendering step before force populating the inputs and outputs. Note that a rendering step is necessary to load these I/Os, though if a step has already occurred externally, no additional rendering step is needed</p> <code>True</code> Source code in <code>omnigibson/prims/material_prim.py</code> <pre><code>def shader_force_populate(self, render=True):\n\"\"\"\n    Force populate inputs and outputs of the shader\n    Args:\n        render (bool): If True, takes a rendering step before force populating the inputs and outputs.\n            Note that a rendering step is necessary to load these I/Os, though if a step has already\n            occurred externally, no additional rendering step is needed\n    \"\"\"\nassert self._shader is not None\nasyncio.run(self._load_mdl_parameters(render=render))\n</code></pre>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_input_names_by_type","title":"<code>shader_input_names_by_type(input_type)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>input_type</code> <code>str</code> <p>input type</p> required <p>Returns:</p> Name Type Description <code>set</code> <p>All the shader input names associated with this material that match the given input type</p> Source code in <code>omnigibson/prims/material_prim.py</code> <pre><code>def shader_input_names_by_type(self, input_type):\n\"\"\"\n    Args:\n        input_type (str): input type\n    Returns:\n        set: All the shader input names associated with this material that match the given input type\n    \"\"\"\nreturn {inp.GetBaseName() for inp in self._shader.GetInputs() if inp.GetTypeName().cppTypeName == input_type}\n</code></pre>"},{"location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_update_asset_paths_with_root_path","title":"<code>shader_update_asset_paths_with_root_path(root_path)</code>","text":"<p>Similar to @shader_update_asset_paths, except in this case, root_path is explicitly provided by the caller.</p> <p>Parameters:</p> Name Type Description Default <code>root_path</code> <code>str</code> <p>root to be pre-appended to the original asset paths</p> required Source code in <code>omnigibson/prims/material_prim.py</code> <pre><code>def shader_update_asset_paths_with_root_path(self, root_path):\n\"\"\"\n    Similar to @shader_update_asset_paths, except in this case, root_path is explicitly provided by the caller.\n    Args:\n        root_path (str): root to be pre-appended to the original asset paths\n    \"\"\"\nfor inp_name in self.shader_input_names_by_type(\"SdfAssetPath\"):\ninp = self.get_input(inp_name)\n# If the input doesn't have any path, skip\nif inp is None:\ncontinue\noriginal_path = inp.path if inp.resolvedPath == \"\" else inp.resolvedPath\n# If the input has an empty path, skip\nif original_path == \"\":\ncontinue\nnew_path = os.path.join(root_path, original_path)\nself.set_input(inp_name, new_path)\n</code></pre>"},{"location":"reference/prims/prim_base.html","title":"prim_base","text":""},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim","title":"<code>BasePrim</code>","text":"<p>         Bases: <code>Serializable</code>, <code>UniquelyNamed</code>, <code>Recreatable</code>, <code>ABC</code></p> <p>Provides high level functions to deal with a basic prim and its attributes/ properties. If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created.</p> the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init, <p>unless it is a non-root articulation link.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected for their class.</p> <code>None</code> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>class BasePrim(Serializable, UniquelyNamed, Recreatable, ABC):\n\"\"\"\n    Provides high level functions to deal with a basic prim and its attributes/ properties.\n    If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created.\n    Note: the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init,\n        unless it is a non-root articulation link.\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected\n            for their class.\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\nself._prim_path = prim_path\nself._name = name\nself._load_config = {} if load_config is None else load_config\n# Other values that will be filled in at runtime\nself._applied_visual_material = None\nself._loaded = False                                # Whether this prim exists in the stage or not\nself._initialized = False                           # Whether this prim has its internal handles / info initialized or not (occurs AFTER and INDEPENDENTLY from loading!)\nself._prim = None\nself._state_size = None\nself._n_duplicates = 0                              # Simple counter for keeping track of duplicates for unique name indexing\n# Run some post-loading steps if this prim has already been loaded\nif is_prim_path_valid(prim_path=self._prim_path):\nlog.debug(f\"prim {name} already exists, skipping load\")\nself._prim = get_prim_at_path(prim_path=self._prim_path)\nself._loaded = True\n# Run post load.\nself._post_load()\n# Run super init\nsuper().__init__()\ndef _initialize(self):\n\"\"\"\n        Initializes state of this object and sets up any references necessary post-loading. Should be implemented by\n        sub-class for extended utility\n        \"\"\"\npass\ndef initialize(self):\n\"\"\"\n        Initializes state of this object and sets up any references necessary post-loading. Subclasses should\n        implement / extend the _initialize() method.\n        \"\"\"\nassert not self._initialized, \\\n            f\"Prim {self.name} at prim_path {self._prim_path} can only be initialized once! (It is already initialized)\"\nself._initialize()\n# Cache state size\nself._state_size = len(self.dump_state(serialized=True))\nself._initialized = True\ndef load(self):\n\"\"\"\n        Load this prim into omniverse, and return loaded prim reference.\n        Returns:\n            Usd.Prim: Prim object loaded into the simulator\n        \"\"\"\nif self._loaded:\nraise ValueError(\"Cannot load a single prim multiple times.\")\n# Load prim\nself._prim = self._load()\nself._loaded = True\n# Run any post-loading logic\nself._post_load()\nreturn self._prim\ndef _post_load(self):\n\"\"\"\n        Any actions that should be taken (e.g.: modifying the object's properties such as scale, visibility, additional\n        joints, etc.) that should be taken after loading the raw object into omniverse but BEFORE we initialize the\n        object and grab its handles and internal references. By default, this is a no-op.\n        \"\"\"\npass\ndef remove(self):\n\"\"\"\n        Removes this prim from omniverse stage\n        \"\"\"\nif not self._loaded:\nraise ValueError(\"Cannot remove a prim that was never loaded.\")\n# Remove prim if it can be deleted\nif check_deletable_prim(self.prim_path):\ndelete_prim(self.prim_path)\n# Also clear the name so we can reuse this later\nself.remove_names(include_all_owned=True)\n@abstractmethod\ndef _load(self):\n\"\"\"\n        Loads the raw prim into the simulator. Any post-processing should be done in @self._post_load()\n        \"\"\"\nraise NotImplementedError()\n@property\ndef loaded(self):\nreturn self._loaded\n@property\ndef initialized(self):\nreturn self._initialized\n@property\ndef state_size(self):\n# This is the cached value\nreturn self._state_size\n@property\ndef prim_path(self):\n\"\"\"\n        Returns:\n            str: prim path in the stage.\n        \"\"\"\nreturn self._prim_path\n@property\ndef name(self):\n\"\"\"\n        Returns:\n            str: unique name assigned to this prim\n        \"\"\"\nreturn self._name\n@property\ndef prim(self):\n\"\"\"\n        Returns:\n            Usd.Prim: USD Prim object that this object holds.\n        \"\"\"\nreturn self._prim\n@property\ndef property_names(self):\n\"\"\"\n        Returns:\n            set of str: Set of property names that this prim has (e.g.: visibility, proxyPrim, etc.)\n        \"\"\"\nreturn set(self._prim.GetPropertyNames())\n@property\ndef visible(self):\n\"\"\"\n        Returns:\n            bool: true if the prim is visible in stage. false otherwise.\n        \"\"\"\nreturn UsdGeom.Imageable(self.prim).ComputeVisibility(Usd.TimeCode.Default()) != UsdGeom.Tokens.invisible\n@visible.setter\ndef visible(self, visible):\n\"\"\"\n        Sets the visibility of the prim in stage.\n        Args:\n            visible (bool): flag to set the visibility of the usd prim in stage.\n        \"\"\"\nimageable = UsdGeom.Imageable(self.prim)\nif visible:\nimageable.MakeVisible()\nelse:\nimageable.MakeInvisible()\nreturn\ndef is_valid(self):\n\"\"\"\n        Returns:\n            bool: True is the current prim path corresponds to a valid prim in stage. False otherwise.\n        \"\"\"\nreturn is_prim_path_valid(self.prim_path)\ndef change_prim_path(self, new_prim_path):\n\"\"\"\n        Moves prim from the old path to a new one.\n        Args:\n            new_prim_path (str): new path of the prim to be moved to.\n        \"\"\"\nmove_prim(path_from=self.prim_path, path_to=new_prim_path)\nself._prim_path = new_prim_path\nself._prim = get_prim_at_path(self._prim_path)\nreturn\ndef get_attribute(self, attr):\n\"\"\"\n        Get this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n        Returns:\n            any: value of the requested @attribute\n        \"\"\"\nreturn self._prim.GetAttribute(attr).Get()\ndef set_attribute(self, attr, val):\n\"\"\"\n        Set this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n        Args:\n            attr (str): Attribute to set\n            val (any): Value to set for the attribute. This should be the valid type for that attribute.\n        \"\"\"\nself._prim.GetAttribute(attr).Set(val)\ndef get_property(self, prop):\n\"\"\"\n        Sets property @prop with value @val\n        Args:\n            prop (str): Name of the property to get. See Raw USD Properties in the GUI for examples of property names\n        Returns:\n            any: Property value\n        \"\"\"\nself._prim.GetProperty(prop).Get()\ndef set_property(self, prop, val):\n\"\"\"\n        Sets property @prop with value @val\n        Args:\n            prop (str): Name of the property to set. See Raw USD Properties in the GUI for examples of property names\n            val (any): Value to set for the property. Should be valid for that property\n        \"\"\"\nself._prim.GetProperty(prop).Set(val)\ndef get_custom_data(self):\n\"\"\"\n        Get custom data associated with this prim\n        Returns:\n            dict: Dictionary of any custom information\n        \"\"\"\nreturn self._prim.GetCustomData()\ndef _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n\"\"\"\n        Generates a new instance of this prim's class with specified @prim_path, @name, and @load_config, but otherwise\n        all other kwargs should be identical to this instance's values.\n        Args:\n            prim_path (str): Absolute path to the newly generated prim\n            name (str): Name for the newly created prim\n            load_config (dict): Keyword-mapped kwargs to use to set specific attributes for the created prim's instance\n        Returns:\n            BasePrim: Generated prim object (not loaded, and not initialized!)\n        \"\"\"\nreturn self.__class__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef duplicate(self, prim_path):\n\"\"\"\n        Duplicates this object, and generates a new instance at @prim_path.\n        Note that the created object is automatically loaded into the simulator, but is NOT initialized\n        until a sim step occurs!\n        Args:\n            prim_path (str): Absolute path to the newly generated prim\n        Returns:\n            BasePrim: Generated prim object\n        \"\"\"\nnew_prim = self._create_prim_with_same_kwargs(\nprim_path=prim_path,\nname=f\"{self.name}_copy{self._n_duplicates}\",\nload_config=self._load_config,\n)\nog.sim.import_object(new_prim, register=False, auto_initialize=True)\n# Increment duplicate count\nself._n_duplicates += 1\n# Set visibility\nnew_prim.visible = self.visible\nreturn new_prim\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>unique name assigned to this prim</p>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.prim","title":"<code>prim</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>Usd.Prim: USD Prim object that this object holds.</p>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.prim_path","title":"<code>prim_path</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>prim path in the stage.</p>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.property_names","title":"<code>property_names</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>set of str: Set of property names that this prim has (e.g.: visibility, proxyPrim, etc.)</p>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.visible","title":"<code>visible</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>true if the prim is visible in stage. false otherwise.</p>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.change_prim_path","title":"<code>change_prim_path(new_prim_path)</code>","text":"<p>Moves prim from the old path to a new one.</p> <p>Parameters:</p> Name Type Description Default <code>new_prim_path</code> <code>str</code> <p>new path of the prim to be moved to.</p> required Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def change_prim_path(self, new_prim_path):\n\"\"\"\n    Moves prim from the old path to a new one.\n    Args:\n        new_prim_path (str): new path of the prim to be moved to.\n    \"\"\"\nmove_prim(path_from=self.prim_path, path_to=new_prim_path)\nself._prim_path = new_prim_path\nself._prim = get_prim_at_path(self._prim_path)\nreturn\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.duplicate","title":"<code>duplicate(prim_path)</code>","text":"<p>Duplicates this object, and generates a new instance at @prim_path. Note that the created object is automatically loaded into the simulator, but is NOT initialized until a sim step occurs!</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Absolute path to the newly generated prim</p> required <p>Returns:</p> Name Type Description <code>BasePrim</code> <p>Generated prim object</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def duplicate(self, prim_path):\n\"\"\"\n    Duplicates this object, and generates a new instance at @prim_path.\n    Note that the created object is automatically loaded into the simulator, but is NOT initialized\n    until a sim step occurs!\n    Args:\n        prim_path (str): Absolute path to the newly generated prim\n    Returns:\n        BasePrim: Generated prim object\n    \"\"\"\nnew_prim = self._create_prim_with_same_kwargs(\nprim_path=prim_path,\nname=f\"{self.name}_copy{self._n_duplicates}\",\nload_config=self._load_config,\n)\nog.sim.import_object(new_prim, register=False, auto_initialize=True)\n# Increment duplicate count\nself._n_duplicates += 1\n# Set visibility\nnew_prim.visible = self.visible\nreturn new_prim\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.get_attribute","title":"<code>get_attribute(attr)</code>","text":"<p>Get this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()</p> <p>Returns:</p> Name Type Description <code>any</code> <p>value of the requested @attribute</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def get_attribute(self, attr):\n\"\"\"\n    Get this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n    Returns:\n        any: value of the requested @attribute\n    \"\"\"\nreturn self._prim.GetAttribute(attr).Get()\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.get_custom_data","title":"<code>get_custom_data()</code>","text":"<p>Get custom data associated with this prim</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary of any custom information</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def get_custom_data(self):\n\"\"\"\n    Get custom data associated with this prim\n    Returns:\n        dict: Dictionary of any custom information\n    \"\"\"\nreturn self._prim.GetCustomData()\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.get_property","title":"<code>get_property(prop)</code>","text":"<p>Sets property @prop with value @val</p> <p>Parameters:</p> Name Type Description Default <code>prop</code> <code>str</code> <p>Name of the property to get. See Raw USD Properties in the GUI for examples of property names</p> required <p>Returns:</p> Name Type Description <code>any</code> <p>Property value</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def get_property(self, prop):\n\"\"\"\n    Sets property @prop with value @val\n    Args:\n        prop (str): Name of the property to get. See Raw USD Properties in the GUI for examples of property names\n    Returns:\n        any: Property value\n    \"\"\"\nself._prim.GetProperty(prop).Get()\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.initialize","title":"<code>initialize()</code>","text":"<p>Initializes state of this object and sets up any references necessary post-loading. Subclasses should implement / extend the _initialize() method.</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def initialize(self):\n\"\"\"\n    Initializes state of this object and sets up any references necessary post-loading. Subclasses should\n    implement / extend the _initialize() method.\n    \"\"\"\nassert not self._initialized, \\\n        f\"Prim {self.name} at prim_path {self._prim_path} can only be initialized once! (It is already initialized)\"\nself._initialize()\n# Cache state size\nself._state_size = len(self.dump_state(serialized=True))\nself._initialized = True\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.is_valid","title":"<code>is_valid()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>True is the current prim path corresponds to a valid prim in stage. False otherwise.</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def is_valid(self):\n\"\"\"\n    Returns:\n        bool: True is the current prim path corresponds to a valid prim in stage. False otherwise.\n    \"\"\"\nreturn is_prim_path_valid(self.prim_path)\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.load","title":"<code>load()</code>","text":"<p>Load this prim into omniverse, and return loaded prim reference.</p> <p>Returns:</p> Type Description <p>Usd.Prim: Prim object loaded into the simulator</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def load(self):\n\"\"\"\n    Load this prim into omniverse, and return loaded prim reference.\n    Returns:\n        Usd.Prim: Prim object loaded into the simulator\n    \"\"\"\nif self._loaded:\nraise ValueError(\"Cannot load a single prim multiple times.\")\n# Load prim\nself._prim = self._load()\nself._loaded = True\n# Run any post-loading logic\nself._post_load()\nreturn self._prim\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.remove","title":"<code>remove()</code>","text":"<p>Removes this prim from omniverse stage</p> Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def remove(self):\n\"\"\"\n    Removes this prim from omniverse stage\n    \"\"\"\nif not self._loaded:\nraise ValueError(\"Cannot remove a prim that was never loaded.\")\n# Remove prim if it can be deleted\nif check_deletable_prim(self.prim_path):\ndelete_prim(self.prim_path)\n# Also clear the name so we can reuse this later\nself.remove_names(include_all_owned=True)\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.set_attribute","title":"<code>set_attribute(attr, val)</code>","text":"<p>Set this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()</p> <p>Parameters:</p> Name Type Description Default <code>attr</code> <code>str</code> <p>Attribute to set</p> required <code>val</code> <code>any</code> <p>Value to set for the attribute. This should be the valid type for that attribute.</p> required Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def set_attribute(self, attr, val):\n\"\"\"\n    Set this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n    Args:\n        attr (str): Attribute to set\n        val (any): Value to set for the attribute. This should be the valid type for that attribute.\n    \"\"\"\nself._prim.GetAttribute(attr).Set(val)\n</code></pre>"},{"location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.set_property","title":"<code>set_property(prop, val)</code>","text":"<p>Sets property @prop with value @val</p> <p>Parameters:</p> Name Type Description Default <code>prop</code> <code>str</code> <p>Name of the property to set. See Raw USD Properties in the GUI for examples of property names</p> required <code>val</code> <code>any</code> <p>Value to set for the property. Should be valid for that property</p> required Source code in <code>omnigibson/prims/prim_base.py</code> <pre><code>def set_property(self, prop, val):\n\"\"\"\n    Sets property @prop with value @val\n    Args:\n        prop (str): Name of the property to set. See Raw USD Properties in the GUI for examples of property names\n        val (any): Value to set for the property. Should be valid for that property\n    \"\"\"\nself._prim.GetProperty(prop).Set(val)\n</code></pre>"},{"location":"reference/prims/rigid_prim.html","title":"rigid_prim","text":""},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim","title":"<code>RigidPrim</code>","text":"<p>         Bases: <code>XFormPrim</code></p> <p>Provides high level functions to deal with a rigid body prim and its attributes/ properties. If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created.</p> if the prim does not already have a rigid body api applied to it before it is loaded, <p>it will apply it.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be specified:</p> <p>scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds     to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling. mass (None or float): If specified, mass of this body in kg density (None or float): If specified, density of this body in kg / m^3 visual_only (None or bool): If specified, whether this prim should include collisions or not.     Default is True.</p> <code>None</code> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>class RigidPrim(XFormPrim):\n\"\"\"\n    Provides high level functions to deal with a rigid body prim and its attributes/ properties.\n    If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created.\n    Notes: if the prim does not already have a rigid body api applied to it before it is loaded,\n        it will apply it.\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be\n            specified:\n            scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds\n                to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.\n            mass (None or float): If specified, mass of this body in kg\n            density (None or float): If specified, density of this body in kg / m^3\n            visual_only (None or bool): If specified, whether this prim should include collisions or not.\n                Default is True.\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\n# Other values that will be filled in at runtime\nself._dc = None                     # Dynamic control interface\nself._cs = None                     # Contact sensor interface\nself._handle = None\nself._contact_handle = None\nself._body_name = None\nself._rigid_api = None\nself._physx_rigid_api = None\nself._physx_contact_report_api = None\nself._mass_api = None\nself._visual_only = None\nself._collision_meshes = None\nself._visual_meshes = None\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Apply rigid body and mass APIs\nself._rigid_api = UsdPhysics.RigidBodyAPI(self._prim) if self._prim.HasAPI(UsdPhysics.RigidBodyAPI) else \\\n            UsdPhysics.RigidBodyAPI.Apply(self._prim)\nself._physx_rigid_api = PhysxSchema.PhysxRigidBodyAPI(self._prim) if \\\n            self._prim.HasAPI(PhysxSchema.PhysxRigidBodyAPI) else PhysxSchema.PhysxRigidBodyAPI.Apply(self._prim)\nself._mass_api = UsdPhysics.MassAPI(self._prim) if self._prim.HasAPI(UsdPhysics.MassAPI) else \\\n            UsdPhysics.MassAPI.Apply(self._prim)\n# Only create contact report api if we're not visual only\nif not self._visual_only:\nself._physx_contact_report_api_api = PhysxSchema.PhysxContactReportAPI(self._prim) if \\\n                self._prim.HasAPI(PhysxSchema.PhysxContactReportAPI) else \\\n                PhysxSchema.PhysxContactReportAPI.Apply(self._prim)\n# Store references to owned visual / collision meshes\n# We iterate over all children of this object's prim,\n# and grab any that are presumed to be meshes\nself.update_meshes()\n# Possibly set the mass / density\nif not self.has_collision_meshes:\n# A meta (virtual) link has no collision meshes; set a negligible mass and a zero density (ignored)\nself.mass = 1e-6\nself.density = 0.0\nelif \"mass\" in self._load_config and self._load_config[\"mass\"] is not None:\nself.mass = self._load_config[\"mass\"]\nif \"density\" in self._load_config and self._load_config[\"density\"] is not None:\nself.density = self._load_config[\"density\"]\n# Set the visual-only attribute\n# This automatically handles setting collisions / gravity appropriately\nself.visual_only = self._load_config[\"visual_only\"] if \\\n            \"visual_only\" in self._load_config and self._load_config[\"visual_only\"] is not None else False\n# Create contact sensor\nself._cs = _s.acquire_contact_sensor_interface()\n# self._create_contact_sensor()\ndef _initialize(self):\n# Run super method first\nsuper()._initialize()\n# Get dynamic control and contact sensing interfaces\nself._dc = _dynamic_control.acquire_dynamic_control_interface()\n# Initialize all owned meshes\nfor mesh_group in (self._collision_meshes, self._visual_meshes):\nfor mesh in mesh_group.values():\nmesh.initialize()\n# We grab contact info for the first time before setting our internal handle, because this changes the dc handle\nif self.contact_reporting_enabled:\nself._cs.get_rigid_body_raw_data(self._prim_path)\n# Grab handle to this rigid body and get name\nself.update_handles()\nself._body_name = self.prim_path.split(\"/\")[-1]\ndef update_meshes(self):\n\"\"\"\n        Helper function to refresh owned visual and collision meshes. Useful for synchronizing internal data if\n        additional bodies are added manually\n        \"\"\"\n# Make sure to clean up all pre-existing names for all collision_meshes\nif self._collision_meshes is not None:\nfor collision_mesh in self._collision_meshes.values():\ncollision_mesh.remove_names()\n# Make sure to clean up all pre-existing names for all visual_meshes\nif self._visual_meshes is not None:\nfor visual_mesh in self._visual_meshes.values():\nvisual_mesh.remove_names()\nself._collision_meshes, self._visual_meshes = dict(), dict()\nprims_to_check = []\ncoms, vols = [], []\nfor prim in self._prim.GetChildren():\nprims_to_check.append(prim)\nfor child in prim.GetChildren():\nprims_to_check.append(child)\nfor prim in prims_to_check:\nif prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\nmesh_name, mesh_path = prim.GetName(), prim.GetPrimPath().__str__()\nmesh_prim = get_prim_at_path(prim_path=mesh_path)\nmesh_kwargs = {\"prim_path\": mesh_path, \"name\": f\"{self._name}:{mesh_name}\"}\nif mesh_prim.HasAPI(UsdPhysics.CollisionAPI):\nmesh = CollisionGeomPrim(**mesh_kwargs)\n# We also modify the collision mesh's contact and rest offsets, since omni's default values result\n# in lightweight objects sometimes not triggering contacts correctly\nmesh.set_contact_offset(m.DEFAULT_CONTACT_OFFSET)\nmesh.set_rest_offset(m.DEFAULT_REST_OFFSET)\nself._collision_meshes[mesh_name] = mesh\n# We construct a trimesh object from this mesh in order to infer its center-of-mass and volume\n# TODO: Cleaner way to aggregate this information? Right now we just skip if we encounter a primitive\nmesh_vertices = mesh_prim.GetAttribute(\"points\").Get()\nif mesh_vertices is not None and len(mesh_vertices) &gt;= 4:\nmsh = mesh_prim_to_trimesh_mesh(mesh_prim)\ncoms.append(msh.center_mass)\nvols.append(msh.volume)\nelse:\nself._visual_meshes[mesh_name] = VisualGeomPrim(**mesh_kwargs)\n# If we have any collision meshes, we aggregate their center of mass and volume values to set the center of mass\n# for this link\nif len(coms) &gt; 0:\ncom = (np.array(coms) * np.array(vols).reshape(-1, 1)).sum(axis=0) / np.sum(vols)\nself.set_attribute(\"physics:centerOfMass\", Gf.Vec3f(*com))\ndef enable_collisions(self):\n\"\"\"\n        Enable collisions for this RigidPrim\n        \"\"\"\n# Iterate through all owned collision meshes and toggle on their collisions\nfor col_mesh in self._collision_meshes.values():\ncol_mesh.collision_enabled = True\ndef disable_collisions(self):\n\"\"\"\n        Disable collisions for this RigidPrim\n        \"\"\"\n# Iterate through all owned collision meshes and toggle off their collisions\nfor col_mesh in self._collision_meshes.values():\ncol_mesh.collision_enabled = False\ndef update_handles(self):\n\"\"\"\n        Updates all internal handles for this prim, in case they change since initialization\n        \"\"\"\nself._handle = None if self.kinematic_only else self._dc.get_rigid_body(self._prim_path)\ndef contact_list(self):\n\"\"\"\n        Get list of all current contacts with this rigid body\n        Returns:\n            list of CsRawData: raw contact info for this rigid body\n        \"\"\"\n# # Make sure we have the ability to grab contacts for this object\n# assert self._physx_contact_report_api is not None, \\\n#     \"Cannot grab contacts for this rigid prim without Physx's contact report API being added!\"\ncontacts = []\nif self.contact_reporting_enabled:\nraw_data = self._cs.get_rigid_body_raw_data(self._prim_path)\nfor c in raw_data:\n# contact sensor handles and dynamic articulation handles are not comparable\n# every prim has a cs to convert (cs) handle to prim path (decode_body_name)\n# but not every prim (e.g. groundPlane) has a dc to convert prim path to (dc) handle (get_rigid_body)\n# so simpler to convert both handles (int) to prim paths (str) for comparison\nc = [*c] # CsRawData enforces body0 and body1 types to be ints, but we want strings\nc[2] = self._cs.decode_body_name(c[2])\nc[3] = self._cs.decode_body_name(c[3])\ncontacts.append(CsRawData(*c))\nreturn contacts\ndef set_linear_velocity(self, velocity):\n\"\"\"\n        Sets the linear velocity of the prim in stage.\n        Args:\n            velocity (np.ndarray): linear velocity to set the rigid prim to. Shape (3,).\n        \"\"\"\nif self.dc_is_accessible:\nself._dc.set_rigid_body_linear_velocity(self._handle, velocity)\nelse:\nself._rigid_api.GetVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\ndef get_linear_velocity(self):\n\"\"\"\n        Returns:\n            np.ndarray: current linear velocity of the the rigid prim. Shape (3,).\n        \"\"\"\nif self.dc_is_accessible:\nlin_vel = np.array(self._dc.get_rigid_body_linear_velocity(self._handle))\nelse:\nlin_vel = self._rigid_api.GetVelocityAttr().Get()\nreturn np.array(lin_vel)\ndef set_angular_velocity(self, velocity):\n\"\"\"\n        Sets the angular velocity of the prim in stage.\n        Args:\n            velocity (np.ndarray): angular velocity to set the rigid prim to. Shape (3,).\n        \"\"\"\nif self.dc_is_accessible:\nself._dc.set_rigid_body_angular_velocity(self._handle, velocity)\nelse:\nself._rigid_api.GetAngularVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\ndef get_angular_velocity(self):\n\"\"\"\n        Returns:\n            np.ndarray: current angular velocity of the the rigid prim. Shape (3,).\n        \"\"\"\nif self.dc_is_accessible:\nreturn np.array(self._dc.get_rigid_body_angular_velocity(self._handle))\nelse:\nreturn np.array(self._rigid_api.GetAngularVelocityAttr().Get())\ndef set_position_orientation(self, position=None, orientation=None):\nif self.dc_is_accessible:\ncurrent_position, current_orientation = self.get_position_orientation()\nif position is None:\nposition = current_position\nif orientation is None:\norientation = current_orientation\npose = _dynamic_control.Transform(position, orientation)\nself._dc.set_rigid_body_pose(self._handle, pose)\nelse:\n# Call super method by default\nsuper().set_position_orientation(position=position, orientation=orientation)\ndef get_position_orientation(self):\nif self.dc_is_accessible:\npose = self._dc.get_rigid_body_pose(self._handle)\npos, ori = np.asarray(pose.p), np.asarray(pose.r)\nelse:\n# Call super method by default\npos, ori = super().get_position_orientation()\nreturn np.array(pos), np.array(ori)\ndef set_local_pose(self, translation=None, orientation=None):\nif self.dc_is_accessible:\ncurrent_translation, current_orientation = self.get_local_pose()\ntranslation = current_translation if translation is None else translation\norientation = current_orientation if orientation is None else orientation\norientation = orientation[[3, 0, 1, 2]]  # Flip from x,y,z,w to w,x,y,z\nlocal_transform = tf_matrix_from_pose(translation=translation, orientation=orientation)\nparent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\nUsd.TimeCode.Default()\n)\nmy_world_transform = np.matmul(parent_world_tf, local_transform)\ntransform = Gf.Transform()\ntransform.SetMatrix(Gf.Matrix4d(np.transpose(my_world_transform)))\ncalculated_position = transform.GetTranslation()\ncalculated_orientation = transform.GetRotation().GetQuat()\nself.set_position_orientation(\nposition=np.array(calculated_position), orientation=gf_quat_to_np_array(calculated_orientation)\n)\nelse:\n# Call super method by default\nsuper().set_local_pose(translation=translation, orientation=orientation)\ndef get_local_pose(self):\nif self.dc_is_accessible:\nparent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\nUsd.TimeCode.Default()\n)\nworld_position, world_orientation = self.get_position_orientation()\nworld_orientation = world_orientation[[3, 0, 1, 2]]  # Flip from x,y,z,w to w,x,y,z\nmy_world_transform = tf_matrix_from_pose(translation=world_position, orientation=world_orientation)\nlocal_transform = np.matmul(np.linalg.inv(np.transpose(parent_world_tf)), my_world_transform)\ntransform = Gf.Transform()\ntransform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\ncalculated_translation = transform.GetTranslation()\ncalculated_orientation = transform.GetRotation().GetQuat()\npos, ori = np.array(calculated_translation), gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]] # Flip from w,x,y,z to x,y,z,w to\nelse:\n# Call super method by default\npos, ori = super().get_local_pose()\nreturn np.array(pos), np.array(ori)\n@property\ndef handle(self):\n\"\"\"\n        Handle used by Isaac Sim's dynamic control module to reference this rigid prim\n        Returns:\n            int: ID handle assigned to this prim from dynamic_control interface\n        \"\"\"\nreturn self._handle\n@property\ndef body_name(self):\n\"\"\"\n        Returns:\n            str: Name of this body\n        \"\"\"\nreturn self._body_name\n@property\ndef collision_meshes(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping collision mesh names (str) to mesh prims (CollisionMeshPrim) owned by\n                this rigid body\n        \"\"\"\nreturn self._collision_meshes\n@property\ndef visual_meshes(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping visual mesh names (str) to mesh prims (VisualMeshPrim) owned by\n                this rigid body\n        \"\"\"\nreturn self._visual_meshes\n@property\ndef visual_only(self):\n\"\"\"\n        Returns:\n            bool: Whether this link is a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\nreturn self._visual_only\n@property\ndef has_collision_meshes(self):\n\"\"\"\n        Returns:\n            bool: Whether this link has any collision mesh\n        \"\"\"\nreturn len(self._collision_meshes) &gt; 0\n@visual_only.setter\ndef visual_only(self, val):\n\"\"\"\n        Sets the visaul only state of this link\n        Args:\n            val (bool): Whether this link should be a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\n# Set gravity and collisions based on value\nif val:\nself.disable_collisions()\nself.disable_gravity()\nelse:\nself.enable_collisions()\nself.enable_gravity()\n# Also set the internal value\nself._visual_only = val\n@property\ndef volume(self):\n\"\"\"\n        Note: Currently it doesn't support Capsule type yet\n        Returns:\n            float: total volume of all the collision meshes of the rigid body in m^3.\n        \"\"\"\n# TODO (eric): revise this once omni exposes API to query volume of GeomPrims\nvolume = 0.0\nfor collision_mesh in self._collision_meshes.values():\nmesh = collision_mesh.prim\nmesh_type = mesh.GetPrimTypeInfo().GetTypeName()\nassert mesh_type in GEOM_TYPES, f\"Invalid collision mesh type: {mesh_type}\"\nif mesh_type == \"Mesh\":\n# We construct a trimesh object from this mesh in order to infer its volume\ntrimesh_mesh = mesh_prim_to_trimesh_mesh(mesh)\nif trimesh_mesh.is_volume:\nmesh_volume = trimesh_mesh.volume\nelif trimesh.triangles.all_coplanar(trimesh_mesh.triangles):\n# The mesh is a plane, so we can't make a convex hull -- return 0 volume\nmesh_volume = 0.0\nelse:\n# Fallback to convex hull approximation\nmesh_volume = trimesh_mesh.convex_hull.volume\nelif mesh_type == \"Sphere\":\nmesh_volume = 4 / 3 * np.pi * (mesh.GetAttribute(\"radius\").Get() ** 3)\nelif mesh_type == \"Cube\":\nmesh_volume = mesh.GetAttribute(\"size\").Get() ** 3\nelif mesh_type == \"Cone\":\nmesh_volume = np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get() / 3\nelif mesh_type == \"Cylinder\":\nmesh_volume = np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get()\nelse:\nraise ValueError(f\"Cannot compute volume for mesh of type: {mesh_type}\")\nvolume += mesh_volume * np.product(collision_mesh.get_world_scale())\nreturn volume\n@volume.setter\ndef volume(self, volume):\nraise NotImplementedError(\"Cannot set volume directly for an link!\")\n@property\ndef mass(self):\n\"\"\"\n        Returns:\n            float: mass of the rigid body in kg.\n        \"\"\"\nraw_usd_mass = self._mass_api.GetMassAttr().Get()\n# If our raw_usd_mass isn't specified, we check dynamic control if possible (sim is playing),\n# otherwise we fallback to analytical computation of volume * density\nif raw_usd_mass != 0:\nmass = raw_usd_mass\nelif self.dc_is_accessible:\nmass = self.rigid_body_properties.mass\nelse:\nmass = self.volume * self.density\nreturn mass\n@mass.setter\ndef mass(self, mass):\n\"\"\"\n        Args:\n            mass (float): mass of the rigid body in kg.\n        \"\"\"\nself._mass_api.GetMassAttr().Set(mass)\n@property\ndef density(self):\n\"\"\"\n        Returns:\n            float: density of the rigid body in kg / m^3.\n        \"\"\"\nraw_usd_mass = self._mass_api.GetMassAttr().Get()\n# We first check if the raw usd mass is specified, since mass overrides density\n# If it's specified, we infer density based on that value divided by volume\n# Otherwise, we try to directly grab the raw usd density value, and if that value\n# does not exist, we return 1000 since that is the canonical density assigned by omniverse\nif raw_usd_mass != 0:\ndensity = raw_usd_mass / self.volume\nelse:\ndensity = self._mass_api.GetDensityAttr().Get()\nif density == 0:\ndensity = 1000.0\nreturn density\n@density.setter\ndef density(self, density):\n\"\"\"\n        Args:\n            density (float): density of the rigid body in kg / m^3.\n        \"\"\"\nself._mass_api.GetDensityAttr().Set(density)\n@property\ndef kinematic_only(self):\n\"\"\"\n        Returns:\n            bool: Whether this object is a kinematic-only object (otherwise, it is a rigid body). A kinematic-only\n                object is not subject to simulator dynamics, and remains fixed unless the user explicitly sets the\n                body's pose / velocities. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html?highlight=rigid%20body%20enabled#kinematic-rigid-bodies\n                for more information\n        \"\"\"\nreturn self.get_attribute(\"physics:kinematicEnabled\")\n@kinematic_only.setter\ndef kinematic_only(self, val):\n\"\"\"\n        Args:\n            val (bool): Whether this object is a kinematic-only object (otherwise, it is a rigid body). A kinematic-only\n                object is not subject to simulator dynamics, and remains fixed unless the user explicitly sets the\n                body's pose / velocities. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html?highlight=rigid%20body%20enabled#kinematic-rigid-bodies\n                for more information\n        \"\"\"\nself.set_attribute(\"physics:kinematicEnabled\", val)\nself.set_attribute(\"physics:rigidBodyEnabled\", not val)\n@property\ndef solver_position_iteration_count(self):\n\"\"\"\n        Returns:\n            int: How many position iterations to take per physics step by the physx solver\n        \"\"\"\nreturn self.get_attribute(\"physxRigidBody:solverPositionIterationCount\")\n@solver_position_iteration_count.setter\ndef solver_position_iteration_count(self, count):\n\"\"\"\n        Sets how many position iterations to take per physics step by the physx solver\n        Args:\n            count (int): How many position iterations to take per physics step by the physx solver\n        \"\"\"\nself.set_attribute(\"physxRigidBody:solverPositionIterationCount\", count)\n@property\ndef solver_velocity_iteration_count(self):\n\"\"\"\n        Returns:\n            int: How many velocity iterations to take per physics step by the physx solver\n        \"\"\"\nreturn self.get_attribute(\"physxRigidBody:solverVelocityIterationCount\")\n@solver_velocity_iteration_count.setter\ndef solver_velocity_iteration_count(self, count):\n\"\"\"\n        Sets how many velocity iterations to take per physics step by the physx solver\n        Args:\n            count (int): How many velocity iterations to take per physics step by the physx solver\n        \"\"\"\nself.set_attribute(\"physxRigidBody:solverVelocityIterationCount\", count)\n@property\ndef stabilization_threshold(self):\n\"\"\"\n        Returns:\n            float: threshold for stabilizing this rigid body\n        \"\"\"\nreturn self.get_attribute(\"physxRigidBody:stabilizationThreshold\")\n@stabilization_threshold.setter\ndef stabilization_threshold(self, threshold):\n\"\"\"\n        Sets threshold for stabilizing this rigid body\n        Args:\n            threshold (float): stabilizing threshold\n        \"\"\"\nself.set_attribute(\"physxRigidBody:stabilizationThreshold\", threshold)\n@property\ndef sleep_threshold(self):\n\"\"\"\n        Returns:\n            float: threshold for sleeping this rigid body\n        \"\"\"\nreturn self.get_attribute(\"physxRigidBody:sleepThreshold\")\n@sleep_threshold.setter\ndef sleep_threshold(self, threshold):\n\"\"\"\n        Sets threshold for sleeping this rigid body\n        Args:\n            threshold (float): Sleeping threshold\n        \"\"\"\nself.set_attribute(\"physxRigidBody:sleepThreshold\", threshold)\n@property\ndef ccd_enabled(self):\n\"\"\"\n        Returns:\n            bool: whether CCD is enabled or not for this link\n        \"\"\"\nreturn self.get_attribute(\"physxRigidBody:enableCCD\")\n@ccd_enabled.setter\ndef ccd_enabled(self, enabled):\n\"\"\"\n        Args:\n            enabled (bool): whether CCD should be enabled or not for this link\n        \"\"\"\nself.set_attribute(\"physxRigidBody:enableCCD\", enabled)\n@property\ndef contact_reporting_enabled(self):\n\"\"\"\n        Returns:\n            bool: Whether contact reporting is enabled for this rigid prim or not\n        \"\"\"\nreturn self._prim.HasAPI(PhysxSchema.PhysxContactReportAPI)\n@property\ndef rigid_body_properties(self):\n\"\"\"\n        Returns:\n            None or RigidBodyProperty: Properties for this rigid body, if accessible. If they do not exist or\n                dc cannot be queried, this will return None\n        \"\"\"\nreturn self._dc.get_rigid_body_properties(self._handle) if self.dc_is_accessible else None\n@property\ndef dc_is_accessible(self):\n\"\"\"\n        Checks if dynamic control interface is accessible (checks whether we have a dc handle for this body\n        and if dc is simulating)\n        Returns:\n            bool: Whether dc interface can be used or not\n        \"\"\"\nreturn self._handle is not None and self._dc.is_simulating() and not self.kinematic_only\ndef enable_gravity(self):\n\"\"\"\n        Enables gravity for this rigid body\n        \"\"\"\nself.set_attribute(\"physxRigidBody:disableGravity\", False)\n# self._dc.set_rigid_body_disable_gravity(self._handle, False)\ndef disable_gravity(self):\n\"\"\"\n        Disables gravity for this rigid body\n        \"\"\"\nself.set_attribute(\"physxRigidBody:disableGravity\", True)\n# self._dc.set_rigid_body_disable_gravity(self._handle, True)\ndef wake(self):\n\"\"\"\n        Enable physics for this rigid body\n        \"\"\"\nif self.dc_is_accessible:\nself._dc.wake_up_rigid_body(self._handle)\ndef sleep(self):\n\"\"\"\n        Disable physics for this rigid body\n        \"\"\"\nif self.dc_is_accessible:\nself._dc.sleep_rigid_body(self._handle)\ndef _dump_state(self):\n# Grab pose from super class\nstate = super()._dump_state()\nstate[\"lin_vel\"] = self.get_linear_velocity()\nstate[\"ang_vel\"] = self.get_angular_velocity()\nreturn state\ndef _load_state(self, state):\n# Call super first\nsuper()._load_state(state=state)\n# Set velocities if not kinematic\nif not self.kinematic_only:\nself.set_linear_velocity(np.array(state[\"lin_vel\"]))\nself.set_angular_velocity(np.array(state[\"ang_vel\"]))\ndef _serialize(self, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\nreturn np.concatenate([\nstate_flat,\nstate[\"lin_vel\"],\nstate[\"ang_vel\"],\n]).astype(float)\ndef _deserialize(self, state):\n# Call supermethod first\nstate_dic, idx = super()._deserialize(state=state)\n# We deserialize deterministically by knowing the order of values -- lin_vel, ang_vel\nstate_dic[\"lin_vel\"] = state[idx: idx+3]\nstate_dic[\"ang_vel\"] = state[idx + 3: idx + 6]\nreturn state_dic, idx + 6\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.body_name","title":"<code>body_name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this body</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.ccd_enabled","title":"<code>ccd_enabled</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>whether CCD is enabled or not for this link</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.collision_meshes","title":"<code>collision_meshes</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping collision mesh names (str) to mesh prims (CollisionMeshPrim) owned by this rigid body</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.contact_reporting_enabled","title":"<code>contact_reporting_enabled</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether contact reporting is enabled for this rigid prim or not</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.dc_is_accessible","title":"<code>dc_is_accessible</code>  <code>property</code>","text":"<p>Checks if dynamic control interface is accessible (checks whether we have a dc handle for this body and if dc is simulating)</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether dc interface can be used or not</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.density","title":"<code>density</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>density of the rigid body in kg / m^3.</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.handle","title":"<code>handle</code>  <code>property</code>","text":"<p>Handle used by Isaac Sim's dynamic control module to reference this rigid prim</p> <p>Returns:</p> Name Type Description <code>int</code> <p>ID handle assigned to this prim from dynamic_control interface</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.has_collision_meshes","title":"<code>has_collision_meshes</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this link has any collision mesh</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.kinematic_only","title":"<code>kinematic_only</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this object is a kinematic-only object (otherwise, it is a rigid body). A kinematic-only object is not subject to simulator dynamics, and remains fixed unless the user explicitly sets the body's pose / velocities. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics/rigid-bodies.html?highlight=rigid%20body%20enabled#kinematic-rigid-bodies for more information</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.mass","title":"<code>mass</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>mass of the rigid body in kg.</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.rigid_body_properties","title":"<code>rigid_body_properties</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or RigidBodyProperty: Properties for this rigid body, if accessible. If they do not exist or dc cannot be queried, this will return None</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.sleep_threshold","title":"<code>sleep_threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>threshold for sleeping this rigid body</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.solver_position_iteration_count","title":"<code>solver_position_iteration_count</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>How many position iterations to take per physics step by the physx solver</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.solver_velocity_iteration_count","title":"<code>solver_velocity_iteration_count</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>How many velocity iterations to take per physics step by the physx solver</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.stabilization_threshold","title":"<code>stabilization_threshold</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>threshold for stabilizing this rigid body</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.visual_meshes","title":"<code>visual_meshes</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping visual mesh names (str) to mesh prims (VisualMeshPrim) owned by this rigid body</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.visual_only","title":"<code>visual_only</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this link is a visual-only link (i.e.: no gravity or collisions applied)</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.volume","title":"<code>volume</code>  <code>property</code> <code>writable</code>","text":"<p>Note: Currently it doesn't support Capsule type yet</p> <p>Returns:</p> Name Type Description <code>float</code> <p>total volume of all the collision meshes of the rigid body in m^3.</p>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.contact_list","title":"<code>contact_list()</code>","text":"<p>Get list of all current contacts with this rigid body</p> <p>Returns:</p> Type Description <p>list of CsRawData: raw contact info for this rigid body</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def contact_list(self):\n\"\"\"\n    Get list of all current contacts with this rigid body\n    Returns:\n        list of CsRawData: raw contact info for this rigid body\n    \"\"\"\n# # Make sure we have the ability to grab contacts for this object\n# assert self._physx_contact_report_api is not None, \\\n#     \"Cannot grab contacts for this rigid prim without Physx's contact report API being added!\"\ncontacts = []\nif self.contact_reporting_enabled:\nraw_data = self._cs.get_rigid_body_raw_data(self._prim_path)\nfor c in raw_data:\n# contact sensor handles and dynamic articulation handles are not comparable\n# every prim has a cs to convert (cs) handle to prim path (decode_body_name)\n# but not every prim (e.g. groundPlane) has a dc to convert prim path to (dc) handle (get_rigid_body)\n# so simpler to convert both handles (int) to prim paths (str) for comparison\nc = [*c] # CsRawData enforces body0 and body1 types to be ints, but we want strings\nc[2] = self._cs.decode_body_name(c[2])\nc[3] = self._cs.decode_body_name(c[3])\ncontacts.append(CsRawData(*c))\nreturn contacts\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.disable_collisions","title":"<code>disable_collisions()</code>","text":"<p>Disable collisions for this RigidPrim</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def disable_collisions(self):\n\"\"\"\n    Disable collisions for this RigidPrim\n    \"\"\"\n# Iterate through all owned collision meshes and toggle off their collisions\nfor col_mesh in self._collision_meshes.values():\ncol_mesh.collision_enabled = False\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.disable_gravity","title":"<code>disable_gravity()</code>","text":"<p>Disables gravity for this rigid body</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def disable_gravity(self):\n\"\"\"\n    Disables gravity for this rigid body\n    \"\"\"\nself.set_attribute(\"physxRigidBody:disableGravity\", True)\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.enable_collisions","title":"<code>enable_collisions()</code>","text":"<p>Enable collisions for this RigidPrim</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def enable_collisions(self):\n\"\"\"\n    Enable collisions for this RigidPrim\n    \"\"\"\n# Iterate through all owned collision meshes and toggle on their collisions\nfor col_mesh in self._collision_meshes.values():\ncol_mesh.collision_enabled = True\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.enable_gravity","title":"<code>enable_gravity()</code>","text":"<p>Enables gravity for this rigid body</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def enable_gravity(self):\n\"\"\"\n    Enables gravity for this rigid body\n    \"\"\"\nself.set_attribute(\"physxRigidBody:disableGravity\", False)\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.get_angular_velocity","title":"<code>get_angular_velocity()</code>","text":"<p>Returns:</p> Type Description <p>np.ndarray: current angular velocity of the the rigid prim. Shape (3,).</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def get_angular_velocity(self):\n\"\"\"\n    Returns:\n        np.ndarray: current angular velocity of the the rigid prim. Shape (3,).\n    \"\"\"\nif self.dc_is_accessible:\nreturn np.array(self._dc.get_rigid_body_angular_velocity(self._handle))\nelse:\nreturn np.array(self._rigid_api.GetAngularVelocityAttr().Get())\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.get_linear_velocity","title":"<code>get_linear_velocity()</code>","text":"<p>Returns:</p> Type Description <p>np.ndarray: current linear velocity of the the rigid prim. Shape (3,).</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def get_linear_velocity(self):\n\"\"\"\n    Returns:\n        np.ndarray: current linear velocity of the the rigid prim. Shape (3,).\n    \"\"\"\nif self.dc_is_accessible:\nlin_vel = np.array(self._dc.get_rigid_body_linear_velocity(self._handle))\nelse:\nlin_vel = self._rigid_api.GetVelocityAttr().Get()\nreturn np.array(lin_vel)\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.set_angular_velocity","title":"<code>set_angular_velocity(velocity)</code>","text":"<p>Sets the angular velocity of the prim in stage.</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>np.ndarray</code> <p>angular velocity to set the rigid prim to. Shape (3,).</p> required Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def set_angular_velocity(self, velocity):\n\"\"\"\n    Sets the angular velocity of the prim in stage.\n    Args:\n        velocity (np.ndarray): angular velocity to set the rigid prim to. Shape (3,).\n    \"\"\"\nif self.dc_is_accessible:\nself._dc.set_rigid_body_angular_velocity(self._handle, velocity)\nelse:\nself._rigid_api.GetAngularVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.set_linear_velocity","title":"<code>set_linear_velocity(velocity)</code>","text":"<p>Sets the linear velocity of the prim in stage.</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>np.ndarray</code> <p>linear velocity to set the rigid prim to. Shape (3,).</p> required Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def set_linear_velocity(self, velocity):\n\"\"\"\n    Sets the linear velocity of the prim in stage.\n    Args:\n        velocity (np.ndarray): linear velocity to set the rigid prim to. Shape (3,).\n    \"\"\"\nif self.dc_is_accessible:\nself._dc.set_rigid_body_linear_velocity(self._handle, velocity)\nelse:\nself._rigid_api.GetVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.sleep","title":"<code>sleep()</code>","text":"<p>Disable physics for this rigid body</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def sleep(self):\n\"\"\"\n    Disable physics for this rigid body\n    \"\"\"\nif self.dc_is_accessible:\nself._dc.sleep_rigid_body(self._handle)\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.update_handles","title":"<code>update_handles()</code>","text":"<p>Updates all internal handles for this prim, in case they change since initialization</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def update_handles(self):\n\"\"\"\n    Updates all internal handles for this prim, in case they change since initialization\n    \"\"\"\nself._handle = None if self.kinematic_only else self._dc.get_rigid_body(self._prim_path)\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.update_meshes","title":"<code>update_meshes()</code>","text":"<p>Helper function to refresh owned visual and collision meshes. Useful for synchronizing internal data if additional bodies are added manually</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def update_meshes(self):\n\"\"\"\n    Helper function to refresh owned visual and collision meshes. Useful for synchronizing internal data if\n    additional bodies are added manually\n    \"\"\"\n# Make sure to clean up all pre-existing names for all collision_meshes\nif self._collision_meshes is not None:\nfor collision_mesh in self._collision_meshes.values():\ncollision_mesh.remove_names()\n# Make sure to clean up all pre-existing names for all visual_meshes\nif self._visual_meshes is not None:\nfor visual_mesh in self._visual_meshes.values():\nvisual_mesh.remove_names()\nself._collision_meshes, self._visual_meshes = dict(), dict()\nprims_to_check = []\ncoms, vols = [], []\nfor prim in self._prim.GetChildren():\nprims_to_check.append(prim)\nfor child in prim.GetChildren():\nprims_to_check.append(child)\nfor prim in prims_to_check:\nif prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\nmesh_name, mesh_path = prim.GetName(), prim.GetPrimPath().__str__()\nmesh_prim = get_prim_at_path(prim_path=mesh_path)\nmesh_kwargs = {\"prim_path\": mesh_path, \"name\": f\"{self._name}:{mesh_name}\"}\nif mesh_prim.HasAPI(UsdPhysics.CollisionAPI):\nmesh = CollisionGeomPrim(**mesh_kwargs)\n# We also modify the collision mesh's contact and rest offsets, since omni's default values result\n# in lightweight objects sometimes not triggering contacts correctly\nmesh.set_contact_offset(m.DEFAULT_CONTACT_OFFSET)\nmesh.set_rest_offset(m.DEFAULT_REST_OFFSET)\nself._collision_meshes[mesh_name] = mesh\n# We construct a trimesh object from this mesh in order to infer its center-of-mass and volume\n# TODO: Cleaner way to aggregate this information? Right now we just skip if we encounter a primitive\nmesh_vertices = mesh_prim.GetAttribute(\"points\").Get()\nif mesh_vertices is not None and len(mesh_vertices) &gt;= 4:\nmsh = mesh_prim_to_trimesh_mesh(mesh_prim)\ncoms.append(msh.center_mass)\nvols.append(msh.volume)\nelse:\nself._visual_meshes[mesh_name] = VisualGeomPrim(**mesh_kwargs)\n# If we have any collision meshes, we aggregate their center of mass and volume values to set the center of mass\n# for this link\nif len(coms) &gt; 0:\ncom = (np.array(coms) * np.array(vols).reshape(-1, 1)).sum(axis=0) / np.sum(vols)\nself.set_attribute(\"physics:centerOfMass\", Gf.Vec3f(*com))\n</code></pre>"},{"location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.wake","title":"<code>wake()</code>","text":"<p>Enable physics for this rigid body</p> Source code in <code>omnigibson/prims/rigid_prim.py</code> <pre><code>def wake(self):\n\"\"\"\n    Enable physics for this rigid body\n    \"\"\"\nif self.dc_is_accessible:\nself._dc.wake_up_rigid_body(self._handle)\n</code></pre>"},{"location":"reference/prims/xform_prim.html","title":"xform_prim","text":""},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim","title":"<code>XFormPrim</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Provides high level functions to deal with an Xform prim and its attributes/ properties. If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created when self.load(...) is called.</p> the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init, <p>unless it is a non-root articulation link.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. For this xform prim, the below values can be specified:</p> <p>scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds     to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>class XFormPrim(BasePrim):\n\"\"\"\n    Provides high level functions to deal with an Xform prim and its attributes/ properties.\n    If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created when self.load(...) is called.\n    Note: the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init,\n        unless it is a non-root articulation link.\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. For this xform prim, the below values can be specified:\n            scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds\n                to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nload_config=None,\n):\n# Other values that will be filled in at runtime\nself._binding_api = None\nself._material = None\nself._collision_filter_api = None\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _load(self):\nreturn og.sim.stage.DefinePrim(self._prim_path, \"Xform\")\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Make sure all xforms have pose and scaling info\nself._set_xform_properties()\n# Create collision filter API\nself._collision_filter_api = UsdPhysics.FilteredPairsAPI(self._prim) if \\\n            self._prim.HasAPI(UsdPhysics.FilteredPairsAPI) else UsdPhysics.FilteredPairsAPI.Apply(self._prim)\n# Create binding API\nself._binding_api = UsdShade.MaterialBindingAPI(self.prim) if \\\n            self._prim.HasAPI(UsdShade.MaterialBindingAPI) else UsdShade.MaterialBindingAPI.Apply(self.prim)\n# Grab the attached material if it exists\nif self.has_material():\nself._material = MaterialPrim(\nprim_path=self._binding_api.GetDirectBinding().GetMaterialPath().pathString,\nname=f\"{self.name}:material\",\n)\n# Optionally set the scale and visibility\nif \"scale\" in self._load_config and self._load_config[\"scale\"] is not None:\nself.scale = self._load_config[\"scale\"]\ndef _set_xform_properties(self):\ncurrent_position, current_orientation = self.get_position_orientation()\nproperties_to_remove = [\n\"xformOp:rotateX\",\n\"xformOp:rotateXZY\",\n\"xformOp:rotateY\",\n\"xformOp:rotateYXZ\",\n\"xformOp:rotateYZX\",\n\"xformOp:rotateZ\",\n\"xformOp:rotateZYX\",\n\"xformOp:rotateZXY\",\n\"xformOp:rotateXYZ\",\n\"xformOp:transform\",\n]\nprop_names = self.prim.GetPropertyNames()\nxformable = UsdGeom.Xformable(self.prim)\nxformable.ClearXformOpOrder()\n# TODO: wont be able to delete props for non root links on articulated objects\nfor prop_name in prop_names:\nif prop_name in properties_to_remove:\nself.prim.RemoveProperty(prop_name)\nif \"xformOp:scale\" not in prop_names:\nxform_op_scale = xformable.AddXformOp(UsdGeom.XformOp.TypeScale, UsdGeom.XformOp.PrecisionDouble, \"\")\nxform_op_scale.Set(Gf.Vec3d([1.0, 1.0, 1.0]))\nelse:\nxform_op_scale = UsdGeom.XformOp(self._prim.GetAttribute(\"xformOp:scale\"))\nif \"xformOp:translate\" not in prop_names:\nxform_op_translate = xformable.AddXformOp(\nUsdGeom.XformOp.TypeTranslate, UsdGeom.XformOp.PrecisionDouble, \"\"\n)\nelse:\nxform_op_translate = UsdGeom.XformOp(self._prim.GetAttribute(\"xformOp:translate\"))\nif \"xformOp:orient\" not in prop_names:\nxform_op_rot = xformable.AddXformOp(UsdGeom.XformOp.TypeOrient, UsdGeom.XformOp.PrecisionDouble, \"\")\nelse:\nxform_op_rot = UsdGeom.XformOp(self._prim.GetAttribute(\"xformOp:orient\"))\nxformable.SetXformOpOrder([xform_op_translate, xform_op_rot, xform_op_scale])\nself.set_position_orientation(position=current_position, orientation=current_orientation)\nnew_position, new_orientation = self.get_position_orientation()\nr1 = R.from_quat(current_orientation).as_matrix()\nr2 = R.from_quat(new_orientation).as_matrix()\n# Make sure setting is done correctly\nassert np.allclose(new_position, current_position, atol=1e-4) and np.allclose(r1, r2, atol=1e-4), \\\n            f\"{self.prim_path}: old_pos: {current_position}, new_pos: {new_position}, \" \\\n            f\"old_orn: {current_orientation}, new_orn: {new_orientation}\"\ndef has_material(self):\n\"\"\"\n        Returns:\n            bool: True if there is a visual material bound to this prim. False otherwise\n        \"\"\"\nmaterial_path = self._binding_api.GetDirectBinding().GetMaterialPath().pathString\nreturn False if material_path == \"\" else True\ndef set_position_orientation(self, position=None, orientation=None):\n\"\"\"\n        Sets prim's pose with respect to the world frame\n        Args:\n            position (None or 3-array): if specified, (x,y,z) position in the world frame\n                Default is None, which means left unchanged.\n            orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the world frame.\n                Default is None, which means left unchanged.\n        \"\"\"\ncurrent_position, current_orientation = self.get_position_orientation()\nposition = current_position if position is None else np.array(position, dtype=float)\norientation = current_orientation if orientation is None else np.array(orientation, dtype=float)\norientation = orientation[[3, 0, 1, 2]]     # Flip from x,y,z,w to w,x,y,z\nmat = Gf.Transform()\nmat.SetRotation(Gf.Rotation(Gf.Quatd(*orientation)))\nmat.SetTranslation(Gf.Vec3d(*position))\n# mat.SetScale(Gf.Vec3d(*(self.get_world_scale() / self.scale)))\n# TODO (eric): understand why this (mat.setScale) works - this works empirically but it's unclear why.\nmat.SetScale(Gf.Vec3d(*(self.scale.astype(np.float64))))\nmy_world_transform = np.transpose(mat.GetMatrix())\nparent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\nparent_world_transform = np.transpose(parent_world_tf)\nlocal_transform = np.matmul(np.linalg.inv(parent_world_transform), my_world_transform)\ntransform = Gf.Transform()\ntransform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\ncalculated_translation = transform.GetTranslation()\ncalculated_orientation = transform.GetRotation().GetQuat()\nself.set_local_pose(\ntranslation=np.array(calculated_translation), orientation=gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]]     # Flip from w,x,y,z to x,y,z,w\n)\ndef get_position_orientation(self):\n\"\"\"\n        Gets prim's pose with respect to the world's frame.\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) position in the world frame\n                - 4-array: (x,y,z,w) quaternion orientation in the world frame\n        \"\"\"\nprim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\ntransform = Gf.Transform()\ntransform.SetMatrix(prim_tf)\nposition = transform.GetTranslation()\norientation = transform.GetRotation().GetQuat()\nreturn np.array(position), gf_quat_to_np_array(orientation)[[1, 2, 3, 0]]\ndef set_position(self, position):\n\"\"\"\n        Set this prim's position with respect to the world frame\n        Args:\n            position (3-array): (x,y,z) global cartesian position to set\n        \"\"\"\nself.set_position_orientation(position=position)\ndef get_position(self):\n\"\"\"\n        Get this prim's position with respect to the world frame\n        Returns:\n            3-array: (x,y,z) global cartesian position of this prim\n        \"\"\"\nreturn self.get_position_orientation()[0]\ndef set_orientation(self, orientation):\n\"\"\"\n        Set this prim's orientation with respect to the world frame\n        Args:\n            orientation (4-array): (x,y,z,w) global quaternion orientation to set\n        \"\"\"\nself.set_position_orientation(orientation=orientation)\ndef get_orientation(self):\n\"\"\"\n        Get this prim's orientation with respect to the world frame\n        Returns:\n            4-array: (x,y,z,w) global quaternion orientation of this prim\n        \"\"\"\nreturn self.get_position_orientation()[1]\ndef get_rpy(self):\n\"\"\"\n        Get this prim's orientation with respect to the world frame\n        Returns:\n            3-array: (roll, pitch, yaw) global euler orientation of this prim\n        \"\"\"\nreturn mat2euler(quat2mat(self.get_orientation()))\ndef get_local_pose(self):\n\"\"\"\n        Gets prim's pose with respect to the prim's local frame (it's parent frame)\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) position in the local frame\n                - 4-array: (x,y,z,w) quaternion orientation in the local frame\n        \"\"\"\nxform_translate_op = self.get_attribute(\"xformOp:translate\")\nxform_orient_op = self.get_attribute(\"xformOp:orient\")\nreturn np.array(xform_translate_op), gf_quat_to_np_array(xform_orient_op)[[1, 2, 3, 0]]\ndef set_local_pose(self, translation=None, orientation=None):\n\"\"\"\n        Sets prim's pose with respect to the local frame (the prim's parent frame).\n        Args:\n            translation (None or 3-array): if specified, (x,y,z) translation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n            orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n        \"\"\"\nproperties = self.prim.GetPropertyNames()\nif translation is not None:\ntranslation = Gf.Vec3d(*np.array(translation, dtype=float))\nif \"xformOp:translate\" not in properties:\ncarb.log_error(\n\"Translate property needs to be set for {} before setting its position\".format(self.name)\n)\nself.set_attribute(\"xformOp:translate\", translation)\nif orientation is not None:\norientation = np.array(orientation, dtype=float)[[3, 0, 1, 2]]\nif \"xformOp:orient\" not in properties:\ncarb.log_error(\n\"Orient property needs to be set for {} before setting its orientation\".format(self.name)\n)\nxform_op = self._prim.GetAttribute(\"xformOp:orient\")\nif xform_op.GetTypeName() == \"quatf\":\nrotq = Gf.Quatf(*orientation)\nelse:\nrotq = Gf.Quatd(*orientation)\nxform_op.Set(rotq)\nreturn\ndef get_world_scale(self):\n\"\"\"\n        Gets prim's scale with respect to the world's frame.\n        Returns:\n            np.ndarray: scale applied to the prim's dimensions in the world frame. shape is (3, ).\n        \"\"\"\nprim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\ntransform = Gf.Transform()\ntransform.SetMatrix(prim_tf)\nreturn np.array(transform.GetScale())\n@property\ndef scale(self):\n\"\"\"\n        Gets prim's scale with respect to the local frame (the parent's frame).\n        Returns:\n            np.ndarray: scale applied to the prim's dimensions in the local frame. shape is (3, ).\n        \"\"\"\nreturn np.array(self.get_attribute(\"xformOp:scale\"))\n@scale.setter\ndef scale(self, scale):\n\"\"\"\n        Sets prim's scale with respect to the local frame (the prim's parent frame).\n        Args:\n            scale (float or np.ndarray): scale to be applied to the prim's dimensions. shape is (3, ).\n                                          Defaults to None, which means left unchanged.\n        \"\"\"\nscale = np.array(scale, dtype=float) if isinstance(scale, Iterable) else np.ones(3) * scale\nscale = Gf.Vec3d(*scale)\nproperties = self.prim.GetPropertyNames()\nif \"xformOp:scale\" not in properties:\ncarb.log_error(\"Scale property needs to be set for {} before setting its scale\".format(self.name))\nself.set_attribute(\"xformOp:scale\", scale)\n@property\ndef aabb(self):\n\"\"\"\n        Get this xform's actual bounding box, axis-aligned in the world frame\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) lower corner of the bounding box\n                - 3-array: (x,y,z) upper corner of the bounding box\n        \"\"\"\nreturn BoundingBoxAPI.compute_aabb(self)\n@property\ndef aabb_extent(self):\n\"\"\"\n        Get this xform's actual bounding box extent\n        Returns:\n            3-array: (x,y,z) bounding box\n        \"\"\"\nmin_corner, max_corner = self.aabb\nreturn max_corner - min_corner\n@property\ndef aabb_center(self):\n\"\"\"\n        Get this xform's actual bounding box center\n        Returns:\n            3-array: (x,y,z) bounding box center\n        \"\"\"\nmin_corner, max_corner = self.aabb\nreturn (max_corner + min_corner) / 2.0\n@property\ndef material(self):\n\"\"\"\n        Returns:\n            None or MaterialPrim: The bound material to this prim, if there is one\n        \"\"\"\nreturn self._material\n@material.setter\ndef material(self, material):\n\"\"\"\n        Set the material @material for this prim. This will also bind the material to this prim\n        Args:\n            material (MaterialPrim): Material to bind to this prim\n        \"\"\"\nself._binding_api.Bind(UsdShade.Material(material.prim), bindingStrength=UsdShade.Tokens.weakerThanDescendants)\nself._material = material\ndef add_filtered_collision_pair(self, prim):\n\"\"\"\n        Adds a collision filter pair with another prim\n        Args:\n            prim (XFormPrim): Another prim to filter collisions with\n        \"\"\"\n# Add to both this prim's and the other prim's filtered pair\nself._collision_filter_api.GetFilteredPairsRel().AddTarget(prim.prim_path)\nprim._collision_filter_api.GetFilteredPairsRel().AddTarget(self._prim_path)\ndef remove_filtered_collision_pair(self, prim):\n\"\"\"\n        Removes a collision filter pair with another prim\n        Args:\n            prim (XFormPrim): Another prim to remove filter collisions with\n        \"\"\"\n# Add to both this prim's and the other prim's filtered pair\nself._collision_filter_api.GetFilteredPairsRel().RemoveTarget(prim.prim_path)\nprim._collision_filter_api.GetFilteredPairsRel().RemoveTarget(self._prim_path)\ndef _dump_state(self):\npos, ori = self.get_position_orientation()\nreturn dict(pos=pos, ori=ori)\ndef _load_state(self, state):\nself.set_position_orientation(np.array(state[\"pos\"]), np.array(state[\"ori\"]))\ndef _serialize(self, state):\nreturn np.concatenate([state[\"pos\"], state[\"ori\"]]).astype(float)\ndef _deserialize(self, state):\n# We deserialize deterministically by knowing the order of values -- pos, ori\nreturn dict(pos=state[0:3], ori=state[3:7]), 7\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.aabb","title":"<code>aabb</code>  <code>property</code>","text":"<p>Get this xform's actual bounding box, axis-aligned in the world frame</p> <p>Returns:</p> Type Description <p>2-tuple: - 3-array: (x,y,z) lower corner of the bounding box - 3-array: (x,y,z) upper corner of the bounding box</p>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.aabb_center","title":"<code>aabb_center</code>  <code>property</code>","text":"<p>Get this xform's actual bounding box center</p> <p>Returns:</p> Type Description <p>3-array: (x,y,z) bounding box center</p>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.aabb_extent","title":"<code>aabb_extent</code>  <code>property</code>","text":"<p>Get this xform's actual bounding box extent</p> <p>Returns:</p> Type Description <p>3-array: (x,y,z) bounding box</p>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.material","title":"<code>material</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>None or MaterialPrim: The bound material to this prim, if there is one</p>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.scale","title":"<code>scale</code>  <code>property</code> <code>writable</code>","text":"<p>Gets prim's scale with respect to the local frame (the parent's frame).</p> <p>Returns:</p> Type Description <p>np.ndarray: scale applied to the prim's dimensions in the local frame. shape is (3, ).</p>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.add_filtered_collision_pair","title":"<code>add_filtered_collision_pair(prim)</code>","text":"<p>Adds a collision filter pair with another prim</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>XFormPrim</code> <p>Another prim to filter collisions with</p> required Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def add_filtered_collision_pair(self, prim):\n\"\"\"\n    Adds a collision filter pair with another prim\n    Args:\n        prim (XFormPrim): Another prim to filter collisions with\n    \"\"\"\n# Add to both this prim's and the other prim's filtered pair\nself._collision_filter_api.GetFilteredPairsRel().AddTarget(prim.prim_path)\nprim._collision_filter_api.GetFilteredPairsRel().AddTarget(self._prim_path)\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_local_pose","title":"<code>get_local_pose()</code>","text":"<p>Gets prim's pose with respect to the prim's local frame (it's parent frame)</p> <p>Returns:</p> Type Description <p>2-tuple: - 3-array: (x,y,z) position in the local frame - 4-array: (x,y,z,w) quaternion orientation in the local frame</p> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def get_local_pose(self):\n\"\"\"\n    Gets prim's pose with respect to the prim's local frame (it's parent frame)\n    Returns:\n        2-tuple:\n            - 3-array: (x,y,z) position in the local frame\n            - 4-array: (x,y,z,w) quaternion orientation in the local frame\n    \"\"\"\nxform_translate_op = self.get_attribute(\"xformOp:translate\")\nxform_orient_op = self.get_attribute(\"xformOp:orient\")\nreturn np.array(xform_translate_op), gf_quat_to_np_array(xform_orient_op)[[1, 2, 3, 0]]\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_orientation","title":"<code>get_orientation()</code>","text":"<p>Get this prim's orientation with respect to the world frame</p> <p>Returns:</p> Type Description <p>4-array: (x,y,z,w) global quaternion orientation of this prim</p> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def get_orientation(self):\n\"\"\"\n    Get this prim's orientation with respect to the world frame\n    Returns:\n        4-array: (x,y,z,w) global quaternion orientation of this prim\n    \"\"\"\nreturn self.get_position_orientation()[1]\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_position","title":"<code>get_position()</code>","text":"<p>Get this prim's position with respect to the world frame</p> <p>Returns:</p> Type Description <p>3-array: (x,y,z) global cartesian position of this prim</p> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def get_position(self):\n\"\"\"\n    Get this prim's position with respect to the world frame\n    Returns:\n        3-array: (x,y,z) global cartesian position of this prim\n    \"\"\"\nreturn self.get_position_orientation()[0]\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_position_orientation","title":"<code>get_position_orientation()</code>","text":"<p>Gets prim's pose with respect to the world's frame.</p> <p>Returns:</p> Type Description <p>2-tuple: - 3-array: (x,y,z) position in the world frame - 4-array: (x,y,z,w) quaternion orientation in the world frame</p> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def get_position_orientation(self):\n\"\"\"\n    Gets prim's pose with respect to the world's frame.\n    Returns:\n        2-tuple:\n            - 3-array: (x,y,z) position in the world frame\n            - 4-array: (x,y,z,w) quaternion orientation in the world frame\n    \"\"\"\nprim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\ntransform = Gf.Transform()\ntransform.SetMatrix(prim_tf)\nposition = transform.GetTranslation()\norientation = transform.GetRotation().GetQuat()\nreturn np.array(position), gf_quat_to_np_array(orientation)[[1, 2, 3, 0]]\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_rpy","title":"<code>get_rpy()</code>","text":"<p>Get this prim's orientation with respect to the world frame</p> <p>Returns:</p> Type Description <p>3-array: (roll, pitch, yaw) global euler orientation of this prim</p> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def get_rpy(self):\n\"\"\"\n    Get this prim's orientation with respect to the world frame\n    Returns:\n        3-array: (roll, pitch, yaw) global euler orientation of this prim\n    \"\"\"\nreturn mat2euler(quat2mat(self.get_orientation()))\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_world_scale","title":"<code>get_world_scale()</code>","text":"<p>Gets prim's scale with respect to the world's frame.</p> <p>Returns:</p> Type Description <p>np.ndarray: scale applied to the prim's dimensions in the world frame. shape is (3, ).</p> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def get_world_scale(self):\n\"\"\"\n    Gets prim's scale with respect to the world's frame.\n    Returns:\n        np.ndarray: scale applied to the prim's dimensions in the world frame. shape is (3, ).\n    \"\"\"\nprim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\ntransform = Gf.Transform()\ntransform.SetMatrix(prim_tf)\nreturn np.array(transform.GetScale())\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.has_material","title":"<code>has_material()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>True if there is a visual material bound to this prim. False otherwise</p> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def has_material(self):\n\"\"\"\n    Returns:\n        bool: True if there is a visual material bound to this prim. False otherwise\n    \"\"\"\nmaterial_path = self._binding_api.GetDirectBinding().GetMaterialPath().pathString\nreturn False if material_path == \"\" else True\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.remove_filtered_collision_pair","title":"<code>remove_filtered_collision_pair(prim)</code>","text":"<p>Removes a collision filter pair with another prim</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>XFormPrim</code> <p>Another prim to remove filter collisions with</p> required Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def remove_filtered_collision_pair(self, prim):\n\"\"\"\n    Removes a collision filter pair with another prim\n    Args:\n        prim (XFormPrim): Another prim to remove filter collisions with\n    \"\"\"\n# Add to both this prim's and the other prim's filtered pair\nself._collision_filter_api.GetFilteredPairsRel().RemoveTarget(prim.prim_path)\nprim._collision_filter_api.GetFilteredPairsRel().RemoveTarget(self._prim_path)\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_local_pose","title":"<code>set_local_pose(translation=None, orientation=None)</code>","text":"<p>Sets prim's pose with respect to the local frame (the prim's parent frame).</p> <p>Parameters:</p> Name Type Description Default <code>translation</code> <code>None or 3-array</code> <p>if specified, (x,y,z) translation in the local frame of the prim (with respect to its parent prim). Default is None, which means left unchanged.</p> <code>None</code> <code>orientation</code> <code>None or 4-array</code> <p>if specified, (x,y,z,w) quaternion orientation in the local frame of the prim (with respect to its parent prim). Default is None, which means left unchanged.</p> <code>None</code> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def set_local_pose(self, translation=None, orientation=None):\n\"\"\"\n    Sets prim's pose with respect to the local frame (the prim's parent frame).\n    Args:\n        translation (None or 3-array): if specified, (x,y,z) translation in the local frame of the prim\n            (with respect to its parent prim). Default is None, which means left unchanged.\n        orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the local frame of the prim\n            (with respect to its parent prim). Default is None, which means left unchanged.\n    \"\"\"\nproperties = self.prim.GetPropertyNames()\nif translation is not None:\ntranslation = Gf.Vec3d(*np.array(translation, dtype=float))\nif \"xformOp:translate\" not in properties:\ncarb.log_error(\n\"Translate property needs to be set for {} before setting its position\".format(self.name)\n)\nself.set_attribute(\"xformOp:translate\", translation)\nif orientation is not None:\norientation = np.array(orientation, dtype=float)[[3, 0, 1, 2]]\nif \"xformOp:orient\" not in properties:\ncarb.log_error(\n\"Orient property needs to be set for {} before setting its orientation\".format(self.name)\n)\nxform_op = self._prim.GetAttribute(\"xformOp:orient\")\nif xform_op.GetTypeName() == \"quatf\":\nrotq = Gf.Quatf(*orientation)\nelse:\nrotq = Gf.Quatd(*orientation)\nxform_op.Set(rotq)\nreturn\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_orientation","title":"<code>set_orientation(orientation)</code>","text":"<p>Set this prim's orientation with respect to the world frame</p> <p>Parameters:</p> Name Type Description Default <code>orientation</code> <code>4-array</code> <p>(x,y,z,w) global quaternion orientation to set</p> required Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def set_orientation(self, orientation):\n\"\"\"\n    Set this prim's orientation with respect to the world frame\n    Args:\n        orientation (4-array): (x,y,z,w) global quaternion orientation to set\n    \"\"\"\nself.set_position_orientation(orientation=orientation)\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_position","title":"<code>set_position(position)</code>","text":"<p>Set this prim's position with respect to the world frame</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>3-array</code> <p>(x,y,z) global cartesian position to set</p> required Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def set_position(self, position):\n\"\"\"\n    Set this prim's position with respect to the world frame\n    Args:\n        position (3-array): (x,y,z) global cartesian position to set\n    \"\"\"\nself.set_position_orientation(position=position)\n</code></pre>"},{"location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_position_orientation","title":"<code>set_position_orientation(position=None, orientation=None)</code>","text":"<p>Sets prim's pose with respect to the world frame</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>None or 3-array</code> <p>if specified, (x,y,z) position in the world frame Default is None, which means left unchanged.</p> <code>None</code> <code>orientation</code> <code>None or 4-array</code> <p>if specified, (x,y,z,w) quaternion orientation in the world frame. Default is None, which means left unchanged.</p> <code>None</code> Source code in <code>omnigibson/prims/xform_prim.py</code> <pre><code>def set_position_orientation(self, position=None, orientation=None):\n\"\"\"\n    Sets prim's pose with respect to the world frame\n    Args:\n        position (None or 3-array): if specified, (x,y,z) position in the world frame\n            Default is None, which means left unchanged.\n        orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the world frame.\n            Default is None, which means left unchanged.\n    \"\"\"\ncurrent_position, current_orientation = self.get_position_orientation()\nposition = current_position if position is None else np.array(position, dtype=float)\norientation = current_orientation if orientation is None else np.array(orientation, dtype=float)\norientation = orientation[[3, 0, 1, 2]]     # Flip from x,y,z,w to w,x,y,z\nmat = Gf.Transform()\nmat.SetRotation(Gf.Rotation(Gf.Quatd(*orientation)))\nmat.SetTranslation(Gf.Vec3d(*position))\n# mat.SetScale(Gf.Vec3d(*(self.get_world_scale() / self.scale)))\n# TODO (eric): understand why this (mat.setScale) works - this works empirically but it's unclear why.\nmat.SetScale(Gf.Vec3d(*(self.scale.astype(np.float64))))\nmy_world_transform = np.transpose(mat.GetMatrix())\nparent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\nparent_world_transform = np.transpose(parent_world_tf)\nlocal_transform = np.matmul(np.linalg.inv(parent_world_transform), my_world_transform)\ntransform = Gf.Transform()\ntransform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\ncalculated_translation = transform.GetTranslation()\ncalculated_orientation = transform.GetRotation().GetQuat()\nself.set_local_pose(\ntranslation=np.array(calculated_translation), orientation=gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]]     # Flip from w,x,y,z to x,y,z,w\n)\n</code></pre>"},{"location":"reference/renderer_settings/index.html","title":"renderer_settings","text":""},{"location":"reference/renderer_settings/common_settings.html","title":"common_settings","text":""},{"location":"reference/renderer_settings/common_settings.html#renderer_settings.common_settings.CommonSettings","title":"<code>CommonSettings</code>","text":"<p>         Bases: <code>SettingsBase</code></p> <p>Common setting group that handles a variety of sub-settings, including:     - Rendering     - Geometry     - Materials     - Lighting     - Simple Fog     - Flow     - Debug View</p> Source code in <code>omnigibson/renderer_settings/common_settings.py</code> <pre><code>class CommonSettings(SettingsBase):\n\"\"\"\n    Common setting group that handles a variety of sub-settings, including:\n        - Rendering\n        - Geometry\n        - Materials\n        - Lighting\n        - Simple Fog\n        - Flow\n        - Debug View\n    \"\"\"\ndef __init__(self):\nself.render_settings = RenderSettings()\nself.geometry_settings = GeometrySettings()\nself.materials_settings = MaterialsSettings()\nself.lighting_settings = LightingSettings()\nself.simple_fog_setting = SimpleFogSettings()\nself.flow_settings = FlowSettings()\nself.debug_view_settings = DebugViewSettings()\n@property\ndef settings(self):\nsettings = {}\nsettings.update(self.render_settings.settings)\nsettings.update(self.geometry_settings.settings)\nsettings.update(self.materials_settings.settings)\nsettings.update(self.lighting_settings.settings)\nsettings.update(self.simple_fog_setting.settings)\nsettings.update(self.flow_settings.settings)\nsettings.update(self.debug_view_settings.settings)\nreturn settings\n</code></pre>"},{"location":"reference/renderer_settings/path_tracing_settings.html","title":"path_tracing_settings","text":""},{"location":"reference/renderer_settings/post_processing_settings.html","title":"post_processing_settings","text":""},{"location":"reference/renderer_settings/post_processing_settings.html#renderer_settings.post_processing_settings.PostProcessingSettings","title":"<code>PostProcessingSettings</code>","text":"<p>         Bases: <code>SettingsBase</code></p> <p>Post-Processing setting group that handles a variety of sub-settings, including:     - Tone Mapping     - Auto Exposure     - Color Correction     - Color Grading     - XR Compositing     - Chromatic Aberration     - Depth Of Field Camera Overrides     - Motion Blur     - FTT Bloom     - TV Noise &amp; Film Grain     - Reshade</p> Source code in <code>omnigibson/renderer_settings/post_processing_settings.py</code> <pre><code>class PostProcessingSettings(SettingsBase):\n\"\"\"\n    Post-Processing setting group that handles a variety of sub-settings, including:\n        - Tone Mapping\n        - Auto Exposure\n        - Color Correction\n        - Color Grading\n        - XR Compositing\n        - Chromatic Aberration\n        - Depth Of Field Camera Overrides\n        - Motion Blur\n        - FTT Bloom\n        - TV Noise &amp; Film Grain\n        - Reshade\n    \"\"\"\ndef __init__(self):\nself.tone_mapping_settings = ToneMappingSettings()\nself.auto_exposure_settings = AutoExposureSettings()\nself.color_correction_settings = ColorCorrectionSettings()\nself.color_grading_settings = ColorGradingSettings()\nself.xr_compositing_settings = XRCompositingSettings()\nself.chromatic_aberration_settings = ChromaticAberrationSettings()\nself.depth_of_field_settings = DepthOfFieldSettings()\nself.motion_blur_settings = MotionBlurSettings()\nself.ftt_bloom_settings = FTTBloomSettings()\nself.tv_noise_grain_settings = TVNoiseGrainSettings()\nself.reshade_settings = ReshadeSettings()\n@property\ndef settings(self):\nsettings = {}\nsettings.update(self.tone_mapping_settings.settings)\nsettings.update(self.auto_exposure_settings.settings)\nsettings.update(self.color_correction_settings.settings)\nsettings.update(self.color_grading_settings.settings)\nsettings.update(self.xr_compositing_settings.settings)\nsettings.update(self.chromatic_aberration_settings.settings)\nsettings.update(self.depth_of_field_settings.settings)\nsettings.update(self.motion_blur_settings.settings)\nsettings.update(self.ftt_bloom_settings.settings)\nsettings.update(self.tv_noise_grain_settings.settings)\nsettings.update(self.reshade_settings.settings)\nreturn settings\n</code></pre>"},{"location":"reference/renderer_settings/real_time_settings.html","title":"real_time_settings","text":""},{"location":"reference/renderer_settings/real_time_settings.html#renderer_settings.real_time_settings.RealTimeSettings","title":"<code>RealTimeSettings</code>","text":"<p>         Bases: <code>SettingsBase</code></p> <p>Real-Time setting group that handles a variety of sub-settings, including:     - Eco Mode     - Anti Aliasing     - Direct Lighting     - Reflections     - Translucency     - Global Volumetric Effects     - Caustics     - Indirect Diffuse Lighting     - RTMulti GPU (if multiple GPUs available)</p> Source code in <code>omnigibson/renderer_settings/real_time_settings.py</code> <pre><code>class RealTimeSettings(SettingsBase):\n\"\"\"\n    Real-Time setting group that handles a variety of sub-settings, including:\n        - Eco Mode\n        - Anti Aliasing\n        - Direct Lighting\n        - Reflections\n        - Translucency\n        - Global Volumetric Effects\n        - Caustics\n        - Indirect Diffuse Lighting\n        - RTMulti GPU (if multiple GPUs available)\n    \"\"\"\ndef __init__(self):\nself.eco_mode_settings = EcoModeSettings()\nself.anti_aliasing_settings = AntiAliasingSettings()\nself.direct_lighting_settings = DirectLightingSettings()\nself.reflections_settings = ReflectionsSettings()\nself.translucency_settings = TranslucencySettings()\nself.global_volumetric_effects_settings = GlobalVolumetricEffectsSettings()\nself.caustics_settings = CausticsSettings()\nself.indirect_diffuse_lighting_settings = IndirectDiffuseLightingSettings()\ngpu_count = carb.settings.get_settings().get(\"/renderer/multiGpu/currentGpuCount\")\nif gpu_count and gpu_count &gt; 1:\nself.rt_multi_gpu_settings = RTMultiGPUSettings()\n@property\ndef settings(self):\nsettings = {}\nsettings.update(self.eco_mode_settings.settings)\nsettings.update(self.anti_aliasing_settings.settings)\nsettings.update(self.direct_lighting_settings.settings)\nsettings.update(self.reflections_settings.settings)\nsettings.update(self.translucency_settings.settings)\nsettings.update(self.global_volumetric_effects_settings.settings)\nsettings.update(self.caustics_settings.settings)\nsettings.update(self.indirect_diffuse_lighting_settings.settings)\ngpu_count = carb.settings.get_settings().get(\"/renderer/multiGpu/currentGpuCount\")\nif gpu_count and gpu_count &gt; 1:\nsettings.update(self.rt_multi_gpu_settings.settings)\nreturn settings\n</code></pre>"},{"location":"reference/renderer_settings/renderer_settings.html","title":"renderer_settings","text":""},{"location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings","title":"<code>RendererSettings</code>","text":"<p>Controller for all renderer settings.</p> Source code in <code>omnigibson/renderer_settings/renderer_settings.py</code> <pre><code>@singleton\nclass RendererSettings:\n\"\"\"\n    Controller for all renderer settings.\n    \"\"\"\ndef __init__(self):\nself._carb_settings = carb.settings.get_settings()\nself.common_settings = CommonSettings()\nself.path_tracing_settings = PathTracingSettings()\nself.post_processing_settings = PostProcessingSettings()\nself.real_time_settings = RealTimeSettings()\ndef set_setting(self, path, value):\n\"\"\"\n        Sets setting @path with value @value.\n        Args:\n            path (str): Path of the setting to set.\n            value (any): Value to set for for setting @path.\n        \"\"\"\nif path not in self.settings:\nraise NotImplementedError(f\"Setting {path} is not supported.\")\nself.settings[path].set(value)\ndef reset_setting(self, path):\n\"\"\"\n        Resets setting @path to default value.\n        Args:\n            path (str): Path of the setting to reset.\n        \"\"\"\nif path not in self.settings:\nraise NotImplementedError(f\"Setting {path} is not supported.\")\nself.settings[path].reset()\ndef get_setting_from_path(self, path):\n\"\"\"\n        Get the value of setting @path.\n        Args:\n            path (str): Path of the setting to get.\n        Returns:\n            any: Value of the requested setting @path.\n        \"\"\"\nreturn self._carb_settings.get(path)\ndef get_current_renderer(self):\n\"\"\"\n        Get the current renderer.\n        Args:\n            path (str): Path of the setting to get.\n        Returns:\n            str: the current renderer.\n        \"\"\"\nreturn RendererSettingsFactory.get_current_renderer()\ndef set_current_renderer(self, renderer):\n\"\"\"\n        Set the current renderer to @renderer.\n        Args:\n            renderer (str): The renderer to set as current (e.g. Real-Time, Path-Traced).\n        \"\"\"\nassert (\nrenderer in RendererSettingsFactory.get_registered_renderers()\n), f\"renderer must be one of {RendererSettingsFactory.get_registered_renderers()}\"\nprint(f\"Set current renderer to {renderer}.\")\nRendererSettingsFactory.set_current_renderer(renderer)\n@property\ndef settings(self):\n\"\"\"\n        Get all available settings.\n        Returns:\n            dict: A dictionary of all available settings.\n                Keys are setting paths and values are setting item objects. \n        \"\"\"\nsettings = {}\nsettings.update(self.common_settings.settings)\nsettings.update(self.path_tracing_settings.settings)\nsettings.update(self.post_processing_settings.settings)\nsettings.update(self.real_time_settings.settings)\nreturn settings\n</code></pre>"},{"location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.settings","title":"<code>settings</code>  <code>property</code>","text":"<p>Get all available settings.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary of all available settings. Keys are setting paths and values are setting item objects.</p>"},{"location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.get_current_renderer","title":"<code>get_current_renderer()</code>","text":"<p>Get the current renderer.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of the setting to get.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>the current renderer.</p> Source code in <code>omnigibson/renderer_settings/renderer_settings.py</code> <pre><code>def get_current_renderer(self):\n\"\"\"\n    Get the current renderer.\n    Args:\n        path (str): Path of the setting to get.\n    Returns:\n        str: the current renderer.\n    \"\"\"\nreturn RendererSettingsFactory.get_current_renderer()\n</code></pre>"},{"location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.get_setting_from_path","title":"<code>get_setting_from_path(path)</code>","text":"<p>Get the value of setting @path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of the setting to get.</p> required <p>Returns:</p> Name Type Description <code>any</code> <p>Value of the requested setting @path.</p> Source code in <code>omnigibson/renderer_settings/renderer_settings.py</code> <pre><code>def get_setting_from_path(self, path):\n\"\"\"\n    Get the value of setting @path.\n    Args:\n        path (str): Path of the setting to get.\n    Returns:\n        any: Value of the requested setting @path.\n    \"\"\"\nreturn self._carb_settings.get(path)\n</code></pre>"},{"location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.reset_setting","title":"<code>reset_setting(path)</code>","text":"<p>Resets setting @path to default value.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of the setting to reset.</p> required Source code in <code>omnigibson/renderer_settings/renderer_settings.py</code> <pre><code>def reset_setting(self, path):\n\"\"\"\n    Resets setting @path to default value.\n    Args:\n        path (str): Path of the setting to reset.\n    \"\"\"\nif path not in self.settings:\nraise NotImplementedError(f\"Setting {path} is not supported.\")\nself.settings[path].reset()\n</code></pre>"},{"location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.set_current_renderer","title":"<code>set_current_renderer(renderer)</code>","text":"<p>Set the current renderer to @renderer.</p> <p>Parameters:</p> Name Type Description Default <code>renderer</code> <code>str</code> <p>The renderer to set as current (e.g. Real-Time, Path-Traced).</p> required Source code in <code>omnigibson/renderer_settings/renderer_settings.py</code> <pre><code>def set_current_renderer(self, renderer):\n\"\"\"\n    Set the current renderer to @renderer.\n    Args:\n        renderer (str): The renderer to set as current (e.g. Real-Time, Path-Traced).\n    \"\"\"\nassert (\nrenderer in RendererSettingsFactory.get_registered_renderers()\n), f\"renderer must be one of {RendererSettingsFactory.get_registered_renderers()}\"\nprint(f\"Set current renderer to {renderer}.\")\nRendererSettingsFactory.set_current_renderer(renderer)\n</code></pre>"},{"location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.set_setting","title":"<code>set_setting(path, value)</code>","text":"<p>Sets setting @path with value @value.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of the setting to set.</p> required <code>value</code> <code>any</code> <p>Value to set for for setting @path.</p> required Source code in <code>omnigibson/renderer_settings/renderer_settings.py</code> <pre><code>def set_setting(self, path, value):\n\"\"\"\n    Sets setting @path with value @value.\n    Args:\n        path (str): Path of the setting to set.\n        value (any): Value to set for for setting @path.\n    \"\"\"\nif path not in self.settings:\nraise NotImplementedError(f\"Setting {path} is not supported.\")\nself.settings[path].set(value)\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html","title":"settings_base","text":""},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem","title":"<code>SettingItem</code>","text":"<p>A wrapper of an individual setting item.</p> <p>Parameters:</p> Name Type Description Default <code>owner</code> <p>class:<code>SubSettingsBase</code>): The SubSettingsBase object owning this setting.</p> required <code>setting_type</code> <p>class:<code>SettingType</code>): Setting type (e.g. float, int).</p> required <code>name</code> <code>str</code> <p>Description of this setting.</p> required <code>path</code> <code>str</code> <p>Path of this setting.</p> required <code>range_from</code> <code>float</code> <p>The lower bound of the values for this setting. Defaults to -inf.</p> <code>-float('inf')</code> <code>range_to</code> <code>float</code> <p>The upper bound of the values for this settin. Defaults to inf.</p> <code>float('inf')</code> <code>range_list</code> <code>list</code> <p>Possible values for this setting. Defaults to None.</p> <code>None</code> <code>range_dict</code> <code>dict</code> <p>Possible values for this setting. Defaults to None.</p> <code>None</code> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>class SettingItem:\n\"\"\"\n    A wrapper of an individual setting item.\n    Args:\n        owner (:class:`SubSettingsBase`): The SubSettingsBase object owning this setting.\n        setting_type (:class:`SettingType`): Setting type (e.g. float, int).\n        name (str): Description of this setting.\n        path (str): Path of this setting.\n        range_from (float): The lower bound of the values for this setting. Defaults to -inf.\n        range_to (float): The upper bound of the values for this settin. Defaults to inf.\n        range_list (list): Possible values for this setting. Defaults to None.\n        range_dict (dict): Possible values for this setting. Defaults to None.\n    \"\"\"\ndef __init__(\nself,\nowner,\nsetting_type: SettingType,\nname,\npath,\nrange_from=-float(\"inf\"),\nrange_to=float(\"inf\"),\nrange_list=None,\nrange_dict=None,\n):\nself._carb_settings = carb.settings.get_settings()\nself.owner = owner\nself.setting_type = setting_type\nself.name = name\nself.path = path\nself.range_from = range_from\nself.range_to = range_to\nself.range_list = range_list\nself.range_dict = range_dict\nself.initial_value = self.value\n@property\ndef value(self):\n\"\"\"\n        Get the current setting value.\n        Returns:\n            any: The current setting value.\n        \"\"\"\nreturn self._carb_settings.get(self.path)\ndef get(self):\n\"\"\"\n        Get the current setting value.\n        Returns:\n            any: The current setting value.\n        \"\"\"\nreturn self.value\ndef reset(self):\n\"\"\"\n        Reset the current setting value to default.\n        \"\"\"\nself.set(self.initial_value)\ndef set(self, value):\n\"\"\"\n        Set the current setting to @value.\n        Args:\n            value (any): Value to set for the current setting value.\n        \"\"\"\nprint(f\"Set setting {self.path} ({self.name}) to {value}.\")  # carb.log_info\nif not self.owner.is_enabled():\nprint(f\"Note: {self.owner.enabled_setting_path} is not enabled.\")\n# Validate range list and range dict.\nif self.range_list:\nassert value in self.range_list, f\"Setting {self.path} must be chosen from {self.range_list}.\"\nif self.range_dict:\nassert isinstance(self.range_dict, dict)\nassert (\nvalue in self.range_dict.values()\n), f\"Setting {self.path} must be chosen from a value (not key) in {self.range_dict}.\"\nif self.setting_type == SettingType.FLOAT:\nassert isinstance(value, (int, float)), f\"Setting {self.path} must be of type float.\"\nassert (\nvalue &gt;= self.range_from and value &lt;= self.range_to\n), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\nself._carb_settings.set_float(self.path, value)\nelif self.setting_type == SettingType.INT:\nassert isinstance(value, int), f\"Setting {self.path} must be of type int.\"\nassert (\nvalue &gt;= self.range_from and value &lt;= self.range_to\n), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\nself._carb_settings.set_int(self.path, value)\nelif self.setting_type == SettingType.COLOR3:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\nfor v in value:\nassert (\nisinstance(v, (int, float)) and v &gt;= 0 and v &lt;= 1\n), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\nself._carb_settings.set_float_array(self.path, value)\nelif self.setting_type == SettingType.BOOL:\nassert isinstance(value, bool), f\"Setting {self.path} must be of type bool.\"\nself._carb_settings.set_bool(self.path, value)\nelif self.setting_type == SettingType.STRING:\nassert isinstance(value, str), f\"Setting {self.path} must be of type str.\"\nself._carb_settings.set_string(self.path, value)\nelif self.setting_type == SettingType.DOUBLE3:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n), f\"Setting {self.path} must be a list of 3 floats.\"\nfor v in value:\nassert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 3 floats.\"\nself._carb_settings.set_float_array(self.path, value)\nelif self.setting_type == SettingType.INT2:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n), f\"Setting {self.path} must be a list of 2 ints.\"\nfor v in value:\nassert isinstance(v, int), f\"Setting {self.path} must be a list of 2 ints.\"\nself._carb_settings.set_int_array(self.path, value)\nelif self.setting_type == SettingType.DOUBLE2:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n), f\"Setting {self.path} must be a list of 2 floats.\"\nfor v in value:\nassert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 2 floats.\"\nself._carb_settings.set_float_array(self.path, value)\nelse:\nraise TypeError(f\"Setting type {self.setting_type} is not supported.\")\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.value","title":"<code>value</code>  <code>property</code>","text":"<p>Get the current setting value.</p> <p>Returns:</p> Name Type Description <code>any</code> <p>The current setting value.</p>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.get","title":"<code>get()</code>","text":"<p>Get the current setting value.</p> <p>Returns:</p> Name Type Description <code>any</code> <p>The current setting value.</p> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>def get(self):\n\"\"\"\n    Get the current setting value.\n    Returns:\n        any: The current setting value.\n    \"\"\"\nreturn self.value\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.reset","title":"<code>reset()</code>","text":"<p>Reset the current setting value to default.</p> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>def reset(self):\n\"\"\"\n    Reset the current setting value to default.\n    \"\"\"\nself.set(self.initial_value)\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.set","title":"<code>set(value)</code>","text":"<p>Set the current setting to @value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>any</code> <p>Value to set for the current setting value.</p> required Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>def set(self, value):\n\"\"\"\n    Set the current setting to @value.\n    Args:\n        value (any): Value to set for the current setting value.\n    \"\"\"\nprint(f\"Set setting {self.path} ({self.name}) to {value}.\")  # carb.log_info\nif not self.owner.is_enabled():\nprint(f\"Note: {self.owner.enabled_setting_path} is not enabled.\")\n# Validate range list and range dict.\nif self.range_list:\nassert value in self.range_list, f\"Setting {self.path} must be chosen from {self.range_list}.\"\nif self.range_dict:\nassert isinstance(self.range_dict, dict)\nassert (\nvalue in self.range_dict.values()\n), f\"Setting {self.path} must be chosen from a value (not key) in {self.range_dict}.\"\nif self.setting_type == SettingType.FLOAT:\nassert isinstance(value, (int, float)), f\"Setting {self.path} must be of type float.\"\nassert (\nvalue &gt;= self.range_from and value &lt;= self.range_to\n), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\nself._carb_settings.set_float(self.path, value)\nelif self.setting_type == SettingType.INT:\nassert isinstance(value, int), f\"Setting {self.path} must be of type int.\"\nassert (\nvalue &gt;= self.range_from and value &lt;= self.range_to\n), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\nself._carb_settings.set_int(self.path, value)\nelif self.setting_type == SettingType.COLOR3:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\nfor v in value:\nassert (\nisinstance(v, (int, float)) and v &gt;= 0 and v &lt;= 1\n), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\nself._carb_settings.set_float_array(self.path, value)\nelif self.setting_type == SettingType.BOOL:\nassert isinstance(value, bool), f\"Setting {self.path} must be of type bool.\"\nself._carb_settings.set_bool(self.path, value)\nelif self.setting_type == SettingType.STRING:\nassert isinstance(value, str), f\"Setting {self.path} must be of type str.\"\nself._carb_settings.set_string(self.path, value)\nelif self.setting_type == SettingType.DOUBLE3:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n), f\"Setting {self.path} must be a list of 3 floats.\"\nfor v in value:\nassert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 3 floats.\"\nself._carb_settings.set_float_array(self.path, value)\nelif self.setting_type == SettingType.INT2:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n), f\"Setting {self.path} must be a list of 2 ints.\"\nfor v in value:\nassert isinstance(v, int), f\"Setting {self.path} must be a list of 2 ints.\"\nself._carb_settings.set_int_array(self.path, value)\nelif self.setting_type == SettingType.DOUBLE2:\nassert (\nisinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n), f\"Setting {self.path} must be a list of 2 floats.\"\nfor v in value:\nassert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 2 floats.\"\nself._carb_settings.set_float_array(self.path, value)\nelse:\nraise TypeError(f\"Setting type {self.setting_type} is not supported.\")\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingsBase","title":"<code>SettingsBase</code>","text":"<p>Base class for all renderer settings classes.</p> <p>Settings classes include Common, Real-Time (Ray-Tracing), Path-Tracing and Post Processing.</p> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>class SettingsBase(metaclass=ABCMeta):\n\"\"\"\n    Base class for all renderer settings classes.\n    Settings classes include Common, Real-Time (Ray-Tracing), Path-Tracing and Post Processing.\n    \"\"\"\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase","title":"<code>SubSettingsBase</code>","text":"<p>Base class for all renderer sub-settings classes.</p> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>class SubSettingsBase(metaclass=ABCMeta):\n\"\"\"\n    Base class for all renderer sub-settings classes.\n    \"\"\"\ndef __init__(self):\nself._carb_settings = carb.settings.get_settings()\n@property\ndef enabled_setting_path(self):\n\"\"\"\n        The path of \"enabled\" setting for this sub-settings class.\n        Subclass with \"enabled\" mode needs to overwrite this method. \n        Returns:\n            str or None: The path of \"enabled\" mode for this sub-setting class.\n                Defaults to None, which means this sub-setting group cannot be enabled/disabled.\n        \"\"\"\nreturn None\ndef is_enabled(self):\n\"\"\"\n        Get the enabled status for this sub-setting class.\n        Returns:\n            bool: Whether this sub-setting group is enabled.\n                Returns true if this sub-setting group has no \"enabled\" mode.\n        \"\"\"\nif not self.enabled_setting_path:\nreturn True\nreturn self._carb_settings.get(self.enabled_setting_path)\ndef enable(self):\n\"\"\"\n        Enable this sub-setting class.\n        \"\"\"\nif not self.enabled_setting_path:\nprint(f\"{self.__class__.__name__} has no enabled mode.\")\nreturn\nself._carb_settings.set_bool(self.enabled_setting_path, True)\ndef disable(self):\n\"\"\"\n        Disable this sub-setting class.\n        \"\"\"\nif not self.enabled_setting_path:\nprint(f\"{self.__class__.__name__} has no enabled mode.\")\nreturn\nself._carb_settings.set_bool(self.enabled_setting_path, False)\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.enabled_setting_path","title":"<code>enabled_setting_path</code>  <code>property</code>","text":"<p>The path of \"enabled\" setting for this sub-settings class.</p> <p>Subclass with \"enabled\" mode needs to overwrite this method. </p> <p>Returns:</p> Type Description <p>str or None: The path of \"enabled\" mode for this sub-setting class. Defaults to None, which means this sub-setting group cannot be enabled/disabled.</p>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.disable","title":"<code>disable()</code>","text":"<p>Disable this sub-setting class.</p> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>def disable(self):\n\"\"\"\n    Disable this sub-setting class.\n    \"\"\"\nif not self.enabled_setting_path:\nprint(f\"{self.__class__.__name__} has no enabled mode.\")\nreturn\nself._carb_settings.set_bool(self.enabled_setting_path, False)\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.enable","title":"<code>enable()</code>","text":"<p>Enable this sub-setting class.</p> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>def enable(self):\n\"\"\"\n    Enable this sub-setting class.\n    \"\"\"\nif not self.enabled_setting_path:\nprint(f\"{self.__class__.__name__} has no enabled mode.\")\nreturn\nself._carb_settings.set_bool(self.enabled_setting_path, True)\n</code></pre>"},{"location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.is_enabled","title":"<code>is_enabled()</code>","text":"<p>Get the enabled status for this sub-setting class.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this sub-setting group is enabled. Returns true if this sub-setting group has no \"enabled\" mode.</p> Source code in <code>omnigibson/renderer_settings/settings_base.py</code> <pre><code>def is_enabled(self):\n\"\"\"\n    Get the enabled status for this sub-setting class.\n    Returns:\n        bool: Whether this sub-setting group is enabled.\n            Returns true if this sub-setting group has no \"enabled\" mode.\n    \"\"\"\nif not self.enabled_setting_path:\nreturn True\nreturn self._carb_settings.get(self.enabled_setting_path)\n</code></pre>"},{"location":"reference/reward_functions/index.html","title":"reward_functions","text":""},{"location":"reference/reward_functions/collision_reward.html","title":"collision_reward","text":""},{"location":"reference/reward_functions/collision_reward.html#reward_functions.collision_reward.CollisionReward","title":"<code>CollisionReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Collision reward Penalize robot collision. Typically collision_reward_weight is negative. Note that we ignore collisions with any floor objects.</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>robot identifier to evaluate collision penalty with. Default is 0, corresponding to the first robot added to the scene</p> <code>0</code> <code>ignore_self_collisions</code> <code>bool</code> <p>Whether to ignore robot self-collisions or not</p> <code>True</code> <code>r_collision</code> <code>float</code> <p>Penalty value (&gt;0) to penalize collisions</p> <code>0.1</code> Source code in <code>omnigibson/reward_functions/collision_reward.py</code> <pre><code>class CollisionReward(BaseRewardFunction):\n\"\"\"\n    Collision reward\n    Penalize robot collision. Typically collision_reward_weight is negative. Note that we ignore collisions with any\n    floor objects.\n    Args:\n        robot_idn (int): robot identifier to evaluate collision penalty with. Default is 0, corresponding to the first\n            robot added to the scene\n        ignore_self_collisions (bool): Whether to ignore robot self-collisions or not\n        r_collision (float): Penalty value (&gt;0) to penalize collisions\n    \"\"\"\ndef __init__(self, robot_idn=0, ignore_self_collisions=True, r_collision=0.1):\n# Store internal vars\nassert r_collision &gt; 0, f\"r_collision must be positive, got: {r_collision}!\"\nself._robot_idn = robot_idn\nself._ignore_self_collisions = ignore_self_collisions\nself._r_collision = r_collision\n# Run super\nsuper().__init__()\ndef _step(self, task, env, action):\n# Penalty is Reward is -self._r_collision if there were any collisions in the last timestep\nrobot = env.robots[self._robot_idn]\n# Ignore floors and potentially robot's own prims as well\nfloors = list(env.scene.object_registry(\"category\", \"floors\", []))\nignore_objs = floors if self._ignore_self_collisions is None else floors + [robot]\nin_contact = len(env.robots[self._robot_idn].states[ContactBodies].get_value(ignore_objs=tuple(ignore_objs))) &gt; 0\nreward = float(in_contact) * -self._r_collision\nreturn reward, {}\n</code></pre>"},{"location":"reference/reward_functions/point_goal_reward.html","title":"point_goal_reward","text":""},{"location":"reference/reward_functions/point_goal_reward.html#reward_functions.point_goal_reward.PointGoalReward","title":"<code>PointGoalReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Point goal reward Success reward for reaching the goal with the robot's base</p> <p>Parameters:</p> Name Type Description Default <code>pointgoal</code> <code>PointGoal</code> <p>Termination condition for checking whether a point goal is reached</p> required <code>r_pointgoal</code> <code>float</code> <p>Reward for reaching the point goal</p> <code>10.0</code> Source code in <code>omnigibson/reward_functions/point_goal_reward.py</code> <pre><code>class PointGoalReward(BaseRewardFunction):\n\"\"\"\n    Point goal reward\n    Success reward for reaching the goal with the robot's base\n    Args:\n        pointgoal (PointGoal): Termination condition for checking whether a point goal is reached\n        r_pointgoal (float): Reward for reaching the point goal\n    \"\"\"\ndef __init__(self, pointgoal, r_pointgoal=10.0):\n# Store internal vars\nself._pointgoal = pointgoal\nself._r_pointgoal = r_pointgoal\n# Run super\nsuper().__init__()\ndef _step(self, task, env, action):\n# Reward received the pointgoal success condition is met\nreward = self._r_pointgoal if self._pointgoal.success else 0.0\nreturn reward, {}\n</code></pre>"},{"location":"reference/reward_functions/potential_reward.html","title":"potential_reward","text":""},{"location":"reference/reward_functions/potential_reward.html#reward_functions.potential_reward.PotentialReward","title":"<code>PotentialReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Potential reward Assume task has get_potential implemented; Low potential is preferred (e.g. a common potential for goal-directed task is the distance to goal)</p> <p>Parameters:</p> Name Type Description Default <code>potential_fcn</code> <code>method</code> <p>function for calculating potential. Function signature should be:</p> <p>potential = potential_fcn(env)</p> <p>where @env is a Environment instance, and @potential is a float value representing the calculated potential</p> required <code>r_potential</code> <code>float</code> <p>Reward weighting to give proportional to the potential difference calculated in between env timesteps</p> <code>1.0</code> Source code in <code>omnigibson/reward_functions/potential_reward.py</code> <pre><code>class PotentialReward(BaseRewardFunction):\n\"\"\"\n    Potential reward\n    Assume task has get_potential implemented; Low potential is preferred\n    (e.g. a common potential for goal-directed task is the distance to goal)\n    Args:\n        potential_fcn (method): function for calculating potential. Function signature should be:\n            potential = potential_fcn(env)\n            where @env is a Environment instance, and @potential is a float value representing the calculated potential\n        r_potential (float): Reward weighting to give proportional to the potential difference calculated\n            in between env timesteps\n    \"\"\"\ndef __init__(self, potential_fcn, r_potential=1.0):\n# Store internal vars\nself._potential_fcn = potential_fcn\nself._r_potential = r_potential\n# Store internal vars that will be filled in at runtime\nself._potential = None\n# Run super\nsuper().__init__()\ndef reset(self, task, env):\n\"\"\"\n        Compute the initial potential after episode reset\n        :param task: task instance\n        :param env: environment instance\n        \"\"\"\n# Reset potential\nself._potential = self._potential_fcn(env)\ndef _step(self, task, env, action):\n# Reward is proportional to the potential difference between the current and previous timestep\nnew_potential = self._potential_fcn(env)\nreward = (self._potential - new_potential) * self._r_potential\n# Update internal potential\nself._potential = new_potential\nreturn reward, {}\n</code></pre>"},{"location":"reference/reward_functions/potential_reward.html#reward_functions.potential_reward.PotentialReward.reset","title":"<code>reset(task, env)</code>","text":"<p>Compute the initial potential after episode reset</p> <p>:param task: task instance :param env: environment instance</p> Source code in <code>omnigibson/reward_functions/potential_reward.py</code> <pre><code>def reset(self, task, env):\n\"\"\"\n    Compute the initial potential after episode reset\n    :param task: task instance\n    :param env: environment instance\n    \"\"\"\n# Reset potential\nself._potential = self._potential_fcn(env)\n</code></pre>"},{"location":"reference/reward_functions/reaching_goal_reward.html","title":"reaching_goal_reward","text":""},{"location":"reference/reward_functions/reaching_goal_reward.html#reward_functions.reaching_goal_reward.ReachingGoalReward","title":"<code>ReachingGoalReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Reaching goal reward Success reward for reaching the goal with the robot's end-effector</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>robot identifier to evaluate point goal with. Default is 0, corresponding to the first robot added to the scene</p> <code>0</code> <code>r_reach</code> <code>float</code> <p>reward for succeeding to reach the goal</p> <code>10.0</code> <code>distance_tol</code> <code>float</code> <p>Distance (m) tolerance between goal position and @robot_idn's robot eef position that is accepted as a success</p> <code>0.1</code> Source code in <code>omnigibson/reward_functions/reaching_goal_reward.py</code> <pre><code>class ReachingGoalReward(BaseRewardFunction):\n\"\"\"\n    Reaching goal reward\n    Success reward for reaching the goal with the robot's end-effector\n    Args:\n        robot_idn (int): robot identifier to evaluate point goal with. Default is 0, corresponding to the first\n            robot added to the scene\n        r_reach (float): reward for succeeding to reach the goal\n        distance_tol (float): Distance (m) tolerance between goal position and @robot_idn's robot eef position\n            that is accepted as a success\n    \"\"\"\ndef __init__(self, robot_idn=0, r_reach=10.0, distance_tol=0.1):\n# Store internal vars\nself._robot_idn = robot_idn\nself._r_reach = r_reach\nself._distance_tol = distance_tol\n# Run super\nsuper().__init__()\ndef _step(self, task, env, action):\n# Sparse reward is received if distance between robot_idn robot's eef and goal is below the distance threshold\nsuccess = T.l2_distance(env.robots[self._robot_idn].get_eef_position(), task.goal_pos) &lt; \\\n            self._distance_tol\nreward = self._r_reach if success else 0.0\nreturn reward, {}\n</code></pre>"},{"location":"reference/reward_functions/reward_function_base.html","title":"reward_function_base","text":""},{"location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction","title":"<code>BaseRewardFunction</code>","text":"<p>         Bases: <code>Registerable</code></p> <p>Base RewardFunction class Reward-specific reset and get_reward methods are implemented in subclasses</p> Source code in <code>omnigibson/reward_functions/reward_function_base.py</code> <pre><code>class BaseRewardFunction(Registerable, metaclass=ABCMeta):\n\"\"\"\n    Base RewardFunction class\n    Reward-specific reset and get_reward methods are implemented in subclasses\n    \"\"\"\ndef __init__(self):\n# Store internal vars that will be filled in at runtime\nself._reward = None\nself._info = None\n@abstractmethod\ndef _step(self, task, env, action):\n\"\"\"\n        Step the reward function and compute the reward at the current timestep. Overwritten by subclasses.\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n        Returns:\n            2-tuple:\n                - bool: computed reward\n                - dict: any reward-related information for this specific reward\n        \"\"\"\nraise NotImplementedError()\ndef step(self, task, env, action):\n\"\"\"\n        Step the reward function and compute the reward at the current timestep.\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n        Returns:\n            2-tuple:\n                - bool: computed reward\n                - dict: any reward-related information for this specific reward\n        \"\"\"\n# Step internally and store output\nself._reward, self._info = self._step(task=task, env=env, action=action)\n# Return reward and a copy of the info\nreturn self._reward, deepcopy(self._info)\ndef reset(self, task, env):\n\"\"\"\n        Reward function-specific reset\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n        \"\"\"\n# Reset internal vars\nself._reward = None\nself._info = None\n@property\ndef reward(self):\n\"\"\"\n        Returns:\n            float: Current reward for this reward function\n        \"\"\"\nassert self._reward is not None, \"At least one step() must occur before reward can be calculated!\"\nreturn self._reward\n@property\ndef info(self):\n\"\"\"\n        Returns:\n            dict: Current info for this reward function\n        \"\"\"\nassert self._info is not None, \"At least one step() must occur before info can be calculated!\"\nreturn self._info\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseRewardFunction\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_REWARD_FUNCTIONS\nreturn REGISTERED_REWARD_FUNCTIONS\n</code></pre>"},{"location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.info","title":"<code>info</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Current info for this reward function</p>"},{"location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.reward","title":"<code>reward</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Current reward for this reward function</p>"},{"location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.reset","title":"<code>reset(task, env)</code>","text":"<p>Reward function-specific reset</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>BaseTask</code> <p>Task instance</p> required <code>env</code> <code>Environment</code> <p>Environment instance</p> required Source code in <code>omnigibson/reward_functions/reward_function_base.py</code> <pre><code>def reset(self, task, env):\n\"\"\"\n    Reward function-specific reset\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n    \"\"\"\n# Reset internal vars\nself._reward = None\nself._info = None\n</code></pre>"},{"location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.step","title":"<code>step(task, env, action)</code>","text":"<p>Step the reward function and compute the reward at the current timestep.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>BaseTask</code> <p>Task instance</p> required <code>env</code> <code>Environment</code> <p>Environment instance</p> required <code>action</code> <code>n-array</code> <p>1D flattened array of actions executed by all agents in the environment</p> required <p>Returns:</p> Type Description <p>2-tuple: - bool: computed reward - dict: any reward-related information for this specific reward</p> Source code in <code>omnigibson/reward_functions/reward_function_base.py</code> <pre><code>def step(self, task, env, action):\n\"\"\"\n    Step the reward function and compute the reward at the current timestep.\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n        action (n-array): 1D flattened array of actions executed by all agents in the environment\n    Returns:\n        2-tuple:\n            - bool: computed reward\n            - dict: any reward-related information for this specific reward\n    \"\"\"\n# Step internally and store output\nself._reward, self._info = self._step(task=task, env=env, action=action)\n# Return reward and a copy of the info\nreturn self._reward, deepcopy(self._info)\n</code></pre>"},{"location":"reference/robots/index.html","title":"robots","text":""},{"location":"reference/robots/active_camera_robot.html","title":"active_camera_robot","text":""},{"location":"reference/robots/active_camera_robot.html#robots.active_camera_robot.ActiveCameraRobot","title":"<code>ActiveCameraRobot</code>","text":"<p>         Bases: <code>BaseRobot</code></p> <p>Robot that is is equipped with an onboard camera that can be moved independently from the robot's other kinematic joints (e.g.: independent of base and arm for a mobile manipulator).</p> controller_config should, at the minimum, contain: <p>camera: controller specifications for the controller to control this robot's camera.     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre> Source code in <code>omnigibson/robots/active_camera_robot.py</code> <pre><code>class ActiveCameraRobot(BaseRobot):\n\"\"\"\n    Robot that is is equipped with an onboard camera that can be moved independently from the robot's other kinematic\n    joints (e.g.: independent of base and arm for a mobile manipulator).\n    NOTE: controller_config should, at the minimum, contain:\n        camera: controller specifications for the controller to control this robot's camera.\n            Should include:\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n    \"\"\"\ndef _validate_configuration(self):\n# Make sure a camera controller is specified\nassert (\n\"camera\" in self._controllers\n), \"Controller 'camera' must exist in controllers! Current controllers: {}\".format(\nlist(self._controllers.keys())\n)\n# run super\nsuper()._validate_configuration()\ndef _get_proprioception_dict(self):\ndic = super()._get_proprioception_dict()\n# Add camera pos info\njoint_positions = self.get_joint_positions(normalized=False)\njoint_velocities = self.get_joint_velocities(normalized=False)\ndic[\"camera_qpos\"] = joint_positions[self.camera_control_idx]\ndic[\"camera_qpos_sin\"] = np.sin(joint_positions[self.camera_control_idx])\ndic[\"camera_qpos_cos\"] = np.cos(joint_positions[self.camera_control_idx])\ndic[\"camera_qvel\"] = joint_velocities[self.camera_control_idx]\nreturn dic\n@property\ndef default_proprio_obs(self):\nobs_keys = super().default_proprio_obs\nreturn obs_keys + [\"camera_qpos_sin\", \"camera_qpos_cos\"]\n@property\ndef controller_order(self):\n# By default, only camera is supported\nreturn [\"camera\"]\n@property\ndef _default_controllers(self):\n# Always call super first\ncontrollers = super()._default_controllers\n# For best generalizability use, joint controller as default\ncontrollers[\"camera\"] = \"JointController\"\nreturn controllers\n@property\ndef _default_camera_joint_controller_config(self):\n\"\"\"\n        Returns:\n            dict: Default camera joint controller config to control this robot's camera\n        \"\"\"\nreturn {\n\"name\": \"JointController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"velocity\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.camera_control_idx,\n\"command_output_limits\": \"default\",\n\"use_delta_commands\": False,\n}\n@property\ndef _default_camera_null_joint_controller_config(self):\n\"\"\"\n        Returns:\n            dict: Default null joint controller config to control this robot's camera i.e. dummy controller\n        \"\"\"\nreturn {\n\"name\": \"NullJointController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"velocity\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.camera_control_idx,\n}\n@property\ndef _default_controller_config(self):\n# Always run super method first\ncfg = super()._default_controller_config\n# We additionally add in camera default\ncfg[\"camera\"] = {\nself._default_camera_joint_controller_config[\"name\"]: self._default_camera_joint_controller_config,\nself._default_camera_null_joint_controller_config[\"name\"]: self._default_camera_null_joint_controller_config,\n}\nreturn cfg\n@property\n@abstractmethod\ndef camera_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to camera joints.\n        \"\"\"\nraise NotImplementedError\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"ActiveCameraRobot\")\nreturn classes\n</code></pre>"},{"location":"reference/robots/active_camera_robot.html#robots.active_camera_robot.ActiveCameraRobot.camera_control_idx","title":"<code>camera_control_idx</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to camera joints.</p>"},{"location":"reference/robots/fetch.html","title":"fetch","text":""},{"location":"reference/robots/fetch.html#robots.fetch.Fetch","title":"<code>Fetch</code>","text":"<p>         Bases: <code>ManipulationRobot</code>, <code>TwoWheelRobot</code>, <code>ActiveCameraRobot</code></p> <p>Fetch Robot Reference: https://fetchrobotics.com/robotics-platforms/fetch-mobile-manipulator/</p> Source code in <code>omnigibson/robots/fetch.py</code> <pre><code>class Fetch(ManipulationRobot, TwoWheelRobot, ActiveCameraRobot):\n\"\"\"\n    Fetch Robot\n    Reference: https://fetchrobotics.com/robotics-platforms/fetch-mobile-manipulator/\n    \"\"\"\ndef __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\nfixed_base=False,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to BaseRobot\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n# Unique to ManipulationRobot\ngrasping_mode=\"physical\",\n# Unique to Fetch\nrigid_trunk=False,\ndefault_trunk_offset=0.365,\ndefault_arm_pose=\"vertical\",\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n                If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n                If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n                If \"sticky\", will magnetize any object touching the gripper's fingers.\n            rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n            default_trunk_offset (float): sets the default height of the robot's trunk\n            default_arm_pose (str): Default pose for the robot arm. Should be one of:\n                {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Store args\nself.rigid_trunk = rigid_trunk\nself.default_trunk_offset = default_trunk_offset\nassert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\nself.default_arm_pose = default_arm_pose\n# Parse reset joint pos if specifying special string\nif isinstance(reset_joint_pos, str):\nassert (\nreset_joint_pos in RESET_JOINT_OPTIONS\n), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\nreset_joint_pos = (\nself.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n)\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\nobs_modalities=obs_modalities,\nproprio_obs=proprio_obs,\ngrasping_mode=grasping_mode,\n**kwargs,\n)\n@property\ndef model_name(self):\nreturn \"Fetch\"\n@property\ndef tucked_default_joint_pos(self):\nreturn np.array(\n[\n0.0,\n0.0,  # wheels\n0.02,  # trunk\n0.0,\n1.1707963267948966,\n0.0,  # head\n1.4707963267948965,\n-0.4,\n1.6707963267948966,\n0.0,\n1.5707963267948966,\n0.0,  # arm\n0.05,\n0.05,  # gripper\n]\n)\n@property\ndef untucked_default_joint_pos(self):\npos = np.zeros(self.n_joints)\npos[self.base_control_idx] = 0.0\npos[self.trunk_control_idx] = 0.02 + self.default_trunk_offset\npos[self.camera_control_idx] = np.array([0.0, 0.45])\npos[self.gripper_control_idx[self.default_arm]] = np.array([0.05, 0.05])  # open gripper\n# Choose arm based on setting\nif self.default_arm_pose == \"vertical\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[-0.94121, -0.64134, 1.55186, 1.65672, -0.93218, 1.53416, 2.14474]\n)\nelif self.default_arm_pose == \"diagonal15\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[-0.95587, -0.34778, 1.46388, 1.47821, -0.93813, 1.4587, 1.9939]\n)\nelif self.default_arm_pose == \"diagonal30\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[-1.06595, -0.22184, 1.53448, 1.46076, -0.84995, 1.36904, 1.90996]\n)\nelif self.default_arm_pose == \"diagonal45\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[-1.11479, -0.0685, 1.5696, 1.37304, -0.74273, 1.3983, 1.79618]\n)\nelif self.default_arm_pose == \"horizontal\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[-1.43016, 0.20965, 1.86816, 1.77576, -0.27289, 1.31715, 2.01226]\n)\nelse:\nraise ValueError(\"Unknown default arm pose: {}\".format(self.default_arm_pose))\nreturn pos\n@property\ndef discrete_action_list(self):\n# Not supported for this robot\nraise NotImplementedError()\ndef _create_discrete_action_space(self):\n# Fetch does not support discrete actions\nraise ValueError(\"Fetch does not support discrete actions!\")\ndef tuck(self):\n\"\"\"\n        Immediately set this robot's configuration to be in tucked mode\n        \"\"\"\nself.set_joint_positions(self.tucked_default_joint_pos)\ndef untuck(self):\n\"\"\"\n        Immediately set this robot's configuration to be in untucked mode\n        \"\"\"\nself.set_joint_positions(self.untucked_default_joint_pos)\ndef _initialize(self):\n# Run super method first\nsuper()._initialize()\n# Set the joint friction for EEF to be higher\nfor arm in self.arm_names:\nfor joint in self.finger_joints[arm]:\nif joint.joint_type != JointType.JOINT_FIXED:\njoint.friction = 500\ndef _actions_to_control(self, action):\n# Run super method first\nu_vec, u_type_vec = super()._actions_to_control(action=action)\n# Override trunk value if we're keeping the trunk rigid\nif self.rigid_trunk:\nu_vec[self.trunk_control_idx] = self.untucked_default_joint_pos[self.trunk_control_idx]\nu_type_vec[self.trunk_control_idx] = ControlType.POSITION\n# Return control\nreturn u_vec, u_type_vec\ndef _get_proprioception_dict(self):\ndic = super()._get_proprioception_dict()\n# Add trunk info\njoint_positions = self.get_joint_positions(normalized=False)\njoint_velocities = self.get_joint_velocities(normalized=False)\ndic[\"trunk_qpos\"] = joint_positions[self.trunk_control_idx]\ndic[\"trunk_qvel\"] = joint_velocities[self.trunk_control_idx]\nreturn dic\n@property\ndef default_proprio_obs(self):\nobs_keys = super().default_proprio_obs\nreturn obs_keys + [\"trunk_qpos\"]\n@property\ndef controller_order(self):\n# Ordered by general robot kinematics chain\nreturn [\"base\", \"camera\", \"arm_{}\".format(self.default_arm), \"gripper_{}\".format(self.default_arm)]\n@property\ndef _default_controllers(self):\n# Always call super first\ncontrollers = super()._default_controllers\n# We use multi finger gripper, differential drive, and IK controllers as default\ncontrollers[\"base\"] = \"DifferentialDriveController\"\ncontrollers[\"camera\"] = \"JointController\"\ncontrollers[\"arm_{}\".format(self.default_arm)] = \"InverseKinematicsController\"\ncontrollers[\"gripper_{}\".format(self.default_arm)] = \"MultiFingerGripperController\"\nreturn controllers\n@property\ndef _default_controller_config(self):\n# Grab defaults from super method first\ncfg = super()._default_controller_config\n# Need to override joint idx being controlled to include trunk in default arm controller configs\nfor arm_cfg in cfg[f\"arm_{self.default_arm}\"].values():\narm_cfg[\"dof_idx\"] = np.concatenate([self.trunk_control_idx, self.arm_control_idx[self.default_arm]])\n# If using rigid trunk, we also clamp its limits\nif self.rigid_trunk:\narm_cfg[\"control_limits\"][\"position\"][0][self.trunk_control_idx] = \\\n                    self.untucked_default_joint_pos[self.trunk_control_idx]\narm_cfg[\"control_limits\"][\"position\"][1][self.trunk_control_idx] = \\\n                    self.untucked_default_joint_pos[self.trunk_control_idx]\nreturn cfg\n@property\ndef default_joint_pos(self):\nreturn self.untucked_default_joint_pos\n@property\ndef wheel_radius(self):\nreturn 0.0613\n@property\ndef wheel_axle_length(self):\nreturn 0.372\n@property\ndef finger_lengths(self):\nreturn {self.default_arm: 0.1}\n@property\ndef assisted_grasp_start_points(self):\nreturn {\nself.default_arm: [\nGraspingPoint(link_name=\"r_gripper_finger_link\", position=[0.04, -0.012, 0.014]),\nGraspingPoint(link_name=\"r_gripper_finger_link\", position=[0.04, -0.012, -0.014]),\nGraspingPoint(link_name=\"r_gripper_finger_link\", position=[-0.04, -0.012, 0.014]),\nGraspingPoint(link_name=\"r_gripper_finger_link\", position=[-0.04, -0.012, -0.014]),\n]\n}\n@property\ndef assisted_grasp_end_points(self):\nreturn {\nself.default_arm: [\nGraspingPoint(link_name=\"l_gripper_finger_link\", position=[0.04, 0.012, 0.014]),\nGraspingPoint(link_name=\"l_gripper_finger_link\", position=[0.04, 0.012, -0.014]),\nGraspingPoint(link_name=\"l_gripper_finger_link\", position=[-0.04, 0.012, 0.014]),\nGraspingPoint(link_name=\"l_gripper_finger_link\", position=[-0.04, 0.012, -0.014]),\n]\n}\n@property\ndef base_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\nreturn np.array([0, 1])\n@property\ndef trunk_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to trunk joint.\n        \"\"\"\nreturn np.array([2])\n@property\ndef camera_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.\n        \"\"\"\nreturn np.array([3, 5])\n@property\ndef arm_control_idx(self):\nreturn {self.default_arm: np.array([4, 6, 7, 8, 9, 10, 11])}\n@property\ndef gripper_control_idx(self):\nreturn {self.default_arm: np.array([12, 13])}\n@property\ndef disabled_collision_pairs(self):\nreturn [\n[\"torso_lift_link\", \"shoulder_lift_link\"],\n[\"torso_lift_link\", \"torso_fixed_link\"],\n]\n@property\ndef arm_link_names(self):\nreturn {self.default_arm: [\n\"shoulder_pan_link\",\n\"shoulder_lift_link\",\n\"upperarm_roll_link\",\n\"elbow_flex_link\",\n\"forearm_roll_link\",\n\"wrist_flex_link\",\n\"wrist_roll_link\",\n]}\n@property\ndef arm_joint_names(self):\nreturn {self.default_arm: [\n\"torso_lift_joint\",\n\"shoulder_pan_joint\",\n\"shoulder_lift_joint\",\n\"upperarm_roll_joint\",\n\"elbow_flex_joint\",\n\"forearm_roll_joint\",\n\"wrist_flex_joint\",\n\"wrist_roll_joint\",\n]}\n@property\ndef eef_link_names(self):\nreturn {self.default_arm: \"gripper_link\"}\n@property\ndef finger_link_names(self):\nreturn {self.default_arm: [\"r_gripper_finger_link\", \"l_gripper_finger_link\"]}\n@property\ndef finger_joint_names(self):\nreturn {self.default_arm: [\"r_gripper_finger_joint\", \"l_gripper_finger_joint\"]}\n@property\ndef usd_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/fetch/fetch/fetch.usd\")\n@property\ndef robot_arm_descriptor_yamls(self):\nreturn {self.default_arm: os.path.join(gm.ASSET_PATH, \"models/fetch/fetch_descriptor.yaml\")}\n@property\ndef urdf_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/fetch/fetch.urdf\")\n</code></pre>"},{"location":"reference/robots/fetch.html#robots.fetch.Fetch.base_control_idx","title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>"},{"location":"reference/robots/fetch.html#robots.fetch.Fetch.camera_control_idx","title":"<code>camera_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.</p>"},{"location":"reference/robots/fetch.html#robots.fetch.Fetch.trunk_control_idx","title":"<code>trunk_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to trunk joint.</p>"},{"location":"reference/robots/fetch.html#robots.fetch.Fetch.__init__","title":"<code>__init__(name, prim_path=None, class_id=None, uuid=None, scale=None, visible=True, visual_only=False, self_collisions=False, load_config=None, fixed_base=False, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', grasping_mode='physical', rigid_trunk=False, default_trunk_offset=0.365, default_arm_pose='vertical', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>control_freq</code> <code>float</code> <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p> <code>None</code> <code>controller_config</code> <code>None or dict</code> <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p> <code>None</code> <code>action_type</code> <code>str</code> <p>one of {discrete, continuous} - what type of action space to use</p> <code>'continuous'</code> <code>action_normalize</code> <code>bool</code> <p>whether to normalize inputted actions. This will override any default values specified by this class.</p> <code>True</code> <code>reset_joint_pos</code> <code>None or n-array</code> <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p> <code>None</code> <code>obs_modalities</code> <code>str or list of str</code> <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p> <code>'all'</code> <code>proprio_obs</code> <code>str or list of str</code> <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p> <code>'default'</code> <code>grasping_mode</code> <code>str</code> <p>One of {\"physical\", \"assisted\", \"sticky\"}. If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force). If \"assisted\", will magnetize any object touching and within the gripper's fingers. If \"sticky\", will magnetize any object touching the gripper's fingers.</p> <code>'physical'</code> <code>default_trunk_offset</code> <code>float</code> <p>sets the default height of the robot's trunk</p> <code>0.365</code> <code>default_arm_pose</code> <code>str</code> <p>Default pose for the robot arm. Should be one of:</p> <code>'vertical'</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/robots/fetch.py</code> <pre><code>def __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\nfixed_base=False,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to BaseRobot\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n# Unique to ManipulationRobot\ngrasping_mode=\"physical\",\n# Unique to Fetch\nrigid_trunk=False,\ndefault_trunk_offset=0.365,\ndefault_arm_pose=\"vertical\",\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n            If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n            If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n            If \"sticky\", will magnetize any object touching the gripper's fingers.\n        rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n        default_trunk_offset (float): sets the default height of the robot's trunk\n        default_arm_pose (str): Default pose for the robot arm. Should be one of:\n            {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Store args\nself.rigid_trunk = rigid_trunk\nself.default_trunk_offset = default_trunk_offset\nassert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\nself.default_arm_pose = default_arm_pose\n# Parse reset joint pos if specifying special string\nif isinstance(reset_joint_pos, str):\nassert (\nreset_joint_pos in RESET_JOINT_OPTIONS\n), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\nreset_joint_pos = (\nself.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n)\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\nobs_modalities=obs_modalities,\nproprio_obs=proprio_obs,\ngrasping_mode=grasping_mode,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/robots/fetch.html#robots.fetch.Fetch.tuck","title":"<code>tuck()</code>","text":"<p>Immediately set this robot's configuration to be in tucked mode</p> Source code in <code>omnigibson/robots/fetch.py</code> <pre><code>def tuck(self):\n\"\"\"\n    Immediately set this robot's configuration to be in tucked mode\n    \"\"\"\nself.set_joint_positions(self.tucked_default_joint_pos)\n</code></pre>"},{"location":"reference/robots/fetch.html#robots.fetch.Fetch.untuck","title":"<code>untuck()</code>","text":"<p>Immediately set this robot's configuration to be in untucked mode</p> Source code in <code>omnigibson/robots/fetch.py</code> <pre><code>def untuck(self):\n\"\"\"\n    Immediately set this robot's configuration to be in untucked mode\n    \"\"\"\nself.set_joint_positions(self.untucked_default_joint_pos)\n</code></pre>"},{"location":"reference/robots/freight.html","title":"freight","text":""},{"location":"reference/robots/freight.html#robots.freight.Freight","title":"<code>Freight</code>","text":"<p>         Bases: <code>TwoWheelRobot</code></p> <p>Freight Robot Reference: https://fetchrobotics.com/robotics-platforms/freight-base/ Uses joint velocity control</p> Source code in <code>omnigibson/robots/freight.py</code> <pre><code>class Freight(TwoWheelRobot):\n\"\"\"\n    Freight Robot\n    Reference: https://fetchrobotics.com/robotics-platforms/freight-base/\n    Uses joint velocity control\n    \"\"\"\n@property\ndef model_name(self):\nreturn \"Freight\"\n@property\ndef wheel_radius(self):\nreturn 0.0613\n@property\ndef wheel_axle_length(self):\nreturn 0.372\n@property\ndef base_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\nreturn np.array([0, 1])\n@property\ndef default_joint_pos(self):\nreturn np.zeros(self.n_joints)\n@property\ndef usd_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/fetch/freight/freight.usd\")\n@property\ndef urdf_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/fetch/freight.urdf\")\n</code></pre>"},{"location":"reference/robots/freight.html#robots.freight.Freight.base_control_idx","title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>"},{"location":"reference/robots/husky.html","title":"husky","text":""},{"location":"reference/robots/husky.html#robots.husky.Husky","title":"<code>Husky</code>","text":"<p>         Bases: <code>LocomotionRobot</code></p> <p>Husky robot Reference: https://clearpathrobotics.com/, http://wiki.ros.org/Robots/Husky</p> Source code in <code>omnigibson/robots/husky.py</code> <pre><code>class Husky(LocomotionRobot):\n\"\"\"\n    Husky robot\n    Reference: https://clearpathrobotics.com/, http://wiki.ros.org/Robots/Husky\n    \"\"\"\ndef _create_discrete_action_space(self):\nraise ValueError(\"Husky does not support discrete actions!\")\n@property\ndef base_control_idx(self):\nreturn np.array([0, 1, 2, 3])\n@property\ndef default_joint_pos(self):\nreturn np.zeros(self.n_joints)\n@property\ndef usd_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/husky/husky/husky.usd\")\n@property\ndef urdf_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/husky/husky.urdf\")\n</code></pre>"},{"location":"reference/robots/locobot.html","title":"locobot","text":""},{"location":"reference/robots/locobot.html#robots.locobot.Locobot","title":"<code>Locobot</code>","text":"<p>         Bases: <code>TwoWheelRobot</code></p> <p>Locobot robot Reference: https://www.trossenrobotics.com/locobot-pyrobot-ros-rover.aspx</p> Source code in <code>omnigibson/robots/locobot.py</code> <pre><code>class Locobot(TwoWheelRobot):\n\"\"\"\n    Locobot robot\n    Reference: https://www.trossenrobotics.com/locobot-pyrobot-ros-rover.aspx\n    \"\"\"\n@property\ndef model_name(self):\nreturn \"Locobot\"\n@property\ndef wheel_radius(self):\nreturn 0.038\n@property\ndef wheel_axle_length(self):\nreturn 0.230\n@property\ndef base_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\nreturn np.array([1, 0])\n@property\ndef default_joint_pos(self):\nreturn np.zeros(self.n_joints)\n@property\ndef usd_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/locobot/locobot/locobot.usd\")\n@property\ndef urdf_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/locobot/locobot.urdf\")\n</code></pre>"},{"location":"reference/robots/locobot.html#robots.locobot.Locobot.base_control_idx","title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>"},{"location":"reference/robots/locomotion_robot.html","title":"locomotion_robot","text":""},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot","title":"<code>LocomotionRobot</code>","text":"<p>         Bases: <code>BaseRobot</code></p> <p>Robot that is is equipped with locomotive (navigational) capabilities. Provides common interface for a wide variety of robots.</p> controller_config should, at the minimum, contain: <p>base: controller specifications for the controller to control this robot's base (locomotion).     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre> Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>class LocomotionRobot(BaseRobot):\n\"\"\"\n    Robot that is is equipped with locomotive (navigational) capabilities.\n    Provides common interface for a wide variety of robots.\n    NOTE: controller_config should, at the minimum, contain:\n        base: controller specifications for the controller to control this robot's base (locomotion).\n            Should include:\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n    \"\"\"\ndef _validate_configuration(self):\n# We make sure that our base controller exists and is a locomotion controller\nassert (\n\"base\" in self._controllers\n), \"Controller 'base' must exist in controllers! Current controllers: {}\".format(list(self._controllers.keys()))\nassert isinstance(\nself._controllers[\"base\"], LocomotionController\n), \"Base controller must be a LocomotionController!\"\n# run super\nsuper()._validate_configuration()\ndef _get_proprioception_dict(self):\ndic = super()._get_proprioception_dict()\njoint_positions = self.get_joint_positions(normalized=False)\njoint_velocities = self.get_joint_velocities(normalized=False)\n# Add base info\ndic[\"base_qpos\"] = joint_positions[self.base_control_idx]\ndic[\"base_qpos_sin\"] = np.sin(joint_positions[self.base_control_idx])\ndic[\"base_qpos_cos\"] = np.cos(joint_positions[self.base_control_idx])\ndic[\"base_qvel\"] = joint_velocities[self.base_control_idx]\nreturn dic\n@property\ndef default_proprio_obs(self):\nobs_keys = super().default_proprio_obs\nreturn obs_keys + [\"base_qpos_sin\", \"base_qpos_cos\", \"robot_lin_vel\", \"robot_ang_vel\"]\n@property\ndef controller_order(self):\n# By default, only base is supported\nreturn [\"base\"]\n@property\ndef _default_controllers(self):\n# Always call super first\ncontrollers = super()._default_controllers\n# For best generalizability use, joint controller as default\ncontrollers[\"base\"] = \"JointController\"\nreturn controllers\n@property\ndef _default_base_joint_controller_config(self):\n\"\"\"\n        Returns:\n            dict: Default base joint controller config to control this robot's base. Uses velocity\n                control by default.\n        \"\"\"\nreturn {\n\"name\": \"JointController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"velocity\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.base_control_idx,\n\"command_output_limits\": \"default\",\n\"use_delta_commands\": False,\n}\n@property\ndef _default_base_null_joint_controller_config(self):\n\"\"\"\n        Returns:\n            dict: Default null joint controller config to control this robot's base i.e. dummy controller\n        \"\"\"\nreturn {\n\"name\": \"NullJointController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"velocity\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.base_control_idx,\n}\n@property\ndef _default_controller_config(self):\n# Always run super method first\ncfg = super()._default_controller_config\n# Add supported base controllers\ncfg[\"base\"] = {\nself._default_base_joint_controller_config[\"name\"]: self._default_base_joint_controller_config,\nself._default_base_null_joint_controller_config[\"name\"]: self._default_base_null_joint_controller_config,\n}\nreturn cfg\ndef move_by(self, delta):\n\"\"\"\n        Move robot base without physics simulation\n        Args:\n            delta (float):float], (x,y,z) cartesian delta base position\n        \"\"\"\nnew_pos = np.array(delta) + self.get_position()\nself.set_position(position=new_pos)\ndef move_forward(self, delta=0.05):\n\"\"\"\n        Move robot base forward without physics simulation\n        Args:\n            delta (float): delta base position forward\n        \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([delta, 0, 0])))\ndef move_backward(self, delta=0.05):\n\"\"\"\n        Move robot base backward without physics simulation\n        Args:\n            delta (float): delta base position backward\n        \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([-delta, 0, 0])))\ndef move_left(self, delta=0.05):\n\"\"\"\n        Move robot base left without physics simulation\n        Args:\n            delta (float): delta base position left\n        \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([0, -delta, 0])))\ndef move_right(self, delta=0.05):\n\"\"\"\n        Move robot base right without physics simulation\n        Args:\n            delta (float): delta base position right\n        \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([0, delta, 0])))\ndef turn_left(self, delta=0.03):\n\"\"\"\n        Rotate robot base left without physics simulation\n        Args:\n            delta (float): delta angle to rotate the base left\n        \"\"\"\nquat = self.get_orientation()\nquat = qmult((euler2quat(-delta, 0, 0)), quat)\nself.set_orientation(quat)\ndef turn_right(self, delta=0.03):\n\"\"\"\n        Rotate robot base right without physics simulation\n        Args:\n            delta (float): angle to rotate the base right\n        \"\"\"\nquat = self.get_orientation()\nquat = qmult((euler2quat(delta, 0, 0)), quat)\nself.set_orientation(quat)\n@property\n@abstractmethod\ndef base_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to base joints.\n        \"\"\"\nraise NotImplementedError\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"LocomotionRobot\")\nreturn classes\n</code></pre>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.base_control_idx","title":"<code>base_control_idx</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to base joints.</p>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_backward","title":"<code>move_backward(delta=0.05)</code>","text":"<p>Move robot base backward without physics simulation</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>delta base position backward</p> <code>0.05</code> Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>def move_backward(self, delta=0.05):\n\"\"\"\n    Move robot base backward without physics simulation\n    Args:\n        delta (float): delta base position backward\n    \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([-delta, 0, 0])))\n</code></pre>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_by","title":"<code>move_by(delta)</code>","text":"<p>Move robot base without physics simulation</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>float], (x,y,z) cartesian delta base position</p> required Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>def move_by(self, delta):\n\"\"\"\n    Move robot base without physics simulation\n    Args:\n        delta (float):float], (x,y,z) cartesian delta base position\n    \"\"\"\nnew_pos = np.array(delta) + self.get_position()\nself.set_position(position=new_pos)\n</code></pre>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_forward","title":"<code>move_forward(delta=0.05)</code>","text":"<p>Move robot base forward without physics simulation</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>delta base position forward</p> <code>0.05</code> Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>def move_forward(self, delta=0.05):\n\"\"\"\n    Move robot base forward without physics simulation\n    Args:\n        delta (float): delta base position forward\n    \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([delta, 0, 0])))\n</code></pre>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_left","title":"<code>move_left(delta=0.05)</code>","text":"<p>Move robot base left without physics simulation</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>delta base position left</p> <code>0.05</code> Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>def move_left(self, delta=0.05):\n\"\"\"\n    Move robot base left without physics simulation\n    Args:\n        delta (float): delta base position left\n    \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([0, -delta, 0])))\n</code></pre>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_right","title":"<code>move_right(delta=0.05)</code>","text":"<p>Move robot base right without physics simulation</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>delta base position right</p> <code>0.05</code> Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>def move_right(self, delta=0.05):\n\"\"\"\n    Move robot base right without physics simulation\n    Args:\n        delta (float): delta base position right\n    \"\"\"\nself.move_by(quat2mat(self.get_orientation()).dot(np.array([0, delta, 0])))\n</code></pre>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.turn_left","title":"<code>turn_left(delta=0.03)</code>","text":"<p>Rotate robot base left without physics simulation</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>delta angle to rotate the base left</p> <code>0.03</code> Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>def turn_left(self, delta=0.03):\n\"\"\"\n    Rotate robot base left without physics simulation\n    Args:\n        delta (float): delta angle to rotate the base left\n    \"\"\"\nquat = self.get_orientation()\nquat = qmult((euler2quat(-delta, 0, 0)), quat)\nself.set_orientation(quat)\n</code></pre>"},{"location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.turn_right","title":"<code>turn_right(delta=0.03)</code>","text":"<p>Rotate robot base right without physics simulation</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>angle to rotate the base right</p> <code>0.03</code> Source code in <code>omnigibson/robots/locomotion_robot.py</code> <pre><code>def turn_right(self, delta=0.03):\n\"\"\"\n    Rotate robot base right without physics simulation\n    Args:\n        delta (float): angle to rotate the base right\n    \"\"\"\nquat = self.get_orientation()\nquat = qmult((euler2quat(delta, 0, 0)), quat)\nself.set_orientation(quat)\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html","title":"manipulation_robot","text":""},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot","title":"<code>ManipulationRobot</code>","text":"<p>         Bases: <code>BaseRobot</code></p> <p>Robot that is is equipped with grasping (manipulation) capabilities. Provides common interface for a wide variety of robots.</p> controller_config should, at the minimum, contain: <p>arm: controller specifications for the controller to control this robot's arm (manipulation).     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>class ManipulationRobot(BaseRobot):\n\"\"\"\n    Robot that is is equipped with grasping (manipulation) capabilities.\n    Provides common interface for a wide variety of robots.\n    NOTE: controller_config should, at the minimum, contain:\n        arm: controller specifications for the controller to control this robot's arm (manipulation).\n            Should include:\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n    \"\"\"\ndef __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to BaseRobot\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n# Unique to ManipulationRobot\ngrasping_mode=\"physical\",\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n                If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n                If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n                If \"sticky\", will magnetize any object touching the gripper's fingers.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Store relevant internal vars\nassert_valid_key(key=grasping_mode, valid_keys=AG_MODES, name=\"grasping_mode\")\nself._grasping_mode = grasping_mode\n# Initialize other variables used for assistive grasping\nself._ag_data = {arm: None for arm in self.arm_names}\nself._ag_freeze_joint_pos = {\narm: {} for arm in self.arm_names\n}  # Frozen positions for keeping fingers held still\nself._ag_obj_in_hand = {arm: None for arm in self.arm_names}\nself._ag_obj_constraints = {arm: None for arm in self.arm_names}\nself._ag_obj_constraint_params = {arm: {} for arm in self.arm_names}\nself._ag_freeze_gripper = {arm: None for arm in self.arm_names}\nself._ag_release_counter = {arm: None for arm in self.arm_names}\nself._ag_check_in_volume = {arm: None for arm in self.arm_names}\nself._ag_calculate_volume = {arm: None for arm in self.arm_names}\n# Call super() method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\nobs_modalities=obs_modalities,\nproprio_obs=proprio_obs,\n**kwargs,\n)\ndef _validate_configuration(self):\n# Iterate over all arms\nfor arm in self.arm_names:\n# We make sure that our arm controller exists and is a manipulation controller\nassert (\n\"arm_{}\".format(arm) in self._controllers\n), \"Controller 'arm_{}' must exist in controllers! Current controllers: {}\".format(\narm, list(self._controllers.keys())\n)\nassert isinstance(\nself._controllers[\"arm_{}\".format(arm)], ManipulationController\n), \"Arm {} controller must be a ManipulationController!\".format(arm)\n# We make sure that our gripper controller exists and is a gripper controller\nassert (\n\"gripper_{}\".format(arm) in self._controllers\n), \"Controller 'gripper_{}' must exist in controllers! Current controllers: {}\".format(\narm, list(self._controllers.keys())\n)\nassert isinstance(\nself._controllers[\"gripper_{}\".format(arm)], GripperController\n), \"Gripper {} controller must be a GripperController!\".format(arm)\n# run super\nsuper()._validate_configuration()\ndef _initialize(self):\nsuper()._initialize()\nif gm.AG_CLOTH:\nfor arm in self.arm_names:\nself._ag_check_in_volume[arm], self._ag_calculate_volume[arm] = \\\n                    generate_points_in_volume_checker_function(obj=self, volume_link=self.eef_links[arm], mesh_name_prefixes=\"container\")\ndef is_grasping(self, arm=\"default\", candidate_obj=None):\n\"\"\"\n        Returns True if the robot is grasping the target option @candidate_obj or any object if @candidate_obj is None.\n        Args:\n            arm (str): specific arm to check for grasping. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n            candidate_obj (EntityPrim or None): object to check if this robot is currently grasping. If None, then\n                will be a general (object-agnostic) check for grasping.\n                Note: if self.grasping_mode is \"physical\", then @candidate_obj will be ignored completely\n        Returns:\n            IsGraspingState: For the specific manipulator appendage, returns IsGraspingState.TRUE if it is grasping\n                (potentially @candidate_obj if specified), IsGraspingState.FALSE if it is not grasping,\n                and IsGraspingState.UNKNOWN if unknown.\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nif self.grasping_mode != \"physical\":\nis_grasping_obj = (\nself._ag_obj_in_hand[arm] is not None\nif candidate_obj is None\nelse self._ag_obj_in_hand[arm] == candidate_obj\n)\nis_grasping = (\nIsGraspingState.TRUE\nif is_grasping_obj and self._ag_release_counter[arm] is None\nelse IsGraspingState.FALSE\n)\nelse:\n# Infer from the gripper controller the state\nis_grasping = self._controllers[\"gripper_{}\".format(arm)].is_grasping()\n# If candidate obj is not None, we also check to see if our fingers are in contact with the object\nif is_grasping and candidate_obj is not None:\ngrasping_obj = False\nobj_links = {link.prim_path for link in candidate_obj.links.values()}\nfinger_links = {link.prim_path for link in self.finger_links[arm]}\nfor c in self.contact_list():\nc_set = {c.body0, c.body1}\n# Valid grasping of object if one of the set is a finger link and the other is the grasped object\nif len(c_set - finger_links) == 1 and len(c_set - obj_links) == 1:\ngrasping_obj = True\nbreak\n# Update is_grasping\nis_grasping = grasping_obj\nreturn is_grasping\ndef _find_gripper_contacts(self, arm=\"default\", return_contact_positions=False):\n\"\"\"\n        For arm @arm, calculate any body IDs and corresponding link IDs that are not part of the robot\n        itself that are in contact with any of this arm's gripper's fingers\n        Args:\n            arm (str): specific arm whose gripper will be checked for contact. Default is \"default\" which\n                corresponds to the first entry in self.arm_names\n            return_contact_positions (bool): if True, will additionally return the contact (x,y,z) position\n        Returns:\n            2-tuple:\n                - set: set of unique contact prim_paths that are not the robot self-collisions.\n                    If @return_contact_positions is True, then returns (prim_path, pos), where pos is the contact\n                    (x,y,z) position\n                    Note: if no objects that are not the robot itself are intersecting, the set will be empty.\n                - dict: dictionary mapping unique contact objects defined by the contact prim_path to\n                    set of unique robot link prim_paths that it is in contact with\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nrobot_contact_links = dict()\ncontact_data = set()\n# Find all objects in contact with all finger joints for this arm\ncon_results = [con for link in self.finger_links[arm] for con in link.contact_list()]\n# Get robot contact links\nlink_paths = set(self.link_prim_paths)\nfor con_res in con_results:\n# Only add this contact if it's not a robot self-collision\nother_contact_set = {con_res.body0, con_res.body1} - link_paths\nif len(other_contact_set) == 1:\nlink_contact, other_contact = (con_res.body0, con_res.body1) if \\\n                    list(other_contact_set)[0] == con_res.body1 else (con_res.body1, con_res.body0)\n# Add to contact data\ncontact_data.add((other_contact, tuple(con_res.position)) if return_contact_positions else other_contact)\n# Also add robot contact link info\nif other_contact not in robot_contact_links:\nrobot_contact_links[other_contact] = set()\nrobot_contact_links[other_contact].add(link_contact)\nreturn contact_data, robot_contact_links\ndef set_position_orientation(self, position=None, orientation=None):\n# Store the original EEF poses.\noriginal_poses = {}\nfor arm in self.arm_names:\noriginal_poses[arm] = (self.get_eef_position(arm), self.get_eef_orientation(arm))\n# Run the super method\nsuper().set_position_orientation(position=position, orientation=orientation)\n# Now for each hand, if it was holding an AG object, teleport it.\nfor arm in self.arm_names:\nif self._ag_obj_in_hand[arm] is not None:\noriginal_eef_pose = T.pose2mat(original_poses[arm])\ninv_original_eef_pose = T.pose_inv(pose_mat=original_eef_pose)\noriginal_obj_pose = T.pose2mat(self._ag_obj_in_hand[arm].get_position_orientation())\nnew_eef_pose = T.pose2mat((self.get_eef_position(arm), self.get_eef_orientation(arm)))\n# New object pose is transform:\n# original --&gt; \"De\"transform the original EEF pose --&gt; \"Re\"transform the new EEF pose\nnew_obj_pose = new_eef_pose @ inv_original_eef_pose @ original_obj_pose\nself._ag_obj_in_hand[arm].set_position_orientation(*T.mat2pose(hmat=new_obj_pose))\ndef apply_action(self, action):\n# First run assisted grasping\nif self.grasping_mode != \"physical\":\nself._handle_assisted_grasping(action=action)\n# Potentially freeze gripper joints\nfor arm in self.arm_names:\nif self._ag_freeze_gripper[arm]:\nself._freeze_gripper(arm)\n# Run super method as normal\nsuper().apply_action(action)\ndef deploy_control(self, control, control_type, indices=None, normalized=False):\n# We intercept the gripper control and replace it with the current joint position if we're freezing our gripper\nfor arm in self.arm_names:\nif self._ag_freeze_gripper[arm]:\ncontrol[self.gripper_control_idx[arm]] = self._ag_obj_constraint_params[arm][\"gripper_pos\"] if \\\n                    self.controllers[f\"gripper_{arm}\"].control_type == ControlType.POSITION else 0.0\nsuper().deploy_control(control=control, control_type=control_type, indices=indices, normalized=normalized)\ndef _release_grasp(self, arm=\"default\"):\n\"\"\"\n        Magic action to release this robot's grasp on an object\n        Args:\n            arm (str): specific arm whose grasp will be released.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\n# Remove joint and filtered collision restraints\nog.sim.stage.RemovePrim(self._ag_obj_constraint_params[arm][\"ag_joint_prim_path\"])\nself._ag_data[arm] = None\nself._ag_obj_constraints[arm] = None\nself._ag_obj_constraint_params[arm] = {}\nself._ag_freeze_gripper[arm] = False\nself._ag_release_counter[arm] = 0\ndef release_grasp_immediately(self):\n\"\"\"\n        Magic action to release this robot's grasp for all arms at once.\n        As opposed to @_release_grasp, this method would byupass the release window mechanism and immediately release.\n        \"\"\"\nfor arm in self.arm_names:\nif self._ag_obj_in_hand[arm] is not None:\nself._release_grasp(arm=arm)\n# TODO: Verify not needed!\n# for finger_link in self.finger_links[arm]:\n#     finger_link.remove_filtered_collision_pair(prim=self._ag_obj_in_hand[arm])\nself._ag_obj_in_hand[arm] = None\nself._ag_release_counter[arm] = None\ndef get_control_dict(self):\n# In addition to super method, add in EEF states\ndic = super().get_control_dict()\nfor arm in self.arm_names:\ndic[\"eef_{}_pos_relative\".format(arm)] = self.get_relative_eef_position(arm)\ndic[\"eef_{}_quat_relative\".format(arm)] = self.get_relative_eef_orientation(arm)\nreturn dic\ndef _get_proprioception_dict(self):\ndic = super()._get_proprioception_dict()\n# Loop over all arms to grab proprio info\njoint_positions = self.get_joint_positions(normalized=False)\njoint_velocities = self.get_joint_velocities(normalized=False)\nfor arm in self.arm_names:\n# Add arm info\ndic[\"arm_{}_qpos\".format(arm)] = joint_positions[self.arm_control_idx[arm]]\ndic[\"arm_{}_qpos_sin\".format(arm)] = np.sin(joint_positions[self.arm_control_idx[arm]])\ndic[\"arm_{}_qpos_cos\".format(arm)] = np.cos(joint_positions[self.arm_control_idx[arm]])\ndic[\"arm_{}_qvel\".format(arm)] = joint_velocities[self.arm_control_idx[arm]]\n# Add eef and grasping info\ndic[\"eef_{}_pos_global\".format(arm)] = self.get_eef_position(arm)\ndic[\"eef_{}_quat_global\".format(arm)] = self.get_eef_orientation(arm)\ndic[\"eef_{}_pos\".format(arm)] = self.get_relative_eef_position(arm)\ndic[\"eef_{}_quat\".format(arm)] = self.get_relative_eef_orientation(arm)\ndic[\"grasp_{}\".format(arm)] = np.array([self.is_grasping(arm)])\ndic[\"gripper_{}_qpos\".format(arm)] = joint_positions[self.gripper_control_idx[arm]]\ndic[\"gripper_{}_qvel\".format(arm)] = joint_velocities[self.gripper_control_idx[arm]]\nreturn dic\n@property\ndef default_proprio_obs(self):\nobs_keys = super().default_proprio_obs\nfor arm in self.arm_names:\nobs_keys += [\n\"arm_{}_qpos_sin\".format(arm),\n\"arm_{}_qpos_cos\".format(arm),\n\"eef_{}_pos\".format(arm),\n\"eef_{}_quat\".format(arm),\n\"gripper_{}_qpos\".format(arm),\n\"grasp_{}\".format(arm),\n]\nreturn obs_keys\n@property\ndef grasping_mode(self):\n\"\"\"\n        Grasping mode of this robot. Is one of AG_MODES\n        Returns:\n            str: Grasping mode for this robot\n        \"\"\"\nreturn self._grasping_mode\n@property\ndef controller_order(self):\n# Assumes we have arm(s) and corresponding gripper(s)\ncontrollers = []\nfor arm in self.arm_names:\ncontrollers += [\"arm_{}\".format(arm), \"gripper_{}\".format(arm)]\nreturn controllers\n@property\ndef _default_controllers(self):\n# Always call super first\ncontrollers = super()._default_controllers\n# For best generalizability use, joint controller as default\nfor arm in self.arm_names:\ncontrollers[\"arm_{}\".format(arm)] = \"JointController\"\ncontrollers[\"gripper_{}\".format(arm)] = \"JointController\"\nreturn controllers\n@property\ndef n_arms(self):\n\"\"\"\n        Returns:\n            int: Number of arms this robot has. Returns 1 by default\n        \"\"\"\nreturn 1\n@property\ndef arm_names(self):\n\"\"\"\n        Returns:\n            list of str: List of arm names for this robot. Should correspond to the keys used to index into\n                arm- and gripper-related dictionaries, e.g.: eef_link_names, finger_link_names, etc.\n                Default is string enumeration based on @self.n_arms.\n        \"\"\"\nreturn [str(i) for i in range(self.n_arms)]\n@property\ndef default_arm(self):\n\"\"\"\n        Returns:\n            str: Default arm name for this robot, corresponds to the first entry in @arm_names by default\n        \"\"\"\nreturn self.arm_names[0]\n@property\n@abstractmethod\ndef arm_link_names(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding arm link names,\n                should correspond to specific link names in this robot's underlying model file\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef arm_joint_names(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding arm joint names,\n                should correspond to specific joint names in this robot's underlying model file\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef eef_link_names(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding name of the EEF link,\n                should correspond to specific link name in this robot's underlying model file\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef finger_link_names(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to array of link names corresponding to\n                this robot's fingers\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef finger_joint_names(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to array of joint names corresponding to\n                this robot's fingers\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef arm_control_idx(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to indices in low-level control\n                vector corresponding to arm joints.\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef gripper_control_idx(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to indices in low-level control\n                vector corresponding to gripper joints.\n        \"\"\"\nraise NotImplementedError\n@property\ndef arm_links(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot links corresponding to\n                that arm's links\n        \"\"\"\nreturn {arm: [self._links[link] for link in self.arm_link_names[arm]] for arm in self.arm_names}\n@property\ndef eef_links(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot link corresponding to that arm's\n                eef link\n        \"\"\"\nreturn {arm: self._links[self.eef_link_names[arm]] for arm in self.arm_names}\n@property\ndef finger_links(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot links corresponding to\n                that arm's finger links\n        \"\"\"\nreturn {arm: [self._links[link] for link in self.finger_link_names[arm]] for arm in self.arm_names}\n@property\ndef finger_joints(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot joints corresponding to\n                that arm's finger joints\n        \"\"\"\nreturn {arm: [self._joints[joint] for joint in self.finger_joint_names[arm]] for arm in self.arm_names}\n@property\ndef assisted_grasp_start_points(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping individual arm appendage names to array of GraspingPoint tuples,\n                composed of (link_name, position) values specifying valid grasping start points located at\n                cartesian (x,y,z) coordinates specified in link_name's local coordinate frame.\n                These values will be used in conjunction with\n                @self.assisted_grasp_end_points to trigger assisted grasps, where objects that intersect\n                with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in\n                @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper\n                appendage). By default, each entry returns None, and must be implemented by any robot subclass that\n                wishes to use assisted grasping.\n        \"\"\"\nreturn {arm: None for arm in self.arm_names}\n@property\ndef assisted_grasp_end_points(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping individual arm appendage names to array of GraspingPoint tuples,\n                composed of (link_name, position) values specifying valid grasping end points located at\n                cartesian (x,y,z) coordinates specified in link_name's local coordinate frame.\n                These values will be used in conjunction with\n                @self.assisted_grasp_start_points to trigger assisted grasps, where objects that intersect\n                with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in\n                @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper\n                appendage). By default, each entry returns None, and must be implemented by any robot subclass that\n                wishes to use assisted grasping.\n        \"\"\"\nreturn {arm: None for arm in self.arm_names}\n@property\ndef finger_lengths(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding length of the fingers in that\n                hand defined from the palm (assuming all fingers in one hand are equally long)\n        \"\"\"\nraise NotImplementedError\ndef get_eef_position(self, arm=\"default\"):\n\"\"\"\n        Args:\n            arm (str): specific arm to grab eef position. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n        Returns:\n            3-array: (x,y,z) global end-effector Cartesian position for this robot's end-effector corresponding\n                to arm @arm\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self._links[self.eef_link_names[arm]].get_position()\ndef get_eef_orientation(self, arm=\"default\"):\n\"\"\"\n        Args:\n            arm (str): specific arm to grab eef orientation. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n        Returns:\n            3-array: (x,y,z,w) global quaternion orientation for this robot's end-effector corresponding\n                to arm @arm\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self._links[self.eef_link_names[arm]].get_orientation()\ndef get_relative_eef_pose(self, arm=\"default\", mat=False):\n\"\"\"\n        Args:\n            arm (str): specific arm to grab eef pose. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n            mat (bool): whether to return pose in matrix form (mat=True) or (pos, quat) tuple (mat=False)\n        Returns:\n            2-tuple or (4, 4)-array: End-effector pose, either in 4x4 homogeneous\n                matrix form (if @mat=True) or (pos, quat) tuple (if @mat=False), corresponding to arm @arm\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\neef_link_pose = self.eef_links[arm].get_position_orientation()\nbase_link_pose = self.get_position_orientation()\npose = T.relative_pose_transform(*eef_link_pose, *base_link_pose)\nreturn T.pose2mat(pose) if mat else pose\ndef get_relative_eef_position(self, arm=\"default\"):\n\"\"\"\n        Args:\n            arm (str): specific arm to grab relative eef pos.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        Returns:\n            3-array: (x,y,z) Cartesian position of end-effector relative to robot base frame\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self.get_relative_eef_pose(arm=arm)[0]\ndef get_relative_eef_orientation(self, arm=\"default\"):\n\"\"\"\n        Args:\n            arm (str): specific arm to grab relative eef orientation.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        Returns:\n            4-array: (x,y,z,w) quaternion orientation of end-effector relative to robot base frame\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self.get_relative_eef_pose(arm=arm)[1]\ndef _calculate_in_hand_object_rigid(self, arm=\"default\"):\n\"\"\"\n        Calculates which object to assisted-grasp for arm @arm. Returns an (object_id, link_id) tuple or None\n        if no valid AG-enabled object can be found.\n        Args:\n            arm (str): specific arm to calculate in-hand object for.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        Returns:\n            None or 2-tuple: If a valid assisted-grasp object is found, returns the corresponding\n                (object, object_link) (i.e.: (BaseObject, RigidPrim)) pair to the contacted in-hand object.\n                Otherwise, returns None\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\n# If we're not using physical grasping, we check for gripper contact\nif self.grasping_mode != \"physical\":\ncandidates_set, robot_contact_links = self._find_gripper_contacts(arm=arm)\n# If we're using assisted grasping, we further filter candidates via ray-casting\nif self.grasping_mode == \"assisted\":\nraise NotImplementedError(\"Not assisted grasp avaialble yet in OmnOmniGibson!\")\nelse:\nraise ValueError(\"Invalid grasping mode for calculating in hand object: {}\".format(self.grasping_mode))\n# Immediately return if there are no valid candidates\nif len(candidates_set) == 0:\nreturn None\n# Find the closest object to the gripper center\ngripper_center_pos = self.eef_links[arm].get_position()\ncandidate_data = []\nfor prim_path in candidates_set:\n# Calculate position of the object link\n# Note: this assumes the simulator is playing!\nrb_handle = self._dc.get_rigid_body(prim_path)\npose = self._dc.get_rigid_body_pose(rb_handle)\nlink_pos = np.asarray(pose.p)\ndist = np.linalg.norm(np.array(link_pos) - np.array(gripper_center_pos))\ncandidate_data.append((prim_path, dist))\ncandidate_data = sorted(candidate_data, key=lambda x: x[-1])\nag_prim_path, _ = candidate_data[0]\n# Make sure the ag_prim_path is not a self collision\nassert ag_prim_path not in self.link_prim_paths, \"assisted grasp object cannot be the robot itself!\"\n# Make sure at least two fingers are in contact with this object\nrobot_contacts = robot_contact_links[ag_prim_path]\ntouching_at_least_two_fingers = len({link.prim_path for link in self.finger_links[arm]}.intersection(robot_contacts)) &gt;= 2\n# TODO: Better heuristic, hacky, we assume the parent object prim path is the prim_path minus the last \"/\" item\nag_obj_prim_path = \"/\".join(prim_path.split(\"/\")[:-1])\nag_obj_link_name = prim_path.split(\"/\")[-1]\nag_obj = og.sim.scene.object_registry(\"prim_path\", ag_obj_prim_path)\nag_obj_link = ag_obj.links[ag_obj_link_name]\n# Return None if object cannot be assisted grasped or not touching at least two fingers\nif ag_obj is None or (not can_assisted_grasp(ag_obj)) or (not touching_at_least_two_fingers):\nreturn None\n# Get object and its contacted link\nreturn ag_obj, ag_obj_link\ndef _handle_release_window(self, arm=\"default\"):\n\"\"\"\n        Handles releasing an object from arm @arm\n        Args:\n            arm (str): specific arm to handle release window.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nself._ag_release_counter[arm] += 1\ntime_since_release = self._ag_release_counter[arm] * og.sim.get_rendering_dt()\nif time_since_release &gt;= m.RELEASE_WINDOW:\n# TODO: Verify not needed!\n# Remove filtered collision restraints\n# for finger_link in self.finger_links[arm]:\n#     finger_link.remove_filtered_collision_pair(prim=self._ag_obj_in_hand[arm])\nself._ag_obj_in_hand[arm] = None\nself._ag_release_counter[arm] = None\ndef _freeze_gripper(self, arm=\"default\"):\n\"\"\"\n        Freezes gripper finger joints - used in assisted grasping.\n        Args:\n            arm (str): specific arm to freeze gripper.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nfor joint_name, j_val in self._ag_freeze_joint_pos[arm].items():\njoint = self._joints[joint_name]\njoint.set_pos(pos=j_val)\njoint.set_vel(vel=0.0)\n@property\ndef robot_arm_descriptor_yamls(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to files path to the descriptor\n                of the robot for IK Controller.\n        \"\"\"\nraise NotImplementedError\n@property\ndef _default_arm_joint_controller_configs(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default controller config to control that\n                robot's arm. Uses velocity control by default.\n        \"\"\"\ndic = {}\nfor arm in self.arm_names:\ndic[arm] = {\n\"name\": \"JointController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"velocity\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.arm_control_idx[arm],\n\"command_output_limits\": \"default\",\n\"use_delta_commands\": False,\n}\nreturn dic\n@property\ndef _default_arm_ik_controller_configs(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default controller config for an\n                Inverse kinematics controller to control this robot's arm\n        \"\"\"\ndic = {}\nfor arm in self.arm_names:\ndic[arm] = {\n\"name\": \"InverseKinematicsController\",\n\"task_name\": f\"eef_{arm}\",\n\"robot_description_path\": self.robot_arm_descriptor_yamls[arm],\n\"robot_urdf_path\": self.urdf_path,\n\"eef_name\": self.eef_link_names[arm],\n\"control_freq\": self._control_freq,\n\"default_joint_pos\": self.default_joint_pos,\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.arm_control_idx[arm],\n\"command_output_limits\": (\nnp.array([-0.2, -0.2, -0.2, -0.5, -0.5, -0.5]),\nnp.array([0.2, 0.2, 0.2, 0.5, 0.5, 0.5]),\n),\n\"kv\": 2.0,\n\"mode\": \"pose_delta_ori\",\n\"smoothing_filter_size\": 2,\n\"workspace_pose_limiter\": None,\n}\nreturn dic\n@property\ndef _default_arm_null_joint_controller_configs(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default arm null controller config\n                to control this robot's arm i.e. dummy controller\n        \"\"\"\ndic = {}\nfor arm in self.arm_names:\ndic[arm] = {\n\"name\": \"NullJointController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"velocity\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.arm_control_idx[arm],\n}\nreturn dic\n@property\ndef _default_gripper_multi_finger_controller_configs(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default controller config to control\n                this robot's multi finger gripper. Assumes robot gripper idx has exactly two elements\n        \"\"\"\ndic = {}\nfor arm in self.arm_names:\ndic[arm] = {\n\"name\": \"MultiFingerGripperController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"position\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.gripper_control_idx[arm],\n\"command_output_limits\": \"default\",\n\"mode\": \"binary\",\n\"limit_tolerance\": 0.001,\n}\nreturn dic\n@property\ndef _default_gripper_joint_controller_configs(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default gripper joint controller config\n                to control this robot's gripper\n        \"\"\"\ndic = {}\nfor arm in self.arm_names:\ndic[arm] = {\n\"name\": \"JointController\",\n\"control_freq\": self._control_freq,\n\"motor_type\": \"velocity\",\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.gripper_control_idx[arm],\n\"command_output_limits\": \"default\",\n\"use_delta_commands\": False,\n}\nreturn dic\n@property\ndef _default_gripper_null_controller_configs(self):\n\"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default gripper null controller config\n                to control this robot's (non-prehensile) gripper i.e. dummy controller\n        \"\"\"\ndic = {}\nfor arm in self.arm_names:\ndic[arm] = {\n\"name\": \"NullJointController\",\n\"control_freq\": self._control_freq,\n\"control_limits\": self.control_limits,\n}\nreturn dic\n@property\ndef _default_controller_config(self):\n# Always run super method first\ncfg = super()._default_controller_config\narm_ik_configs = self._default_arm_ik_controller_configs\narm_joint_configs = self._default_arm_joint_controller_configs\narm_null_joint_configs = self._default_arm_null_joint_controller_configs\ngripper_pj_configs = self._default_gripper_multi_finger_controller_configs\ngripper_joint_configs = self._default_gripper_joint_controller_configs\ngripper_null_configs = self._default_gripper_null_controller_configs\n# Add arm and gripper defaults, per arm\nfor arm in self.arm_names:\ncfg[\"arm_{}\".format(arm)] = {\narm_ik_configs[arm][\"name\"]: arm_ik_configs[arm],\narm_joint_configs[arm][\"name\"]: arm_joint_configs[arm],\narm_null_joint_configs[arm][\"name\"]: arm_null_joint_configs[arm],\n}\ncfg[\"gripper_{}\".format(arm)] = {\ngripper_pj_configs[arm][\"name\"]: gripper_pj_configs[arm],\ngripper_joint_configs[arm][\"name\"]: gripper_joint_configs[arm],\ngripper_null_configs[arm][\"name\"]: gripper_null_configs[arm],\n}\nreturn cfg\ndef _establish_grasp_rigid(self, arm=\"default\", ag_data=None):\n\"\"\"\n        Establishes an ag-assisted grasp, if enabled.\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n            ag_data (None or 2-tuple): if specified, assisted-grasp object, link tuple (i.e. :(BaseObject, RigidPrim)).\n                Otherwise, does a no-op\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\n# Return immediately if ag_data is None\nif ag_data is None:\nreturn\nag_obj, ag_link = ag_data\n# Create a p2p joint if it's a child link of a fixed URDF that is connected by a revolute or prismatic joint\njoint_type = \"FixedJoint\"\nif ag_obj.fixed_base:\n# We search up the tree path from the ag_link until we encounter the root (joint == 0) or a non fixed\n# joint (e.g.: revolute or fixed)\nlink_handle = ag_link.handle\njoint_handle = self._dc.get_rigid_body_parent_joint(link_handle)\nwhile joint_handle != 0:\n# If this joint type is not fixed, we've encountered a valid moving joint\n# So we create a spherical joint rather than fixed joint\nif self._dc.get_joint_type(joint_handle) != JointType.JOINT_FIXED:\njoint_type = \"SphericalJoint\"\nbreak\n# Grab the parent link and its parent joint for the link\nlink_handle = self._dc.get_joint_parent_body(joint_handle)\njoint_handle = self._dc.get_rigid_body_parent_joint(link_handle)\nforce_data, _ = self._find_gripper_contacts(arm=arm, return_contact_positions=True)\ncontact_pos = None\nfor c_link_prim_path, c_contact_pos in force_data:\nif c_link_prim_path == ag_link.prim_path:\ncontact_pos = np.array(c_contact_pos)\nbreak\nassert contact_pos is not None\n# Joint frame set at the contact point\n# Need to find distance between robot and contact point in robot link's local frame and\n# ag link and contact point in ag link's local frame\njoint_frame_pos = contact_pos\njoint_frame_orn = np.array([0, 0, 0, 1.0])\neef_link_pos, eef_link_orn = self.eef_links[arm].get_position_orientation()\nparent_frame_pos, parent_frame_orn = T.relative_pose_transform(joint_frame_pos, joint_frame_orn, eef_link_pos, eef_link_orn)\nobj_link_pos, obj_link_orn = ag_link.get_position_orientation()\nchild_frame_pos, child_frame_orn = T.relative_pose_transform(joint_frame_pos, joint_frame_orn, obj_link_pos, obj_link_orn)\n# Create the joint\njoint_prim_path = f\"{self.eef_links[arm].prim_path}/ag_constraint\"\njoint_prim = create_joint(\nprim_path=joint_prim_path,\njoint_type=joint_type,\nbody0=self.eef_links[arm].prim_path,\nbody1=ag_link.prim_path,\nenabled=True,\njoint_frame_in_parent_frame_pos=parent_frame_pos / self.scale,\njoint_frame_in_parent_frame_quat=parent_frame_orn,\njoint_frame_in_child_frame_pos=child_frame_pos / ag_obj.scale,\njoint_frame_in_child_frame_quat=child_frame_orn,\n)\n# Save a reference to this joint prim\nself._ag_obj_constraints[arm] = joint_prim\n# Modify max force based on user-determined assist parameters\n# TODO\nmax_force = m.ASSIST_FORCE if joint_type == \"FixedJoint\" else m.ASSIST_FORCE * m.ARTICULATED_ASSIST_FRACTION\n# joint_prim.GetAttribute(\"physics:breakForce\").Set(max_force)\nself._ag_obj_constraint_params[arm] = {\n\"ag_obj_prim_path\": ag_obj.prim_path,\n\"ag_link_prim_path\": ag_link.prim_path,\n\"ag_joint_prim_path\": joint_prim_path,\n\"joint_type\": joint_type,\n\"gripper_pos\": self.get_joint_positions()[self.gripper_control_idx[arm]],\n\"max_force\": max_force,\n}\nself._ag_obj_in_hand[arm] = ag_obj\nself._ag_freeze_gripper[arm] = True\n# Disable collisions while picking things up\n# TODO: Verify not needed!\n# for finger_link in self.finger_links[arm]:\n#     finger_link.add_filtered_collision_pair(prim=ag_obj)\nfor joint in self.finger_joints[arm]:\nj_val = joint.get_state()[0][0]\nself._ag_freeze_joint_pos[arm][joint.joint_name] = j_val\ndef _handle_assisted_grasping(self, action):\n\"\"\"\n        Handles assisted grasping.\n        Args:\n            action (n-array): gripper action to apply. &gt;= 0 is release (open), &lt; 0 is grasp (close).\n        \"\"\"\n# Loop over all arms\nfor arm in self.arm_names:\n# Make sure gripper action dimension is only 1\nassert (\nself._controllers[\"gripper_{}\".format(arm)].command_dim == 1\n), \"Gripper {} controller command dim must be 1 to use assisted grasping, got: {}\".format(\narm, self._controllers[\"gripper_{}\".format(arm)].command_dim\n)\n# TODO: Why are we separately checking for complementary conditions?\nthreshold = np.mean(self._controllers[\"gripper_{}\".format(arm)].command_input_limits)\napplying_grasp = action[self.controller_action_idx[\"gripper_{}\".format(arm)]] &lt; threshold\nreleasing_grasp = action[self.controller_action_idx[\"gripper_{}\".format(arm)]] &gt; threshold\n# Execute gradual release of object\nif self._ag_obj_in_hand[arm]:\nif self._ag_release_counter[arm] is not None:\nself._handle_release_window(arm=arm)\nelse:\n# constraint_violated = (\n#     get_constraint_violation(self._ag_obj_cid[arm]) &gt; m.CONSTRAINT_VIOLATION_THRESHOLD\n# )\n# if constraint_violated or releasing_grasp:\nif gm.AG_CLOTH:\nself._update_constraint_cloth(arm=arm)\nif releasing_grasp:\nself._release_grasp(arm=arm)\nelif applying_grasp:\nself._ag_data[arm] = self._calculate_in_hand_object(arm=arm)\nself._establish_grasp(arm=arm, ag_data=self._ag_data[arm])\ndef _update_constraint_cloth(self, arm=\"default\"):\n\"\"\"\n        Update the AG constraint for cloth: for the fixed joint between the attachment point and the world, we set\n        the local pos to match the current eef link position plus the attachment_point_pos_local offset. As a result,\n        the joint will drive the attachment point to the updated position, which will then drive the cloth.\n        See _establish_grasp_cloth for more details.\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\nattachment_point_pos_local = self._ag_obj_constraint_params[arm][\"attachment_point_pos_local\"]\neef_link_pos, eef_link_orn = self.eef_links[arm].get_position_orientation()\nattachment_point_pos, _ = T.pose_transform(eef_link_pos, eef_link_orn, attachment_point_pos_local, [0, 0, 0, 1])\njoint_prim = self._ag_obj_constraints[arm]\njoint_prim.GetAttribute(\"physics:localPos1\").Set(Gf.Vec3f(*attachment_point_pos.astype(float)))\ndef _calculate_in_hand_object(self, arm=\"default\"):\nif gm.AG_CLOTH:\nreturn self._calculate_in_hand_object_cloth(arm)\nelse:\nreturn self._calculate_in_hand_object_rigid(arm)\ndef _establish_grasp(self, arm=\"default\", ag_data=None):\nif gm.AG_CLOTH:\nreturn self._establish_grasp_cloth(arm, ag_data)\nelse:\nreturn self._establish_grasp_rigid(arm, ag_data)\ndef _calculate_in_hand_object_cloth(self, arm=\"default\"):\n\"\"\"\n        Same as _calculate_in_hand_object_rigid, except for cloth. Only one should be used at any given time.\n        Calculates which object to assisted-grasp for arm @arm. Returns an (BaseObject, RigidPrim, np.ndarray) tuple or\n        None if no valid AG-enabled object can be found.\n        1) Check if the gripper is closed enough\n        2) Go through each of the cloth object, and check if its attachment point link position is within the \"ghost\"\n        box volume of the gripper link.\n        Only returns the first valid object and ignore the rest.\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        Returns:\n            None or 3-tuple: If a valid assisted-grasp object is found,\n                returns the corresponding (object, object_link, attachment_point_position), i.e.\n                ((BaseObject, RigidPrim, np.ndarray)) to the contacted in-hand object. Otherwise, returns None\n        \"\"\"\n# TODO (eric): Assume joint_pos = 0 means fully closed\nGRIPPER_FINGER_CLOSE_THRESHOLD = 0.03\ngripper_finger_pos = self.get_joint_positions()[self.gripper_control_idx[arm]]\ngripper_finger_close = np.sum(gripper_finger_pos) &lt; GRIPPER_FINGER_CLOSE_THRESHOLD\nif not gripper_finger_close:\nreturn None\ncloth_objs = og.sim.scene.object_registry(\"prim_type\", PrimType.CLOTH)\nif cloth_objs is None:\nreturn None\n# TODO (eric): Only AG one cloth at any given moment.\n# Returns the first cloth that overlaps with the \"ghost\" box volume\nfor cloth_obj in cloth_objs:\nattachment_point_pos = cloth_obj.links[\"attachment_point\"].get_position()\nparticles_in_volume = self._ag_check_in_volume[arm]([attachment_point_pos])\nif particles_in_volume.sum() &gt; 0:\nreturn cloth_obj, cloth_obj.links[\"attachment_point\"], attachment_point_pos\nreturn None\ndef _establish_grasp_cloth(self, arm=\"default\", ag_data=None):\n\"\"\"\n        Same as _establish_grasp_cloth, except for cloth. Only one should be used at any given time.\n        Establishes an ag-assisted grasp, if enabled.\n        Create a fixed joint between the attachment point link of the cloth object and the world.\n        In theory, we could have created a fixed joint to the eef link, but omni doesn't support this as the robot has\n        an articulation root API attached to it, which is incompatible with the attachment API.\n        We also store attachment_point_pos_local as the attachment point position in the eef link frame when the fixed\n        joint is created. As the eef link frame changes its pose, we will use attachment_point_pos_local to figure out\n        the new attachment_point_pos in the world frame and set the fixed joint to there. See _update_constraint_cloth\n        for more details.\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n            ag_data (None or 3-tuple): If specified, should be the corresponding\n                (object, object_link, attachment_point_position), i.e. ((BaseObject, RigidPrim, np.ndarray)) to the]\n                contacted in-hand object\n        \"\"\"\narm = self.default_arm if arm == \"default\" else arm\n# Return immediately if ag_data is None\nif ag_data is None:\nreturn\nag_obj, ag_link, attachment_point_pos = ag_data\n# Find the attachment point position in the eef frame\neef_link_pos, eef_link_orn = self.eef_links[arm].get_position_orientation()\nattachment_point_pos_local, _ = \\\n            T.relative_pose_transform(attachment_point_pos, [0, 0, 0, 1], eef_link_pos, eef_link_orn)\n# Create the joint\njoint_prim_path = f\"{ag_link.prim_path}/ag_constraint\"\njoint_type = \"FixedJoint\"\njoint_prim = create_joint(\nprim_path=joint_prim_path,\njoint_type=joint_type,\nbody0=ag_link.prim_path,\nbody1=None,\nenabled=False,\njoint_frame_in_child_frame_pos=attachment_point_pos,\n)\n# Save a reference to this joint prim\nself._ag_obj_constraints[arm] = joint_prim\n# Modify max force based on user-determined assist parameters\n# TODO\nmax_force = m.ASSIST_FORCE\n# joint_prim.GetAttribute(\"physics:breakForce\").Set(max_force)\nself._ag_obj_constraint_params[arm] = {\n\"ag_obj_prim_path\": ag_obj.prim_path,\n\"ag_link_prim_path\": ag_link.prim_path,\n\"ag_joint_prim_path\": joint_prim_path,\n\"joint_type\": joint_type,\n\"gripper_pos\": self.get_joint_positions()[self.gripper_control_idx[arm]],\n\"max_force\": max_force,\n\"attachment_point_pos_local\": attachment_point_pos_local,\n}\nself._ag_obj_in_hand[arm] = ag_obj\nself._ag_freeze_gripper[arm] = True\n# Disable collisions while picking things up\n# for finger_link in self.finger_links[arm]:\n#     finger_link.add_filtered_collision_pair(prim=ag_obj)\nfor joint in self.finger_joints[arm]:\nj_val = joint.get_state()[0][0]\nself._ag_freeze_joint_pos[arm][joint.joint_name] = j_val\ndef _dump_state(self):\n# Call super first\nstate = super()._dump_state()\n# If we're using actual physical grasping, no extra state needed to save\nif self.grasping_mode == \"physical\":\nreturn state\n# TODO: Include AG_state\nreturn state\ndef _load_state(self, state):\nsuper()._load_state(state=state)\n# No additional loading needed if we're using physical grasping\nif self.grasping_mode == \"physical\":\nreturn\n# TODO: Include AG_state\ndef _serialize(self, state):\n# Call super first\nstate_flat = super()._serialize(state=state)\n# No additional serialization needed if we're using physical grasping\nif self.grasping_mode == \"physical\":\nreturn state_flat\n# TODO AG\nreturn state_flat\ndef _deserialize(self, state):\n# Call super first\nstate_dict, idx = super()._deserialize(state=state)\n# No additional deserialization needed if we're using physical grasping\nif self.grasping_mode == \"physical\":\nreturn state_dict, idx\n# TODO AG\nreturn state_dict, idx\ndef can_toggle(self, toggle_position, toggle_distance_threshold):\n# Calculate for any fingers in any arm\nfor arm in self.arm_names:\nfor link in self.finger_links[arm]:\nlink_pos = link.get_position()\nif np.linalg.norm(np.array(link_pos) - np.array(toggle_position)) &lt; toggle_distance_threshold:\nreturn True\nreturn False\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"ManipulationRobot\")\nreturn classes\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_control_idx","title":"<code>arm_control_idx</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to indices in low-level control vector corresponding to arm joints.</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_joint_names","title":"<code>arm_joint_names</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to corresponding arm joint names, should correspond to specific joint names in this robot's underlying model file</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_link_names","title":"<code>arm_link_names</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to corresponding arm link names, should correspond to specific link names in this robot's underlying model file</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_links","title":"<code>arm_links</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to robot links corresponding to that arm's links</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_names","title":"<code>arm_names</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>list of str: List of arm names for this robot. Should correspond to the keys used to index into arm- and gripper-related dictionaries, e.g.: eef_link_names, finger_link_names, etc. Default is string enumeration based on @self.n_arms.</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.assisted_grasp_end_points","title":"<code>assisted_grasp_end_points</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping individual arm appendage names to array of GraspingPoint tuples, composed of (link_name, position) values specifying valid grasping end points located at cartesian (x,y,z) coordinates specified in link_name's local coordinate frame. These values will be used in conjunction with @self.assisted_grasp_start_points to trigger assisted grasps, where objects that intersect with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper appendage). By default, each entry returns None, and must be implemented by any robot subclass that wishes to use assisted grasping.</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.assisted_grasp_start_points","title":"<code>assisted_grasp_start_points</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping individual arm appendage names to array of GraspingPoint tuples, composed of (link_name, position) values specifying valid grasping start points located at cartesian (x,y,z) coordinates specified in link_name's local coordinate frame. These values will be used in conjunction with @self.assisted_grasp_end_points to trigger assisted grasps, where objects that intersect with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper appendage). By default, each entry returns None, and must be implemented by any robot subclass that wishes to use assisted grasping.</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.default_arm","title":"<code>default_arm</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Default arm name for this robot, corresponds to the first entry in @arm_names by default</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.eef_link_names","title":"<code>eef_link_names</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to corresponding name of the EEF link, should correspond to specific link name in this robot's underlying model file</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.eef_links","title":"<code>eef_links</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to robot link corresponding to that arm's eef link</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_joint_names","title":"<code>finger_joint_names</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to array of joint names corresponding to this robot's fingers</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_joints","title":"<code>finger_joints</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to robot joints corresponding to that arm's finger joints</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_lengths","title":"<code>finger_lengths</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to corresponding length of the fingers in that hand defined from the palm (assuming all fingers in one hand are equally long)</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_link_names","title":"<code>finger_link_names</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to array of link names corresponding to this robot's fingers</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_links","title":"<code>finger_links</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to robot links corresponding to that arm's finger links</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.grasping_mode","title":"<code>grasping_mode</code>  <code>property</code>","text":"<p>Grasping mode of this robot. Is one of AG_MODES</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Grasping mode for this robot</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.gripper_control_idx","title":"<code>gripper_control_idx</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to indices in low-level control vector corresponding to gripper joints.</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.n_arms","title":"<code>n_arms</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of arms this robot has. Returns 1 by default</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.robot_arm_descriptor_yamls","title":"<code>robot_arm_descriptor_yamls</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping arm appendage name to files path to the descriptor of the robot for IK Controller.</p>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.__init__","title":"<code>__init__(name, prim_path=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, load_config=None, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', grasping_mode='physical', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>control_freq</code> <code>float</code> <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p> <code>None</code> <code>controller_config</code> <code>None or dict</code> <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p> <code>None</code> <code>action_type</code> <code>str</code> <p>one of {discrete, continuous} - what type of action space to use</p> <code>'continuous'</code> <code>action_normalize</code> <code>bool</code> <p>whether to normalize inputted actions. This will override any default values specified by this class.</p> <code>True</code> <code>reset_joint_pos</code> <code>None or n-array</code> <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p> <code>None</code> <code>obs_modalities</code> <code>str or list of str</code> <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p> <code>'all'</code> <code>proprio_obs</code> <code>str or list of str</code> <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p> <code>'default'</code> <code>grasping_mode</code> <code>str</code> <p>One of {\"physical\", \"assisted\", \"sticky\"}. If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force). If \"assisted\", will magnetize any object touching and within the gripper's fingers. If \"sticky\", will magnetize any object touching the gripper's fingers.</p> <code>'physical'</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to BaseRobot\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n# Unique to ManipulationRobot\ngrasping_mode=\"physical\",\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n            If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n            If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n            If \"sticky\", will magnetize any object touching the gripper's fingers.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Store relevant internal vars\nassert_valid_key(key=grasping_mode, valid_keys=AG_MODES, name=\"grasping_mode\")\nself._grasping_mode = grasping_mode\n# Initialize other variables used for assistive grasping\nself._ag_data = {arm: None for arm in self.arm_names}\nself._ag_freeze_joint_pos = {\narm: {} for arm in self.arm_names\n}  # Frozen positions for keeping fingers held still\nself._ag_obj_in_hand = {arm: None for arm in self.arm_names}\nself._ag_obj_constraints = {arm: None for arm in self.arm_names}\nself._ag_obj_constraint_params = {arm: {} for arm in self.arm_names}\nself._ag_freeze_gripper = {arm: None for arm in self.arm_names}\nself._ag_release_counter = {arm: None for arm in self.arm_names}\nself._ag_check_in_volume = {arm: None for arm in self.arm_names}\nself._ag_calculate_volume = {arm: None for arm in self.arm_names}\n# Call super() method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\nobs_modalities=obs_modalities,\nproprio_obs=proprio_obs,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_eef_orientation","title":"<code>get_eef_orientation(arm='default')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>arm</code> <code>str</code> <p>specific arm to grab eef orientation. Default is \"default\" which corresponds to the first entry in self.arm_names</p> <code>'default'</code> <p>Returns:</p> Type Description <p>3-array: (x,y,z,w) global quaternion orientation for this robot's end-effector corresponding to arm @arm</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def get_eef_orientation(self, arm=\"default\"):\n\"\"\"\n    Args:\n        arm (str): specific arm to grab eef orientation. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n    Returns:\n        3-array: (x,y,z,w) global quaternion orientation for this robot's end-effector corresponding\n            to arm @arm\n    \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self._links[self.eef_link_names[arm]].get_orientation()\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_eef_position","title":"<code>get_eef_position(arm='default')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>arm</code> <code>str</code> <p>specific arm to grab eef position. Default is \"default\" which corresponds to the first entry in self.arm_names</p> <code>'default'</code> <p>Returns:</p> Type Description <p>3-array: (x,y,z) global end-effector Cartesian position for this robot's end-effector corresponding to arm @arm</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def get_eef_position(self, arm=\"default\"):\n\"\"\"\n    Args:\n        arm (str): specific arm to grab eef position. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n    Returns:\n        3-array: (x,y,z) global end-effector Cartesian position for this robot's end-effector corresponding\n            to arm @arm\n    \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self._links[self.eef_link_names[arm]].get_position()\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_relative_eef_orientation","title":"<code>get_relative_eef_orientation(arm='default')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>arm</code> <code>str</code> <p>specific arm to grab relative eef orientation. Default is \"default\" which corresponds to the first entry in self.arm_names</p> <code>'default'</code> <p>Returns:</p> Type Description <p>4-array: (x,y,z,w) quaternion orientation of end-effector relative to robot base frame</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def get_relative_eef_orientation(self, arm=\"default\"):\n\"\"\"\n    Args:\n        arm (str): specific arm to grab relative eef orientation.\n            Default is \"default\" which corresponds to the first entry in self.arm_names\n    Returns:\n        4-array: (x,y,z,w) quaternion orientation of end-effector relative to robot base frame\n    \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self.get_relative_eef_pose(arm=arm)[1]\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_relative_eef_pose","title":"<code>get_relative_eef_pose(arm='default', mat=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>arm</code> <code>str</code> <p>specific arm to grab eef pose. Default is \"default\" which corresponds to the first entry in self.arm_names</p> <code>'default'</code> <code>mat</code> <code>bool</code> <p>whether to return pose in matrix form (mat=True) or (pos, quat) tuple (mat=False)</p> <code>False</code> <p>Returns:</p> Type Description <p>2-tuple or (4, 4)-array: End-effector pose, either in 4x4 homogeneous matrix form (if @mat=True) or (pos, quat) tuple (if @mat=False), corresponding to arm @arm</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def get_relative_eef_pose(self, arm=\"default\", mat=False):\n\"\"\"\n    Args:\n        arm (str): specific arm to grab eef pose. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n        mat (bool): whether to return pose in matrix form (mat=True) or (pos, quat) tuple (mat=False)\n    Returns:\n        2-tuple or (4, 4)-array: End-effector pose, either in 4x4 homogeneous\n            matrix form (if @mat=True) or (pos, quat) tuple (if @mat=False), corresponding to arm @arm\n    \"\"\"\narm = self.default_arm if arm == \"default\" else arm\neef_link_pose = self.eef_links[arm].get_position_orientation()\nbase_link_pose = self.get_position_orientation()\npose = T.relative_pose_transform(*eef_link_pose, *base_link_pose)\nreturn T.pose2mat(pose) if mat else pose\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_relative_eef_position","title":"<code>get_relative_eef_position(arm='default')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>arm</code> <code>str</code> <p>specific arm to grab relative eef pos. Default is \"default\" which corresponds to the first entry in self.arm_names</p> <code>'default'</code> <p>Returns:</p> Type Description <p>3-array: (x,y,z) Cartesian position of end-effector relative to robot base frame</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def get_relative_eef_position(self, arm=\"default\"):\n\"\"\"\n    Args:\n        arm (str): specific arm to grab relative eef pos.\n            Default is \"default\" which corresponds to the first entry in self.arm_names\n    Returns:\n        3-array: (x,y,z) Cartesian position of end-effector relative to robot base frame\n    \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nreturn self.get_relative_eef_pose(arm=arm)[0]\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.is_grasping","title":"<code>is_grasping(arm='default', candidate_obj=None)</code>","text":"<p>Returns True if the robot is grasping the target option @candidate_obj or any object if @candidate_obj is None.</p> <p>Parameters:</p> Name Type Description Default <code>arm</code> <code>str</code> <p>specific arm to check for grasping. Default is \"default\" which corresponds to the first entry in self.arm_names</p> <code>'default'</code> <code>candidate_obj</code> <code>EntityPrim or None</code> <p>object to check if this robot is currently grasping. If None, then will be a general (object-agnostic) check for grasping. Note: if self.grasping_mode is \"physical\", then @candidate_obj will be ignored completely</p> <code>None</code> <p>Returns:</p> Name Type Description <code>IsGraspingState</code> <p>For the specific manipulator appendage, returns IsGraspingState.TRUE if it is grasping (potentially @candidate_obj if specified), IsGraspingState.FALSE if it is not grasping, and IsGraspingState.UNKNOWN if unknown.</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def is_grasping(self, arm=\"default\", candidate_obj=None):\n\"\"\"\n    Returns True if the robot is grasping the target option @candidate_obj or any object if @candidate_obj is None.\n    Args:\n        arm (str): specific arm to check for grasping. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n        candidate_obj (EntityPrim or None): object to check if this robot is currently grasping. If None, then\n            will be a general (object-agnostic) check for grasping.\n            Note: if self.grasping_mode is \"physical\", then @candidate_obj will be ignored completely\n    Returns:\n        IsGraspingState: For the specific manipulator appendage, returns IsGraspingState.TRUE if it is grasping\n            (potentially @candidate_obj if specified), IsGraspingState.FALSE if it is not grasping,\n            and IsGraspingState.UNKNOWN if unknown.\n    \"\"\"\narm = self.default_arm if arm == \"default\" else arm\nif self.grasping_mode != \"physical\":\nis_grasping_obj = (\nself._ag_obj_in_hand[arm] is not None\nif candidate_obj is None\nelse self._ag_obj_in_hand[arm] == candidate_obj\n)\nis_grasping = (\nIsGraspingState.TRUE\nif is_grasping_obj and self._ag_release_counter[arm] is None\nelse IsGraspingState.FALSE\n)\nelse:\n# Infer from the gripper controller the state\nis_grasping = self._controllers[\"gripper_{}\".format(arm)].is_grasping()\n# If candidate obj is not None, we also check to see if our fingers are in contact with the object\nif is_grasping and candidate_obj is not None:\ngrasping_obj = False\nobj_links = {link.prim_path for link in candidate_obj.links.values()}\nfinger_links = {link.prim_path for link in self.finger_links[arm]}\nfor c in self.contact_list():\nc_set = {c.body0, c.body1}\n# Valid grasping of object if one of the set is a finger link and the other is the grasped object\nif len(c_set - finger_links) == 1 and len(c_set - obj_links) == 1:\ngrasping_obj = True\nbreak\n# Update is_grasping\nis_grasping = grasping_obj\nreturn is_grasping\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.release_grasp_immediately","title":"<code>release_grasp_immediately()</code>","text":"<p>Magic action to release this robot's grasp for all arms at once. As opposed to @_release_grasp, this method would byupass the release window mechanism and immediately release.</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def release_grasp_immediately(self):\n\"\"\"\n    Magic action to release this robot's grasp for all arms at once.\n    As opposed to @_release_grasp, this method would byupass the release window mechanism and immediately release.\n    \"\"\"\nfor arm in self.arm_names:\nif self._ag_obj_in_hand[arm] is not None:\nself._release_grasp(arm=arm)\n# TODO: Verify not needed!\n# for finger_link in self.finger_links[arm]:\n#     finger_link.remove_filtered_collision_pair(prim=self._ag_obj_in_hand[arm])\nself._ag_obj_in_hand[arm] = None\nself._ag_release_counter[arm] = None\n</code></pre>"},{"location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.can_assisted_grasp","title":"<code>can_assisted_grasp(obj)</code>","text":"<p>Check whether an object @obj can be grasped. This is done by checking its category to see if is in the allowlist.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object targeted for an assisted grasp</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether or not this object can be grasped</p> Source code in <code>omnigibson/robots/manipulation_robot.py</code> <pre><code>def can_assisted_grasp(obj):\n\"\"\"\n    Check whether an object @obj can be grasped. This is done\n    by checking its category to see if is in the allowlist.\n    Args:\n        obj (BaseObject): Object targeted for an assisted grasp\n    Returns:\n        bool: Whether or not this object can be grasped\n    \"\"\"\nif isinstance(obj, DatasetObject) and obj.category != \"object\":\n# Use manually defined allowlist\nreturn obj.category in m.ASSIST_GRASP_OBJ_CATEGORIES\nelse:\n# Use fallback based on mass\nmass = obj.mass\nprint(f\"Mass for AG: obj: {mass}, max mass: {m.ASSIST_GRASP_MASS_THRESHOLD}, obj: {obj.name}\")\nreturn mass &lt;= m.ASSIST_GRASP_MASS_THRESHOLD\n</code></pre>"},{"location":"reference/robots/robot_base.html","title":"robot_base","text":""},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot","title":"<code>BaseRobot</code>","text":"<p>         Bases: <code>USDObject</code>, <code>ControllableObject</code>, <code>GymObservable</code></p> <p>Base class for USD-based robot agents.</p> <p>This class handles object loading, and provides method interfaces that should be implemented by subclassed robots.</p> Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>class BaseRobot(USDObject, ControllableObject, GymObservable):\n\"\"\"\n    Base class for USD-based robot agents.\n    This class handles object loading, and provides method interfaces that should be\n    implemented by subclassed robots.\n    \"\"\"\ndef __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to this class\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Store inputs\nself._obs_modalities = obs_modalities if obs_modalities == \"all\" else \\\n            {obs_modalities} if isinstance(obs_modalities, str) else set(obs_modalities)              # this will get updated later when we fill in our sensors\nself._proprio_obs = self.default_proprio_obs if proprio_obs == \"default\" else list(proprio_obs)\n# Process abilities\nrobot_abilities = {\"robot\": {}}\nabilities = robot_abilities if abilities is None else robot_abilities.update(abilities)\n# Initialize internal attributes that will be loaded later\nself._sensors = None                     # e.g.: scan sensor, vision sensor\n# If specified, make sure scale is uniform -- this is because non-uniform scale can result in non-matching\n# collision representations for parts of the robot that were optimized (e.g.: bounding sphere for wheels)\nassert scale is None or isinstance(scale, int) or isinstance(scale, float) or np.all(scale == scale[0]), \\\n            f\"Robot scale must be uniform! Got: {scale}\"\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nusd_path=self.usd_path,\nname=name,\ncategory=m.ROBOT_CATEGORY,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=PrimType.RIGID,\ninclude_default_states=True,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\n**kwargs,\n)\ndef _post_load(self):\n# Run super post load first\nsuper()._post_load()\n# Search for any sensors this robot might have attached to any of its links\nself._sensors = dict()\nobs_modalities = set()\nfor link_name, link in self._links.items():\n# Search through all children prims and see if we find any sensor\nfor prim in link.prim.GetChildren():\nprim_type = prim.GetPrimTypeInfo().GetTypeName()\nif prim_type in SENSOR_PRIMS_TO_SENSOR_CLS:\n# Infer what obs modalities to use for this sensor\nsensor_cls = SENSOR_PRIMS_TO_SENSOR_CLS[prim_type]\nmodalities = sensor_cls.all_modalities if self._obs_modalities == \"all\" else \\\n                        sensor_cls.all_modalities.intersection(self._obs_modalities)\nobs_modalities = obs_modalities.union(modalities)\n# Create the sensor and store it internally\nsensor = create_sensor(\nsensor_type=prim_type,\nprim_path=str(prim.GetPrimPath()),\nname=f\"{self.name}:{link_name}_{prim_type}_sensor\",\nmodalities=modalities,\n)\nself._sensors[sensor.name] = sensor\n# Since proprioception isn't an actual sensor, we need to possibly manually add it here as well\nif self._obs_modalities == \"all\":\nobs_modalities.add(\"proprio\")\n# Update our overall obs modalities\nself._obs_modalities = obs_modalities\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Initialize all sensors\nfor sensor in self._sensors.values():\nsensor.initialize()\n# Load the observation space for this robot\nself.load_observation_space()\n# Validate this robot configuration\nself._validate_configuration()\ndef _validate_configuration(self):\n\"\"\"\n        Run any needed sanity checks to make sure this robot was created correctly.\n        \"\"\"\npass\ndef can_toggle(self, toggle_position, toggle_distance_threshold):\n\"\"\"\n        Returns True if the part of the robot that can toggle a toggleable is within the given range of a\n        point corresponding to a toggle marker\n        by default, we assume robot cannot toggle toggle markers\n        Args:\n            toggle_position (3-array): (x,y,z) cartesian position values as a reference point for evaluating\n                whether a toggle can occur\n            toggle_distance_threshold (float): distance value below which a toggle is allowed\n        Returns:\n            bool: True if the part of the robot that can toggle a toggleable is within the given range of a\n                point corresponding to a toggle marker. By default, we assume robot cannot toggle toggle markers\n        \"\"\"\nreturn False\ndef get_obs(self):\n\"\"\"\n        Grabs all observations from the robot. This is keyword-mapped based on each observation modality\n            (e.g.: proprio, rgb, etc.)\n        Returns:\n            dict: Keyword-mapped dictionary mapping observation modality names to\n                observations (usually np arrays)\n        \"\"\"\n# Our sensors already know what observation modalities it has, so we simply iterate over all of them\n# and grab their observations, processing them into a flat dict\nobs_dict = dict()\nfor sensor_name, sensor in self._sensors.items():\nsensor_obs = sensor.get_obs()\nfor obs_modality, obs in sensor_obs.items():\nobs_dict[f\"{sensor_name}_{obs_modality}\"] = obs\n# Have to handle proprio separately since it's not an actual sensor\nif \"proprio\" in self._obs_modalities:\nobs_dict[\"proprio\"] = self.get_proprioception()\nreturn obs_dict\ndef get_proprioception(self):\n\"\"\"\n        Returns:\n            n-array: numpy array of all robot-specific proprioceptive observations.\n        \"\"\"\nproprio_dict = self._get_proprioception_dict()\nreturn np.concatenate([proprio_dict[obs] for obs in self._proprio_obs])\ndef _get_proprioception_dict(self):\n\"\"\"\n        Returns:\n            dict: keyword-mapped proprioception observations available for this robot.\n                Can be extended by subclasses\n        \"\"\"\njoint_positions = self.get_joint_positions(normalized=False)\njoint_velocities = self.get_joint_velocities(normalized=False)\njoint_efforts = self.get_joint_efforts(normalized=False)\npos, ori = self.get_position(), self.get_rpy()\nreturn dict(\njoint_qpos=joint_positions,\njoint_qpos_sin=np.sin(joint_positions),\njoint_qpos_cos=np.cos(joint_positions),\njoint_qvel=joint_velocities,\njoint_qeffort=joint_efforts,\nrobot_pos=pos,\nrobot_ori_cos=np.cos(ori),\nrobot_ori_sin=np.sin(ori),\nrobot_lin_vel=self.get_linear_velocity(),\nrobot_ang_vel=self.get_angular_velocity(),\n)\ndef _load_observation_space(self):\n# We compile observation spaces from our sensors\nobs_space = dict()\nfor sensor_name, sensor in self._sensors.items():\n# Load the sensor observation space\nsensor_obs_space = sensor.load_observation_space()\nfor obs_modality, obs_modality_space in sensor_obs_space.items():\nobs_space[f\"{sensor_name}_{obs_modality}\"] = obs_modality_space\n# Have to handle proprio separately since it's not an actual sensor\nif \"proprio\" in self._obs_modalities:\nobs_space[\"proprio\"] = self._build_obs_box_space(shape=(self.proprioception_dim,), low=-np.inf, high=np.inf)\nreturn obs_space\ndef add_obs_modality(self, modality):\n\"\"\"\n        Adds observation modality @modality to this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES\n        Args:\n            modality (str): Observation modality to add to this robot\n        \"\"\"\n# Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n# then we add it\nfor sensor in self._sensors.values():\nif modality in sensor.all_modalities:\nsensor.add_modality(modality=modality)\ndef remove_obs_modality(self, modality):\n\"\"\"\n        Remove observation modality @modality from this robot. Note: Should be one of\n        omnigibson.sensors.ALL_SENSOR_MODALITIES\n        Args:\n            modality (str): Observation modality to remove from this robot\n        \"\"\"\n# Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n# then we remove it\nfor sensor in self._sensors.values():\nif modality in sensor.all_modalities:\nsensor.remove_modality(modality=modality)\ndef visualize_sensors(self):\n\"\"\"\n        Renders this robot's key sensors, visualizing them via matplotlib plots\n        \"\"\"\nframes = dict()\nremaining_obs_modalities = deepcopy(self.obs_modalities)\nfor sensor in self.sensors.values():\nobs = sensor.get_obs()\nsensor_frames = []\nif isinstance(sensor, VisionSensor):\n# We check for rgb, depth, normal, seg_instance\nfor modality in [\"rgb\", \"depth\", \"normal\", \"seg_instance\"]:\nif modality in sensor.modalities:\nob = obs[modality]\nif modality == \"rgb\":\n# Ignore alpha channel, map to floats\nob = ob[:, :, :3] / 255.0\nelif modality == \"seg_instance\":\n# Map IDs to rgb\nob = segmentation_to_rgb(ob, N=256) / 255.0\nelif modality == \"normal\":\n# Re-map to 0 - 1 range\nob = (ob + 1.0) / 2.0\nelse:\n# Depth, nothing to do here\npass\n# Add this observation to our frames and remove the modality\nsensor_frames.append((modality, ob))\nremaining_obs_modalities -= {modality}\nelse:\n# Warn user that we didn't find this modality\nprint(f\"Modality {modality} is not active in sensor {sensor.name}, skipping...\")\nelif isinstance(sensor, ScanSensor):\n# We check for occupancy_grid\noccupancy_grid = obs.get(\"occupancy_grid\", None)\nif occupancy_grid is not None:\nsensor_frames.append((\"occupancy_grid\", occupancy_grid))\nremaining_obs_modalities -= {\"occupancy_grid\"}\n# Map the sensor name to the frames for that sensor\nframes[sensor.name] = sensor_frames\n# Warn user that any remaining modalities are not able to be visualized\nif len(remaining_obs_modalities) &gt; 0:\nprint(f\"Modalities: {remaining_obs_modalities} cannot be visualized, skipping...\")\n# Write all the frames to a plot\nfor sensor_name, sensor_frames in frames.items():\nn_sensor_frames = len(sensor_frames)\nif n_sensor_frames &gt; 0:\nfig, axes = plt.subplots(nrows=1, ncols=n_sensor_frames)\nif n_sensor_frames == 1:\naxes = [axes]\n# Dump frames and set each subtitle\nfor i, (modality, frame) in enumerate(sensor_frames):\naxes[i].imshow(frame)\naxes[i].set_title(modality)\naxes[i].set_axis_off()\n# Set title\nfig.suptitle(sensor_name)\nplt.show(block=False)\n# One final plot show so all the figures get rendered\nplt.show()\ndef remove(self):\n# Remove all sensors\nfor sensor in self._sensors.values():\nsensor.remove()\n# Run super\nsuper().remove()\n@property\ndef sensors(self):\n\"\"\"\n        Returns:\n            dict: Keyword-mapped dictionary mapping sensor names to BaseSensor instances owned by this robot\n        \"\"\"\nreturn self._sensors\n@property\ndef obs_modalities(self):\n\"\"\"\n        Returns:\n            set of str: Observation modalities used for this robot (e.g.: proprio, rgb, etc.)\n        \"\"\"\nassert self._loaded, \"Cannot check observation modalities until we load this robot!\"\nreturn self._obs_modalities\n@property\ndef proprioception_dim(self):\n\"\"\"\n        Returns:\n            int: Size of self.get_proprioception() vector\n        \"\"\"\nreturn len(self.get_proprioception())\n@property\ndef default_proprio_obs(self):\n\"\"\"\n        Returns:\n            list of str: Default proprioception observations to use\n        \"\"\"\nreturn []\n@property\ndef model_name(self):\n\"\"\"\n        Returns:\n            str: name of this robot model. usually corresponds to the class name of a given robot model\n        \"\"\"\nreturn self.__class__.__name__\n@property\n@abstractmethod\ndef usd_path(self):\n# For all robots, this must be specified a priori, before we actually initialize the USDObject constructor!\n# So we override the parent implementation, and make this an abstract method\nraise NotImplementedError\n@property\ndef urdf_path(self):\n\"\"\"\n        Returns:\n            str: file path to the robot urdf file.\n        \"\"\"\nraise NotImplementedError\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseRobot\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global robot registry -- override super registry\nglobal REGISTERED_ROBOTS\nreturn REGISTERED_ROBOTS\n</code></pre>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.default_proprio_obs","title":"<code>default_proprio_obs</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>list of str: Default proprioception observations to use</p>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.model_name","title":"<code>model_name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>name of this robot model. usually corresponds to the class name of a given robot model</p>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.obs_modalities","title":"<code>obs_modalities</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>set of str: Observation modalities used for this robot (e.g.: proprio, rgb, etc.)</p>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.proprioception_dim","title":"<code>proprioception_dim</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Size of self.get_proprioception() vector</p>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.sensors","title":"<code>sensors</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped dictionary mapping sensor names to BaseSensor instances owned by this robot</p>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.urdf_path","title":"<code>urdf_path</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>file path to the robot urdf file.</p>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.__init__","title":"<code>__init__(name, prim_path=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, load_config=None, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>fixed_base</code> <code>bool</code> <p>whether to fix the base of this object or not</p> <code>False</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>control_freq</code> <code>float</code> <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p> <code>None</code> <code>controller_config</code> <code>None or dict</code> <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p> <code>None</code> <code>action_type</code> <code>str</code> <p>one of {discrete, continuous} - what type of action space to use</p> <code>'continuous'</code> <code>action_normalize</code> <code>bool</code> <p>whether to normalize inputted actions. This will override any default values specified by this class.</p> <code>True</code> <code>reset_joint_pos</code> <code>None or n-array</code> <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p> <code>None</code> <code>obs_modalities</code> <code>str or list of str</code> <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p> <code>'all'</code> <code>proprio_obs</code> <code>str or list of str</code> <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p> <code>'default'</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>def __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nfixed_base=False,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to this class\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Store inputs\nself._obs_modalities = obs_modalities if obs_modalities == \"all\" else \\\n        {obs_modalities} if isinstance(obs_modalities, str) else set(obs_modalities)              # this will get updated later when we fill in our sensors\nself._proprio_obs = self.default_proprio_obs if proprio_obs == \"default\" else list(proprio_obs)\n# Process abilities\nrobot_abilities = {\"robot\": {}}\nabilities = robot_abilities if abilities is None else robot_abilities.update(abilities)\n# Initialize internal attributes that will be loaded later\nself._sensors = None                     # e.g.: scan sensor, vision sensor\n# If specified, make sure scale is uniform -- this is because non-uniform scale can result in non-matching\n# collision representations for parts of the robot that were optimized (e.g.: bounding sphere for wheels)\nassert scale is None or isinstance(scale, int) or isinstance(scale, float) or np.all(scale == scale[0]), \\\n        f\"Robot scale must be uniform! Got: {scale}\"\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nusd_path=self.usd_path,\nname=name,\ncategory=m.ROBOT_CATEGORY,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=fixed_base,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nprim_type=PrimType.RIGID,\ninclude_default_states=True,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.add_obs_modality","title":"<code>add_obs_modality(modality)</code>","text":"<p>Adds observation modality @modality to this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES</p> <p>Parameters:</p> Name Type Description Default <code>modality</code> <code>str</code> <p>Observation modality to add to this robot</p> required Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>def add_obs_modality(self, modality):\n\"\"\"\n    Adds observation modality @modality to this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES\n    Args:\n        modality (str): Observation modality to add to this robot\n    \"\"\"\n# Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n# then we add it\nfor sensor in self._sensors.values():\nif modality in sensor.all_modalities:\nsensor.add_modality(modality=modality)\n</code></pre>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.can_toggle","title":"<code>can_toggle(toggle_position, toggle_distance_threshold)</code>","text":"<p>Returns True if the part of the robot that can toggle a toggleable is within the given range of a point corresponding to a toggle marker by default, we assume robot cannot toggle toggle markers</p> <p>Parameters:</p> Name Type Description Default <code>toggle_position</code> <code>3-array</code> <p>(x,y,z) cartesian position values as a reference point for evaluating whether a toggle can occur</p> required <code>toggle_distance_threshold</code> <code>float</code> <p>distance value below which a toggle is allowed</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the part of the robot that can toggle a toggleable is within the given range of a point corresponding to a toggle marker. By default, we assume robot cannot toggle toggle markers</p> Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>def can_toggle(self, toggle_position, toggle_distance_threshold):\n\"\"\"\n    Returns True if the part of the robot that can toggle a toggleable is within the given range of a\n    point corresponding to a toggle marker\n    by default, we assume robot cannot toggle toggle markers\n    Args:\n        toggle_position (3-array): (x,y,z) cartesian position values as a reference point for evaluating\n            whether a toggle can occur\n        toggle_distance_threshold (float): distance value below which a toggle is allowed\n    Returns:\n        bool: True if the part of the robot that can toggle a toggleable is within the given range of a\n            point corresponding to a toggle marker. By default, we assume robot cannot toggle toggle markers\n    \"\"\"\nreturn False\n</code></pre>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.get_obs","title":"<code>get_obs()</code>","text":"<p>Grabs all observations from the robot. This is keyword-mapped based on each observation modality     (e.g.: proprio, rgb, etc.)</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped dictionary mapping observation modality names to observations (usually np arrays)</p> Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>def get_obs(self):\n\"\"\"\n    Grabs all observations from the robot. This is keyword-mapped based on each observation modality\n        (e.g.: proprio, rgb, etc.)\n    Returns:\n        dict: Keyword-mapped dictionary mapping observation modality names to\n            observations (usually np arrays)\n    \"\"\"\n# Our sensors already know what observation modalities it has, so we simply iterate over all of them\n# and grab their observations, processing them into a flat dict\nobs_dict = dict()\nfor sensor_name, sensor in self._sensors.items():\nsensor_obs = sensor.get_obs()\nfor obs_modality, obs in sensor_obs.items():\nobs_dict[f\"{sensor_name}_{obs_modality}\"] = obs\n# Have to handle proprio separately since it's not an actual sensor\nif \"proprio\" in self._obs_modalities:\nobs_dict[\"proprio\"] = self.get_proprioception()\nreturn obs_dict\n</code></pre>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.get_proprioception","title":"<code>get_proprioception()</code>","text":"<p>Returns:</p> Type Description <p>n-array: numpy array of all robot-specific proprioceptive observations.</p> Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>def get_proprioception(self):\n\"\"\"\n    Returns:\n        n-array: numpy array of all robot-specific proprioceptive observations.\n    \"\"\"\nproprio_dict = self._get_proprioception_dict()\nreturn np.concatenate([proprio_dict[obs] for obs in self._proprio_obs])\n</code></pre>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.remove_obs_modality","title":"<code>remove_obs_modality(modality)</code>","text":"<p>Remove observation modality @modality from this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES</p> <p>Parameters:</p> Name Type Description Default <code>modality</code> <code>str</code> <p>Observation modality to remove from this robot</p> required Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>def remove_obs_modality(self, modality):\n\"\"\"\n    Remove observation modality @modality from this robot. Note: Should be one of\n    omnigibson.sensors.ALL_SENSOR_MODALITIES\n    Args:\n        modality (str): Observation modality to remove from this robot\n    \"\"\"\n# Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n# then we remove it\nfor sensor in self._sensors.values():\nif modality in sensor.all_modalities:\nsensor.remove_modality(modality=modality)\n</code></pre>"},{"location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.visualize_sensors","title":"<code>visualize_sensors()</code>","text":"<p>Renders this robot's key sensors, visualizing them via matplotlib plots</p> Source code in <code>omnigibson/robots/robot_base.py</code> <pre><code>def visualize_sensors(self):\n\"\"\"\n    Renders this robot's key sensors, visualizing them via matplotlib plots\n    \"\"\"\nframes = dict()\nremaining_obs_modalities = deepcopy(self.obs_modalities)\nfor sensor in self.sensors.values():\nobs = sensor.get_obs()\nsensor_frames = []\nif isinstance(sensor, VisionSensor):\n# We check for rgb, depth, normal, seg_instance\nfor modality in [\"rgb\", \"depth\", \"normal\", \"seg_instance\"]:\nif modality in sensor.modalities:\nob = obs[modality]\nif modality == \"rgb\":\n# Ignore alpha channel, map to floats\nob = ob[:, :, :3] / 255.0\nelif modality == \"seg_instance\":\n# Map IDs to rgb\nob = segmentation_to_rgb(ob, N=256) / 255.0\nelif modality == \"normal\":\n# Re-map to 0 - 1 range\nob = (ob + 1.0) / 2.0\nelse:\n# Depth, nothing to do here\npass\n# Add this observation to our frames and remove the modality\nsensor_frames.append((modality, ob))\nremaining_obs_modalities -= {modality}\nelse:\n# Warn user that we didn't find this modality\nprint(f\"Modality {modality} is not active in sensor {sensor.name}, skipping...\")\nelif isinstance(sensor, ScanSensor):\n# We check for occupancy_grid\noccupancy_grid = obs.get(\"occupancy_grid\", None)\nif occupancy_grid is not None:\nsensor_frames.append((\"occupancy_grid\", occupancy_grid))\nremaining_obs_modalities -= {\"occupancy_grid\"}\n# Map the sensor name to the frames for that sensor\nframes[sensor.name] = sensor_frames\n# Warn user that any remaining modalities are not able to be visualized\nif len(remaining_obs_modalities) &gt; 0:\nprint(f\"Modalities: {remaining_obs_modalities} cannot be visualized, skipping...\")\n# Write all the frames to a plot\nfor sensor_name, sensor_frames in frames.items():\nn_sensor_frames = len(sensor_frames)\nif n_sensor_frames &gt; 0:\nfig, axes = plt.subplots(nrows=1, ncols=n_sensor_frames)\nif n_sensor_frames == 1:\naxes = [axes]\n# Dump frames and set each subtitle\nfor i, (modality, frame) in enumerate(sensor_frames):\naxes[i].imshow(frame)\naxes[i].set_title(modality)\naxes[i].set_axis_off()\n# Set title\nfig.suptitle(sensor_name)\nplt.show(block=False)\n# One final plot show so all the figures get rendered\nplt.show()\n</code></pre>"},{"location":"reference/robots/tiago.html","title":"tiago","text":""},{"location":"reference/robots/tiago.html#robots.tiago.Tiago","title":"<code>Tiago</code>","text":"<p>         Bases: <code>ManipulationRobot</code>, <code>LocomotionRobot</code>, <code>ActiveCameraRobot</code></p> <p>Tiago Robot Reference: https://pal-robotics.com/robots/tiago/</p> <p>NOTE: If using IK Control for both the right and left arms, note that the left arm dictates control of the trunk, and the right arm passively must follow. That is, sending desired delta position commands to the right end effector will be computed independently from any trunk motion occurring during that timestep.</p> Source code in <code>omnigibson/robots/tiago.py</code> <pre><code>class Tiago(ManipulationRobot, LocomotionRobot, ActiveCameraRobot):\n\"\"\"\n    Tiago Robot\n    Reference: https://pal-robotics.com/robots/tiago/\n    NOTE: If using IK Control for both the right and left arms, note that the left arm dictates control of the trunk,\n    and the right arm passively must follow. That is, sending desired delta position commands to the right end effector\n    will be computed independently from any trunk motion occurring during that timestep.\n    \"\"\"\ndef __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to BaseRobot\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n# Unique to ManipulationRobot\ngrasping_mode=\"physical\",\n# Unique to Tiago\nrigid_trunk=False,\ndefault_trunk_offset=0.365,\ndefault_arm_pose=\"vertical\",\n**kwargs,\n):\n\"\"\"\n        Args:\n            name (str): Name for the object. Names need to be unique per scene\n            prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n                created at /World/&lt;name&gt;\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n                If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n                If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n                If \"sticky\", will magnetize any object touching the gripper's fingers.\n            rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n            default_trunk_offset (float): sets the default height of the robot's trunk\n            default_arm_pose (str): Default pose for the robot arm. Should be one of:\n                {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n# Store args\nself.rigid_trunk = rigid_trunk\nself.default_trunk_offset = default_trunk_offset\nassert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\nself.default_arm_pose = default_arm_pose\n# Other args that will be created at runtime\nself._world_base_fixed_joint_prim = None\n# Parse reset joint pos if specifying special string\nif isinstance(reset_joint_pos, str):\nassert (\nreset_joint_pos in RESET_JOINT_OPTIONS\n), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\nreset_joint_pos = (\nself.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n)\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=True,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\nobs_modalities=obs_modalities,\nproprio_obs=proprio_obs,\ngrasping_mode=grasping_mode,\n**kwargs,\n)\n@property\ndef arm_joint_names(self):\nnames = dict()\nfor arm in self.arm_names:\nnames[arm] = [\"torso_lift_joint\"] + [\nf\"arm_{arm}_{i}_joint\" for i in range(1, 8)\n]\nreturn names\n@property\ndef model_name(self):\nreturn \"Tiago\"\n@property\ndef n_arms(self):\nreturn 2\n@property\ndef arm_names(self):\nreturn [\"left\", \"right\"]\n@property\ndef tucked_default_joint_pos(self):\npos = np.zeros(self.n_dof)\n# Keep the current joint positions for the base joints\npos[self.base_idx] = self.get_joint_positions()[self.base_idx]\npos[self.trunk_control_idx] = 0\npos[self.camera_control_idx] = np.array([0.0, 0.0])\nfor arm in self.arm_names:\npos[self.gripper_control_idx[arm]] = np.array([0.045, 0.045])  # open gripper\npos[self.arm_control_idx[arm]] = np.array(\n[-1.10, 1.47, 2.71, 1.71, -1.57, 1.39, 0]\n)\nreturn pos\n@property\ndef untucked_default_joint_pos(self):\npos = np.zeros(self.n_dof)\n# Keep the current joint positions for the base joints\npos[self.base_idx] = self.get_joint_positions()[self.base_idx]\npos[self.trunk_control_idx] = 0.02 + self.default_trunk_offset\npos[self.camera_control_idx] = np.array([0.0, 0.45])\npos[self.gripper_control_idx[self.default_arm]] = np.array([0.045, 0.045])  # open gripper\n# Choose arm based on setting\nif self.default_arm_pose == \"vertical\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n)\nelif self.default_arm_pose == \"diagonal15\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n)\nelif self.default_arm_pose == \"diagonal30\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n)\nelif self.default_arm_pose == \"diagonal45\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n)\nelif self.default_arm_pose == \"horizontal\":\npos[self.arm_control_idx[self.default_arm]] = np.array(\n[0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n)\nelse:\nraise ValueError(\"Unknown default arm pose: {}\".format(self.default_arm_pose))\nreturn pos\ndef _create_discrete_action_space(self):\n# Tiago does not support discrete actions\nraise ValueError(\"Fetch does not support discrete actions!\")\n@property\ndef discrete_action_list(self):\n# Not supported for this robot\nraise NotImplementedError()\ndef tuck(self):\n\"\"\"\n        Immediately set this robot's configuration to be in tucked mode\n        \"\"\"\nself.set_joint_positions(self.tucked_default_joint_pos)\ndef untuck(self):\n\"\"\"\n        Immediately set this robot's configuration to be in untucked mode\n        \"\"\"\nself.set_joint_positions(self.untucked_default_joint_pos)\ndef reset(self):\n\"\"\"\n        Reset should not change the robot base pose.\n        We need to cache and restore the base joints to the world.\n        \"\"\"\nbase_joint_positions = self.get_joint_positions()[self.base_idx]\nsuper().reset()\nself.set_joint_positions(base_joint_positions, indices=self.base_idx)\ndef _post_load(self):\nsuper()._post_load()\n# The eef gripper links should be visual-only. They only contain a \"ghost\" box volume for detecting objects\n# inside the gripper, in order to activate attachments (AG for Cloths).\nfor arm in self.arm_names:\nself.eef_links[arm].visual_only = True\nself.eef_links[arm].visible = False\nself._world_base_fixed_joint_prim = get_prim_at_path(f\"{self._prim_path}/rootJoint\")\nposition, orientation = self.get_position_orientation()\n# Set the world-to-base fixed joint to be at the robot's current pose\nself._world_base_fixed_joint_prim.GetAttribute(\"physics:localPos0\").Set(tuple(position))\nself._world_base_fixed_joint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*orientation[[3, 0, 1, 2]]))\ndef _initialize(self):\n# Run super method first\nsuper()._initialize()\n# Set the joint friction for EEF to be higher\nfor arm in self.arm_names:\nfor joint in self.finger_joints[arm]:\nif joint.joint_type != JointType.JOINT_FIXED:\njoint.friction = 500\n# Name of the actual root link that we are interested in. Note that this is different from self.root_link_name,\n# which is \"base_footprint_x\", corresponding to the first of the 6 1DoF joints to control the base.\n@property\ndef base_footprint_link_name(self):\nreturn \"base_footprint\"\n@property\ndef base_footprint_link(self):\n\"\"\"\n        Returns:\n            RigidPrim: base footprint link of this object prim\n        \"\"\"\nreturn self._links[self.base_footprint_link_name]\ndef _actions_to_control(self, action):\n# Run super method first\nu_vec, u_type_vec = super()._actions_to_control(action=action)\n# Change the control from base_footprint_link (\"base_footprint\") frame to root_link (\"base_footprint_x\") frame\nbase_orn = self.base_footprint_link.get_orientation()\nroot_link_orn = self.root_link.get_orientation()\ncur_orn = T.mat2quat(T.quat2mat(root_link_orn).T  @ T.quat2mat(base_orn))\n# Rotate the linear and angular velocity to the desired frame\nlin_vel_global, _ = T.pose_transform([0, 0, 0], cur_orn, u_vec[self.base_idx[:3]], [0, 0, 0, 1])\nang_vel_global, _ = T.pose_transform([0, 0, 0], cur_orn, u_vec[self.base_idx[3:]], [0, 0, 0, 1])\nu_vec[self.base_control_idx] = np.array([lin_vel_global[0], lin_vel_global[1], ang_vel_global[2]])\nreturn u_vec, u_type_vec\ndef _get_proprioception_dict(self):\ndic = super()._get_proprioception_dict()\n# Add trunk info\njoint_positions = self.get_joint_positions(normalized=False)\njoint_velocities = self.get_joint_velocities(normalized=False)\ndic[\"trunk_qpos\"] = joint_positions[self.trunk_control_idx]\ndic[\"trunk_qvel\"] = joint_velocities[self.trunk_control_idx]\nreturn dic\n@property\ndef control_limits(self):\n# Overwrite the control limits with the maximum linear and angular velocities for the purpose of clip_control\n# Note that when clip_control happens, the control is still in the base_footprint_link (\"base_footprint\") frame\n# Omniverse still thinks these joints have no limits because when the control is transformed to the root_link\n# (\"base_footprint_x\") frame, it can go above this limit.\nlimits = super().control_limits\nlimits[\"velocity\"][0][self.base_idx[:3]] = -m.MAX_LINEAR_VELOCITY\nlimits[\"velocity\"][1][self.base_idx[:3]] = m.MAX_LINEAR_VELOCITY\nlimits[\"velocity\"][0][self.base_idx[3:]] = -m.MAX_ANGULAR_VELOCITY\nlimits[\"velocity\"][1][self.base_idx[3:]] = m.MAX_ANGULAR_VELOCITY\nreturn limits\ndef get_control_dict(self):\n# Modify the right hand's pos_relative in the z-direction based on the trunk's value\n# We do this so we decouple the trunk's dynamic value from influencing the IK controller solution for the right\n# hand, which does not control the trunk\ndic = super().get_control_dict()\ndic[\"eef_right_pos_relative\"][2] = dic[\"eef_right_pos_relative\"][2] - self.get_joint_positions()[self.trunk_control_idx]\nreturn dic\n@property\ndef default_proprio_obs(self):\nobs_keys = super().default_proprio_obs\nreturn obs_keys + [\"trunk_qpos\"]\n@property\ndef controller_order(self):\ncontrollers = [\"base\", \"camera\"]\nfor arm in self.arm_names:\ncontrollers += [\"arm_{}\".format(arm), \"gripper_{}\".format(arm)]\nreturn controllers\n@property\ndef _default_controllers(self):\n# Always call super first\ncontrollers = super()._default_controllers\n# We use multi finger gripper, differential drive, and IK controllers as default\ncontrollers[\"base\"] = \"JointController\"\ncontrollers[\"camera\"] = \"JointController\"\nfor arm in self.arm_names:\ncontrollers[\"arm_{}\".format(arm)] = \"InverseKinematicsController\"\ncontrollers[\"gripper_{}\".format(arm)] = \"MultiFingerGripperController\"\nreturn controllers\n@property\ndef _default_base_controller_configs(self):\ndic = {\n\"name\": \"JointController\",\n\"control_freq\": self._control_freq,\n\"control_limits\": self.control_limits,\n\"use_delta_commands\": False,\n\"motor_type\": \"velocity\",\n\"compute_delta_in_quat_space\": [(3, 4, 5)],\n\"dof_idx\": self.base_control_idx,\n}\nreturn dic\n@property\ndef _default_controller_config(self):\n# Grab defaults from super method first\ncfg = super()._default_controller_config\n# Get default base controller for omnidirectional Tiago\ncfg[\"base\"] = {\"JointController\": self._default_base_controller_configs}\nfor arm in self.arm_names:\nfor arm_cfg in cfg[\"arm_{}\".format(arm)].values():\nif arm == \"left\":\n# Need to override joint idx being controlled to include trunk in default arm controller configs\narm_cfg[\"dof_idx\"] = np.concatenate([self.trunk_control_idx, self.arm_control_idx[arm]])\n# If using rigid trunk, we also clamp its limits\n# TODO: How to handle for right arm which has a fixed trunk internally even though the trunk is moving\n# via the left arm??\nif self.rigid_trunk:\narm_cfg[\"control_limits\"][\"position\"][0][self.trunk_control_idx] = \\\n                        self.untucked_default_joint_pos[self.trunk_control_idx]\narm_cfg[\"control_limits\"][\"position\"][1][self.trunk_control_idx] = \\\n                        self.untucked_default_joint_pos[self.trunk_control_idx]\nreturn cfg\n@property\ndef default_joint_pos(self):\nreturn self.tucked_default_joint_pos\n@property\ndef assisted_grasp_start_points(self):\nreturn {\narm: [\nGraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[0.04, -0.012, 0.014]),\nGraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[0.04, -0.012, -0.014]),\nGraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[-0.04, -0.012, 0.014]),\nGraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[-0.04, -0.012, -0.014]),\n]\nfor arm in self.arm_names\n}\n@property\ndef assisted_grasp_end_points(self):\nreturn {\narm: [\nGraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[0.04, 0.012, 0.014]),\nGraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[0.04, 0.012, -0.014]),\nGraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[-0.04, 0.012, 0.014]),\nGraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[-0.04, 0.012, -0.014]),\n]\nfor arm in self.arm_names\n}\n@property\ndef base_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to the three controllable 1DoF base joints\n        \"\"\"\njoints = list(self.joints.keys())\nreturn np.array(\n[\njoints.index(f\"base_footprint_{component}_joint\")\nfor component in [\"x\", \"y\", \"rz\"]\n]\n)\n@property\ndef base_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to the six 1DoF base joints\n        \"\"\"\njoints = list(self.joints.keys())\nreturn np.array(\n[\njoints.index(f\"base_footprint_{component}_joint\")\nfor component in [\"x\", \"y\", \"z\", \"rx\", \"ry\", \"rz\"]\n]\n)\n@property\ndef trunk_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to trunk joint.\n        \"\"\"\nreturn np.array([6])\n@property\ndef camera_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.\n        \"\"\"\nreturn np.array([9, 12])\n@property\ndef arm_control_idx(self):\nreturn {\"left\": np.array([7, 10, 13, 15, 17, 19, 21]), \"right\": np.array([8, 11, 14, 16, 18, 20, 22])}\n@property\ndef gripper_control_idx(self):\nreturn {\"left\": np.array([23, 24]), \"right\": np.array([25, 26])}\n@property\ndef finger_lengths(self):\nreturn {arm: 0.12 for arm in self.arm_names}\n@property\ndef disabled_collision_pairs(self):\nreturn []\n@property\ndef arm_link_names(self):\nreturn {arm: [f\"arm_{arm}_{i}_link\" for i in range(1, 8)] for arm in self.arm_names}\n@property\ndef eef_link_names(self):\nreturn {arm: \"gripper_{}_grasping_frame\".format(arm) for arm in self.arm_names}\n@property\ndef finger_link_names(self):\nreturn {arm: [\"gripper_{}_right_finger_link\".format(arm), \"gripper_{}_left_finger_link\".format(arm)] for arm in\nself.arm_names}\n@property\ndef finger_joint_names(self):\nreturn {arm: [\"gripper_{}_right_finger_joint\".format(arm), \"gripper_{}_left_finger_joint\".format(arm)] for arm\nin self.arm_names}\n@property\ndef usd_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/tiago/tiago_dual_omnidirectional_stanford/tiago_dual_omnidirectional_stanford_33.usd\")\n@property\ndef robot_arm_descriptor_yamls(self):\nreturn {\"left\": os.path.join(gm.ASSET_PATH, \"models/tiago/tiago_dual_omnidirectional_stanford_left_arm_descriptor.yaml\"),\n\"right\": os.path.join(gm.ASSET_PATH, \"models/tiago/tiago_dual_omnidirectional_stanford_right_arm_fixed_trunk_descriptor.yaml\")}\n@property\ndef urdf_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/tiago/tiago_dual_omnidirectional_stanford.urdf\")\ndef get_position_orientation(self):\n# If the simulator is playing, return the pose of the base_footprint link frame\nif self._dc is not None and self._dc.is_simulating():\nreturn self.base_footprint_link.get_position_orientation()\n# Else, return the pose of the robot frame\nelse:\nreturn super().get_position_orientation()\ndef set_position_orientation(self, position=None, orientation=None):\ncurrent_position, current_orientation = self.get_position_orientation()\nif position is None:\nposition = current_position\nif orientation is None:\norientation = current_orientation\n# If the simulator is playing, set the 6 base joints to achieve the desired pose of base_footprint link frame\nif self._dc is not None and self._dc.is_simulating():\n# Find the relative transformation from base_footprint_link (\"base_footprint\") frame to root_link\n# (\"base_footprint_x\") frame. Assign it to the 6 1DoF joints that control the base.\n# Note that the 6 1DoF joints are originated from the root_link (\"base_footprint_x\") frame.\njoint_pos, joint_orn = self.root_link.get_position_orientation()\ninv_joint_pos, inv_joint_orn = T.mat2pose(T.pose_inv(T.pose2mat((joint_pos, joint_orn))))\nrelative_pos, relative_orn = T.pose_transform(inv_joint_pos, inv_joint_orn, position, orientation)\nrelative_rpy = T.quat2euler(relative_orn)\nself.joints[\"base_footprint_x_joint\"].set_pos(relative_pos[0], drive=False)\nself.joints[\"base_footprint_y_joint\"].set_pos(relative_pos[1], drive=False)\nself.joints[\"base_footprint_z_joint\"].set_pos(relative_pos[2], drive=False)\nself.joints[\"base_footprint_rx_joint\"].set_pos(relative_rpy[0], drive=False)\nself.joints[\"base_footprint_ry_joint\"].set_pos(relative_rpy[1], drive=False)\nself.joints[\"base_footprint_rz_joint\"].set_pos(relative_rpy[2], drive=False)\n# Else, set the pose of the robot frame, and then move the joint frame of the world_base_joint to match it\nelse:\n# Call the super() method to move the robot frame first\nsuper().set_position_orientation(position, orientation)\n# Move the joint frame for the world_base_joint\nif self._world_base_fixed_joint_prim is not None:\nself._world_base_fixed_joint_prim.GetAttribute(\"physics:localPos0\").Set(tuple(position))\nself._world_base_fixed_joint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*orientation[[3, 0, 1, 2]]))\ndef set_linear_velocity(self, velocity: np.ndarray):\n# Transform the desired linear velocity from the world frame to the root_link (\"base_footprint_x\") frame\n# Note that this will also set the target to be the desired linear velocity (i.e. the robot will try to maintain\n# such velocity), which is different from the default behavior of set_linear_velocity for all other objects.\norn = self.root_link.get_orientation()\nvelocity_in_root_link = T.quat2mat(orn).T @ velocity\nself.joints[\"base_footprint_x_joint\"].set_vel(velocity_in_root_link[0], drive=False)\nself.joints[\"base_footprint_y_joint\"].set_vel(velocity_in_root_link[1], drive=False)\nself.joints[\"base_footprint_z_joint\"].set_vel(velocity_in_root_link[2], drive=False)\ndef get_linear_velocity(self) -&gt; np.ndarray:\n# Note that the link we are interested in is self.base_footprint_link, not self.root_link\nreturn self.base_footprint_link.get_linear_velocity()\ndef set_angular_velocity(self, velocity: np.ndarray) -&gt; None:\n# See comments of self.set_linear_velocity\norn = self.root_link.get_orientation()\nvelocity_in_root_link = T.quat2mat(orn).T @ velocity\nself.joints[\"base_footprint_rx_joint\"].set_vel(velocity_in_root_link[0], drive=False)\nself.joints[\"base_footprint_ry_joint\"].set_vel(velocity_in_root_link[1], drive=False)\nself.joints[\"base_footprint_rz_joint\"].set_vel(velocity_in_root_link[2], drive=False)\ndef get_angular_velocity(self) -&gt; np.ndarray:\n# Note that the link we are interested in is self.base_footprint_link, not self.root_link\nreturn self.base_footprint_link.get_angular_velocity()\n</code></pre>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.base_control_idx","title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to the three controllable 1DoF base joints</p>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.base_footprint_link","title":"<code>base_footprint_link</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>RigidPrim</code> <p>base footprint link of this object prim</p>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.base_idx","title":"<code>base_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to the six 1DoF base joints</p>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.camera_control_idx","title":"<code>camera_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.</p>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.trunk_control_idx","title":"<code>trunk_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to trunk joint.</p>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.__init__","title":"<code>__init__(name, prim_path=None, class_id=None, uuid=None, scale=None, visible=True, visual_only=False, self_collisions=False, load_config=None, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', grasping_mode='physical', rigid_trunk=False, default_trunk_offset=0.365, default_arm_pose='vertical', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene</p> required <code>prim_path</code> <code>None or str</code> <p>global path in the stage to this object. If not specified, will automatically be created at /World/ <code>None</code> <code>category</code> <code>str</code> <p>Category for the object. Defaults to \"object\".</p> required <code>class_id</code> <code>None or int</code> <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p> <code>None</code> <code>uuid</code> <code>None or int</code> <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p> <code>None</code> <code>scale</code> <code>None or float or 3-array</code> <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p> <code>None</code> <code>visible</code> <code>bool</code> <p>whether to render this object or not in the stage</p> <code>True</code> <code>visual_only</code> <code>bool</code> <p>Whether this object should be visual only (and not collide with any other objects)</p> <code>False</code> <code>self_collisions</code> <code>bool</code> <p>Whether to enable self collisions for this object</p> <code>False</code> <code>prim_type</code> <code>PrimType</code> <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p> required <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p> <code>None</code> <code>abilities</code> <code>None or dict</code> <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p> <code>None</code> <code>control_freq</code> <code>float</code> <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p> <code>None</code> <code>controller_config</code> <code>None or dict</code> <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p> <code>None</code> <code>action_type</code> <code>str</code> <p>one of {discrete, continuous} - what type of action space to use</p> <code>'continuous'</code> <code>action_normalize</code> <code>bool</code> <p>whether to normalize inputted actions. This will override any default values specified by this class.</p> <code>True</code> <code>reset_joint_pos</code> <code>None or n-array</code> <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p> <code>None</code> <code>obs_modalities</code> <code>str or list of str</code> <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p> <code>'all'</code> <code>proprio_obs</code> <code>str or list of str</code> <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p> <code>'default'</code> <code>grasping_mode</code> <code>str</code> <p>One of {\"physical\", \"assisted\", \"sticky\"}. If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force). If \"assisted\", will magnetize any object touching and within the gripper's fingers. If \"sticky\", will magnetize any object touching the gripper's fingers.</p> <code>'physical'</code> <code>default_trunk_offset</code> <code>float</code> <p>sets the default height of the robot's trunk</p> <code>0.365</code> <code>default_arm_pose</code> <code>str</code> <p>Default pose for the robot arm. Should be one of:</p> <code>'vertical'</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p> <code>{}</code> Source code in <code>omnigibson/robots/tiago.py</code> <pre><code>def __init__(\nself,\n# Shared kwargs in hierarchy\nname,\nprim_path=None,\nclass_id=None,\nuuid=None,\nscale=None,\nvisible=True,\nvisual_only=False,\nself_collisions=False,\nload_config=None,\n# Unique to USDObject hierarchy\nabilities=None,\n# Unique to ControllableObject hierarchy\ncontrol_freq=None,\ncontroller_config=None,\naction_type=\"continuous\",\naction_normalize=True,\nreset_joint_pos=None,\n# Unique to BaseRobot\nobs_modalities=\"all\",\nproprio_obs=\"default\",\n# Unique to ManipulationRobot\ngrasping_mode=\"physical\",\n# Unique to Tiago\nrigid_trunk=False,\ndefault_trunk_offset=0.365,\ndefault_arm_pose=\"vertical\",\n**kwargs,\n):\n\"\"\"\n    Args:\n        name (str): Name for the object. Names need to be unique per scene\n        prim_path (None or str): global path in the stage to this object. If not specified, will automatically be\n            created at /World/&lt;name&gt;\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n            If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n            If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n            If \"sticky\", will magnetize any object touching the gripper's fingers.\n        rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n        default_trunk_offset (float): sets the default height of the robot's trunk\n        default_arm_pose (str): Default pose for the robot arm. Should be one of:\n            {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n# Store args\nself.rigid_trunk = rigid_trunk\nself.default_trunk_offset = default_trunk_offset\nassert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\nself.default_arm_pose = default_arm_pose\n# Other args that will be created at runtime\nself._world_base_fixed_joint_prim = None\n# Parse reset joint pos if specifying special string\nif isinstance(reset_joint_pos, str):\nassert (\nreset_joint_pos in RESET_JOINT_OPTIONS\n), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\nreset_joint_pos = (\nself.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n)\n# Run super init\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nclass_id=class_id,\nuuid=uuid,\nscale=scale,\nvisible=visible,\nfixed_base=True,\nvisual_only=visual_only,\nself_collisions=self_collisions,\nload_config=load_config,\nabilities=abilities,\ncontrol_freq=control_freq,\ncontroller_config=controller_config,\naction_type=action_type,\naction_normalize=action_normalize,\nreset_joint_pos=reset_joint_pos,\nobs_modalities=obs_modalities,\nproprio_obs=proprio_obs,\ngrasping_mode=grasping_mode,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.reset","title":"<code>reset()</code>","text":"<p>Reset should not change the robot base pose. We need to cache and restore the base joints to the world.</p> Source code in <code>omnigibson/robots/tiago.py</code> <pre><code>def reset(self):\n\"\"\"\n    Reset should not change the robot base pose.\n    We need to cache and restore the base joints to the world.\n    \"\"\"\nbase_joint_positions = self.get_joint_positions()[self.base_idx]\nsuper().reset()\nself.set_joint_positions(base_joint_positions, indices=self.base_idx)\n</code></pre>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.tuck","title":"<code>tuck()</code>","text":"<p>Immediately set this robot's configuration to be in tucked mode</p> Source code in <code>omnigibson/robots/tiago.py</code> <pre><code>def tuck(self):\n\"\"\"\n    Immediately set this robot's configuration to be in tucked mode\n    \"\"\"\nself.set_joint_positions(self.tucked_default_joint_pos)\n</code></pre>"},{"location":"reference/robots/tiago.html#robots.tiago.Tiago.untuck","title":"<code>untuck()</code>","text":"<p>Immediately set this robot's configuration to be in untucked mode</p> Source code in <code>omnigibson/robots/tiago.py</code> <pre><code>def untuck(self):\n\"\"\"\n    Immediately set this robot's configuration to be in untucked mode\n    \"\"\"\nself.set_joint_positions(self.untucked_default_joint_pos)\n</code></pre>"},{"location":"reference/robots/turtlebot.html","title":"turtlebot","text":""},{"location":"reference/robots/turtlebot.html#robots.turtlebot.Turtlebot","title":"<code>Turtlebot</code>","text":"<p>         Bases: <code>TwoWheelRobot</code></p> <p>Turtlebot robot Reference: http://wiki.ros.org/Robots/TurtleBot Uses joint velocity control</p> Source code in <code>omnigibson/robots/turtlebot.py</code> <pre><code>class Turtlebot(TwoWheelRobot):\n\"\"\"\n    Turtlebot robot\n    Reference: http://wiki.ros.org/Robots/TurtleBot\n    Uses joint velocity control\n    \"\"\"\n@property\ndef wheel_radius(self):\nreturn 0.038\n@property\ndef wheel_axle_length(self):\nreturn 0.23\n@property\ndef base_control_idx(self):\n\"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\nreturn np.array([0, 1])\n@property\ndef default_joint_pos(self):\nreturn np.zeros(self.n_joints)\n@property\ndef usd_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/turtlebot/turtlebot/turtlebot.usd\")\n@property\ndef urdf_path(self):\nreturn os.path.join(gm.ASSET_PATH, \"models/turtlebot/turtlebot.urdf\")\n</code></pre>"},{"location":"reference/robots/turtlebot.html#robots.turtlebot.Turtlebot.base_control_idx","title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>"},{"location":"reference/robots/two_wheel_robot.html","title":"two_wheel_robot","text":""},{"location":"reference/robots/two_wheel_robot.html#robots.two_wheel_robot.TwoWheelRobot","title":"<code>TwoWheelRobot</code>","text":"<p>         Bases: <code>LocomotionRobot</code></p> <p>Robot that is is equipped with locomotive (navigational) capabilities, as defined by two wheels that can be used for differential drive (e.g.: Turtlebot). Provides common interface for a wide variety of robots.</p> controller_config should, at the minimum, contain: <p>base: controller specifications for the controller to control this robot's base (locomotion).     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre> Source code in <code>omnigibson/robots/two_wheel_robot.py</code> <pre><code>class TwoWheelRobot(LocomotionRobot):\n\"\"\"\n    Robot that is is equipped with locomotive (navigational) capabilities, as defined by two wheels that can be used\n    for differential drive (e.g.: Turtlebot).\n    Provides common interface for a wide variety of robots.\n    NOTE: controller_config should, at the minimum, contain:\n        base: controller specifications for the controller to control this robot's base (locomotion).\n            Should include:\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n    \"\"\"\ndef _validate_configuration(self):\n# Make sure base only has two indices (i.e.: two wheels for differential drive)\nassert len(self.base_control_idx) == 2, \"Differential drive can only be used with robot with two base joints!\"\n# run super\nsuper()._validate_configuration()\ndef _create_discrete_action_space(self):\n# Set action list based on controller (joint or DD) used\n# We set straight velocity to be 50% of max velocity for the wheels\nmax_wheel_joint_vels = self.control_limits[\"velocity\"][1][self.base_control_idx]\nassert len(max_wheel_joint_vels) == 2, \"TwoWheelRobot must only have two base (wheel) joints!\"\nassert max_wheel_joint_vels[0] == max_wheel_joint_vels[1], \"Both wheels must have the same max speed!\"\nwheel_straight_vel = 0.5 * max_wheel_joint_vels[0]\nwheel_rotate_vel = 0.5\nif self._controller_config[\"base\"][\"name\"] == \"JointController\":\naction_list = [\n[wheel_straight_vel, wheel_straight_vel],\n[-wheel_straight_vel, -wheel_straight_vel],\n[wheel_rotate_vel, -wheel_rotate_vel],\n[-wheel_rotate_vel, wheel_rotate_vel],\n[0, 0],\n]\nelse:\n# DifferentialDriveController\nlin_vel = wheel_straight_vel * self.wheel_radius\nang_vel = wheel_rotate_vel * self.wheel_radius * 2.0 / self.wheel_axle_length\naction_list = [\n[lin_vel, 0],\n[-lin_vel, 0],\n[0, ang_vel],\n[0, -ang_vel],\n[0, 0],\n]\nself.action_list = action_list\n# Return this action space\nreturn gym.spaces.Discrete(n=len(self.action_list))\ndef _get_proprioception_dict(self):\ndic = super()._get_proprioception_dict()\n# Grab wheel joint velocity info\njoints = list(self._joints.values())\nwheel_joints = [joints[idx] for idx in self.base_control_idx]\nl_vel, r_vel = [jnt.get_state()[1] for jnt in wheel_joints]\n# Compute linear and angular velocities\nlin_vel = (l_vel + r_vel) / 2.0 * self.wheel_radius\nang_vel = (r_vel - l_vel) / self.wheel_axle_length\n# Add info\ndic[\"dd_base_lin_vel\"] = lin_vel        # lin_vel is already 1D np array of length 1\ndic[\"dd_base_ang_vel\"] = ang_vel        # lin_vel is already 1D np array of length 1\nreturn dic\n@property\ndef default_proprio_obs(self):\nobs_keys = super().default_proprio_obs\nreturn obs_keys + [\"dd_base_lin_vel\", \"dd_base_ang_vel\"]\n@property\ndef _default_controllers(self):\n# Always call super first\ncontrollers = super()._default_controllers\n# Use DifferentialDrive as default\ncontrollers[\"base\"] = \"DifferentialDriveController\"\nreturn controllers\n@property\ndef _default_base_differential_drive_controller_config(self):\n\"\"\"\n        Returns:\n            dict: Default differential drive controller config to\n                control this robot's base.\n        \"\"\"\nreturn {\n\"name\": \"DifferentialDriveController\",\n\"control_freq\": self._control_freq,\n\"wheel_radius\": self.wheel_radius,\n\"wheel_axle_length\": self.wheel_axle_length,\n\"control_limits\": self.control_limits,\n\"dof_idx\": self.base_control_idx,\n}\n@property\ndef _default_controller_config(self):\n# Always run super method first\ncfg = super()._default_controller_config\n# Add differential drive option to base\ncfg[\"base\"][\nself._default_base_differential_drive_controller_config[\"name\"]\n] = self._default_base_differential_drive_controller_config\nreturn cfg\n@property\n@abstractmethod\ndef wheel_radius(self):\n\"\"\"\n        Returns:\n            float: radius of each wheel at the base, in metric units\n        \"\"\"\nraise NotImplementedError\n@property\n@abstractmethod\ndef wheel_axle_length(self):\n\"\"\"\n        Returns:\n            float: perpendicular distance between the robot's two wheels, in metric units\n        \"\"\"\nraise NotImplementedError\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"TwoWheelRobot\")\nreturn classes\n</code></pre>"},{"location":"reference/robots/two_wheel_robot.html#robots.two_wheel_robot.TwoWheelRobot.wheel_axle_length","title":"<code>wheel_axle_length</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>perpendicular distance between the robot's two wheels, in metric units</p>"},{"location":"reference/robots/two_wheel_robot.html#robots.two_wheel_robot.TwoWheelRobot.wheel_radius","title":"<code>wheel_radius</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>radius of each wheel at the base, in metric units</p>"},{"location":"reference/scenes/index.html","title":"scenes","text":""},{"location":"reference/scenes/interactive_traversable_scene.html","title":"interactive_traversable_scene","text":""},{"location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene","title":"<code>InteractiveTraversableScene</code>","text":"<p>         Bases: <code>TraversableScene</code></p> <p>Create an interactive scene defined from a scene json file. In general, this supports curated, pre-defined scene layouts with annotated objects. This adds semantic support via a segmentation map generated for this specific scene.</p> Source code in <code>omnigibson/scenes/interactive_traversable_scene.py</code> <pre><code>class InteractiveTraversableScene(TraversableScene):\n\"\"\"\n    Create an interactive scene defined from a scene json file.\n    In general, this supports curated, pre-defined scene layouts with annotated objects.\n    This adds semantic support via a segmentation map generated for this specific scene.\n    \"\"\"\ndef __init__(\nself,\nscene_model,\nscene_instance=None,\nscene_file=None,\ntrav_map_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\nload_object_categories=None,\nnot_load_object_categories=None,\nload_room_types=None,\nload_room_instances=None,\nseg_map_resolution=0.1,\ninclude_robots=True,\n):\n\"\"\"\n        Args:\n            scene_model (str): Scene model name, e.g.: Rs_int\n            scene_instance (None or str): name of json file to load (without .json); if None,\n                defaults to og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.urdf\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                This will override scene_instance and scene_model!\n            trav_map_resolution (float): traversability map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n            load_object_categories (None or list): if specified, only load these object categories into the scene\n            not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n            load_room_types (None or list): only load objects in these room types into the scene\n            load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n            seg_map_resolution (float): room segmentation map resolution\n            include_robots (bool): whether to also include the robot(s) defined in the scene\n        \"\"\"\n# Store attributes from inputs\nself.include_robots = include_robots\n# Infer scene directory\nself.scene_dir = get_og_scene_path(scene_model)\n# Other values that will be loaded at runtime\nself.load_object_categories = None\nself.not_load_object_categories = None\nself.load_room_instances = None\n# Get scene information\nif scene_file is None:\nscene_file = self.get_scene_loading_info(\nscene_model=scene_model,\nscene_instance=scene_instance,\n)\n# Load room semantic and instance segmentation map (must occur AFTER inferring scene directory)\nself._seg_map = SegmentationMap(scene_dir=self.scene_dir, map_resolution=seg_map_resolution)\n# Decide which room(s) and object categories to load\nself.filter_rooms_and_object_categories(\nload_object_categories, not_load_object_categories, load_room_types, load_room_instances\n)\n# Run super init first\nsuper().__init__(\nscene_model=scene_model,\nscene_file=scene_file,\ntrav_map_resolution=trav_map_resolution,\ntrav_map_erosion=trav_map_erosion,\ntrav_map_with_objects=trav_map_with_objects,\nbuild_graph=build_graph,\nnum_waypoints=num_waypoints,\nwaypoint_resolution=waypoint_resolution,\nuse_floor_plane=False,\n)\ndef get_scene_loading_info(self, scene_model, scene_instance=None):\n\"\"\"\n        Gets scene loading info to know what single USD file to load, specified indirectly via @scene_instance if it\n        is specified, otherwise, will grab the \"best\" scene file to load.\n        Args:\n            scene_model (str): Name of the scene to load, e.g, Rs_int, etc.\n            scene_instance (None or str): If specified, should be name of json file to load. (without .json), default to\n                og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.json\n        Returns:\n            str: Absolute path to the desired scene file (.json) to load\n        \"\"\"\n# Infer scene file from model and directory\nfname = \"{}_best\".format(scene_model) if scene_instance is None else scene_instance\nreturn os.path.join(self.scene_dir, \"json\", \"{}.json\".format(fname))\ndef filter_rooms_and_object_categories(\nself, load_object_categories, not_load_object_categories, load_room_types, load_room_instances\n):\n\"\"\"\n        Handle partial scene loading based on object categories, room types or room instances\n        Args:\n            load_object_categories (None or list): if specified, only load these object categories into the scene\n            not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n            load_room_types (None or list): only load objects in these room types into the scene\n            load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n        \"\"\"\nself.load_object_categories = [load_object_categories] if \\\n            isinstance(load_object_categories, str) else load_object_categories\nself.not_load_object_categories = [not_load_object_categories] if \\\n            isinstance(not_load_object_categories, str) else not_load_object_categories\nif load_room_instances is not None:\nif isinstance(load_room_instances, str):\nload_room_instances = [load_room_instances]\nload_room_instances_filtered = []\nfor room_instance in load_room_instances:\nif room_instance in self._seg_map.room_ins_name_to_ins_id:\nload_room_instances_filtered.append(room_instance)\nelse:\nlog.warning(\"room_instance [{}] does not exist.\".format(room_instance))\nself.load_room_instances = load_room_instances_filtered\nelif load_room_types is not None:\nif isinstance(load_room_types, str):\nload_room_types = [load_room_types]\nload_room_instances_filtered = []\nfor room_type in load_room_types:\nif room_type in self._seg_map.room_sem_name_to_ins_name:\nload_room_instances_filtered.extend(self._seg_map.room_sem_name_to_ins_name[room_type])\nelse:\nlog.warning(\"room_type [{}] does not exist.\".format(room_type))\nself.load_room_instances = load_room_instances_filtered\nelse:\nself.load_room_instances = None\ndef _load(self):\n# Run super first\nsuper()._load()\n# Load the traversability map if we have the connectivity graph\nmaps_path = os.path.join(self.scene_dir, \"layout\")\nif self.has_connectivity_graph:\nself._trav_map.load_map(maps_path)\ndef _should_load_object(self, obj_info):\ncategory = obj_info[\"args\"].get(\"category\", \"object\")\nin_rooms = obj_info[\"args\"].get(\"in_rooms\", [])\n# Do not load these object categories (can blacklist building structures as well)\nnot_blacklisted = self.not_load_object_categories is None or category not in self.not_load_object_categories\n# Only load these object categories (no need to white list building structures)\nwhitelisted = self.load_object_categories is None or category in self.load_object_categories\n# This object is not located in one of the selected rooms, skip\nvalid_room = self.load_room_instances is None or len(set(self.load_room_instances) &amp; set(in_rooms)) &gt;= 0\n# Check whether this is an agent and we allow agents\nagent_ok = self.include_robots or category != robot_macros.ROBOT_CATEGORY\n# We only load this model if all the above conditions are met\nreturn not_blacklisted and whitelisted and valid_room and agent_ok\n@property\ndef seg_map(self):\n\"\"\"\n        Returns:\n            SegmentationMap: Map for segmenting this scene\n        \"\"\"\nreturn self._seg_map\n@classmethod\ndef modify_init_info_for_restoring(cls, init_info):\n# Run super first\nsuper().modify_init_info_for_restoring(init_info=init_info)\n# We also make sure we load in any robots, and also pop any filters that were stored\ninit_info[\"args\"][\"include_robots\"] = True\ninit_info[\"args\"][\"load_object_categories\"] = None\ninit_info[\"args\"][\"not_load_object_categories\"] = None\ninit_info[\"args\"][\"load_room_types\"] = None\ninit_info[\"args\"][\"load_room_instances\"] = None\n</code></pre>"},{"location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.seg_map","title":"<code>seg_map</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>SegmentationMap</code> <p>Map for segmenting this scene</p>"},{"location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.__init__","title":"<code>__init__(scene_model, scene_instance=None, scene_file=None, trav_map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2, load_object_categories=None, not_load_object_categories=None, load_room_types=None, load_room_instances=None, seg_map_resolution=0.1, include_robots=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>scene_model</code> <code>str</code> <p>Scene model name, e.g.: Rs_int</p> required <code>scene_instance</code> <code>None or str</code> <p>name of json file to load (without .json); if None, defaults to og_dataset/scenes//json/.urdf <code>None</code> <code>scene_file</code> <code>None or str</code> <p>If specified, full path of JSON file to load (with .json). This will override scene_instance and scene_model!</p> <code>None</code> <code>trav_map_resolution</code> <code>float</code> <p>traversability map resolution</p> <code>0.1</code> <code>trav_map_erosion</code> <code>float</code> <p>erosion radius of traversability areas, should be robot footprint radius</p> <code>2</code> <code>trav_map_with_objects</code> <code>bool</code> <p>whether to use objects or not when constructing graph</p> <code>True</code> <code>build_graph</code> <code>bool</code> <p>build connectivity graph</p> <code>True</code> <code>num_waypoints</code> <code>int</code> <p>number of way points returned</p> <code>10</code> <code>waypoint_resolution</code> <code>float</code> <p>resolution of adjacent way points</p> <code>0.2</code> <code>load_object_categories</code> <code>None or list</code> <p>if specified, only load these object categories into the scene</p> <code>None</code> <code>not_load_object_categories</code> <code>None or list</code> <p>if specified, do not load these object categories into the scene</p> <code>None</code> <code>load_room_types</code> <code>None or list</code> <p>only load objects in these room types into the scene</p> <code>None</code> <code>load_room_instances</code> <code>None or list</code> <p>if specified, only load objects in these room instances into the scene</p> <code>None</code> <code>seg_map_resolution</code> <code>float</code> <p>room segmentation map resolution</p> <code>0.1</code> <code>include_robots</code> <code>bool</code> <p>whether to also include the robot(s) defined in the scene</p> <code>True</code> Source code in <code>omnigibson/scenes/interactive_traversable_scene.py</code> <pre><code>def __init__(\nself,\nscene_model,\nscene_instance=None,\nscene_file=None,\ntrav_map_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\nload_object_categories=None,\nnot_load_object_categories=None,\nload_room_types=None,\nload_room_instances=None,\nseg_map_resolution=0.1,\ninclude_robots=True,\n):\n\"\"\"\n    Args:\n        scene_model (str): Scene model name, e.g.: Rs_int\n        scene_instance (None or str): name of json file to load (without .json); if None,\n            defaults to og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.urdf\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            This will override scene_instance and scene_model!\n        trav_map_resolution (float): traversability map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n        load_object_categories (None or list): if specified, only load these object categories into the scene\n        not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n        load_room_types (None or list): only load objects in these room types into the scene\n        load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n        seg_map_resolution (float): room segmentation map resolution\n        include_robots (bool): whether to also include the robot(s) defined in the scene\n    \"\"\"\n# Store attributes from inputs\nself.include_robots = include_robots\n# Infer scene directory\nself.scene_dir = get_og_scene_path(scene_model)\n# Other values that will be loaded at runtime\nself.load_object_categories = None\nself.not_load_object_categories = None\nself.load_room_instances = None\n# Get scene information\nif scene_file is None:\nscene_file = self.get_scene_loading_info(\nscene_model=scene_model,\nscene_instance=scene_instance,\n)\n# Load room semantic and instance segmentation map (must occur AFTER inferring scene directory)\nself._seg_map = SegmentationMap(scene_dir=self.scene_dir, map_resolution=seg_map_resolution)\n# Decide which room(s) and object categories to load\nself.filter_rooms_and_object_categories(\nload_object_categories, not_load_object_categories, load_room_types, load_room_instances\n)\n# Run super init first\nsuper().__init__(\nscene_model=scene_model,\nscene_file=scene_file,\ntrav_map_resolution=trav_map_resolution,\ntrav_map_erosion=trav_map_erosion,\ntrav_map_with_objects=trav_map_with_objects,\nbuild_graph=build_graph,\nnum_waypoints=num_waypoints,\nwaypoint_resolution=waypoint_resolution,\nuse_floor_plane=False,\n)\n</code></pre>"},{"location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.filter_rooms_and_object_categories","title":"<code>filter_rooms_and_object_categories(load_object_categories, not_load_object_categories, load_room_types, load_room_instances)</code>","text":"<p>Handle partial scene loading based on object categories, room types or room instances</p> <p>Parameters:</p> Name Type Description Default <code>load_object_categories</code> <code>None or list</code> <p>if specified, only load these object categories into the scene</p> required <code>not_load_object_categories</code> <code>None or list</code> <p>if specified, do not load these object categories into the scene</p> required <code>load_room_types</code> <code>None or list</code> <p>only load objects in these room types into the scene</p> required <code>load_room_instances</code> <code>None or list</code> <p>if specified, only load objects in these room instances into the scene</p> required Source code in <code>omnigibson/scenes/interactive_traversable_scene.py</code> <pre><code>def filter_rooms_and_object_categories(\nself, load_object_categories, not_load_object_categories, load_room_types, load_room_instances\n):\n\"\"\"\n    Handle partial scene loading based on object categories, room types or room instances\n    Args:\n        load_object_categories (None or list): if specified, only load these object categories into the scene\n        not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n        load_room_types (None or list): only load objects in these room types into the scene\n        load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n    \"\"\"\nself.load_object_categories = [load_object_categories] if \\\n        isinstance(load_object_categories, str) else load_object_categories\nself.not_load_object_categories = [not_load_object_categories] if \\\n        isinstance(not_load_object_categories, str) else not_load_object_categories\nif load_room_instances is not None:\nif isinstance(load_room_instances, str):\nload_room_instances = [load_room_instances]\nload_room_instances_filtered = []\nfor room_instance in load_room_instances:\nif room_instance in self._seg_map.room_ins_name_to_ins_id:\nload_room_instances_filtered.append(room_instance)\nelse:\nlog.warning(\"room_instance [{}] does not exist.\".format(room_instance))\nself.load_room_instances = load_room_instances_filtered\nelif load_room_types is not None:\nif isinstance(load_room_types, str):\nload_room_types = [load_room_types]\nload_room_instances_filtered = []\nfor room_type in load_room_types:\nif room_type in self._seg_map.room_sem_name_to_ins_name:\nload_room_instances_filtered.extend(self._seg_map.room_sem_name_to_ins_name[room_type])\nelse:\nlog.warning(\"room_type [{}] does not exist.\".format(room_type))\nself.load_room_instances = load_room_instances_filtered\nelse:\nself.load_room_instances = None\n</code></pre>"},{"location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.get_scene_loading_info","title":"<code>get_scene_loading_info(scene_model, scene_instance=None)</code>","text":"<p>Gets scene loading info to know what single USD file to load, specified indirectly via @scene_instance if it is specified, otherwise, will grab the \"best\" scene file to load.</p> <p>Parameters:</p> Name Type Description Default <code>scene_model</code> <code>str</code> <p>Name of the scene to load, e.g, Rs_int, etc.</p> required <code>scene_instance</code> <code>None or str</code> <p>If specified, should be name of json file to load. (without .json), default to og_dataset/scenes//json/.json <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Absolute path to the desired scene file (.json) to load</p> Source code in <code>omnigibson/scenes/interactive_traversable_scene.py</code> <pre><code>def get_scene_loading_info(self, scene_model, scene_instance=None):\n\"\"\"\n    Gets scene loading info to know what single USD file to load, specified indirectly via @scene_instance if it\n    is specified, otherwise, will grab the \"best\" scene file to load.\n    Args:\n        scene_model (str): Name of the scene to load, e.g, Rs_int, etc.\n        scene_instance (None or str): If specified, should be name of json file to load. (without .json), default to\n            og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.json\n    Returns:\n        str: Absolute path to the desired scene file (.json) to load\n    \"\"\"\n# Infer scene file from model and directory\nfname = \"{}_best\".format(scene_model) if scene_instance is None else scene_instance\nreturn os.path.join(self.scene_dir, \"json\", \"{}.json\".format(fname))\n</code></pre>"},{"location":"reference/scenes/scene_base.html","title":"scene_base","text":""},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene","title":"<code>Scene</code>","text":"<p>         Bases: <code>Serializable</code>, <code>Registerable</code>, <code>Recreatable</code>, <code>ABC</code></p> <p>Base class for all Scene objects. Contains the base functionalities for an arbitary scene with an arbitrary set of added objects</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>class Scene(Serializable, Registerable, Recreatable, ABC):\n\"\"\"\n    Base class for all Scene objects.\n    Contains the base functionalities for an arbitary scene with an arbitrary set of added objects\n    \"\"\"\ndef __init__(\nself,\nscene_file=None,\nuse_floor_plane=True,\nfloor_plane_visible=True,\nuse_skybox=True,\nfloor_plane_color=(1.0, 1.0, 1.0),\n):\n\"\"\"\n        Args:\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                None results in no additional objects being loaded into the scene\n            use_floor_plane (bool): whether to load a flat floor plane into the simulator\n            floor_plane_visible (bool): whether to render the additionally added floor plane\n            floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n                to the generated floor plane\n        \"\"\"\n# Store internal variables\nself.scene_file = scene_file\nself._loaded = False                    # Whether this scene exists in the stage or not\nself._initialized = False               # Whether this scene has its internal handles / info initialized or not (occurs AFTER and INDEPENDENTLY from loading!)\nself._registry = None\nself._world_prim = None\nself._initial_state = None\nself._objects_info = None                       # Information associated with this scene\nself._use_floor_plane = use_floor_plane\nself._floor_plane_visible = floor_plane_visible\nself._floor_plane_color = floor_plane_color\nself._floor_plane = None\nself._use_skybox = use_skybox\nself._skybox = None\n# Call super init\nsuper().__init__()\n@property\ndef registry(self):\n\"\"\"\n        Returns:\n            SerializableRegistry: Master registry containing sub-registries of objects, robots, systems, etc.\n        \"\"\"\nreturn self._registry\n@property\ndef skybox(self):\n\"\"\"\n        Returns:\n            None or LightObject: Skybox light associated with this scene, if it is used\n        \"\"\"\nreturn self._skybox\n@property\ndef object_registry(self):\n\"\"\"\n        Returns:\n            SerializableRegistry: Object registry containing all active standalone objects in the scene\n        \"\"\"\nreturn self._registry(key=\"name\", value=\"object_registry\")\n@property\ndef system_registry(self):\n\"\"\"\n        Returns:\n            SerializableRegistry: System registry containing all systems in the scene (e.g.: water, dust, etc.)\n        \"\"\"\nreturn self._registry(key=\"name\", value=\"system_registry\")\n@property\ndef objects(self):\n\"\"\"\n        Get the objects in the scene.\n        Returns:\n            list of BaseObject: Standalone object(s) that are currently in this scene\n        \"\"\"\nreturn self.object_registry.objects\n@property\ndef robots(self):\n\"\"\"\n        Robots in the scene\n        Returns:\n            list of BaseRobot: Robot(s) that are currently in this scene\n        \"\"\"\nreturn list(self.object_registry(\"category\", robot_macros.ROBOT_CATEGORY, []))\n@property\ndef systems(self):\n\"\"\"\n        Systems in the scene\n        Returns:\n            list of BaseSystem: System(s) that are available to use in this scene\n        \"\"\"\nreturn self.system_registry.objects\n@property\ndef object_registry_unique_keys(self):\n\"\"\"\n        Returns:\n            list of str: Keys with which to index into the object registry. These should be valid public attributes of\n                prims that we can use as unique IDs to reference prims, e.g., prim.prim_path, prim.name, prim.handle, etc.\n        \"\"\"\nreturn [\"name\", \"prim_path\", \"uuid\"]\n@property\ndef object_registry_group_keys(self):\n\"\"\"\n        Returns:\n            list of str: Keys with which to index into the object registry. These should be valid public attributes of\n                prims that we can use as grouping IDs to reference prims, e.g., prim.in_rooms\n        \"\"\"\nreturn [\"prim_type\", \"states\", \"category\", \"fixed_base\", \"in_rooms\", \"abilities\"]\n@property\ndef loaded(self):\nreturn self._loaded\n@property\ndef initialized(self):\nreturn self._initialized\ndef _load(self):\n\"\"\"\n        Load the scene into simulator\n        The elements to load may include: floor, building, objects, etc.\n        \"\"\"\n# We just add a ground plane if requested\nif self._use_floor_plane:\nself.add_ground_plane(color=self._floor_plane_color, visible=self._floor_plane_visible)\n# Also add skybox if requested\nif self._use_skybox:\nself._skybox = LightObject(\nprim_path=\"/World/skybox\",\nname=\"skybox\",\nlight_type=\"Dome\",\nintensity=1500,\n)\nog.sim.import_object(self._skybox, register=False)\nlight_prim = self._skybox.light_link.prim\nlight_prim.GetAttribute(\"color\").Set(Gf.Vec3f(1.07, 0.85, 0.61))\nlight_prim.GetAttribute(\"texture:file\").Set(Sdf.AssetPath(m.DEFAULT_SKYBOX_TEXTURE))\ndef _load_objects_from_scene_file(self):\n\"\"\"\n        Loads scene objects based on metadata information found in the current USD stage's scene info\n        (information stored in the world prim's CustomData)\n        \"\"\"\n# Grab objects info from the scene file\nwith open(self.scene_file, \"r\") as f:\nscene_info = json.load(f)\ninit_info = scene_info[\"objects_info\"][\"init_info\"]\ninit_state = scene_info[\"state\"][\"object_registry\"]\n# Iterate over all scene info, and instantiate object classes linked to the objects found on the stage\n# accordingly\nfor obj_name, obj_info in init_info.items():\n# Check whether we should load the object or not\nif not self._should_load_object(obj_info=obj_info):\ncontinue\n# Create object class instance\nobj = create_object_from_init_info(obj_info)\n# Import into the simulator\nog.sim.import_object(obj)\n# Set the init pose accordingly\nobj.set_position_orientation(\nposition=init_state[obj_name][\"root_link\"][\"pos\"],\norientation=init_state[obj_name][\"root_link\"][\"ori\"],\n)\n# disable collision between the fixed links of the fixed objects\nfixed_objs = self.object_registry(\"fixed_base\", True, default_val=[])\nif len(fixed_objs) &gt; 1:\n# We iterate over all pairwise combinations of fixed objects\nbuilding_categories = {\"walls\", \"floors\", \"ceilings\"}\nfor obj_a, obj_b in combinations(fixed_objs, 2):\n# TODO: Remove this hotfix once asset collision meshes are fixed!\n# Filter out collisions between walls / ceilings / floors and ALL links of the other object\nif obj_a.category in building_categories:\nfor link in obj_b.links.values():\nobj_a.root_link.add_filtered_collision_pair(link)\nelif obj_b.category in building_categories:\nfor link in obj_a.links.values():\nobj_b.root_link.add_filtered_collision_pair(link)\nelse:\n# Only filter out root links\nobj_a.root_link.add_filtered_collision_pair(obj_b.root_link)\ndef _should_load_object(self, obj_info):\n\"\"\"\n        Helper function to check whether we should load an object given its init_info. Useful for potentially filtering\n        objects based on, e.g., their category, size, etc.\n        Subclasses can implement additional logic. By default, this returns True\n        Args:\n            obj_info (dict): Dictionary of object kwargs that will be used to load the object\n        Returns:\n            bool: Whether this object should be loaded or not\n        \"\"\"\nreturn True\ndef load(self):\n\"\"\"\n        Load the scene into simulator\n        The elements to load may include: floor, building, objects, etc.\n        \"\"\"\n# Make sure simulator is stopped\nassert og.sim.is_stopped(), \"Simulator should be stopped when loading this scene!\"\n# Do not override this function. Override _load instead.\nif self._loaded:\nraise ValueError(\"This scene is already loaded.\")\n# Create the registry for tracking all objects in the scene\nself._registry = self._create_registry()\n# Store world prim and load the scene into the simulator\nself._world_prim = og.sim.world_prim\nself._load()\n# If we have any scene file specified, use it to load the objects within it and also update the initial state\nif self.scene_file is not None:\nself._load_objects_from_scene_file()\n# We're now loaded\nself._loaded = True\n# Always stop the sim if we started it internally\nif not og.sim.is_stopped():\nog.sim.stop()\ndef clear_systems(self):\n# Clears systems so they can be re-initialized\nfor system in self.systems:\nsystem.clear()\ndef clear(self):\n\"\"\"\n        Clears any internal state before the scene is destroyed\n        \"\"\"\n# Must clear all systems\nself.clear_systems()\ndef _initialize(self):\n\"\"\"\n        Initializes state of this scene and sets up any references necessary post-loading. Should be implemented by\n        sub-class for extended utility\n        \"\"\"\npass\ndef initialize(self):\n\"\"\"\n        Initializes state of this scene and sets up any references necessary post-loading. Subclasses should\n        implement / extend the _initialize() method.\n        \"\"\"\nassert not self._initialized, \"Scene can only be initialized once! (It is already initialized)\"\nself._initialize()\n# Grab relevant objects info\nself.update_objects_info()\nself.wake_scene_objects()\nself._initialized = True\n# Store initial state, which may be loaded from a scene file if specified\nif self.scene_file is None:\ninit_state = self.dump_state(serialized=False)\nelse:\nwith open(self.scene_file, \"r\") as f:\nscene_info = json.load(f)\ninit_state = scene_info[\"state\"]\nog.sim.load_state(init_state, serialized=False)\nself._initial_state = init_state\ndef _create_registry(self):\n\"\"\"\n        Creates the internal registry used for tracking all objects\n        Returns:\n            SerializableRegistry: registry for tracking all objects\n        \"\"\"\n# Create meta registry and populate with internal registries for robots, objects, and systems\nregistry = SerializableRegistry(\nname=\"master_registry\",\nclass_types=SerializableRegistry,\n)\n# Add registry for systems -- this is already created externally, so we just update it and pull it directly\nregistry.add(obj=SYSTEM_REGISTRY)\n# Add registry for objects\nregistry.add(obj=SerializableRegistry(\nname=\"object_registry\",\nclass_types=BaseObject,\ndefault_key=\"name\",\nunique_keys=self.object_registry_unique_keys,\ngroup_keys=self.object_registry_group_keys,\n))\nreturn registry\ndef wake_scene_objects(self):\n\"\"\"\n        Force wakeup sleeping objects\n        \"\"\"\nfor obj in self.objects:\nobj.wake()\ndef get_objects_with_state(self, state):\n\"\"\"\n        Get the objects with a given state in the scene.\n        Args:\n            state (BaseObjectState): state of the objects to get\n        Returns:\n            set: all objects with the given state\n        \"\"\"\nreturn self.object_registry(\"states\", state, set())\ndef get_objects_with_state_recursive(self, state):\n\"\"\"\n        Get the objects with a given state and its subclasses in the scene.\n        Args:\n            state (BaseObjectState): state of the objects to get\n        Returns:\n            set: all objects with the given state and its subclasses\n        \"\"\"\nobjs = set()\nstates = {state}\nwhile states:\nnext_states = set()\nfor state in states:\nobjs |= self.object_registry(\"states\", state, set())\nnext_states |= set(state.__subclasses__())\nstates = next_states\nreturn objs\ndef _add_object(self, obj):\n\"\"\"\n        Add an object to the scene's internal object tracking mechanisms.\n        Note that if the scene is not loaded, it should load this added object alongside its other objects when\n        scene.load() is called. The object should also be accessible through scene.objects.\n        Args:\n            obj (BaseObject): the object to load into the simulator\n        \"\"\"\npass\ndef add_object(self, obj, register=True, _is_call_from_simulator=False):\n\"\"\"\n        Add an object to the scene, loading it if the scene is already loaded.\n        Note that calling add_object to an already loaded scene should only be done by the simulator's import_object()\n        function.\n        Args:\n            obj (BaseObject): the object to load\n            register (bool): whether to track this object internally in the scene registry\n            _is_call_from_simulator (bool): whether the caller is the simulator. This should\n            **not** be set by any callers that are not the Simulator class\n        Returns:\n            Usd.Prim: the prim of the loaded object if the scene was already loaded, or None if the scene is not loaded\n                (in that case, the object is stored to be loaded together with the scene)\n        \"\"\"\n# Make sure the simulator is the one calling this function\nassert _is_call_from_simulator, \"Use import_object() for adding objects to a simulator and scene!\"\n# If the scene is already loaded, we need to load this object separately. Otherwise, don't do anything now,\n# let scene._load() load the object when called later on.\nprim = obj.load()\n# Add this object to our registry based on its type, if we want to register it\nif register:\nself.object_registry.add(obj)\n# Run any additional scene-specific logic with the created object\nself._add_object(obj)\nreturn prim\ndef remove_object(self, obj):\n\"\"\"\n        Method to remove an object from the simulator\n        Args:\n            obj (BaseObject): Object to remove\n        \"\"\"\n# Remove from the appropriate registry\nself.object_registry.remove(obj)\n# Remove from omni stage\nobj.remove()\ndef reset(self):\n\"\"\"\n        Resets this scene\n        \"\"\"\n# Make sure the simulator is playing\nassert og.sim.is_playing(), \"Simulator must be playing in order to reset the scene!\"\n# Reset the states of all objects (including robots), including (non-)kinematic states and internal variables.\nassert self._initial_state is not None\nself.load_state(self._initial_state)\nog.sim.step()\n@property\ndef n_floors(self):\n\"\"\"\n        Returns:\n            int: Number of floors in this scene\n        \"\"\"\n# Default is a single floor\nreturn 1\n@property\ndef n_objects(self):\n\"\"\"\n        Returns:\n            int: number of objects\n        \"\"\"\nreturn len(self.objects)\n@property\ndef fixed_objects(self):\n\"\"\"\n        Returns:\n            dict: Keyword-mapped objects that are fixed in the scene. Maps object name to their object class instances\n                (DatasetObject)\n        \"\"\"\nreturn {obj.name: obj for obj in self.object_registry(\"fixed_base\", True)}\ndef get_random_floor(self):\n\"\"\"\n        Sample a random floor among all existing floor_heights in the scene.\n        Most scenes in OmniGibson only have a single floor.\n        Returns:\n            int: an integer between 0 and self.n_floors-1\n        \"\"\"\nreturn np.random.randint(0, self.n_floors)\ndef get_random_point(self, floor=None):\n\"\"\"\n        Sample a random point on the given floor number. If not given, sample a random floor number.\n        Should be implemented by subclass.\n        Args:\n            floor (None or int): floor number. None means the floor is randomly sampled\n        Returns:\n            2-tuple:\n                - int: floor number. This is the sampled floor number if @floor is None\n                - 3-array: (x,y,z) randomly sampled point\n        \"\"\"\nraise NotImplementedError()\ndef get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n\"\"\"\n        Get the shortest path from one point to another point.\n        Args:\n            floor (int): floor number\n            source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n            target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n            entire_path (bool): whether to return the entire path\n        Returns:\n            2-tuple:\n                - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n                - float: geodesic distance of the path\n        \"\"\"\nraise NotImplementedError()\ndef get_floor_height(self, floor=0):\n\"\"\"\n        Get the height of the given floor. Default is 0.0, since we only have a single floor\n        Args:\n            floor: an integer identifying the floor\n        Returns:\n            int: height of the given floor\n        \"\"\"\nreturn 0.0\ndef add_ground_plane(\nself,\nsize=None,\nz_position: float = 0,\nname=\"ground_plane\",\nprim_path: str = \"/World/groundPlane\",\nstatic_friction: float = 0.5,\ndynamic_friction: float = 0.5,\nrestitution: float = 0.8,\ncolor=None,\nvisible=True,\n):\n\"\"\"\n        Generate a ground plane into the simulator\n        Args:\n            size (None or float): If specified, sets the (x,y) size of the generated plane\n            z_position (float): Z position of the generated plane\n            name (str): Name to assign to the generated plane\n            prim_path (str): Prim path for the generated plane\n            static_friction (float): Static friction of the generated plane\n            dynamic_friction (float): Dynamics friction of the generated plane\n            restitution (float): Restitution of the generated plane\n            color (None or 3-array): If specified, sets the (R,G,B) color of the generated plane\n            visible (bool): Whether the plane should be visible or not\n        \"\"\"\nplane = GroundPlane(\nprim_path=prim_path,\nname=name,\nz_position=z_position,\nsize=size,\ncolor=None if color is None else np.array(color),\nvisible=visible,\n# TODO: update with new PhysicsMaterial API\n# static_friction=static_friction,\n# dynamic_friction=dynamic_friction,\n# restitution=restitution,\n)\nself._floor_plane = XFormPrim(\nprim_path=plane.prim_path,\nname=plane.name,\n)\ndef update_initial_state(self):\n\"\"\"\n        Updates the initial state for this scene (which the scene will get reset to upon calling reset())\n        \"\"\"\nself._initial_state = self.dump_state(serialized=False)\ndef update_objects_info(self):\n\"\"\"\n        Updates the scene-relevant information and saves it to the active USD. Useful for reloading a scene directly\n        from a saved USD in this format.\n        \"\"\"\n# Save relevant information\n# Iterate over all objects and save their init info\ninit_info = {obj.name: obj.get_init_info() for obj in self.object_registry.objects}\n# Compose as single dictionary and store internally\nself._objects_info = dict(init_info=init_info)\ndef get_objects_info(self):\n\"\"\"\n        Stored information, if any, for this scene. Structure is:\n            \"init_info\":\n                \"&lt;obj0&gt;\": &lt;obj0&gt; init kw/args\n                ...\n                \"&lt;robot0&gt;\": &lt;robot0&gt; init kw/args\n                ...\n        Returns:\n            None or dict: If it exists, nested dictionary of relevant objects' information\n        \"\"\"\nreturn self._objects_info\n@property\ndef state_size(self):\n# Total state size is the state size of our registry\nreturn self._registry.state_size\ndef _dump_state(self):\n# Default state for the scene is from the registry alone\nreturn self._registry.dump_state(serialized=False)\ndef _load_state(self, state):\n# Default state for the scene is from the registry alone\nself._registry.load_state(state=state, serialized=False)\ndef _serialize(self, state):\n# Default state for the scene is from the registry alone\nreturn self._registry.serialize(state=state)\ndef _deserialize(self, state):\n# Default state for the scene is from the registry alone\n# We split this into two explicit steps, because the actual registry state size might dynamically change\n# as we're deserializing\nstate_dict = self._registry.deserialize(state=state)\nreturn state_dict, self._registry.state_size\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_SCENES\nreturn REGISTERED_SCENES\n@classmethod\ndef modify_init_info_for_restoring(cls, init_info):\n\"\"\"\n        Helper function to modify a given init info for restoring a scene from corresponding scene info.\n        Note that this function modifies IN-PLACE!\n        Args:\n            init_info (dict): Information for this scene from @self.get_init_info()\n        \"\"\"\n# Default is pass\npass\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.fixed_objects","title":"<code>fixed_objects</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped objects that are fixed in the scene. Maps object name to their object class instances (DatasetObject)</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.n_floors","title":"<code>n_floors</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of floors in this scene</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.n_objects","title":"<code>n_objects</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>number of objects</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.object_registry","title":"<code>object_registry</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>SerializableRegistry</code> <p>Object registry containing all active standalone objects in the scene</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.object_registry_group_keys","title":"<code>object_registry_group_keys</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>list of str: Keys with which to index into the object registry. These should be valid public attributes of prims that we can use as grouping IDs to reference prims, e.g., prim.in_rooms</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.object_registry_unique_keys","title":"<code>object_registry_unique_keys</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>list of str: Keys with which to index into the object registry. These should be valid public attributes of prims that we can use as unique IDs to reference prims, e.g., prim.prim_path, prim.name, prim.handle, etc.</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.objects","title":"<code>objects</code>  <code>property</code>","text":"<p>Get the objects in the scene.</p> <p>Returns:</p> Type Description <p>list of BaseObject: Standalone object(s) that are currently in this scene</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.registry","title":"<code>registry</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>SerializableRegistry</code> <p>Master registry containing sub-registries of objects, robots, systems, etc.</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.robots","title":"<code>robots</code>  <code>property</code>","text":"<p>Robots in the scene</p> <p>Returns:</p> Type Description <p>list of BaseRobot: Robot(s) that are currently in this scene</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.skybox","title":"<code>skybox</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or LightObject: Skybox light associated with this scene, if it is used</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.system_registry","title":"<code>system_registry</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>SerializableRegistry</code> <p>System registry containing all systems in the scene (e.g.: water, dust, etc.)</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.systems","title":"<code>systems</code>  <code>property</code>","text":"<p>Systems in the scene</p> <p>Returns:</p> Type Description <p>list of BaseSystem: System(s) that are available to use in this scene</p>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.__init__","title":"<code>__init__(scene_file=None, use_floor_plane=True, floor_plane_visible=True, use_skybox=True, floor_plane_color=(1.0, 1.0, 1.0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>scene_file</code> <code>None or str</code> <p>If specified, full path of JSON file to load (with .json). None results in no additional objects being loaded into the scene</p> <code>None</code> <code>use_floor_plane</code> <code>bool</code> <p>whether to load a flat floor plane into the simulator</p> <code>True</code> <code>floor_plane_visible</code> <code>bool</code> <p>whether to render the additionally added floor plane</p> <code>True</code> <code>floor_plane_color</code> <code>3-array</code> <p>if @floor_plane_visible is True, this determines the (R,G,B) color assigned to the generated floor plane</p> <code>(1.0, 1.0, 1.0)</code> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def __init__(\nself,\nscene_file=None,\nuse_floor_plane=True,\nfloor_plane_visible=True,\nuse_skybox=True,\nfloor_plane_color=(1.0, 1.0, 1.0),\n):\n\"\"\"\n    Args:\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            None results in no additional objects being loaded into the scene\n        use_floor_plane (bool): whether to load a flat floor plane into the simulator\n        floor_plane_visible (bool): whether to render the additionally added floor plane\n        floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n            to the generated floor plane\n    \"\"\"\n# Store internal variables\nself.scene_file = scene_file\nself._loaded = False                    # Whether this scene exists in the stage or not\nself._initialized = False               # Whether this scene has its internal handles / info initialized or not (occurs AFTER and INDEPENDENTLY from loading!)\nself._registry = None\nself._world_prim = None\nself._initial_state = None\nself._objects_info = None                       # Information associated with this scene\nself._use_floor_plane = use_floor_plane\nself._floor_plane_visible = floor_plane_visible\nself._floor_plane_color = floor_plane_color\nself._floor_plane = None\nself._use_skybox = use_skybox\nself._skybox = None\n# Call super init\nsuper().__init__()\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.add_ground_plane","title":"<code>add_ground_plane(size=None, z_position=0, name='ground_plane', prim_path='/World/groundPlane', static_friction=0.5, dynamic_friction=0.5, restitution=0.8, color=None, visible=True)</code>","text":"<p>Generate a ground plane into the simulator</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>None or float</code> <p>If specified, sets the (x,y) size of the generated plane</p> <code>None</code> <code>z_position</code> <code>float</code> <p>Z position of the generated plane</p> <code>0</code> <code>name</code> <code>str</code> <p>Name to assign to the generated plane</p> <code>'ground_plane'</code> <code>prim_path</code> <code>str</code> <p>Prim path for the generated plane</p> <code>'/World/groundPlane'</code> <code>static_friction</code> <code>float</code> <p>Static friction of the generated plane</p> <code>0.5</code> <code>dynamic_friction</code> <code>float</code> <p>Dynamics friction of the generated plane</p> <code>0.5</code> <code>restitution</code> <code>float</code> <p>Restitution of the generated plane</p> <code>0.8</code> <code>color</code> <code>None or 3-array</code> <p>If specified, sets the (R,G,B) color of the generated plane</p> <code>None</code> <code>visible</code> <code>bool</code> <p>Whether the plane should be visible or not</p> <code>True</code> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def add_ground_plane(\nself,\nsize=None,\nz_position: float = 0,\nname=\"ground_plane\",\nprim_path: str = \"/World/groundPlane\",\nstatic_friction: float = 0.5,\ndynamic_friction: float = 0.5,\nrestitution: float = 0.8,\ncolor=None,\nvisible=True,\n):\n\"\"\"\n    Generate a ground plane into the simulator\n    Args:\n        size (None or float): If specified, sets the (x,y) size of the generated plane\n        z_position (float): Z position of the generated plane\n        name (str): Name to assign to the generated plane\n        prim_path (str): Prim path for the generated plane\n        static_friction (float): Static friction of the generated plane\n        dynamic_friction (float): Dynamics friction of the generated plane\n        restitution (float): Restitution of the generated plane\n        color (None or 3-array): If specified, sets the (R,G,B) color of the generated plane\n        visible (bool): Whether the plane should be visible or not\n    \"\"\"\nplane = GroundPlane(\nprim_path=prim_path,\nname=name,\nz_position=z_position,\nsize=size,\ncolor=None if color is None else np.array(color),\nvisible=visible,\n# TODO: update with new PhysicsMaterial API\n# static_friction=static_friction,\n# dynamic_friction=dynamic_friction,\n# restitution=restitution,\n)\nself._floor_plane = XFormPrim(\nprim_path=plane.prim_path,\nname=plane.name,\n)\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.add_object","title":"<code>add_object(obj, register=True, _is_call_from_simulator=False)</code>","text":"<p>Add an object to the scene, loading it if the scene is already loaded.</p> <p>Note that calling add_object to an already loaded scene should only be done by the simulator's import_object() function.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>the object to load</p> required <code>register</code> <code>bool</code> <p>whether to track this object internally in the scene registry</p> <code>True</code> <code>_is_call_from_simulator</code> <code>bool</code> <p>whether the caller is the simulator. This should</p> <code>False</code> <p>Returns:</p> Type Description <p>Usd.Prim: the prim of the loaded object if the scene was already loaded, or None if the scene is not loaded (in that case, the object is stored to be loaded together with the scene)</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def add_object(self, obj, register=True, _is_call_from_simulator=False):\n\"\"\"\n    Add an object to the scene, loading it if the scene is already loaded.\n    Note that calling add_object to an already loaded scene should only be done by the simulator's import_object()\n    function.\n    Args:\n        obj (BaseObject): the object to load\n        register (bool): whether to track this object internally in the scene registry\n        _is_call_from_simulator (bool): whether the caller is the simulator. This should\n        **not** be set by any callers that are not the Simulator class\n    Returns:\n        Usd.Prim: the prim of the loaded object if the scene was already loaded, or None if the scene is not loaded\n            (in that case, the object is stored to be loaded together with the scene)\n    \"\"\"\n# Make sure the simulator is the one calling this function\nassert _is_call_from_simulator, \"Use import_object() for adding objects to a simulator and scene!\"\n# If the scene is already loaded, we need to load this object separately. Otherwise, don't do anything now,\n# let scene._load() load the object when called later on.\nprim = obj.load()\n# Add this object to our registry based on its type, if we want to register it\nif register:\nself.object_registry.add(obj)\n# Run any additional scene-specific logic with the created object\nself._add_object(obj)\nreturn prim\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.clear","title":"<code>clear()</code>","text":"<p>Clears any internal state before the scene is destroyed</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def clear(self):\n\"\"\"\n    Clears any internal state before the scene is destroyed\n    \"\"\"\n# Must clear all systems\nself.clear_systems()\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_floor_height","title":"<code>get_floor_height(floor=0)</code>","text":"<p>Get the height of the given floor. Default is 0.0, since we only have a single floor</p> <p>Parameters:</p> Name Type Description Default <code>floor</code> <p>an integer identifying the floor</p> <code>0</code> <p>Returns:</p> Name Type Description <code>int</code> <p>height of the given floor</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def get_floor_height(self, floor=0):\n\"\"\"\n    Get the height of the given floor. Default is 0.0, since we only have a single floor\n    Args:\n        floor: an integer identifying the floor\n    Returns:\n        int: height of the given floor\n    \"\"\"\nreturn 0.0\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_objects_info","title":"<code>get_objects_info()</code>","text":"<p>Stored information, if any, for this scene. Structure is:</p> <pre><code>\"init_info\":\n    \"&lt;obj0&gt;\": &lt;obj0&gt; init kw/args\n    ...\n    \"&lt;robot0&gt;\": &lt;robot0&gt; init kw/args\n    ...\n</code></pre> <p>Returns:</p> Type Description <p>None or dict: If it exists, nested dictionary of relevant objects' information</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def get_objects_info(self):\n\"\"\"\n    Stored information, if any, for this scene. Structure is:\n        \"init_info\":\n            \"&lt;obj0&gt;\": &lt;obj0&gt; init kw/args\n            ...\n            \"&lt;robot0&gt;\": &lt;robot0&gt; init kw/args\n            ...\n    Returns:\n        None or dict: If it exists, nested dictionary of relevant objects' information\n    \"\"\"\nreturn self._objects_info\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_objects_with_state","title":"<code>get_objects_with_state(state)</code>","text":"<p>Get the objects with a given state in the scene.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>BaseObjectState</code> <p>state of the objects to get</p> required <p>Returns:</p> Name Type Description <code>set</code> <p>all objects with the given state</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def get_objects_with_state(self, state):\n\"\"\"\n    Get the objects with a given state in the scene.\n    Args:\n        state (BaseObjectState): state of the objects to get\n    Returns:\n        set: all objects with the given state\n    \"\"\"\nreturn self.object_registry(\"states\", state, set())\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_objects_with_state_recursive","title":"<code>get_objects_with_state_recursive(state)</code>","text":"<p>Get the objects with a given state and its subclasses in the scene.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>BaseObjectState</code> <p>state of the objects to get</p> required <p>Returns:</p> Name Type Description <code>set</code> <p>all objects with the given state and its subclasses</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def get_objects_with_state_recursive(self, state):\n\"\"\"\n    Get the objects with a given state and its subclasses in the scene.\n    Args:\n        state (BaseObjectState): state of the objects to get\n    Returns:\n        set: all objects with the given state and its subclasses\n    \"\"\"\nobjs = set()\nstates = {state}\nwhile states:\nnext_states = set()\nfor state in states:\nobjs |= self.object_registry(\"states\", state, set())\nnext_states |= set(state.__subclasses__())\nstates = next_states\nreturn objs\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_random_floor","title":"<code>get_random_floor()</code>","text":"<p>Sample a random floor among all existing floor_heights in the scene. Most scenes in OmniGibson only have a single floor.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>an integer between 0 and self.n_floors-1</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def get_random_floor(self):\n\"\"\"\n    Sample a random floor among all existing floor_heights in the scene.\n    Most scenes in OmniGibson only have a single floor.\n    Returns:\n        int: an integer between 0 and self.n_floors-1\n    \"\"\"\nreturn np.random.randint(0, self.n_floors)\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_random_point","title":"<code>get_random_point(floor=None)</code>","text":"<p>Sample a random point on the given floor number. If not given, sample a random floor number. Should be implemented by subclass.</p> <p>Parameters:</p> Name Type Description Default <code>floor</code> <code>None or int</code> <p>floor number. None means the floor is randomly sampled</p> <code>None</code> <p>Returns:</p> Type Description <p>2-tuple: - int: floor number. This is the sampled floor number if @floor is None - 3-array: (x,y,z) randomly sampled point</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def get_random_point(self, floor=None):\n\"\"\"\n    Sample a random point on the given floor number. If not given, sample a random floor number.\n    Should be implemented by subclass.\n    Args:\n        floor (None or int): floor number. None means the floor is randomly sampled\n    Returns:\n        2-tuple:\n            - int: floor number. This is the sampled floor number if @floor is None\n            - 3-array: (x,y,z) randomly sampled point\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_shortest_path","title":"<code>get_shortest_path(floor, source_world, target_world, entire_path=False)</code>","text":"<p>Get the shortest path from one point to another point.</p> <p>Parameters:</p> Name Type Description Default <code>floor</code> <code>int</code> <p>floor number</p> required <code>source_world</code> <code>2-array</code> <p>(x,y) 2D source location in world reference frame (metric)</p> required <code>target_world</code> <code>2-array</code> <p>(x,y) 2D target location in world reference frame (metric)</p> required <code>entire_path</code> <code>bool</code> <p>whether to return the entire path</p> <code>False</code> <p>Returns:</p> Type Description <p>2-tuple: - (N, 2) array: array of path waypoints, where N is the number of generated waypoints - float: geodesic distance of the path</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n\"\"\"\n    Get the shortest path from one point to another point.\n    Args:\n        floor (int): floor number\n        source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n        target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n        entire_path (bool): whether to return the entire path\n    Returns:\n        2-tuple:\n            - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n            - float: geodesic distance of the path\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.initialize","title":"<code>initialize()</code>","text":"<p>Initializes state of this scene and sets up any references necessary post-loading. Subclasses should implement / extend the _initialize() method.</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def initialize(self):\n\"\"\"\n    Initializes state of this scene and sets up any references necessary post-loading. Subclasses should\n    implement / extend the _initialize() method.\n    \"\"\"\nassert not self._initialized, \"Scene can only be initialized once! (It is already initialized)\"\nself._initialize()\n# Grab relevant objects info\nself.update_objects_info()\nself.wake_scene_objects()\nself._initialized = True\n# Store initial state, which may be loaded from a scene file if specified\nif self.scene_file is None:\ninit_state = self.dump_state(serialized=False)\nelse:\nwith open(self.scene_file, \"r\") as f:\nscene_info = json.load(f)\ninit_state = scene_info[\"state\"]\nog.sim.load_state(init_state, serialized=False)\nself._initial_state = init_state\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.load","title":"<code>load()</code>","text":"<p>Load the scene into simulator The elements to load may include: floor, building, objects, etc.</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def load(self):\n\"\"\"\n    Load the scene into simulator\n    The elements to load may include: floor, building, objects, etc.\n    \"\"\"\n# Make sure simulator is stopped\nassert og.sim.is_stopped(), \"Simulator should be stopped when loading this scene!\"\n# Do not override this function. Override _load instead.\nif self._loaded:\nraise ValueError(\"This scene is already loaded.\")\n# Create the registry for tracking all objects in the scene\nself._registry = self._create_registry()\n# Store world prim and load the scene into the simulator\nself._world_prim = og.sim.world_prim\nself._load()\n# If we have any scene file specified, use it to load the objects within it and also update the initial state\nif self.scene_file is not None:\nself._load_objects_from_scene_file()\n# We're now loaded\nself._loaded = True\n# Always stop the sim if we started it internally\nif not og.sim.is_stopped():\nog.sim.stop()\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.modify_init_info_for_restoring","title":"<code>modify_init_info_for_restoring(init_info)</code>  <code>classmethod</code>","text":"<p>Helper function to modify a given init info for restoring a scene from corresponding scene info. Note that this function modifies IN-PLACE!</p> <p>Parameters:</p> Name Type Description Default <code>init_info</code> <code>dict</code> <p>Information for this scene from @self.get_init_info()</p> required Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>@classmethod\ndef modify_init_info_for_restoring(cls, init_info):\n\"\"\"\n    Helper function to modify a given init info for restoring a scene from corresponding scene info.\n    Note that this function modifies IN-PLACE!\n    Args:\n        init_info (dict): Information for this scene from @self.get_init_info()\n    \"\"\"\n# Default is pass\npass\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.remove_object","title":"<code>remove_object(obj)</code>","text":"<p>Method to remove an object from the simulator</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object to remove</p> required Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def remove_object(self, obj):\n\"\"\"\n    Method to remove an object from the simulator\n    Args:\n        obj (BaseObject): Object to remove\n    \"\"\"\n# Remove from the appropriate registry\nself.object_registry.remove(obj)\n# Remove from omni stage\nobj.remove()\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.reset","title":"<code>reset()</code>","text":"<p>Resets this scene</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def reset(self):\n\"\"\"\n    Resets this scene\n    \"\"\"\n# Make sure the simulator is playing\nassert og.sim.is_playing(), \"Simulator must be playing in order to reset the scene!\"\n# Reset the states of all objects (including robots), including (non-)kinematic states and internal variables.\nassert self._initial_state is not None\nself.load_state(self._initial_state)\nog.sim.step()\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.update_initial_state","title":"<code>update_initial_state()</code>","text":"<p>Updates the initial state for this scene (which the scene will get reset to upon calling reset())</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def update_initial_state(self):\n\"\"\"\n    Updates the initial state for this scene (which the scene will get reset to upon calling reset())\n    \"\"\"\nself._initial_state = self.dump_state(serialized=False)\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.update_objects_info","title":"<code>update_objects_info()</code>","text":"<p>Updates the scene-relevant information and saves it to the active USD. Useful for reloading a scene directly from a saved USD in this format.</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def update_objects_info(self):\n\"\"\"\n    Updates the scene-relevant information and saves it to the active USD. Useful for reloading a scene directly\n    from a saved USD in this format.\n    \"\"\"\n# Save relevant information\n# Iterate over all objects and save their init info\ninit_info = {obj.name: obj.get_init_info() for obj in self.object_registry.objects}\n# Compose as single dictionary and store internally\nself._objects_info = dict(init_info=init_info)\n</code></pre>"},{"location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.wake_scene_objects","title":"<code>wake_scene_objects()</code>","text":"<p>Force wakeup sleeping objects</p> Source code in <code>omnigibson/scenes/scene_base.py</code> <pre><code>def wake_scene_objects(self):\n\"\"\"\n    Force wakeup sleeping objects\n    \"\"\"\nfor obj in self.objects:\nobj.wake()\n</code></pre>"},{"location":"reference/scenes/static_traversable_scene.html","title":"static_traversable_scene","text":""},{"location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene","title":"<code>StaticTraversableScene</code>","text":"<p>         Bases: <code>TraversableScene</code></p> <p>Static traversable scene class for OmniGibson, where scene is defined by a singular mesh (no intereactable objects)</p> Source code in <code>omnigibson/scenes/static_traversable_scene.py</code> <pre><code>class StaticTraversableScene(TraversableScene):\n\"\"\"\n    Static traversable scene class for OmniGibson, where scene is defined by a singular mesh (no intereactable objects)\n    \"\"\"\ndef __init__(\nself,\nscene_model,\nscene_file=None,\ntrav_map_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\nfloor_plane_visible=False,\nfloor_plane_color=(1.0, 1.0, 1.0),\n):\n\"\"\"\n        Args:\n            scene_model (str): Scene model name, e.g.: Adrian\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                None results in no additional objects being loaded into the scene\n            trav_map_resolution (float): traversability map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n            floor_plane_visible (bool): whether to render the additionally added floor plane\n            floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n                to the generated floor plane\n        \"\"\"\n# Store and initialize additional variables\nself._floor_heights = None\nself._scene_mesh = None\n# Run super init\nsuper().__init__(\nscene_model=scene_model,\nscene_file=scene_file,\ntrav_map_resolution=trav_map_resolution,\ntrav_map_erosion=trav_map_erosion,\ntrav_map_with_objects=trav_map_with_objects,\nbuild_graph=build_graph,\nnum_waypoints=num_waypoints,\nwaypoint_resolution=waypoint_resolution,\nuse_floor_plane=True,\nfloor_plane_visible=floor_plane_visible,\nfloor_plane_color=floor_plane_color,\n)\ndef _load(self):\n# Run super first\nsuper()._load()\n# Load the scene mesh (use downsampled one if available)\nfilename = os.path.join(get_scene_path(self.scene_model), \"mesh_z_up_downsampled.obj\")\nif not os.path.isfile(filename):\nfilename = os.path.join(get_scene_path(self.scene_model), \"mesh_z_up.obj\")\nscene_prim = add_asset_to_stage(\nasset_path=filename,\nprim_path=f\"/World/scene_{self.scene_model}\",\n)\n# Grab the actual mesh prim\nself._scene_mesh = CollisionVisualGeomPrim(\nprim_path=f\"/World/scene_{self.scene_model}/mesh_z_up/{self.scene_model}_mesh_texture\",\nname=f\"{self.scene_model}_mesh\",\n)\n# Load floor metadata\nfloor_height_path = os.path.join(get_scene_path(self.scene_model), \"floors.txt\")\nassert os.path.isfile(floor_height_path), f\"floor_heights.txt cannot be found in model: {self.scene_model}\"\nwith open(floor_height_path, \"r\") as f:\nself.floor_heights = sorted(list(map(float, f.readlines())))\nlog.debug(\"Floors {}\".format(self.floor_heights))\n# Move the floor plane to the first floor by default\nself.move_floor_plane(floor=0)\n# Filter the collision between the scene mesh and the floor plane\nself._scene_mesh.add_filtered_collision_pair(prim=self._floor_plane)\n# Load the traversability map\nself._trav_map.load_map(get_scene_path(self.scene_model))\ndef move_floor_plane(self, floor=0, additional_elevation=0.02, height=None):\n\"\"\"\n        Resets the floor plane to a new floor\n        Args:\n            floor (int): Integer identifying the floor to move the floor plane to\n            additional_elevation (float): Additional elevation with respect to the height of the floor\n            height (None or float): If specified, alternative parameter to directly control the height of the ground\n                plane. Note that this will override @additional_elevation and @floor!\n        \"\"\"\nheight = height if height is not None else self.floor_heights[floor] + additional_elevation\nself._floor_plane.set_position(np.array([0, 0, height]))\ndef get_floor_height(self, floor=0):\n\"\"\"\n        Return the current floor height (in meter)\n        Returns:\n            int: current floor height\n        \"\"\"\nreturn self.floor_heights[floor]\n@property\ndef n_floors(self):\nreturn len(self._floor_heights)\n</code></pre>"},{"location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene.__init__","title":"<code>__init__(scene_model, scene_file=None, trav_map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2, floor_plane_visible=False, floor_plane_color=(1.0, 1.0, 1.0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>scene_model</code> <code>str</code> <p>Scene model name, e.g.: Adrian</p> required <code>scene_file</code> <code>None or str</code> <p>If specified, full path of JSON file to load (with .json). None results in no additional objects being loaded into the scene</p> <code>None</code> <code>trav_map_resolution</code> <code>float</code> <p>traversability map resolution</p> <code>0.1</code> <code>trav_map_erosion</code> <code>float</code> <p>erosion radius of traversability areas, should be robot footprint radius</p> <code>2</code> <code>trav_map_with_objects</code> <code>bool</code> <p>whether to use objects or not when constructing graph</p> <code>True</code> <code>build_graph</code> <code>bool</code> <p>build connectivity graph</p> <code>True</code> <code>num_waypoints</code> <code>int</code> <p>number of way points returned</p> <code>10</code> <code>waypoint_resolution</code> <code>float</code> <p>resolution of adjacent way points</p> <code>0.2</code> <code>floor_plane_visible</code> <code>bool</code> <p>whether to render the additionally added floor plane</p> <code>False</code> <code>floor_plane_color</code> <code>3-array</code> <p>if @floor_plane_visible is True, this determines the (R,G,B) color assigned to the generated floor plane</p> <code>(1.0, 1.0, 1.0)</code> Source code in <code>omnigibson/scenes/static_traversable_scene.py</code> <pre><code>def __init__(\nself,\nscene_model,\nscene_file=None,\ntrav_map_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\nfloor_plane_visible=False,\nfloor_plane_color=(1.0, 1.0, 1.0),\n):\n\"\"\"\n    Args:\n        scene_model (str): Scene model name, e.g.: Adrian\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            None results in no additional objects being loaded into the scene\n        trav_map_resolution (float): traversability map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n        floor_plane_visible (bool): whether to render the additionally added floor plane\n        floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n            to the generated floor plane\n    \"\"\"\n# Store and initialize additional variables\nself._floor_heights = None\nself._scene_mesh = None\n# Run super init\nsuper().__init__(\nscene_model=scene_model,\nscene_file=scene_file,\ntrav_map_resolution=trav_map_resolution,\ntrav_map_erosion=trav_map_erosion,\ntrav_map_with_objects=trav_map_with_objects,\nbuild_graph=build_graph,\nnum_waypoints=num_waypoints,\nwaypoint_resolution=waypoint_resolution,\nuse_floor_plane=True,\nfloor_plane_visible=floor_plane_visible,\nfloor_plane_color=floor_plane_color,\n)\n</code></pre>"},{"location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene.get_floor_height","title":"<code>get_floor_height(floor=0)</code>","text":"<p>Return the current floor height (in meter)</p> <p>Returns:</p> Name Type Description <code>int</code> <p>current floor height</p> Source code in <code>omnigibson/scenes/static_traversable_scene.py</code> <pre><code>def get_floor_height(self, floor=0):\n\"\"\"\n    Return the current floor height (in meter)\n    Returns:\n        int: current floor height\n    \"\"\"\nreturn self.floor_heights[floor]\n</code></pre>"},{"location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene.move_floor_plane","title":"<code>move_floor_plane(floor=0, additional_elevation=0.02, height=None)</code>","text":"<p>Resets the floor plane to a new floor</p> <p>Parameters:</p> Name Type Description Default <code>floor</code> <code>int</code> <p>Integer identifying the floor to move the floor plane to</p> <code>0</code> <code>additional_elevation</code> <code>float</code> <p>Additional elevation with respect to the height of the floor</p> <code>0.02</code> <code>height</code> <code>None or float</code> <p>If specified, alternative parameter to directly control the height of the ground plane. Note that this will override @additional_elevation and @floor!</p> <code>None</code> Source code in <code>omnigibson/scenes/static_traversable_scene.py</code> <pre><code>def move_floor_plane(self, floor=0, additional_elevation=0.02, height=None):\n\"\"\"\n    Resets the floor plane to a new floor\n    Args:\n        floor (int): Integer identifying the floor to move the floor plane to\n        additional_elevation (float): Additional elevation with respect to the height of the floor\n        height (None or float): If specified, alternative parameter to directly control the height of the ground\n            plane. Note that this will override @additional_elevation and @floor!\n    \"\"\"\nheight = height if height is not None else self.floor_heights[floor] + additional_elevation\nself._floor_plane.set_position(np.array([0, 0, height]))\n</code></pre>"},{"location":"reference/scenes/traversable_scene.html","title":"traversable_scene","text":""},{"location":"reference/scenes/traversable_scene.html#scenes.traversable_scene.TraversableScene","title":"<code>TraversableScene</code>","text":"<p>         Bases: <code>Scene</code></p> <p>Traversable scene class. Contains the functionalities for navigation such as shortest path computation</p> Source code in <code>omnigibson/scenes/traversable_scene.py</code> <pre><code>class TraversableScene(Scene):\n\"\"\"\n    Traversable scene class.\n    Contains the functionalities for navigation such as shortest path computation\n    \"\"\"\ndef __init__(\nself,\nscene_model,\nscene_file=None,\ntrav_map_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\nuse_floor_plane=True,\nfloor_plane_visible=True,\nfloor_plane_color=(1.0, 1.0, 1.0),\n):\n\"\"\"\n        Args:\n            scene_model (str): Scene model name, e.g.: Adrian or Rs_int\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                None results in no additional objects being loaded into the scene\n            trav_map_resolution (float): traversability map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n            use_floor_plane (bool): whether to load a flat floor plane into the simulator\n            floor_plane_visible (bool): whether to render the additionally added floor plane\n            floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n                to the generated floor plane\n        \"\"\"\nlog.info(\"TraversableScene model: {}\".format(scene_model))\nself.scene_model = scene_model\n# Create traversable map\nself._trav_map = TraversableMap(\nmap_resolution=trav_map_resolution,\ntrav_map_erosion=trav_map_erosion,\ntrav_map_with_objects=trav_map_with_objects,\nbuild_graph=build_graph,\nnum_waypoints=num_waypoints,\nwaypoint_resolution=waypoint_resolution,\n)\n# Run super init\nsuper().__init__(\nscene_file=scene_file,\nuse_floor_plane=use_floor_plane,\nfloor_plane_visible=floor_plane_visible,\nfloor_plane_color=floor_plane_color,\n)\n@property\ndef trav_map(self):\n\"\"\"\n        Returns:\n            TraversableMap: Map for computing connectivity between nodes for this scene\n        \"\"\"\nreturn self._trav_map\n@property\ndef has_connectivity_graph(self):\n# Connectivity graph is determined by travserable map\nreturn self._trav_map.build_graph\ndef get_random_point(self, floor=None):\nreturn self._trav_map.get_random_point(floor=floor)\ndef get_shortest_path(self, floor, source_world, target_world, entire_path=False):\nassert self._trav_map.build_graph, \"cannot get shortest path without building the graph\"\nreturn self._trav_map.get_shortest_path(\nfloor=floor,\nsource_world=source_world,\ntarget_world=target_world,\nentire_path=entire_path,\n)\n</code></pre>"},{"location":"reference/scenes/traversable_scene.html#scenes.traversable_scene.TraversableScene.trav_map","title":"<code>trav_map</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>TraversableMap</code> <p>Map for computing connectivity between nodes for this scene</p>"},{"location":"reference/scenes/traversable_scene.html#scenes.traversable_scene.TraversableScene.__init__","title":"<code>__init__(scene_model, scene_file=None, trav_map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2, use_floor_plane=True, floor_plane_visible=True, floor_plane_color=(1.0, 1.0, 1.0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>scene_model</code> <code>str</code> <p>Scene model name, e.g.: Adrian or Rs_int</p> required <code>scene_file</code> <code>None or str</code> <p>If specified, full path of JSON file to load (with .json). None results in no additional objects being loaded into the scene</p> <code>None</code> <code>trav_map_resolution</code> <code>float</code> <p>traversability map resolution</p> <code>0.1</code> <code>trav_map_erosion</code> <code>float</code> <p>erosion radius of traversability areas, should be robot footprint radius</p> <code>2</code> <code>trav_map_with_objects</code> <code>bool</code> <p>whether to use objects or not when constructing graph</p> <code>True</code> <code>build_graph</code> <code>bool</code> <p>build connectivity graph</p> <code>True</code> <code>num_waypoints</code> <code>int</code> <p>number of way points returned</p> <code>10</code> <code>waypoint_resolution</code> <code>float</code> <p>resolution of adjacent way points</p> <code>0.2</code> <code>use_floor_plane</code> <code>bool</code> <p>whether to load a flat floor plane into the simulator</p> <code>True</code> <code>floor_plane_visible</code> <code>bool</code> <p>whether to render the additionally added floor plane</p> <code>True</code> <code>floor_plane_color</code> <code>3-array</code> <p>if @floor_plane_visible is True, this determines the (R,G,B) color assigned to the generated floor plane</p> <code>(1.0, 1.0, 1.0)</code> Source code in <code>omnigibson/scenes/traversable_scene.py</code> <pre><code>def __init__(\nself,\nscene_model,\nscene_file=None,\ntrav_map_resolution=0.1,\ntrav_map_erosion=2,\ntrav_map_with_objects=True,\nbuild_graph=True,\nnum_waypoints=10,\nwaypoint_resolution=0.2,\nuse_floor_plane=True,\nfloor_plane_visible=True,\nfloor_plane_color=(1.0, 1.0, 1.0),\n):\n\"\"\"\n    Args:\n        scene_model (str): Scene model name, e.g.: Adrian or Rs_int\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            None results in no additional objects being loaded into the scene\n        trav_map_resolution (float): traversability map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n        use_floor_plane (bool): whether to load a flat floor plane into the simulator\n        floor_plane_visible (bool): whether to render the additionally added floor plane\n        floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n            to the generated floor plane\n    \"\"\"\nlog.info(\"TraversableScene model: {}\".format(scene_model))\nself.scene_model = scene_model\n# Create traversable map\nself._trav_map = TraversableMap(\nmap_resolution=trav_map_resolution,\ntrav_map_erosion=trav_map_erosion,\ntrav_map_with_objects=trav_map_with_objects,\nbuild_graph=build_graph,\nnum_waypoints=num_waypoints,\nwaypoint_resolution=waypoint_resolution,\n)\n# Run super init\nsuper().__init__(\nscene_file=scene_file,\nuse_floor_plane=use_floor_plane,\nfloor_plane_visible=floor_plane_visible,\nfloor_plane_color=floor_plane_color,\n)\n</code></pre>"},{"location":"reference/scripts/setup.html","title":"setup","text":"<p>Helper script to setup this OmniGibson repository. Configures environment and downloads assets</p>"},{"location":"reference/sensors/index.html","title":"sensors","text":""},{"location":"reference/sensors/index.html#sensors.create_sensor","title":"<code>create_sensor(sensor_type, prim_path, name, modalities='all', sensor_kwargs=None, noise_type=None, noise_kwargs=None)</code>","text":"<p>Create a sensor of type @sensor_type with optional keyword args @sensor_kwargs that should be passed to the constructor. Also, additionally send noise of type @noise_type with corresponding keyword args @noise_kwargs that should be passed to the noise constructor.</p> <p>Parameters:</p> Name Type Description Default <code>sensor_type</code> <code>str</code> <p>Type of sensor to create. Should be either one of SENSOR_PRIM_TO_SENSOR.keys() or one of REGISTERED_SENSORS (i.e.: the string name of the desired class to create)</p> required <code>prim_path</code> <code>str</code> <p>prim path of the Sensor to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the sensor. Names need to be unique per scene.</p> required <code>modalities</code> <code>str or list of str</code> <p>Modality(s) supported by this sensor. Valid options are part of sensor.all_modalities. Default is \"all\", which corresponds to all modalities being used</p> <code>'all'</code> <code>sensor_kwargs</code> <code>dict</code> <p>Any keyword kwargs to pass to the constructor</p> <code>None</code> <code>noise_type</code> <code>str</code> <p>Type of sensor to create. Should be one of REGISTERED_SENSOR_NOISES (i.e.: the string name of the desired class to create)</p> <code>None</code> <code>noise_kwargs</code> <code>dict</code> <p>Any keyword kwargs to pass to the constructor</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BaseSensor</code> <p>Created sensor with specified params</p> Source code in <code>omnigibson/sensors/__init__.py</code> <pre><code>def create_sensor(\nsensor_type,\nprim_path,\nname,\nmodalities=\"all\",\nsensor_kwargs=None,\nnoise_type=None,\nnoise_kwargs=None\n):\n\"\"\"\n    Create a sensor of type @sensor_type with optional keyword args @sensor_kwargs that should be passed to the\n    constructor. Also, additionally send noise of type @noise_type with corresponding keyword args @noise_kwargs\n    that should be passed to the noise constructor.\n    Args:\n        sensor_type (str): Type of sensor to create. Should be either one of SENSOR_PRIM_TO_SENSOR.keys() or\n            one of REGISTERED_SENSORS (i.e.: the string name of the desired class to create)\n        prim_path (str): prim path of the Sensor to encapsulate or create.\n        name (str): Name for the sensor. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Valid options are part of\n            sensor.all_modalities. Default is \"all\", which corresponds to all modalities being used\n        sensor_kwargs (dict): Any keyword kwargs to pass to the constructor\n        noise_type (str): Type of sensor to create. Should be one of REGISTERED_SENSOR_NOISES\n            (i.e.: the string name of the desired class to create)\n        noise_kwargs (dict): Any keyword kwargs to pass to the constructor\n    Returns:\n        BaseSensor: Created sensor with specified params\n    \"\"\"\n# Run basic sanity check\nassert isinstance(sensor_type, str), \"Inputted sensor_type must be a string!\"\n# Grab the requested sensor class\nif sensor_type in SENSOR_PRIMS_TO_SENSOR_CLS:\nsensor_cls = SENSOR_PRIMS_TO_SENSOR_CLS[sensor_type]\nelif sensor_type in REGISTERED_SENSORS:\nsensor_cls = REGISTERED_SENSORS[sensor_type]\nelse:\n# This is an error, we didn't find the requested sensor ):\nraise ValueError(f\"No sensor found with corresponding sensor_type: {sensor_type}\")\n# Create the noise, and sanity check to make sure it's a valid type\nnoise = None\nif noise_type is not None:\nassert_valid_key(key=noise_type, valid_keys=REGISTERED_SENSOR_NOISES, name=\"sensor noise type\")\nnoise_kwargs = dict() if noise_kwargs is None else noise_kwargs\nnoise = REGISTERED_SENSOR_NOISES[noise_type](**noise_kwargs)\n# Create the sensor\nsensor_kwargs = dict() if sensor_kwargs is None else sensor_kwargs\nsensor = sensor_cls(prim_path=prim_path, name=name, modalities=modalities, noise=noise, **sensor_kwargs)\nreturn sensor\n</code></pre>"},{"location":"reference/sensors/dropout_sensor_noise.html","title":"dropout_sensor_noise","text":""},{"location":"reference/sensors/dropout_sensor_noise.html#sensors.dropout_sensor_noise.DropoutSensorNoise","title":"<code>DropoutSensorNoise</code>","text":"<p>         Bases: <code>BaseSensorNoise</code></p> <p>Naive dropout sensor noise model</p> <p>Parameters:</p> Name Type Description Default <code>dropout_prob</code> <code>float</code> <p>Value in [0.0, 1.0] representing fraction of a single observation to be replaced with @dropout_value</p> <code>0.05</code> <code>dropout_value</code> <code>float</code> <p>Value in [0.0, 1.0] to replace observations selected to be dropped out</p> <code>1.0</code> <code>enabled</code> <code>bool</code> <p>Whether this sensor should be enabled by default</p> <code>True</code> Source code in <code>omnigibson/sensors/dropout_sensor_noise.py</code> <pre><code>class DropoutSensorNoise(BaseSensorNoise):\n\"\"\"\n    Naive dropout sensor noise model\n    Args:\n        dropout_prob (float): Value in [0.0, 1.0] representing fraction of a single observation to be replaced\n            with @dropout_value\n        dropout_value (float): Value in [0.0, 1.0] to replace observations selected to be dropped out\n        enabled (bool): Whether this sensor should be enabled by default\n    \"\"\"\ndef __init__(\nself,\ndropout_prob=0.05,\ndropout_value=1.0,\nenabled=True,\n):\n# Store args, and make sure values are in acceptable range\nfor name, val in zip((\"dropout_prob\", \"dropout_value\"), (dropout_prob, dropout_value)):\nassert 0.0 &lt;= val &lt;= 1.0, f\"{name} should be in range [0.0, 1.0], got: {val}\"\nself._dropout_prob = dropout_prob\nself._dropout_value = dropout_value\n# Run super method\nsuper().__init__(enabled=enabled)\ndef _corrupt(self, obs):\n# If our noise rate is 0, we just return the obs\nif self._dropout_prob == 0.0:\nreturn obs\n# Corrupt with randomized dropout\nvalid_mask = np.random.choice(2, obs.shape, p=[self._dropout_prob, 1.0 - self._dropout_prob])\nobs[valid_mask == 0] = self._dropout_value\nreturn obs\n@property\ndef dropout_prob(self):\n\"\"\"\n        Returns:\n            float: Value in [0.0, 1.0] representing fraction of a single observation to be replaced\n                with self.dropout_value\n        \"\"\"\nreturn self._dropout_prob\n@dropout_prob.setter\ndef dropout_prob(self, p):\n\"\"\"\n        Set the dropout probability for this noise model.\n        Args:\n            p (float): Value in [0.0, 1.0] representing fraction of a single observation to be replaced\n                with self.dropout_value\n        \"\"\"\nassert 0.0 &lt;= p &lt;= 1.0, f\"dropout_prob should be in range [0.0, 1.0], got: {p}\"\nself._dropout_prob = p\n@property\ndef dropout_value(self):\n\"\"\"\n        Returns:\n            float: Value in [0.0, 1.0] to replace observations selected to be dropped out\n        \"\"\"\nreturn self._dropout_value\n@dropout_value.setter\ndef dropout_value(self, val):\n\"\"\"\n        Set the dropout value for this noise model.\n        Args:\n            val (float): Value in [0.0, 1.0] to replace observations selected to be dropped out\n        \"\"\"\nassert 0.0 &lt;= val &lt;= 1.0, f\"dropout_value should be in range [0.0, 1.0], got: {val}\"\nself._dropout_value = val\n</code></pre>"},{"location":"reference/sensors/dropout_sensor_noise.html#sensors.dropout_sensor_noise.DropoutSensorNoise.dropout_prob","title":"<code>dropout_prob</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Value in [0.0, 1.0] representing fraction of a single observation to be replaced with self.dropout_value</p>"},{"location":"reference/sensors/dropout_sensor_noise.html#sensors.dropout_sensor_noise.DropoutSensorNoise.dropout_value","title":"<code>dropout_value</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Value in [0.0, 1.0] to replace observations selected to be dropped out</p>"},{"location":"reference/sensors/scan_sensor.html","title":"scan_sensor","text":""},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor","title":"<code>ScanSensor</code>","text":"<p>         Bases: <code>BaseSensor</code></p> <p>General 2D LiDAR range sensor and occupancy grid sensor.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>modalities</code> <code>str or list of str</code> <p>Modality(s) supported by this sensor. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of cls.all_modalities. For this scan sensor, this includes any of:     {scan, occupancy_grid} Note that in order for \"occupancy_grid\" to be used, \"scan\" must also be included.</p> <code>'all'</code> <code>enabled</code> <code>bool</code> <p>Whether this sensor should be enabled by default</p> <code>True</code> <code>noise</code> <code>None or BaseSensorNoise</code> <p>If specified, sensor noise model to apply to this sensor.</p> <code>None</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this sensor's prim at runtime.</p> <code>None</code> <code>min_range</code> <code>float</code> <p>Minimum range to sense in meters</p> <code>0.05</code> <code>max_range</code> <code>float</code> <p>Maximum range to sense in meters</p> <code>10.0</code> <code>horizontal_fov</code> <code>float</code> <p>Field of view of sensor, in degrees</p> <code>360.0</code> <code>vertical_fov</code> <code>float</code> <p>Field of view of sensor, in degrees</p> <code>1.0</code> <code>yaw_offset</code> <code>float</code> <p>Degrees for offsetting this sensors horizontal FOV. Useful in cases where this sensor's forward direction is different than expected</p> <code>0.0</code> <code>horizontal_resolution</code> <code>float</code> <p>Degrees in between each horizontal scan hit</p> <code>1.0</code> <code>vertical_resolution</code> <code>float</code> <p>Degrees in between each vertical scan hit</p> <code>1.0</code> <code>rotation_rate</code> <code>float</code> <p>How fast the range sensor is rotating, in rotations per sec. Set to 0 for all scans be to hit at once</p> <code>0.0</code> <code>draw_points</code> <code>bool</code> <p>Whether to draw the points hit by this sensor</p> <code>False</code> <code>draw_lines</code> <code>bool</code> <p>Whether to draw the lines representing the scans from this sensor</p> <code>False</code> <code>occupancy_grid_resolution</code> <code>int</code> <p>How many discretized nodes in the occupancy grid. This will specify the height == width of the map</p> <code>128</code> <code>occupancy_grid_range</code> <code>float</code> <p>Range of the occupancy grid, in meters</p> <code>5.0</code> <code>occupancy_grid_inner_radius</code> <code>float</code> <p>Inner range of the occupancy grid that will assumed to be empty, in meters</p> <code>0.5</code> <code>occupancy_grid_local_link</code> <code>None or XFormPrim</code> <p>XForm prim that represents the \"origin\" of any generated occupancy grid, e.g.: if this scan sensor is attached to a robot, then this should possibly be the base link for that robot. If None is specified, then this will default to this own sensor's frame as the origin.</p> <code>None</code> Source code in <code>omnigibson/sensors/scan_sensor.py</code> <pre><code>class ScanSensor(BaseSensor):\n\"\"\"\n    General 2D LiDAR range sensor and occupancy grid sensor.\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Default is \"all\", which corresponds\n            to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.\n            For this scan sensor, this includes any of:\n                {scan, occupancy_grid}\n            Note that in order for \"occupancy_grid\" to be used, \"scan\" must also be included.\n        enabled (bool): Whether this sensor should be enabled by default\n        noise (None or BaseSensorNoise): If specified, sensor noise model to apply to this sensor.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this sensor's prim at runtime.\n        min_range (float): Minimum range to sense in meters\n        max_range (float): Maximum range to sense in meters\n        horizontal_fov (float): Field of view of sensor, in degrees\n        vertical_fov (float): Field of view of sensor, in degrees\n        yaw_offset (float): Degrees for offsetting this sensors horizontal FOV.\n            Useful in cases where this sensor's forward direction is different than expected\n        horizontal_resolution (float): Degrees in between each horizontal scan hit\n        vertical_resolution (float): Degrees in between each vertical scan hit\n        rotation_rate (float): How fast the range sensor is rotating, in rotations per sec. Set to 0 for all scans\n            be to hit at once\n        draw_points (bool): Whether to draw the points hit by this sensor\n        draw_lines (bool): Whether to draw the lines representing the scans from this sensor\n        occupancy_grid_resolution (int): How many discretized nodes in the occupancy grid. This will specify the\n            height == width of the map\n        occupancy_grid_range (float): Range of the occupancy grid, in meters\n        occupancy_grid_inner_radius (float): Inner range of the occupancy grid that will assumed to be empty, in meters\n        occupancy_grid_local_link (None or XFormPrim): XForm prim that represents the \"origin\" of any generated\n            occupancy grid, e.g.: if this scan sensor is attached to a robot, then this should possibly be the base link\n            for that robot. If None is specified, then this will default to this own sensor's frame as the origin.\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nmodalities=\"all\",\nenabled=True,\nnoise=None,\nload_config=None,\n# Basic LIDAR kwargs\nmin_range=0.05,\nmax_range=10.0,\nhorizontal_fov=360.0,\nvertical_fov=1.0,\nyaw_offset=0.0,\nhorizontal_resolution=1.0,\nvertical_resolution=1.0,\nrotation_rate=0.0,\ndraw_points=False,\ndraw_lines=False,\n# Occupancy Grid kwargs\noccupancy_grid_resolution=128,\noccupancy_grid_range=5.0,\noccupancy_grid_inner_radius=0.5,\noccupancy_grid_local_link=None,\n):\n# Store settings\nself.occupancy_grid_resolution = occupancy_grid_resolution\nself.occupancy_grid_range = occupancy_grid_range\nself.occupancy_grid_inner_radius = int(occupancy_grid_inner_radius * occupancy_grid_resolution\n/ occupancy_grid_range)\nself.occupancy_grid_local_link = self if occupancy_grid_local_link is None else occupancy_grid_local_link\n# Create variables that will be filled in at runtime\nself._rs = None                 # Range sensor interface, analagous to others, e.g.: dynamic control interface\n# Create load config from inputs\nload_config = dict() if load_config is None else load_config\nload_config[\"min_range\"] = min_range\nload_config[\"max_range\"] = max_range\nload_config[\"horizontal_fov\"] = horizontal_fov\nload_config[\"vertical_fov\"] = vertical_fov\nload_config[\"yaw_offset\"] = yaw_offset\nload_config[\"horizontal_resolution\"] = horizontal_resolution\nload_config[\"vertical_resolution\"] = vertical_resolution\nload_config[\"rotation_rate\"] = rotation_rate\nload_config[\"draw_points\"] = draw_points\nload_config[\"draw_lines\"] = draw_lines\n# Sanity check modalities -- if we're using occupancy_grid without scan modality, raise an error\nif isinstance(modalities, Iterable) and not isinstance(modalities, str) and \"occupancy_grid\" in modalities:\nassert \"scan\" in modalities, f\"'scan' modality must be included in order to get occupancy_grid modality!\"\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nmodalities=modalities,\nenabled=enabled,\nnoise=noise,\nload_config=load_config,\n)\ndef _load(self):\n# Define a LIDAR prim at the current stage\nresult, lidar = execute(\"RangeSensorCreateLidar\", path=self._prim_path)\nreturn lidar.GetPrim()\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Set all the lidar kwargs\nself.min_range = self._load_config[\"min_range\"]\nself.max_range = self._load_config[\"max_range\"]\nself.horizontal_fov = self._load_config[\"horizontal_fov\"]\nself.vertical_fov = self._load_config[\"vertical_fov\"]\nself.yaw_offset = self._load_config[\"yaw_offset\"]\nself.horizontal_resolution = self._load_config[\"horizontal_resolution\"]\nself.vertical_resolution = self._load_config[\"vertical_resolution\"]\nself.rotation_rate = self._load_config[\"rotation_rate\"]\nself.draw_points = self._load_config[\"draw_points\"]\nself.draw_lines = self._load_config[\"draw_lines\"]\ndef _initialize(self):\n# run super first\nsuper()._initialize()\n# Initialize lidar sensor interface\nself._rs = _range_sensor.acquire_lidar_sensor_interface()\n@property\ndef _obs_space_mapping(self):\n# Set the remaining modalities' values\n# (obs modality, shape, low, high)\nobs_space_mapping = dict(\nscan=((self.n_horizontal_rays, self.n_vertical_rays), 0.0, 1.0, np.float32),\noccupancy_grid=((self.occupancy_grid_resolution, self.occupancy_grid_resolution, 1), 0.0, 1.0, np.float32),\n)\nreturn obs_space_mapping\ndef get_local_occupancy_grid(self, scan):\n\"\"\"\n        Get local occupancy grid based on current 1D scan\n        Args:\n            n-array: 1D LiDAR scan\n        Returns:\n            2D-array: (occupancy_grid_resolution, occupancy_grid_resolution)-sized numpy array of the local occupancy grid\n        \"\"\"\n# Run sanity checks first\nassert \"occupancy_grid\" in self._modalities, \"Occupancy grid is not enabled for this range sensor!\"\nassert self.n_vertical_rays == 1, \"Occupancy grid is only valid for a 1D range sensor (n_vertical_rays = 1)!\"\n# Grab vector of corresponding angles for each scan line\nangles = np.arange(\n-np.radians(self.horizontal_fov / 2),\nnp.radians(self.horizontal_fov / 2),\nnp.radians(self.horizontal_resolution),\n)\n# Convert into 3D unit vectors for each angle\nunit_vector_laser = np.array([[np.cos(ang), np.sin(ang), 0.0] for ang in angles])\n# Scale unit vectors by corresponding laser scan distnaces\nassert ((scan &gt;= 0.0) &amp; (scan &lt;= 1.0)).all(), \"scan out of valid range [0, 1]\"\nscan_laser = unit_vector_laser * (scan * (self.max_range - self.min_range) + self.min_range)\n# Convert scans from laser frame to world frame\npos, ori = self.get_position_orientation()\nscan_world = quat2mat(ori).dot(scan_laser.T).T + pos\n# Convert scans from world frame to local base frame\nbase_pos, base_ori = self.occupancy_grid_local_link.get_position_orientation()\nscan_local = quat2mat(base_ori).T.dot((scan_world - base_pos).T).T\nscan_local = scan_local[:, :2]\nscan_local = np.concatenate([np.array([[0, 0]]), scan_local, np.array([[0, 0]])], axis=0)\n# flip y axis\nscan_local[:, 1] *= -1\n# Initialize occupancy grid -- default is unknown values\noccupancy_grid = np.zeros((self.occupancy_grid_resolution, self.occupancy_grid_resolution)).astype(np.uint8)\noccupancy_grid.fill(int(OccupancyGridState.UNKNOWN * 2.0))\n# Convert local scans into the corresponding OG square it should belong to (note now all values are &gt; 0, since\n# OG ranges from [0, resolution] x [0, resolution])\nscan_local_in_map = scan_local / self.occupancy_grid_range * self.occupancy_grid_resolution + \\\n                            (self.occupancy_grid_resolution / 2)\nscan_local_in_map = scan_local_in_map.reshape((1, -1, 1, 2)).astype(np.int32)\n# For each scan hit,\nfor i in range(scan_local_in_map.shape[1]):\ncv2.circle(\nimg=occupancy_grid,\ncenter=(scan_local_in_map[0, i, 0, 0], scan_local_in_map[0, i, 0, 1]),\nradius=2,\ncolor=int(OccupancyGridState.OBSTACLES * 2.0),\nthickness=-1,\n)\ncv2.fillPoly(\nimg=occupancy_grid, pts=scan_local_in_map, color=int(OccupancyGridState.FREESPACE * 2.0), lineType=1\n)\ncv2.circle(\nimg=occupancy_grid,\ncenter=(self.occupancy_grid_resolution // 2, self.occupancy_grid_resolution // 2),\nradius=self.occupancy_grid_inner_radius,\ncolor=int(OccupancyGridState.FREESPACE * 2.0),\nthickness=-1,\n)\nreturn occupancy_grid[:, :, None].astype(np.float32) / 2.0\ndef _get_obs(self):\n# Run super first to grab any upstream obs\nobs = super()._get_obs()\n# Add scan info (normalized to [0.0, 1.0])\nif \"scan\" in self._modalities:\nraw_scan = self._rs.get_linear_depth_data(self._prim_path)\n# Sometimes get_linear_depth_data will return values that are slightly out of range, needs clipping\nraw_scan = np.clip(raw_scan, self.min_range, self.max_range)\nobs[\"scan\"] = (raw_scan - self.min_range) / (self.max_range - self.min_range)\n# Optionally add occupancy grid info\nif \"occupancy_grid\" in self._modalities:\nobs[\"occupancy_grid\"] = self.get_local_occupancy_grid(scan=obs[\"scan\"])\nreturn obs\n@property\ndef n_horizontal_rays(self):\n\"\"\"\n        Returns:\n            int: Number of horizontal rays for this range sensor\n        \"\"\"\nreturn int(self.horizontal_fov // self.horizontal_resolution)\n@property\ndef n_vertical_rays(self):\n\"\"\"\n        Returns:\n            int: Number of vertical rays for this range sensor\n        \"\"\"\nreturn int(self.vertical_fov // self.vertical_resolution)\n@property\ndef min_range(self):\n\"\"\"\n        Gets this range sensor's min_range (minimum distance in meters which will register a hit)\n        Returns:\n            float: minimum range for this range sensor, in meters\n        \"\"\"\nreturn self.get_attribute(\"minRange\")\n@min_range.setter\ndef min_range(self, val):\n\"\"\"\n        Sets this range sensor's min_range (minimum distance in meters which will register a hit)\n        Args:\n            val (float): minimum range for this range sensor, in meters\n        \"\"\"\nself.set_attribute(\"minRange\", val)\n@property\ndef max_range(self):\n\"\"\"\n        Gets this range sensor's max_range (maximum distance in meters which will register a hit)\n        Returns:\n            float: maximum range for this range sensor, in meters\n        \"\"\"\nreturn self.get_attribute(\"maxRange\")\n@max_range.setter\ndef max_range(self, val):\n\"\"\"\n        Sets this range sensor's max_range (maximum distance in meters which will register a hit)\n        Args:\n            val (float): maximum range for this range sensor, in meters\n        \"\"\"\nself.set_attribute(\"maxRange\", val)\n@property\ndef draw_lines(self):\n\"\"\"\n        Gets whether range lines are drawn for this sensor\n        Returns:\n            bool: Whether range lines are drawn for this sensor\n        \"\"\"\nreturn self.get_attribute(\"drawLines\")\n@draw_lines.setter\ndef draw_lines(self, draw):\n\"\"\"\n        Sets whether range lines are drawn for this sensor\n        Args:\n            draw (float): Whether range lines are drawn for this sensor\n        \"\"\"\nself.set_attribute(\"drawLines\", draw)\n@property\ndef draw_points(self):\n\"\"\"\n        Gets whether range points are drawn for this sensor\n        Returns:\n            bool: Whether range points are drawn for this sensor\n        \"\"\"\nreturn self.get_attribute(\"drawPoints\")\n@draw_points.setter\ndef draw_points(self, draw):\n\"\"\"\n        Sets whether range points are drawn for this sensor\n        Args:\n            draw (float): Whether range points are drawn for this sensor\n        \"\"\"\nself.set_attribute(\"drawPoints\", draw)\n@property\ndef horizontal_fov(self):\n\"\"\"\n        Gets this range sensor's horizontal_fov\n        Returns:\n            float: horizontal field of view for this range sensor\n        \"\"\"\nreturn self.get_attribute(\"horizontalFov\")\n@horizontal_fov.setter\ndef horizontal_fov(self, fov):\n\"\"\"\n        Sets this range sensor's horizontal_fov\n        Args:\n            fov (float): horizontal field of view to set\n        \"\"\"\nself.set_attribute(\"horizontalFov\", fov)\n@property\ndef horizontal_resolution(self):\n\"\"\"\n        Gets this range sensor's horizontal_resolution (degrees in between each horizontal hit)\n        Returns:\n            float: horizontal resolution for this range sensor, in degrees\n        \"\"\"\nreturn self.get_attribute(\"horizontalResolution\")\n@horizontal_resolution.setter\ndef horizontal_resolution(self, resolution):\n\"\"\"\n        Sets this range sensor's horizontal_resolution (degrees in between each horizontal hit)\n        Args:\n            resolution (float): horizontal resolution to set, in degrees\n        \"\"\"\nself.set_attribute(\"horizontalResolution\", resolution)\n@property\ndef vertical_fov(self):\n\"\"\"\n        Gets this range sensor's vertical_fov\n        Returns:\n            float: vertical field of view for this range sensor\n        \"\"\"\nreturn self.get_attribute(\"verticalFov\")\n@vertical_fov.setter\ndef vertical_fov(self, fov):\n\"\"\"\n        Sets this range sensor's vertical_fov\n        Args:\n            fov (float): vertical field of view to set\n        \"\"\"\nself.set_attribute(\"verticalFov\", fov)\n@property\ndef vertical_resolution(self):\n\"\"\"\n        Gets this range sensor's vertical_resolution (degrees in between each vertical hit)\n        Returns:\n            float: vertical resolution for this range sensor, in degrees\n        \"\"\"\nreturn self.get_attribute(\"verticalResolution\")\n@vertical_resolution.setter\ndef vertical_resolution(self, resolution):\n\"\"\"\n        Sets this range sensor's vertical_resolution (degrees in between each vertical hit)\n        Args:\n            resolution (float): vertical resolution to set, in degrees\n        \"\"\"\nself.set_attribute(\"verticalResolution\", resolution)\n@property\ndef yaw_offset(self):\n\"\"\"\n        Gets this range sensor's yaw_offset (used in cases where this sensor's forward direction is different than expected)\n        Returns:\n            float: yaw offset for this range sensor in degrees\n        \"\"\"\nreturn self.get_attribute(\"yawOffset\")\n@yaw_offset.setter\ndef yaw_offset(self, offset):\n\"\"\"\n        Sets this range sensor's yaw_offset (used in cases where this sensor's forward direction is different than expected)\n        Args:\n            offset (float): yaw offset to set in degrees.\n        \"\"\"\nself.set_attribute(\"yawOffset\", offset)\n@property\ndef rotation_rate(self):\n\"\"\"\n        Gets this range sensor's rotation_rate, in degrees per second. Note that a 0 value corresponds to no rotation,\n        and all range hits are assumed to be received at the exact same time.\n        Returns:\n            float: rotation rate for this range sensor in degrees per second\n        \"\"\"\nreturn self.get_attribute(\"rotationRate\")\n@rotation_rate.setter\ndef rotation_rate(self, rate):\n\"\"\"\n        Sets this range sensor's rotation_rate, in degrees per second. Note that a 0 value corresponds to no rotation,\n        and all range hits are assumed to be received at the exact same time.\n        Args:\n            rate (float): rotation rate for this range sensor in degrees per second\n        \"\"\"\nself.set_attribute(\"rotationRate\", rate)\n@classproperty\ndef all_modalities(cls):\nreturn {\"scan\", \"occupancy_grid\"}\n@classproperty\ndef no_noise_modalities(cls):\n# Occupancy grid should have no noise\nreturn {\"occupancy_grid\"}\n@property\ndef enabled(self):\n# Just use super\nreturn super().enabled\n@enabled.setter\ndef enabled(self, enabled):\n# We must use super and additionally directly en/disable the sensor in the simulation\n# Note: weird syntax below required to \"extend\" super class's implementation, see:\n# https://stackoverflow.com/a/37663266\nsuper(ScanSensor, self.__class__).enabled.fset(self, enabled)\nself.set_attribute(\"enabled\", enabled)\n</code></pre>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.draw_lines","title":"<code>draw_lines</code>  <code>property</code> <code>writable</code>","text":"<p>Gets whether range lines are drawn for this sensor</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether range lines are drawn for this sensor</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.draw_points","title":"<code>draw_points</code>  <code>property</code> <code>writable</code>","text":"<p>Gets whether range points are drawn for this sensor</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether range points are drawn for this sensor</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.horizontal_fov","title":"<code>horizontal_fov</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's horizontal_fov</p> <p>Returns:</p> Name Type Description <code>float</code> <p>horizontal field of view for this range sensor</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.horizontal_resolution","title":"<code>horizontal_resolution</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's horizontal_resolution (degrees in between each horizontal hit)</p> <p>Returns:</p> Name Type Description <code>float</code> <p>horizontal resolution for this range sensor, in degrees</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.max_range","title":"<code>max_range</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's max_range (maximum distance in meters which will register a hit)</p> <p>Returns:</p> Name Type Description <code>float</code> <p>maximum range for this range sensor, in meters</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.min_range","title":"<code>min_range</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's min_range (minimum distance in meters which will register a hit)</p> <p>Returns:</p> Name Type Description <code>float</code> <p>minimum range for this range sensor, in meters</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.n_horizontal_rays","title":"<code>n_horizontal_rays</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of horizontal rays for this range sensor</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.n_vertical_rays","title":"<code>n_vertical_rays</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of vertical rays for this range sensor</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.rotation_rate","title":"<code>rotation_rate</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's rotation_rate, in degrees per second. Note that a 0 value corresponds to no rotation, and all range hits are assumed to be received at the exact same time.</p> <p>Returns:</p> Name Type Description <code>float</code> <p>rotation rate for this range sensor in degrees per second</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.vertical_fov","title":"<code>vertical_fov</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's vertical_fov</p> <p>Returns:</p> Name Type Description <code>float</code> <p>vertical field of view for this range sensor</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.vertical_resolution","title":"<code>vertical_resolution</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's vertical_resolution (degrees in between each vertical hit)</p> <p>Returns:</p> Name Type Description <code>float</code> <p>vertical resolution for this range sensor, in degrees</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.yaw_offset","title":"<code>yaw_offset</code>  <code>property</code> <code>writable</code>","text":"<p>Gets this range sensor's yaw_offset (used in cases where this sensor's forward direction is different than expected)</p> <p>Returns:</p> Name Type Description <code>float</code> <p>yaw offset for this range sensor in degrees</p>"},{"location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.get_local_occupancy_grid","title":"<code>get_local_occupancy_grid(scan)</code>","text":"<p>Get local occupancy grid based on current 1D scan</p> <p>Parameters:</p> Name Type Description Default <code>n-array</code> <p>1D LiDAR scan</p> required <p>Returns:</p> Type Description <p>2D-array: (occupancy_grid_resolution, occupancy_grid_resolution)-sized numpy array of the local occupancy grid</p> Source code in <code>omnigibson/sensors/scan_sensor.py</code> <pre><code>def get_local_occupancy_grid(self, scan):\n\"\"\"\n    Get local occupancy grid based on current 1D scan\n    Args:\n        n-array: 1D LiDAR scan\n    Returns:\n        2D-array: (occupancy_grid_resolution, occupancy_grid_resolution)-sized numpy array of the local occupancy grid\n    \"\"\"\n# Run sanity checks first\nassert \"occupancy_grid\" in self._modalities, \"Occupancy grid is not enabled for this range sensor!\"\nassert self.n_vertical_rays == 1, \"Occupancy grid is only valid for a 1D range sensor (n_vertical_rays = 1)!\"\n# Grab vector of corresponding angles for each scan line\nangles = np.arange(\n-np.radians(self.horizontal_fov / 2),\nnp.radians(self.horizontal_fov / 2),\nnp.radians(self.horizontal_resolution),\n)\n# Convert into 3D unit vectors for each angle\nunit_vector_laser = np.array([[np.cos(ang), np.sin(ang), 0.0] for ang in angles])\n# Scale unit vectors by corresponding laser scan distnaces\nassert ((scan &gt;= 0.0) &amp; (scan &lt;= 1.0)).all(), \"scan out of valid range [0, 1]\"\nscan_laser = unit_vector_laser * (scan * (self.max_range - self.min_range) + self.min_range)\n# Convert scans from laser frame to world frame\npos, ori = self.get_position_orientation()\nscan_world = quat2mat(ori).dot(scan_laser.T).T + pos\n# Convert scans from world frame to local base frame\nbase_pos, base_ori = self.occupancy_grid_local_link.get_position_orientation()\nscan_local = quat2mat(base_ori).T.dot((scan_world - base_pos).T).T\nscan_local = scan_local[:, :2]\nscan_local = np.concatenate([np.array([[0, 0]]), scan_local, np.array([[0, 0]])], axis=0)\n# flip y axis\nscan_local[:, 1] *= -1\n# Initialize occupancy grid -- default is unknown values\noccupancy_grid = np.zeros((self.occupancy_grid_resolution, self.occupancy_grid_resolution)).astype(np.uint8)\noccupancy_grid.fill(int(OccupancyGridState.UNKNOWN * 2.0))\n# Convert local scans into the corresponding OG square it should belong to (note now all values are &gt; 0, since\n# OG ranges from [0, resolution] x [0, resolution])\nscan_local_in_map = scan_local / self.occupancy_grid_range * self.occupancy_grid_resolution + \\\n                        (self.occupancy_grid_resolution / 2)\nscan_local_in_map = scan_local_in_map.reshape((1, -1, 1, 2)).astype(np.int32)\n# For each scan hit,\nfor i in range(scan_local_in_map.shape[1]):\ncv2.circle(\nimg=occupancy_grid,\ncenter=(scan_local_in_map[0, i, 0, 0], scan_local_in_map[0, i, 0, 1]),\nradius=2,\ncolor=int(OccupancyGridState.OBSTACLES * 2.0),\nthickness=-1,\n)\ncv2.fillPoly(\nimg=occupancy_grid, pts=scan_local_in_map, color=int(OccupancyGridState.FREESPACE * 2.0), lineType=1\n)\ncv2.circle(\nimg=occupancy_grid,\ncenter=(self.occupancy_grid_resolution // 2, self.occupancy_grid_resolution // 2),\nradius=self.occupancy_grid_inner_radius,\ncolor=int(OccupancyGridState.FREESPACE * 2.0),\nthickness=-1,\n)\nreturn occupancy_grid[:, :, None].astype(np.float32) / 2.0\n</code></pre>"},{"location":"reference/sensors/sensor_base.html","title":"sensor_base","text":""},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor","title":"<code>BaseSensor</code>","text":"<p>         Bases: <code>XFormPrim</code>, <code>GymObservable</code>, <code>Registerable</code></p> <p>Base Sensor class. Sensor-specific get_obs method is implemented in subclasses</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Sensor to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the sensor. Names need to be unique per scene.</p> required <code>modalities</code> <code>str or list of str</code> <p>Modality(s) supported by this sensor. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.</p> <code>'all'</code> <code>enabled</code> <code>bool</code> <p>Whether this sensor should be enabled by default</p> <code>True</code> <code>noise</code> <code>None or BaseSensorNoise</code> <p>If specified, sensor noise model to apply to this sensor.</p> <code>None</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this sensor's prim at runtime.</p> <code>None</code> Source code in <code>omnigibson/sensors/sensor_base.py</code> <pre><code>class BaseSensor(XFormPrim, GymObservable, Registerable, metaclass=ABCMeta):\n\"\"\"\n    Base Sensor class.\n    Sensor-specific get_obs method is implemented in subclasses\n    Args:\n        prim_path (str): prim path of the Sensor to encapsulate or create.\n        name (str): Name for the sensor. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Default is \"all\", which corresponds\n            to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.\n        enabled (bool): Whether this sensor should be enabled by default\n        noise (None or BaseSensorNoise): If specified, sensor noise model to apply to this sensor.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this sensor's prim at runtime.\n    \"\"\"\ndef __init__(\nself,\nprim_path,\nname,\nmodalities=\"all\",\nenabled=True,\nnoise=None,\nload_config=None,\n):\n# Store inputs (and sanity check modalities along the way)\nif modalities == \"all\":\nmodalities = self.all_modalities\nelse:\nmodalities = [modalities] if isinstance(modalities, str) else modalities\nfor modality in modalities:\nassert_valid_key(key=modality, valid_keys=self.all_modalities, name=\"modality\")\nself._modalities = set(modalities)\nself._enabled = enabled\nself._noise = noise\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nload_config=load_config,\n)\ndef _load(self):\n# Sub-sensors must implement this class directly! Cannot use parent XForm class by default\nraise NotImplementedError(\"Sensor class must implement _load!\")\ndef _post_load(self):\n# Run super first\nsuper()._post_load()\n# Set the enabled property based on the internal value\n# This is done so that any subclassed sensors which require simulator specific enabling can handle this now\nself.enabled = self._enabled\ndef get_obs(self):\n# Get sensor reading, and optionally corrupt the readings with noise using self.noise if\n# self.noise.enabled is True.\n# Note that the returned dictionary will only be filled in if this sensor is enabled!\nif not self._enabled:\nreturn dict()\nobs = self._get_obs()\nif self._noise is not None:\nfor k, v in obs.items():\nif k not in self.no_noise_modalities:\nobs[k] = self._noise(v)\nreturn obs\ndef _get_obs(self):\n\"\"\"\n        Get sensor reading. Should generally be extended by subclass.\n        Returns:\n            dict: Keyword-mapped observations mapping modality names to numpy arrays of arbitrary dimension\n        \"\"\"\n# Default is returning an empty dict\nreturn dict()\ndef _load_observation_space(self):\n# Fill in observation space based on mapping and active modalities\nobs_space = dict()\nfor modality, space in self._obs_space_mapping.items():\nif modality in self._modalities:\nif isinstance(space, Space):\n# Directly add this space\nobs_space[modality] = space\nelse:\n# Assume we are procedurally generating a box space\nshape, low, high, dtype = space\nobs_space[modality] = self._build_obs_box_space(shape=shape, low=low, high=high, dtype=dtype)\nreturn obs_space\ndef add_modality(self, modality):\n\"\"\"\n        Add a modality to this sensor. Must be a valid modality (one of self.all_modalities)\n        Args:\n            modality (str): Name of the modality to add to this sensor\n        \"\"\"\nassert_valid_key(key=modality, valid_keys=self.all_modalities, name=\"modality\")\nif modality not in self._modalities:\nself._modalities.add(modality)\n# Update observation space\nself.load_observation_space()\ndef remove_modality(self, modality):\n\"\"\"\n        Remove a modality from this sensor. Must be a valid modality that is active (one of self.modalities)\n        Args:\n            modality (str): Name of the modality to remove from this sensor\n        \"\"\"\nassert_valid_key(key=modality, valid_keys=self._modalities, name=\"modality\")\nif modality in self._modalities:\nself._modalities.remove(modality)\n# Update observation space\nself.load_observation_space()\n@property\ndef modalities(self):\n\"\"\"\n        Returns:\n            set: Name of modalities provided by this sensor. This should correspond to all the keys provided\n                in self.get_obs()\n        \"\"\"\nreturn self._modalities\n@property\ndef _obs_space_mapping(self):\n\"\"\"\n        Returns:\n            dict: Keyword-mapped observation space settings for each modality. For each modality in\n                cls.all_modalities, its name should map directly to the corresponding gym space Space for that modality\n                or a 4-tuple entry (shape, low, high, dtype) for procedurally generating the appropriate Box Space\n                for that modality\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef all_modalities(cls):\n\"\"\"\n        Returns:\n            set: All possible valid modalities for this sensor. Should be implemented by subclass.\n        \"\"\"\nraise NotImplementedError()\n@property\ndef noise(self):\n\"\"\"\n        Returns:\n            None or BaseSensorNoise: Noise model to use for this sensor\n        \"\"\"\nreturn self._noise\n@classproperty\ndef no_noise_modalities(cls):\n\"\"\"\n        Returns:\n            set: Modalities that should NOT be passed through noise, irregardless of whether noise is enabled or not.\n                This is useful for some modalities which are not exclusively numerical arrays.\n        \"\"\"\nraise NotImplementedError()\n@property\ndef enabled(self):\n\"\"\"\n        Returns:\n            bool: Whether this sensor is enabled or not\n        \"\"\"\n# By default, we simply return the internal value. Subclasses may need to extend this functionality,\n# e.g. by disabling actual sim functionality for better computational efficiency\nreturn self._enabled\n@enabled.setter\ndef enabled(self, enabled):\n\"\"\"\n        Args:\n            enabled (bool): Whether this sensor should be enabled or not\n        \"\"\"\n# By default, we simply store the value internally. Subclasses may need to extend this functionality,\n# e.g. by disabling actual sim functionality for better computational efficiency\nself._enabled = enabled\n@classproperty\ndef sensor_type(cls):\n\"\"\"\n        Returns:\n            str: Type of this sensor. By default, this is the sensor class name\n        \"\"\"\nreturn cls.__name__\n@classmethod\ndef _register_cls(cls):\nglobal ALL_SENSOR_MODALITIES\n# Run super first\nsuper()._register_cls()\n# Also store modalities from this sensor class if we're registering it\nif cls.__name__ not in cls._do_not_register_classes:\nALL_SENSOR_MODALITIES.union(cls.all_modalities)\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseSensor\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_SENSORS\nreturn REGISTERED_SENSORS\n</code></pre>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.enabled","title":"<code>enabled</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this sensor is enabled or not</p>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.modalities","title":"<code>modalities</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>set</code> <p>Name of modalities provided by this sensor. This should correspond to all the keys provided in self.get_obs()</p>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.noise","title":"<code>noise</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>None or BaseSensorNoise: Noise model to use for this sensor</p>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.add_modality","title":"<code>add_modality(modality)</code>","text":"<p>Add a modality to this sensor. Must be a valid modality (one of self.all_modalities)</p> <p>Parameters:</p> Name Type Description Default <code>modality</code> <code>str</code> <p>Name of the modality to add to this sensor</p> required Source code in <code>omnigibson/sensors/sensor_base.py</code> <pre><code>def add_modality(self, modality):\n\"\"\"\n    Add a modality to this sensor. Must be a valid modality (one of self.all_modalities)\n    Args:\n        modality (str): Name of the modality to add to this sensor\n    \"\"\"\nassert_valid_key(key=modality, valid_keys=self.all_modalities, name=\"modality\")\nif modality not in self._modalities:\nself._modalities.add(modality)\n# Update observation space\nself.load_observation_space()\n</code></pre>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.all_modalities","title":"<code>all_modalities()</code>","text":"<p>Returns:</p> Name Type Description <code>set</code> <p>All possible valid modalities for this sensor. Should be implemented by subclass.</p> Source code in <code>omnigibson/sensors/sensor_base.py</code> <pre><code>@classproperty\ndef all_modalities(cls):\n\"\"\"\n    Returns:\n        set: All possible valid modalities for this sensor. Should be implemented by subclass.\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.no_noise_modalities","title":"<code>no_noise_modalities()</code>","text":"<p>Returns:</p> Name Type Description <code>set</code> <p>Modalities that should NOT be passed through noise, irregardless of whether noise is enabled or not. This is useful for some modalities which are not exclusively numerical arrays.</p> Source code in <code>omnigibson/sensors/sensor_base.py</code> <pre><code>@classproperty\ndef no_noise_modalities(cls):\n\"\"\"\n    Returns:\n        set: Modalities that should NOT be passed through noise, irregardless of whether noise is enabled or not.\n            This is useful for some modalities which are not exclusively numerical arrays.\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.remove_modality","title":"<code>remove_modality(modality)</code>","text":"<p>Remove a modality from this sensor. Must be a valid modality that is active (one of self.modalities)</p> <p>Parameters:</p> Name Type Description Default <code>modality</code> <code>str</code> <p>Name of the modality to remove from this sensor</p> required Source code in <code>omnigibson/sensors/sensor_base.py</code> <pre><code>def remove_modality(self, modality):\n\"\"\"\n    Remove a modality from this sensor. Must be a valid modality that is active (one of self.modalities)\n    Args:\n        modality (str): Name of the modality to remove from this sensor\n    \"\"\"\nassert_valid_key(key=modality, valid_keys=self._modalities, name=\"modality\")\nif modality in self._modalities:\nself._modalities.remove(modality)\n# Update observation space\nself.load_observation_space()\n</code></pre>"},{"location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.sensor_type","title":"<code>sensor_type()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Type of this sensor. By default, this is the sensor class name</p> Source code in <code>omnigibson/sensors/sensor_base.py</code> <pre><code>@classproperty\ndef sensor_type(cls):\n\"\"\"\n    Returns:\n        str: Type of this sensor. By default, this is the sensor class name\n    \"\"\"\nreturn cls.__name__\n</code></pre>"},{"location":"reference/sensors/sensor_noise_base.html","title":"sensor_noise_base","text":""},{"location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise","title":"<code>BaseSensorNoise</code>","text":"<p>         Bases: <code>Registerable</code></p> <p>Base SensorNoise class. Sensor noise-specific add_noise method is implemented in subclasses</p> <p>Parameters:</p> Name Type Description Default <code>enabled</code> <code>bool</code> <p>Whether this sensor should be enabled by default</p> <code>True</code> Source code in <code>omnigibson/sensors/sensor_noise_base.py</code> <pre><code>class BaseSensorNoise(Registerable, metaclass=ABCMeta):\n\"\"\"\n    Base SensorNoise class.\n    Sensor noise-specific add_noise method is implemented in subclasses\n    Args:\n        enabled (bool): Whether this sensor should be enabled by default\n    \"\"\"\ndef __init__(self, enabled=True):\n# Store whether this noise model is enabled or not\nself._enabled = enabled\ndef __call__(self, obs):\n\"\"\"\n        If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading. This is an\n        identical call to self.corrupt(...)\n        Args:\n            obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n        Returns:\n            np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n        \"\"\"\nreturn self.corrupt(obs=obs)\ndef corrupt(self, obs):\n\"\"\"\n        If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading.\n        Args:\n            obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n        Returns:\n            np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n        \"\"\"\n# Run sanity check to make sure obs is in acceptable range\nassert len(obs[(obs &lt; 0.0) | (obs &gt; 1.0)]) == 0, \"sensor reading has to be between [0.0, 1.0]\"\nreturn self._corrupt(obs=obs) if self._enabled else obs\n@abstractmethod\ndef _corrupt(self, obs):\n\"\"\"\n        Corrupts observation @obs by adding sensor noise to sensor reading\n        Args:\n            obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n        Returns:\n            np.array: Corrupted observation numpy array\n        \"\"\"\nraise NotImplementedError()\n@property\ndef enabled(self):\n\"\"\"\n        Returns:\n            bool: Whether this noise model is enabled or not\n        \"\"\"\nreturn self._enabled\n@enabled.setter\ndef enabled(self, enabled):\n\"\"\"\n        En/disables this noise model\n        Args:\n            enabled (bool): Whether this noise model should be enabled or not\n        \"\"\"\nself._enabled = enabled\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseSensorNoise\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_SENSOR_NOISES\nreturn REGISTERED_SENSOR_NOISES\n</code></pre>"},{"location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise.enabled","title":"<code>enabled</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this noise model is enabled or not</p>"},{"location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise.__call__","title":"<code>__call__(obs)</code>","text":"<p>If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading. This is an identical call to self.corrupt(...)</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>np.array</code> <p>observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]</p> required <p>Returns:</p> Type Description <p>np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through</p> Source code in <code>omnigibson/sensors/sensor_noise_base.py</code> <pre><code>def __call__(self, obs):\n\"\"\"\n    If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading. This is an\n    identical call to self.corrupt(...)\n    Args:\n        obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n    Returns:\n        np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n    \"\"\"\nreturn self.corrupt(obs=obs)\n</code></pre>"},{"location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise.corrupt","title":"<code>corrupt(obs)</code>","text":"<p>If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>np.array</code> <p>observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]</p> required <p>Returns:</p> Type Description <p>np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through</p> Source code in <code>omnigibson/sensors/sensor_noise_base.py</code> <pre><code>def corrupt(self, obs):\n\"\"\"\n    If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading.\n    Args:\n        obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n    Returns:\n        np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n    \"\"\"\n# Run sanity check to make sure obs is in acceptable range\nassert len(obs[(obs &lt; 0.0) | (obs &gt; 1.0)]) == 0, \"sensor reading has to be between [0.0, 1.0]\"\nreturn self._corrupt(obs=obs) if self._enabled else obs\n</code></pre>"},{"location":"reference/sensors/vision_sensor.html","title":"vision_sensor","text":""},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor","title":"<code>VisionSensor</code>","text":"<p>         Bases: <code>BaseSensor</code></p> <p>Vision sensor that handles a variety of modalities, including:</p> <pre><code>- RGB (normal)\n- Depth (normal, linear)\n- Normals\n- Segmentation (semantic, instance)\n- Optical flow\n- 2D Bounding boxes (tight, loose)\n- 3D Bounding boxes\n- Camera state\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>modalities</code> <code>str or list of str</code> <p>Modality(s) supported by this sensor. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of cls.all_modalities. For this vision sensor, this includes any of:     {rgb, depth, depth_linear, normal, seg_semantic, seg_instance, flow, bbox_2d_tight,     bbox_2d_loose, bbox_3d, camera}</p> <code>'all'</code> <code>enabled</code> <code>bool</code> <p>Whether this sensor should be enabled by default</p> <code>True</code> <code>noise</code> <code>None or BaseSensorNoise</code> <p>If specified, sensor noise model to apply to this sensor.</p> <code>None</code> <code>load_config</code> <code>None or dict</code> <p>If specified, should contain keyword-mapped values that are relevant for loading this sensor's prim at runtime.</p> <code>None</code> <code>image_height</code> <code>int</code> <p>Height of generated images, in pixels</p> <code>128</code> <code>image_width</code> <code>int</code> <p>Width of generated images, in pixels</p> <code>128</code> <code>viewport_name</code> <code>None or str</code> <p>If specified, will link this camera to the specified viewport, overriding its current camera. Otherwise, creates a new viewport</p> <code>None</code> Source code in <code>omnigibson/sensors/vision_sensor.py</code> <pre><code>class VisionSensor(BaseSensor):\n\"\"\"\n    Vision sensor that handles a variety of modalities, including:\n        - RGB (normal)\n        - Depth (normal, linear)\n        - Normals\n        - Segmentation (semantic, instance)\n        - Optical flow\n        - 2D Bounding boxes (tight, loose)\n        - 3D Bounding boxes\n        - Camera state\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Default is \"all\", which corresponds\n            to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.\n            For this vision sensor, this includes any of:\n                {rgb, depth, depth_linear, normal, seg_semantic, seg_instance, flow, bbox_2d_tight,\n                bbox_2d_loose, bbox_3d, camera}\n        enabled (bool): Whether this sensor should be enabled by default\n        noise (None or BaseSensorNoise): If specified, sensor noise model to apply to this sensor.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this sensor's prim at runtime.\n        image_height (int): Height of generated images, in pixels\n        image_width (int): Width of generated images, in pixels\n        viewport_name (None or str): If specified, will link this camera to the specified viewport, overriding its\n            current camera. Otherwise, creates a new viewport\n    \"\"\"\n_SENSOR_HELPERS = dict(\nrgb=sensors_util.get_rgb,\ndepth=sensors_util.get_depth,\ndepth_linear=sensors_util.get_depth_linear,\nnormal=sensors_util.get_normals,\nseg_semantic=sensors_util.get_semantic_segmentation,\nseg_instance=sensors_util.get_instance_segmentation,\nflow=sensors_util.get_motion_vector,\nbbox_2d_tight=sensors_util.get_bounding_box_2d_tight,\nbbox_2d_loose=sensors_util.get_bounding_box_2d_loose,\nbbox_3d=sensors_util.get_bounding_box_3d,\ncamera=get_camera_params,\n)\n# Define raw sensor types\n_RAW_SENSOR_TYPES = dict(\nrgb=sensor_types.Rgb,\ndepth=sensor_types.Depth,\ndepth_linear=sensor_types.DepthLinear,\nnormal=sensor_types.Normal,\nseg_semantic=sensor_types.SemanticSegmentation,\nseg_instance=sensor_types.InstanceSegmentation,\nflow=sensor_types.MotionVector,\nbbox_2d_tight=sensor_types.BoundingBox2DTight,\nbbox_2d_loose=sensor_types.BoundingBox2DLoose,\nbbox_3d=sensor_types.BoundingBox3D,\n)\n# Persistent dictionary of sensors, mapped from prim_path to sensor\nSENSORS = dict()\ndef __init__(\nself,\nprim_path,\nname,\nmodalities=\"all\",\nenabled=True,\nnoise=None,\nload_config=None,\nimage_height=128,\nimage_width=128,\nviewport_name=None,\n):\n# Create load config from inputs\nload_config = dict() if load_config is None else load_config\nload_config[\"image_height\"] = image_height\nload_config[\"image_width\"] = image_width\nload_config[\"viewport_name\"] = viewport_name\n# Create variables that will be filled in later at runtime\nself._sd = None             # synthetic data interface\nself._viewport = None       # Viewport from which to grab data\n# Run super method\nsuper().__init__(\nprim_path=prim_path,\nname=name,\nmodalities=modalities,\nenabled=enabled,\nnoise=noise,\nload_config=load_config,\n)\ndef _load(self):\n# Define a new camera prim at the current stage\n# Note that we can't use og.sim.stage here because the vision sensors get loaded first\nreturn UsdGeom.Camera.Define(get_current_stage(), self._prim_path).GetPrim()\ndef _post_load(self):\n# run super first\nsuper()._post_load()\n# Add this sensor to the list of global sensors\nself.SENSORS[self._prim_path] = self\n# Get synthetic data interface\nself._sd = sd.acquire_syntheticdata_interface()\n# Create a new viewport to link to this camera or link to a pre-existing one\nviewport_name = self._load_config[\"viewport_name\"]\nif viewport_name is not None:\nvp_names_to_handles = {vp.name: vp for vp in get_viewport_window_instances()}\nassert_valid_key(key=viewport_name, valid_keys=vp_names_to_handles, name=\"viewport name\")\nviewport = vp_names_to_handles[viewport_name]\nelse:\nviewport = create_viewport_window()\n# Take a render step to make sure the viewport is generated before docking it\nrender()\n# Grab the newly created viewport and dock it to the GUI\n# The first viewport is always the \"main\" global camera, and any additional cameras are auxiliary views\n# These auxiliary views will be stacked in a single column\n# Thus, the first auxiliary viewport should be generated to the left of the main dockspace, and any\n# subsequent viewports should be equally spaced according to the number of pre-existing auxiliary views\nn_auxiliary_sensors = len(self.SENSORS) - 1\nif n_auxiliary_sensors == 1:\n# This is the first auxiliary viewport, dock to the left of the main dockspace\ndock_window(space=omni.ui.Workspace.get_window(\"DockSpace\"), name=viewport.name,\nlocation=omni.ui.DockPosition.LEFT, ratio=0.25)\nelif n_auxiliary_sensors &gt; 1:\n# This is any additional auxiliary viewports, dock equally-spaced in the auxiliary column\n# We also need to re-dock any prior viewports!\nfor i in range(2, n_auxiliary_sensors + 1):\ndock_window(space=omni.ui.Workspace.get_window(f\"Viewport {i - 1}\"), name=f\"Viewport {i}\",\nlocation=omni.ui.DockPosition.BOTTOM, ratio=(1 + n_auxiliary_sensors - i) / (2 + n_auxiliary_sensors - i))\nself._viewport = viewport\n# Link the camera and viewport together\nself._viewport.viewport_api.set_active_camera(self._prim_path)\n# Requires 3 render updates to propagate changes\nfor i in range(3):\nrender()\n# Set the viewer size (requires taking one render step afterwards)\nself._viewport.viewport_api.set_texture_resolution((self._load_config[\"image_width\"], self._load_config[\"image_height\"]))\n# Requires 3 render updates to propagate changes\nfor i in range(3):\nrender()\ndef _initialize(self):\n# Run super first\nsuper()._initialize()\n# Initialize sensors\nself.initialize_sensors(names=self._modalities)\ndef initialize_sensors(self, names):\n\"\"\"Initializes a raw sensor in the simulation.\n        Args:\n            names (str or list of str): Name of the raw sensor(s) to initialize.\n                If they are not part of self._RAW_SENSOR_TYPES' keys, we will simply pass over them\n        \"\"\"\n# Standardize the input and grab the intersection with all possible raw sensors\nnames = set([names]) if isinstance(names, str) else set(names)\nnames = names.intersection(set(self._RAW_SENSOR_TYPES.keys()))\n# Initialize sensors\nsensors = []\nfor name in names:\nsensors.append(sensors_util.create_or_retrieve_sensor(self._viewport.viewport_api, self._RAW_SENSOR_TYPES[name]))\n# Suppress syntheticdata warning here because we know the first render is invalid\nwith suppress_omni_log(channels=[\"omni.syntheticdata.plugin\"]):\nrender()\nrender()    # Extra frame required to prevent access violation error\ndef _get_obs(self):\n# Make sure we're initialized\nassert self.initialized, \"Cannot grab vision observations without first initializing this VisionSensor!\"\n# Run super first to grab any upstream obs\nobs = super()._get_obs()\n# Process each sensor modality individually\nfor modality in self.modalities:\nmod_kwargs = dict()\nmod_kwargs[\"viewport\"] = self._viewport.viewport_api\nif modality == \"seg_instance\":\nmod_kwargs.update({\"parsed\": True, \"return_mapping\": False})\nelif modality == \"bbox_3d\":\nmod_kwargs.update({\"parsed\": True, \"return_corners\": True})\nobs[modality] = self._SENSOR_HELPERS[modality](**mod_kwargs)\nreturn obs\ndef add_modality(self, modality):\n# Check if we already have this modality (if so, no need to initialize it explicitly)\nshould_initialize = modality not in self._modalities\n# Run super\nsuper().add_modality(modality=modality)\n# We also need to initialize this new modality\nif should_initialize:\nself.initialize_sensors(names=modality)\ndef get_local_pose(self):\n# We have to overwrite this because camera prims can't set their quat for some reason ):\nxform_translate_op = self.get_attribute(\"xformOp:translate\")\nxform_orient_op = self.get_attribute(\"xformOp:rotateXYZ\")\nreturn np.array(xform_translate_op), euler2quat(np.array(xform_orient_op))\ndef remove(self):\n# Remove from global sensors dictionary\nself.SENSORS.pop(self._prim_path)\n# Remove viewport\nself._viewport.destroy()\n# Run super\nsuper().remove()\n@property\ndef viewer_visibility(self):\n\"\"\"\n        Returns:\n            bool: Whether the viewer is visible or not\n        \"\"\"\nreturn self._viewport.visible\n@viewer_visibility.setter\ndef viewer_visibility(self, visible):\n\"\"\"\n        Sets whether the viewer should be visible or not in the Omni UI\n        Args:\n            visible (bool): Whether the viewer should be visible or not\n        \"\"\"\nself._viewport.visible = visible\n# Requires 1 render update to propagate changes\nrender()\n@property\ndef image_height(self):\n\"\"\"\n        Returns:\n            int: Image height of this sensor, in pixels\n        \"\"\"\nreturn self._viewport.viewport_api.get_texture_resolution()[1]\n@image_height.setter\ndef image_height(self, height):\n\"\"\"\n        Sets the image height @height for this sensor\n        Args:\n            height (int): Image height of this sensor, in pixels\n        \"\"\"\nwidth, _ = self._viewport.viewport_api.get_texture_resolution()\nself._viewport.viewport_api.set_texture_resolution((width, height))\n# Requires 3 updates to propagate changes\nfor i in range(3):\nrender()\n@property\ndef image_width(self):\n\"\"\"\n        Returns:\n            int: Image width of this sensor, in pixels\n        \"\"\"\nreturn self._viewport.viewport_api.get_texture_resolution()[0]\n@image_width.setter\ndef image_width(self, width):\n\"\"\"\n        Sets the image width @width for this sensor\n        Args:\n            width (int): Image width of this sensor, in pixels\n        \"\"\"\n_, height = self._viewport.viewport_api.get_texture_resolution()\nself._viewport.viewport_api.set_texture_resolution((width, height))\n# Requires 3 updates to propagate changes\nfor i in range(3):\nrender()\n@property\ndef clipping_range(self):\n\"\"\"\n        Returns:\n            2-tuple: [min, max] value of the sensor's clipping range, in meters\n        \"\"\"\nreturn np.array(self.get_attribute(\"clippingRange\"))\n@clipping_range.setter\ndef clipping_range(self, limits):\n\"\"\"\n        Sets the clipping range @limits for this sensor\n        Args:\n            limits (2-tuple): [min, max] value of the sensor's clipping range, in meters\n        \"\"\"\nself.set_attribute(attr=\"clippingRange\", val=Gf.Vec2f(*limits))\n# In order for sensor changes to propagate, we must toggle its visibility\nself.visible = False\n# A single update step has to happen here before we toggle visibility for changes to propagate\nrender()\nself.visible = True\n@property\ndef focal_length(self):\n\"\"\"\n        Returns:\n            float: focal length of this sensor, in meters\n        \"\"\"\nreturn self.get_attribute(\"focalLength\")\n@focal_length.setter\ndef focal_length(self, length):\n\"\"\"\n        Sets the focal length @length for this sensor\n        Args:\n            length (float): focal length of this sensor, in meters\n        \"\"\"\nself.set_attribute(\"focalLength\", length)\n@property\ndef _obs_space_mapping(self):\n# Generate the complex space types for special modalities:\n# {\"bbox_2d_tight\", \"bbox_2d_loose\", \"bbox_3d\", \"camera\"}\nbbox_3d_space = gym.spaces.Sequence(space=gym.spaces.Tuple((\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=int),  # uniqueId\ngym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # name\ngym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # semanticLabel\ngym.spaces.Text(min_length=0, max_length=50, charset=VALID_OMNI_CHARS),  # metadata\ngym.spaces.Sequence(space=gym.spaces.Box(low=0, high=MAX_INSTANCE_COUNT, shape=(), dtype=np.uint)),   # instanceIds\ngym.spaces.Box(low=0, high=MAX_CLASS_COUNT, shape=(), dtype=np.uint),  # semanticId\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # x_min\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # y_min\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # z_min\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # x_max\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # y_max\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # z_max\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(4, 4), dtype=float), # transform\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(8, 3), dtype=float), # corners\n)))\nbbox_2d_space = gym.spaces.Sequence(space=gym.spaces.Tuple((\ngym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=int),  # uniqueId\ngym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # name\ngym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # semanticLabel\ngym.spaces.Text(min_length=0, max_length=50, charset=VALID_OMNI_CHARS),  # metadata\ngym.spaces.Sequence(space=gym.spaces.Box(low=0, high=MAX_INSTANCE_COUNT, shape=(), dtype=np.uint)), # instanceIds\ngym.spaces.Box(low=0, high=MAX_CLASS_COUNT, shape=(), dtype=np.uint),  # semanticId\ngym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # x_min\ngym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # y_min\ngym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # x_max\ngym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # y_max\n)))\ncamera_space = gym.spaces.Dict(dict(\npose=gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4, 4), dtype=float),\nfov=gym.spaces.Box(low=0, high=np.inf, shape=(), dtype=float),\nfocal_length=gym.spaces.Box(low=0, high=np.inf, shape=(), dtype=float),\nhorizontal_aperature=gym.spaces.Box(low=0, high=np.inf, shape=(), dtype=float),\nview_projection_matrix=gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4, 4), dtype=float),\nresolution=gym.spaces.Dict(dict(\nwidth=gym.spaces.Box(low=1, high=MAX_VIEWER_SIZE, shape=(), dtype=np.uint),\nheight=gym.spaces.Box(low=1, high=MAX_VIEWER_SIZE, shape=(), dtype=np.uint),\n)),\nclipping_range=gym.spaces.Box(low=0, high=np.inf, shape=(2,), dtype=float),\n))\nobs_space_mapping = dict(\nrgb=((self.image_height, self.image_width, 4), 0, 255, np.uint8),\ndepth=((self.image_height, self.image_width), 0.0, 1.0, np.float32),\ndepth_linear=((self.image_height, self.image_width), 0.0, np.inf, np.float32),\nnormal=((self.image_height, self.image_width, 3), -1.0, 1.0, np.float32),\nseg_semantic=((self.image_height, self.image_width), 0, MAX_CLASS_COUNT, np.uint32),\nseg_instance=((self.image_height, self.image_width), 0, MAX_INSTANCE_COUNT, np.uint32),\nflow=((self.image_height, self.image_width, 3), -np.inf, np.inf, np.float32),\nbbox_2d_tight=bbox_2d_space,\nbbox_2d_loose=bbox_2d_space,\nbbox_3d=bbox_3d_space,\ncamera=camera_space,\n)\nreturn obs_space_mapping\n@classmethod\ndef clear(cls):\n\"\"\"\n        Clears all cached sensors that have been generated. Should be used when the simulator is completely reset; i.e.:\n        all objects on the stage are destroyed\n        \"\"\"\nfor sensor in cls.SENSORS.values():\n# Destroy any sensor that is not attached to the main viewport window\nif sensor._viewport.name != \"Viewport\":\nsensor._viewport.destroy()\n# Render to update\nrender()\ncls.SENSORS = dict()\n@classproperty\ndef all_modalities(cls):\nreturn {k for k in cls._SENSOR_HELPERS.keys()}\n@classproperty\ndef no_noise_modalities(cls):\n# bounding boxes and camera state should not have noise\nreturn {\"bbox_2d_tight\", \"bbox_2d_loose\", \"bbox_3d\", \"camera\"}\n</code></pre>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.clipping_range","title":"<code>clipping_range</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>2-tuple: [min, max] value of the sensor's clipping range, in meters</p>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.focal_length","title":"<code>focal_length</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>focal length of this sensor, in meters</p>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.image_height","title":"<code>image_height</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Image height of this sensor, in pixels</p>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.image_width","title":"<code>image_width</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Image width of this sensor, in pixels</p>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.viewer_visibility","title":"<code>viewer_visibility</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the viewer is visible or not</p>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.clear","title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clears all cached sensors that have been generated. Should be used when the simulator is completely reset; i.e.: all objects on the stage are destroyed</p> Source code in <code>omnigibson/sensors/vision_sensor.py</code> <pre><code>@classmethod\ndef clear(cls):\n\"\"\"\n    Clears all cached sensors that have been generated. Should be used when the simulator is completely reset; i.e.:\n    all objects on the stage are destroyed\n    \"\"\"\nfor sensor in cls.SENSORS.values():\n# Destroy any sensor that is not attached to the main viewport window\nif sensor._viewport.name != \"Viewport\":\nsensor._viewport.destroy()\n# Render to update\nrender()\ncls.SENSORS = dict()\n</code></pre>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.initialize_sensors","title":"<code>initialize_sensors(names)</code>","text":"<p>Initializes a raw sensor in the simulation.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>str or list of str</code> <p>Name of the raw sensor(s) to initialize. If they are not part of self._RAW_SENSOR_TYPES' keys, we will simply pass over them</p> required Source code in <code>omnigibson/sensors/vision_sensor.py</code> <pre><code>def initialize_sensors(self, names):\n\"\"\"Initializes a raw sensor in the simulation.\n    Args:\n        names (str or list of str): Name of the raw sensor(s) to initialize.\n            If they are not part of self._RAW_SENSOR_TYPES' keys, we will simply pass over them\n    \"\"\"\n# Standardize the input and grab the intersection with all possible raw sensors\nnames = set([names]) if isinstance(names, str) else set(names)\nnames = names.intersection(set(self._RAW_SENSOR_TYPES.keys()))\n# Initialize sensors\nsensors = []\nfor name in names:\nsensors.append(sensors_util.create_or_retrieve_sensor(self._viewport.viewport_api, self._RAW_SENSOR_TYPES[name]))\n# Suppress syntheticdata warning here because we know the first render is invalid\nwith suppress_omni_log(channels=[\"omni.syntheticdata.plugin\"]):\nrender()\nrender()    # Extra frame required to prevent access violation error\n</code></pre>"},{"location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.render","title":"<code>render()</code>","text":"<p>Refreshes the Isaac Sim app rendering components including UI elements and view ports..etc.</p> Source code in <code>omnigibson/sensors/vision_sensor.py</code> <pre><code>def render():\n\"\"\"\n    Refreshes the Isaac Sim app rendering components including UI elements and view ports..etc.\n    \"\"\"\nset_carb_setting(og.app._carb_settings, \"/app/player/playSimulations\", False)\nog.app.update()\nset_carb_setting(og.app._carb_settings, \"/app/player/playSimulations\", True)\n</code></pre>"},{"location":"reference/systems/index.html","title":"systems","text":""},{"location":"reference/systems/macro_particle_system.html","title":"macro_particle_system","text":""},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem","title":"<code>MacroParticleSystem</code>","text":"<p>         Bases: <code>BaseSystem</code></p> <p>Global system for modeling \"macro\" level particles, e.g.: dirt, dust, etc.</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>class MacroParticleSystem(BaseSystem):\n\"\"\"\n    Global system for modeling \"macro\" level particles, e.g.: dirt, dust, etc.\n    \"\"\"\n# Template object to use -- this should be some instance of BasePrim. This will be the\n# object that symbolizes a single particle, and will be duplicated to generate the particle system.\n# Note that this object is NOT part of the actual particle system itself!\nparticle_object = None\n# dict, array of particle objects, mapped by their prim names\nparticles = None\n# Scaling factor to sample from when generating a new particle\nmin_scale = None              # (x,y,z) scaling\nmax_scale = None              # (x,y,z) scaling\n# Color associated with this system (NOTE: external queries should call cls.color)\n_color = None\n@classmethod\ndef initialize(cls):\n# Run super method first\nsuper().initialize()\n# Initialize mutable class variables so they don't automatically get overridden by children classes\ncls.particles = dict()\ncls.min_scale = np.ones(3)\ncls.max_scale = np.ones(3)\n# Create the system prim -- this is merely a scope prim\nog.sim.stage.DefinePrim(f\"/World/{cls.name}\", \"Scope\")\n# Load the particle template, and make it kinematic only because it's not interacting with anything\nparticle_template = cls._create_particle_template()\nog.sim.import_object(obj=particle_template, register=False, auto_initialize=True)\nparticle_template.kinematic_only = True\n# Make sure there is no ambiguity about which mesh to use as the particle from this template\nassert len(particle_template.links) == 1, \"MacroParticleSystem particle template has more than one link\"\nassert len(particle_template.root_link.visual_meshes) == 1, \"MacroParticleSystem particle template has more than one visual mesh\"\n# Class particle objet is assumed to be the first and only visual mesh belonging to the root link\ntemplate = list(particle_template.root_link.visual_meshes.values())[0]\ntemplate.material.shader_force_populate(render=True)\ncls.set_particle_template_object(obj=template)\n@classproperty\ndef particle_idns(cls):\n\"\"\"\n        Returns:\n            set: idn of all the particles across all groups.\n        \"\"\"\nreturn {cls.particle_name2idn(particle_name) for particle_name in cls.particles}\n@classproperty\ndef next_available_particle_idn(cls):\n\"\"\"\n        Returns:\n            int: the next available particle idn across all groups.\n        \"\"\"\nif cls.n_particles == 0:\nreturn 0\nelse:\n# We don't fill in any holes, just simply use the next subsequent integer after the largest\n# current ID\nreturn max(cls.particle_idns) + 1\n@classmethod\ndef _create_particle_template(cls):\n\"\"\"\n        Creates the particle template to be used for this system.\n        NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n            visual mesh attached to its root link, since this will be the actual visual mesh used\n        Returns:\n            EntityPrim: Particle template that will be duplicated when generating future particle groups\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef reset(cls):\n# Call super first\nsuper().reset()\n# Reset all internal variables\ncls.remove_all_particles()\n@classproperty\ndef n_particles(cls):\n\"\"\"\n        Returns:\n            int: Number of active particles in this system\n        \"\"\"\nreturn len(cls.particles)\n@classproperty\ndef particle_name_prefix(cls):\n\"\"\"\n        Returns:\n            str: Naming prefix used for all generated particles. This is coupled with the unique particle ID to generate\n                the full particle name\n        \"\"\"\nreturn f\"{cls.name}Particle\"\n@classproperty\ndef state_size(cls):\n# We have n_particles (1), each particle pose (7*n), scale (3*n), and\n# possibly template pose (7), and template scale (3)\nstate_size = 10 * cls.n_particles + 1\nreturn state_size if cls.particle_object is None else state_size + 10\n@classmethod\ndef _dump_state(cls):\nreturn dict(\nn_particles=cls.n_particles,\nposes=[particle.get_local_pose() for particle in cls.particles.values()],\nscales=[particle.scale for particle in cls.particles.values()],\ntemplate_pose=cls.particle_object.get_local_pose() if cls.particle_object is not None else None,\ntemplate_scale=cls.particle_object.scale if cls.particle_object is not None else None,\n)\n@classmethod\ndef _load_state(cls, state):\n\"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to set\n        \"\"\"\n# Sanity check loading particles\nassert cls.n_particles == state[\"n_particles\"], f\"Inconsistent number of particles found when loading \" \\\n                                                        f\"particles state! Current number: {cls.n_particles}, \" \\\n                                                        f\"loaded number: {state['n_particles']}\"\n# Load the poses and scales\nfor particle, pose, scale in zip(cls.particles.values(), state[\"poses\"], state[\"scales\"]):\nparticle.set_local_pose(*pose)\nparticle.scale = scale\n# Load template pose and scale if it exists\nif state[\"template_pose\"] is not None:\ncls.particle_object.set_local_pose(*state[\"template_pose\"])\ncls.particle_object.scale = state[\"template_scale\"]\n@classmethod\ndef _serialize(cls, state):\n# Array is n_particles + poses for all particles, then the template info\nstates_flat = [\n[state[\"n_particles\"]],\n*[np.concatenate(pose) for pose in state[\"poses\"]],\n*state[\"scales\"]\n]\n# Optionally add template pose and scale if it's not None\nif state[\"template_pose\"] is not None:\nstates_flat += [*state[\"template_pose\"], state[\"template_scale\"]]\nreturn np.concatenate(states_flat).astype(float)\n@classmethod\ndef _deserialize(cls, state):\n# First index is number of particles, rest are the individual particle poses\nstate_dict = dict()\nn_particles = int(state[0])\nstate_dict[\"n_particles\"] = n_particles\nposes, scales = [], []\npose_offset_idx = 1                                 # This is where the pose info begins in the flattened array\nscale_offset_idx = n_particles * 7 + pose_offset_idx  # This is where the scale info begins in the flattened array\nfor i in range(n_particles):\nposes.append([\nstate[7*i + pose_offset_idx: 7*i + pose_offset_idx + 3],\nstate[7*i + pose_offset_idx + 3: 7*(i+1) + pose_offset_idx]\n])      # pos, ori\nscales.append(state[3*i + scale_offset_idx : 3*(i + 1) + scale_offset_idx])      # scale\nstate_dict[\"poses\"] = poses\nstate_dict[\"scales\"] = scales\n# Update idx - 1 for n_particles + 10*n_particles for pose + scale\nidx = 1 + n_particles * 10\ntemplate_pose, template_scale = None, None\n# If our state size is larger than the current index we're at, this corresponds to the template info\nif cls.state_size &gt; idx:\ntemplate_pose = [\nstate[idx: idx + 3],\nstate[idx + 3: idx + 7],\n]\ntemplate_scale = state[idx + 7: idx + 10]\nidx += 10\nstate_dict[\"template_pose\"] = template_pose\nstate_dict[\"template_scale\"] = template_scale\nreturn state_dict, idx\n@classmethod\ndef set_particle_template_object(cls, obj):\n\"\"\"\n        Sets the template particle object that will be used for duplication purposes. Note that this automatically\n        adds @obj itself to the ongoing array of particles!\n        Args:\n            obj (BasePrim): Object to serve as template\n        \"\"\"\n# Update color if it exists and store particle object\ncolor = np.ones(3)\nif obj.has_material():\ndiffuse_texture = obj.material.diffuse_texture\ncolor = plt.imread(diffuse_texture).mean(axis=(0, 1)) if diffuse_texture else obj.material.diffuse_color_constant\ncls._color = color\ncls.particle_object = obj\n@classmethod\ndef set_scale_limits(cls, minimum=None, maximum=None):\n\"\"\"\n        Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n        Args:\n            minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n                particles\n            maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n                particles\n        \"\"\"\nif minimum is not None:\ncls.min_scale = np.array(minimum)\nif maximum is not None:\ncls.max_scale = np.array(maximum)\n@classmethod\ndef remove_all_particles(cls):\n\"\"\"\n        Removes all particles and deletes them from the simulator\n        \"\"\"\n# Use list explicitly to prevent mid-loop mutation of dict\nfor particle_name in list(cls.particles.keys()):\ncls.remove_particle(name=particle_name)\n@classmethod\ndef add_particle(cls, prim_path, idn=None, scale=None, position=None, orientation=None):\n\"\"\"\n        Adds a particle to this system.\n        Args:\n            prim_path (str): Absolute path to the newly created particle, minus the name for this particle\n            idn (None or int): If specified, should be unique identifier to assign to this particle. If not, will\n                automatically generate a new unique one\n            scale (None or 3-array): Relative (x,y,z) scale of the particle, if any. If not specified, will\n                automatically be sampled based on cls.min_scale and cls.max_scale\n            position (None or 3-array): Global (x,y,z) position to set this particle to, if any\n            orientation (None or 4-array): Global (x,y,z,w) quaternion orientation to set this particle to, if any\n        Returns:\n            XFormPrim: Newly created particle instance, which is added internally as well\n        \"\"\"\n# Generate the new particle\nname = cls.particle_idn2name(idn=cls.next_available_particle_idn if idn is None else idn)\n# Make sure name doesn't already exist\nassert name not in cls.particles.keys(), f\"Cannot create particle with name {name} because it already exists!\"\nnew_particle = cls._load_new_particle(prim_path=f\"{prim_path}/{name}\", name=name)\n# Sample the scale and also make sure the particle is visible\nnew_particle.scale *= np.random.uniform(cls.min_scale, cls.max_scale) if scale is None else scale\nnew_particle.visible = True\n# Set the pose\nnew_particle.set_position_orientation(position=position, orientation=orientation)\n# Track this particle as well\ncls.particles[new_particle.name] = new_particle\nreturn new_particle\n@classmethod\ndef remove_particle(cls, name):\n\"\"\"\n        Remove particle with name @name from both the simulator as well as internally\n        Args:\n            name (str): Name of the particle to remove\n        \"\"\"\nassert name in cls.particles, f\"Got invalid name for particle to remove {name}\"\nparticle = cls.particles.pop(name)\nparticle.remove()\n@classmethod\ndef _load_new_particle(cls, prim_path, name):\n\"\"\"\n        Loads a new particle into the current stage, leveraging @cls.particle_object as a template for the new particle\n        to load. This function should be implemented by any subclasses.\n        Args:\n            prim_path (str): The absolute stage path at which to create the new particle\n            name (str): The name to assign to this new particle at the path\n        Returns:\n            XFormPrim: Loaded particle\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef particle_name2idn(cls, name):\n\"\"\"\n        Args:\n            name (str): Particle name to grab its corresponding unique id number for\n        Returns:\n            int: Unique ID assigned to the particle based on its name\n        \"\"\"\nassert cls.particle_name_prefix in name, \\\n            f\"Particle name should have '{cls.particle_name_prefix}' in it when checking ID! Got: {name}\"\nreturn int(name.split(cls.particle_name_prefix)[-1])\n@classmethod\ndef particle_idn2name(cls, idn):\n\"\"\"\n        Args:\n            idn (int): Unique ID number assigned to the particle to grab the name for\n        Returns:\n            str: Particle name corresponding to its unique id number\n        \"\"\"\nassert isinstance(idn, int), \\\n            f\"Particle idn must be an integer when checking name! Got: {idn}. Type: {type(idn)}\"\nreturn f\"{cls.particle_name_prefix}{idn}\"\n@classproperty\ndef color(cls):\nreturn np.array(cls._color)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.add_particle","title":"<code>add_particle(prim_path, idn=None, scale=None, position=None, orientation=None)</code>  <code>classmethod</code>","text":"<p>Adds a particle to this system.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Absolute path to the newly created particle, minus the name for this particle</p> required <code>idn</code> <code>None or int</code> <p>If specified, should be unique identifier to assign to this particle. If not, will automatically generate a new unique one</p> <code>None</code> <code>scale</code> <code>None or 3-array</code> <p>Relative (x,y,z) scale of the particle, if any. If not specified, will automatically be sampled based on cls.min_scale and cls.max_scale</p> <code>None</code> <code>position</code> <code>None or 3-array</code> <p>Global (x,y,z) position to set this particle to, if any</p> <code>None</code> <code>orientation</code> <code>None or 4-array</code> <p>Global (x,y,z,w) quaternion orientation to set this particle to, if any</p> <code>None</code> <p>Returns:</p> Name Type Description <code>XFormPrim</code> <p>Newly created particle instance, which is added internally as well</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef add_particle(cls, prim_path, idn=None, scale=None, position=None, orientation=None):\n\"\"\"\n    Adds a particle to this system.\n    Args:\n        prim_path (str): Absolute path to the newly created particle, minus the name for this particle\n        idn (None or int): If specified, should be unique identifier to assign to this particle. If not, will\n            automatically generate a new unique one\n        scale (None or 3-array): Relative (x,y,z) scale of the particle, if any. If not specified, will\n            automatically be sampled based on cls.min_scale and cls.max_scale\n        position (None or 3-array): Global (x,y,z) position to set this particle to, if any\n        orientation (None or 4-array): Global (x,y,z,w) quaternion orientation to set this particle to, if any\n    Returns:\n        XFormPrim: Newly created particle instance, which is added internally as well\n    \"\"\"\n# Generate the new particle\nname = cls.particle_idn2name(idn=cls.next_available_particle_idn if idn is None else idn)\n# Make sure name doesn't already exist\nassert name not in cls.particles.keys(), f\"Cannot create particle with name {name} because it already exists!\"\nnew_particle = cls._load_new_particle(prim_path=f\"{prim_path}/{name}\", name=name)\n# Sample the scale and also make sure the particle is visible\nnew_particle.scale *= np.random.uniform(cls.min_scale, cls.max_scale) if scale is None else scale\nnew_particle.visible = True\n# Set the pose\nnew_particle.set_position_orientation(position=position, orientation=orientation)\n# Track this particle as well\ncls.particles[new_particle.name] = new_particle\nreturn new_particle\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.n_particles","title":"<code>n_particles()</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of active particles in this system</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef n_particles(cls):\n\"\"\"\n    Returns:\n        int: Number of active particles in this system\n    \"\"\"\nreturn len(cls.particles)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.next_available_particle_idn","title":"<code>next_available_particle_idn()</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>the next available particle idn across all groups.</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef next_available_particle_idn(cls):\n\"\"\"\n    Returns:\n        int: the next available particle idn across all groups.\n    \"\"\"\nif cls.n_particles == 0:\nreturn 0\nelse:\n# We don't fill in any holes, just simply use the next subsequent integer after the largest\n# current ID\nreturn max(cls.particle_idns) + 1\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.particle_idn2name","title":"<code>particle_idn2name(idn)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>idn</code> <code>int</code> <p>Unique ID number assigned to the particle to grab the name for</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Particle name corresponding to its unique id number</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef particle_idn2name(cls, idn):\n\"\"\"\n    Args:\n        idn (int): Unique ID number assigned to the particle to grab the name for\n    Returns:\n        str: Particle name corresponding to its unique id number\n    \"\"\"\nassert isinstance(idn, int), \\\n        f\"Particle idn must be an integer when checking name! Got: {idn}. Type: {type(idn)}\"\nreturn f\"{cls.particle_name_prefix}{idn}\"\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.particle_idns","title":"<code>particle_idns()</code>","text":"<p>Returns:</p> Name Type Description <code>set</code> <p>idn of all the particles across all groups.</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef particle_idns(cls):\n\"\"\"\n    Returns:\n        set: idn of all the particles across all groups.\n    \"\"\"\nreturn {cls.particle_name2idn(particle_name) for particle_name in cls.particles}\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.particle_name2idn","title":"<code>particle_name2idn(name)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Particle name to grab its corresponding unique id number for</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>Unique ID assigned to the particle based on its name</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef particle_name2idn(cls, name):\n\"\"\"\n    Args:\n        name (str): Particle name to grab its corresponding unique id number for\n    Returns:\n        int: Unique ID assigned to the particle based on its name\n    \"\"\"\nassert cls.particle_name_prefix in name, \\\n        f\"Particle name should have '{cls.particle_name_prefix}' in it when checking ID! Got: {name}\"\nreturn int(name.split(cls.particle_name_prefix)[-1])\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.particle_name_prefix","title":"<code>particle_name_prefix()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Naming prefix used for all generated particles. This is coupled with the unique particle ID to generate the full particle name</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef particle_name_prefix(cls):\n\"\"\"\n    Returns:\n        str: Naming prefix used for all generated particles. This is coupled with the unique particle ID to generate\n            the full particle name\n    \"\"\"\nreturn f\"{cls.name}Particle\"\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.remove_all_particles","title":"<code>remove_all_particles()</code>  <code>classmethod</code>","text":"<p>Removes all particles and deletes them from the simulator</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_all_particles(cls):\n\"\"\"\n    Removes all particles and deletes them from the simulator\n    \"\"\"\n# Use list explicitly to prevent mid-loop mutation of dict\nfor particle_name in list(cls.particles.keys()):\ncls.remove_particle(name=particle_name)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.remove_particle","title":"<code>remove_particle(name)</code>  <code>classmethod</code>","text":"<p>Remove particle with name @name from both the simulator as well as internally</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the particle to remove</p> required Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_particle(cls, name):\n\"\"\"\n    Remove particle with name @name from both the simulator as well as internally\n    Args:\n        name (str): Name of the particle to remove\n    \"\"\"\nassert name in cls.particles, f\"Got invalid name for particle to remove {name}\"\nparticle = cls.particles.pop(name)\nparticle.remove()\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.set_particle_template_object","title":"<code>set_particle_template_object(obj)</code>  <code>classmethod</code>","text":"<p>Sets the template particle object that will be used for duplication purposes. Note that this automatically adds @obj itself to the ongoing array of particles!</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BasePrim</code> <p>Object to serve as template</p> required Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef set_particle_template_object(cls, obj):\n\"\"\"\n    Sets the template particle object that will be used for duplication purposes. Note that this automatically\n    adds @obj itself to the ongoing array of particles!\n    Args:\n        obj (BasePrim): Object to serve as template\n    \"\"\"\n# Update color if it exists and store particle object\ncolor = np.ones(3)\nif obj.has_material():\ndiffuse_texture = obj.material.diffuse_texture\ncolor = plt.imread(diffuse_texture).mean(axis=(0, 1)) if diffuse_texture else obj.material.diffuse_color_constant\ncls._color = color\ncls.particle_object = obj\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.set_scale_limits","title":"<code>set_scale_limits(minimum=None, maximum=None)</code>  <code>classmethod</code>","text":"<p>Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles</p> <p>Parameters:</p> Name Type Description Default <code>minimum</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) minimum scaling factor to apply to generated particles</p> <code>None</code> <code>maximum</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) maximum scaling factor to apply to generated particles</p> <code>None</code> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef set_scale_limits(cls, minimum=None, maximum=None):\n\"\"\"\n    Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n    Args:\n        minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n            particles\n        maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n            particles\n    \"\"\"\nif minimum is not None:\ncls.min_scale = np.array(minimum)\nif maximum is not None:\ncls.max_scale = np.array(maximum)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem","title":"<code>VisualParticleSystem</code>","text":"<p>         Bases: <code>MacroParticleSystem</code></p> <p>Particle system class that additionally includes sampling utilities for placing particles on specific objects</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>class VisualParticleSystem(MacroParticleSystem):\n\"\"\"\n    Particle system class that additionally includes sampling utilities for placing particles on specific objects\n    \"\"\"\n# Maps group name to the particles associated with it\n# This is an ordered dict of ordered dict (nested ordered dict maps particle names to particle instance)\n_group_particles = None\n# Maps group name to the parent object (the object with particles attached to it) of the group\n_group_objects = None\n# Maps particle name to dict of {obj, link}\n_particles_info = None\n# Pre-cached information about visual particles so that we have efficient runtime computations\n# Maps particle name to local pose matrix for computing global poses for the particle\n_particles_local_mat = None\n# Default behavior for this class -- whether to clip generated particles halfway into objects when sampling\n# their locations on the surface of the given object\n_CLIP_INTO_OBJECTS = False\n# Default parameters for sampling particle locations\n# See omnigibson/utils/sampling_utils.py for how they are used.\n_SAMPLING_AXIS_PROBABILITIES = (0.25, 0.25, 0.5)\n_SAMPLING_AABB_OFFSET = 0.01\n_SAMPLING_BIMODAL_MEAN_FRACTION = 0.9\n_SAMPLING_BIMODAL_STDEV_FRACTION = 0.2\n_SAMPLING_MAX_ATTEMPTS = 20\n@classmethod\ndef initialize(cls):\n# Run super method first\nsuper().initialize()\n# Initialize mutable class variables so they don't automatically get overridden by children classes\ncls._group_particles = dict()\ncls._group_objects = dict()\ncls._particles_info = dict()\ncls._particles_local_mat = dict()\n@classproperty\ndef groups(cls):\n\"\"\"\n        Returns:\n            set of str: Current attachment particle group names\n        \"\"\"\nreturn set(cls._group_particles.keys())\n@classproperty\ndef state_size(cls):\n# Get super size first\nstate_size = super().state_size\n# Additionally, we have n_groups (1), with m_particles for each group (n), attached_obj_uuids (n), and\n# particle ids and corresponding link info for each particle (m * 2)\nreturn state_size + 1 + 2 * len(cls._group_particles) + \\\n               sum(2 * cls.num_group_particles(group) for group in cls.groups)\n@classmethod\ndef _load_new_particle(cls, prim_path, name):\n# We copy the template prim and generate the new object if the prim doesn't already exist, otherwise we\n# reference the pre-existing one\nif not get_prim_at_path(prim_path):\nomni.kit.commands.execute(\n\"CopyPrim\",\npath_from=cls.particle_object.prim_path,\npath_to=prim_path,\n)\nreturn VisualGeomPrim(prim_path=prim_path, name=name)\n@classmethod\ndef set_particle_template_object(cls, obj):\n# Sanity check to make sure the added object is an instance of VisualGeomPrim\nassert isinstance(obj, VisualGeomPrim), \\\n            f\"Particle template object for {cls.name} must be a VisualGeomPrim instance!\"\n# Run super method\nsuper().set_particle_template_object(obj=obj)\n@classmethod\ndef clear(cls):\n# Run super method first\nsuper().clear()\n# Clear all groups as well\ncls._group_particles = dict()\ncls._group_objects = dict()\ncls._particles_info = dict()\ncls._particles_local_mat = dict()\n@classmethod\ndef remove_particle(cls, name):\n\"\"\"\n        Remove particle with name @name from both the simulator and internal state\n        Args:\n            name (str): Name of the particle to remove\n        \"\"\"\n# Run super first\nsuper().remove_particle(name=name)\n# Remove this particle from its respective group as well\ncls._group_particles[cls._particles_info[name][\"obj\"].name].pop(name)\ncls._particles_info.pop(name)\ncls._particles_local_mat.pop(name)\n@classmethod\ndef remove_all_group_particles(cls, group):\n\"\"\"\n        Remove particle with name @name from both the simulator as well as internally\n        Args:\n            group (str): Name of the attachment group to remove all particles from\n        \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Remove all particles from the group\nfor particle_name in list(cls._group_particles[group].keys()):\ncls.remove_particle(name=particle_name)\n@classmethod\ndef num_group_particles(cls, group):\n\"\"\"\n        Gets the number of particles for the given group in the simulator\n        Args:\n            group (str): Name of the attachment group to remove all particles from.\n        Returns:\n            int: Number of particles allocated to this group in the scene. Note that if @group does not\n                exist, this will return 0\n        \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\nreturn len(cls._group_particles[group])\n@classmethod\ndef get_group_name(cls, obj):\n\"\"\"\n        Grabs the corresponding group name for object @obj\n        Args:\n            obj (BaseObject): Object for which its procedurally generated particle attachment name should be grabbed\n        Returns:\n            str: Name of the attachment group to use when executing commands from this class on\n                that specific attachment group\n        \"\"\"\nreturn obj.name\n@classmethod\ndef create_attachment_group(cls, obj):\n\"\"\"\n        Creates an attachment group internally for object @obj. Note that this does NOT automatically generate particles\n        for this object (should call generate_group_particles(...) ).\n        Args:\n            obj (BaseObject): Object for which a new particle attachment group will be created for\n        Returns:\n            str: Name of the attachment group to use when executing commands from this class on\n                that specific attachment group\n        \"\"\"\ngroup = cls.get_group_name(obj=obj)\n# This should only happen once for a single attachment group, so we explicitly check to make sure the object\n# doesn't already exist\nassert group not in cls.groups, \\\n            f\"Cannot create new attachment group because group with name {group} already exists!\"\n# Create the group\ncls._group_particles[group] = dict()\ncls._group_objects[group] = obj\nreturn group\n@classmethod\ndef remove_attachment_group(cls, group):\n\"\"\"\n        Removes an attachment group internally for object @obj. Note that this will automatically remove any particles\n        currently assigned to that group\n        Args:\n            group (str): Name of the attachment group to remove\n        Returns:\n            str: Name of the attachment group to use when executing commands from this class on\n                that specific attachment group\n        \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Remove all particles from the group\ncls.remove_all_group_particles(group=group)\n# Remove the actual groups\ncls._group_particles.pop(group)\ncls._group_objects.pop(group)\nreturn group\n@classmethod\ndef update_particle_scaling(cls, group):\n\"\"\"\n        Update particle scaling for group @group before generating group particles. Default is a no-op\n        (i.e.: returns the current cls.min_scale, cls.max_scale)\n        Args:\n            group (str): Specific group for which to modify the particle scaling\n        Returns:\n            2-tuple:\n                - 3-array: min scaling factor to set\n                - 3-array: max scaling factor to set\n        \"\"\"\nreturn cls.min_scale, cls.max_scale\n@classmethod\ndef sample_scales(cls, group, n):\n\"\"\"\n        Samples @n particle scales for group @group.\n        Args:\n            group (str): Specific group for which to sample scales\n            n (int): Number of scales to sample\n        Returns:\n            (n, 3) array: Array of sampled scales\n        \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Update scaling and grab object\ncls.set_scale_limits(*cls.update_particle_scaling(group=group))\nobj = cls._group_objects[group]\n# Sample scales of the particles to generate\n# Since the particles will be placed under the object, it will be affected/stretched by obj.scale. In order to\n# preserve the absolute size of the particles, we need to scale the particle by obj.scale in some way. However,\n# since the particles have a relative rotation w.r.t the object, the scale between the two don't align. As a\n# heuristics, we divide it by the avg_scale, which is the cubic root of the product of the scales along 3 axes.\navg_scale = np.cbrt(np.product(obj.scale))\nreturn np.random.uniform(cls.min_scale, cls.max_scale, (n, 3)) / avg_scale\n@classmethod\ndef generate_group_particles(\ncls,\ngroup,\npositions,\norientations=None,\nscales=None,\nlink_prim_paths=None,\n):\n\"\"\"\n        Generates new particle objects within group @group at the specified pose (@positions, @orientations) with\n        corresponding scales @scales.\n        NOTE: Assumes positions are the exact contact point on @group object's surface. If cls._CLIP_INTO_OBJECTS\n            is not True, then the positions will be offset away from the object by half of its bbox\n        Args:\n            group (str): Object on which to sample particle locations\n            positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions\n            orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n                orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n            scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scaling in its\n                local frame. If not specified, all we randomly sampled based on @cls.min_scale and @cls.max_scale\n            link_prim_paths (None or list of str): Determines which link each generated particle will\n                be attached to. If not specified, all will be attached to the group object's root link\n        \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Update scaling\ncls.set_scale_limits(*cls.update_particle_scaling(group=group))\n# Standardize orientations and links\nobj = cls._group_objects[group]\nn_particles = positions.shape[0]\nif orientations is None:\norientations = np.zeros((n_particles, 4))\norientations[:, -1] = 1.0\nlink_prim_paths = [obj.root_link.prim_path] * n_particles if link_prim_paths is None else link_prim_paths\nif scales is None:\nscales = cls.sample_scales(group=group, n=n_particles)\nbbox_extents_local = [(cls.particle_object.aabb_extent * scale).tolist() for scale in scales]\n# If we're using flatcache, we need to update the object's pose on the USD manually\nif gm.ENABLE_FLATCACHE:\nFlatcacheAPI.sync_raw_object_transforms_in_usd(prim=obj)\n# Generate particles\nz_up = np.zeros((3, 1))\nz_up[-1] = 1.0\nfor position, orientation, scale, bbox_extent_local, link_prim_path in \\\n                zip(positions, orientations, scales, bbox_extents_local, link_prim_paths):\nlink_name = link_prim_path.split(\"/\")[-1]\nlink = obj.links[link_name]\n# Possibly shift the particle slightly away from the object if we're not clipping into objects\nif cls._CLIP_INTO_OBJECTS:\n# Shift the particle halfway down\nbase_to_center = bbox_extent_local[2] / 2.0\nnormal = (T.quat2mat(orientation) @ z_up).flatten()\nposition -= normal * base_to_center\n# Create particle\nparticle = cls.add_particle(\nprim_path=link_prim_path,\nposition=position,\norientation=orientation,\nscale=scale,\n)\n# Add to group\ncls._group_particles[group][particle.name] = particle\ncls._particles_info[particle.name] = dict(obj=cls._group_objects[group], link=link)\n# Update particle local matrix\ncls._particles_local_mat[particle.name] = cls._compute_particle_local_mat(name=particle.name)\n@classmethod\ndef generate_group_particles_on_object(cls, group, max_samples, min_samples_for_success=1):\n\"\"\"\n        Generates @max_samples new particle objects and samples their locations on the surface of object @obj. Note\n        that if any particles are in the group already, they will be removed\n        Args:\n            group (str): Object on which to sample particle locations\n            max_samples (int): Maximum number of particles to sample\n            min_samples_for_success (int): Minimum number of particles required to be sampled successfully in order\n                for this generation process to be considered successful\n        Returns:\n            bool: True if enough particles were generated successfully (number of successfully sampled points &gt;=\n                min_samples_for_success), otherwise False\n        \"\"\"\nassert max_samples &gt;= min_samples_for_success, \"number of particles to sample should exceed the min for success\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Remove all stale particles\ncls.remove_all_group_particles(group=group)\n# Generate requested number of particles\nobj = cls._group_objects[group]\n# Sample scales and corresponding bbox extents\nscales = cls.sample_scales(group=group, n=max_samples)\n# For sampling particle positions, we need the global bbox extents, NOT the local extents\n# which is what we would get naively if we directly use @scales\navg_scale = np.cbrt(np.product(obj.scale))\nbbox_extents_global = scales * cls.particle_object.aabb_extent.reshape(1, 3) * avg_scale\n# Sample locations for all particles\n# TODO: Does simulation need to play at this point in time? Answer: yes\nresults = sample_cuboid_on_object_symmetric_bimodal_distribution(\nobj=obj,\nnum_samples=max_samples,\ncuboid_dimensions=bbox_extents_global,\nbimodal_mean_fraction=cls._SAMPLING_BIMODAL_MEAN_FRACTION,\nbimodal_stdev_fraction=cls._SAMPLING_BIMODAL_STDEV_FRACTION,\naxis_probabilities=cls._SAMPLING_AXIS_PROBABILITIES,\nundo_cuboid_bottom_padding=True,\nverify_cuboid_empty=False,\naabb_offset=cls._SAMPLING_AABB_OFFSET,\nmax_sampling_attempts=cls._SAMPLING_MAX_ATTEMPTS,\nrefuse_downwards=True,\n)\n# Use sampled points\npositions, orientations, particle_scales, link_prim_paths = [], [], [], []\nfor result, scale in zip(results, scales):\nposition, normal, quaternion, hit_link, reasons = result\nif position is not None:\npositions.append(position)\norientations.append(quaternion)\nparticle_scales.append(scale)\nlink_prim_paths.append(hit_link)\nsuccess = len(positions) &gt;= min_samples_for_success\n# If we generated a sufficient number of points, generate them in the simulator\nif success:\ncls.generate_group_particles(\ngroup=group,\npositions=np.array(positions),\norientations=np.array(orientations),\nscales=np.array(scales),\nlink_prim_paths=link_prim_paths,\n)\nreturn success\n@classmethod\ndef get_particles_position_orientation(cls):\n\"\"\"\n        Computes all particles' global positions and orientations that belong to this system\n        Note: This is more optimized than doing a for loop with self.get_particle_position_orientation()\n        Returns:\n            2-tuple:\n                - (n, 3)-array: per-particle (x,y,z) position in the world frame\n                - (n, 4)-array: per-particle (x,y,z,w) quaternion orientation in the world frame\n        \"\"\"\n# Iterate over all particles and compute link tfs programmatically, then batch the matrix transform\nlink_tfs = dict()\nlink_tfs_batch = np.zeros((cls.n_particles, 4, 4))\nparticle_local_poses_batch = np.zeros_like(link_tfs_batch)\nfor i, name in enumerate(cls.particles):\nlink = cls._particles_info[name][\"link\"]\nif link in link_tfs:\nlink_tf = link_tfs[link]\nelse:\nlink_tf = T.pose2mat(link.get_position_orientation())\nlink_tfs[link] = link_tf\nlink_tfs_batch[i] = link_tf\nparticle_local_poses_batch[i] = cls._particles_local_mat[name]\n# Compute once\nglobal_poses = np.matmul(link_tfs_batch, particle_local_poses_batch)\n# Decompose back into positions and orientations\nreturn global_poses[:, :3, 3], T.mat2quat(global_poses[:, :3, :3])\n@classmethod\ndef get_particle_position_orientation(cls, name):\n\"\"\"\n        Compute particle's global position and orientation. This automatically takes into account the relative\n        pose w.r.t. its parent link and the global pose of that parent link.\n        Args:\n            name (str): Name of the particle to compute global position and orientation for\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) position in the world frame\n                - 4-array: (x,y,z,w) quaternion orientation in the world frame\n        \"\"\"\n# First, get local pose, scale it by the parent link's scale, and then convert into a matrix\nparent_link = cls._particles_info[name][\"link\"]\nlocal_mat = cls._particles_local_mat[name]\nlink_tf = T.pose2mat(parent_link.get_position_orientation())\n# Multiply the local pose by the link's global transform, then return as pos, quat tuple\nval = T.mat2pose(link_tf @ local_mat)\nreturn val\n@classmethod\ndef _compute_particle_local_mat(cls, name):\n\"\"\"\n        Computes particle @name's local transform as a homogeneous 4x4 matrix\n        Args:\n            name (str): Name of the particle to compute local transform matrix for\n        Returns:\n            np.array: (4, 4) homogeneous transform matrix\n        \"\"\"\nparticle = cls.particles[name]\nparent_link = cls._particles_info[name][\"link\"]\nlocal_pos, local_quat = particle.get_local_pose()\nreturn T.pose2mat((parent_link.scale * local_pos, local_quat))\n@classmethod\ndef _validate_group(cls, group):\n\"\"\"\n        Checks if particle attachment group @group exists. (If not, can create the group via create_attachment_group).\n        This will raise a ValueError if it doesn't exist.\n        Args:\n            group (str): Name of the group to check for\n        \"\"\"\nif group not in cls.groups:\nraise ValueError(f\"Particle attachment group {group} does not exist!\")\n@classmethod\ndef _sync_particle_groups(cls, group_objects, particle_idns, particle_attached_link_names):\n\"\"\"\n        Synchronizes the particle groups based on desired identification numbers @group_idns\n        Args:\n            group_objects (list of None or BaseObject): Desired unique group objects that should be active for\n            this particle system. Any objects that aren't found will be skipped over\n            particle_idns (list of list of int): Per-group unique id numbers for the particles assigned to that group.\n                List should be same length as @group_idns with sub-entries corresponding to the desired number of\n                particles assigned to that group\n            particle_attached_link_names (list of list of str): Per-group link names corresponding to the specific\n                links each particle is attached for each group. List should be same length as @group_idns with\n                sub-entries corresponding to the desired number of particles assigned to that group\n        \"\"\"\n# We have to be careful here -- some particle groups may have been deleted / are mismatched, so we need\n# to update accordingly, potentially deleting stale groups and creating new groups as needed\nname_to_info_mapping = {obj.name: {\n\"n_particles\": len(p_idns),\n\"particle_idns\": p_idns,\n\"link_names\": link_names,\n}\nfor obj, p_idns, link_names in\nzip(group_objects, particle_idns, particle_attached_link_names)}\ncurrent_group_names = cls.groups\ndesired_group_names = set(obj.name for obj in group_objects)\ngroups_to_delete = current_group_names - desired_group_names\ngroups_to_create = desired_group_names - current_group_names\ncommon_groups = current_group_names.intersection(desired_group_names)\n# Sanity check the common groups, we will recreate any where there is a mismatch\nfor name in common_groups:\ninfo = name_to_info_mapping[name]\nif cls.num_group_particles(group=name) != info[\"n_particles\"]:\nlog.debug(f\"Got mismatch in particle group {name} when syncing, \"\nf\"deleting and recreating group now.\")\n# Add this group to both the delete and creation pile\ngroups_to_delete.add(name)\ngroups_to_create.add(name)\n# Delete any groups we no longer want\nfor name in groups_to_delete:\ncls.remove_attachment_group(group=name)\n# Create any groups we don't already have\nfor name in groups_to_create:\nobj = og.sim.scene.object_registry(\"name\", name)\ninfo = name_to_info_mapping[name]\ncls.create_attachment_group(obj=obj)\nfor particle_idn, link_name in zip(info[\"particle_idns\"], info[\"link_names\"]):\n# Create the necessary particles\nparticle = cls.add_particle(\nprim_path=f\"{obj.prim_path}/{link_name}\",\nidn=int(particle_idn),\n)\ncls._group_particles[name][particle.name] = particle\ncls._particles_info[particle.name] = dict(obj=obj, link=obj.links[link_name])\n@classmethod\ndef create(cls, name, create_particle_template, min_scale=None, max_scale=None, **kwargs):\n\"\"\"\n        Utility function to programmatically generate monolithic visual particle system classes.\n        Note: If using super() calls in any functions, we have to use slightly esoteric syntax in order to\n        accommodate this procedural method for using super calls\n        cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\n            Use: super(cls).__get__(cls).&lt;METHOD_NAME&gt;(&lt;KWARGS&gt;)\n        Args:\n            name (str): Name of the visual particles, in snake case.\n            min_scale (None or 3-array): If specified, sets the minumum bound for the visual particles' relative scale.\n                Else, defaults to 1\n            max_scale (None or 3-array): If specified, sets the maximum bound for the visual particles' relative scale.\n                Else, defaults to 1\n            create_particle_template (function): Method for generating the visual particle template that will be duplicated\n                when generating groups of particles.\n                Expected signature:\n                create_particle_template(prim_path: str, name: str) --&gt; EntityPrim\n                where @prim_path and @name are the parameters to assign to the generated EntityPrim.\n                NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n                    visual mesh attached to its root link, since this will be the actual visual mesh used\n            **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n                the class attribute to modify and the values represent the functions / value to set\n                (Note: These values should have either @classproperty or @classmethod decorators!)\n        Returns:\n            VisualParticleSystem: Generated visual particle system class\n        \"\"\"\n# Override the necessary parameters\n@classproperty\ndef cp_register_system(cls):\n# We should register this system since it's an \"actual\" system (not an intermediate class)\nreturn True\n@classmethod\ndef cm_initialize(cls):\n# Run super first (we have to use a bit esoteric syntax in order to accommodate this procedural method for\n# using super calls -- cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\nsuper(cls).__get__(cls).initialize()\n# Potentially override the min / max scales\nif min_scale is not None:\ncls.min_scale = np.array(min_scale)\nif max_scale is not None:\ncls.max_scale = np.array(max_scale)\n@classmethod\ndef cm_create_particle_template(cls):\nreturn create_particle_template(prim_path=f\"{cls.prim_path}/template\", name=f\"{cls.name}_template\")\n# Add to any other params specified\nkwargs[\"_register_system\"] = cp_register_system\nkwargs[\"initialize\"] = cm_initialize\nkwargs[\"_create_particle_template\"] = cm_create_particle_template\n# Create and return the class\nreturn subclass_factory(name=snake_case_to_camel_case(name), base_classes=cls, **kwargs)\n@classmethod\ndef _dump_state(cls):\nstate = super()._dump_state()\n# Add in per-group information\ngroups_dict = dict()\nfor group_name, group_particles in cls._group_particles.items():\ngroups_dict[group_name] = dict(\nparticle_attached_obj_uuid=cls._group_objects[group_name].uuid,\nn_particles=cls.num_group_particles(group=group_name),\nparticle_idns=[cls.particle_name2idn(name=name) for name in group_particles.keys()],\nparticle_attached_link_names=[cls._particles_info[name][\"link\"].prim_path.split(\"/\")[-1] for name in group_particles.keys()],\n)\nstate[\"n_groups\"] = len(cls._group_particles)\nstate[\"groups\"] = groups_dict\nreturn state\n@classmethod\ndef _load_state(cls, state):\n# First, we sync our particle systems\n\"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to set\n        \"\"\"\n# Synchronize particle groups\ncls._sync_particle_groups(\ngroup_objects=[og.sim.scene.object_registry(\"uuid\", info[\"particle_attached_obj_uuid\"])\nfor info in state[\"groups\"].values()],\nparticle_idns=[info[\"particle_idns\"] for info in state[\"groups\"].values()],\nparticle_attached_link_names=[info[\"particle_attached_link_names\"] for info in state[\"groups\"].values()],\n)\n# Sanity check loading particles\nassert cls.n_particles == state[\"n_particles\"], f\"Inconsistent number of particles found when loading \" \\\n                                                        f\"particles state! Current number: {cls.n_particles}, \" \\\n                                                        f\"loaded number: {state['n_particles']}\"\n# Run super\nsuper()._load_state(state=state)\n# Make sure we update all the local transforms\nfor name in cls.particles:\ncls._particles_local_mat[name] = cls._compute_particle_local_mat(name=name)\n@classmethod\ndef _serialize(cls, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\ngroups_dict = state[\"groups\"]\nstate_group_flat = [[state[\"n_groups\"]]]\nfor group_name, group_dict in groups_dict.items():\ngroup_obj_link2id = {link_name: i for i, link_name in enumerate(cls._group_objects[group_name].links.keys())}\nstate_group_flat += [\n[group_dict[\"particle_attached_obj_uuid\"]],\n[group_dict[\"n_particles\"]],\ngroup_dict[\"particle_idns\"],\n[group_obj_link2id[link_name] for link_name in group_dict[\"particle_attached_link_names\"]],\n]\nreturn np.concatenate([*state_group_flat, state_flat]).astype(float)\n@classmethod\ndef _deserialize(cls, state):\n# Synchronize the particle groups\nn_groups = int(state[0])\ngroups_dict = dict()\ngroup_objs = []\n# Index starts at 1 because index 0 is n_groups\nidx = 1\nfor i in range(n_groups):\nobj_uuid, n_particles = int(state[idx]), int(state[idx + 1])\nobj = og.sim.scene.object_registry(\"uuid\", obj_uuid)\ngroup_obj_id2link = {i: link_name for i, link_name in enumerate(obj.links.keys())}\ngroup_objs.append(obj)\ngroups_dict[obj.name] = dict(\nparticle_attached_obj_uuid=obj_uuid,\nn_particles=n_particles,\nparticle_idns=[int(idn) for idn in state[idx + 2 : idx + 2 + n_particles]], # Idx + 2 because the first two are obj_uuid and n_particles\nparticle_attached_link_names=[group_obj_id2link[int(idn)] for idn in state[idx + 2 + n_particles : idx + 2 + n_particles * 2]],\n)\nidx += 2 + n_particles * 2\nlog.debug(f\"Syncing {cls.name} particles with {n_groups} groups..\")\ncls._sync_particle_groups(\ngroup_objects=group_objs,\nparticle_idns=[group_info[\"particle_idns\"] for group_info in groups_dict.values()],\nparticle_attached_link_names=[group_info[\"particle_attached_link_names\"] for group_info in groups_dict.values()],\n)\n# Get super method\nstate_dict, idx_super = super()._deserialize(state=state[idx:])\nstate_dict[\"groups\"] = groups_dict\nreturn state_dict, idx + idx_super\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.create","title":"<code>create(name, create_particle_template, min_scale=None, max_scale=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Utility function to programmatically generate monolithic visual particle system classes.</p> <p>Note: If using super() calls in any functions, we have to use slightly esoteric syntax in order to accommodate this procedural method for using super calls cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python     Use: super(cls).get(cls).() <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the visual particles, in snake case.</p> required <code>min_scale</code> <code>None or 3-array</code> <p>If specified, sets the minumum bound for the visual particles' relative scale. Else, defaults to 1</p> <code>None</code> <code>max_scale</code> <code>None or 3-array</code> <p>If specified, sets the maximum bound for the visual particles' relative scale. Else, defaults to 1</p> <code>None</code> <code>create_particle_template</code> <code>function</code> <p>Method for generating the visual particle template that will be duplicated when generating groups of particles. Expected signature:</p> <p>create_particle_template(prim_path: str, name: str) --&gt; EntityPrim</p> <p>where @prim_path and @name are the parameters to assign to the generated EntityPrim. NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single     visual mesh attached to its root link, since this will be the actual visual mesh used</p> required <code>**kwargs</code> <code>any</code> <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class attribute to modify and the values represent the functions / value to set (Note: These values should have either @classproperty or @classmethod decorators!)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>VisualParticleSystem</code> <p>Generated visual particle system class</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef create(cls, name, create_particle_template, min_scale=None, max_scale=None, **kwargs):\n\"\"\"\n    Utility function to programmatically generate monolithic visual particle system classes.\n    Note: If using super() calls in any functions, we have to use slightly esoteric syntax in order to\n    accommodate this procedural method for using super calls\n    cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\n        Use: super(cls).__get__(cls).&lt;METHOD_NAME&gt;(&lt;KWARGS&gt;)\n    Args:\n        name (str): Name of the visual particles, in snake case.\n        min_scale (None or 3-array): If specified, sets the minumum bound for the visual particles' relative scale.\n            Else, defaults to 1\n        max_scale (None or 3-array): If specified, sets the maximum bound for the visual particles' relative scale.\n            Else, defaults to 1\n        create_particle_template (function): Method for generating the visual particle template that will be duplicated\n            when generating groups of particles.\n            Expected signature:\n            create_particle_template(prim_path: str, name: str) --&gt; EntityPrim\n            where @prim_path and @name are the parameters to assign to the generated EntityPrim.\n            NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n                visual mesh attached to its root link, since this will be the actual visual mesh used\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class attribute to modify and the values represent the functions / value to set\n            (Note: These values should have either @classproperty or @classmethod decorators!)\n    Returns:\n        VisualParticleSystem: Generated visual particle system class\n    \"\"\"\n# Override the necessary parameters\n@classproperty\ndef cp_register_system(cls):\n# We should register this system since it's an \"actual\" system (not an intermediate class)\nreturn True\n@classmethod\ndef cm_initialize(cls):\n# Run super first (we have to use a bit esoteric syntax in order to accommodate this procedural method for\n# using super calls -- cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\nsuper(cls).__get__(cls).initialize()\n# Potentially override the min / max scales\nif min_scale is not None:\ncls.min_scale = np.array(min_scale)\nif max_scale is not None:\ncls.max_scale = np.array(max_scale)\n@classmethod\ndef cm_create_particle_template(cls):\nreturn create_particle_template(prim_path=f\"{cls.prim_path}/template\", name=f\"{cls.name}_template\")\n# Add to any other params specified\nkwargs[\"_register_system\"] = cp_register_system\nkwargs[\"initialize\"] = cm_initialize\nkwargs[\"_create_particle_template\"] = cm_create_particle_template\n# Create and return the class\nreturn subclass_factory(name=snake_case_to_camel_case(name), base_classes=cls, **kwargs)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.create_attachment_group","title":"<code>create_attachment_group(obj)</code>  <code>classmethod</code>","text":"<p>Creates an attachment group internally for object @obj. Note that this does NOT automatically generate particles for this object (should call generate_group_particles(...) ).</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object for which a new particle attachment group will be created for</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Name of the attachment group to use when executing commands from this class on that specific attachment group</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef create_attachment_group(cls, obj):\n\"\"\"\n    Creates an attachment group internally for object @obj. Note that this does NOT automatically generate particles\n    for this object (should call generate_group_particles(...) ).\n    Args:\n        obj (BaseObject): Object for which a new particle attachment group will be created for\n    Returns:\n        str: Name of the attachment group to use when executing commands from this class on\n            that specific attachment group\n    \"\"\"\ngroup = cls.get_group_name(obj=obj)\n# This should only happen once for a single attachment group, so we explicitly check to make sure the object\n# doesn't already exist\nassert group not in cls.groups, \\\n        f\"Cannot create new attachment group because group with name {group} already exists!\"\n# Create the group\ncls._group_particles[group] = dict()\ncls._group_objects[group] = obj\nreturn group\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.generate_group_particles","title":"<code>generate_group_particles(group, positions, orientations=None, scales=None, link_prim_paths=None)</code>  <code>classmethod</code>","text":"<p>Generates new particle objects within group @group at the specified pose (@positions, @orientations) with corresponding scales @scales.</p> Assumes positions are the exact contact point on @group object's surface. If cls._CLIP_INTO_OBJECTS <p>is not True, then the positions will be offset away from the object by half of its bbox</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>Object on which to sample particle locations</p> required <code>positions</code> <code>np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) positions</p> required <code>orientations</code> <code>None or np.array</code> <p>(n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)</p> <code>None</code> <code>scales</code> <code>None or np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) scaling in its local frame. If not specified, all we randomly sampled based on @cls.min_scale and @cls.max_scale</p> <code>None</code> <code>link_prim_paths</code> <code>None or list of str</code> <p>Determines which link each generated particle will be attached to. If not specified, all will be attached to the group object's root link</p> <code>None</code> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef generate_group_particles(\ncls,\ngroup,\npositions,\norientations=None,\nscales=None,\nlink_prim_paths=None,\n):\n\"\"\"\n    Generates new particle objects within group @group at the specified pose (@positions, @orientations) with\n    corresponding scales @scales.\n    NOTE: Assumes positions are the exact contact point on @group object's surface. If cls._CLIP_INTO_OBJECTS\n        is not True, then the positions will be offset away from the object by half of its bbox\n    Args:\n        group (str): Object on which to sample particle locations\n        positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions\n        orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n            orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scaling in its\n            local frame. If not specified, all we randomly sampled based on @cls.min_scale and @cls.max_scale\n        link_prim_paths (None or list of str): Determines which link each generated particle will\n            be attached to. If not specified, all will be attached to the group object's root link\n    \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Update scaling\ncls.set_scale_limits(*cls.update_particle_scaling(group=group))\n# Standardize orientations and links\nobj = cls._group_objects[group]\nn_particles = positions.shape[0]\nif orientations is None:\norientations = np.zeros((n_particles, 4))\norientations[:, -1] = 1.0\nlink_prim_paths = [obj.root_link.prim_path] * n_particles if link_prim_paths is None else link_prim_paths\nif scales is None:\nscales = cls.sample_scales(group=group, n=n_particles)\nbbox_extents_local = [(cls.particle_object.aabb_extent * scale).tolist() for scale in scales]\n# If we're using flatcache, we need to update the object's pose on the USD manually\nif gm.ENABLE_FLATCACHE:\nFlatcacheAPI.sync_raw_object_transforms_in_usd(prim=obj)\n# Generate particles\nz_up = np.zeros((3, 1))\nz_up[-1] = 1.0\nfor position, orientation, scale, bbox_extent_local, link_prim_path in \\\n            zip(positions, orientations, scales, bbox_extents_local, link_prim_paths):\nlink_name = link_prim_path.split(\"/\")[-1]\nlink = obj.links[link_name]\n# Possibly shift the particle slightly away from the object if we're not clipping into objects\nif cls._CLIP_INTO_OBJECTS:\n# Shift the particle halfway down\nbase_to_center = bbox_extent_local[2] / 2.0\nnormal = (T.quat2mat(orientation) @ z_up).flatten()\nposition -= normal * base_to_center\n# Create particle\nparticle = cls.add_particle(\nprim_path=link_prim_path,\nposition=position,\norientation=orientation,\nscale=scale,\n)\n# Add to group\ncls._group_particles[group][particle.name] = particle\ncls._particles_info[particle.name] = dict(obj=cls._group_objects[group], link=link)\n# Update particle local matrix\ncls._particles_local_mat[particle.name] = cls._compute_particle_local_mat(name=particle.name)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.generate_group_particles_on_object","title":"<code>generate_group_particles_on_object(group, max_samples, min_samples_for_success=1)</code>  <code>classmethod</code>","text":"<p>Generates @max_samples new particle objects and samples their locations on the surface of object @obj. Note that if any particles are in the group already, they will be removed</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>Object on which to sample particle locations</p> required <code>max_samples</code> <code>int</code> <p>Maximum number of particles to sample</p> required <code>min_samples_for_success</code> <code>int</code> <p>Minimum number of particles required to be sampled successfully in order for this generation process to be considered successful</p> <code>1</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if enough particles were generated successfully (number of successfully sampled points &gt;= min_samples_for_success), otherwise False</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef generate_group_particles_on_object(cls, group, max_samples, min_samples_for_success=1):\n\"\"\"\n    Generates @max_samples new particle objects and samples their locations on the surface of object @obj. Note\n    that if any particles are in the group already, they will be removed\n    Args:\n        group (str): Object on which to sample particle locations\n        max_samples (int): Maximum number of particles to sample\n        min_samples_for_success (int): Minimum number of particles required to be sampled successfully in order\n            for this generation process to be considered successful\n    Returns:\n        bool: True if enough particles were generated successfully (number of successfully sampled points &gt;=\n            min_samples_for_success), otherwise False\n    \"\"\"\nassert max_samples &gt;= min_samples_for_success, \"number of particles to sample should exceed the min for success\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Remove all stale particles\ncls.remove_all_group_particles(group=group)\n# Generate requested number of particles\nobj = cls._group_objects[group]\n# Sample scales and corresponding bbox extents\nscales = cls.sample_scales(group=group, n=max_samples)\n# For sampling particle positions, we need the global bbox extents, NOT the local extents\n# which is what we would get naively if we directly use @scales\navg_scale = np.cbrt(np.product(obj.scale))\nbbox_extents_global = scales * cls.particle_object.aabb_extent.reshape(1, 3) * avg_scale\n# Sample locations for all particles\n# TODO: Does simulation need to play at this point in time? Answer: yes\nresults = sample_cuboid_on_object_symmetric_bimodal_distribution(\nobj=obj,\nnum_samples=max_samples,\ncuboid_dimensions=bbox_extents_global,\nbimodal_mean_fraction=cls._SAMPLING_BIMODAL_MEAN_FRACTION,\nbimodal_stdev_fraction=cls._SAMPLING_BIMODAL_STDEV_FRACTION,\naxis_probabilities=cls._SAMPLING_AXIS_PROBABILITIES,\nundo_cuboid_bottom_padding=True,\nverify_cuboid_empty=False,\naabb_offset=cls._SAMPLING_AABB_OFFSET,\nmax_sampling_attempts=cls._SAMPLING_MAX_ATTEMPTS,\nrefuse_downwards=True,\n)\n# Use sampled points\npositions, orientations, particle_scales, link_prim_paths = [], [], [], []\nfor result, scale in zip(results, scales):\nposition, normal, quaternion, hit_link, reasons = result\nif position is not None:\npositions.append(position)\norientations.append(quaternion)\nparticle_scales.append(scale)\nlink_prim_paths.append(hit_link)\nsuccess = len(positions) &gt;= min_samples_for_success\n# If we generated a sufficient number of points, generate them in the simulator\nif success:\ncls.generate_group_particles(\ngroup=group,\npositions=np.array(positions),\norientations=np.array(orientations),\nscales=np.array(scales),\nlink_prim_paths=link_prim_paths,\n)\nreturn success\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.get_group_name","title":"<code>get_group_name(obj)</code>  <code>classmethod</code>","text":"<p>Grabs the corresponding group name for object @obj</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object for which its procedurally generated particle attachment name should be grabbed</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Name of the attachment group to use when executing commands from this class on that specific attachment group</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef get_group_name(cls, obj):\n\"\"\"\n    Grabs the corresponding group name for object @obj\n    Args:\n        obj (BaseObject): Object for which its procedurally generated particle attachment name should be grabbed\n    Returns:\n        str: Name of the attachment group to use when executing commands from this class on\n            that specific attachment group\n    \"\"\"\nreturn obj.name\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.get_particle_position_orientation","title":"<code>get_particle_position_orientation(name)</code>  <code>classmethod</code>","text":"<p>Compute particle's global position and orientation. This automatically takes into account the relative pose w.r.t. its parent link and the global pose of that parent link.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the particle to compute global position and orientation for</p> required <p>Returns:</p> Type Description <p>2-tuple: - 3-array: (x,y,z) position in the world frame - 4-array: (x,y,z,w) quaternion orientation in the world frame</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef get_particle_position_orientation(cls, name):\n\"\"\"\n    Compute particle's global position and orientation. This automatically takes into account the relative\n    pose w.r.t. its parent link and the global pose of that parent link.\n    Args:\n        name (str): Name of the particle to compute global position and orientation for\n    Returns:\n        2-tuple:\n            - 3-array: (x,y,z) position in the world frame\n            - 4-array: (x,y,z,w) quaternion orientation in the world frame\n    \"\"\"\n# First, get local pose, scale it by the parent link's scale, and then convert into a matrix\nparent_link = cls._particles_info[name][\"link\"]\nlocal_mat = cls._particles_local_mat[name]\nlink_tf = T.pose2mat(parent_link.get_position_orientation())\n# Multiply the local pose by the link's global transform, then return as pos, quat tuple\nval = T.mat2pose(link_tf @ local_mat)\nreturn val\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.get_particles_position_orientation","title":"<code>get_particles_position_orientation()</code>  <code>classmethod</code>","text":"<p>Computes all particles' global positions and orientations that belong to this system</p> <p>Note: This is more optimized than doing a for loop with self.get_particle_position_orientation()</p> <p>Returns:</p> Type Description <p>2-tuple: - (n, 3)-array: per-particle (x,y,z) position in the world frame - (n, 4)-array: per-particle (x,y,z,w) quaternion orientation in the world frame</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef get_particles_position_orientation(cls):\n\"\"\"\n    Computes all particles' global positions and orientations that belong to this system\n    Note: This is more optimized than doing a for loop with self.get_particle_position_orientation()\n    Returns:\n        2-tuple:\n            - (n, 3)-array: per-particle (x,y,z) position in the world frame\n            - (n, 4)-array: per-particle (x,y,z,w) quaternion orientation in the world frame\n    \"\"\"\n# Iterate over all particles and compute link tfs programmatically, then batch the matrix transform\nlink_tfs = dict()\nlink_tfs_batch = np.zeros((cls.n_particles, 4, 4))\nparticle_local_poses_batch = np.zeros_like(link_tfs_batch)\nfor i, name in enumerate(cls.particles):\nlink = cls._particles_info[name][\"link\"]\nif link in link_tfs:\nlink_tf = link_tfs[link]\nelse:\nlink_tf = T.pose2mat(link.get_position_orientation())\nlink_tfs[link] = link_tf\nlink_tfs_batch[i] = link_tf\nparticle_local_poses_batch[i] = cls._particles_local_mat[name]\n# Compute once\nglobal_poses = np.matmul(link_tfs_batch, particle_local_poses_batch)\n# Decompose back into positions and orientations\nreturn global_poses[:, :3, 3], T.mat2quat(global_poses[:, :3, :3])\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.groups","title":"<code>groups()</code>","text":"<p>Returns:</p> Type Description <p>set of str: Current attachment particle group names</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef groups(cls):\n\"\"\"\n    Returns:\n        set of str: Current attachment particle group names\n    \"\"\"\nreturn set(cls._group_particles.keys())\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.num_group_particles","title":"<code>num_group_particles(group)</code>  <code>classmethod</code>","text":"<p>Gets the number of particles for the given group in the simulator</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>Name of the attachment group to remove all particles from.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>Number of particles allocated to this group in the scene. Note that if @group does not exist, this will return 0</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef num_group_particles(cls, group):\n\"\"\"\n    Gets the number of particles for the given group in the simulator\n    Args:\n        group (str): Name of the attachment group to remove all particles from.\n    Returns:\n        int: Number of particles allocated to this group in the scene. Note that if @group does not\n            exist, this will return 0\n    \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\nreturn len(cls._group_particles[group])\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.remove_all_group_particles","title":"<code>remove_all_group_particles(group)</code>  <code>classmethod</code>","text":"<p>Remove particle with name @name from both the simulator as well as internally</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>Name of the attachment group to remove all particles from</p> required Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_all_group_particles(cls, group):\n\"\"\"\n    Remove particle with name @name from both the simulator as well as internally\n    Args:\n        group (str): Name of the attachment group to remove all particles from\n    \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Remove all particles from the group\nfor particle_name in list(cls._group_particles[group].keys()):\ncls.remove_particle(name=particle_name)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.remove_attachment_group","title":"<code>remove_attachment_group(group)</code>  <code>classmethod</code>","text":"<p>Removes an attachment group internally for object @obj. Note that this will automatically remove any particles currently assigned to that group</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>Name of the attachment group to remove</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Name of the attachment group to use when executing commands from this class on that specific attachment group</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_attachment_group(cls, group):\n\"\"\"\n    Removes an attachment group internally for object @obj. Note that this will automatically remove any particles\n    currently assigned to that group\n    Args:\n        group (str): Name of the attachment group to remove\n    Returns:\n        str: Name of the attachment group to use when executing commands from this class on\n            that specific attachment group\n    \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Remove all particles from the group\ncls.remove_all_group_particles(group=group)\n# Remove the actual groups\ncls._group_particles.pop(group)\ncls._group_objects.pop(group)\nreturn group\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.remove_particle","title":"<code>remove_particle(name)</code>  <code>classmethod</code>","text":"<p>Remove particle with name @name from both the simulator and internal state</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the particle to remove</p> required Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_particle(cls, name):\n\"\"\"\n    Remove particle with name @name from both the simulator and internal state\n    Args:\n        name (str): Name of the particle to remove\n    \"\"\"\n# Run super first\nsuper().remove_particle(name=name)\n# Remove this particle from its respective group as well\ncls._group_particles[cls._particles_info[name][\"obj\"].name].pop(name)\ncls._particles_info.pop(name)\ncls._particles_local_mat.pop(name)\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.sample_scales","title":"<code>sample_scales(group, n)</code>  <code>classmethod</code>","text":"<p>Samples @n particle scales for group @group.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>Specific group for which to sample scales</p> required <code>n</code> <code>int</code> <p>Number of scales to sample</p> required <p>Returns:</p> Type Description <p>(n, 3) array: Array of sampled scales</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef sample_scales(cls, group, n):\n\"\"\"\n    Samples @n particle scales for group @group.\n    Args:\n        group (str): Specific group for which to sample scales\n        n (int): Number of scales to sample\n    Returns:\n        (n, 3) array: Array of sampled scales\n    \"\"\"\n# Make sure the group exists\ncls._validate_group(group=group)\n# Update scaling and grab object\ncls.set_scale_limits(*cls.update_particle_scaling(group=group))\nobj = cls._group_objects[group]\n# Sample scales of the particles to generate\n# Since the particles will be placed under the object, it will be affected/stretched by obj.scale. In order to\n# preserve the absolute size of the particles, we need to scale the particle by obj.scale in some way. However,\n# since the particles have a relative rotation w.r.t the object, the scale between the two don't align. As a\n# heuristics, we divide it by the avg_scale, which is the cubic root of the product of the scales along 3 axes.\navg_scale = np.cbrt(np.product(obj.scale))\nreturn np.random.uniform(cls.min_scale, cls.max_scale, (n, 3)) / avg_scale\n</code></pre>"},{"location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.update_particle_scaling","title":"<code>update_particle_scaling(group)</code>  <code>classmethod</code>","text":"<p>Update particle scaling for group @group before generating group particles. Default is a no-op (i.e.: returns the current cls.min_scale, cls.max_scale)</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>Specific group for which to modify the particle scaling</p> required <p>Returns:</p> Type Description <p>2-tuple: - 3-array: min scaling factor to set - 3-array: max scaling factor to set</p> Source code in <code>omnigibson/systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef update_particle_scaling(cls, group):\n\"\"\"\n    Update particle scaling for group @group before generating group particles. Default is a no-op\n    (i.e.: returns the current cls.min_scale, cls.max_scale)\n    Args:\n        group (str): Specific group for which to modify the particle scaling\n    Returns:\n        2-tuple:\n            - 3-array: min scaling factor to set\n            - 3-array: max scaling factor to set\n    \"\"\"\nreturn cls.min_scale, cls.max_scale\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html","title":"micro_particle_system","text":""},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.Cloth","title":"<code>Cloth</code>","text":"<p>         Bases: <code>MicroParticleSystem</code></p> <p>Particle system class to simulate cloth.</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>class Cloth(MicroParticleSystem):\n\"\"\"\n    Particle system class to simulate cloth.\n    \"\"\"\n@classproperty\ndef _register_system(cls):\n# We should register this system since it's an \"actual\" system (not an intermediate class)\nreturn True\n@classproperty\ndef particle_contact_offset(cls):\n# TODO (eric): figure out whether one offset can fit all\nreturn 0.005\n@classproperty\ndef state_size(cls):\n# Default is no state\nreturn 0\n@classmethod\ndef _dump_state(cls):\n# Empty by default\nreturn dict()\n@classmethod\ndef _load_state(cls, state):\n# Nothing by default\npass\n@classmethod\ndef _serialize(cls, state):\n# Nothing by default\nreturn np.array([], dtype=float)\n@classmethod\ndef _deserialize(cls, state):\n# Nothing by default\nreturn dict(), 0\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.FluidSystem","title":"<code>FluidSystem</code>","text":"<p>         Bases: <code>PhysicalParticleSystem</code></p> <p>Particle system class simulating fluids, leveraging isosurface feature in omniverse to render nice PBR fluid texture. Individual particles are composed of spheres.</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>class FluidSystem(PhysicalParticleSystem):\n\"\"\"\n    Particle system class simulating fluids, leveraging isosurface feature in omniverse to render nice PBR fluid\n    texture. Individual particles are composed of spheres.\n    \"\"\"\n# Material -- either a MaterialPrim or None if no material is used for this particle system\n_material = None\n# Color associated with this system (NOTE: external queries should call cls.color)\n# The default color is blue.\n_color = np.array([0.0, 0.0, 1.0])\n@classmethod\ndef initialize(cls):\n# Run super first\nsuper().initialize()\n# Create the particle material\ncls._material = cls._create_particle_material_template()\n# Load the material\ncls._material.load()\n# Bind the material to the particle system (for isosurface) and the prototypes (for non-isosurface)\ncls._material.bind(cls.system_prim_path)\nfor prototype in cls.particle_prototypes:\ncls._material.bind(prototype.prim_path)\n# Also apply physics to this material\nparticleUtils.add_pbd_particle_material(og.sim.stage, cls.mat_path)\n# Force populate inputs and outputs of the shader\ncls._material.shader_force_populate()\n# Potentially modify the material\ncls._customize_particle_material()\n# Compute the overall color of the fluid system\nbase_color_weight = cls._material.diffuse_reflection_weight\ntransmission_weight = cls._material.enable_specular_transmission * cls._material.specular_transmission_weight\ntotal_weight = base_color_weight + transmission_weight\nif total_weight == 0.0:\n# If the fluid doesn't have any color, we add a \"blue\" tint by default\ncolor = np.array([0.0, 0.0, 1.0])\nelse:\nbase_color_weight /= total_weight\ntransmission_weight /= total_weight\n# Weighted sum of base color and transmission color\ncolor = base_color_weight * cls._material.diffuse_reflection_color + \\\n                    transmission_weight * (0.5 * cls._material.specular_transmission_color + \\\n                                           0.5 * cls._material.specular_transmission_scattering_color)\ncls._color = color\n# Set custom isosurface rendering settings if we are using high-quality rendering\nif gm.ENABLE_HQ_RENDERING:\nset_carb_settings_for_fluid_isosurface()\n# We also modify the grid smoothing radius to avoid \"blobby\" appearances\ncls.system_prim.GetAttribute(\"physxParticleIsosurface:gridSmoothingRadius\").Set(0.0001)\n@classproperty\ndef is_fluid(cls):\nreturn True\n@classproperty\ndef use_isosurface(cls):\nreturn True\n@classproperty\ndef material(cls):\n\"\"\"\n        Returns:\n            None or MaterialPrim: The bound material to this prim, if there is one\n        \"\"\"\nreturn cls._material\n@classproperty\ndef particle_radius(cls):\n\"\"\"\n        Returns:\n            float: Radius for the particles to be generated, since all fluids are composed of spheres\n        \"\"\"\n# Magic number from omni tutorials\n# See https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_physics.html#offset-autocomputation\nreturn 0.99 * 0.6 * cls.particle_contact_offset\n@classproperty\ndef _material_mtl_name(cls):\n\"\"\"\n        Returns:\n            None or str: Material mdl preset name to use for generating this fluid material. NOTE: Should be an\n                entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string. If None if specified, will default\n                to the generic OmniSurface material\n        \"\"\"\nreturn None\n@classmethod\ndef _create_particle_prototypes(cls):\n# Simulate particles with simple spheres\nprototype = UsdGeom.Sphere.Define(og.sim.stage, f\"{cls.prim_path}/prototype0\")\nprototype.CreateRadiusAttr().Set(cls.particle_radius)\nprototype = VisualGeomPrim(prim_path=prototype.GetPath().pathString, name=prototype.GetPath().pathString)\nprototype.visible = False\nreturn [prototype]\n@classmethod\ndef _create_particle_material_template(cls):\n# We use a template from OmniPresets if @_material_mtl_name is specified, else the default OmniSurface\nreturn MaterialPrim(\nprim_path=cls.mat_path,\nname=cls.mat_name,\nload_config={\n\"mdl_name\": f\"OmniSurface{'' if cls._material_mtl_name is None else 'Presets'}.mdl\",\n\"mtl_name\": f\"OmniSurface{'' if cls._material_mtl_name is None else ('_' + cls._material_mtl_name)}\"\n}\n)\n@classmethod\ndef create(\ncls,\nname,\nparticle_contact_offset,\nparticle_density,\nmaterial_mtl_name=None,\ncustomize_particle_material=None,\n**kwargs,\n):\n\"\"\"\n        Utility function to programmatically generate monolithic fluid system classes.\n        Args:\n            name (str): Name of the system\n            particle_contact_offset (float): Contact offset for the generated system\n            particle_density (float): Particle density for the generated system\n            material_mtl_name (None or str): Material mdl preset name to use for generating this fluid material.\n                NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string.\n                If None if specified, will default to the generic OmniSurface material\n            customize_particle_material (None or function): Method for customizing the particle material for the fluid\n                after it has been loaded. Default is None, which will produce a no-op.\n                If specified, expected signature:\n                _customize_particle_material(mat: MaterialPrim) --&gt; None\n                where @MaterialPrim is the material to modify in-place\n            **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n                the class attribute to modify and the values represent the functions / value to set\n                (Note: These values should have either @classproperty or @classmethod decorators!)\n        Returns:\n            FluidSystem: Generated system class\n        \"\"\"\n@classproperty\ndef cp_material_mtl_name(cls):\nreturn material_mtl_name\n@classmethod\ndef cm_customize_particle_material(cls):\nif customize_particle_material is not None:\ncustomize_particle_material(mat=cls._material)\n# Add to any other params specified\nkwargs[\"_material_mtl_name\"] = cp_material_mtl_name\nkwargs[\"_customize_particle_material\"] = cm_customize_particle_material\n# Create and return the class\nreturn super().create(\nname=name,\nparticle_contact_offset=particle_contact_offset,\nparticle_density=particle_density,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.FluidSystem.create","title":"<code>create(name, particle_contact_offset, particle_density, material_mtl_name=None, customize_particle_material=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Utility function to programmatically generate monolithic fluid system classes.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the system</p> required <code>particle_contact_offset</code> <code>float</code> <p>Contact offset for the generated system</p> required <code>particle_density</code> <code>float</code> <p>Particle density for the generated system</p> required <code>material_mtl_name</code> <code>None or str</code> <p>Material mdl preset name to use for generating this fluid material. NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string. If None if specified, will default to the generic OmniSurface material</p> <code>None</code> <code>customize_particle_material</code> <code>None or function</code> <p>Method for customizing the particle material for the fluid after it has been loaded. Default is None, which will produce a no-op. If specified, expected signature:</p> <p>_customize_particle_material(mat: MaterialPrim) --&gt; None</p> <p>where @MaterialPrim is the material to modify in-place</p> <code>None</code> <code>**kwargs</code> <code>any</code> <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class attribute to modify and the values represent the functions / value to set (Note: These values should have either @classproperty or @classmethod decorators!)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FluidSystem</code> <p>Generated system class</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef create(\ncls,\nname,\nparticle_contact_offset,\nparticle_density,\nmaterial_mtl_name=None,\ncustomize_particle_material=None,\n**kwargs,\n):\n\"\"\"\n    Utility function to programmatically generate monolithic fluid system classes.\n    Args:\n        name (str): Name of the system\n        particle_contact_offset (float): Contact offset for the generated system\n        particle_density (float): Particle density for the generated system\n        material_mtl_name (None or str): Material mdl preset name to use for generating this fluid material.\n            NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string.\n            If None if specified, will default to the generic OmniSurface material\n        customize_particle_material (None or function): Method for customizing the particle material for the fluid\n            after it has been loaded. Default is None, which will produce a no-op.\n            If specified, expected signature:\n            _customize_particle_material(mat: MaterialPrim) --&gt; None\n            where @MaterialPrim is the material to modify in-place\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class attribute to modify and the values represent the functions / value to set\n            (Note: These values should have either @classproperty or @classmethod decorators!)\n    Returns:\n        FluidSystem: Generated system class\n    \"\"\"\n@classproperty\ndef cp_material_mtl_name(cls):\nreturn material_mtl_name\n@classmethod\ndef cm_customize_particle_material(cls):\nif customize_particle_material is not None:\ncustomize_particle_material(mat=cls._material)\n# Add to any other params specified\nkwargs[\"_material_mtl_name\"] = cp_material_mtl_name\nkwargs[\"_customize_particle_material\"] = cm_customize_particle_material\n# Create and return the class\nreturn super().create(\nname=name,\nparticle_contact_offset=particle_contact_offset,\nparticle_density=particle_density,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.FluidSystem.material","title":"<code>material()</code>","text":"<p>Returns:</p> Type Description <p>None or MaterialPrim: The bound material to this prim, if there is one</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef material(cls):\n\"\"\"\n    Returns:\n        None or MaterialPrim: The bound material to this prim, if there is one\n    \"\"\"\nreturn cls._material\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.FluidSystem.particle_radius","title":"<code>particle_radius()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Radius for the particles to be generated, since all fluids are composed of spheres</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_radius(cls):\n\"\"\"\n    Returns:\n        float: Radius for the particles to be generated, since all fluids are composed of spheres\n    \"\"\"\n# Magic number from omni tutorials\n# See https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_physics.html#offset-autocomputation\nreturn 0.99 * 0.6 * cls.particle_contact_offset\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.GranularSystem","title":"<code>GranularSystem</code>","text":"<p>         Bases: <code>PhysicalParticleSystem</code></p> <p>Particle system class simulating granular materials. Individual particles are composed of custom USD objects.</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>class GranularSystem(PhysicalParticleSystem):\n\"\"\"\n    Particle system class simulating granular materials. Individual particles are composed of custom USD objects.\n    \"\"\"\n@classproperty\ndef is_fluid(cls):\nreturn False\n@classmethod\ndef _create_particle_prototypes(cls):\n# Load the particle template\nparticle_template = cls._create_particle_template()\nog.sim.import_object(obj=particle_template, register=False, auto_initialize=True)\n# Make sure there is no ambiguity about which mesh to use as the particle from this template\nassert len(particle_template.links) == 1, \"GranularSystem particle template has more than one link\"\nassert len(particle_template.root_link.visual_meshes) == 1, \"GranularSystem particle template has more than one visual mesh\"\n# The prototype is assumed to be the first and only visual mesh belonging to the root link\nvisual_geom = list(particle_template.root_link.visual_meshes.values())[0]\n# Copy it to the standardized prim path\nprototype_path = f\"{cls.prim_path}/prototype0\"\nomni.kit.commands.execute(\"CopyPrim\", path_from=visual_geom.prim_path, path_to=prototype_path)\n# Wrap it with VisualGeomPrim with the correct scale\nprototype = VisualGeomPrim(prim_path=prototype_path, name=prototype_path)\nprototype.scale = (cls.particle_radius * 2) / prototype.aabb_extent\nprototype.visible = False\nreturn [prototype]\n@classmethod\ndef _create_particle_template(cls):\n\"\"\"\n        Creates the particle template to be used for this system.\n        NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n            visual mesh attached to its root link, since this will be the actual visual mesh used\n        Returns:\n            EntityPrim: Particle template that will be duplicated when generating future particle groups\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef create(\ncls,\nname,\nparticle_contact_offset,\nparticle_density,\ncreate_particle_template,\n**kwargs,\n):\n\"\"\"\n        Utility function to programmatically generate monolithic fluid system classes.\n        Args:\n            name (str): Name of the system\n            particle_contact_offset (float): Contact offset for the generated system\n            particle_density (float): Particle density for the generated system\n            material_mtl_name (None or str): Material mdl preset name to use for generating this fluid material.\n                NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string.\n                If None if specified, will default to the generic OmniSurface material\n            create_particle_template (function): Method for generating the visual particle template that will be duplicated\n                when generating groups of particles.\n                Expected signature:\n                create_particle_template(prim_path: str, name: str) --&gt; EntityPrim\n                where @prim_path and @name are the parameters to assign to the generated EntityPrim.\n                NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n                    visual mesh attached to its root link, since this will be the actual visual mesh used\n            **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n                the class attribute to modify and the values represent the functions / value to set\n                (Note: These values should have either @classproperty or @classmethod decorators!)\n        Returns:\n            GranularSystem: Generated granular system class\n        \"\"\"\n@classmethod\ndef cm_create_particle_template(cls):\nreturn create_particle_template(prim_path=f\"{cls.prim_path}/template\", name=f\"{cls.name}_template\")\n# Add to any other params specified\nkwargs[\"_create_particle_template\"] = cm_create_particle_template\n# Create and return the class\nreturn super().create(\nname=name,\nparticle_contact_offset=particle_contact_offset,\nparticle_density=particle_density,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.GranularSystem.create","title":"<code>create(name, particle_contact_offset, particle_density, create_particle_template, **kwargs)</code>  <code>classmethod</code>","text":"<p>Utility function to programmatically generate monolithic fluid system classes.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the system</p> required <code>particle_contact_offset</code> <code>float</code> <p>Contact offset for the generated system</p> required <code>particle_density</code> <code>float</code> <p>Particle density for the generated system</p> required <code>material_mtl_name</code> <code>None or str</code> <p>Material mdl preset name to use for generating this fluid material. NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string. If None if specified, will default to the generic OmniSurface material</p> required <code>create_particle_template</code> <code>function</code> <p>Method for generating the visual particle template that will be duplicated when generating groups of particles. Expected signature:</p> <p>create_particle_template(prim_path: str, name: str) --&gt; EntityPrim</p> <p>where @prim_path and @name are the parameters to assign to the generated EntityPrim. NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single     visual mesh attached to its root link, since this will be the actual visual mesh used</p> required <code>**kwargs</code> <code>any</code> <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class attribute to modify and the values represent the functions / value to set (Note: These values should have either @classproperty or @classmethod decorators!)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>GranularSystem</code> <p>Generated granular system class</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef create(\ncls,\nname,\nparticle_contact_offset,\nparticle_density,\ncreate_particle_template,\n**kwargs,\n):\n\"\"\"\n    Utility function to programmatically generate monolithic fluid system classes.\n    Args:\n        name (str): Name of the system\n        particle_contact_offset (float): Contact offset for the generated system\n        particle_density (float): Particle density for the generated system\n        material_mtl_name (None or str): Material mdl preset name to use for generating this fluid material.\n            NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string.\n            If None if specified, will default to the generic OmniSurface material\n        create_particle_template (function): Method for generating the visual particle template that will be duplicated\n            when generating groups of particles.\n            Expected signature:\n            create_particle_template(prim_path: str, name: str) --&gt; EntityPrim\n            where @prim_path and @name are the parameters to assign to the generated EntityPrim.\n            NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n                visual mesh attached to its root link, since this will be the actual visual mesh used\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class attribute to modify and the values represent the functions / value to set\n            (Note: These values should have either @classproperty or @classmethod decorators!)\n    Returns:\n        GranularSystem: Generated granular system class\n    \"\"\"\n@classmethod\ndef cm_create_particle_template(cls):\nreturn create_particle_template(prim_path=f\"{cls.prim_path}/template\", name=f\"{cls.name}_template\")\n# Add to any other params specified\nkwargs[\"_create_particle_template\"] = cm_create_particle_template\n# Create and return the class\nreturn super().create(\nname=name,\nparticle_contact_offset=particle_contact_offset,\nparticle_density=particle_density,\n**kwargs,\n)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem","title":"<code>MicroParticleSystem</code>","text":"<p>         Bases: <code>BaseSystem</code></p> <p>Global system for modeling \"micro\" level particles, e.g.: water, seeds, cloth. This system leverages Omniverse's native physx particle systems</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>class MicroParticleSystem(BaseSystem):\n\"\"\"\n    Global system for modeling \"micro\" level particles, e.g.: water, seeds, cloth. This system leverages\n    Omniverse's native physx particle systems\n    \"\"\"\n# Particle system prim in the scene, should be generated at runtime\nsystem_prim = None\n@classmethod\ndef initialize(cls):\n# Run super first\nsuper().initialize()\nif not gm.USE_GPU_DYNAMICS:\nraise ValueError(f\"Failed to initialize {cls.name} system. Please set gm.USE_GPU_DYNAMICS to be True.\")\ncls.system_prim = cls._create_particle_system()\n@classproperty\ndef system_prim_path(cls):\nreturn f\"{cls.prim_path}/system\"\n@classproperty\ndef visual_only(cls):\n\"\"\"\n        Returns:\n            bool: Whether this particle system should be visual-only, i.e.: not subject to collisions and physics. If True,\n                the generated particles will not move or collide\n        \"\"\"\nreturn False\n@classproperty\ndef particle_contact_offset(cls):\n\"\"\"\n        Returns:\n            float: Contact offset value to use for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#particle-system-configuration\n                for more information\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef use_smoothing(cls):\n\"\"\"\n        Returns:\n            bool: Whether to use smoothing or not for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#smoothing\n                for more information\n        \"\"\"\nreturn False\n@classproperty\ndef use_anisotropy(cls):\n\"\"\"\n        Returns:\n            bool: Whether to use anisotropy or not for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#anisotropy\n                for more information\n        \"\"\"\nreturn False\n@classproperty\ndef use_isosurface(cls):\n\"\"\"\n        Returns:\n            bool: Whether to use isosurface or not for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#isosurface\n                for more information\n        \"\"\"\nreturn False\n@classproperty\ndef particle_radius(cls):\n\"\"\"\n        Returns:\n            float: Radius for the particles to be generated, since all fluids are composed of spheres\n        \"\"\"\n# Magic number from omni tutorials\n# See https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_physics.html#offset-autocomputation\nreturn 0.99 * cls.particle_contact_offset\n@classmethod\ndef _create_particle_system(cls):\n\"\"\"\n        Creates the single, global particle system. This should only be ever called once, and during initialize()\n        Returns:\n            Usd.Prim: Particle system prim created\n        \"\"\"\nreturn create_physx_particle_system(\nprim_path=cls.system_prim_path,\nphysics_scene_path=og.sim.get_physics_context().get_current_physics_scene_prim().GetPrimPath().pathString,\nparticle_contact_offset=cls.particle_contact_offset,\nvisual_only=cls.visual_only,\nsmoothing=cls.use_smoothing and gm.ENABLE_HQ_RENDERING,\nanisotropy=cls.use_anisotropy and gm.ENABLE_HQ_RENDERING,\nisosurface=cls.use_isosurface and gm.ENABLE_HQ_RENDERING,\n).GetPrim()\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_contact_offset","title":"<code>particle_contact_offset()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Contact offset value to use for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#particle-system-configuration for more information</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_contact_offset(cls):\n\"\"\"\n    Returns:\n        float: Contact offset value to use for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#particle-system-configuration\n            for more information\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_radius","title":"<code>particle_radius()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Radius for the particles to be generated, since all fluids are composed of spheres</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_radius(cls):\n\"\"\"\n    Returns:\n        float: Radius for the particles to be generated, since all fluids are composed of spheres\n    \"\"\"\n# Magic number from omni tutorials\n# See https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_physics.html#offset-autocomputation\nreturn 0.99 * cls.particle_contact_offset\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.use_anisotropy","title":"<code>use_anisotropy()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether to use anisotropy or not for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#anisotropy for more information</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef use_anisotropy(cls):\n\"\"\"\n    Returns:\n        bool: Whether to use anisotropy or not for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#anisotropy\n            for more information\n    \"\"\"\nreturn False\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.use_isosurface","title":"<code>use_isosurface()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether to use isosurface or not for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#isosurface for more information</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef use_isosurface(cls):\n\"\"\"\n    Returns:\n        bool: Whether to use isosurface or not for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#isosurface\n            for more information\n    \"\"\"\nreturn False\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.use_smoothing","title":"<code>use_smoothing()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether to use smoothing or not for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#smoothing for more information</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef use_smoothing(cls):\n\"\"\"\n    Returns:\n        bool: Whether to use smoothing or not for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#smoothing\n            for more information\n    \"\"\"\nreturn False\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.visual_only","title":"<code>visual_only()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this particle system should be visual-only, i.e.: not subject to collisions and physics. If True, the generated particles will not move or collide</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef visual_only(cls):\n\"\"\"\n    Returns:\n        bool: Whether this particle system should be visual-only, i.e.: not subject to collisions and physics. If True,\n            the generated particles will not move or collide\n    \"\"\"\nreturn False\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem","title":"<code>PhysicalParticleSystem</code>","text":"<p>         Bases: <code>MicroParticleSystem</code></p> <p>Global system for modeling physical \"micro\" level particles, e.g.: water, seeds, rice, etc. This system leverages Omniverse's native physx particle systems</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>class PhysicalParticleSystem(MicroParticleSystem):\n\"\"\"\n    Global system for modeling physical \"micro\" level particles, e.g.: water, seeds, rice, etc. This system leverages\n    Omniverse's native physx particle systems\n    \"\"\"\n# Particle prototypes -- will be list of mesh prims to use as particle prototypes for this system\nparticle_prototypes = None\n# Particle instancers -- maps name to particle instancer prims (dict)\nparticle_instancers = None\n# Scaling factor to sample from when generating a new particle\nmin_scale = None  # (x,y,z) scaling\nmax_scale = None  # (x,y,z) scaling\n# Max particle instancer identification number -- this monotonically increases until reset() is called\nmax_instancer_idn = None\n@classproperty\ndef n_particles(cls):\n\"\"\"\n        Returns:\n            int: Number of active particles in this system\n        \"\"\"\nreturn sum([instancer.n_particles for instancer in cls.particle_instancers.values()])\n@classproperty\ndef n_instancers(cls):\n\"\"\"\n        Returns:\n            int: Number of active particles in this system\n        \"\"\"\nreturn len(cls.particle_instancers)\n@classproperty\ndef instancer_idns(cls):\n\"\"\"\n        Returns:\n            int: Number of active particles in this system\n        \"\"\"\nreturn [inst.idn for inst in cls.particle_instancers.values()]\n@classproperty\ndef mat_path(cls):\n\"\"\"\n        Returns:\n            str: Path to this system's material in the scene stage\n        \"\"\"\nreturn f\"{cls.prim_path}/material\"\n@classproperty\ndef mat_name(cls):\n\"\"\"\n        Returns:\n            str: Name of this system's material\n        \"\"\"\nreturn f\"{cls.name}:material\"\n@classmethod\ndef initialize(cls):\n# Run super first\nsuper().initialize()\n# Initialize class variables that are mutable so they don't get overridden by children classes\ncls.particle_instancers = dict()\n# Set the default scales\ncls.min_scale = np.ones(3)\ncls.max_scale = np.ones(3)\n# Initialize max instancer idn\ncls.max_instancer_idn = -1\ncls.particle_prototypes = cls._create_particle_prototypes()\n@classmethod\ndef reset(cls):\n# Call super first\nsuper().reset()\n# Reset all internal variables\ncls.remove_all_particle_instancers()\n@classproperty\ndef next_available_instancer_idn(cls):\n\"\"\"\n        Updates the max instancer identification number based on the current internal state\n        \"\"\"\nif cls.n_instancers == 0:\nreturn cls.default_instancer_idn\nelse:\nfor idn in range(max(cls.instancer_idns) + 2):\nif idn not in cls.instancer_idns:\nreturn idn\n@classproperty\ndef default_instancer_idn(cls):\nreturn 0\n@classproperty\ndef state_size(cls):\n# We have the number of particle instancers (1), the instancer groups, particle groups, and,\n# number of particles in each instancer (3n),\n# and the corresponding states in each instancer (X)\nreturn 1 + 3 * len(cls.particle_instancers) + sum(inst.state_size for inst in cls.particle_instancers.values())\n@classproperty\ndef default_particle_instancer(cls):\n\"\"\"\n        Returns:\n            PhysxParticleInstancer: Default particle instancer for this particle system\n        \"\"\"\n# Default instancer is the 0th ID instancer\nname = cls.particle_instancer_idn_to_name(idn=cls.default_instancer_idn)\n# NOTE: Cannot use dict.get() call for some reason; it messes up IDE introspection\nreturn cls.particle_instancers[name] if name in cls.particle_instancers \\\n            else cls.generate_particle_instancer(n_particles=0, idn=cls.default_instancer_idn)\n@classproperty\ndef color(cls):\nreturn cls._color\n@classproperty\ndef is_fluid(cls):\n\"\"\"\n        Returns:\n            bool: Whether this system is modeling fluid or not\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef particle_density(cls):\n\"\"\"\n        Returns:\n            float: The per-particle density, in kg / m^3\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef _create_particle_prototypes(cls):\n\"\"\"\n        Creates any relevant particle prototypes to be used by this particle system.\n        Returns:\n            list of VisualGeomPrim: Visual mesh prim(s) to use as this system's particle prototype(s)\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef _create_particle_material_template(cls):\n\"\"\"\n        Creates the particle material template to be used for this particle system. Prim path does not matter,\n        as it will be overridden internally such that it is a child prim of this particle system's prim.\n        NOTE: This material is a template because it is loading an Omni material preset. It can then be customized (in\n        addition to modifying its physical material properties) via @_customize_particle_material\n        Returns:\n            None or MaterialPrim: If specified, is the material to apply to all particles. If None, no material\n                will be used. Default is None\n        \"\"\"\nreturn None\n@classmethod\ndef _customize_particle_material(cls):\n\"\"\"\n        Modifies this particle system's particle material once it is loaded. Default is a no-op\n        \"\"\"\npass\n@classmethod\ndef generate_particles(\ncls,\npositions,\ninstancer_idn=None,\nparticle_group=0,\nvelocities=None,\norientations=None,\nscales=None,\nself_collision=True,\nprototype_indices=None,\n):\n\"\"\"\n        Generates new particles, either as part of a pre-existing instancer corresponding to @instancer_idn or as part\n            of a newly generated instancer.\n        NOTE:\n        Args:\n            positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n                If not specified, will be set to the origin by default\n            instancer_idn (None or int): Unique identification number of the particle instancer to assign the generated\n                particles to. This is used to deterministically reproduce individual particle instancer states\n                dynamically, even if we delete / add additional ones at runtime during simulation. If there is no\n                active instancer that matches the requested idn, a new one will be created.\n                If None, this system will add particles to the default particle instancer\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n                with each other. Particles in the same group will have collision behavior dictated by @self_collision\n            velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n                If not specified, all will be set to 0\n            orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n                orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n            scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n                If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not\n            prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n                each particle. If None, will use all 0s (i.e.: the first prototype created)\n        Returns:\n            PhysxParticleInstancer: Particle instancer that includes the generated particles\n        \"\"\"\n# Create a new particle instancer if a new idn is requested, otherwise use the pre-existing one\ninst = cls.default_particle_instancer if instancer_idn is None else \\\n            cls.particle_instancers.get(cls.particle_instancer_idn_to_name(idn=instancer_idn), None)\nif inst is None:\ninst = cls.generate_particle_instancer(\nidn=instancer_idn,\nparticle_group=particle_group,\nn_particles=len(positions),\npositions=positions,\nvelocities=velocities,\norientations=orientations,\nscales=scales,\nprototype_indices=prototype_indices,\nself_collision=self_collision,\n)\nelse:\ninst.add_particles(\npositions=positions,\nvelocities=velocities,\norientations=orientations,\nscales=scales,\nprototype_indices=prototype_indices,\n)\nreturn inst\n@classmethod\ndef generate_particle_instancer(\ncls,\nn_particles,\nidn=None,\nparticle_group=0,\npositions=None,\nvelocities=None,\norientations=None,\nscales=None,\nself_collision=True,\nprototype_indices=None,\n):\n\"\"\"\n        Generates a new particle instancer with unique identification number @idn, and registers it internally\n        Args:\n            n_particles (int): Number of particles to generate for this instancer\n            idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n                deterministically reproduce individual particle instancer states dynamically, even if we\n                delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n                identifier automatically.\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n                with each other. Particles in the same group will have collision behavior dictated by @self_collision\n            positions (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n                If not specified, will be set to the origin by default\n            velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n                If not specified, all will be set to 0\n            orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n                orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n            scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n                If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not\n            prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n                each particle. If None, will use all 0s (i.e.: the first prototype created)\n        Returns:\n            PhysxParticleInstancer: Generated particle instancer\n        \"\"\"\n# Run sanity checks\nassert cls.initialized, \"Must initialize system before generating particle instancers!\"\n# Automatically generate an identification number for this instancer if none is specified\nif idn is None:\nidn = cls.next_available_instancer_idn\nassert idn not in cls.instancer_idns, f\"instancer idn {idn} already exists.\"\n# Generate standardized prim path for this instancer\nname = cls.particle_instancer_idn_to_name(idn=idn)\n# Create the instancer\ninstance = create_physx_particleset_pointinstancer(\nname=name,\nparticle_system_path=cls.prim_path,\nphysx_particle_system_path=cls.system_prim_path,\nparticle_group=particle_group,\npositions=np.zeros((n_particles, 3)) if positions is None else positions,\nself_collision=self_collision,\nfluid=cls.is_fluid,\nparticle_mass=None,\nparticle_density=cls.particle_density,\norientations=orientations,\nvelocities=velocities,\nangular_velocities=None,\nscales=np.random.uniform(cls.min_scale, cls.max_scale, size=(n_particles, 3)) if scales is None else scales,\nprototype_prim_paths=[pp.prim_path for pp in cls.particle_prototypes],\nprototype_indices=prototype_indices,\nenabled=not cls.visual_only,\n)\n# Create the instancer object that wraps the raw prim\ninstancer = PhysxParticleInstancer(\nprim_path=instance.GetPrimPath().pathString,\nname=name,\nidn=idn,\n)\ninstancer.initialize()\ncls.particle_instancers[name] = instancer\nreturn instancer\n@classmethod\ndef generate_particles_from_link(\ncls,\nobj,\nlink,\nuse_visual_meshes=True,\nmesh_name_prefixes=None,\ninstancer_idn=None,\nparticle_group=0,\nsampling_distance=None,\nmax_samples=5e5,\nsample_volume=True,\nself_collision=True,\nprototype_indices_choices=None,\n):\n\"\"\"\n        Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh\n        located at @mesh_prim_path, and registers it internally\n        Args:\n            obj (EntityPrim): Object whose @link's visual meshes will be converted into sampled particles\n            link (RigidPrim): @obj's link whose visual meshes will be converted into sampled particles\n            use_visual_meshes (bool): Whether to use visual meshes of the link to generate particles\n            mesh_name_prefixes (None or str): If specified, specifies the substring that must exist in @link's\n                mesh names in order for that mesh to be included in the particle generator function.\n                If None, no filtering will be used.\n            instancer_idn (None or int): Unique identification number of the particle instancer to assign the generated\n                particles to. This is used to deterministically reproduce individual particle instancer states\n                dynamically, even if we delete / add additional ones at runtime during simulation. If there is no\n                active instancer that matches the requested idn, a new one will be created.\n                If None, this system will add particles to the default particle instancer\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n                with each other. Particles in the same group will have collision behavior dictated by @self_collision.\n                Only used if a new particle instancer is created!\n            sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n                a simulator autocomputed value will be used\n            max_samples (int): Maximum number of particles to sample\n            sample_volume (bool): Whether to sample the particles at the mesh's surface or throughout its entire volume\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not. Only used if a new particle instancer is created!\n            prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n                should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n                single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n                sample from those IDs for each particle.\n        Returns:\n            PhysxParticleInstancer: Particle instancer that includes the generated particles\n        \"\"\"\n# Run sanity checks\nassert cls.initialized, \"Must initialize system before generating particle instancers!\"\n# TODO: Implement!\nassert sample_volume, \"Sampling surface of link for particles is not supported yet!\"\n# Generate a checker function to see if particles are within the link's volumes\ncheck_in_volume, _ = generate_points_in_volume_checker_function(\nobj=obj,\nvolume_link=link,\nuse_visual_meshes=use_visual_meshes,\nmesh_name_prefixes=mesh_name_prefixes,\n)\n# Grab the link's AABB (or fallback to obj AABB if link does not have a valid AABB),\n# and generate a grid of points based on the sampling distance\ntry:\nlow, high = link.aabb\nextent = link.aabb_extent\nexcept ValueError:\nlow, high = obj.aabb\nextent = obj.aabb_extent\n# We sample the range of each extent minus\nsampling_distance = 2 * cls.particle_radius if sampling_distance is None else sampling_distance\nn_particles_per_axis = (extent / sampling_distance).astype(int)\nassert np.all(n_particles_per_axis), f\"link {link.name} is too small to sample any particle of radius {cls.particle_radius}.\"\n# 1e-10 is added because the extent might be an exact multiple of particle radius\narrs = [np.arange(lo + cls.particle_radius, hi - cls.particle_radius + 1e-10, cls.particle_radius * 2)\nfor lo, hi, n in zip(low, high, n_particles_per_axis)]\n# Generate 3D-rectangular grid of points\nparticle_positions = np.stack([arr.flatten() for arr in np.meshgrid(*arrs)]).T\n# Check which points are inside the volume and only keep those\nparticle_positions = particle_positions[np.where(check_in_volume(particle_positions))[0]]\n# Also potentially sub-sample if we're past our limit\nif len(particle_positions) &gt; max_samples:\nparticle_positions = particle_positions[\nnp.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n# Get information about our sampled points\nn_particles = len(particle_positions)\nif prototype_indices_choices is not None:\nprototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n                isinstance(prototype_indices_choices, int) else \\\n                np.random.choice(prototype_indices_choices, size=(n_particles,))\nelse:\nprototype_indices = None\nreturn cls.generate_particles(\ninstancer_idn=instancer_idn,\nparticle_group=particle_group,\npositions=particle_positions,\nself_collision=self_collision,\nprototype_indices=prototype_indices,\n)\n@classmethod\ndef generate_particles_on_object(\ncls,\nobj,\ninstancer_idn=None,\nparticle_group=0,\nsampling_distance=None,\nmax_samples=5e5,\nmin_samples_for_success=1,\nself_collision=True,\nprototype_indices_choices=None,\n):\n\"\"\"\n        Generates @n_particles new particle objects and samples their locations on the top surface of object @obj\n        Args:\n            obj (BaseObject): Object on which to generate a particle instancer with sampled particles on the object's\n                top surface\n            instancer_idn (None or int): Unique identification number of the particle instancer to assign the generated\n                particles to. This is used to deterministically reproduce individual particle instancer states\n                dynamically, even if we delete / add additional ones at runtime during simulation. If there is no\n                active instancer that matches the requested idn, a new one will be created.\n                If None, this system will add particles to the default particle instancer\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide.\n                Only used if a new particle instancer is created!\n            sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n                a simulator autocomputed value will be used\n            max_samples (int): Maximum number of particles to sample\n            min_samples_for_success (int): Minimum number of particles required to be sampled successfully in order\n                for this generation process to be considered successful\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not. Only used if a new particle instancer is created!\n            prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n                should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n                single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n                sample from those IDs for each particle.\n        Returns:\n            bool: True if enough particles were generated successfully (number of successfully sampled points &gt;=\n                min_samples_for_success), otherwise False\n        \"\"\"\nassert max_samples &gt;= min_samples_for_success, \"number of particles to sample should exceed the min for success\"\n# We densely sample a grid of points by ray-casting from top to bottom to find the valid positions\nradius = cls.particle_radius\nresults = sample_cuboid_on_object_full_grid_topdown(\nobj,\n# the grid is fully dense - particles are sitting next to each other\nray_spacing=radius * 2 if sampling_distance is None else sampling_distance,\n# assume the particles are extremely small - sample cuboids of size 0 for better performance\ncuboid_dimensions=np.zeros(3),\n# raycast start inside the aabb in x-y plane and outside the aabb in the z-axis\naabb_offset=np.array([-radius, -radius, radius]),\n# bottom padding should be the same as the particle radius\ncuboid_bottom_padding=radius,\n# undo_cuboid_bottom_padding should be False - the sampled positions are above the surface by its radius\nundo_cuboid_bottom_padding=False,\n)\nparticle_positions = np.array([result[0] for result in results if result[0] is not None])\n# Also potentially sub-sample if we're past our limit\nif len(particle_positions) &gt; max_samples:\nparticle_positions = particle_positions[\nnp.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n# Get information about our sampled points\nn_particles = len(particle_positions)\nif prototype_indices_choices is not None:\nprototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n                isinstance(prototype_indices_choices, int) else \\\n                np.random.choice(prototype_indices_choices, size=(n_particles,))\nelse:\nprototype_indices = None\nsuccess = n_particles &gt;= min_samples_for_success\n# If we generated a sufficient number of points, generate them in the simulator\nif success:\ncls.generate_particles(\ninstancer_idn=instancer_idn,\nparticle_group=particle_group,\npositions=particle_positions,\nself_collision=self_collision,\nprototype_indices=prototype_indices,\n)\nreturn success\n@classmethod\ndef remove_particle_instancer(cls, name):\n\"\"\"\n        Removes particle instancer with name @name from this system.\n        Args:\n            name (str): Particle instancer name to remove. If it does not exist, then an error will be raised\n        \"\"\"\n# Make sure the instancer actually exists\nassert_valid_key(key=name, valid_keys=cls.particle_instancers, name=\"particle instancer\")\n# Remove instancer from our tracking and delete its prim\ninstancer = cls.particle_instancers.pop(name)\ninstancer.remove()\nog.sim.stage.RemovePrim(f\"{cls.prim_path}/{name}\")\n@classmethod\ndef particle_instancer_name_to_idn(cls, name):\n\"\"\"\n        Args:\n            name (str): Particle instancer name\n        Returns:\n            int: Particle instancer identification number\n        \"\"\"\nreturn int(name.split(f\"{cls.name}Instancer\")[-1])\n@classmethod\ndef particle_instancer_idn_to_name(cls, idn):\n\"\"\"\n        Args:\n            idn (idn): Particle instancer identification number\n        Returns:\n            str: Name of the particle instancer auto-generated from its unique identification number\n        \"\"\"\nreturn f\"{cls.name}Instancer{idn}\"\n@classmethod\ndef _sync_particle_instancers(cls, idns, particle_groups, particle_counts):\n\"\"\"\n        Synchronizes the particle instancers based on desired identification numbers @idns\n        Args:\n            idns (list of int): Desired unique instancers that should be active for this particle system\n            particle_groups (list of int): Desired particle groups that each instancer should be. Length of this\n                list should be the same length as @idns\n            particle_counts (list of int): Desired particle counts that should exist per instancer. Length of this\n                list should be the same length as @idns\n        \"\"\"\n# We have to be careful here -- some particle instancers may have been deleted / are mismatched, so we need\n# to update accordingly, potentially deleting stale instancers and creating new instancers as needed\nidn_to_info_mapping = {idn: {\"group\": group, \"count\": count}\nfor idn, group, count in zip(idns, particle_groups, particle_counts)}\ncurrent_instancer_names = set(cls.particle_instancers.keys())\ndesired_instancer_names = set(cls.particle_instancer_idn_to_name(idn=idn) for idn in idns)\ninstancers_to_delete = current_instancer_names - desired_instancer_names\ninstancers_to_create = desired_instancer_names - current_instancer_names\ncommon_instancers = current_instancer_names.intersection(desired_instancer_names)\n# Sanity check the common instancers, we will recreate any where there is a mismatch\nfor name in common_instancers:\nidn = cls.particle_instancer_name_to_idn(name=name)\ninfo = idn_to_info_mapping[idn]\ninstancer = cls.particle_instancers[name]\nif instancer.particle_group != info[\"group\"]:\ninstancer.particle_group = info[\"group\"]\ncount_diff = info[\"count\"] - instancer.n_particles\nif count_diff &gt; 0:\n# We need to add more particles to this group\ninstancer.add_particles(positions=np.zeros((count_diff, 3)))\nelif count_diff &lt; 0:\n# We need to remove particles from this group\ninstancer.remove_particles(idxs=np.arange(-count_diff))\n# Delete any instancers we no longer want\nfor name in instancers_to_delete:\ncls.remove_particle_instancer(name=name)\n# Create any instancers we don't already have\nfor name in instancers_to_create:\nidn = cls.particle_instancer_name_to_idn(name=name)\ninfo = idn_to_info_mapping[idn]\ncls.generate_particle_instancer(idn=idn, particle_group=info[\"group\"], n_particles=info[\"count\"])\n@classmethod\ndef _dump_state(cls):\nreturn dict(\nn_instancers=cls.n_instancers,\ninstancer_idns=cls.instancer_idns,\ninstancer_particle_groups=[inst.particle_group for inst in cls.particle_instancers.values()],\ninstancer_particle_counts=[inst.n_particles for inst in cls.particle_instancers.values()],\nparticle_states=dict(((name, inst.dump_state(serialized=False))\nfor name, inst in cls.particle_instancers.items())),\n)\n@classmethod\ndef _load_state(cls, state):\n# Synchronize the particle instancers\ncls._sync_particle_instancers(\nidns=state[\"instancer_idns\"],\nparticle_groups=state[\"instancer_particle_groups\"],\nparticle_counts=state[\"instancer_particle_counts\"],\n)\n# Iterate over all particle states and load their respective states\nfor name, inst_state in state[\"particle_states\"].items():\ncls.particle_instancers[name].load_state(inst_state, serialized=False)\n@classmethod\ndef _serialize(cls, state):\n# Array is number of particle instancers, then the corresponding states for each particle instancer\nreturn np.concatenate([\n[state[\"n_instancers\"]],\nstate[\"instancer_idns\"],\nstate[\"instancer_particle_groups\"],\nstate[\"instancer_particle_counts\"],\n*[cls.particle_instancers[name].serialize(inst_state)\nfor name, inst_state in state[\"particle_states\"].items()],\n]).astype(float)\n@classmethod\ndef _deserialize(cls, state):\n# Synchronize the particle instancers\nn_instancers = int(state[0])\ninstancer_info = dict()\nidx = 1\nfor info_name in (\"instancer_idns\", \"instancer_particle_groups\", \"instancer_particle_counts\"):\ninstancer_info[info_name] = state[idx: idx + n_instancers].astype(int).tolist()\nidx += n_instancers\n# Syncing is needed so that each particle instancer can further deserialize its own state\nlog.debug(f\"Syncing {cls.name} particles with {n_instancers} instancers..\")\ncls._sync_particle_instancers(\nidns=instancer_info[\"instancer_idns\"],\nparticle_groups=instancer_info[\"instancer_particle_groups\"],\nparticle_counts=instancer_info[\"instancer_particle_counts\"],\n)\n# Procedurally deserialize the particle states\nparticle_states = dict()\nfor idn in instancer_info[\"instancer_idns\"]:\nname = cls.particle_instancer_idn_to_name(idn=idn)\nstate_size = cls.particle_instancers[name].state_size\nparticle_states[name] = cls.particle_instancers[name].deserialize(state[idx: idx + state_size])\nidx += state_size\nreturn dict(\nn_instancers=n_instancers,\n**instancer_info,\nparticle_states=particle_states,\n), idx\n@classmethod\ndef set_scale_limits(cls, minimum=None, maximum=None):\n\"\"\"\n        Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n        Args:\n            minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n                particles\n            maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n                particles\n        \"\"\"\nif minimum is not None:\ncls.min_scale = np.array(minimum)\nif maximum is not None:\ncls.max_scale = np.array(maximum)\n@classmethod\ndef remove_all_particle_instancers(cls):\n\"\"\"\n        Removes all particle instancers and deletes them from the simulator\n        \"\"\"\ncls._sync_particle_instancers(idns=[], particle_groups=[], particle_counts=[])\n@classmethod\ndef create(\ncls,\nname,\nparticle_contact_offset,\nparticle_density,\n**kwargs,\n):\n\"\"\"\n        Utility function to programmatically generate monolithic fluid system classes.\n        Args:\n            name (str): Name of the system, in snake case.\n            particle_contact_offset (float): Contact offset for the generated system\n            particle_density (float): Particle density for the generated system\n            **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n                the class attribute to modify and the values represent the functions / value to set\n                (Note: These values should have either @classproperty or @classmethod decorators!)\n        Returns:\n            PhysicalParticleSystem: Generated system class\n        \"\"\"\n# Override the necessary parameters\n@classproperty\ndef cp_register_system(cls):\n# We should register this system since it's an \"actual\" system (not an intermediate class)\nreturn True\n@classproperty\ndef cp_particle_contact_offset(cls):\nreturn particle_contact_offset\n@classproperty\ndef cp_particle_density(cls):\nreturn particle_density\n# Add to any other params specified\nkwargs[\"_register_system\"] = cp_register_system\nkwargs[\"particle_contact_offset\"] = cp_particle_contact_offset\nkwargs[\"particle_density\"] = cp_particle_density\n# Create and return the class\nreturn subclass_factory(name=snake_case_to_camel_case(name), base_classes=cls, **kwargs)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.create","title":"<code>create(name, particle_contact_offset, particle_density, **kwargs)</code>  <code>classmethod</code>","text":"<p>Utility function to programmatically generate monolithic fluid system classes.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the system, in snake case.</p> required <code>particle_contact_offset</code> <code>float</code> <p>Contact offset for the generated system</p> required <code>particle_density</code> <code>float</code> <p>Particle density for the generated system</p> required <code>**kwargs</code> <code>any</code> <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class attribute to modify and the values represent the functions / value to set (Note: These values should have either @classproperty or @classmethod decorators!)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>PhysicalParticleSystem</code> <p>Generated system class</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef create(\ncls,\nname,\nparticle_contact_offset,\nparticle_density,\n**kwargs,\n):\n\"\"\"\n    Utility function to programmatically generate monolithic fluid system classes.\n    Args:\n        name (str): Name of the system, in snake case.\n        particle_contact_offset (float): Contact offset for the generated system\n        particle_density (float): Particle density for the generated system\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class attribute to modify and the values represent the functions / value to set\n            (Note: These values should have either @classproperty or @classmethod decorators!)\n    Returns:\n        PhysicalParticleSystem: Generated system class\n    \"\"\"\n# Override the necessary parameters\n@classproperty\ndef cp_register_system(cls):\n# We should register this system since it's an \"actual\" system (not an intermediate class)\nreturn True\n@classproperty\ndef cp_particle_contact_offset(cls):\nreturn particle_contact_offset\n@classproperty\ndef cp_particle_density(cls):\nreturn particle_density\n# Add to any other params specified\nkwargs[\"_register_system\"] = cp_register_system\nkwargs[\"particle_contact_offset\"] = cp_particle_contact_offset\nkwargs[\"particle_density\"] = cp_particle_density\n# Create and return the class\nreturn subclass_factory(name=snake_case_to_camel_case(name), base_classes=cls, **kwargs)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.default_particle_instancer","title":"<code>default_particle_instancer()</code>","text":"<p>Returns:</p> Name Type Description <code>PhysxParticleInstancer</code> <p>Default particle instancer for this particle system</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef default_particle_instancer(cls):\n\"\"\"\n    Returns:\n        PhysxParticleInstancer: Default particle instancer for this particle system\n    \"\"\"\n# Default instancer is the 0th ID instancer\nname = cls.particle_instancer_idn_to_name(idn=cls.default_instancer_idn)\n# NOTE: Cannot use dict.get() call for some reason; it messes up IDE introspection\nreturn cls.particle_instancers[name] if name in cls.particle_instancers \\\n        else cls.generate_particle_instancer(n_particles=0, idn=cls.default_instancer_idn)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.generate_particle_instancer","title":"<code>generate_particle_instancer(n_particles, idn=None, particle_group=0, positions=None, velocities=None, orientations=None, scales=None, self_collision=True, prototype_indices=None)</code>  <code>classmethod</code>","text":"<p>Generates a new particle instancer with unique identification number @idn, and registers it internally</p> <p>Parameters:</p> Name Type Description Default <code>n_particles</code> <code>int</code> <p>Number of particles to generate for this instancer</p> required <code>idn</code> <code>None or int</code> <p>Unique identification number to assign to this particle instancer. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If None, this system will generate a unique identifier automatically.</p> <code>None</code> <code>particle_group</code> <code>int</code> <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision</p> <code>0</code> <code>positions</code> <code>None or np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) positions. If not specified, will be set to the origin by default</p> <code>None</code> <code>velocities</code> <code>None or np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) velocities. If not specified, all will be set to 0</p> <code>None</code> <code>orientations</code> <code>None or np.array</code> <p>(n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)</p> <code>None</code> <code>scales</code> <code>None or np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) scales. If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)</p> <code>None</code> <code>self_collision</code> <code>bool</code> <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p> <code>True</code> <code>prototype_indices</code> <code>None or list of int</code> <p>If specified, should specify which prototype should be used for each particle. If None, will use all 0s (i.e.: the first prototype created)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PhysxParticleInstancer</code> <p>Generated particle instancer</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particle_instancer(\ncls,\nn_particles,\nidn=None,\nparticle_group=0,\npositions=None,\nvelocities=None,\norientations=None,\nscales=None,\nself_collision=True,\nprototype_indices=None,\n):\n\"\"\"\n    Generates a new particle instancer with unique identification number @idn, and registers it internally\n    Args:\n        n_particles (int): Number of particles to generate for this instancer\n        idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n            deterministically reproduce individual particle instancer states dynamically, even if we\n            delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n            identifier automatically.\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision\n        positions (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n            If not specified, will be set to the origin by default\n        velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n            If not specified, all will be set to 0\n        orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n            orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n            If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n            each particle. If None, will use all 0s (i.e.: the first prototype created)\n    Returns:\n        PhysxParticleInstancer: Generated particle instancer\n    \"\"\"\n# Run sanity checks\nassert cls.initialized, \"Must initialize system before generating particle instancers!\"\n# Automatically generate an identification number for this instancer if none is specified\nif idn is None:\nidn = cls.next_available_instancer_idn\nassert idn not in cls.instancer_idns, f\"instancer idn {idn} already exists.\"\n# Generate standardized prim path for this instancer\nname = cls.particle_instancer_idn_to_name(idn=idn)\n# Create the instancer\ninstance = create_physx_particleset_pointinstancer(\nname=name,\nparticle_system_path=cls.prim_path,\nphysx_particle_system_path=cls.system_prim_path,\nparticle_group=particle_group,\npositions=np.zeros((n_particles, 3)) if positions is None else positions,\nself_collision=self_collision,\nfluid=cls.is_fluid,\nparticle_mass=None,\nparticle_density=cls.particle_density,\norientations=orientations,\nvelocities=velocities,\nangular_velocities=None,\nscales=np.random.uniform(cls.min_scale, cls.max_scale, size=(n_particles, 3)) if scales is None else scales,\nprototype_prim_paths=[pp.prim_path for pp in cls.particle_prototypes],\nprototype_indices=prototype_indices,\nenabled=not cls.visual_only,\n)\n# Create the instancer object that wraps the raw prim\ninstancer = PhysxParticleInstancer(\nprim_path=instance.GetPrimPath().pathString,\nname=name,\nidn=idn,\n)\ninstancer.initialize()\ncls.particle_instancers[name] = instancer\nreturn instancer\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.generate_particles","title":"<code>generate_particles(positions, instancer_idn=None, particle_group=0, velocities=None, orientations=None, scales=None, self_collision=True, prototype_indices=None)</code>  <code>classmethod</code>","text":"<p>Generates new particles, either as part of a pre-existing instancer corresponding to @instancer_idn or as part     of a newly generated instancer.</p> <p>NOTE:</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) positions. If not specified, will be set to the origin by default</p> required <code>instancer_idn</code> <code>None or int</code> <p>Unique identification number of the particle instancer to assign the generated particles to. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If there is no active instancer that matches the requested idn, a new one will be created. If None, this system will add particles to the default particle instancer</p> <code>None</code> <code>particle_group</code> <code>int</code> <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision</p> <code>0</code> <code>velocities</code> <code>None or np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) velocities. If not specified, all will be set to 0</p> <code>None</code> <code>orientations</code> <code>None or np.array</code> <p>(n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)</p> <code>None</code> <code>scales</code> <code>None or np.array</code> <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) scales. If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)</p> <code>None</code> <code>self_collision</code> <code>bool</code> <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p> <code>True</code> <code>prototype_indices</code> <code>None or list of int</code> <p>If specified, should specify which prototype should be used for each particle. If None, will use all 0s (i.e.: the first prototype created)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PhysxParticleInstancer</code> <p>Particle instancer that includes the generated particles</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particles(\ncls,\npositions,\ninstancer_idn=None,\nparticle_group=0,\nvelocities=None,\norientations=None,\nscales=None,\nself_collision=True,\nprototype_indices=None,\n):\n\"\"\"\n    Generates new particles, either as part of a pre-existing instancer corresponding to @instancer_idn or as part\n        of a newly generated instancer.\n    NOTE:\n    Args:\n        positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n            If not specified, will be set to the origin by default\n        instancer_idn (None or int): Unique identification number of the particle instancer to assign the generated\n            particles to. This is used to deterministically reproduce individual particle instancer states\n            dynamically, even if we delete / add additional ones at runtime during simulation. If there is no\n            active instancer that matches the requested idn, a new one will be created.\n            If None, this system will add particles to the default particle instancer\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision\n        velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n            If not specified, all will be set to 0\n        orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n            orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n            If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n            each particle. If None, will use all 0s (i.e.: the first prototype created)\n    Returns:\n        PhysxParticleInstancer: Particle instancer that includes the generated particles\n    \"\"\"\n# Create a new particle instancer if a new idn is requested, otherwise use the pre-existing one\ninst = cls.default_particle_instancer if instancer_idn is None else \\\n        cls.particle_instancers.get(cls.particle_instancer_idn_to_name(idn=instancer_idn), None)\nif inst is None:\ninst = cls.generate_particle_instancer(\nidn=instancer_idn,\nparticle_group=particle_group,\nn_particles=len(positions),\npositions=positions,\nvelocities=velocities,\norientations=orientations,\nscales=scales,\nprototype_indices=prototype_indices,\nself_collision=self_collision,\n)\nelse:\ninst.add_particles(\npositions=positions,\nvelocities=velocities,\norientations=orientations,\nscales=scales,\nprototype_indices=prototype_indices,\n)\nreturn inst\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.generate_particles_from_link","title":"<code>generate_particles_from_link(obj, link, use_visual_meshes=True, mesh_name_prefixes=None, instancer_idn=None, particle_group=0, sampling_distance=None, max_samples=500000.0, sample_volume=True, self_collision=True, prototype_indices_choices=None)</code>  <code>classmethod</code>","text":"<p>Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh located at @mesh_prim_path, and registers it internally</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>EntityPrim</code> <p>Object whose @link's visual meshes will be converted into sampled particles</p> required <code>link</code> <code>RigidPrim</code> <p>@obj's link whose visual meshes will be converted into sampled particles</p> required <code>use_visual_meshes</code> <code>bool</code> <p>Whether to use visual meshes of the link to generate particles</p> <code>True</code> <code>mesh_name_prefixes</code> <code>None or str</code> <p>If specified, specifies the substring that must exist in @link's mesh names in order for that mesh to be included in the particle generator function. If None, no filtering will be used.</p> <code>None</code> <code>instancer_idn</code> <code>None or int</code> <p>Unique identification number of the particle instancer to assign the generated particles to. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If there is no active instancer that matches the requested idn, a new one will be created. If None, this system will add particles to the default particle instancer</p> <code>None</code> <code>particle_group</code> <code>int</code> <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision. Only used if a new particle instancer is created!</p> <code>0</code> <code>sampling_distance</code> <code>None or float</code> <p>If specified, sets the distance between sampled particles. If None, a simulator autocomputed value will be used</p> <code>None</code> <code>max_samples</code> <code>int</code> <p>Maximum number of particles to sample</p> <code>500000.0</code> <code>sample_volume</code> <code>bool</code> <p>Whether to sample the particles at the mesh's surface or throughout its entire volume</p> <code>True</code> <code>self_collision</code> <code>bool</code> <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not. Only used if a new particle instancer is created!</p> <code>True</code> <code>prototype_indices_choices</code> <code>None or int or list of int</code> <p>If specified, should specify which prototype(s) should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly sample from those IDs for each particle.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PhysxParticleInstancer</code> <p>Particle instancer that includes the generated particles</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particles_from_link(\ncls,\nobj,\nlink,\nuse_visual_meshes=True,\nmesh_name_prefixes=None,\ninstancer_idn=None,\nparticle_group=0,\nsampling_distance=None,\nmax_samples=5e5,\nsample_volume=True,\nself_collision=True,\nprototype_indices_choices=None,\n):\n\"\"\"\n    Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh\n    located at @mesh_prim_path, and registers it internally\n    Args:\n        obj (EntityPrim): Object whose @link's visual meshes will be converted into sampled particles\n        link (RigidPrim): @obj's link whose visual meshes will be converted into sampled particles\n        use_visual_meshes (bool): Whether to use visual meshes of the link to generate particles\n        mesh_name_prefixes (None or str): If specified, specifies the substring that must exist in @link's\n            mesh names in order for that mesh to be included in the particle generator function.\n            If None, no filtering will be used.\n        instancer_idn (None or int): Unique identification number of the particle instancer to assign the generated\n            particles to. This is used to deterministically reproduce individual particle instancer states\n            dynamically, even if we delete / add additional ones at runtime during simulation. If there is no\n            active instancer that matches the requested idn, a new one will be created.\n            If None, this system will add particles to the default particle instancer\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision.\n            Only used if a new particle instancer is created!\n        sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n            a simulator autocomputed value will be used\n        max_samples (int): Maximum number of particles to sample\n        sample_volume (bool): Whether to sample the particles at the mesh's surface or throughout its entire volume\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not. Only used if a new particle instancer is created!\n        prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n            should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n            single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n            sample from those IDs for each particle.\n    Returns:\n        PhysxParticleInstancer: Particle instancer that includes the generated particles\n    \"\"\"\n# Run sanity checks\nassert cls.initialized, \"Must initialize system before generating particle instancers!\"\n# TODO: Implement!\nassert sample_volume, \"Sampling surface of link for particles is not supported yet!\"\n# Generate a checker function to see if particles are within the link's volumes\ncheck_in_volume, _ = generate_points_in_volume_checker_function(\nobj=obj,\nvolume_link=link,\nuse_visual_meshes=use_visual_meshes,\nmesh_name_prefixes=mesh_name_prefixes,\n)\n# Grab the link's AABB (or fallback to obj AABB if link does not have a valid AABB),\n# and generate a grid of points based on the sampling distance\ntry:\nlow, high = link.aabb\nextent = link.aabb_extent\nexcept ValueError:\nlow, high = obj.aabb\nextent = obj.aabb_extent\n# We sample the range of each extent minus\nsampling_distance = 2 * cls.particle_radius if sampling_distance is None else sampling_distance\nn_particles_per_axis = (extent / sampling_distance).astype(int)\nassert np.all(n_particles_per_axis), f\"link {link.name} is too small to sample any particle of radius {cls.particle_radius}.\"\n# 1e-10 is added because the extent might be an exact multiple of particle radius\narrs = [np.arange(lo + cls.particle_radius, hi - cls.particle_radius + 1e-10, cls.particle_radius * 2)\nfor lo, hi, n in zip(low, high, n_particles_per_axis)]\n# Generate 3D-rectangular grid of points\nparticle_positions = np.stack([arr.flatten() for arr in np.meshgrid(*arrs)]).T\n# Check which points are inside the volume and only keep those\nparticle_positions = particle_positions[np.where(check_in_volume(particle_positions))[0]]\n# Also potentially sub-sample if we're past our limit\nif len(particle_positions) &gt; max_samples:\nparticle_positions = particle_positions[\nnp.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n# Get information about our sampled points\nn_particles = len(particle_positions)\nif prototype_indices_choices is not None:\nprototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n            isinstance(prototype_indices_choices, int) else \\\n            np.random.choice(prototype_indices_choices, size=(n_particles,))\nelse:\nprototype_indices = None\nreturn cls.generate_particles(\ninstancer_idn=instancer_idn,\nparticle_group=particle_group,\npositions=particle_positions,\nself_collision=self_collision,\nprototype_indices=prototype_indices,\n)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.generate_particles_on_object","title":"<code>generate_particles_on_object(obj, instancer_idn=None, particle_group=0, sampling_distance=None, max_samples=500000.0, min_samples_for_success=1, self_collision=True, prototype_indices_choices=None)</code>  <code>classmethod</code>","text":"<p>Generates @n_particles new particle objects and samples their locations on the top surface of object @obj</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object on which to generate a particle instancer with sampled particles on the object's top surface</p> required <code>instancer_idn</code> <code>None or int</code> <p>Unique identification number of the particle instancer to assign the generated particles to. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If there is no active instancer that matches the requested idn, a new one will be created. If None, this system will add particles to the default particle instancer</p> <code>None</code> <code>particle_group</code> <code>int</code> <p>ID for this particle set. Particles from different groups will automatically collide. Only used if a new particle instancer is created!</p> <code>0</code> <code>sampling_distance</code> <code>None or float</code> <p>If specified, sets the distance between sampled particles. If None, a simulator autocomputed value will be used</p> <code>None</code> <code>max_samples</code> <code>int</code> <p>Maximum number of particles to sample</p> <code>500000.0</code> <code>min_samples_for_success</code> <code>int</code> <p>Minimum number of particles required to be sampled successfully in order for this generation process to be considered successful</p> <code>1</code> <code>self_collision</code> <code>bool</code> <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not. Only used if a new particle instancer is created!</p> <code>True</code> <code>prototype_indices_choices</code> <code>None or int or list of int</code> <p>If specified, should specify which prototype(s) should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly sample from those IDs for each particle.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if enough particles were generated successfully (number of successfully sampled points &gt;= min_samples_for_success), otherwise False</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particles_on_object(\ncls,\nobj,\ninstancer_idn=None,\nparticle_group=0,\nsampling_distance=None,\nmax_samples=5e5,\nmin_samples_for_success=1,\nself_collision=True,\nprototype_indices_choices=None,\n):\n\"\"\"\n    Generates @n_particles new particle objects and samples their locations on the top surface of object @obj\n    Args:\n        obj (BaseObject): Object on which to generate a particle instancer with sampled particles on the object's\n            top surface\n        instancer_idn (None or int): Unique identification number of the particle instancer to assign the generated\n            particles to. This is used to deterministically reproduce individual particle instancer states\n            dynamically, even if we delete / add additional ones at runtime during simulation. If there is no\n            active instancer that matches the requested idn, a new one will be created.\n            If None, this system will add particles to the default particle instancer\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide.\n            Only used if a new particle instancer is created!\n        sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n            a simulator autocomputed value will be used\n        max_samples (int): Maximum number of particles to sample\n        min_samples_for_success (int): Minimum number of particles required to be sampled successfully in order\n            for this generation process to be considered successful\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not. Only used if a new particle instancer is created!\n        prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n            should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n            single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n            sample from those IDs for each particle.\n    Returns:\n        bool: True if enough particles were generated successfully (number of successfully sampled points &gt;=\n            min_samples_for_success), otherwise False\n    \"\"\"\nassert max_samples &gt;= min_samples_for_success, \"number of particles to sample should exceed the min for success\"\n# We densely sample a grid of points by ray-casting from top to bottom to find the valid positions\nradius = cls.particle_radius\nresults = sample_cuboid_on_object_full_grid_topdown(\nobj,\n# the grid is fully dense - particles are sitting next to each other\nray_spacing=radius * 2 if sampling_distance is None else sampling_distance,\n# assume the particles are extremely small - sample cuboids of size 0 for better performance\ncuboid_dimensions=np.zeros(3),\n# raycast start inside the aabb in x-y plane and outside the aabb in the z-axis\naabb_offset=np.array([-radius, -radius, radius]),\n# bottom padding should be the same as the particle radius\ncuboid_bottom_padding=radius,\n# undo_cuboid_bottom_padding should be False - the sampled positions are above the surface by its radius\nundo_cuboid_bottom_padding=False,\n)\nparticle_positions = np.array([result[0] for result in results if result[0] is not None])\n# Also potentially sub-sample if we're past our limit\nif len(particle_positions) &gt; max_samples:\nparticle_positions = particle_positions[\nnp.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n# Get information about our sampled points\nn_particles = len(particle_positions)\nif prototype_indices_choices is not None:\nprototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n            isinstance(prototype_indices_choices, int) else \\\n            np.random.choice(prototype_indices_choices, size=(n_particles,))\nelse:\nprototype_indices = None\nsuccess = n_particles &gt;= min_samples_for_success\n# If we generated a sufficient number of points, generate them in the simulator\nif success:\ncls.generate_particles(\ninstancer_idn=instancer_idn,\nparticle_group=particle_group,\npositions=particle_positions,\nself_collision=self_collision,\nprototype_indices=prototype_indices,\n)\nreturn success\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.instancer_idns","title":"<code>instancer_idns()</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of active particles in this system</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef instancer_idns(cls):\n\"\"\"\n    Returns:\n        int: Number of active particles in this system\n    \"\"\"\nreturn [inst.idn for inst in cls.particle_instancers.values()]\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.is_fluid","title":"<code>is_fluid()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this system is modeling fluid or not</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef is_fluid(cls):\n\"\"\"\n    Returns:\n        bool: Whether this system is modeling fluid or not\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.mat_name","title":"<code>mat_name()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this system's material</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef mat_name(cls):\n\"\"\"\n    Returns:\n        str: Name of this system's material\n    \"\"\"\nreturn f\"{cls.name}:material\"\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.mat_path","title":"<code>mat_path()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Path to this system's material in the scene stage</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef mat_path(cls):\n\"\"\"\n    Returns:\n        str: Path to this system's material in the scene stage\n    \"\"\"\nreturn f\"{cls.prim_path}/material\"\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.n_instancers","title":"<code>n_instancers()</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of active particles in this system</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef n_instancers(cls):\n\"\"\"\n    Returns:\n        int: Number of active particles in this system\n    \"\"\"\nreturn len(cls.particle_instancers)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.n_particles","title":"<code>n_particles()</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of active particles in this system</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef n_particles(cls):\n\"\"\"\n    Returns:\n        int: Number of active particles in this system\n    \"\"\"\nreturn sum([instancer.n_particles for instancer in cls.particle_instancers.values()])\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.next_available_instancer_idn","title":"<code>next_available_instancer_idn()</code>","text":"<p>Updates the max instancer identification number based on the current internal state</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef next_available_instancer_idn(cls):\n\"\"\"\n    Updates the max instancer identification number based on the current internal state\n    \"\"\"\nif cls.n_instancers == 0:\nreturn cls.default_instancer_idn\nelse:\nfor idn in range(max(cls.instancer_idns) + 2):\nif idn not in cls.instancer_idns:\nreturn idn\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.particle_density","title":"<code>particle_density()</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>The per-particle density, in kg / m^3</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_density(cls):\n\"\"\"\n    Returns:\n        float: The per-particle density, in kg / m^3\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.particle_instancer_idn_to_name","title":"<code>particle_instancer_idn_to_name(idn)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>idn</code> <code>idn</code> <p>Particle instancer identification number</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Name of the particle instancer auto-generated from its unique identification number</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef particle_instancer_idn_to_name(cls, idn):\n\"\"\"\n    Args:\n        idn (idn): Particle instancer identification number\n    Returns:\n        str: Name of the particle instancer auto-generated from its unique identification number\n    \"\"\"\nreturn f\"{cls.name}Instancer{idn}\"\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.particle_instancer_name_to_idn","title":"<code>particle_instancer_name_to_idn(name)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Particle instancer name</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>Particle instancer identification number</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef particle_instancer_name_to_idn(cls, name):\n\"\"\"\n    Args:\n        name (str): Particle instancer name\n    Returns:\n        int: Particle instancer identification number\n    \"\"\"\nreturn int(name.split(f\"{cls.name}Instancer\")[-1])\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.remove_all_particle_instancers","title":"<code>remove_all_particle_instancers()</code>  <code>classmethod</code>","text":"<p>Removes all particle instancers and deletes them from the simulator</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef remove_all_particle_instancers(cls):\n\"\"\"\n    Removes all particle instancers and deletes them from the simulator\n    \"\"\"\ncls._sync_particle_instancers(idns=[], particle_groups=[], particle_counts=[])\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.remove_particle_instancer","title":"<code>remove_particle_instancer(name)</code>  <code>classmethod</code>","text":"<p>Removes particle instancer with name @name from this system.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Particle instancer name to remove. If it does not exist, then an error will be raised</p> required Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef remove_particle_instancer(cls, name):\n\"\"\"\n    Removes particle instancer with name @name from this system.\n    Args:\n        name (str): Particle instancer name to remove. If it does not exist, then an error will be raised\n    \"\"\"\n# Make sure the instancer actually exists\nassert_valid_key(key=name, valid_keys=cls.particle_instancers, name=\"particle instancer\")\n# Remove instancer from our tracking and delete its prim\ninstancer = cls.particle_instancers.pop(name)\ninstancer.remove()\nog.sim.stage.RemovePrim(f\"{cls.prim_path}/{name}\")\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysicalParticleSystem.set_scale_limits","title":"<code>set_scale_limits(minimum=None, maximum=None)</code>  <code>classmethod</code>","text":"<p>Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles</p> <p>Parameters:</p> Name Type Description Default <code>minimum</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) minimum scaling factor to apply to generated particles</p> <code>None</code> <code>maximum</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) maximum scaling factor to apply to generated particles</p> <code>None</code> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef set_scale_limits(cls, minimum=None, maximum=None):\n\"\"\"\n    Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n    Args:\n        minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n            particles\n        maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n            particles\n    \"\"\"\nif minimum is not None:\ncls.min_scale = np.array(minimum)\nif maximum is not None:\ncls.max_scale = np.array(maximum)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer","title":"<code>PhysxParticleInstancer</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Simple class that wraps the raw omniverse point instancer prim and provides convenience functions for particle access</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>class PhysxParticleInstancer(BasePrim):\n\"\"\"\n    Simple class that wraps the raw omniverse point instancer prim and provides convenience functions for\n    particle access\n    \"\"\"\ndef __init__(self, prim_path, name, idn):\n\"\"\"\n        Args:\n            prim_path (str): prim path of the Prim to encapsulate or create.\n            name (str): Name for the object. Names need to be unique per scene.\n            idn (int): Unique identification number to assign to this particle instancer. This is used to\n                deterministically reproduce individual particle instancer states dynamically, even if we\n                delete / add additional ones at runtime during simulation.\n        \"\"\"\n# Store inputs\nself._idn = idn\n# Values loaded at runtime\nself._n_particles = None\n# Run super method directly\nsuper().__init__(prim_path=prim_path, name=name)\ndef _load(self):\n# We raise an error, this should NOT be created from scratch\nraise NotImplementedError(\"PhysxPointInstancer should NOT be loaded via this class! Should be created before.\")\ndef _post_load(self):\n# Run super\nsuper()._post_load()\n# Store how many particles we have\nself._n_particles = len(self.particle_positions)\ndef add_particles(\nself,\npositions,\nvelocities=None,\norientations=None,\nscales=None,\nprototype_indices=None,\n):\n\"\"\"\n        Adds particles to this particle instancer.\n        positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n        velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n            If not specified, all will be set to 0\n        orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n            orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n            If not specified, will be scale [1, 1, 1] by default\n        prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n            each particle. If None, will use all 0s (i.e.: the first prototype created)\n        \"\"\"\nn_new_particles = len(positions)\nvelocities = np.zeros((n_new_particles, 3)) if velocities is None else velocities\nif orientations is None:\norientations = np.zeros((n_new_particles, 4))\norientations[:, -1] = 1.0\nscales = np.ones((n_new_particles, 3)) * np.ones((1, 3)) if scales is None else scales\nprototype_indices = np.zeros(n_new_particles, dtype=int) if prototype_indices is None else prototype_indices\n# Update the number of particles and update the values\nself._n_particles += n_new_particles\nself.particle_positions = np.vstack([self.particle_positions, positions])\nself.particle_velocities = np.vstack([self.particle_velocities, velocities])\nself.particle_orientations = np.vstack([self.particle_orientations, orientations])\nself.particle_scales = np.vstack([self.particle_scales, scales])\nself.particle_prototype_ids = np.hstack([self.particle_prototype_ids, prototype_indices])\ndef remove_particles(self, idxs):\n\"\"\"\n        Remove particles from this instancer, specified by their indices @idxs in the data array\n        Args:\n            idxs (list or np.array of int): IDs corresponding to the indices of specific particles to remove from this\n                instancer\n        \"\"\"\nif len(idxs) &gt; 0:\n# Update the number of particles\nself._n_particles -= len(idxs)\n# Remove all requested indices and write to all the internal data arrays\nself.particle_positions = np.delete(self.particle_positions, idxs, axis=0)\nself.particle_velocities = np.delete(self.particle_velocities, idxs, axis=0)\nself.particle_orientations = np.delete(self.particle_orientations, idxs, axis=0)\nself.particle_scales = np.delete(self.particle_scales, idxs, axis=0)\nself.particle_prototype_ids = np.delete(self.particle_prototype_ids, idxs, axis=0)\ndef remove_all_particles(self):\n\"\"\"\n        Removes all particles from this instancer, but does NOT delete this instancer\n        \"\"\"\nself.remove_particles(idxs=np.arange(self._n_particles))\n@property\ndef n_particles(self):\n\"\"\"\n        Returns:\n            int: Number of particles owned by this instancer\n        \"\"\"\nreturn self._n_particles\n@property\ndef idn(self):\n\"\"\"\n        Returns:\n            int: Identification number of this particle instancer\n        \"\"\"\nreturn self._idn\n@property\ndef particle_group(self):\n\"\"\"\n        Returns:\n            int: Particle group this instancer belongs to\n        \"\"\"\nreturn self.get_attribute(attr=\"physxParticle:particleGroup\")\n@particle_group.setter\ndef particle_group(self, group):\n\"\"\"\n        Args:\n            group (int): Particle group this instancer belongs to\n        \"\"\"\nself.set_attribute(attr=\"physxParticle:particleGroup\", val=group)\n@property\ndef particle_positions(self):\n\"\"\"\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\nreturn np.array(self.get_attribute(attr=\"positions\"))\n@particle_positions.setter\ndef particle_positions(self, pos):\n\"\"\"\n        Set the particle positions for this instancer\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired positions are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\nassert pos.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {pos.shape[0]}, vs. number of particles {self._n_particles}!\"\nself.set_attribute(attr=\"positions\", val=Vt.Vec3fArray.FromNumpy(pos.astype(float)))\n@property\ndef particle_orientations(self):\n\"\"\"\n        Returns:\n            np.array: (N, 4) numpy array, where each of the N particles' orientations are expressed in (x,y,z,w)\n                quaternion coordinates relative to this instancer's parent prim\n        \"\"\"\noris = self.get_attribute(attr=\"orientations\")\nassert oris is not None, f\"Orientations should be set for particle instancer {self.name}!\"\nreturn np.array(oris)\n@particle_orientations.setter\ndef particle_orientations(self, quat):\n\"\"\"\n        Set the particle positions for this instancer\n        Args:\n            np.array: (N, 4) numpy array, where each of the N particles' desired orientations are expressed in (x,y,z,w)\n                quaternion coordinates relative to this instancer's parent prim\n        \"\"\"\nassert quat.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {quat.shape[0]}, vs. number of particles {self._n_particles}!\"\n# Swap w position, since Quath takes (w,x,y,z)\nquat = quat.astype(float)\nquat = quat[:, [3, 0, 1, 2]]\nself.set_attribute(attr=\"orientations\", val=Vt.QuathArray.FromNumpy(quat))\n@property\ndef particle_velocities(self):\n\"\"\"\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' velocities are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\nreturn np.array(self.get_attribute(attr=\"velocities\"))\n@particle_velocities.setter\ndef particle_velocities(self, vel):\n\"\"\"\n        Set the particle velocities for this instancer\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired velocities are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\nassert vel.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {vel.shape[0]}, vs. number of particles {self._n_particles}!\"\nvel = vel.astype(float)\nself.set_attribute(attr=\"velocities\", val=Vt.Vec3fArray.FromNumpy(vel))\n@property\ndef particle_scales(self):\n\"\"\"\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' scales are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\nscales = self.get_attribute(attr=\"scales\")\nreturn np.ones((self._n_particles, 3)) if scales is None else np.array(scales)\n@particle_scales.setter\ndef particle_scales(self, scales):\n\"\"\"\n        Set the particle scales for this instancer\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired scales are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\nassert scales.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {scales.shape[0]}, vs. number of particles {self._n_particles}!\"\nscales = scales.astype(float)\nself.set_attribute(attr=\"scales\", val=Vt.Vec3fArray.FromNumpy(scales))\n@property\ndef particle_prototype_ids(self):\n\"\"\"\n        Returns:\n            np.array: (N,) numpy array, where each of the N particles' prototype_id (i.e.: which prototype is being used\n                for that particle)\n        \"\"\"\nids = self.get_attribute(attr=\"protoIndices\")\nreturn np.zeros(self.n_particles) if ids is None else np.array(ids)\n@particle_prototype_ids.setter\ndef particle_prototype_ids(self, prototype_ids):\n\"\"\"\n        Set the particle prototype_ids for this instancer\n        Args:\n            np.array: (N,) numpy array, where each of the N particles' desired prototype_id\n                (i.e.: which prototype is being used for that particle)\n        \"\"\"\nassert prototype_ids.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {prototype_ids.shape[0]}, vs. number of particles {self._n_particles}!\"\nself.set_attribute(attr=\"protoIndices\", val=prototype_ids)\n@property\ndef state_size(self):\n# idn (1), particle_group (1), n_particles (1), and the corresponding states for each particle\n# N * (pos (3) + vel (3) + orn (4) + scale (3) + prototype_id (1))\nreturn 3 + self._n_particles * 14\ndef _dump_state(self):\nreturn dict(\nidn=self._idn,\nparticle_group=self.particle_group,\nn_particles=self._n_particles,\nparticle_positions=self.particle_positions,\nparticle_velocities=self.particle_velocities,\nparticle_orientations=self.particle_orientations,\nparticle_scales=self.particle_scales,\nparticle_prototype_ids=self.particle_prototype_ids,\n)\ndef _load_state(self, state):\n# Sanity check the identification number and particle group\nassert self._idn == state[\"idn\"], f\"Got mismatch in identification number for this particle instancer when \" \\\n            f\"loading state! Should be: {self._idn}, got: {state['idn']}.\"\nassert self.particle_group == state[\"particle_group\"], f\"Got mismatch in particle group for this particle \" \\\n            f\"instancer when loading state! Should be: {self.particle_group}, got: {state['particle_group']}.\"\n# Set values appropriately\nself._n_particles = state[\"n_particles\"]\nkeys = (\"particle_positions\", \"particle_velocities\", \"particle_orientations\", \"particle_scales\", \"particle_prototype_ids\")\nfor key in keys:\n# Make sure the loaded state is a numpy array, it could have been accidentally casted into a list during\n# JSON-serialization\nval = np.array(state[key]) if not isinstance(state[key], np.ndarray) else state[key]\nsetattr(self, key, val)\ndef _serialize(self, state):\n# Compress into a 1D array\nreturn np.concatenate([\n[state[\"idn\"], state[\"particle_group\"], state[\"n_particles\"]],\nstate[\"particle_positions\"].reshape(-1),\nstate[\"particle_velocities\"].reshape(-1),\nstate[\"particle_orientations\"].reshape(-1),\nstate[\"particle_scales\"].reshape(-1),\nstate[\"particle_prototype_ids\"],\n]).astype(float)\ndef _deserialize(self, state):\n# Sanity check the identification number\nassert self._idn == state[0], f\"Got mismatch in identification number for this particle instancer when \" \\\n            f\"deserializing state! Should be: {self._idn}, got: {state[0]}.\"\nassert self.particle_group == state[1], f\"Got mismatch in particle group for this particle \" \\\n            f\"instancer when deserializing state! Should be: {self.particle_group}, got: {state[1]}.\"\n# De-compress from 1D array\nn_particles = int(state[2])\nstate_dict = dict(\nidn=int(state[0]),\nparticle_group=int(state[1]),\nn_particles=n_particles,\n)\n# Process remaining keys and reshape automatically\nkeys = (\"particle_positions\", \"particle_velocities\", \"particle_orientations\", \"particle_scales\", \"particle_prototype_ids\")\nsizes = ((n_particles, 3), (n_particles, 3), (n_particles, 4), (n_particles, 3), (n_particles,))\nidx = 3\nfor key, size in zip(keys, sizes):\nlength = np.product(size)\nstate_dict[key] = state[idx: idx + length].reshape(size)\nidx += length\nreturn state_dict, idx\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.idn","title":"<code>idn</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Identification number of this particle instancer</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.n_particles","title":"<code>n_particles</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Number of particles owned by this instancer</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_group","title":"<code>particle_group</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Particle group this instancer belongs to</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_orientations","title":"<code>particle_orientations</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>np.array: (N, 4) numpy array, where each of the N particles' orientations are expressed in (x,y,z,w) quaternion coordinates relative to this instancer's parent prim</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_positions","title":"<code>particle_positions</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z) cartesian coordinates relative to this instancer's parent prim</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_prototype_ids","title":"<code>particle_prototype_ids</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>np.array: (N,) numpy array, where each of the N particles' prototype_id (i.e.: which prototype is being used for that particle)</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_scales","title":"<code>particle_scales</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>np.array: (N, 3) numpy array, where each of the N particles' scales are expressed in (x,y,z) cartesian coordinates relative to this instancer's parent prim</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_velocities","title":"<code>particle_velocities</code>  <code>property</code> <code>writable</code>","text":"<p>Returns:</p> Type Description <p>np.array: (N, 3) numpy array, where each of the N particles' velocities are expressed in (x,y,z) cartesian coordinates relative to this instancer's parent prim</p>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.__init__","title":"<code>__init__(prim_path, name, idn)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>prim path of the Prim to encapsulate or create.</p> required <code>name</code> <code>str</code> <p>Name for the object. Names need to be unique per scene.</p> required <code>idn</code> <code>int</code> <p>Unique identification number to assign to this particle instancer. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation.</p> required Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>def __init__(self, prim_path, name, idn):\n\"\"\"\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        idn (int): Unique identification number to assign to this particle instancer. This is used to\n            deterministically reproduce individual particle instancer states dynamically, even if we\n            delete / add additional ones at runtime during simulation.\n    \"\"\"\n# Store inputs\nself._idn = idn\n# Values loaded at runtime\nself._n_particles = None\n# Run super method directly\nsuper().__init__(prim_path=prim_path, name=name)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.add_particles","title":"<code>add_particles(positions, velocities=None, orientations=None, scales=None, prototype_indices=None)</code>","text":"<p>Adds particles to this particle instancer.</p> <p>positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions. velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.     If not specified, all will be set to 0 orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion     orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1) scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.     If not specified, will be scale [1, 1, 1] by default prototype_indices (None or list of int): If specified, should specify which prototype should be used for     each particle. If None, will use all 0s (i.e.: the first prototype created)</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>def add_particles(\nself,\npositions,\nvelocities=None,\norientations=None,\nscales=None,\nprototype_indices=None,\n):\n\"\"\"\n    Adds particles to this particle instancer.\n    positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n    velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n        If not specified, all will be set to 0\n    orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n        orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n    scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n        If not specified, will be scale [1, 1, 1] by default\n    prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n        each particle. If None, will use all 0s (i.e.: the first prototype created)\n    \"\"\"\nn_new_particles = len(positions)\nvelocities = np.zeros((n_new_particles, 3)) if velocities is None else velocities\nif orientations is None:\norientations = np.zeros((n_new_particles, 4))\norientations[:, -1] = 1.0\nscales = np.ones((n_new_particles, 3)) * np.ones((1, 3)) if scales is None else scales\nprototype_indices = np.zeros(n_new_particles, dtype=int) if prototype_indices is None else prototype_indices\n# Update the number of particles and update the values\nself._n_particles += n_new_particles\nself.particle_positions = np.vstack([self.particle_positions, positions])\nself.particle_velocities = np.vstack([self.particle_velocities, velocities])\nself.particle_orientations = np.vstack([self.particle_orientations, orientations])\nself.particle_scales = np.vstack([self.particle_scales, scales])\nself.particle_prototype_ids = np.hstack([self.particle_prototype_ids, prototype_indices])\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.remove_all_particles","title":"<code>remove_all_particles()</code>","text":"<p>Removes all particles from this instancer, but does NOT delete this instancer</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>def remove_all_particles(self):\n\"\"\"\n    Removes all particles from this instancer, but does NOT delete this instancer\n    \"\"\"\nself.remove_particles(idxs=np.arange(self._n_particles))\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.remove_particles","title":"<code>remove_particles(idxs)</code>","text":"<p>Remove particles from this instancer, specified by their indices @idxs in the data array</p> <p>Parameters:</p> Name Type Description Default <code>idxs</code> <code>list or np.array of int</code> <p>IDs corresponding to the indices of specific particles to remove from this instancer</p> required Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>def remove_particles(self, idxs):\n\"\"\"\n    Remove particles from this instancer, specified by their indices @idxs in the data array\n    Args:\n        idxs (list or np.array of int): IDs corresponding to the indices of specific particles to remove from this\n            instancer\n    \"\"\"\nif len(idxs) &gt; 0:\n# Update the number of particles\nself._n_particles -= len(idxs)\n# Remove all requested indices and write to all the internal data arrays\nself.particle_positions = np.delete(self.particle_positions, idxs, axis=0)\nself.particle_velocities = np.delete(self.particle_velocities, idxs, axis=0)\nself.particle_orientations = np.delete(self.particle_orientations, idxs, axis=0)\nself.particle_scales = np.delete(self.particle_scales, idxs, axis=0)\nself.particle_prototype_ids = np.delete(self.particle_prototype_ids, idxs, axis=0)\n</code></pre>"},{"location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.set_carb_settings_for_fluid_isosurface","title":"<code>set_carb_settings_for_fluid_isosurface()</code>","text":"<p>Sets relevant rendering settings in the carb settings in order to use isosurface effectively</p> Source code in <code>omnigibson/systems/micro_particle_system.py</code> <pre><code>def set_carb_settings_for_fluid_isosurface():\n\"\"\"\n    Sets relevant rendering settings in the carb settings in order to use isosurface effectively\n    \"\"\"\n# Settings for Isosurface\nisregistry = carb.settings.acquire_settings_interface()\n# disable grid and lights\ndOptions = isregistry.get_as_int(\"persistent/app/viewport/displayOptions\")\ndOptions &amp;= ~(1 &lt;&lt; 6 | 1 &lt;&lt; 8)\nisregistry.set_int(\"persistent/app/viewport/displayOptions\", dOptions)\nisregistry.set_bool(SETTING_UPDATE_TO_USD, True)\nisregistry.set_int(SETTING_NUM_THREADS, 8)\nisregistry.set_bool(SETTING_UPDATE_VELOCITIES_TO_USD, True)\nisregistry.set_bool(SETTING_UPDATE_PARTICLES_TO_USD, True)     # TODO: Why does setting this value --&gt; True result in no isosurface being rendered?\nisregistry.set_int(\"persistent/simulation/minFrameRate\", 60)\nisregistry.set_bool(\"rtx-defaults/pathtracing/lightcache/cached/enabled\", False)\nisregistry.set_bool(\"rtx-defaults/pathtracing/cached/enabled\", False)\nisregistry.set_int(\"rtx-defaults/pathtracing/fireflyFilter/maxIntensityPerSample\", 10000)\nisregistry.set_int(\"rtx-defaults/pathtracing/fireflyFilter/maxIntensityPerSampleDiffuse\", 50000)\nisregistry.set_float(\"rtx-defaults/pathtracing/optixDenoiser/blendFactor\", 0.09)\nisregistry.set_int(\"rtx-defaults/pathtracing/aa/op\", 2)\nisregistry.set_int(\"rtx-defaults/pathtracing/maxBounces\", 32)\nisregistry.set_int(\"rtx-defaults/pathtracing/maxSpecularAndTransmissionBounces\", 16)\nisregistry.set_int(\"rtx-defaults/post/dlss/execMode\", 1)\nisregistry.set_int(\"rtx-defaults/translucency/maxRefractionBounces\", 12)\n</code></pre>"},{"location":"reference/systems/system_base.html","title":"system_base","text":""},{"location":"reference/systems/system_base.html#systems.system_base.BaseSystem","title":"<code>BaseSystem</code>","text":"<p>         Bases: <code>SerializableNonInstance</code>, <code>UniquelyNamedNonInstance</code></p> <p>Base class for all systems. These are non-instance objects that should be used globally for a given environment. This is useful for items in a scene that are non-discrete / cannot be distinguished into individual instances, e.g.: water, particles, etc. While we keep the python convention of the system class name being camel case (e.g. StrawberrySmoothie), we adopt the snake case for the system registry to unify with the category of BaseObject. For example, get_system(\"strawberry_smoothie\") will return the StrawberrySmoothie class.</p> Source code in <code>omnigibson/systems/system_base.py</code> <pre><code>class BaseSystem(SerializableNonInstance, UniquelyNamedNonInstance):\n\"\"\"\n    Base class for all systems. These are non-instance objects that should be used globally for a given environment.\n    This is useful for items in a scene that are non-discrete / cannot be distinguished into individual instances,\n    e.g.: water, particles, etc. While we keep the python convention of the system class name being camel case\n    (e.g. StrawberrySmoothie), we adopt the snake case for the system registry to unify with the category of BaseObject.\n    For example, get_system(\"strawberry_smoothie\") will return the StrawberrySmoothie class.\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\n# While class names are camel case, we convert them to snake case to be consistent with object categories.\ncls._snake_case_name = camel_case_to_snake_case(cls.__name__)\n# Run super init\nsuper().__init_subclass__(**kwargs)\n# Register this system if requested\nif cls._register_system:\nglobal REGISTERED_SYSTEMS\nREGISTERED_SYSTEMS[cls._snake_case_name] = cls\ncls._uuid = get_uuid(cls._snake_case_name)\ninitialized = False\n_uuid = None\n_snake_case_name = None\n@classproperty\ndef name(cls):\n# Class name is the unique name assigned\nreturn cls._snake_case_name\n@classproperty\ndef uuid(cls):\nreturn cls._uuid\n@classproperty\ndef prim_path(cls):\n\"\"\"\n        Returns:\n            str: Path to this system's prim in the scene stage\n        \"\"\"\nreturn f\"/World/{cls.name}\"\n@classproperty\ndef _register_system(cls):\n\"\"\"\n        Returns:\n            bool: True if this system should be registered (i.e.: it is not an intermediate class but a \"final\" subclass\n                representing a system we'd actually like to use, e.g.: water, dust, etc. Should be set by the subclass\n        \"\"\"\n# We assume we aren't registering by default\nreturn False\n@classmethod\ndef initialize(cls):\n\"\"\"\n        Initializes this system\n        \"\"\"\nassert not cls.initialized, f\"Already initialized system {cls.name}!\"\nog.sim.stage.DefinePrim(cls.prim_path, \"Scope\")\ncls.initialized = True\n@classmethod\ndef clear(cls):\n\"\"\"\n        Clears this system, so that it may possibly be re-initialized. Useful for, e.g., when loading from a new\n        scene during the same sim instance\n        \"\"\"\nif cls.initialized:\ncls.reset()\ncls.initialized = False\n@classmethod\ndef reset(cls):\n\"\"\"\n        Reset this system\n        \"\"\"\npass\n@classmethod\ndef get_active_systems(cls):\n\"\"\"\n        Returns:\n            dict: Mapping from system name to system for all systems that are subclasses of this system AND active (initialized)\n        \"\"\"\nreturn {system.name: system for system in SYSTEM_REGISTRY.objects if issubclass(system, cls)}\ndef __init__(self):\nraise ValueError(\"System classes should not be created!\")\n</code></pre>"},{"location":"reference/systems/system_base.html#systems.system_base.BaseSystem.clear","title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clears this system, so that it may possibly be re-initialized. Useful for, e.g., when loading from a new scene during the same sim instance</p> Source code in <code>omnigibson/systems/system_base.py</code> <pre><code>@classmethod\ndef clear(cls):\n\"\"\"\n    Clears this system, so that it may possibly be re-initialized. Useful for, e.g., when loading from a new\n    scene during the same sim instance\n    \"\"\"\nif cls.initialized:\ncls.reset()\ncls.initialized = False\n</code></pre>"},{"location":"reference/systems/system_base.html#systems.system_base.BaseSystem.get_active_systems","title":"<code>get_active_systems()</code>  <code>classmethod</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Mapping from system name to system for all systems that are subclasses of this system AND active (initialized)</p> Source code in <code>omnigibson/systems/system_base.py</code> <pre><code>@classmethod\ndef get_active_systems(cls):\n\"\"\"\n    Returns:\n        dict: Mapping from system name to system for all systems that are subclasses of this system AND active (initialized)\n    \"\"\"\nreturn {system.name: system for system in SYSTEM_REGISTRY.objects if issubclass(system, cls)}\n</code></pre>"},{"location":"reference/systems/system_base.html#systems.system_base.BaseSystem.initialize","title":"<code>initialize()</code>  <code>classmethod</code>","text":"<p>Initializes this system</p> Source code in <code>omnigibson/systems/system_base.py</code> <pre><code>@classmethod\ndef initialize(cls):\n\"\"\"\n    Initializes this system\n    \"\"\"\nassert not cls.initialized, f\"Already initialized system {cls.name}!\"\nog.sim.stage.DefinePrim(cls.prim_path, \"Scope\")\ncls.initialized = True\n</code></pre>"},{"location":"reference/systems/system_base.html#systems.system_base.BaseSystem.prim_path","title":"<code>prim_path()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Path to this system's prim in the scene stage</p> Source code in <code>omnigibson/systems/system_base.py</code> <pre><code>@classproperty\ndef prim_path(cls):\n\"\"\"\n    Returns:\n        str: Path to this system's prim in the scene stage\n    \"\"\"\nreturn f\"/World/{cls.name}\"\n</code></pre>"},{"location":"reference/systems/system_base.html#systems.system_base.BaseSystem.reset","title":"<code>reset()</code>  <code>classmethod</code>","text":"<p>Reset this system</p> Source code in <code>omnigibson/systems/system_base.py</code> <pre><code>@classmethod\ndef reset(cls):\n\"\"\"\n    Reset this system\n    \"\"\"\npass\n</code></pre>"},{"location":"reference/tasks/index.html","title":"tasks","text":""},{"location":"reference/tasks/bddl_backend.html","title":"bddl_backend","text":""},{"location":"reference/tasks/behavior_task.html","title":"behavior_task","text":""},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask","title":"<code>BehaviorTask</code>","text":"<p>         Bases: <code>BaseTask</code></p> <p>Task for BEHAVIOR</p> <p>Parameters:</p> Name Type Description Default <code>activity_name</code> <code>None or str</code> <p>Name of the Behavior Task to instantiate</p> <code>None</code> <code>activity_definition_id</code> <code>int</code> <p>Specification to load for the desired task. For a given Behavior Task, multiple task specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This ID determines which specification to use</p> <code>0</code> <code>activity_instance_id</code> <code>int</code> <p>Specific pre-configured instance of a scene to load for this BehaviorTask. This will be used only if @online_object_sampling is False.</p> <code>0</code> <code>predefined_problem</code> <code>None or str</code> <p>If specified, specifies the raw string definition of the Behavior Task to load. This will automatically override @activity_name and @activity_definition_id.</p> <code>None</code> <code>online_object_sampling</code> <code>bool</code> <p>whether to sample object locations online at runtime or not</p> <code>False</code> <code>debug_object_sampling</code> <code>None or str</code> <p>if specified, should be the object name to debug for placement functionality</p> <code>None</code> <code>highlight_task_relevant_objects</code> <code>bool</code> <p>whether to overlay task-relevant objects in the scene with a colored mask</p> <code>False</code> <code>termination_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p> <code>None</code> <code>reward_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p> <code>None</code> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>class BehaviorTask(BaseTask):\n\"\"\"\n    Task for BEHAVIOR\n    Args:\n        activity_name (None or str): Name of the Behavior Task to instantiate\n        activity_definition_id (int): Specification to load for the desired task. For a given Behavior Task, multiple task\n            specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This\n            ID determines which specification to use\n        activity_instance_id (int): Specific pre-configured instance of a scene to load for this BehaviorTask. This\n            will be used only if @online_object_sampling is False.\n        predefined_problem (None or str): If specified, specifies the raw string definition of the Behavior Task to\n            load. This will automatically override @activity_name and @activity_definition_id.\n        online_object_sampling (bool): whether to sample object locations online at runtime or not\n        debug_object_sampling (None or str): if specified, should be the object name to debug for placement functionality\n        highlight_task_relevant_objects (bool): whether to overlay task-relevant objects in the scene with a colored mask\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\ndef __init__(\nself,\nactivity_name=None,\nactivity_definition_id=0,\nactivity_instance_id=0,\npredefined_problem=None,\nonline_object_sampling=False,\ndebug_object_sampling=None,\nhighlight_task_relevant_objects=False,\ntermination_config=None,\nreward_config=None,\n):\n# Make sure task name is valid\nwith open(os.path.join(os.path.dirname(bddl.__file__), \"activity_manifest.txt\")) as f:\nall_activities = {line.strip() for line in f.readlines()}\nassert_valid_key(key=activity_name, valid_keys=all_activities, name=\"Behavior Task\")\n# Initialize relevant variables\n# BDDL\nself.backend = OmniGibsonBDDLBackend()\n# Activity info\nself.activity_name = None\nself.activity_definition_id = activity_definition_id\nself.activity_instance_id = activity_instance_id\nself.activity_conditions = None\nself.activity_initial_conditions = None\nself.activity_goal_conditions = None\nself.activity_natural_language_goal_conditions = None\nself.ground_goal_state_options = None\nself.instruction_order = None\nself.feedback = None\nself.scene_model = None\n# Object info\nself.object_taxonomy = ObjectTaxonomy()\nself.debug_object_sampling = debug_object_sampling\nself.online_object_sampling = online_object_sampling\nself.highlight_task_relevant_objs = highlight_task_relevant_objects\nself.object_scope = None\nself.object_instance_to_category = None\nself.room_type_to_object_instance = None\nself.non_sampleable_object_instances = None\nself.non_sampleable_object_scope = None\nself.non_sampleable_object_conditions = None\nself.non_sampleable_object_scope_filtered_initial = None\nself.object_sampling_orders = None\nself.sampled_objects = None\nself.sampleable_object_conditions = None\n# Logic-tracking info\nself.currently_viewed_index = None\nself.currently_viewed_instruction = None\n# Load the initial behavior configuration\nself.update_activity(activity_name=activity_name, activity_definition_id=activity_definition_id, predefined_problem=predefined_problem)\n# Run super init\nsuper().__init__(termination_config=termination_config, reward_config=reward_config)\ndef _create_termination_conditions(self):\n# Initialize termination conditions dict and fill in with Timeout and PredicateGoal\nterminations = dict()\nterminations[\"timeout\"] = Timeout(max_steps=self._termination_config[\"max_steps\"])\nterminations[\"predicate\"] = PredicateGoal(goal_fcn=lambda: self.activity_goal_conditions)\nreturn terminations\ndef _create_reward_functions(self):\n# Initialize reward functions dict and fill in with Potential reward\nrewards = dict()\nrewards[\"potential\"] = PotentialReward(\npotential_fcn=self.get_potential,\nr_potential=self._reward_config[\"r_potential\"],\n)\nreturn rewards\ndef _load(self, env):\n# Get the name of the scene\nself.scene_model = og.sim.scene.scene_model\n# Initialize the current activity\nsuccess, self.feedback = self.initialize_activity(env=env)\nif not success:\nprint(f\"Failed to initialize Behavior Activity. Feedback:\\n{self.feedback}\")\n# Highlight any task relevant objects if requested\nif self.highlight_task_relevant_objs:\nfor obj_name, obj in self.object_scope.items():\nif isinstance(obj, BaseRobot):\ncontinue\nobj.highlighted = True\ndef _load_non_low_dim_observation_space(self):\n# No non-low dim observations so we return an empty dict\nreturn dict()\ndef update_activity(self, activity_name, activity_definition_id, predefined_problem=None):\n\"\"\"\n        Update the active Behavior activity being deployed\n        Args:\n            activity_name (None or str): Name of the Behavior Task to instantiate\n            activity_definition_id (int): Specification to load for the desired task. For a given Behavior Task, multiple task\n                specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This\n                ID determines which specification to use\n            predefined_problem (None or str): If specified, specifies the raw string definition of the Behavior Task to\n                load. This will automatically override @activity_name and @activity_definition_id.\n        \"\"\"\n# Update internal variables based on values\n# Activity info\nself.activity_name = activity_name\nself.activity_definition_id = activity_definition_id\nself.activity_conditions = Conditions(\nactivity_name,\nactivity_definition_id,\nsimulator_name=\"igibson\",       # TODO: Update!\npredefined_problem=predefined_problem,\n)\n# Object info\nself.object_scope = get_object_scope(self.activity_conditions)\nself.object_instance_to_category = {\nobj_inst: obj_cat\nfor obj_cat in self.activity_conditions.parsed_objects\nfor obj_inst in self.activity_conditions.parsed_objects[obj_cat]\n}\n# Generate initial and goal conditions\nself.activity_initial_conditions = get_initial_conditions(self.activity_conditions, self.backend, self.object_scope)\nself.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\nself.ground_goal_state_options = get_ground_goal_state_options(\nself.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n)\n# Demo attributes\nself.instruction_order = np.arange(len(self.activity_conditions.parsed_goal_conditions))\nnp.random.shuffle(self.instruction_order)\nself.currently_viewed_index = 0\nself.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\nself.activity_natural_language_goal_conditions = get_natural_goal_conditions(self.activity_conditions)\ndef get_potential(self, env):\n\"\"\"\n        Compute task-specific potential: distance to the goal\n        Args:\n            env (Environment): Current active environment instance\n        Returns:\n            float: Computed potential\n        \"\"\"\n# Evaluate the first ground goal state option as the potential\n_, satisfied_predicates = evaluate_goal_conditions(self.ground_goal_state_options[0])\nsuccess_score = len(satisfied_predicates[\"satisfied\"]) / (\nlen(satisfied_predicates[\"satisfied\"]) + len(satisfied_predicates[\"unsatisfied\"])\n)\nreturn -success_score\ndef initialize_activity(self, env):\n\"\"\"\n        Initializes the desired activity in the current environment @env\n        Args:\n            env (Environment): Current active environment instance\n        Returns:\n            2-tuple:\n                - bool: Whether the generated scene activity should be accepted or not\n                - dict: Any feedback from the sampling / initialization process\n        \"\"\"\naccept_scene = True\nfeedback = None\nif self.online_object_sampling:\n# Reject scenes with missing non-sampleable objects\n# Populate object_scope with sampleable objects and the robot\naccept_scene, feedback = self.check_scene(env)\nif not accept_scene:\nreturn accept_scene, feedback\n# Sample objects to satisfy initial conditions\naccept_scene, feedback = self.sample(env)\nif not accept_scene:\nreturn accept_scene, feedback\nelse:\n# Load existing scene cache and assign object scope accordingly\nself.assign_object_scope_with_cache(env)\n# Generate goal condition with the fully populated self.object_scope\nself.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\nself.ground_goal_state_options = get_ground_goal_state_options(\nself.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n)\nreturn accept_scene, feedback\ndef parse_non_sampleable_object_room_assignment(self, env):\n\"\"\"\n        Infers which rooms each object is assigned to\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\nself.room_type_to_object_instance = dict()\nself.non_sampleable_object_instances = set()\nfor cond in self.activity_conditions.parsed_initial_conditions:\nif cond[0] == \"inroom\":\nobj_inst, room_type = cond[1], cond[2]\nobj_cat = self.object_instance_to_category[obj_inst]\nif obj_cat not in NON_SAMPLEABLE_OBJECTS:\n# Invalid room assignment\nreturn \"You have assigned room type for [{}], but [{}] is sampleable. Only non-sampleable objects can have room assignment.\".format(\nobj_cat, obj_cat\n)\nif room_type not in og.sim.scene.seg_map.room_sem_name_to_ins_name:\n# Missing room type\nreturn \"Room type [{}] missing in scene [{}].\".format(room_type, og.sim.scene.scene_model)\nif room_type not in self.room_type_to_object_instance:\nself.room_type_to_object_instance[room_type] = []\nself.room_type_to_object_instance[room_type].append(obj_inst)\nif obj_inst in self.non_sampleable_object_instances:\n# Duplicate room assignment\nreturn \"Object [{}] has more than one room assignment\".format(obj_inst)\nself.non_sampleable_object_instances.add(obj_inst)\nfor obj_cat in self.activity_conditions.parsed_objects:\nif obj_cat not in NON_SAMPLEABLE_OBJECTS:\ncontinue\nfor obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\nif obj_inst not in self.non_sampleable_object_instances:\n# Missing room assignment\nreturn \"All non-sampleable objects should have room assignment. [{}] does not have one.\".format(\nobj_inst\n)\ndef build_sampling_order(self, env):\n\"\"\"\n        Sampling orders is a list of lists: [[batch_1_inst_1, ... batch_1_inst_N], [batch_2_inst_1, batch_2_inst_M], ...]\n        Sampling should happen for batch 1 first, then batch 2, so on and so forth\n        Example: OnTop(plate, table) should belong to batch 1, and OnTop(apple, plate) should belong to batch 2\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\nself.object_sampling_orders = []\ncur_batch = self.non_sampleable_object_instances\nwhile len(cur_batch) &gt; 0:\nself.object_sampling_orders.append(cur_batch)\nnext_batch = set()\nfor cond in self.activity_conditions.parsed_initial_conditions:\nif len(cond) == 3 and cond[2] in cur_batch:\nnext_batch.add(cond[1])\ncur_batch = next_batch\nif len(self.object_sampling_orders) &gt; 0:\nremaining_objs = self.object_scope.keys() - set.union(*self.object_sampling_orders)\nelse:\nremaining_objs = self.object_scope.keys()\n# Macro particles and water don't need initial conditions\nremaining_objs = {obj_inst for obj_inst in remaining_objs\nif self.object_instance_to_category[obj_inst] not in MACRO_PARTICLE_SYNSETS.union(WATER_SYNSETS)}\nif len(remaining_objs) != 0:\nreturn \"Some objects do not have any kinematic condition defined for them in the initial conditions: {}\".format(\n\", \".join(remaining_objs)\n)\ndef build_non_sampleable_object_scope(self, env):\n\"\"\"\n        Store simulator object options for non-sampleable objects in self.non_sampleable_object_scope\n        {\n            \"living_room\": {\n                \"table1\": {\n                    \"living_room_0\": [URDFObject, URDFObject, URDFObject],\n                    \"living_room_1\": [URDFObject]\n                },\n                \"table2\": {\n                    \"living_room_0\": [URDFObject, URDFObject],\n                    \"living_room_1\": [URDFObject, URDFObject]\n                },\n                \"chair1\": {\n                    \"living_room_0\": [URDFObject],\n                    \"living_room_1\": [URDFObject]\n                },\n            }\n        }\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\nroom_type_to_scene_objs = {}\nfor room_type in self.room_type_to_object_instance:\nroom_type_to_scene_objs[room_type] = {}\nfor obj_inst in self.room_type_to_object_instance[room_type]:\nroom_type_to_scene_objs[room_type][obj_inst] = {}\nobj_cat = self.object_instance_to_category[obj_inst]\n# We allow burners to be used as if they are stoves\ncategories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\nif obj_cat == \"stove.n.01\":\ncategories += self.object_taxonomy.get_subtree_igibson_categories(\"burner.n.02\")\nfor room_inst in og.sim.scene.seg_map.room_sem_name_to_ins_name[room_type]:\n# A list of scene objects that satisfy the requested categories\nroom_objs = og.sim.scene.object_registry(\"in_rooms\", room_inst, default_val=[])\nscene_objs = [obj for obj in room_objs if obj.category in categories]\nif len(scene_objs) != 0:\nroom_type_to_scene_objs[room_type][obj_inst][room_inst] = scene_objs\nerror_msg = self.consolidate_room_instance(room_type_to_scene_objs, \"initial_pre-sampling\")\nif error_msg:\nreturn error_msg\nself.non_sampleable_object_scope = room_type_to_scene_objs\ndef import_sampleable_objects(self, env):\n\"\"\"\n        Import all objects that can be sampled\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\nassert og.sim.is_stopped(), \"Simulator should be stopped when importing sampleable objects\"\n# Move the robot object frame to a far away location, similar to other newly imported objects below\nenv.robots[0].set_position_orientation([300, 300, 300], [0, 0, 0, 1])\nself.sampled_objects = set()\nnum_new_obj = 0\n# Only populate self.object_scope for sampleable objects\navg_category_spec = get_og_avg_category_specs()\nfor obj_cat in self.activity_conditions.parsed_objects:\nif obj_cat == \"agent.n.01\":\ncontinue\nif obj_cat in NON_SAMPLEABLE_OBJECTS:\ncontinue\nif obj_cat in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\nassert len(self.activity_conditions.parsed_objects[obj_cat]) == 1, \"Systems are singletons\"\nobj_inst = self.activity_conditions.parsed_objects[obj_cat][0]\nself.object_scope[obj_inst] = get_system(SYSTEM_SYNSETS_TO_SYSTEM_NAMES[obj_cat])\ncontinue\nis_sliceable = self.object_taxonomy.has_ability(obj_cat, \"sliceable\")\ncategories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\n# TODO: temporary hack\nremove_categories = [\n\"pop_case\",  # too large\n\"jewel\",  # too small\n\"ring\",  # too small\n]\nfor remove_category in remove_categories:\nif remove_category in categories:\ncategories.remove(remove_category)\nfor obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\ncategory = np.random.choice(categories)\n# for sliceable objects, only get the whole objects\ntry:\nmodel_choices = get_object_models_of_category(\ncategory, filter_method=\"sliceable_whole\" if is_sliceable else None\n)\nexcept:\nog.sim.play()\nreturn f\"Missing object category: {category}\"\nif len(model_choices) == 0:\n# restore back to the play state\nog.sim.play()\nreturn f\"Missing valid object models for category: {category}\"\n# TODO: This no longer works because model ID changes in the new asset\n# Filter object models if the object category is openable\n# synset = self.object_taxonomy.get_class_name_from_igibson_category(category)\n# if self.object_taxonomy.has_ability(synset, \"openable\"):\n#     # Always use the articulated version of a certain object if its category is openable\n#     # E.g. backpack, jar, etc\n#     model_choices = [m for m in model_choices if \"articulated_\" in m]\n#     if len(model_choices) == 0:\n#         return \"{} is Openable, but does not have articulated models.\".format(category)\n# Randomly select an object model\nmodel = np.random.choice(model_choices)\n# TODO: temporary hack no longer works because model ID changes in the new asset\n# for \"collecting aluminum cans\", we need pop cans (not bottles)\n# if category == \"pop\" and self.activity_name in [\"collecting_aluminum_cans\"]:\n#     model = np.random.choice([str(i) for i in range(40, 46)])\n# if category == \"spoon\" and self.activity_name in [\"polishing_silver\"]:\n#     model = np.random.choice([str(i) for i in [2, 5, 6]])\nmodel_path = get_og_model_path(category, model)\nusd_path = os.path.join(model_path, \"usd\", f\"{model}.usd\")\nobj_name = \"{}_{}\".format(category, len(og.sim.scene.objects))\n# create the object\nsimulator_obj = DatasetObject(\nprim_path=f\"/World/{obj_name}\",\nusd_path=usd_path,\nname=obj_name,\ncategory=category,\nfit_avg_dim_volume=True,\n)\nnum_new_obj += 1\n# Load the object into the simulator\nassert og.sim.scene.loaded, \"Scene is not loaded\"\nog.sim.import_object(simulator_obj)\n# Set these objects to be far-away locations\nsimulator_obj.set_position(np.array([100.0 + num_new_obj - 1, 100.0, -100.0]))\nself.sampled_objects.add(simulator_obj)\nself.object_scope[obj_inst] = simulator_obj\ndef check_scene(self, env):\n\"\"\"\n        Runs sanity checks for the current scene for the given BEHAVIOR task\n        Args:\n            env (Environment): Current active environment instance\n        Returns:\n            2-tuple:\n                - bool: Whether the generated scene activity should be accepted or not\n                - dict: Any feedback from the sampling / initialization process\n        \"\"\"\nerror_msg = self.parse_non_sampleable_object_room_assignment(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.build_sampling_order(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.build_non_sampleable_object_scope(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.import_sampleable_objects(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nself.object_scope[\"agent.n.01_1\"] = self.get_agent(env)\nreturn True, None\ndef get_agent(self, env):\n\"\"\"\n        Grab the 0th agent from @env\n        Args:\n            env (Environment): Current active environment instance\n        Returns:\n            BaseRobot: The 0th robot from the environment instance\n        \"\"\"\n# We assume the relevant agent is the first agent in the scene\nreturn env.robots[0]\ndef assign_object_scope_with_cache(self, env):\n\"\"\"\n        Assigns objects within the current object scope\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\n# Assign object_scope based on a cached scene\nfor obj_inst in self.object_scope:\nmatched_sim_obj = None\n# If the object scope points to the agent\nif obj_inst == \"agent.n.01_1\":\nmatched_sim_obj = self.get_agent(env)\n# If the object scope points to a system\nelif self.object_instance_to_category[obj_inst] in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\nmatched_sim_obj = get_system(SYSTEM_SYNSETS_TO_SYSTEM_NAMES[self.object_instance_to_category[obj_inst]])\nelse:\nlog.info(f\"checking objects...\")\nfor sim_obj in og.sim.scene.objects:\nlog.info(f\"checking bddl obj scope for obj: {sim_obj.name}\")\nif hasattr(sim_obj, \"bddl_object_scope\") and sim_obj.bddl_object_scope == obj_inst:\nmatched_sim_obj = sim_obj\nbreak\nassert matched_sim_obj is not None, obj_inst\nself.object_scope[obj_inst] = matched_sim_obj\ndef process_single_condition(self, condition):\n\"\"\"\n        Processes a single BDDL condition\n        Args:\n            condition (Condition): Condition to process\n        Returns:\n            2-tuple:\n                - Expression: Condition's expression\n                - bool: Whether this evaluated condition is positive or negative\n        \"\"\"\nif not isinstance(condition.children[0], Negation) and not isinstance(condition.children[0], AtomicFormula):\nlog.warning((\"Skipping over sampling of predicate that is not a negation or an atomic formula\"))\nreturn None, None\nif isinstance(condition.children[0], Negation):\ncondition = condition.children[0].children[0]\npositive = False\nelse:\ncondition = condition.children[0]\npositive = True\nreturn condition, positive\ndef group_initial_conditions(self):\n\"\"\"\n        We group initial conditions by first splitting the desired task-relevant objects into non-sampleable objects\n        and sampleable objects.\n        Non-sampleable objects are objects that should ALREADY be in the scene, and should NOT be generated / sampled\n        on the fly\n        Sampleable objects are objects that need to be additionally imported into the scene.\n        Returns:\n            None or str: None if successful, otherwise failure string\n        \"\"\"\nself.non_sampleable_object_conditions = []\nself.sampleable_object_conditions = []\n# TODO: currently we assume self.initial_conditions is a list of\n# bddl.condition_evaluation.HEAD, each with one child.\n# This child is either a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate or\n# a Negation of a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate\nfor condition in self.activity_initial_conditions:\ncondition, positive = self.process_single_condition(condition)\nif condition is None:\ncontinue\n# Sampled conditions must always be positive\n# Non-positive (e.g.: NOT onTop) is not restrictive enough for sampling\nif condition.STATE_NAME in KINEMATICS_STATES and not positive:\nreturn \"Initial condition has negative kinematic conditions: {}\".format(condition.body)\ncondition_body = set(condition.body)\n# If the condition involves any non-sampleable object (e.g.: furniture), it's a non-sampleable condition\n# This means that there's no ordering constraint in terms of sampling, because we know the, e.g., furniture\n# object already exists in the scene and is placed, so these specific conditions can be sampled without\n# any dependencies\nif len(self.non_sampleable_object_instances.intersection(condition_body)) &gt; 0:\nself.non_sampleable_object_conditions.append((condition, positive))\nelse:\n# There are dependencies that must be taken into account\nself.sampleable_object_conditions.append((condition, positive))\ndef filter_object_scope(self, input_object_scope, conditions, condition_type):\n\"\"\"\n        Filters the object scope based on given @input_object_scope, @conditions, and @condition_type\n        Args:\n            input_object_scope (dict):\n            conditions (list): List of conditions to filter scope with, where each list entry is\n                a tuple of (condition, positive), where @positive is True if the condition has a positive\n                evaluation.\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n        Returns:\n            dict: Filtered object scope\n        \"\"\"\nfiltered_object_scope = {}\nfor room_type in input_object_scope:\nfiltered_object_scope[room_type] = {}\nfor scene_obj in input_object_scope[room_type]:\nfiltered_object_scope[room_type][scene_obj] = {}\nfor room_inst in input_object_scope[room_type][scene_obj]:\n# These are a list of candidate simulator objects that need sampling test\nfor obj in input_object_scope[room_type][scene_obj][room_inst]:\n# Temporarily set object_scope to point to this candidate object\nself.object_scope[scene_obj] = obj\nsuccess = True\n# If this candidate object is not involved in any conditions,\n# success will be True by default and this object will qualify\nfor condition, positive in conditions:\n# Sample positive kinematic conditions that involve this candidate object\nif condition.STATE_NAME in KINEMATICS_STATES and positive and scene_obj in condition.body:\n# Use pybullet GUI for debugging\nif self.debug_object_sampling is not None and self.debug_object_sampling == condition.body[0]:\ngm.DEBUG = True\nsuccess = condition.sample(binary_state=positive)\nlog_msg = \" \".join(\n[\n\"{} condition sampling\".format(condition_type),\nroom_type,\nscene_obj,\nroom_inst,\nobj.name,\ncondition.STATE_NAME,\nstr(condition.body),\nstr(success),\n]\n)\nlog.warning(log_msg)\n# If any condition fails for this candidate object, skip\nif not success:\nbreak\n# If this candidate object fails, move on to the next candidate object\nif not success:\ncontinue\nif room_inst not in filtered_object_scope[room_type][scene_obj]:\nfiltered_object_scope[room_type][scene_obj][room_inst] = []\nfiltered_object_scope[room_type][scene_obj][room_inst].append(obj)\nreturn filtered_object_scope\ndef consolidate_room_instance(self, filtered_object_scope, condition_type):\n\"\"\"\n        Consolidates room instances\n        Args:\n            filtered_object_scope (dict): Filtered object scope\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n        \"\"\"\nfor room_type in filtered_object_scope:\n# For each room_type, filter in room_inst that has successful\n# sampling options for all obj_inst in this room_type\nroom_inst_satisfied = set.intersection(\n*[\nset(filtered_object_scope[room_type][obj_inst].keys())\nfor obj_inst in filtered_object_scope[room_type]\n]\n)\nif len(room_inst_satisfied) == 0:\nerror_msg = \"{}: Room type [{}] of scene [{}] do not contain or cannot sample all the objects needed.\\nThe following are the possible room instances for each object, the intersection of which is an empty set.\\n\".format(\ncondition_type, room_type, self.scene_model\n)\nfor obj_inst in filtered_object_scope[room_type]:\nerror_msg += (\n\"{}: \".format(obj_inst) + \", \".join(filtered_object_scope[room_type][obj_inst].keys()) + \"\\n\"\n)\nreturn error_msg\nfor obj_inst in filtered_object_scope[room_type]:\nfiltered_object_scope[room_type][obj_inst] = {\nkey: val\nfor key, val in filtered_object_scope[room_type][obj_inst].items()\nif key in room_inst_satisfied\n}\ndef maximum_bipartite_matching(self, filtered_object_scope, condition_type):\n\"\"\"\n        Matches objects from @filtered_object_scope to specific room instances it can be\n        sampled from\n        Args:\n            filtered_object_scope (dict): Filtered object scope\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\n# For each room instance, perform maximum bipartite matching between object instance in scope to simulator objects\n# Left nodes: a list of object instance in scope\n# Right nodes: a list of simulator objects\n# Edges: if the simulator object can support the sampling requirement of ths object instance\nfor room_type in filtered_object_scope:\n# The same room instances will be shared across all scene obj in a given room type\nsome_obj = list(filtered_object_scope[room_type].keys())[0]\nroom_insts = list(filtered_object_scope[room_type][some_obj].keys())\nsuccess = False\n# Loop through each room instance\nfor room_inst in room_insts:\ngraph = nx.Graph()\n# For this given room instance, gether mapping from obj instance to a list of simulator obj\nobj_inst_to_obj_per_room_inst = {}\nfor obj_inst in filtered_object_scope[room_type]:\nobj_inst_to_obj_per_room_inst[obj_inst] = filtered_object_scope[room_type][obj_inst][room_inst]\ntop_nodes = []\nlog_msg = \"MBM for room instance [{}]\".format(room_inst)\nlog.warning((log_msg))\nfor obj_inst in obj_inst_to_obj_per_room_inst:\nfor obj in obj_inst_to_obj_per_room_inst[obj_inst]:\n# Create an edge between obj instance and each of the simulator obj that supports sampling\ngraph.add_edge(obj_inst, obj)\nlog_msg = \"Adding edge: {} &lt;-&gt; {}\".format(obj_inst, obj.name)\nlog.warning((log_msg))\ntop_nodes.append(obj_inst)\n# Need to provide top_nodes that contain all nodes in one bipartite node set\n# The matches will have two items for each match (e.g. A -&gt; B, B -&gt; A)\nmatches = nx.bipartite.maximum_matching(graph, top_nodes=top_nodes)\nif len(matches) == 2 * len(obj_inst_to_obj_per_room_inst):\nlog.warning((\"Object scope finalized:\"))\nfor obj_inst, obj in matches.items():\nif obj_inst in obj_inst_to_obj_per_room_inst:\nself.object_scope[obj_inst] = obj\nlog.warning((obj_inst, obj.name))\nsuccess = True\nbreak\nif not success:\nreturn \"{}: Room type [{}] of scene [{}] do not have enough simulator objects that can successfully sample all the objects needed. This is usually caused by specifying too many object instances in the object scope or the conditions are so stringent that too few simulator objects can satisfy them via sampling.\\n\".format(\ncondition_type, room_type, self.scene_model\n)\ndef sample_conditions(self, input_object_scope, conditions, condition_type):\n\"\"\"\n        Sample conditions\n        Args:\n            input_object_scope (dict):\n            conditions (list): List of conditions to filter scope with, where each list entry is\n                a tuple of (condition, positive), where @positive is True if the condition has a positive\n                evaluation.\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\nfiltered_object_scope = self.filter_object_scope(input_object_scope, conditions, condition_type)\nerror_msg = self.consolidate_room_instance(filtered_object_scope, condition_type)\nif error_msg:\nreturn error_msg, None\nreturn self.maximum_bipartite_matching(filtered_object_scope, condition_type), filtered_object_scope\ndef sample_initial_conditions(self):\n\"\"\"\n        Sample initial conditions\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\nerror_msg, self.non_sampleable_object_scope_filtered_initial = self.sample_conditions(\nself.non_sampleable_object_scope, self.non_sampleable_object_conditions, \"initial\"\n)\nreturn error_msg\ndef sample_goal_conditions(self):\n\"\"\"\n        Sample goal conditions\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\nnp.random.shuffle(self.ground_goal_state_options)\nlog.warning((\"number of ground_goal_state_options\", len(self.ground_goal_state_options)))\nnum_goal_condition_set_to_test = 10\ngoal_condition_success = False\n# Try to fulfill different set of ground goal conditions (maximum num_goal_condition_set_to_test)\nfor goal_condition_set in self.ground_goal_state_options[:num_goal_condition_set_to_test]:\ngoal_condition_processed = []\nfor condition in goal_condition_set:\ncondition, positive = self.process_single_condition(condition)\nif condition is None:\ncontinue\ngoal_condition_processed.append((condition, positive))\nerror_msg, _ = self.sample_conditions(\nself.non_sampleable_object_scope_filtered_initial, goal_condition_processed, \"goal\"\n)\nif not error_msg:\n# if one set of goal conditions (and initial conditions) are satisfied, sampling is successful\ngoal_condition_success = True\nbreak\nif not goal_condition_success:\nreturn error_msg\ndef sample_initial_conditions_final(self):\n\"\"\"\n        Sample final initial conditions\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\n# Do the final round of sampling with object scope fixed\nfor condition, positive in self.non_sampleable_object_conditions:\nnum_trials = 10\nfor _ in range(num_trials):\nsuccess = condition.sample(binary_state=positive)\nif success:\nbreak\nif not success:\nerror_msg = \"Non-sampleable object conditions failed even after successful matching: {}\".format(\ncondition.body\n)\nreturn error_msg\nif len(self.object_sampling_orders) &gt; 0:\n# Pop non-sampleable objects\nself.object_sampling_orders.pop(0)\nfor cur_batch in self.object_sampling_orders:\n# First sample non-sliced conditions\nfor condition, positive in self.sampleable_object_conditions:\nif condition.STATE_NAME == \"sliced\":\ncontinue\n# Sample conditions that involve the current batch of objects\nif condition.body[0] in cur_batch:\nnum_trials = 10\nfor _ in range(num_trials):\nsuccess = condition.sample(binary_state=positive)\nif success:\nbreak\nif not success:\nreturn \"Sampleable object conditions failed: {} {}\".format(\ncondition.STATE_NAME, condition.body\n)\n# Then sample sliced conditions\nfor condition, positive in self.sampleable_object_conditions:\nif condition.STATE_NAME != \"sliced\":\ncontinue\n# Sample conditions that involve the current batch of objects\nif condition.body[0] in cur_batch:\nsuccess = condition.sample(binary_state=positive)\nif not success:\nreturn \"Sampleable object conditions failed: {}\".format(condition.body)\n# One more sim step to make sure the object states are propagated correctly\n# E.g. after sampling Filled.set_value(True), Filled.get_value() will become True only after one step\nog.sim.step()\ndef sample(self, env, validate_goal=False):\n\"\"\"\n        Run sampling for this BEHAVIOR task\n        Args:\n            env (Environment): Current active environment instance\n            validate_goal (bool): Whether the goal should be validated or not\n        Returns:\n            2-tuple:\n                - bool: Whether sampling was successful or not\n                - None or str: None if successful, otherwise the associated error message\n        \"\"\"\n# Auto-initialize all sampleable objects\nog.sim.play()\nenv.scene.reset()\nerror_msg = self.group_initial_conditions()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.sample_initial_conditions()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nif validate_goal:\nerror_msg = self.sample_goal_conditions()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.sample_initial_conditions_final()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nenv.scene.update_initial_state()\nog.sim.stop()\nreturn True, None\ndef _get_obs(self, env):\nlow_dim_obs = dict()\nlow_dim_obs[\"robot_pos\"] = np.array(env.robots[0].get_position())\nlow_dim_obs[\"robot_ori_cos\"] = np.cos(env.robots[0].get_rpy())\nlow_dim_obs[\"robot_ori_sin\"] = np.sin(env.robots[0].get_rpy())\ni = 0\nfor _, v in self.object_scope.items():\n# TODO: May need to update checking here to USDObject? Or even baseobject?\nif isinstance(v, DatasetObject):\nlow_dim_obs[f\"obj_{i}_valid\"] = np.array([1.0])\nlow_dim_obs[f\"obj_{i}_pos\"] = v.get_position()\nlow_dim_obs[f\"obj_{i}_ori_cos\"] = np.cos(v.get_rpy())\nlow_dim_obs[f\"obj_{i}_ori_sin\"] = np.sin(v.get_rpy())\nfor arm in env.robots[0].arm_names:\ngrasping_object = env.robots[0].is_grasping(arm=arm, candidate_obj=v)\nlow_dim_obs[f\"obj_{i}_pos_in_gripper_{arm}\"] = np.array([float(grasping_object)])\ni += 1\nreturn low_dim_obs, dict()\ndef _step_termination(self, env, action, info=None):\n# Run super first\ndone, info = super()._step_termination(env=env, action=action, info=info)\n# Add additional info\ninfo[\"goal_status\"] = self._termination_conditions[\"predicate\"].goal_status\nreturn done, info\ndef show_instruction(self):\n\"\"\"\n        Get current instruction for user\n        Returns:\n            3-tuple:\n                - str: Current goal condition in natural language\n                - 3-tuple: (R,G,B) color to assign to text\n                - list of BaseObject: Relevant objects for the current instruction\n        \"\"\"\nsatisfied = self.currently_viewed_instruction in self._termination_conditions[\"predicate\"].goal_status[\"satisfied\"]\nnatural_language_condition = self.activity_natural_language_goal_conditions[self.currently_viewed_instruction]\nobjects = self.activity_goal_conditions[self.currently_viewed_instruction].get_relevant_objects()\ntext_color = (\n[83.0 / 255.0, 176.0 / 255.0, 72.0 / 255.0] if satisfied else [255.0 / 255.0, 51.0 / 255.0, 51.0 / 255.0]\n)\nreturn natural_language_condition, text_color, objects\ndef iterate_instruction(self):\n\"\"\"\n        Increment the instruction\n        \"\"\"\nself.currently_viewed_index = (self.currently_viewed_index + 1) % len(self.activity_conditions.parsed_goal_conditions)\nself.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\n@property\ndef name(self):\n\"\"\"\n        Returns:\n            str: Name of this task. Defaults to class name\n        \"\"\"\nname_base = super().name\n# Add activity name, def id, and inst id\nreturn f\"{name_base}_{self.activity_name}_{self.activity_definition_id}_{self.activity_instance_id}\"\n@classproperty\ndef valid_scene_types(cls):\n# Must be an interactive traversable scene\nreturn {InteractiveTraversableScene}\n@classproperty\ndef default_termination_config(cls):\nreturn {\n\"max_steps\": 500,\n}\n@classproperty\ndef default_reward_config(cls):\nreturn {\n\"r_potential\": 1.0,\n}\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this task. Defaults to class name</p>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.assign_object_scope_with_cache","title":"<code>assign_object_scope_with_cache(env)</code>","text":"<p>Assigns objects within the current object scope</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def assign_object_scope_with_cache(self, env):\n\"\"\"\n    Assigns objects within the current object scope\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\n# Assign object_scope based on a cached scene\nfor obj_inst in self.object_scope:\nmatched_sim_obj = None\n# If the object scope points to the agent\nif obj_inst == \"agent.n.01_1\":\nmatched_sim_obj = self.get_agent(env)\n# If the object scope points to a system\nelif self.object_instance_to_category[obj_inst] in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\nmatched_sim_obj = get_system(SYSTEM_SYNSETS_TO_SYSTEM_NAMES[self.object_instance_to_category[obj_inst]])\nelse:\nlog.info(f\"checking objects...\")\nfor sim_obj in og.sim.scene.objects:\nlog.info(f\"checking bddl obj scope for obj: {sim_obj.name}\")\nif hasattr(sim_obj, \"bddl_object_scope\") and sim_obj.bddl_object_scope == obj_inst:\nmatched_sim_obj = sim_obj\nbreak\nassert matched_sim_obj is not None, obj_inst\nself.object_scope[obj_inst] = matched_sim_obj\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.build_non_sampleable_object_scope","title":"<code>build_non_sampleable_object_scope(env)</code>","text":"<p>Store simulator object options for non-sampleable objects in self.non_sampleable_object_scope {     \"living_room\": {         \"table1\": {             \"living_room_0\": [URDFObject, URDFObject, URDFObject],             \"living_room_1\": [URDFObject]         },         \"table2\": {             \"living_room_0\": [URDFObject, URDFObject],             \"living_room_1\": [URDFObject, URDFObject]         },         \"chair1\": {             \"living_room_0\": [URDFObject],             \"living_room_1\": [URDFObject]         },     } }</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def build_non_sampleable_object_scope(self, env):\n\"\"\"\n    Store simulator object options for non-sampleable objects in self.non_sampleable_object_scope\n    {\n        \"living_room\": {\n            \"table1\": {\n                \"living_room_0\": [URDFObject, URDFObject, URDFObject],\n                \"living_room_1\": [URDFObject]\n            },\n            \"table2\": {\n                \"living_room_0\": [URDFObject, URDFObject],\n                \"living_room_1\": [URDFObject, URDFObject]\n            },\n            \"chair1\": {\n                \"living_room_0\": [URDFObject],\n                \"living_room_1\": [URDFObject]\n            },\n        }\n    }\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\nroom_type_to_scene_objs = {}\nfor room_type in self.room_type_to_object_instance:\nroom_type_to_scene_objs[room_type] = {}\nfor obj_inst in self.room_type_to_object_instance[room_type]:\nroom_type_to_scene_objs[room_type][obj_inst] = {}\nobj_cat = self.object_instance_to_category[obj_inst]\n# We allow burners to be used as if they are stoves\ncategories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\nif obj_cat == \"stove.n.01\":\ncategories += self.object_taxonomy.get_subtree_igibson_categories(\"burner.n.02\")\nfor room_inst in og.sim.scene.seg_map.room_sem_name_to_ins_name[room_type]:\n# A list of scene objects that satisfy the requested categories\nroom_objs = og.sim.scene.object_registry(\"in_rooms\", room_inst, default_val=[])\nscene_objs = [obj for obj in room_objs if obj.category in categories]\nif len(scene_objs) != 0:\nroom_type_to_scene_objs[room_type][obj_inst][room_inst] = scene_objs\nerror_msg = self.consolidate_room_instance(room_type_to_scene_objs, \"initial_pre-sampling\")\nif error_msg:\nreturn error_msg\nself.non_sampleable_object_scope = room_type_to_scene_objs\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.build_sampling_order","title":"<code>build_sampling_order(env)</code>","text":"<p>Sampling orders is a list of lists: [[batch_1_inst_1, ... batch_1_inst_N], [batch_2_inst_1, batch_2_inst_M], ...] Sampling should happen for batch 1 first, then batch 2, so on and so forth Example: OnTop(plate, table) should belong to batch 1, and OnTop(apple, plate) should belong to batch 2</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def build_sampling_order(self, env):\n\"\"\"\n    Sampling orders is a list of lists: [[batch_1_inst_1, ... batch_1_inst_N], [batch_2_inst_1, batch_2_inst_M], ...]\n    Sampling should happen for batch 1 first, then batch 2, so on and so forth\n    Example: OnTop(plate, table) should belong to batch 1, and OnTop(apple, plate) should belong to batch 2\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\nself.object_sampling_orders = []\ncur_batch = self.non_sampleable_object_instances\nwhile len(cur_batch) &gt; 0:\nself.object_sampling_orders.append(cur_batch)\nnext_batch = set()\nfor cond in self.activity_conditions.parsed_initial_conditions:\nif len(cond) == 3 and cond[2] in cur_batch:\nnext_batch.add(cond[1])\ncur_batch = next_batch\nif len(self.object_sampling_orders) &gt; 0:\nremaining_objs = self.object_scope.keys() - set.union(*self.object_sampling_orders)\nelse:\nremaining_objs = self.object_scope.keys()\n# Macro particles and water don't need initial conditions\nremaining_objs = {obj_inst for obj_inst in remaining_objs\nif self.object_instance_to_category[obj_inst] not in MACRO_PARTICLE_SYNSETS.union(WATER_SYNSETS)}\nif len(remaining_objs) != 0:\nreturn \"Some objects do not have any kinematic condition defined for them in the initial conditions: {}\".format(\n\", \".join(remaining_objs)\n)\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.check_scene","title":"<code>check_scene(env)</code>","text":"<p>Runs sanity checks for the current scene for the given BEHAVIOR task</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required <p>Returns:</p> Type Description <p>2-tuple: - bool: Whether the generated scene activity should be accepted or not - dict: Any feedback from the sampling / initialization process</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def check_scene(self, env):\n\"\"\"\n    Runs sanity checks for the current scene for the given BEHAVIOR task\n    Args:\n        env (Environment): Current active environment instance\n    Returns:\n        2-tuple:\n            - bool: Whether the generated scene activity should be accepted or not\n            - dict: Any feedback from the sampling / initialization process\n    \"\"\"\nerror_msg = self.parse_non_sampleable_object_room_assignment(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.build_sampling_order(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.build_non_sampleable_object_scope(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.import_sampleable_objects(env)\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nself.object_scope[\"agent.n.01_1\"] = self.get_agent(env)\nreturn True, None\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.consolidate_room_instance","title":"<code>consolidate_room_instance(filtered_object_scope, condition_type)</code>","text":"<p>Consolidates room instances</p> <p>Parameters:</p> Name Type Description Default <code>filtered_object_scope</code> <code>dict</code> <p>Filtered object scope</p> required <code>condition_type</code> <code>str</code> <p>What type of condition to sample, e.g., \"initial\"</p> required Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def consolidate_room_instance(self, filtered_object_scope, condition_type):\n\"\"\"\n    Consolidates room instances\n    Args:\n        filtered_object_scope (dict): Filtered object scope\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n    \"\"\"\nfor room_type in filtered_object_scope:\n# For each room_type, filter in room_inst that has successful\n# sampling options for all obj_inst in this room_type\nroom_inst_satisfied = set.intersection(\n*[\nset(filtered_object_scope[room_type][obj_inst].keys())\nfor obj_inst in filtered_object_scope[room_type]\n]\n)\nif len(room_inst_satisfied) == 0:\nerror_msg = \"{}: Room type [{}] of scene [{}] do not contain or cannot sample all the objects needed.\\nThe following are the possible room instances for each object, the intersection of which is an empty set.\\n\".format(\ncondition_type, room_type, self.scene_model\n)\nfor obj_inst in filtered_object_scope[room_type]:\nerror_msg += (\n\"{}: \".format(obj_inst) + \", \".join(filtered_object_scope[room_type][obj_inst].keys()) + \"\\n\"\n)\nreturn error_msg\nfor obj_inst in filtered_object_scope[room_type]:\nfiltered_object_scope[room_type][obj_inst] = {\nkey: val\nfor key, val in filtered_object_scope[room_type][obj_inst].items()\nif key in room_inst_satisfied\n}\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.filter_object_scope","title":"<code>filter_object_scope(input_object_scope, conditions, condition_type)</code>","text":"<p>Filters the object scope based on given @input_object_scope, @conditions, and @condition_type</p> <p>Parameters:</p> Name Type Description Default <code>input_object_scope</code> <code>dict</code> required <code>conditions</code> <code>list</code> <p>List of conditions to filter scope with, where each list entry is a tuple of (condition, positive), where @positive is True if the condition has a positive evaluation.</p> required <code>condition_type</code> <code>str</code> <p>What type of condition to sample, e.g., \"initial\"</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Filtered object scope</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def filter_object_scope(self, input_object_scope, conditions, condition_type):\n\"\"\"\n    Filters the object scope based on given @input_object_scope, @conditions, and @condition_type\n    Args:\n        input_object_scope (dict):\n        conditions (list): List of conditions to filter scope with, where each list entry is\n            a tuple of (condition, positive), where @positive is True if the condition has a positive\n            evaluation.\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n    Returns:\n        dict: Filtered object scope\n    \"\"\"\nfiltered_object_scope = {}\nfor room_type in input_object_scope:\nfiltered_object_scope[room_type] = {}\nfor scene_obj in input_object_scope[room_type]:\nfiltered_object_scope[room_type][scene_obj] = {}\nfor room_inst in input_object_scope[room_type][scene_obj]:\n# These are a list of candidate simulator objects that need sampling test\nfor obj in input_object_scope[room_type][scene_obj][room_inst]:\n# Temporarily set object_scope to point to this candidate object\nself.object_scope[scene_obj] = obj\nsuccess = True\n# If this candidate object is not involved in any conditions,\n# success will be True by default and this object will qualify\nfor condition, positive in conditions:\n# Sample positive kinematic conditions that involve this candidate object\nif condition.STATE_NAME in KINEMATICS_STATES and positive and scene_obj in condition.body:\n# Use pybullet GUI for debugging\nif self.debug_object_sampling is not None and self.debug_object_sampling == condition.body[0]:\ngm.DEBUG = True\nsuccess = condition.sample(binary_state=positive)\nlog_msg = \" \".join(\n[\n\"{} condition sampling\".format(condition_type),\nroom_type,\nscene_obj,\nroom_inst,\nobj.name,\ncondition.STATE_NAME,\nstr(condition.body),\nstr(success),\n]\n)\nlog.warning(log_msg)\n# If any condition fails for this candidate object, skip\nif not success:\nbreak\n# If this candidate object fails, move on to the next candidate object\nif not success:\ncontinue\nif room_inst not in filtered_object_scope[room_type][scene_obj]:\nfiltered_object_scope[room_type][scene_obj][room_inst] = []\nfiltered_object_scope[room_type][scene_obj][room_inst].append(obj)\nreturn filtered_object_scope\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.get_agent","title":"<code>get_agent(env)</code>","text":"<p>Grab the 0th agent from @env</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required <p>Returns:</p> Name Type Description <code>BaseRobot</code> <p>The 0th robot from the environment instance</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def get_agent(self, env):\n\"\"\"\n    Grab the 0th agent from @env\n    Args:\n        env (Environment): Current active environment instance\n    Returns:\n        BaseRobot: The 0th robot from the environment instance\n    \"\"\"\n# We assume the relevant agent is the first agent in the scene\nreturn env.robots[0]\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.get_potential","title":"<code>get_potential(env)</code>","text":"<p>Compute task-specific potential: distance to the goal</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Computed potential</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def get_potential(self, env):\n\"\"\"\n    Compute task-specific potential: distance to the goal\n    Args:\n        env (Environment): Current active environment instance\n    Returns:\n        float: Computed potential\n    \"\"\"\n# Evaluate the first ground goal state option as the potential\n_, satisfied_predicates = evaluate_goal_conditions(self.ground_goal_state_options[0])\nsuccess_score = len(satisfied_predicates[\"satisfied\"]) / (\nlen(satisfied_predicates[\"satisfied\"]) + len(satisfied_predicates[\"unsatisfied\"])\n)\nreturn -success_score\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.group_initial_conditions","title":"<code>group_initial_conditions()</code>","text":"<p>We group initial conditions by first splitting the desired task-relevant objects into non-sampleable objects and sampleable objects.</p> <p>Non-sampleable objects are objects that should ALREADY be in the scene, and should NOT be generated / sampled on the fly</p> <p>Sampleable objects are objects that need to be additionally imported into the scene.</p> <p>Returns:</p> Type Description <p>None or str: None if successful, otherwise failure string</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def group_initial_conditions(self):\n\"\"\"\n    We group initial conditions by first splitting the desired task-relevant objects into non-sampleable objects\n    and sampleable objects.\n    Non-sampleable objects are objects that should ALREADY be in the scene, and should NOT be generated / sampled\n    on the fly\n    Sampleable objects are objects that need to be additionally imported into the scene.\n    Returns:\n        None or str: None if successful, otherwise failure string\n    \"\"\"\nself.non_sampleable_object_conditions = []\nself.sampleable_object_conditions = []\n# TODO: currently we assume self.initial_conditions is a list of\n# bddl.condition_evaluation.HEAD, each with one child.\n# This child is either a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate or\n# a Negation of a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate\nfor condition in self.activity_initial_conditions:\ncondition, positive = self.process_single_condition(condition)\nif condition is None:\ncontinue\n# Sampled conditions must always be positive\n# Non-positive (e.g.: NOT onTop) is not restrictive enough for sampling\nif condition.STATE_NAME in KINEMATICS_STATES and not positive:\nreturn \"Initial condition has negative kinematic conditions: {}\".format(condition.body)\ncondition_body = set(condition.body)\n# If the condition involves any non-sampleable object (e.g.: furniture), it's a non-sampleable condition\n# This means that there's no ordering constraint in terms of sampling, because we know the, e.g., furniture\n# object already exists in the scene and is placed, so these specific conditions can be sampled without\n# any dependencies\nif len(self.non_sampleable_object_instances.intersection(condition_body)) &gt; 0:\nself.non_sampleable_object_conditions.append((condition, positive))\nelse:\n# There are dependencies that must be taken into account\nself.sampleable_object_conditions.append((condition, positive))\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.import_sampleable_objects","title":"<code>import_sampleable_objects(env)</code>","text":"<p>Import all objects that can be sampled</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def import_sampleable_objects(self, env):\n\"\"\"\n    Import all objects that can be sampled\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\nassert og.sim.is_stopped(), \"Simulator should be stopped when importing sampleable objects\"\n# Move the robot object frame to a far away location, similar to other newly imported objects below\nenv.robots[0].set_position_orientation([300, 300, 300], [0, 0, 0, 1])\nself.sampled_objects = set()\nnum_new_obj = 0\n# Only populate self.object_scope for sampleable objects\navg_category_spec = get_og_avg_category_specs()\nfor obj_cat in self.activity_conditions.parsed_objects:\nif obj_cat == \"agent.n.01\":\ncontinue\nif obj_cat in NON_SAMPLEABLE_OBJECTS:\ncontinue\nif obj_cat in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\nassert len(self.activity_conditions.parsed_objects[obj_cat]) == 1, \"Systems are singletons\"\nobj_inst = self.activity_conditions.parsed_objects[obj_cat][0]\nself.object_scope[obj_inst] = get_system(SYSTEM_SYNSETS_TO_SYSTEM_NAMES[obj_cat])\ncontinue\nis_sliceable = self.object_taxonomy.has_ability(obj_cat, \"sliceable\")\ncategories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\n# TODO: temporary hack\nremove_categories = [\n\"pop_case\",  # too large\n\"jewel\",  # too small\n\"ring\",  # too small\n]\nfor remove_category in remove_categories:\nif remove_category in categories:\ncategories.remove(remove_category)\nfor obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\ncategory = np.random.choice(categories)\n# for sliceable objects, only get the whole objects\ntry:\nmodel_choices = get_object_models_of_category(\ncategory, filter_method=\"sliceable_whole\" if is_sliceable else None\n)\nexcept:\nog.sim.play()\nreturn f\"Missing object category: {category}\"\nif len(model_choices) == 0:\n# restore back to the play state\nog.sim.play()\nreturn f\"Missing valid object models for category: {category}\"\n# TODO: This no longer works because model ID changes in the new asset\n# Filter object models if the object category is openable\n# synset = self.object_taxonomy.get_class_name_from_igibson_category(category)\n# if self.object_taxonomy.has_ability(synset, \"openable\"):\n#     # Always use the articulated version of a certain object if its category is openable\n#     # E.g. backpack, jar, etc\n#     model_choices = [m for m in model_choices if \"articulated_\" in m]\n#     if len(model_choices) == 0:\n#         return \"{} is Openable, but does not have articulated models.\".format(category)\n# Randomly select an object model\nmodel = np.random.choice(model_choices)\n# TODO: temporary hack no longer works because model ID changes in the new asset\n# for \"collecting aluminum cans\", we need pop cans (not bottles)\n# if category == \"pop\" and self.activity_name in [\"collecting_aluminum_cans\"]:\n#     model = np.random.choice([str(i) for i in range(40, 46)])\n# if category == \"spoon\" and self.activity_name in [\"polishing_silver\"]:\n#     model = np.random.choice([str(i) for i in [2, 5, 6]])\nmodel_path = get_og_model_path(category, model)\nusd_path = os.path.join(model_path, \"usd\", f\"{model}.usd\")\nobj_name = \"{}_{}\".format(category, len(og.sim.scene.objects))\n# create the object\nsimulator_obj = DatasetObject(\nprim_path=f\"/World/{obj_name}\",\nusd_path=usd_path,\nname=obj_name,\ncategory=category,\nfit_avg_dim_volume=True,\n)\nnum_new_obj += 1\n# Load the object into the simulator\nassert og.sim.scene.loaded, \"Scene is not loaded\"\nog.sim.import_object(simulator_obj)\n# Set these objects to be far-away locations\nsimulator_obj.set_position(np.array([100.0 + num_new_obj - 1, 100.0, -100.0]))\nself.sampled_objects.add(simulator_obj)\nself.object_scope[obj_inst] = simulator_obj\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.initialize_activity","title":"<code>initialize_activity(env)</code>","text":"<p>Initializes the desired activity in the current environment @env</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required <p>Returns:</p> Type Description <p>2-tuple: - bool: Whether the generated scene activity should be accepted or not - dict: Any feedback from the sampling / initialization process</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def initialize_activity(self, env):\n\"\"\"\n    Initializes the desired activity in the current environment @env\n    Args:\n        env (Environment): Current active environment instance\n    Returns:\n        2-tuple:\n            - bool: Whether the generated scene activity should be accepted or not\n            - dict: Any feedback from the sampling / initialization process\n    \"\"\"\naccept_scene = True\nfeedback = None\nif self.online_object_sampling:\n# Reject scenes with missing non-sampleable objects\n# Populate object_scope with sampleable objects and the robot\naccept_scene, feedback = self.check_scene(env)\nif not accept_scene:\nreturn accept_scene, feedback\n# Sample objects to satisfy initial conditions\naccept_scene, feedback = self.sample(env)\nif not accept_scene:\nreturn accept_scene, feedback\nelse:\n# Load existing scene cache and assign object scope accordingly\nself.assign_object_scope_with_cache(env)\n# Generate goal condition with the fully populated self.object_scope\nself.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\nself.ground_goal_state_options = get_ground_goal_state_options(\nself.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n)\nreturn accept_scene, feedback\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.iterate_instruction","title":"<code>iterate_instruction()</code>","text":"<p>Increment the instruction</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def iterate_instruction(self):\n\"\"\"\n    Increment the instruction\n    \"\"\"\nself.currently_viewed_index = (self.currently_viewed_index + 1) % len(self.activity_conditions.parsed_goal_conditions)\nself.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.maximum_bipartite_matching","title":"<code>maximum_bipartite_matching(filtered_object_scope, condition_type)</code>","text":"<p>Matches objects from @filtered_object_scope to specific room instances it can be sampled from</p> <p>Parameters:</p> Name Type Description Default <code>filtered_object_scope</code> <code>dict</code> <p>Filtered object scope</p> required <code>condition_type</code> <code>str</code> <p>What type of condition to sample, e.g., \"initial\"</p> required <p>Returns:</p> Type Description <p>None or str: If successful, returns None. Otherwise, returns an error message</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def maximum_bipartite_matching(self, filtered_object_scope, condition_type):\n\"\"\"\n    Matches objects from @filtered_object_scope to specific room instances it can be\n    sampled from\n    Args:\n        filtered_object_scope (dict): Filtered object scope\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\n# For each room instance, perform maximum bipartite matching between object instance in scope to simulator objects\n# Left nodes: a list of object instance in scope\n# Right nodes: a list of simulator objects\n# Edges: if the simulator object can support the sampling requirement of ths object instance\nfor room_type in filtered_object_scope:\n# The same room instances will be shared across all scene obj in a given room type\nsome_obj = list(filtered_object_scope[room_type].keys())[0]\nroom_insts = list(filtered_object_scope[room_type][some_obj].keys())\nsuccess = False\n# Loop through each room instance\nfor room_inst in room_insts:\ngraph = nx.Graph()\n# For this given room instance, gether mapping from obj instance to a list of simulator obj\nobj_inst_to_obj_per_room_inst = {}\nfor obj_inst in filtered_object_scope[room_type]:\nobj_inst_to_obj_per_room_inst[obj_inst] = filtered_object_scope[room_type][obj_inst][room_inst]\ntop_nodes = []\nlog_msg = \"MBM for room instance [{}]\".format(room_inst)\nlog.warning((log_msg))\nfor obj_inst in obj_inst_to_obj_per_room_inst:\nfor obj in obj_inst_to_obj_per_room_inst[obj_inst]:\n# Create an edge between obj instance and each of the simulator obj that supports sampling\ngraph.add_edge(obj_inst, obj)\nlog_msg = \"Adding edge: {} &lt;-&gt; {}\".format(obj_inst, obj.name)\nlog.warning((log_msg))\ntop_nodes.append(obj_inst)\n# Need to provide top_nodes that contain all nodes in one bipartite node set\n# The matches will have two items for each match (e.g. A -&gt; B, B -&gt; A)\nmatches = nx.bipartite.maximum_matching(graph, top_nodes=top_nodes)\nif len(matches) == 2 * len(obj_inst_to_obj_per_room_inst):\nlog.warning((\"Object scope finalized:\"))\nfor obj_inst, obj in matches.items():\nif obj_inst in obj_inst_to_obj_per_room_inst:\nself.object_scope[obj_inst] = obj\nlog.warning((obj_inst, obj.name))\nsuccess = True\nbreak\nif not success:\nreturn \"{}: Room type [{}] of scene [{}] do not have enough simulator objects that can successfully sample all the objects needed. This is usually caused by specifying too many object instances in the object scope or the conditions are so stringent that too few simulator objects can satisfy them via sampling.\\n\".format(\ncondition_type, room_type, self.scene_model\n)\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.parse_non_sampleable_object_room_assignment","title":"<code>parse_non_sampleable_object_room_assignment(env)</code>","text":"<p>Infers which rooms each object is assigned to</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def parse_non_sampleable_object_room_assignment(self, env):\n\"\"\"\n    Infers which rooms each object is assigned to\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\nself.room_type_to_object_instance = dict()\nself.non_sampleable_object_instances = set()\nfor cond in self.activity_conditions.parsed_initial_conditions:\nif cond[0] == \"inroom\":\nobj_inst, room_type = cond[1], cond[2]\nobj_cat = self.object_instance_to_category[obj_inst]\nif obj_cat not in NON_SAMPLEABLE_OBJECTS:\n# Invalid room assignment\nreturn \"You have assigned room type for [{}], but [{}] is sampleable. Only non-sampleable objects can have room assignment.\".format(\nobj_cat, obj_cat\n)\nif room_type not in og.sim.scene.seg_map.room_sem_name_to_ins_name:\n# Missing room type\nreturn \"Room type [{}] missing in scene [{}].\".format(room_type, og.sim.scene.scene_model)\nif room_type not in self.room_type_to_object_instance:\nself.room_type_to_object_instance[room_type] = []\nself.room_type_to_object_instance[room_type].append(obj_inst)\nif obj_inst in self.non_sampleable_object_instances:\n# Duplicate room assignment\nreturn \"Object [{}] has more than one room assignment\".format(obj_inst)\nself.non_sampleable_object_instances.add(obj_inst)\nfor obj_cat in self.activity_conditions.parsed_objects:\nif obj_cat not in NON_SAMPLEABLE_OBJECTS:\ncontinue\nfor obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\nif obj_inst not in self.non_sampleable_object_instances:\n# Missing room assignment\nreturn \"All non-sampleable objects should have room assignment. [{}] does not have one.\".format(\nobj_inst\n)\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.process_single_condition","title":"<code>process_single_condition(condition)</code>","text":"<p>Processes a single BDDL condition</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>Condition</code> <p>Condition to process</p> required <p>Returns:</p> Type Description <p>2-tuple: - Expression: Condition's expression - bool: Whether this evaluated condition is positive or negative</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def process_single_condition(self, condition):\n\"\"\"\n    Processes a single BDDL condition\n    Args:\n        condition (Condition): Condition to process\n    Returns:\n        2-tuple:\n            - Expression: Condition's expression\n            - bool: Whether this evaluated condition is positive or negative\n    \"\"\"\nif not isinstance(condition.children[0], Negation) and not isinstance(condition.children[0], AtomicFormula):\nlog.warning((\"Skipping over sampling of predicate that is not a negation or an atomic formula\"))\nreturn None, None\nif isinstance(condition.children[0], Negation):\ncondition = condition.children[0].children[0]\npositive = False\nelse:\ncondition = condition.children[0]\npositive = True\nreturn condition, positive\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample","title":"<code>sample(env, validate_goal=False)</code>","text":"<p>Run sampling for this BEHAVIOR task</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Current active environment instance</p> required <code>validate_goal</code> <code>bool</code> <p>Whether the goal should be validated or not</p> <code>False</code> <p>Returns:</p> Type Description <p>2-tuple: - bool: Whether sampling was successful or not - None or str: None if successful, otherwise the associated error message</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def sample(self, env, validate_goal=False):\n\"\"\"\n    Run sampling for this BEHAVIOR task\n    Args:\n        env (Environment): Current active environment instance\n        validate_goal (bool): Whether the goal should be validated or not\n    Returns:\n        2-tuple:\n            - bool: Whether sampling was successful or not\n            - None or str: None if successful, otherwise the associated error message\n    \"\"\"\n# Auto-initialize all sampleable objects\nog.sim.play()\nenv.scene.reset()\nerror_msg = self.group_initial_conditions()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.sample_initial_conditions()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nif validate_goal:\nerror_msg = self.sample_goal_conditions()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nerror_msg = self.sample_initial_conditions_final()\nif error_msg:\nlog.warning(error_msg)\nreturn False, error_msg\nenv.scene.update_initial_state()\nog.sim.stop()\nreturn True, None\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_conditions","title":"<code>sample_conditions(input_object_scope, conditions, condition_type)</code>","text":"<p>Sample conditions</p> <p>Parameters:</p> Name Type Description Default <code>input_object_scope</code> <code>dict</code> required <code>conditions</code> <code>list</code> <p>List of conditions to filter scope with, where each list entry is a tuple of (condition, positive), where @positive is True if the condition has a positive evaluation.</p> required <code>condition_type</code> <code>str</code> <p>What type of condition to sample, e.g., \"initial\"</p> required <p>Returns:</p> Type Description <p>None or str: If successful, returns None. Otherwise, returns an error message</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def sample_conditions(self, input_object_scope, conditions, condition_type):\n\"\"\"\n    Sample conditions\n    Args:\n        input_object_scope (dict):\n        conditions (list): List of conditions to filter scope with, where each list entry is\n            a tuple of (condition, positive), where @positive is True if the condition has a positive\n            evaluation.\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\nfiltered_object_scope = self.filter_object_scope(input_object_scope, conditions, condition_type)\nerror_msg = self.consolidate_room_instance(filtered_object_scope, condition_type)\nif error_msg:\nreturn error_msg, None\nreturn self.maximum_bipartite_matching(filtered_object_scope, condition_type), filtered_object_scope\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_goal_conditions","title":"<code>sample_goal_conditions()</code>","text":"<p>Sample goal conditions</p> <p>Returns:</p> Type Description <p>None or str: If successful, returns None. Otherwise, returns an error message</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def sample_goal_conditions(self):\n\"\"\"\n    Sample goal conditions\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\nnp.random.shuffle(self.ground_goal_state_options)\nlog.warning((\"number of ground_goal_state_options\", len(self.ground_goal_state_options)))\nnum_goal_condition_set_to_test = 10\ngoal_condition_success = False\n# Try to fulfill different set of ground goal conditions (maximum num_goal_condition_set_to_test)\nfor goal_condition_set in self.ground_goal_state_options[:num_goal_condition_set_to_test]:\ngoal_condition_processed = []\nfor condition in goal_condition_set:\ncondition, positive = self.process_single_condition(condition)\nif condition is None:\ncontinue\ngoal_condition_processed.append((condition, positive))\nerror_msg, _ = self.sample_conditions(\nself.non_sampleable_object_scope_filtered_initial, goal_condition_processed, \"goal\"\n)\nif not error_msg:\n# if one set of goal conditions (and initial conditions) are satisfied, sampling is successful\ngoal_condition_success = True\nbreak\nif not goal_condition_success:\nreturn error_msg\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_initial_conditions","title":"<code>sample_initial_conditions()</code>","text":"<p>Sample initial conditions</p> <p>Returns:</p> Type Description <p>None or str: If successful, returns None. Otherwise, returns an error message</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def sample_initial_conditions(self):\n\"\"\"\n    Sample initial conditions\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\nerror_msg, self.non_sampleable_object_scope_filtered_initial = self.sample_conditions(\nself.non_sampleable_object_scope, self.non_sampleable_object_conditions, \"initial\"\n)\nreturn error_msg\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_initial_conditions_final","title":"<code>sample_initial_conditions_final()</code>","text":"<p>Sample final initial conditions</p> <p>Returns:</p> Type Description <p>None or str: If successful, returns None. Otherwise, returns an error message</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def sample_initial_conditions_final(self):\n\"\"\"\n    Sample final initial conditions\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\n# Do the final round of sampling with object scope fixed\nfor condition, positive in self.non_sampleable_object_conditions:\nnum_trials = 10\nfor _ in range(num_trials):\nsuccess = condition.sample(binary_state=positive)\nif success:\nbreak\nif not success:\nerror_msg = \"Non-sampleable object conditions failed even after successful matching: {}\".format(\ncondition.body\n)\nreturn error_msg\nif len(self.object_sampling_orders) &gt; 0:\n# Pop non-sampleable objects\nself.object_sampling_orders.pop(0)\nfor cur_batch in self.object_sampling_orders:\n# First sample non-sliced conditions\nfor condition, positive in self.sampleable_object_conditions:\nif condition.STATE_NAME == \"sliced\":\ncontinue\n# Sample conditions that involve the current batch of objects\nif condition.body[0] in cur_batch:\nnum_trials = 10\nfor _ in range(num_trials):\nsuccess = condition.sample(binary_state=positive)\nif success:\nbreak\nif not success:\nreturn \"Sampleable object conditions failed: {} {}\".format(\ncondition.STATE_NAME, condition.body\n)\n# Then sample sliced conditions\nfor condition, positive in self.sampleable_object_conditions:\nif condition.STATE_NAME != \"sliced\":\ncontinue\n# Sample conditions that involve the current batch of objects\nif condition.body[0] in cur_batch:\nsuccess = condition.sample(binary_state=positive)\nif not success:\nreturn \"Sampleable object conditions failed: {}\".format(condition.body)\n# One more sim step to make sure the object states are propagated correctly\n# E.g. after sampling Filled.set_value(True), Filled.get_value() will become True only after one step\nog.sim.step()\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.show_instruction","title":"<code>show_instruction()</code>","text":"<p>Get current instruction for user</p> <p>Returns:</p> Type Description <p>3-tuple: - str: Current goal condition in natural language - 3-tuple: (R,G,B) color to assign to text - list of BaseObject: Relevant objects for the current instruction</p> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def show_instruction(self):\n\"\"\"\n    Get current instruction for user\n    Returns:\n        3-tuple:\n            - str: Current goal condition in natural language\n            - 3-tuple: (R,G,B) color to assign to text\n            - list of BaseObject: Relevant objects for the current instruction\n    \"\"\"\nsatisfied = self.currently_viewed_instruction in self._termination_conditions[\"predicate\"].goal_status[\"satisfied\"]\nnatural_language_condition = self.activity_natural_language_goal_conditions[self.currently_viewed_instruction]\nobjects = self.activity_goal_conditions[self.currently_viewed_instruction].get_relevant_objects()\ntext_color = (\n[83.0 / 255.0, 176.0 / 255.0, 72.0 / 255.0] if satisfied else [255.0 / 255.0, 51.0 / 255.0, 51.0 / 255.0]\n)\nreturn natural_language_condition, text_color, objects\n</code></pre>"},{"location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.update_activity","title":"<code>update_activity(activity_name, activity_definition_id, predefined_problem=None)</code>","text":"<p>Update the active Behavior activity being deployed</p> <p>Parameters:</p> Name Type Description Default <code>activity_name</code> <code>None or str</code> <p>Name of the Behavior Task to instantiate</p> required <code>activity_definition_id</code> <code>int</code> <p>Specification to load for the desired task. For a given Behavior Task, multiple task specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This ID determines which specification to use</p> required <code>predefined_problem</code> <code>None or str</code> <p>If specified, specifies the raw string definition of the Behavior Task to load. This will automatically override @activity_name and @activity_definition_id.</p> <code>None</code> Source code in <code>omnigibson/tasks/behavior_task.py</code> <pre><code>def update_activity(self, activity_name, activity_definition_id, predefined_problem=None):\n\"\"\"\n    Update the active Behavior activity being deployed\n    Args:\n        activity_name (None or str): Name of the Behavior Task to instantiate\n        activity_definition_id (int): Specification to load for the desired task. For a given Behavior Task, multiple task\n            specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This\n            ID determines which specification to use\n        predefined_problem (None or str): If specified, specifies the raw string definition of the Behavior Task to\n            load. This will automatically override @activity_name and @activity_definition_id.\n    \"\"\"\n# Update internal variables based on values\n# Activity info\nself.activity_name = activity_name\nself.activity_definition_id = activity_definition_id\nself.activity_conditions = Conditions(\nactivity_name,\nactivity_definition_id,\nsimulator_name=\"igibson\",       # TODO: Update!\npredefined_problem=predefined_problem,\n)\n# Object info\nself.object_scope = get_object_scope(self.activity_conditions)\nself.object_instance_to_category = {\nobj_inst: obj_cat\nfor obj_cat in self.activity_conditions.parsed_objects\nfor obj_inst in self.activity_conditions.parsed_objects[obj_cat]\n}\n# Generate initial and goal conditions\nself.activity_initial_conditions = get_initial_conditions(self.activity_conditions, self.backend, self.object_scope)\nself.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\nself.ground_goal_state_options = get_ground_goal_state_options(\nself.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n)\n# Demo attributes\nself.instruction_order = np.arange(len(self.activity_conditions.parsed_goal_conditions))\nnp.random.shuffle(self.instruction_order)\nself.currently_viewed_index = 0\nself.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\nself.activity_natural_language_goal_conditions = get_natural_goal_conditions(self.activity_conditions)\n</code></pre>"},{"location":"reference/tasks/dummy_task.html","title":"dummy_task","text":""},{"location":"reference/tasks/dummy_task.html#tasks.dummy_task.DummyTask","title":"<code>DummyTask</code>","text":"<p>         Bases: <code>BaseTask</code></p> <p>Dummy task</p> Source code in <code>omnigibson/tasks/dummy_task.py</code> <pre><code>class DummyTask(BaseTask):\n\"\"\"\n    Dummy task\n    \"\"\"\ndef _load(self, env):\n# Do nothing here\npass\ndef _create_termination_conditions(self):\n# Do nothing\nreturn dict()\ndef _create_reward_functions(self):\n# Do nothing\nreturn dict()\ndef _get_obs(self, env):\n# No task-specific obs of any kind\nreturn dict(), dict()\ndef _load_non_low_dim_observation_space(self):\n# No non-low dim observations so we return an empty dict\nreturn dict()\n@classproperty\ndef valid_scene_types(cls):\n# Any scene works\nreturn {Scene}\n@classproperty\ndef default_termination_config(cls):\n# Empty dict\nreturn {}\n@classproperty\ndef default_reward_config(cls):\n# Empty dict\nreturn {}\n</code></pre>"},{"location":"reference/tasks/point_navigation_task.html","title":"point_navigation_task","text":""},{"location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask","title":"<code>PointNavigationTask</code>","text":"<p>         Bases: <code>BaseTask</code></p> <p>Point Navigation Task The task is to navigate to a goal position</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>Which robot that this task corresponds to</p> <code>0</code> <code>floor</code> <code>int</code> <p>Which floor to navigate on</p> <code>0</code> <code>initial_pos</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) global initial position to place the robot at the start of each task episode. If None, a collision-free value will be randomly sampled</p> <code>None</code> <code>initial_quat</code> <code>None or 4-array</code> <p>If specified, should be (x,y,z,w) global quaternion orientation to place the robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis</p> <code>None</code> <code>goal_pos</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) global goal position to reach for the given task episode. If None, a collision-free value will be randomly sampled</p> <code>None</code> <code>goal_tolerance</code> <code>float</code> <p>Distance between goal position and current position below which is considered a task success</p> <code>0.5</code> <code>goal_in_polar</code> <code>bool</code> <p>Whether to represent the goal in polar coordinates or not when capturing task observations</p> <code>False</code> <code>path_range</code> <code>None or 2-array</code> <p>If specified, should be (min, max) values representing the range of valid total path lengths that are valid when sampling initial / goal positions</p> <code>None</code> <code>visualize_goal</code> <code>bool</code> <p>Whether to visualize the initial / goal locations</p> <code>False</code> <code>visualize_path</code> <code>bool</code> <p>Whether to visualize the path from initial to goal location, as represented by discrete waypoints</p> <code>False</code> <code>goal_height</code> <code>float</code> <p>If visualizing, specifies the height of the visual goals (m)</p> <code>0.06</code> <code>waypoint_height</code> <code>float</code> <p>If visualizing, specifies the height of the visual waypoints (m)</p> <code>0.05</code> <code>waypoint_width</code> <code>float</code> <p>If visualizing, specifies the width of the visual waypoints (m)</p> <code>0.1</code> <code>n_vis_waypoints</code> <code>int</code> <p>If visualizing, specifies the number of waypoints to generate</p> <code>10</code> <code>reward_type</code> <code>str</code> <p>Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}</p> <code>'l2'</code> <code>termination_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p> <code>None</code> <code>reward_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p> <code>None</code> Source code in <code>omnigibson/tasks/point_navigation_task.py</code> <pre><code>class PointNavigationTask(BaseTask):\n\"\"\"\n    Point Navigation Task\n    The task is to navigate to a goal position\n    Args:\n        robot_idn (int): Which robot that this task corresponds to\n        floor (int): Which floor to navigate on\n        initial_pos (None or 3-array): If specified, should be (x,y,z) global initial position to place the robot\n            at the start of each task episode. If None, a collision-free value will be randomly sampled\n        initial_quat (None or 4-array): If specified, should be (x,y,z,w) global quaternion orientation to place the\n            robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis\n        goal_pos (None or 3-array): If specified, should be (x,y,z) global goal position to reach for the given task\n            episode. If None, a collision-free value will be randomly sampled\n        goal_tolerance (float): Distance between goal position and current position below which is considered a task\n            success\n        goal_in_polar (bool): Whether to represent the goal in polar coordinates or not when capturing task observations\n        path_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total path lengths that are valid when sampling initial / goal positions\n        visualize_goal (bool): Whether to visualize the initial / goal locations\n        visualize_path (bool): Whether to visualize the path from initial to goal location, as represented by\n            discrete waypoints\n        goal_height (float): If visualizing, specifies the height of the visual goals (m)\n        waypoint_height (float): If visualizing, specifies the height of the visual waypoints (m)\n        waypoint_width (float): If visualizing, specifies the width of the visual waypoints (m)\n        n_vis_waypoints (int): If visualizing, specifies the number of waypoints to generate\n        reward_type (str): Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\ndef __init__(\nself,\nrobot_idn=0,\nfloor=0,\ninitial_pos=None,\ninitial_quat=None,\ngoal_pos=None,\ngoal_tolerance=0.5,\ngoal_in_polar=False,\npath_range=None,\nvisualize_goal=False,\nvisualize_path=False,\ngoal_height=0.06,\nwaypoint_height=0.05,\nwaypoint_width=0.1,\nn_vis_waypoints=10,\nreward_type=\"l2\",\ntermination_config=None,\nreward_config=None,\n):\n# Store inputs\nself._robot_idn = robot_idn\nself._floor = floor\nself._initial_pos = initial_pos if initial_pos is None else np.array(initial_pos)\nself._initial_quat = initial_quat if initial_quat is None else np.array(initial_quat)\nself._goal_pos = goal_pos if goal_pos is None else np.array(goal_pos)\nself._goal_tolerance = goal_tolerance\nself._goal_in_polar = goal_in_polar\nself._path_range = path_range\nself._randomize_initial_pos = initial_pos is None\nself._randomize_initial_quat = initial_quat is None\nself._randomize_goal_pos = goal_pos is None\nself._visualize_goal = visualize_goal\nself._visualize_path = visualize_path\nself._goal_height = goal_height\nself._waypoint_height = waypoint_height\nself._waypoint_width = waypoint_width\nself._n_vis_waypoints = n_vis_waypoints\nassert_valid_key(key=reward_type, valid_keys=POINT_NAVIGATION_REWARD_TYPES, name=\"reward type\")\nself._reward_type = reward_type\n# Create other attributes that will be filled in at runtime\nself._initial_pos_marker = None\nself._goal_pos_marker = None\nself._waypoint_markers = None\nself._path_length = None\nself._current_robot_pos = None\nself._geodesic_dist = None\n# Run super\nsuper().__init__(termination_config=termination_config, reward_config=reward_config)\ndef _create_termination_conditions(self):\n# Initialize termination conditions dict and fill in with MaxCollision, Timeout, Falling, and PointGoal\nterminations = dict()\nterminations[\"max_collision\"] = MaxCollision(max_collisions=self._termination_config[\"max_collisions\"])\nterminations[\"timeout\"] = Timeout(max_steps=self._termination_config[\"max_steps\"])\nterminations[\"falling\"] = Falling(robot_idn=self._robot_idn, fall_height=self._termination_config[\"fall_height\"])\nterminations[\"pointgoal\"] = PointGoal(\nrobot_idn=self._robot_idn,\ndistance_tol=self._goal_tolerance,\ndistance_axes=\"xy\",\n)\nreturn terminations\ndef _create_reward_functions(self):\n# Initialize reward functions dict and fill in with Potential, Collision, and PointGoal rewards\nrewards = dict()\nrewards[\"potential\"] = PotentialReward(\npotential_fcn=self.get_potential,\nr_potential=self._reward_config[\"r_potential\"],\n)\nrewards[\"collision\"] = CollisionReward(r_collision=self._reward_config[\"r_collision\"])\nrewards[\"pointgoal\"] = PointGoalReward(\npointgoal=self._termination_conditions[\"pointgoal\"],\nr_pointgoal=self._reward_config[\"r_pointgoal\"],\n)\nreturn rewards\ndef _load(self, env):\n# Load visualization\nself._load_visualization_markers(env=env)\n# Auto-initialize all markers\nog.sim.play()\nenv.scene.reset()\nenv.scene.update_initial_state()\nog.sim.stop()\ndef _load_visualization_markers(self, env):\n\"\"\"\n        Load visualization, such as initial and target position, shortest path, etc\n        Args:\n            env (Environment): Active environment instance\n        \"\"\"\nif self._visualize_goal:\nself._initial_pos_marker = PrimitiveObject(\nprim_path=\"/World/task_initial_pos_marker\",\nprimitive_type=\"Cylinder\",\nname=\"task_initial_pos_marker\",\nradius=self._goal_tolerance,\nheight=self._goal_height,\nvisual_only=True,\nrgba=np.array([1, 0, 0, 0.3]),\n)\nself._goal_pos_marker = PrimitiveObject(\nprim_path=\"/World/task_goal_pos_marker\",\nprimitive_type=\"Cylinder\",\nname=\"task_goal_pos_marker\",\nradius=self._goal_tolerance,\nheight=self._goal_height,\nvisual_only=True,\nrgba=np.array([0, 0, 1, 0.3]),\n)\n# Load the objects into the simulator\nog.sim.import_object(self._initial_pos_marker)\nog.sim.import_object(self._goal_pos_marker)\n# Additionally generate waypoints along the path if we're building the map in the environment\nif env.scene.trav_map.build_graph and self._visualize_path:\nwaypoints = []\nfor i in range(self._n_vis_waypoints):\nwaypoint = PrimitiveObject(\nprim_path=f\"/World/task_waypoint_marker{i}\",\nprimitive_type=\"Cylinder\",\nname=f\"task_waypoint_marker{i}\",\nradius=self._waypoint_width,\nheight=self._waypoint_height,\nvisual_only=True,\nrgba=np.array([0, 1, 0, 0.3]),\n)\nog.sim.import_object(waypoint)\nwaypoints.append(waypoint)\n# Store waypoints\nself._waypoint_markers = waypoints\ndef _sample_initial_pose_and_goal_pos(self, env, max_trials=100):\n\"\"\"\n        Potentially sample the robot initial pos / ori and target pos, based on whether we're using randomized\n        initial and goal states. If not randomzied, then this value will return the corresponding values inputted\n        during this task initialization.\n        Args:\n            env (Environment): Environment instance\n            max_trials (int): Number of trials to attempt to sample valid poses and positions\n        Returns:\n            3-tuple:\n                - 3-array: (x,y,z) global sampled initial position\n                - 4-array: (x,y,z,w) global sampled initial orientation in quaternion form\n                - 3-array: (x,y,z) global sampled goal position\n        \"\"\"\n# Possibly sample initial pos\nif self._randomize_initial_pos:\n_, initial_pos = env.scene.get_random_point(floor=self._floor)\nelse:\ninitial_pos = self._initial_pos\n# Possibly sample initial ori\ninitial_quat = T.euler2quat(np.array([0, 0, np.random.uniform(0, np.pi * 2)])) if \\\n            self._randomize_initial_quat else self._initial_quat\n# Possibly sample goal pos\nif self._randomize_goal_pos:\ndist, in_range_dist = 0.0, False\nfor _ in range(max_trials):\n_, goal_pos = env.scene.get_random_point(floor=self._floor)\nif env.scene.trav_map.build_graph:\n_, dist = env.scene.get_shortest_path(self._floor, initial_pos[:2], goal_pos[:2], entire_path=False)\nelse:\ndist = T.l2_distance(initial_pos, goal_pos)\n# If a path range is specified, make sure distance is valid\nif self._path_range is None or self._path_range[0] &lt; dist &lt; self._path_range[1]:\nin_range_dist = True\nbreak\n# Notify if we weren't able to get a valid start / end point sampled in the requested range\nif not in_range_dist:\nlog.warning(\"Failed to sample initial and target positions within requested path range\")\nelse:\ngoal_pos = self._goal_pos\n# Add additional logging info\nlog.info(\"Sampled initial pose: {}, {}\".format(initial_pos, initial_quat))\nlog.info(\"Sampled goal position: {}\".format(goal_pos))\nreturn initial_pos, initial_quat, goal_pos\ndef _get_geodesic_potential(self, env):\n\"\"\"\n        Get potential based on geodesic distance\n        Args:\n            env: environment instance\n        Returns:\n            float: geodesic distance to the target position\n        \"\"\"\n_, geodesic_dist = self.get_shortest_path_to_goal(env=env)\nreturn geodesic_dist\ndef _get_l2_potential(self, env):\n\"\"\"\n        Get potential based on L2 distance\n        Args:\n            env: environment instance\n        Returns:\n            float: L2 distance to the target position\n        \"\"\"\nreturn T.l2_distance(env.robots[self._robot_idn].get_position()[:2], self._goal_pos[:2])\ndef get_potential(self, env):\n\"\"\"\n        Compute task-specific potential: distance to the goal\n        Args:\n            env (Environment): Environment instance\n        Returns:\n            float: Computed potential\n        \"\"\"\nif self._reward_type == \"l2\":\nreward = self._get_l2_potential(env)\nelif self._reward_type == \"geodesic\":\nreward = self._get_geodesic_potential(env)\nelse:\nraise ValueError(f\"Invalid reward type! {self._reward_type}\")\nreturn reward\ndef _reset_agent(self, env):\n# Reset agent\nenv.robots[self._robot_idn].reset()\n# We attempt to sample valid initial poses and goal positions\nsuccess, max_trials = False, 100\ninitial_pos, initial_quat, goal_pos = None, None, None\nfor i in range(max_trials):\ninitial_pos, initial_quat, goal_pos = self._sample_initial_pose_and_goal_pos(env)\n# Make sure the sampled robot start pose and goal position are both collision-free\nsuccess = test_valid_pose(\nenv.robots[self._robot_idn], initial_pos, initial_quat, env.initial_pos_z_offset\n) and test_valid_pose(env.robots[self._robot_idn], goal_pos, None, env.initial_pos_z_offset)\n# Don't need to continue iterating if we succeeded\nif success:\nbreak\n# Notify user if we failed to reset a collision-free sampled pose\nif not success:\nlog.warning(\"WARNING: Failed to reset robot without collision\")\n# Land the robot\nland_object(env.robots[self._robot_idn], initial_pos, initial_quat, env.initial_pos_z_offset)\n# Store the sampled values internally\nself._initial_pos = initial_pos\nself._initial_quat = initial_quat\nself._goal_pos = goal_pos\n# Update visuals if requested\nif self._visualize_goal:\nself._initial_pos_marker.set_position(self._initial_pos)\nself._goal_pos_marker.set_position(self._goal_pos)\ndef _reset_variables(self, env):\n# Run super first\nsuper()._reset_variables(env=env)\n# Reset internal variables\nself._path_length = 0.0\nself._current_robot_pos = self._initial_pos\nself._geodesic_dist = self._get_geodesic_potential(env)\ndef _step_termination(self, env, action, info=None):\n# Run super first\ndone, info = super()._step_termination(env=env, action=action, info=info)\n# Add additional info\ninfo[\"path_length\"] = self._path_length\ninfo[\"spl\"] = float(info[\"success\"]) * min(1.0, self._geodesic_dist / self._path_length) if done and self._path_length != 0.0 else 0.0\nreturn done, info\ndef _global_pos_to_robot_frame(self, env, pos):\n\"\"\"\n        Convert a 3D point in global frame to agent's local frame\n        Args:\n            env (TraversableEnv): Environment instance\n            pos (3-array): global (x,y,z) position\n        Returns:\n            3-array: (x,y,z) position in self._robot_idn agent's local frame\n        \"\"\"\ndelta_pos_global = np.array(pos) - env.robots[self._robot_idn].get_position()\nreturn T.quat2mat(env.robots[self._robot_idn].get_orientation()).T @ delta_pos_global\ndef _get_obs(self, env):\n# Get relative position of goal with respect to the current agent position\nxy_pos_to_goal = self._global_pos_to_robot_frame(env, self._goal_pos)[:2]\nif self._goal_in_polar:\nxy_pos_to_goal = np.array(T.cartesian_to_polar(*xy_pos_to_goal))\n# linear velocity and angular velocity\nquat = env.robots[self._robot_idn].get_orientation()\nlin_vel = T.quat2mat(quat).T @ env.robots[self._robot_idn].get_linear_velocity()\nang_vel = T.quat2mat(quat).T @ env.robots[self._robot_idn].get_angular_velocity()\n# Compose observation dict\nlow_dim_obs = dict(\nxy_pos_to_goal=xy_pos_to_goal,\nrobot_lin_vel=lin_vel,\nrobot_ang_vel=ang_vel,\n)\n# We have no non-low-dim obs, so return empty dict for those\nreturn low_dim_obs, dict()\ndef _load_non_low_dim_observation_space(self):\n# No non-low dim observations so we return an empty dict\nreturn dict()\ndef get_goal_pos(self):\n\"\"\"\n        Returns:\n            3-array: (x,y,z) global current goal position\n        \"\"\"\nreturn self._goal_pos\ndef get_current_pos(self, env):\n\"\"\"\n        Returns:\n            3-array: (x,y,z) global current position representing the robot\n        \"\"\"\nreturn env.robots[self._robot_idn].get_position()\ndef get_shortest_path_to_goal(self, env, start_xy_pos=None, entire_path=False):\n\"\"\"\n        Get the shortest path and geodesic distance from @start_pos to the target position\n        Args:\n            env (TraversableEnv): Environment instance\n            start_xy_pos (None or 2-array): If specified, should be the global (x,y) start position from which\n                to calculate the shortest path to the goal position. If None (default), the robot's current xy position\n                will be used\n            entire_path (bool): Whether to return the entire shortest path\n        Returns:\n            2-tuple:\n                - list of 2-array: List of (x,y) waypoints representing the path # TODO: is this true?\n                - float: geodesic distance of the path to the goal position\n        \"\"\"\nstart_xy_pos = env.robots[self._robot_idn].get_position()[:2] if start_xy_pos is None else start_xy_pos\nreturn env.scene.get_shortest_path(self._floor, start_xy_pos, self._goal_pos[:2], entire_path=entire_path)\ndef _step_visualization(self, env):\n\"\"\"\n        Step visualization\n        Args:\n            env (Environment): Environment instance\n        \"\"\"\nif env.scene.trav_map.build_graph and self._visualize_path:\nshortest_path, _ = self.get_shortest_path_to_goal(env=env, entire_path=True)\nfloor_height = env.scene.get_floor_height(self._floor)\nnum_nodes = min(self._n_vis_waypoints, shortest_path.shape[0])\nfor i in range(num_nodes):\nself._waypoint_markers[i].set_position(\nposition=np.array([shortest_path[i][0], shortest_path[i][1], floor_height])\n)\nfor i in range(num_nodes, self._n_vis_waypoints):\nself._waypoint_markers[i].set_position(position=np.array([0.0, 0.0, 100.0]))\ndef step(self, env, action):\n# Run super method first\nreward, done, info = super().step(env=env, action=action)\n# Step visualization\nself._step_visualization(env=env)\n# Update other internal variables\nnew_robot_pos = env.robots[self._robot_idn].get_position()\nself._path_length += T.l2_distance(self._current_robot_pos[:2], new_robot_pos[:2])\nself._current_robot_pos = new_robot_pos\nreturn reward, done, info\n@classproperty\ndef valid_scene_types(cls):\n# Must be a traversable scene\nreturn {TraversableScene}\n@classproperty\ndef default_termination_config(cls):\nreturn {\n\"max_collisions\": 500,\n\"max_steps\": 500,\n\"fall_height\": 0.03,\n}\n@classproperty\ndef default_reward_config(cls):\nreturn {\n\"r_potential\": 1.0,\n\"r_collision\": 0.1,\n\"r_pointgoal\": 10.0,\n}\n</code></pre>"},{"location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_current_pos","title":"<code>get_current_pos(env)</code>","text":"<p>Returns:</p> Type Description <p>3-array: (x,y,z) global current position representing the robot</p> Source code in <code>omnigibson/tasks/point_navigation_task.py</code> <pre><code>def get_current_pos(self, env):\n\"\"\"\n    Returns:\n        3-array: (x,y,z) global current position representing the robot\n    \"\"\"\nreturn env.robots[self._robot_idn].get_position()\n</code></pre>"},{"location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_goal_pos","title":"<code>get_goal_pos()</code>","text":"<p>Returns:</p> Type Description <p>3-array: (x,y,z) global current goal position</p> Source code in <code>omnigibson/tasks/point_navigation_task.py</code> <pre><code>def get_goal_pos(self):\n\"\"\"\n    Returns:\n        3-array: (x,y,z) global current goal position\n    \"\"\"\nreturn self._goal_pos\n</code></pre>"},{"location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_potential","title":"<code>get_potential(env)</code>","text":"<p>Compute task-specific potential: distance to the goal</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Environment instance</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Computed potential</p> Source code in <code>omnigibson/tasks/point_navigation_task.py</code> <pre><code>def get_potential(self, env):\n\"\"\"\n    Compute task-specific potential: distance to the goal\n    Args:\n        env (Environment): Environment instance\n    Returns:\n        float: Computed potential\n    \"\"\"\nif self._reward_type == \"l2\":\nreward = self._get_l2_potential(env)\nelif self._reward_type == \"geodesic\":\nreward = self._get_geodesic_potential(env)\nelse:\nraise ValueError(f\"Invalid reward type! {self._reward_type}\")\nreturn reward\n</code></pre>"},{"location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_shortest_path_to_goal","title":"<code>get_shortest_path_to_goal(env, start_xy_pos=None, entire_path=False)</code>","text":"<p>Get the shortest path and geodesic distance from @start_pos to the target position</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>TraversableEnv</code> <p>Environment instance</p> required <code>start_xy_pos</code> <code>None or 2-array</code> <p>If specified, should be the global (x,y) start position from which to calculate the shortest path to the goal position. If None (default), the robot's current xy position will be used</p> <code>None</code> <code>entire_path</code> <code>bool</code> <p>Whether to return the entire shortest path</p> <code>False</code> <p>Returns:</p> Type Description <p>2-tuple: - list of 2-array: List of (x,y) waypoints representing the path # TODO: is this true? - float: geodesic distance of the path to the goal position</p> Source code in <code>omnigibson/tasks/point_navigation_task.py</code> <pre><code>def get_shortest_path_to_goal(self, env, start_xy_pos=None, entire_path=False):\n\"\"\"\n    Get the shortest path and geodesic distance from @start_pos to the target position\n    Args:\n        env (TraversableEnv): Environment instance\n        start_xy_pos (None or 2-array): If specified, should be the global (x,y) start position from which\n            to calculate the shortest path to the goal position. If None (default), the robot's current xy position\n            will be used\n        entire_path (bool): Whether to return the entire shortest path\n    Returns:\n        2-tuple:\n            - list of 2-array: List of (x,y) waypoints representing the path # TODO: is this true?\n            - float: geodesic distance of the path to the goal position\n    \"\"\"\nstart_xy_pos = env.robots[self._robot_idn].get_position()[:2] if start_xy_pos is None else start_xy_pos\nreturn env.scene.get_shortest_path(self._floor, start_xy_pos, self._goal_pos[:2], entire_path=entire_path)\n</code></pre>"},{"location":"reference/tasks/point_reaching_task.html","title":"point_reaching_task","text":""},{"location":"reference/tasks/point_reaching_task.html#tasks.point_reaching_task.PointReachingTask","title":"<code>PointReachingTask</code>","text":"<p>         Bases: <code>PointNavigationTask</code></p> <p>Point Reaching Task The goal is to reach a random goal position with the robot's end effector</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>Which robot that this task corresponds to</p> <code>0</code> <code>floor</code> <code>int</code> <p>Which floor to navigate on</p> <code>0</code> <code>initial_pos</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) global initial position to place the robot at the start of each task episode. If None, a collision-free value will be randomly sampled</p> <code>None</code> <code>initial_quat</code> <code>None or 3-array</code> <p>If specified, should be (r,p,y) global euler orientation to place the robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis</p> <code>None</code> <code>goal_pos</code> <code>None or 3-array</code> <p>If specified, should be (x,y,z) global goal position to reach for the given task episode. If None, a collision-free value will be randomly sampled</p> <code>None</code> <code>goal_tolerance</code> <code>float</code> <p>Distance between goal position and current position below which is considered a task success</p> <code>0.1</code> <code>goal_in_polar</code> <code>bool</code> <p>Whether to represent the goal in polar coordinates or not when capturing task observations</p> <code>False</code> <code>path_range</code> <code>None or 2-array</code> <p>If specified, should be (min, max) values representing the range of valid total path lengths that are valid when sampling initial / goal positions</p> <code>None</code> <code>height_range</code> <code>None or 2-array</code> <p>If specified, should be (min, max) values representing the range of valid total heights that are valid when sampling goal positions</p> <code>None</code> <code>visualize_goal</code> <code>bool</code> <p>Whether to visualize the initial / goal locations</p> <code>False</code> <code>visualize_path</code> <code>bool</code> <p>Whether to visualize the path from initial to goal location, as represented by discrete waypoints</p> <code>False</code> <code>goal_height</code> <code>float</code> <p>If visualizing, specifies the height of the visual goals (m)</p> <code>0.06</code> <code>waypoint_height</code> <code>float</code> <p>If visualizing, specifies the height of the visual waypoints (m)</p> <code>0.05</code> <code>waypoint_width</code> <code>float</code> <p>If visualizing, specifies the width of the visual waypoints (m)</p> <code>0.1</code> <code>n_vis_waypoints</code> <code>int</code> <p>If visualizing, specifies the number of waypoints to generate</p> <code>10</code> <code>termination_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p> <code>None</code> <code>reward_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p> <code>None</code> Source code in <code>omnigibson/tasks/point_reaching_task.py</code> <pre><code>class PointReachingTask(PointNavigationTask):\n\"\"\"\n    Point Reaching Task\n    The goal is to reach a random goal position with the robot's end effector\n    Args:\n        robot_idn (int): Which robot that this task corresponds to\n        floor (int): Which floor to navigate on\n        initial_pos (None or 3-array): If specified, should be (x,y,z) global initial position to place the robot\n            at the start of each task episode. If None, a collision-free value will be randomly sampled\n        initial_quat (None or 3-array): If specified, should be (r,p,y) global euler orientation to place the robot\n            at the start of each task episode. If None, a value will be randomly sampled about the z-axis\n        goal_pos (None or 3-array): If specified, should be (x,y,z) global goal position to reach for the given task\n            episode. If None, a collision-free value will be randomly sampled\n        goal_tolerance (float): Distance between goal position and current position below which is considered a task\n            success\n        goal_in_polar (bool): Whether to represent the goal in polar coordinates or not when capturing task observations\n        path_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total path lengths that are valid when sampling initial / goal positions\n        height_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total heights that are valid when sampling goal positions\n        visualize_goal (bool): Whether to visualize the initial / goal locations\n        visualize_path (bool): Whether to visualize the path from initial to goal location, as represented by\n            discrete waypoints\n        goal_height (float): If visualizing, specifies the height of the visual goals (m)\n        waypoint_height (float): If visualizing, specifies the height of the visual waypoints (m)\n        waypoint_width (float): If visualizing, specifies the width of the visual waypoints (m)\n        n_vis_waypoints (int): If visualizing, specifies the number of waypoints to generate\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\ndef __init__(\nself,\nrobot_idn=0,\nfloor=0,\ninitial_pos=None,\ninitial_quat=None,\ngoal_pos=None,\ngoal_tolerance=0.1,\ngoal_in_polar=False,\npath_range=None,\nheight_range=None,\nvisualize_goal=False,\nvisualize_path=False,\ngoal_height=0.06,\nwaypoint_height=0.05,\nwaypoint_width=0.1,\nn_vis_waypoints=10,\nreward_config=None,\ntermination_config=None,\n):\n# Store inputs\nself._height_range = height_range\n# Run super\nsuper().__init__(\nrobot_idn=robot_idn,\nfloor=floor,\ninitial_pos=initial_pos,\ninitial_quat=initial_quat,\ngoal_pos=goal_pos,\ngoal_tolerance=goal_tolerance,\ngoal_in_polar=goal_in_polar,\npath_range=path_range,\nvisualize_goal=visualize_goal,\nvisualize_path=visualize_path,\ngoal_height=goal_height,\nwaypoint_height=waypoint_height,\nwaypoint_width=waypoint_width,\nn_vis_waypoints=n_vis_waypoints,\nreward_type=\"l2\",           # Must use l2 for reaching task\nreward_config=reward_config,\ntermination_config=termination_config,\n)\ndef _create_termination_conditions(self):\n# Run super first\nterminations = super()._create_termination_conditions()\n# We replace the pointgoal condition with a new one, specifying xyz instead of only xy as the axes to measure\n# distance to the goal\nterminations[\"pointgoal\"] = PointGoal(\nrobot_idn=self._robot_idn,\ndistance_tol=self._goal_tolerance,\ndistance_axes=\"xyz\",\n)\nreturn terminations\ndef _sample_initial_pose_and_goal_pos(self, env, max_trials=100):\n# Run super first\ninitial_pos, initial_ori, goal_pos = super()._sample_initial_pose_and_goal_pos(env=env, max_trials=max_trials)\n# Sample goal position to be within requested height range if specified\nif self._height_range is not None:\ngoal_pos[2] += np.random.uniform(*self._height_range)\nreturn initial_pos, initial_ori, goal_pos\ndef _get_l2_potential(self, env):\n# Distance calculated from robot EEF, not base!\nreturn T.l2_distance(env.robots[self._robot_idn].get_eef_position(), self._goal_pos)\ndef _get_obs(self, env):\n# Get obs from super\nlow_dim_obs, obs = super()._get_obs(env=env)\n# Remove xy-pos and replace with full xyz relative distance between current and goal pos\nlow_dim_obs.pop(\"xy_pos_to_goal\")\nlow_dim_obs[\"eef_to_goal\"] = self._global_pos_to_robot_frame(env=env, pos=self._goal_pos)\n# Add local eef position as well\nlow_dim_obs[\"eef_local_pos\"] = self._global_pos_to_robot_frame(env=env, pos=env.robots[self._robot_idn].get_eef_position())\nreturn low_dim_obs, obs\ndef get_current_pos(self, env):\n# Current position is the robot's EEF, not base!\nreturn env.robots[self._robot_idn].get_eef_position()\n</code></pre>"},{"location":"reference/tasks/task_base.html","title":"task_base","text":""},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask","title":"<code>BaseTask</code>","text":"<p>         Bases: <code>GymObservable</code>, <code>Registerable</code></p> <p>Base Task class. Task-specific reset_scene, reset_agent, step methods are implemented in subclasses</p> <p>Parameters:</p> Name Type Description Default <code>termination_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p> <code>None</code> <code>reward_config</code> <code>None or dict</code> <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p> <code>None</code> Source code in <code>omnigibson/tasks/task_base.py</code> <pre><code>class BaseTask(GymObservable, Registerable, metaclass=ABCMeta):\n\"\"\"\n    Base Task class.\n    Task-specific reset_scene, reset_agent, step methods are implemented in subclasses\n    Args:\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\ndef __init__(self, termination_config=None, reward_config=None):\n# Make sure configs are dictionaries\ntermination_config = dict() if termination_config is None else termination_config\nreward_config = dict() if reward_config is None else reward_config\n# Sanity check termination and reward conditions -- any keys found in the inputted config but NOT\n# found in the default config should raise an error\nunknown_termination_keys = set(termination_config.keys()) - set(self.default_termination_config.keys())\nassert len(unknown_termination_keys) == 0, \\\n            f\"Got unknown termination config keys inputted: {unknown_termination_keys}\"\nunknown_reward_keys = set(reward_config.keys()) - set(self.default_reward_config.keys())\nassert len(unknown_reward_keys) == 0, f\"Got unknown reward config keys inputted: {unknown_reward_keys}\"\n# Combine with defaults and store internally\nself._termination_config = self.default_termination_config\nself._termination_config.update(termination_config)\nself._reward_config = self.default_reward_config\nself._reward_config.update(reward_config)\n# Generate reward and termination functions\nself._termination_conditions = self._create_termination_conditions()\nself._reward_functions = self._create_reward_functions()\n# Store other internal vars that will be populated at runtime\nself._loaded = False\nself._reward = None\nself._done = None\nself._info = None\nself._low_dim_obs_dim = None\n# Run super init\nsuper().__init__()\n@abstractmethod\ndef _load(self, env):\n\"\"\"\n        Load this task. Should be implemented by subclass. Can include functionality, e.g.: loading dynamic objects\n        into the environment\n        \"\"\"\nraise NotImplementedError()\n@abstractmethod\ndef _load_non_low_dim_observation_space(self):\n\"\"\"\n        Loads any non-low dim observation spaces for this task.\n        Returns:\n            dict: Keyword-mapped observation space for this object mapping non low dim task observation name to\n                observation space\n        \"\"\"\nraise NotImplementedError()\ndef _load_observation_space(self):\n# Create the non low dim obs space\nobs_space = self._load_non_low_dim_observation_space()\n# Create the low dim obs space and add to the main obs space dict -- make sure we're flattening low dim obs\nobs_space[\"low_dim\"] = self._build_obs_box_space(shape=(self._low_dim_obs_dim,), low=-np.inf, high=np.inf, dtype=np.float64)\nreturn obs_space\ndef load(self, env):\n\"\"\"\n        Load this task\n        \"\"\"\n# Make sure the scene is of the correct type!\nassert any([issubclass(env.scene.__class__, valid_cls) for valid_cls in self.valid_scene_types]), \\\n            f\"Got incompatible scene type {env.scene.__class__.__name__} for task {self.__class__.__name__}! \" \\\n            f\"Scene class must be a subclass of at least one of: \" \\\n            f\"{[cls_type.__name__ for cls_type in self.valid_scene_types]}\"\n# Run internal method\nself._load(env=env)\n# We're now initialized\nself._loaded = True\n@abstractmethod\ndef _create_termination_conditions(self):\n\"\"\"\n        Creates the termination functions in the environment\n        Returns:\n            dict of BaseTerminationCondition: Termination functions created for this task\n        \"\"\"\nraise NotImplementedError()\n@abstractmethod\ndef _create_reward_functions(self):\n\"\"\"\n        Creates the reward functions in the environment\n        Returns:\n            dict of BaseRewardFunction: Reward functions created for this task\n        \"\"\"\nraise NotImplementedError()\ndef _reset_scene(self, env):\n\"\"\"\n        Task-specific scene reset. Default is the normal scene reset\n        Args:\n            env (Environment): environment instance\n        \"\"\"\nenv.scene.reset()\ndef _reset_agent(self, env):\n\"\"\"\n        Task-specific agent reset\n        Args:\n            env (Environment): environment instance\n        \"\"\"\n# Default is no-op\npass\ndef _reset_variables(self, env):\n\"\"\"\n        Task-specific internal variable reset\n        Args:\n            env (Environment): environment instance\n        \"\"\"\n# By default, reset reward, done, and info\nself._reward = None\nself._done = None\nself._info = None\ndef reset(self, env):\n\"\"\"\n        Resets this task in the environment\n        Args:\n            env (Environment): environment instance to reset\n        \"\"\"\n# Reset the scene, agent, and variables\nself._reset_scene(env)\nself._reset_agent(env)\nself._reset_variables(env)\n# Also reset all termination conditions and reward functions\nfor termination_condition in self._termination_conditions.values():\ntermination_condition.reset(self, env)\nfor reward_function in self._reward_functions.values():\nreward_function.reset(self, env)\n# Fill in low dim obs dim so we can use this to create the observation space later\nself._low_dim_obs_dim = len(self.get_obs(env=env, flatten_low_dim=True)[\"low_dim\"])\ndef _step_termination(self, env, action, info=None):\n\"\"\"\n        Step and aggregate termination conditions\n        Args:\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n            info (None or dict): Any info to return\n        Returns:\n            2-tuple:\n                - float: aggregated termination at the current timestep\n                - dict: any information passed through this function or generated by this function\n        \"\"\"\n# Get all dones and successes from individual termination conditions\ndones = []\nsuccesses = []\nfor termination_condition in self._termination_conditions.values():\nd, s = termination_condition.step(self, env, action)\ndones.append(d)\nsuccesses.append(s)\n# Any True found corresponds to a done / success\ndone = sum(dones) &gt; 0\nsuccess = sum(successes) &gt; 0\n# Populate info\ninfo = dict() if info is None else info\ninfo[\"success\"] = success\nreturn done, info\ndef _step_reward(self, env, action, info=None):\n\"\"\"\n        Step and aggregate reward functions\n        Args:\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n            info (None or dict): Any info to return\n        Returns:\n            2-tuple:\n                - float: aggregated reward at the current timestep\n                - dict: any information passed through this function or generated by this function\n        \"\"\"\n# Make sure info is a dict\ntotal_info = dict() if info is None else info\n# We'll also store individual reward split as well\nbreakdown_dict = dict()\n# Aggregate rewards over all reward functions\ntotal_reward = 0.0\nfor reward_name, reward_function in self._reward_functions.items():\nreward, reward_info = reward_function.step(self, env, action)\ntotal_reward += reward\nbreakdown_dict[reward_name] = reward\ntotal_info[reward_name] = reward_info\n# Store breakdown dict\ntotal_info[\"reward_breakdown\"] = breakdown_dict\nreturn total_reward, total_info\n@abstractmethod\ndef _get_obs(self, env):\n\"\"\"\n        Get task-specific observation\n        Args:\n            env (Environment): Environment instance\n        Returns:\n            2-tuple:\n                - dict: Keyword-mapped low dimensional observations from this task\n                - dict: All other keyword-mapped observations from this task\n        \"\"\"\nraise NotImplementedError()\ndef _flatten_low_dim_obs(self, obs):\n\"\"\"\n        Flattens dictionary containing low-dimensional observations @obs and converts it from a dictionary into a\n        1D numpy array\n        Args:\n            obs (dict): Low-dim observation dictionary where each value is a 1D array\n        Returns:\n            n-array: 1D-numpy array of flattened low-dim observations\n        \"\"\"\n# By default, we simply concatenate all values in our obs dict\nreturn np.concatenate([ob for ob in obs.values()]) if len(obs.values()) &gt; 0 else np.array([])\ndef get_obs(self, env, flatten_low_dim=True):\n# Args: env (Environment): environment instance\n# Args: flatten_low_dim (bool): Whether to flatten low-dimensional observations\n# Grab obs internally\nlow_dim_obs, obs = self._get_obs(env=env)\n# Possibly flatten low dim and add to main observation dictionary\nobs[\"low_dim\"] = self._flatten_low_dim_obs(obs=low_dim_obs) if flatten_low_dim else low_dim_obs\nreturn obs\ndef step(self, env, action):\n\"\"\"\n        Perform task-specific step for every timestep\n        Args:\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n        Returns:\n            3-tuple:\n                - float: reward calculated after this step\n                - bool: whether task is done or not\n                - dict: nested dictionary of reward- and done-related info\n        \"\"\"\n# Make sure we're initialized\nassert self._loaded, \"Task must be loaded using load() before calling step()!\"\n# We calculate termination conditions first and then rewards\n# (since some rewards can rely on termination conditions to update)\ndone, done_info = self._step_termination(env=env, action=action)\nreward, reward_info = self._step_reward(env=env, action=action)\n# Update the internal state of this task\nself._reward = reward\nself._done = done\nself._info = {\n\"reward\": reward_info,\n\"done\": done_info,\n}\nreturn self._reward, self._done, deepcopy(self._info)\n@property\ndef name(self):\n\"\"\"\n        Returns:\n            str: Name of this task. Defaults to class name\n        \"\"\"\nreturn self.__class__.__name__\n@property\ndef reward(self):\n\"\"\"\n        Returns:\n            float: Current reward for this task\n        \"\"\"\nassert self._reward is not None, \"At least one step() must occur before reward can be calculated!\"\nreturn self._reward\n@property\ndef done(self):\n\"\"\"\n        Returns:\n            bool: Whether this task is done or not\n        \"\"\"\nassert self._done is not None, \"At least one step() must occur before done can be calculated!\"\nreturn self._done\n@property\ndef info(self):\n\"\"\"\n        Returns:\n            dict: Nested dictionary of information for this task, including reward- and done-specific information\n        \"\"\"\nassert self._info is not None, \"At least one step() must occur before info can be calculated!\"\nreturn self._info\n@classproperty\ndef valid_scene_types(cls):\n\"\"\"\n        Returns:\n            set of Scene: Scene type(s) that are valid (i.e.: compatible) with this specific task. This will be\n                used to sanity check the task + scene combination at runtime\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef default_reward_config(cls):\n\"\"\"\n        Returns:\n            dict: Default reward configuration for this class. Should include any kwargs necessary for\n                any of the reward classes generated in self._create_rewards(). Note: this default config\n                should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n                will raise an error!\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef default_termination_config(cls):\n\"\"\"\n        Returns:\n            dict: Default termination configuration for this class. Should include any kwargs necessary for\n                any of the termination classes generated in self._create_terminations(). Note: this default config\n                should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n                will raise an error!\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseTask\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_TASKS\nreturn REGISTERED_TASKS\n</code></pre>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.done","title":"<code>done</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this task is done or not</p>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.info","title":"<code>info</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Nested dictionary of information for this task, including reward- and done-specific information</p>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this task. Defaults to class name</p>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.reward","title":"<code>reward</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>float</code> <p>Current reward for this task</p>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.default_reward_config","title":"<code>default_reward_config()</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Default reward configuration for this class. Should include any kwargs necessary for any of the reward classes generated in self._create_rewards(). Note: this default config should be fully verbose -- any keys inputted in the constructor but NOT found in this default config will raise an error!</p> Source code in <code>omnigibson/tasks/task_base.py</code> <pre><code>@classproperty\ndef default_reward_config(cls):\n\"\"\"\n    Returns:\n        dict: Default reward configuration for this class. Should include any kwargs necessary for\n            any of the reward classes generated in self._create_rewards(). Note: this default config\n            should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n            will raise an error!\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.default_termination_config","title":"<code>default_termination_config()</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Default termination configuration for this class. Should include any kwargs necessary for any of the termination classes generated in self._create_terminations(). Note: this default config should be fully verbose -- any keys inputted in the constructor but NOT found in this default config will raise an error!</p> Source code in <code>omnigibson/tasks/task_base.py</code> <pre><code>@classproperty\ndef default_termination_config(cls):\n\"\"\"\n    Returns:\n        dict: Default termination configuration for this class. Should include any kwargs necessary for\n            any of the termination classes generated in self._create_terminations(). Note: this default config\n            should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n            will raise an error!\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.load","title":"<code>load(env)</code>","text":"<p>Load this task</p> Source code in <code>omnigibson/tasks/task_base.py</code> <pre><code>def load(self, env):\n\"\"\"\n    Load this task\n    \"\"\"\n# Make sure the scene is of the correct type!\nassert any([issubclass(env.scene.__class__, valid_cls) for valid_cls in self.valid_scene_types]), \\\n        f\"Got incompatible scene type {env.scene.__class__.__name__} for task {self.__class__.__name__}! \" \\\n        f\"Scene class must be a subclass of at least one of: \" \\\n        f\"{[cls_type.__name__ for cls_type in self.valid_scene_types]}\"\n# Run internal method\nself._load(env=env)\n# We're now initialized\nself._loaded = True\n</code></pre>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.reset","title":"<code>reset(env)</code>","text":"<p>Resets this task in the environment</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>environment instance to reset</p> required Source code in <code>omnigibson/tasks/task_base.py</code> <pre><code>def reset(self, env):\n\"\"\"\n    Resets this task in the environment\n    Args:\n        env (Environment): environment instance to reset\n    \"\"\"\n# Reset the scene, agent, and variables\nself._reset_scene(env)\nself._reset_agent(env)\nself._reset_variables(env)\n# Also reset all termination conditions and reward functions\nfor termination_condition in self._termination_conditions.values():\ntermination_condition.reset(self, env)\nfor reward_function in self._reward_functions.values():\nreward_function.reset(self, env)\n# Fill in low dim obs dim so we can use this to create the observation space later\nself._low_dim_obs_dim = len(self.get_obs(env=env, flatten_low_dim=True)[\"low_dim\"])\n</code></pre>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.step","title":"<code>step(env, action)</code>","text":"<p>Perform task-specific step for every timestep</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Environment</code> <p>Environment instance</p> required <code>action</code> <code>n-array</code> <p>1D flattened array of actions executed by all agents in the environment</p> required <p>Returns:</p> Type Description <p>3-tuple: - float: reward calculated after this step - bool: whether task is done or not - dict: nested dictionary of reward- and done-related info</p> Source code in <code>omnigibson/tasks/task_base.py</code> <pre><code>def step(self, env, action):\n\"\"\"\n    Perform task-specific step for every timestep\n    Args:\n        env (Environment): Environment instance\n        action (n-array): 1D flattened array of actions executed by all agents in the environment\n    Returns:\n        3-tuple:\n            - float: reward calculated after this step\n            - bool: whether task is done or not\n            - dict: nested dictionary of reward- and done-related info\n    \"\"\"\n# Make sure we're initialized\nassert self._loaded, \"Task must be loaded using load() before calling step()!\"\n# We calculate termination conditions first and then rewards\n# (since some rewards can rely on termination conditions to update)\ndone, done_info = self._step_termination(env=env, action=action)\nreward, reward_info = self._step_reward(env=env, action=action)\n# Update the internal state of this task\nself._reward = reward\nself._done = done\nself._info = {\n\"reward\": reward_info,\n\"done\": done_info,\n}\nreturn self._reward, self._done, deepcopy(self._info)\n</code></pre>"},{"location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.valid_scene_types","title":"<code>valid_scene_types()</code>","text":"<p>Returns:</p> Type Description <p>set of Scene: Scene type(s) that are valid (i.e.: compatible) with this specific task. This will be used to sanity check the task + scene combination at runtime</p> Source code in <code>omnigibson/tasks/task_base.py</code> <pre><code>@classproperty\ndef valid_scene_types(cls):\n\"\"\"\n    Returns:\n        set of Scene: Scene type(s) that are valid (i.e.: compatible) with this specific task. This will be\n            used to sanity check the task + scene combination at runtime\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/termination_conditions/index.html","title":"termination_conditions","text":""},{"location":"reference/termination_conditions/falling.html","title":"falling","text":""},{"location":"reference/termination_conditions/falling.html#termination_conditions.falling.Falling","title":"<code>Falling</code>","text":"<p>         Bases: <code>FailureCondition</code></p> <p>Falling (failure condition) used for any navigation-type tasks Episode terminates if the robot falls out of the world (i.e.: falls below the floor height by at least @fall_height</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>robot identifier to evaluate condition with. Default is 0, corresponding to the first robot added to the scene</p> <code>0</code> <code>fall_height</code> <code>float</code> <p>distance (m) &gt; 0 below the scene's floor height under which the the robot is considered to be falling out of the world</p> <code>0.03</code> Source code in <code>omnigibson/termination_conditions/falling.py</code> <pre><code>class Falling(FailureCondition):\n\"\"\"\n    Falling (failure condition) used for any navigation-type tasks\n    Episode terminates if the robot falls out of the world (i.e.: falls below the floor height by at least\n    @fall_height\n    Args:\n        robot_idn (int): robot identifier to evaluate condition with. Default is 0, corresponding to the first\n            robot added to the scene\n        fall_height (float): distance (m) &gt; 0 below the scene's floor height under which the the robot is considered\n            to be falling out of the world\n    \"\"\"\ndef __init__(self, robot_idn=0, fall_height=0.03):\n# Store internal vars\nself._robot_idn = robot_idn\nself._fall_height = fall_height\n# Run super init\nsuper().__init__()\ndef _step(self, task, env, action):\n# Terminate if the specified robot is falling out of the scene\nrobot_z = env.scene.robots[self._robot_idn].get_position()[2]\nreturn robot_z &lt; (env.scene.get_floor_height() - self._fall_height)\n</code></pre>"},{"location":"reference/termination_conditions/max_collision.html","title":"max_collision","text":""},{"location":"reference/termination_conditions/max_collision.html#termination_conditions.max_collision.MaxCollision","title":"<code>MaxCollision</code>","text":"<p>         Bases: <code>FailureCondition</code></p> <p>MaxCollision (failure condition) used for navigation tasks Episode terminates if the robot has collided more than max_collisions_allowed times Note that we ignore collisions with any floor objects.</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>robot identifier to evaluate collision checking with. Default is 0, corresponding to the first robot added to the scene</p> <code>0</code> <code>ignore_self_collisions</code> <code>bool</code> <p>Whether to ignore robot self-collisions or not</p> <code>True</code> <code>max_collisions</code> <code>int</code> <p>Maximum number of collisions allowed for any robots in the scene before a termination is triggered</p> <code>500</code> Source code in <code>omnigibson/termination_conditions/max_collision.py</code> <pre><code>class MaxCollision(FailureCondition):\n\"\"\"\n    MaxCollision (failure condition) used for navigation tasks\n    Episode terminates if the robot has collided more than max_collisions_allowed times\n    Note that we ignore collisions with any floor objects.\n    Args:\n        robot_idn (int): robot identifier to evaluate collision checking with. Default is 0, corresponding to the first\n            robot added to the scene\n        ignore_self_collisions (bool): Whether to ignore robot self-collisions or not\n        max_collisions (int): Maximum number of collisions allowed for any robots in the scene before a termination\n            is triggered\n    \"\"\"\ndef __init__(self, robot_idn=0, ignore_self_collisions=True, max_collisions=500):\nself._robot_idn = robot_idn\nself._ignore_self_collisions = ignore_self_collisions\nself._max_collisions = max_collisions\nself._n_collisions = 0\n# Run super init\nsuper().__init__()\ndef reset(self, task, env):\n# Call super first\nsuper().reset(task, env)\n# Also reset collision counter\nself._n_collisions = 0\ndef _step(self, task, env, action):\n# Terminate if the robot has collided more than self._max_collisions times\nrobot = env.robots[self._robot_idn]\nfloors = list(env.scene.object_registry(\"category\", \"floors\", []))\nignore_objs = floors if self._ignore_self_collisions is None else floors + [robot]\nin_contact = len(env.robots[self._robot_idn].states[ContactBodies].get_value(ignore_objs=tuple(ignore_objs))) &gt; 0\nself._n_collisions += int(in_contact)\nreturn self._n_collisions &gt; self._max_collisions\n</code></pre>"},{"location":"reference/termination_conditions/point_goal.html","title":"point_goal","text":""},{"location":"reference/termination_conditions/point_goal.html#termination_conditions.point_goal.PointGoal","title":"<code>PointGoal</code>","text":"<p>         Bases: <code>SuccessCondition</code></p> <p>PointGoal (success condition) used for PointNavFixed/RandomTask Episode terminates if point goal is reached within @distance_tol by the @robot_idn robot's base</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>robot identifier to evaluate point goal with. Default is 0, corresponding to the first robot added to the scene</p> <code>0</code> <code>distance_tol</code> <code>float</code> <p>Distance (m) tolerance between goal position and @robot_idn's robot base position that is accepted as a success</p> <code>0.5</code> <code>distance_axes</code> <code>str</code> <p>Which axes to calculate distances when calculating the goal. Any combination of \"x\", \"y\", and \"z\" is valid (e.g.: \"xy\" or \"xyz\" or \"y\")</p> <code>'xyz'</code> Source code in <code>omnigibson/termination_conditions/point_goal.py</code> <pre><code>class PointGoal(SuccessCondition):\n\"\"\"\n    PointGoal (success condition) used for PointNavFixed/RandomTask\n    Episode terminates if point goal is reached within @distance_tol by the @robot_idn robot's base\n    Args:\n        robot_idn (int): robot identifier to evaluate point goal with. Default is 0, corresponding to the first\n            robot added to the scene\n        distance_tol (float): Distance (m) tolerance between goal position and @robot_idn's robot base position\n            that is accepted as a success\n        distance_axes (str): Which axes to calculate distances when calculating the goal. Any combination of \"x\",\n            \"y\", and \"z\" is valid (e.g.: \"xy\" or \"xyz\" or \"y\")\n    \"\"\"\ndef __init__(self, robot_idn=0, distance_tol=0.5, distance_axes=\"xyz\"):\nself._robot_idn = robot_idn\nself._distance_tol = distance_tol\nself._distance_axes = [i for i, axis in enumerate(\"xyz\") if axis in distance_axes]\n# Run super init\nsuper().__init__()\ndef _step(self, task, env, action):\n# Make sure task is of type PointNavigation -- we import at runtime to avoid circular imports\nfrom omnigibson.tasks.point_navigation_task import PointNavigationTask\nassert isinstance(task, PointNavigationTask), \\\n            f\"Cannot use {self.__class__.__name__} with a non-PointNavigationTask task instance!\"\n# Terminate if point goal is reached (distance below threshold)\nreturn T.l2_distance(task.get_current_pos(env)[self._distance_axes], task.get_goal_pos()[self._distance_axes]) \\\n            &lt; self._distance_tol\n</code></pre>"},{"location":"reference/termination_conditions/predicate_goal.html","title":"predicate_goal","text":""},{"location":"reference/termination_conditions/predicate_goal.html#termination_conditions.predicate_goal.PredicateGoal","title":"<code>PredicateGoal</code>","text":"<p>         Bases: <code>SuccessCondition</code></p> <p>PredicateGoal (success condition) used for BehaviorTask Episode terminates if all the predicates are satisfied</p> <p>Parameters:</p> Name Type Description Default <code>goal_fcn</code> <code>method</code> <p>function for calculating goal(s). Function signature should be:</p> <p>goals = goal_fcn()</p> <p>where @goals is a list of bddl.condition_evaluation.HEAD -- compiled BDDL goal conditions</p> required Source code in <code>omnigibson/termination_conditions/predicate_goal.py</code> <pre><code>class PredicateGoal(SuccessCondition):\n\"\"\"\n    PredicateGoal (success condition) used for BehaviorTask\n    Episode terminates if all the predicates are satisfied\n    Args:\n        goal_fcn (method): function for calculating goal(s). Function signature should be:\n            goals = goal_fcn()\n            where @goals is a list of bddl.condition_evaluation.HEAD -- compiled BDDL goal conditions\n    \"\"\"\ndef __init__(self, goal_fcn):\n# Store internal vars\nself._goal_fcn = goal_fcn\nself._goal_status = None\n# Run super\nsuper().__init__()\ndef reset(self, task, env):\n# Run super first\nsuper().reset(task, env)\n# Reset status\nself._goal_status = {\"satisfied\": [], \"unsatisfied\": []}\ndef _step(self, task, env, action):\n# Terminate if all goal conditions are met in the task\ndone, self._goal_status = evaluate_goal_conditions(self._goal_fcn())\nreturn done\n@property\ndef goal_status(self):\n\"\"\"\n        Returns:\n            dict: Current goal status for the active predicate(s), mapping \"satisfied\" and \"unsatisfied\" to a list\n                of the predicates matching either of those conditions\n        \"\"\"\nreturn self._goal_status\n</code></pre>"},{"location":"reference/termination_conditions/predicate_goal.html#termination_conditions.predicate_goal.PredicateGoal.goal_status","title":"<code>goal_status</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Current goal status for the active predicate(s), mapping \"satisfied\" and \"unsatisfied\" to a list of the predicates matching either of those conditions</p>"},{"location":"reference/termination_conditions/reaching_goal.html","title":"reaching_goal","text":""},{"location":"reference/termination_conditions/reaching_goal.html#termination_conditions.reaching_goal.ReachingGoal","title":"<code>ReachingGoal</code>","text":"<p>         Bases: <code>SuccessCondition</code></p> <p>ReachingGoal (success condition) used for reaching-type tasks Episode terminates if reaching goal is reached within @distance_tol by the @robot_idn robot's base</p> <p>Parameters:</p> Name Type Description Default <code>robot_idn</code> <code>int</code> <p>robot identifier to evaluate point goal with. Default is 0, corresponding to the first robot added to the scene</p> <code>0</code> <code>distance_tol</code> <code>float</code> <p>Distance (m) tolerance between goal position and @robot_idn's robot eef position that is accepted as a success</p> <code>0.5</code> Source code in <code>omnigibson/termination_conditions/reaching_goal.py</code> <pre><code>class ReachingGoal(SuccessCondition):\n\"\"\"\n    ReachingGoal (success condition) used for reaching-type tasks\n    Episode terminates if reaching goal is reached within @distance_tol by the @robot_idn robot's base\n    Args:\n    Args:\n        robot_idn (int): robot identifier to evaluate point goal with. Default is 0, corresponding to the first\n            robot added to the scene\n        distance_tol (float): Distance (m) tolerance between goal position and @robot_idn's robot eef position\n            that is accepted as a success\n    \"\"\"\ndef __init__(self, robot_idn=0, distance_tol=0.5):\nself._robot_idn = robot_idn\nself._distance_tol = distance_tol\n# Run super init\nsuper().__init__()\ndef _step(self, task, env, action):\n# Terminate if point goal is reached (distance below threshold)\nreturn T.l2_distance(env.scene.robots[self._robot_idn].get_eef_position(), task.goal_pos) &lt; \\\n               self._distance_tol\n</code></pre>"},{"location":"reference/termination_conditions/termination_condition_base.html","title":"termination_condition_base","text":""},{"location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition","title":"<code>BaseTerminationCondition</code>","text":"<p>         Bases: <code>Registerable</code></p> <p>Base TerminationCondition class Condition-specific _step() method is implemented in subclasses</p> Source code in <code>omnigibson/termination_conditions/termination_condition_base.py</code> <pre><code>class BaseTerminationCondition(Registerable, metaclass=ABCMeta):\n\"\"\"\n    Base TerminationCondition class\n    Condition-specific _step() method is implemented in subclasses\n    \"\"\"\ndef __init__(self):\n# Initialize internal vars that will be filled in at runtime\nself._done = None\n@abstractmethod\ndef _step(self, task, env, action):\n\"\"\"\n        Step the termination condition and return whether the episode should terminate. Overwritten by subclasses.\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n        Returns:\n            bool: whether environment should terminate or not\n        \"\"\"\nraise NotImplementedError()\ndef step(self, task, env, action):\n\"\"\"\n        Step the termination condition and return whether the episode should terminate.\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n        Returns:\n            2-tuple:\n                - bool: whether environment should terminate or not\n                - bool: whether a success was reached under this termination condition\n        \"\"\"\n# Step internally and store the done state internally as well\nself._done = self._step(task=task, env=env, action=action)\n# We are successful if done is True AND this is a success condition\nsuccess = self._done and self._terminate_is_success\nreturn self._done, success\ndef reset(self, task, env):\n\"\"\"\n        Termination condition-specific reset\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n        \"\"\"\n# Reset internal vars\nself._done = None\n@property\ndef done(self):\n\"\"\"\n        Returns:\n            bool: Whether this termination condition has triggered or not\n        \"\"\"\nassert self._done is not None, \"At least one step() must occur before done can be calculated!\"\nreturn self._done\n@property\ndef success(self):\n\"\"\"\n        Returns:\n            bool: Whether this termination condition has been evaluated as a success or not\n        \"\"\"\nassert self._done is not None, \"At least one step() must occur before success can be calculated!\"\nreturn self._done and self._terminate_is_success\n@classproperty\ndef _terminate_is_success(cls):\n\"\"\"\n        Returns:\n            bool: Whether this termination condition corresponds to a success\n        \"\"\"\nraise NotImplementedError()\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"BaseTerminationCondition\")\nreturn classes\n@classproperty\ndef _cls_registry(cls):\n# Global registry\nglobal REGISTERED_TERMINATION_CONDITIONS\nreturn REGISTERED_TERMINATION_CONDITIONS\n</code></pre>"},{"location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.done","title":"<code>done</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this termination condition has triggered or not</p>"},{"location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.success","title":"<code>success</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>Whether this termination condition has been evaluated as a success or not</p>"},{"location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.reset","title":"<code>reset(task, env)</code>","text":"<p>Termination condition-specific reset</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>BaseTask</code> <p>Task instance</p> required <code>env</code> <code>Environment</code> <p>Environment instance</p> required Source code in <code>omnigibson/termination_conditions/termination_condition_base.py</code> <pre><code>def reset(self, task, env):\n\"\"\"\n    Termination condition-specific reset\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n    \"\"\"\n# Reset internal vars\nself._done = None\n</code></pre>"},{"location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.step","title":"<code>step(task, env, action)</code>","text":"<p>Step the termination condition and return whether the episode should terminate.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>BaseTask</code> <p>Task instance</p> required <code>env</code> <code>Environment</code> <p>Environment instance</p> required <code>action</code> <code>n-array</code> <p>1D flattened array of actions executed by all agents in the environment</p> required <p>Returns:</p> Type Description <p>2-tuple: - bool: whether environment should terminate or not - bool: whether a success was reached under this termination condition</p> Source code in <code>omnigibson/termination_conditions/termination_condition_base.py</code> <pre><code>def step(self, task, env, action):\n\"\"\"\n    Step the termination condition and return whether the episode should terminate.\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n        action (n-array): 1D flattened array of actions executed by all agents in the environment\n    Returns:\n        2-tuple:\n            - bool: whether environment should terminate or not\n            - bool: whether a success was reached under this termination condition\n    \"\"\"\n# Step internally and store the done state internally as well\nself._done = self._step(task=task, env=env, action=action)\n# We are successful if done is True AND this is a success condition\nsuccess = self._done and self._terminate_is_success\nreturn self._done, success\n</code></pre>"},{"location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.FailureCondition","title":"<code>FailureCondition</code>","text":"<p>         Bases: <code>BaseTerminationCondition</code></p> <p>Termination condition corresponding to a failure</p> Source code in <code>omnigibson/termination_conditions/termination_condition_base.py</code> <pre><code>class FailureCondition(BaseTerminationCondition):\n\"\"\"\n    Termination condition corresponding to a failure\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\n# Register as part of locomotion controllers\nsuper().__init_subclass__(**kwargs)\nregister_failure_condition(cls)\n@classproperty\ndef _terminate_is_success(cls):\n# Done --&gt; not success\nreturn False\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"FailureCondition\")\nreturn classes\n</code></pre>"},{"location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.SuccessCondition","title":"<code>SuccessCondition</code>","text":"<p>         Bases: <code>BaseTerminationCondition</code></p> <p>Termination condition corresponding to a success</p> Source code in <code>omnigibson/termination_conditions/termination_condition_base.py</code> <pre><code>class SuccessCondition(BaseTerminationCondition):\n\"\"\"\n    Termination condition corresponding to a success\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\n# Register as part of locomotion controllers\nsuper().__init_subclass__(**kwargs)\nregister_success_condition(cls)\n@classproperty\ndef _terminate_is_success(cls):\n# Done --&gt; success\nreturn True\n@classproperty\ndef _do_not_register_classes(cls):\n# Don't register this class since it's an abstract template\nclasses = super()._do_not_register_classes\nclasses.add(\"SuccessCondition\")\nreturn classes\n</code></pre>"},{"location":"reference/termination_conditions/timeout.html","title":"timeout","text":""},{"location":"reference/termination_conditions/timeout.html#termination_conditions.timeout.Timeout","title":"<code>Timeout</code>","text":"<p>         Bases: <code>FailureCondition</code></p> <p>Timeout (failure condition) Episode terminates if max_step steps have passed</p> <p>Parameters:</p> Name Type Description Default <code>max_steps</code> <code>int</code> <p>Maximum number of episode steps before timeout occurs</p> <code>500</code> Source code in <code>omnigibson/termination_conditions/timeout.py</code> <pre><code>class Timeout(FailureCondition):\n\"\"\"\n    Timeout (failure condition)\n    Episode terminates if max_step steps have passed\n    Args:\n        max_steps (int): Maximum number of episode steps before timeout occurs\n    \"\"\"\ndef __init__(self, max_steps=500):\n# Store internal vars\nself._max_steps = max_steps\n# Run super\nsuper().__init__()\ndef _step(self, task, env, action):\n# Terminate if number of steps passed exceeds threshold\nreturn env.episode_steps &gt;= self._max_steps\n</code></pre>"},{"location":"reference/utils/index.html","title":"utils","text":""},{"location":"reference/utils/asset_utils.html","title":"asset_utils","text":""},{"location":"reference/utils/asset_utils.html#utils.asset_utils.change_data_path","title":"<code>change_data_path()</code>","text":"<p>Changes the data paths for this repo</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def change_data_path():\n\"\"\"\n    Changes the data paths for this repo\n    \"\"\"\nwith open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"..\", \"global_config.yaml\")) as f:\nglobal_config = yaml.load(f, Loader=yaml.FullLoader)\nprint(\"Current dataset path:\")\nfor k, v in global_config.items():\nprint(\"{}: {}\".format(k, v))\nfor k, v in global_config.items():\nnew_path = input(\"Change {} from {} to: \".format(k, v))\nglobal_config[k] = new_path\nprint(\"New dataset path:\")\nfor k, v in global_config.items():\nprint(\"{}: {}\".format(k, v))\nresponse = input(\"Save? [y/n]\")\nif response == \"y\":\nwith open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"..\", \"global_config.yaml\"), \"w\") as f:\nyaml.dump(global_config, f)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.download_assets","title":"<code>download_assets()</code>","text":"<p>Download OmniGibson assets</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def download_assets():\n\"\"\"\n    Download OmniGibson assets\n    \"\"\"\nif os.path.exists(gm.ASSET_PATH):\nprint(\"Assets already downloaded.\")\nelse:\nwith tempfile.TemporaryDirectory() as td:\ntmp_file = os.path.join(td, \"og_assets.tar.gz\")\nos.makedirs(gm.ASSET_PATH, exist_ok=True)\npath = \"https://storage.googleapis.com/gibson_scenes/og_assets.tar.gz\"\nlog.info(f\"Downloading and decompressing demo OmniGibson assets from {path}\")\nassert urlretrieve(path, tmp_file, show_progress), \"Assets download failed.\"\nassert subprocess.call([\"tar\", \"-zxf\", tmp_file, \"--strip-components=1\", \"--directory\", gm.ASSET_PATH]) == 0, \"Assets extraction failed.\"\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.download_demo_data","title":"<code>download_demo_data()</code>","text":"<p>Download OmniGibson demo dataset</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def download_demo_data():\n\"\"\"\n    Download OmniGibson demo dataset\n    \"\"\"\n# TODO: Update. Right now, OG just downloads beta release\ndownload_og_dataset()\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.download_og_dataset","title":"<code>download_og_dataset()</code>","text":"<p>Download OmniGibson dataset</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def download_og_dataset():\n\"\"\"\n    Download OmniGibson dataset\n    \"\"\"\n# Print user agreement\nif os.path.exists(gm.KEY_PATH):\nprint(\"OmniGibson dataset encryption key already installed.\")\nelse:\nprint(\"\\n\")\nprint_user_agreement()\nwhile (\ninput(\n\"Do you agree to the above terms for using OmniGibson dataset? [y/n]\"\n)\n!= \"y\"\n):\nprint(\"You need to agree to the terms for using OmniGibson dataset.\")\ndownload_key()\nif os.path.exists(gm.DATASET_PATH):\nprint(\"OmniGibson dataset already installed.\")\nelse:\ntmp_file = os.path.join(tempfile.gettempdir(), \"og_dataset.tar.gz\")\nos.makedirs(gm.DATASET_PATH, exist_ok=True)\npath = \"https://storage.googleapis.com/gibson_scenes/og_dataset.tar.gz\"\nlog.info(f\"Downloading and decompressing demo OmniGibson dataset from {path}\")\nassert urlretrieve(path, tmp_file, show_progress), \"Dataset download failed.\"\nassert subprocess.call([\"tar\", \"-zxf\", tmp_file, \"--strip-components=1\", \"--directory\", gm.DATASET_PATH]) == 0, \"Dataset extraction failed.\"\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_all_object_categories","title":"<code>get_all_object_categories()</code>","text":"<p>Get OmniGibson all object categories</p> <p>Returns:</p> Name Type Description <code>list</code> <p>all object categories</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_all_object_categories():\n\"\"\"\n    Get OmniGibson all object categories\n    Returns:\n        list: all object categories\n    \"\"\"\nog_dataset_path = gm.DATASET_PATH\nog_categories_path = os.path.join(og_dataset_path, \"objects\")\ncategories =[f for f in os.listdir(og_categories_path) if not is_dot_file(f)]\nreturn sorted(categories)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_all_object_models","title":"<code>get_all_object_models()</code>","text":"<p>Get OmniGibson all object models</p> <p>Returns:</p> Name Type Description <code>list</code> <p>all object model paths</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_all_object_models():\n\"\"\"\n    Get OmniGibson all object models\n    Returns:\n        list: all object model paths\n    \"\"\"\nog_dataset_path = gm.DATASET_PATH\nog_categories_path = os.path.join(og_dataset_path, \"objects\")\ncategories = os.listdir(og_categories_path)\ncategories = [item for item in categories if os.path.isdir(os.path.join(og_categories_path, item))]\nmodels = []\nfor category in categories:\ncategory_models = os.listdir(os.path.join(og_categories_path, category))\ncategory_models = [\nitem for item in category_models if os.path.isdir(os.path.join(og_categories_path, category, item))\n]\nmodels.extend([os.path.join(og_categories_path, category, item) for item in category_models])\nreturn sorted(models)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_assisted_grasping_categories","title":"<code>get_assisted_grasping_categories()</code>","text":"<p>Generate a list of categories that can be grasped using assisted grasping, using labels provided in average category specs file.</p> <p>Returns:</p> Type Description <p>list of str: Object category allowlist for assisted grasping</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_assisted_grasping_categories():\n\"\"\"\n    Generate a list of categories that can be grasped using assisted grasping,\n    using labels provided in average category specs file.\n    Returns:\n        list of str: Object category allowlist for assisted grasping\n    \"\"\"\nassisted_grasp_category_allow_list = set()\navg_category_spec = get_og_avg_category_specs()\nfor k, v in avg_category_spec.items():\nif v[\"enable_ag\"]:\nassisted_grasp_category_allow_list.add(k)\nreturn assisted_grasp_category_allow_list\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_available_g_scenes","title":"<code>get_available_g_scenes()</code>","text":"<p>Returns:</p> Name Type Description <code>list</code> <p>available Gibson scenes</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_available_g_scenes():\n\"\"\"\n    Returns:\n        list: available Gibson scenes\n    \"\"\"\ndata_path = og.g_dataset_path\navailable_g_scenes = sorted([f for f in os.listdir(data_path) if not is_dot_file(f)])\nreturn available_g_scenes\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_available_og_scenes","title":"<code>get_available_og_scenes()</code>","text":"<p>OmniGibson interactive scenes</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Available OmniGibson interactive scenes</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_available_og_scenes():\n\"\"\"\n    OmniGibson interactive scenes\n    Returns:\n        list: Available OmniGibson interactive scenes\n    \"\"\"\nog_dataset_path = gm.DATASET_PATH\nog_scenes_path = os.path.join(og_dataset_path, \"scenes\")\navailable_og_scenes = sorted(\n[f for f in os.listdir(og_scenes_path) if (not is_dot_file(f) and f != \"background\")]\n)\nreturn available_og_scenes\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_object_models_of_category","title":"<code>get_object_models_of_category(category_name, filter_method=None)</code>","text":"<p>Get OmniGibson all object models of a given category</p>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_object_models_of_category--todo-make-this-less-ugly-filter_method-is-a-single-hard-coded-check","title":"TODO: Make this less ugly -- filter_method is a single hard-coded check","text":"<p>Parameters:</p> Name Type Description Default <code>category_name</code> <code>str</code> <p>object category</p> required <code>filter_method</code> <code>str</code> <p>Method to use for filtering object models</p> <code>None</code> <p>Returns:</p> Name Type Description <code>list</code> <p>all object models of a given category</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_object_models_of_category(category_name, filter_method=None):\n\"\"\"\n    Get OmniGibson all object models of a given category\n    # TODO: Make this less ugly -- filter_method is a single hard-coded check\n    Args:\n        category_name (str): object category\n        filter_method (str): Method to use for filtering object models\n    Returns:\n        list: all object models of a given category\n    \"\"\"\nmodels = []\nog_category_path = get_og_category_path(category_name)\nfor model_name in os.listdir(og_category_path):\nif filter_method is None:\nmodels.append(model_name)\nelif filter_method in [\"sliceable_part\", \"sliceable_whole\"]:\nmodel_path = get_og_model_path(category_name, model_name)\nmetadata_json = os.path.join(model_path, \"misc\", \"metadata.json\")\nwith open(metadata_json) as f:\nmetadata = json.load(f)\nif (filter_method == \"sliceable_part\" and \"object_parts\" not in metadata) or (\nfilter_method == \"sliceable_whole\" and \"object_parts\" in metadata\n):\nmodels.append(model_name)\nelse:\nraise Exception(\"Unknown filter method: {}\".format(filter_method))\nreturn sorted(models)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_assets_version","title":"<code>get_og_assets_version()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>OmniGibson asset version</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_og_assets_version():\n\"\"\"\n    Returns:\n        str: OmniGibson asset version\n    \"\"\"\nprocess = subprocess.Popen(\n[\"git\", \"-C\", gm.DATASET_PATH, \"rev-parse\", \"HEAD\"], shell=False, stdout=subprocess.PIPE\n)\ngit_head_hash = str(process.communicate()[0].strip())\nreturn \"{}\".format(git_head_hash)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_avg_category_specs","title":"<code>get_og_avg_category_specs()</code>","text":"<p>Load average object specs (dimension and mass) for objects</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Average category specifications for all object categories</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_og_avg_category_specs():\n\"\"\"\n    Load average object specs (dimension and mass) for objects\n    Returns:\n        dict: Average category specifications for all object categories\n    \"\"\"\navg_obj_dim_file = os.path.join(gm.DATASET_PATH, \"metadata\", \"avg_category_specs.json\")\nif os.path.exists(avg_obj_dim_file):\nwith open(avg_obj_dim_file) as f:\nreturn json.load(f)\nelse:\nlog.warning(\n\"Requested average specs of the object categories in the OmniGibson Dataset of objects, but the \"\n\"file cannot be found. Did you download the dataset? Returning an empty dictionary\"\n)\nreturn dict()\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_category_ids","title":"<code>get_og_category_ids()</code>","text":"<p>Get OmniGibson object categories</p> <p>Returns:</p> Name Type Description <code>str</code> <p>file path to the scene name</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_og_category_ids():\n\"\"\"\n    Get OmniGibson object categories\n    Returns:\n        str: file path to the scene name\n    \"\"\"\nog_dataset_path = gm.DATASET_PATH\nog_categories_files = os.path.join(og_dataset_path, \"metadata\", \"categories.txt\")\nname_to_id = {}\nwith open(og_categories_files, \"r\") as fp:\nfor i, l in enumerate(fp.readlines()):\nname_to_id[l.rstrip()] = i\nreturn defaultdict(lambda: 255, name_to_id)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_category_path","title":"<code>get_og_category_path(category_name)</code>","text":"<p>Get OmniGibson object category path</p> <p>Parameters:</p> Name Type Description Default <code>category_name</code> <code>str</code> <p>object category</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>file path to the object category</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_og_category_path(category_name):\n\"\"\"\n    Get OmniGibson object category path\n    Args:\n        category_name (str): object category\n    Returns:\n        str: file path to the object category\n    \"\"\"\nog_dataset_path = gm.DATASET_PATH\nog_categories_path = os.path.join(og_dataset_path, \"objects\")\nassert category_name in os.listdir(og_categories_path), \"Category {} does not exist\".format(category_name)\nreturn os.path.join(og_categories_path, category_name)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_model_path","title":"<code>get_og_model_path(category_name, model_name)</code>","text":"<p>Get OmniGibson object model path</p> <p>Parameters:</p> Name Type Description Default <code>category_name</code> <code>str</code> <p>object category</p> required <code>model_name</code> <code>str</code> <p>object model</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>file path to the object model</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_og_model_path(category_name, model_name):\n\"\"\"\n    Get OmniGibson object model path\n    Args:\n        category_name (str): object category\n        model_name (str): object model\n    Returns:\n        str: file path to the object model\n    \"\"\"\nog_category_path = get_og_category_path(category_name)\nassert model_name in os.listdir(og_category_path), \"Model {} from category {} does not exist\".format(\nmodel_name, category_name\n)\nreturn os.path.join(og_category_path, model_name)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_scene_path","title":"<code>get_og_scene_path(scene_name)</code>","text":"<p>Get OmniGibson scene path</p> <p>Parameters:</p> Name Type Description Default <code>scene_name</code> <code>str</code> <p>scene name, e.g., \"Rs_int\"</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>file path to the scene name</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_og_scene_path(scene_name):\n\"\"\"\n    Get OmniGibson scene path\n    Args:\n        scene_name (str): scene name, e.g., \"Rs_int\"\n    Returns:\n        str: file path to the scene name\n    \"\"\"\nog_dataset_path = gm.DATASET_PATH\nog_scenes_path = os.path.join(og_dataset_path, \"scenes\")\nlog.info(\"Scene name: {}\".format(scene_name))\nassert scene_name in os.listdir(og_scenes_path), \"Scene {} does not exist\".format(scene_name)\nreturn os.path.join(og_scenes_path, scene_name)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_scene_path","title":"<code>get_scene_path(scene_id)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>scene_id</code> <code>str</code> <p>scene id, e.g., \"Rs_int\"</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>scene path for this scene_id</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_scene_path(scene_id):\n\"\"\"\n    Args:\n        scene_id (str): scene id, e.g., \"Rs_int\"\n    Returns:\n        str: scene path for this scene_id\n    \"\"\"\ndata_path = og.g_dataset_path\nassert scene_id in os.listdir(data_path), \"Scene {} does not exist\".format(scene_id)\nreturn os.path.join(data_path, scene_id)\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.get_texture_file","title":"<code>get_texture_file(mesh_file)</code>","text":"<p>Get texture file</p> <p>Parameters:</p> Name Type Description Default <code>mesh_file</code> <code>str</code> <p>path to mesh obj file</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>texture file path</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def get_texture_file(mesh_file):\n\"\"\"\n    Get texture file\n    Args:\n        mesh_file (str): path to mesh obj file\n    Returns:\n        str: texture file path\n    \"\"\"\nmodel_dir = os.path.dirname(mesh_file)\nwith open(mesh_file, \"r\") as f:\nlines = [line.strip() for line in f.readlines() if \"mtllib\" in line]\nif len(lines) == 0:\nreturn\nmtl_file = lines[0].split()[1]\nmtl_file = os.path.join(model_dir, mtl_file)\nwith open(mtl_file, \"r\") as f:\nlines = [line.strip() for line in f.readlines() if \"map_Kd\" in line]\nif len(lines) == 0:\nreturn\ntexture_file = lines[0].split()[1]\ntexture_file = os.path.join(model_dir, texture_file)\nreturn texture_file\n</code></pre>"},{"location":"reference/utils/asset_utils.html#utils.asset_utils.is_dot_file","title":"<code>is_dot_file(p)</code>","text":"<p>Check if a filename starts with a dot. Note that while this does not actually correspond to checking for hidden files on Windows, the files we want to ignore will still start with a dot and thus this works.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>true if a folder is hidden in the OS</p> Source code in <code>omnigibson/utils/asset_utils.py</code> <pre><code>def is_dot_file(p):\n\"\"\"\n    Check if a filename starts with a dot.\n    Note that while this does not actually correspond to checking for hidden files on Windows, the\n    files we want to ignore will still start with a dot and thus this works.\n    Returns:\n        bool: true if a folder is hidden in the OS\n    \"\"\"\nreturn p.startswith(\".\")\n</code></pre>"},{"location":"reference/utils/config_utils.html","title":"config_utils","text":""},{"location":"reference/utils/config_utils.html#utils.config_utils.dump_config","title":"<code>dump_config(config)</code>","text":"<p>Converts YML config into a string</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Config to dump</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Config as a string</p> Source code in <code>omnigibson/utils/config_utils.py</code> <pre><code>def dump_config(config):\n\"\"\"\n    Converts YML config into a string\n    Args:\n        config (dict): Config to dump\n    Returns:\n        str: Config as a string\n    \"\"\"\nreturn yaml.dump(config)\n</code></pre>"},{"location":"reference/utils/config_utils.html#utils.config_utils.load_default_config","title":"<code>load_default_config()</code>","text":"<p>Loads a default configuration to use for OmniGibson</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Loaded default configuration file</p> Source code in <code>omnigibson/utils/config_utils.py</code> <pre><code>def load_default_config():\n\"\"\"\n    Loads a default configuration to use for OmniGibson\n    Returns:\n        dict: Loaded default configuration file\n    \"\"\"\nreturn parse_config(f\"{example_config_path}/default_cfg.yaml\")\n</code></pre>"},{"location":"reference/utils/config_utils.html#utils.config_utils.parse_config","title":"<code>parse_config(config)</code>","text":"<p>Parse OmniGibson config file / object</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict or str</code> <p>Either config dictionary or path to yaml config to load</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Parsed config</p> Source code in <code>omnigibson/utils/config_utils.py</code> <pre><code>def parse_config(config):\n\"\"\"\n    Parse OmniGibson config file / object\n    Args:\n        config (dict or str): Either config dictionary or path to yaml config to load\n    Returns:\n        dict: Parsed config\n    \"\"\"\nif isinstance(config, collections.Mapping):\nreturn config\nelse:\nassert isinstance(config, str)\nif not os.path.exists(config):\nraise IOError(\n\"config path {} does not exist. Please either pass in a dict or a string that represents the file path to the config yaml.\".format(\nconfig\n)\n)\nwith open(config, \"r\") as f:\nconfig_data = yaml.load(f, Loader=yaml.FullLoader)\nreturn config_data\n</code></pre>"},{"location":"reference/utils/config_utils.html#utils.config_utils.parse_str_config","title":"<code>parse_str_config(config)</code>","text":"<p>Parse string config</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>str</code> <p>Yaml cfg as a string to load</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Parsed config</p> Source code in <code>omnigibson/utils/config_utils.py</code> <pre><code>def parse_str_config(config):\n\"\"\"\n    Parse string config\n    Args:\n        config (str): Yaml cfg as a string to load\n    Returns:\n        dict: Parsed config\n    \"\"\"\nreturn yaml.safe_load(config)\n</code></pre>"},{"location":"reference/utils/constants.html","title":"constants","text":"<p>Constant Definitions</p>"},{"location":"reference/utils/constants.html#utils.constants.get_class_name_to_class_id","title":"<code>get_class_name_to_class_id()</code>","text":"<p>Get mapping from semantic class name to class id</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>starting class id for scene objects</p> Source code in <code>omnigibson/utils/constants.py</code> <pre><code>def get_class_name_to_class_id():\n\"\"\"\n    Get mapping from semantic class name to class id\n    Returns:\n        dict: starting class id for scene objects\n    \"\"\"\nexisting_classes = {item.value for item in SemanticClass}\ncategory_txt = os.path.join(gm.DATASET_PATH, \"metadata/categories.txt\")\nclass_name_to_class_id = {\"agent\": SemanticClass.ROBOTS}  # Agents should have the robot semantic class.\nstarting_class_id = 0\nif os.path.isfile(category_txt):\nwith open(category_txt) as f:\nfor line in f.readlines():\nwhile starting_class_id in existing_classes:\nstarting_class_id += 1\nassert starting_class_id &lt; MAX_CLASS_COUNT, \"Class ID overflow: MAX_CLASS_COUNT is {}.\".format(\nMAX_CLASS_COUNT\n)\nclass_name_to_class_id[line.strip()] = starting_class_id\nstarting_class_id += 1\nreturn class_name_to_class_id\n</code></pre>"},{"location":"reference/utils/constants.html#utils.constants.get_collision_group_mask","title":"<code>get_collision_group_mask(groups_to_exclude=[])</code>","text":"<p>Get a collision group mask that has collisions enabled for every group except those in groups_to_exclude.</p> Source code in <code>omnigibson/utils/constants.py</code> <pre><code>def get_collision_group_mask(groups_to_exclude=[]):\n\"\"\"Get a collision group mask that has collisions enabled for every group except those in groups_to_exclude.\"\"\"\ncollision_mask = ALL_COLLISION_GROUPS_MASK\nfor group in groups_to_exclude:\ncollision_mask &amp;= ~(1 &lt;&lt; group)\nreturn collision_mask\n</code></pre>"},{"location":"reference/utils/control_utils.html","title":"control_utils","text":"<p>Set of utilities for helping to execute robot control</p>"},{"location":"reference/utils/control_utils.html#utils.control_utils.IKSolver","title":"<code>IKSolver</code>","text":"<p>Class for thinly wrapping Lula IK solver</p> Source code in <code>omnigibson/utils/control_utils.py</code> <pre><code>class IKSolver:\n\"\"\"\n    Class for thinly wrapping Lula IK solver\n    \"\"\"\ndef __init__(\nself,\nrobot_description_path,\nrobot_urdf_path,\neef_name,\ndefault_joint_pos,\n):\n# Create robot description, kinematics, and config\nself.robot_description = lula.load_robot(robot_description_path, robot_urdf_path)\nself.kinematics = self.robot_description.kinematics()\nself.config = lula.CyclicCoordDescentIkConfig()\nself.eef_name = eef_name\nself.default_joint_pos = default_joint_pos\ndef solve(\nself,\ntarget_pos,\ntarget_quat=None,\ntolerance_pos=0.002,\ntolerance_quat=0.01,\nweight_pos=1.0,\nweight_quat=0.05,\nmax_iterations=150,\ninitial_joint_pos=None,\n):\n\"\"\"\n        Backs out joint positions to achieve desired @target_pos and @target_quat\n        Args:\n            target_pos (3-array): desired (x,y,z) local target cartesian position in robot's base coordinate frame\n            target_quat (4-array or None): If specified, desired (x,y,z,w) local target quaternion orientation in\n            robot's base coordinate frame. If None, IK will be position-only (will override settings such that\n            orientation's tolerance is very high and weight is 0)\n            tolerance_pos (float): Maximum position error (L2-norm) for a successful IK solution\n            tolerance_quat (float): Maximum orientation error (per-axis L2-norm) for a successful IK solution\n            weight_pos (float): Weight for the relative importance of position error during CCD\n            weight_quat (float): Weight for the relative importance of position error during CCD\n            max_iterations (int): Number of iterations used for each cyclic coordinate descent.\n            initial_joint_pos (None or n-array): If specified, will set the initial cspace seed when solving for joint\n                positions. Otherwise, will use self.default_joint_pos\n        Returns:\n            None or n-array: Joint positions for reaching desired target_pos and target_quat, otherwise None if no\n                solution was found\n        \"\"\"\npos = np.array(target_pos, dtype=np.float64).reshape(3, 1)\nrot = np.array(T.quat2mat(np.array([0, 0, 0, 1.0]) if target_quat is None else target_quat), dtype=np.float64)\nik_target_pose = lula.Pose3(lula.Rotation3(rot), pos)\n# Set the cspace seed and tolerance\ninitial_joint_pos = self.default_joint_pos if initial_joint_pos is None else np.array(initial_joint_pos)\nself.config.cspace_seeds = [initial_joint_pos]\nself.config.position_tolerance = tolerance_pos\nself.config.orientation_tolerance = 100.0 if target_quat is None else tolerance_quat\nself.config.position_weight = weight_pos\nself.config.orientation_weight = 0.0 if target_quat is None else weight_quat\nself.config.max_iterations_per_descent = max_iterations\n# Compute target joint positions\nik_results = lula.compute_ik_ccd(self.kinematics, ik_target_pose, self.eef_name, self.config)\nreturn np.array(ik_results.cspace_position)\n</code></pre>"},{"location":"reference/utils/control_utils.html#utils.control_utils.IKSolver.solve","title":"<code>solve(target_pos, target_quat=None, tolerance_pos=0.002, tolerance_quat=0.01, weight_pos=1.0, weight_quat=0.05, max_iterations=150, initial_joint_pos=None)</code>","text":"<p>Backs out joint positions to achieve desired @target_pos and @target_quat</p> <p>Parameters:</p> Name Type Description Default <code>target_pos</code> <code>3-array</code> <p>desired (x,y,z) local target cartesian position in robot's base coordinate frame</p> required <code>target_quat</code> <code>4-array or None</code> <p>If specified, desired (x,y,z,w) local target quaternion orientation in</p> <code>None</code> <code>tolerance_pos</code> <code>float</code> <p>Maximum position error (L2-norm) for a successful IK solution</p> <code>0.002</code> <code>tolerance_quat</code> <code>float</code> <p>Maximum orientation error (per-axis L2-norm) for a successful IK solution</p> <code>0.01</code> <code>weight_pos</code> <code>float</code> <p>Weight for the relative importance of position error during CCD</p> <code>1.0</code> <code>weight_quat</code> <code>float</code> <p>Weight for the relative importance of position error during CCD</p> <code>0.05</code> <code>max_iterations</code> <code>int</code> <p>Number of iterations used for each cyclic coordinate descent.</p> <code>150</code> <code>initial_joint_pos</code> <code>None or n-array</code> <p>If specified, will set the initial cspace seed when solving for joint positions. Otherwise, will use self.default_joint_pos</p> <code>None</code> <p>Returns:</p> Type Description <p>None or n-array: Joint positions for reaching desired target_pos and target_quat, otherwise None if no solution was found</p> Source code in <code>omnigibson/utils/control_utils.py</code> <pre><code>def solve(\nself,\ntarget_pos,\ntarget_quat=None,\ntolerance_pos=0.002,\ntolerance_quat=0.01,\nweight_pos=1.0,\nweight_quat=0.05,\nmax_iterations=150,\ninitial_joint_pos=None,\n):\n\"\"\"\n    Backs out joint positions to achieve desired @target_pos and @target_quat\n    Args:\n        target_pos (3-array): desired (x,y,z) local target cartesian position in robot's base coordinate frame\n        target_quat (4-array or None): If specified, desired (x,y,z,w) local target quaternion orientation in\n        robot's base coordinate frame. If None, IK will be position-only (will override settings such that\n        orientation's tolerance is very high and weight is 0)\n        tolerance_pos (float): Maximum position error (L2-norm) for a successful IK solution\n        tolerance_quat (float): Maximum orientation error (per-axis L2-norm) for a successful IK solution\n        weight_pos (float): Weight for the relative importance of position error during CCD\n        weight_quat (float): Weight for the relative importance of position error during CCD\n        max_iterations (int): Number of iterations used for each cyclic coordinate descent.\n        initial_joint_pos (None or n-array): If specified, will set the initial cspace seed when solving for joint\n            positions. Otherwise, will use self.default_joint_pos\n    Returns:\n        None or n-array: Joint positions for reaching desired target_pos and target_quat, otherwise None if no\n            solution was found\n    \"\"\"\npos = np.array(target_pos, dtype=np.float64).reshape(3, 1)\nrot = np.array(T.quat2mat(np.array([0, 0, 0, 1.0]) if target_quat is None else target_quat), dtype=np.float64)\nik_target_pose = lula.Pose3(lula.Rotation3(rot), pos)\n# Set the cspace seed and tolerance\ninitial_joint_pos = self.default_joint_pos if initial_joint_pos is None else np.array(initial_joint_pos)\nself.config.cspace_seeds = [initial_joint_pos]\nself.config.position_tolerance = tolerance_pos\nself.config.orientation_tolerance = 100.0 if target_quat is None else tolerance_quat\nself.config.position_weight = weight_pos\nself.config.orientation_weight = 0.0 if target_quat is None else weight_quat\nself.config.max_iterations_per_descent = max_iterations\n# Compute target joint positions\nik_results = lula.compute_ik_ccd(self.kinematics, ik_target_pose, self.eef_name, self.config)\nreturn np.array(ik_results.cspace_position)\n</code></pre>"},{"location":"reference/utils/deprecated_utils.html","title":"deprecated_utils","text":"<p>A set of utility functions slated to be deprecated once Omniverse bugs are fixed</p>"},{"location":"reference/utils/deprecated_utils.html#utils.deprecated_utils.Core","title":"<code>Core</code>","text":"<p>         Bases: <code>OmniCore</code></p> <p>Subclass that overrides a specific function within Omni's Core class to fix a bug</p> Source code in <code>omnigibson/utils/deprecated_utils.py</code> <pre><code>class Core(OmniCore):\n\"\"\"\n    Subclass that overrides a specific function within Omni's Core class to fix a bug\n    \"\"\"\ndef __init__(self, popup_callback: Callable[[str], None], particle_system_name: str):\nself._popup_callback = popup_callback\nself.utils = Utils()    # TODO: THIS IS THE ONLY LINE THAT WE CHANGE! ONCE FIXED, REMOVE THIS\nself.context = ou.get_context()\nself.stage = self.context.get_stage()\nself.selection = self.context.get_selection()\nself.particle_system_name = particle_system_name\nself.sub_stage_update = self.context.get_stage_event_stream().create_subscription_to_pop(self.on_stage_update)\nself.on_stage_update()\ndef get_compute_graph(self, selected_paths, create_new_graph=True, created_paths=None):\n\"\"\"\n        Returns the first ComputeGraph found in selected_paths.\n        If no graph is found and create_new_graph is true, a new graph will be created and its\n        path appended to created_paths (if provided).\n        \"\"\"\ngraph = None\ngraph_paths = [path for path in selected_paths\nif self.stage.GetPrimAtPath(path).GetTypeName() == \"ComputeGraph\"]\nif len(graph_paths) &gt; 0:\ngraph = ogc.get_graph_by_path(graph_paths[0])\nif len(graph_paths) &gt; 1:\ncarb.log_warn(f\"Multiple ComputeGraph prims selected. Only the first will be used: {graph.get_path_to_graph()}\")\nelif create_new_graph:\n# If no graph was found in the selected prims, we'll make a new graph.\ngraph_path = Sdf.Path(f\"/OmniGraph/{self.particle_system_name}\").MakeAbsolutePath(Sdf.Path.absoluteRootPath)\ngraph_path = ou.get_stage_next_free_path(self.stage, graph_path, True)\n# prim = self.stage.GetDefaultPrim()\n# path = str(prim.GetPath()) if prim else \"\"\nself.stage.DefinePrim(\"/OmniGraph\", \"Scope\")\ncontainer_graphs = ogc.get_global_container_graphs()\n# FIXME: container_graphs[0] should be the simulation orchestration graph, but this may change in the future.\ncontainer_graph = container_graphs[0]\nresult, wrapper_node = ogc.cmds.CreateGraphAsNode(\ngraph=container_graph,\nnode_name=Sdf.Path(graph_path).name,\ngraph_path=graph_path,\nevaluator_name=\"push\",\nis_global_graph=True,\nbacked_by_usd=True,\nfc_backing_type=ogc.GraphBackingType.GRAPH_BACKING_TYPE_FLATCACHE_SHARED,\npipeline_stage=ogc.GraphPipelineStage.GRAPH_PIPELINE_STAGE_SIMULATION\n)\ngraph = wrapper_node.get_wrapped_graph()\nif created_paths is not None:\ncreated_paths.append(graph.get_path_to_graph())\ncarb.log_info(f\"No ComputeGraph selected. A new graph has been created at {graph.get_path_to_graph()}\")\nreturn graph\n</code></pre>"},{"location":"reference/utils/deprecated_utils.html#utils.deprecated_utils.Core.get_compute_graph","title":"<code>get_compute_graph(selected_paths, create_new_graph=True, created_paths=None)</code>","text":"<p>Returns the first ComputeGraph found in selected_paths. If no graph is found and create_new_graph is true, a new graph will be created and its path appended to created_paths (if provided).</p> Source code in <code>omnigibson/utils/deprecated_utils.py</code> <pre><code>def get_compute_graph(self, selected_paths, create_new_graph=True, created_paths=None):\n\"\"\"\n    Returns the first ComputeGraph found in selected_paths.\n    If no graph is found and create_new_graph is true, a new graph will be created and its\n    path appended to created_paths (if provided).\n    \"\"\"\ngraph = None\ngraph_paths = [path for path in selected_paths\nif self.stage.GetPrimAtPath(path).GetTypeName() == \"ComputeGraph\"]\nif len(graph_paths) &gt; 0:\ngraph = ogc.get_graph_by_path(graph_paths[0])\nif len(graph_paths) &gt; 1:\ncarb.log_warn(f\"Multiple ComputeGraph prims selected. Only the first will be used: {graph.get_path_to_graph()}\")\nelif create_new_graph:\n# If no graph was found in the selected prims, we'll make a new graph.\ngraph_path = Sdf.Path(f\"/OmniGraph/{self.particle_system_name}\").MakeAbsolutePath(Sdf.Path.absoluteRootPath)\ngraph_path = ou.get_stage_next_free_path(self.stage, graph_path, True)\n# prim = self.stage.GetDefaultPrim()\n# path = str(prim.GetPath()) if prim else \"\"\nself.stage.DefinePrim(\"/OmniGraph\", \"Scope\")\ncontainer_graphs = ogc.get_global_container_graphs()\n# FIXME: container_graphs[0] should be the simulation orchestration graph, but this may change in the future.\ncontainer_graph = container_graphs[0]\nresult, wrapper_node = ogc.cmds.CreateGraphAsNode(\ngraph=container_graph,\nnode_name=Sdf.Path(graph_path).name,\ngraph_path=graph_path,\nevaluator_name=\"push\",\nis_global_graph=True,\nbacked_by_usd=True,\nfc_backing_type=ogc.GraphBackingType.GRAPH_BACKING_TYPE_FLATCACHE_SHARED,\npipeline_stage=ogc.GraphPipelineStage.GRAPH_PIPELINE_STAGE_SIMULATION\n)\ngraph = wrapper_node.get_wrapped_graph()\nif created_paths is not None:\ncreated_paths.append(graph.get_path_to_graph())\ncarb.log_info(f\"No ComputeGraph selected. A new graph has been created at {graph.get_path_to_graph()}\")\nreturn graph\n</code></pre>"},{"location":"reference/utils/deprecated_utils.html#utils.deprecated_utils.Utils","title":"<code>Utils</code>","text":"<p>         Bases: <code>OmniUtils</code></p> <p>Subclass that overrides a specific function within Omni's Utils class to fix a bug</p> Source code in <code>omnigibson/utils/deprecated_utils.py</code> <pre><code>class Utils(OmniUtils):\n\"\"\"\n    Subclass that overrides a specific function within Omni's Utils class to fix a bug\n    \"\"\"\ndef create_material(self, name):\n# TODO: THIS IS THE ONLY LINE WE CHANGE! \"/\" SHOULD BE \"\"\nmaterial_path = \"\"\ndefault_prim = self.stage.GetDefaultPrim()\nif default_prim:\nmaterial_path = default_prim.GetPath().pathString\nif not self.stage.GetPrimAtPath(material_path + \"/Looks\"):\nself.stage.DefinePrim(material_path + \"/Looks\", \"Scope\")\nmaterial_path += \"/Looks/\" + name\nmaterial_path = ou.get_stage_next_free_path(\nself.stage, material_path, False\n)\nmaterial = UsdShade.Material.Define(self.stage, material_path)\nshader_path = material_path + \"/Shader\"\nshader = UsdShade.Shader.Define(self.stage, shader_path)\n# Update Neuraylib MDL search paths\nimport omni.particle.system.core as core\ncore.update_mdl_search_paths()\nshader.SetSourceAsset(name + \".mdl\", \"mdl\")\nshader.SetSourceAssetSubIdentifier(name, \"mdl\")\nshader.GetImplementationSourceAttr().Set(UsdShade.Tokens.sourceAsset)\nshader.CreateOutput(\"out\", Sdf.ValueTypeNames.Token)\nmaterial.CreateSurfaceOutput().ConnectToSource(shader, \"out\")\nreturn [material_path]\n</code></pre>"},{"location":"reference/utils/geometry_utils.html","title":"geometry_utils","text":"<p>A set of helper utility functions for dealing with 3D geometry</p>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_cone","title":"<code>check_points_in_cone(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a cone with specified size @size.</p> <p>NOTE: Assumes the cone and positions are expressed in the same coordinate frame such that the cone's height is aligned with the z-axis</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>2-array</code> <p>(radius, height) dimensions of the cone, specified in its local frame</p> required <code>pos</code> <code>3-array</code> <p>(x,y,z) local location of the cone</p> required <code>quat</code> <code>4-array</code> <p>(x,y,z,w) local orientation of the cone</p> required <code>scale</code> <code>3-array</code> <p>(x,y,z) local scale of the cone, specified in its local frame</p> required <code>particle_positions</code> <code>N, 3) array</code> <p>positions to check for whether it is in the cone</p> required <p>Returns:</p> Type Description <p>(N,) array: boolean numpy array specifying whether each point lies in the cone.</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def check_points_in_cone(size, pos, quat, scale, particle_positions):\n\"\"\"\n    Checks which points are within a cone with specified size @size.\n    NOTE: Assumes the cone and positions are\n    expressed in the same coordinate frame such that the cone's height is aligned with the z-axis\n    Args:\n        size (2-array): (radius, height) dimensions of the cone, specified in its local frame\n        pos (3-array): (x,y,z) local location of the cone\n        quat (4-array): (x,y,z,w) local orientation of the cone\n        scale (3-array): (x,y,z) local scale of the cone, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the cone\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the cone.\n    \"\"\"\nparticle_positions = get_particle_positions_in_frame(\npos=pos,\nquat=quat,\nscale=scale,\nparticle_positions=particle_positions,\n)\nradius, height = size\nin_height = (-height / 2.0 &lt; particle_positions[:, -1]) &amp; (particle_positions[:, -1] &lt; height / 2.0)\nin_radius = np.linalg.norm(particle_positions[:, :-1], axis=-1) &lt; \\\n                (radius * (1 - (particle_positions[:, -1] + height / 2.0) / height ))\nreturn in_height &amp; in_radius\n</code></pre>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_convex_hull_mesh","title":"<code>check_points_in_convex_hull_mesh(mesh_face_centroids, mesh_face_normals, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a sphere with specified size @size.</p> <p>NOTE: Assumes the mesh and positions are expressed in the same coordinate frame</p> <p>Parameters:</p> Name Type Description Default <code>mesh_face_centroids</code> <code>D, 3</code> <p>(x,y,z) location of the centroid of each mesh face, expressed in its local frame</p> required <code>mesh_face_normals</code> <code>D, 3</code> <p>(x,y,z) normalized direction vector of each mesh face, expressed in its local frame</p> required <code>pos</code> <code>3-array</code> <p>(x,y,z) local location of the mesh</p> required <code>quat</code> <code>4-array</code> <p>(x,y,z,w) local orientation of the mesh</p> required <code>scale</code> <code>3-array</code> <p>(x,y,z) local scale of the cube, specified in its local frame</p> required <code>particle_positions</code> <code>N, 3) array</code> <p>positions to check for whether it is in the mesh</p> required <p>Returns:</p> Type Description <p>(N,) array: boolean numpy array specifying whether each point lies in the mesh</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def check_points_in_convex_hull_mesh(mesh_face_centroids, mesh_face_normals, pos, quat, scale, particle_positions):\n\"\"\"\n    Checks which points are within a sphere with specified size @size.\n    NOTE: Assumes the mesh and positions are expressed in the same coordinate frame\n    Args:\n        mesh_face_centroids (D, 3): (x,y,z) location of the centroid of each mesh face, expressed in its local frame\n        mesh_face_normals (D, 3): (x,y,z) normalized direction vector of each mesh face, expressed in its local frame\n        pos (3-array): (x,y,z) local location of the mesh\n        quat (4-array): (x,y,z,w) local orientation of the mesh\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the mesh\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the mesh\n    \"\"\"\nparticle_positions = get_particle_positions_in_frame(\npos=pos,\nquat=quat,\nscale=scale,\nparticle_positions=particle_positions,\n)\n# For every mesh point / normal and particle position pair, we check whether it is \"inside\" (i.e.: the point lies\n# BEHIND the normal plane -- this is easily done by taking the dot product with the vector from the point to the\n# particle position with the normal, and validating that the value is &lt; 0)\nD, _ = mesh_face_centroids.shape\nN, _ = particle_positions.shape\nmesh_points = np.tile(mesh_face_centroids.reshape(1, D, 3), (N, 1, 1))\nmesh_normals = np.tile(mesh_face_normals.reshape(1, D, 3), (N, 1, 1))\nparticle_positions = np.tile(particle_positions.reshape(N, 1, 3), (1, D, 1))\n# All arrays are now (N, D, 3) shape -- efficient for batching\nin_range = ((particle_positions - mesh_points) * mesh_normals).sum(axis=-1) &lt; 0         # shape (N, D)\n# All D normals must be satisfied for a single point to be considered inside the hull\nin_range = in_range.sum(axis=-1) == D\nreturn in_range\n</code></pre>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_cube","title":"<code>check_points_in_cube(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a cube with specified size @size.</p> <p>NOTE: Assumes the cube and positions are expressed in the same coordinate frame such that the cube's dimensions are axis-aligned with (x,y,z)</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>float</code> <p>length of each side of the cube, specified in its local frame</p> required <code>pos</code> <code>3-array</code> <p>(x,y,z) local location of the cube</p> required <code>quat</code> <code>4-array</code> <p>(x,y,z,w) local orientation of the cube</p> required <code>scale</code> <code>3-array</code> <p>(x,y,z) local scale of the cube, specified in its local frame</p> required <code>particle_positions</code> <code>N, 3) array</code> <p>positions to check for whether it is in the cube</p> required <p>Returns:</p> Type Description <p>(N,) array: boolean numpy array specifying whether each point lies in the cube.</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def check_points_in_cube(size, pos, quat, scale, particle_positions):\n\"\"\"\n    Checks which points are within a cube with specified size @size.\n    NOTE: Assumes the cube and positions are expressed\n    in the same coordinate frame such that the cube's dimensions are axis-aligned with (x,y,z)\n    Args:\n        size float: length of each side of the cube, specified in its local frame\n        pos (3-array): (x,y,z) local location of the cube\n        quat (4-array): (x,y,z,w) local orientation of the cube\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the cube\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the cube.\n    \"\"\"\nparticle_positions = get_particle_positions_in_frame(\npos=pos,\nquat=quat,\nscale=scale,\nparticle_positions=particle_positions,\n)\nreturn ((-size / 2.0 &lt; particle_positions) &amp; (particle_positions &lt; size / 2.0)).sum(axis=-1) == 3\n</code></pre>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_cylinder","title":"<code>check_points_in_cylinder(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a cylinder with specified size @size.</p> <p>NOTE: Assumes the cylinder and positions are expressed in the same coordinate frame such that the cylinder's height is aligned with the z-axis</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>2-array</code> <p>(radius, height) dimensions of the cylinder, specified in its local frame</p> required <code>pos</code> <code>3-array</code> <p>(x,y,z) local location of the cylinder</p> required <code>quat</code> <code>4-array</code> <p>(x,y,z,w) local orientation of the cylinder</p> required <code>scale</code> <code>3-array</code> <p>(x,y,z) local scale of the cube, specified in its local frame</p> required <code>particle_positions</code> <code>N, 3) array</code> <p>positions to check for whether it is in the cylinder</p> required <p>Returns:</p> Type Description <p>(N,) array: boolean numpy array specifying whether each point lies in the cylinder.</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def check_points_in_cylinder(size, pos, quat, scale, particle_positions):\n\"\"\"\n    Checks which points are within a cylinder with specified size @size.\n    NOTE: Assumes the cylinder and positions are\n    expressed in the same coordinate frame such that the cylinder's height is aligned with the z-axis\n    Args:\n        size (2-array): (radius, height) dimensions of the cylinder, specified in its local frame\n        pos (3-array): (x,y,z) local location of the cylinder\n        quat (4-array): (x,y,z,w) local orientation of the cylinder\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the cylinder\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the cylinder.\n    \"\"\"\nparticle_positions = get_particle_positions_in_frame(\npos=pos,\nquat=quat,\nscale=scale,\nparticle_positions=particle_positions,\n)\nradius, height = size\nin_height = (-height / 2.0 &lt; particle_positions[:, -1]) &amp; (particle_positions[:, -1] &lt; height / 2.0)\nin_radius = np.linalg.norm(particle_positions[:, :-1], axis=-1) &lt; radius\nreturn in_height &amp; in_radius\n</code></pre>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_sphere","title":"<code>check_points_in_sphere(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a sphere with specified size @size.</p> <p>NOTE: Assumes the sphere and positions are expressed in the same coordinate frame</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>float</code> <p>radius dimensions of the sphere</p> required <code>pos</code> <code>3-array</code> <p>(x,y,z) local location of the sphere</p> required <code>quat</code> <code>4-array</code> <p>(x,y,z,w) local orientation of the sphere</p> required <code>scale</code> <code>3-array</code> <p>(x,y,z) local scale of the cube, specified in its local frame</p> required <code>particle_positions</code> <code>N, 3) array</code> <p>positions to check for whether it is in the sphere</p> required <p>Returns:</p> Type Description <p>(N,) array: boolean numpy array specifying whether each point lies in the sphere</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def check_points_in_sphere(size, pos, quat, scale, particle_positions):\n\"\"\"\n    Checks which points are within a sphere with specified size @size.\n    NOTE: Assumes the sphere and positions are expressed in the same coordinate frame\n    Args:\n        size (float): radius dimensions of the sphere\n        pos (3-array): (x,y,z) local location of the sphere\n        quat (4-array): (x,y,z,w) local orientation of the sphere\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the sphere\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the sphere\n    \"\"\"\nparticle_positions = get_particle_positions_in_frame(\npos=pos,\nquat=quat,\nscale=scale,\nparticle_positions=particle_positions,\n)\nreturn np.linalg.norm(particle_positions, axis=-1) &lt; size\n</code></pre>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.generate_points_in_volume_checker_function","title":"<code>generate_points_in_volume_checker_function(obj, volume_link, use_visual_meshes=True, mesh_name_prefixes=None)</code>","text":"<p>Generates a function for quickly checking which of a group of points are contained within any container volumes.</p> Four volume types are supported <p>\"Cylinder\" - Cylinder volume \"Cube\" - Cube volume \"Sphere\" - Sphere volume \"Mesh\" - Convex hull volume</p> <p>@volume_link should have any number of nested, visual-only meshes of types {Sphere, Cylinder, Cube, Mesh} with naming prefix \"container[...]\"</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>EntityPrim</code> <p>Object which contains @volume_link as one of its links</p> required <code>volume_link</code> <code>RigidPrim</code> <p>Link to use to grab container volumes composing the values for checking the points</p> required <code>use_visual_meshes</code> <code>bool</code> <p>Whether to use @volume_link's visual or collision meshes to generate points fcn</p> <code>True</code> <code>mesh_name_prefixes</code> <code>None or str</code> <p>If specified, specifies the substring that must exist in @volume_link's mesh names in order for that mesh to be included in the volume checker function. If None, no filtering will be used.</p> <code>None</code> <p>Returns:</p> Type Description <p>2-tuple: - function: Function with signature:</p> <pre><code>in_range = check_in_volumes(particle_positions)\n</code></pre> <p>where @in_range is a N-array boolean numpy array, (True where the particle is in the volume), and @particle_positions is a (N, 3) array specifying the particle positions in global coordinates</p> <ul> <li> <p>function: Function for grabbing real-time global scale volume of the container. Signature:</p> <p>vol = total_volume()</p> </li> </ul> <p>where @vol is the total volume being checked (expressed in global scale) aggregated across all container sub-volumes</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def generate_points_in_volume_checker_function(obj, volume_link, use_visual_meshes=True, mesh_name_prefixes=None):\n\"\"\"\n    Generates a function for quickly checking which of a group of points are contained within any container volumes.\n    Four volume types are supported:\n        \"Cylinder\" - Cylinder volume\n        \"Cube\" - Cube volume\n        \"Sphere\" - Sphere volume\n        \"Mesh\" - Convex hull volume\n    @volume_link should have any number of nested, visual-only meshes of types {Sphere, Cylinder, Cube, Mesh} with\n    naming prefix \"container[...]\"\n    Args:\n        obj (EntityPrim): Object which contains @volume_link as one of its links\n        volume_link (RigidPrim): Link to use to grab container volumes composing the values for checking the points\n        use_visual_meshes (bool): Whether to use @volume_link's visual or collision meshes to generate points fcn\n        mesh_name_prefixes (None or str): If specified, specifies the substring that must exist in @volume_link's\n            mesh names in order for that mesh to be included in the volume checker function. If None, no filtering\n            will be used.\n    Returns:\n        2-tuple:\n            - function: Function with signature:\n                in_range = check_in_volumes(particle_positions)\n            where @in_range is a N-array boolean numpy array, (True where the particle is in the volume), and\n            @particle_positions is a (N, 3) array specifying the particle positions in global coordinates\n            - function: Function for grabbing real-time global scale volume of the container. Signature:\n                vol = total_volume()\n            where @vol is the total volume being checked (expressed in global scale) aggregated across\n            all container sub-volumes\n    \"\"\"\n# If the object doesn't uniform scale, we make sure the volume link has no relative orientation w.r.t to\n# the object (root link) frame\n# TODO: Can we remove this restriction in the future? The current paradigm of how scale operates makes this difficult\nif (obj.scale.max() - obj.scale.min()) &gt; 1e-3:\nvolume_link_quat = volume_link.get_orientation()\nobject_quat = obj.get_orientation()\nquat_distance = T.quat_distance(volume_link_quat, object_quat)\nassert np.isclose(quat_distance[3], 1, atol=1e-3), \\\n            f\"Volume link must have no relative orientation w.r.t the root link! (i.e.: quat distance [0, 0, 0, 1])! \" \\\n            f\"Got quat distance: {quat_distance}\"\n# Iterate through all visual meshes and keep track of any that are prefixed with container\ncontainer_meshes = []\nmeshes = volume_link.visual_meshes if use_visual_meshes else volume_link.collision_meshes\nfor container_mesh_name, container_mesh in meshes.items():\nif mesh_name_prefixes is None or mesh_name_prefixes in container_mesh_name:\ncontainer_meshes.append(container_mesh.prim)\n# Programmatically define the volume checker functions based on each container found\nvolume_checker_fcns = []\nvolume_calc_fcns = []\nfor sub_container_mesh in container_meshes:\nmesh_type = sub_container_mesh.GetTypeName()\nif mesh_type == \"Mesh\":\nfcn, vol_fcn = _generate_convex_hull_volume_checker_functions(convex_hull_mesh=sub_container_mesh)\nelif mesh_type == \"Sphere\":\nfcn = lambda mesh, particle_positions: check_points_in_sphere(\nsize=mesh.GetAttribute(\"radius\").Get(),\npos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\nquat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\nscale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\nparticle_positions=particle_positions,\n)\nvol_fcn = lambda mesh: 4 / 3 * np.pi * (mesh.GetAttribute(\"radius\").Get() ** 3)\nelif mesh_type == \"Cylinder\":\nfcn = lambda mesh, particle_positions: check_points_in_cylinder(\nsize=[mesh.GetAttribute(\"radius\").Get(), mesh.GetAttribute(\"height\").Get()],\npos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\nquat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\nscale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\nparticle_positions=particle_positions,\n)\nvol_fcn = lambda mesh: np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get()\nelif mesh_type == \"Cone\":\nfcn = lambda mesh, particle_positions: check_points_in_cone(\nsize=[mesh.GetAttribute(\"radius\").Get(), mesh.GetAttribute(\"height\").Get()],\npos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\nquat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\nscale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\nparticle_positions=particle_positions,\n)\nvol_fcn = lambda mesh: np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get() / 3.0\nelif mesh_type == \"Cube\":\nfcn = lambda mesh, particle_positions: check_points_in_cube(\nsize=mesh.GetAttribute(\"size\").Get(),\npos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\nquat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\nscale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\nparticle_positions=particle_positions,\n)\nvol_fcn = lambda mesh: mesh.GetAttribute(\"size\").Get() ** 3\nelse:\nraise ValueError(f\"Cannot create volume checker function for mesh of type: {mesh_type}\")\nvolume_checker_fcns.append(fcn)\nvolume_calc_fcns.append(vol_fcn)\n# Define the actual volume checker function\ndef check_points_in_volumes(particle_positions):\n# Algo\n# 1. Particles in global frame --&gt; particles in volume link frame (including scaling)\n# 2. For each volume checker function, apply volume checking\n# 3. Aggregate across all functions with OR condition (any volume satisfied for that point)\n######\nn_particles = len(particle_positions)\n# Get pose of origin (global frame) in frame of volume link\n# NOTE: This assumes there is no relative scaling between obj and volume link\nvolume_link_pos, volume_link_quat = volume_link.get_position_orientation()\nparticle_positions = get_particle_positions_in_frame(\npos=volume_link_pos,\nquat=volume_link_quat,\nscale=obj.scale,\nparticle_positions=particle_positions,\n)\nin_volumes = np.zeros(n_particles).astype(bool)\nfor checker_fcn, mesh in zip(volume_checker_fcns, container_meshes):\nin_volumes |= checker_fcn(mesh, particle_positions)\nreturn in_volumes\n# Define the actual volume calculator function\ndef calculate_volume():\n# Aggregate values across all subvolumes\n# NOTE: Assumes all volumes are strictly disjointed (becuase we sum over all subvolumes to calculate\n# total raw volume)\n# TODO: Is there a way we can explicitly check if disjointed?\nvols = [calc_fcn(mesh) * np.product(mesh.GetAttribute(\"xformOp:scale\").Get())\nfor calc_fcn, mesh in zip(volume_calc_fcns, container_meshes)]\n# Aggregate over all volumes and scale by the link's global scale\nreturn np.sum(vols) * np.product(volume_link.get_world_scale())\nreturn check_points_in_volumes, calculate_volume\n</code></pre>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.get_particle_positions_from_frame","title":"<code>get_particle_positions_from_frame(pos, quat, scale, particle_positions)</code>","text":"<p>Transforms particle positions @positions from the frame specified by @pos and @quat with new scale @scale.</p> <p>This is similar to @get_particle_positions_in_frame, but does the reverse operation, inverting @pos and @quat</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>3-array</code> <p>(x,y,z) pos of the local frame</p> required <code>quat</code> <code>4-array</code> <p>(x,y,z,w) quaternion orientation of the local frame</p> required <code>scale</code> <code>3-array</code> <p>(x,y,z) local scale of the local frame</p> required <code>particle_positions</code> <code>N, 3) array</code> <p>positions</p> required <p>Returns:</p> Type Description <p>(N,) array: updated particle positions in the parent coordinate frame</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def get_particle_positions_from_frame(pos, quat, scale, particle_positions):\n\"\"\"\n    Transforms particle positions @positions from the frame specified by @pos and @quat with new scale @scale.\n    This is similar to @get_particle_positions_in_frame, but does the reverse operation, inverting @pos and @quat\n    Args:\n        pos (3-array): (x,y,z) pos of the local frame\n        quat (4-array): (x,y,z,w) quaternion orientation of the local frame\n        scale (3-array): (x,y,z) local scale of the local frame\n        particle_positions ((N, 3) array): positions\n    Returns:\n        (N,) array: updated particle positions in the parent coordinate frame\n    \"\"\"\n# Scale by the new scale\nparticle_positions = particle_positions * scale.reshape(1, 3)\n# Get pose of origin (global frame) in new_frame\norigin_in_new_frame = T.pose2mat((pos, quat))\n# Batch the transforms to get all particle points in the local link frame\npositions_tensor = np.tile(np.eye(4).reshape(1, 4, 4), (len(particle_positions), 1, 1))  # (N, 4, 4)\n# Scale by the new scale#\npositions_tensor[:, :3, 3] = particle_positions\nreturn (origin_in_new_frame @ positions_tensor)[:, :3, 3]  # (N, 3)\n</code></pre>"},{"location":"reference/utils/geometry_utils.html#utils.geometry_utils.get_particle_positions_in_frame","title":"<code>get_particle_positions_in_frame(pos, quat, scale, particle_positions)</code>","text":"<p>Transforms particle positions @positions into the frame specified by @pos and @quat with new scale @scale, where @pos and @quat are assumed to be specified in the same coordinate frame that @particle_positions is specified</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>3-array</code> <p>(x,y,z) pos of the new frame</p> required <code>quat</code> <code>4-array</code> <p>(x,y,z,w) quaternion orientation of the new frame</p> required <code>scale</code> <code>3-array</code> <p>(x,y,z) local scale of the new frame</p> required <code>particle_positions</code> <code>N, 3) array</code> <p>positions</p> required <p>Returns:</p> Type Description <p>(N,) array: updated particle positions in the new coordinate frame</p> Source code in <code>omnigibson/utils/geometry_utils.py</code> <pre><code>def get_particle_positions_in_frame(pos, quat, scale, particle_positions):\n\"\"\"\n    Transforms particle positions @positions into the frame specified by @pos and @quat with new scale @scale,\n    where @pos and @quat are assumed to be specified in the same coordinate frame that @particle_positions is specified\n    Args:\n        pos (3-array): (x,y,z) pos of the new frame\n        quat (4-array): (x,y,z,w) quaternion orientation of the new frame\n        scale (3-array): (x,y,z) local scale of the new frame\n        particle_positions ((N, 3) array): positions\n    Returns:\n        (N,) array: updated particle positions in the new coordinate frame\n    \"\"\"\n# Get pose of origin (global frame) in new_frame\norigin_in_new_frame = T.pose_inv(T.pose2mat((pos, quat)))\n# Batch the transforms to get all particle points in the local link frame\npositions_tensor = np.tile(np.eye(4).reshape(1, 4, 4), (len(particle_positions), 1, 1))  # (N, 4, 4)\n# Scale by the new scale#\npositions_tensor[:, :3, 3] = particle_positions\nparticle_positions = (origin_in_new_frame @ positions_tensor)[:, :3, 3]  # (N, 3)\n# Scale by the new scale\nreturn particle_positions / scale.reshape(1, 3)\n</code></pre>"},{"location":"reference/utils/git_utils.html","title":"git_utils","text":""},{"location":"reference/utils/gym_utils.html","title":"gym_utils","text":""},{"location":"reference/utils/gym_utils.html#utils.gym_utils.GymObservable","title":"<code>GymObservable</code>","text":"<p>Simple class interface for observable objects. These objects should implement a way to grab observations, (get_obs()), and should define an observation space that is created when load_observation_space() is called</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>dict, does nothing, used to sink any extraneous arguments during initialization</p> <code>{}</code> Source code in <code>omnigibson/utils/gym_utils.py</code> <pre><code>class GymObservable(metaclass=ABCMeta):\n\"\"\"\n    Simple class interface for observable objects. These objects should implement a way to grab observations,\n    (get_obs()), and should define an observation space that is created when load_observation_space() is called\n    Args:\n        kwargs: dict, does nothing, used to sink any extraneous arguments during initialization\n    \"\"\"\ndef __init__(self, *args, **kwargs):\n# Initialize variables that we will fill in later\nself.observation_space = None\n# Call any super methods\nsuper().__init__(*args, **kwargs)\n@abstractmethod\ndef get_obs(self, **kwargs):\n\"\"\"\n        Get observations for the object. Note that the shape / nested structure should match that\n        of @self.observation_space!\n        Args:\n            kwargs (dict): Any keyword args necessary for grabbing observations\n        Returns:\n            dict: Keyword-mapped observations mapping observation names to nested observations\n        \"\"\"\nraise NotImplementedError()\n@staticmethod\ndef _build_obs_box_space(shape, low, high, dtype=np.float32):\n\"\"\"\n        Helper function that builds individual observation box spaces.\n        Args:\n            shape (n-array): Shape of the space\n            low (float): Lower bound of the space\n            high (float): Upper bound of the space\n        Returns:\n            gym.spaces.Box: Generated gym box observation space\n        \"\"\"\nreturn gym.spaces.Box(low=low, high=high, shape=shape, dtype=dtype)\n@abstractmethod\ndef _load_observation_space(self):\n\"\"\"\n        Create the observation space for this object. Should be implemented by subclass\n        Returns:\n            dict: Keyword-mapped observation space for this object mapping observation name to observation space\n        \"\"\"\nraise NotImplementedError()\ndef load_observation_space(self):\n\"\"\"\n        Load the observation space internally, and also return this value\n        Returns:\n            gym.spaces.Dict: Loaded observation space for this object\n        \"\"\"\n# Load the observation space and convert it into a gym-compatible dictionary\nself.observation_space = gym.spaces.Dict(self._load_observation_space())\nlog.debug(f\"Loaded obs space dictionary for: {self.__class__.__name__}\")\nreturn self.observation_space\n</code></pre>"},{"location":"reference/utils/gym_utils.html#utils.gym_utils.GymObservable.get_obs","title":"<code>get_obs(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Get observations for the object. Note that the shape / nested structure should match that of @self.observation_space!</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>Any keyword args necessary for grabbing observations</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped observations mapping observation names to nested observations</p> Source code in <code>omnigibson/utils/gym_utils.py</code> <pre><code>@abstractmethod\ndef get_obs(self, **kwargs):\n\"\"\"\n    Get observations for the object. Note that the shape / nested structure should match that\n    of @self.observation_space!\n    Args:\n        kwargs (dict): Any keyword args necessary for grabbing observations\n    Returns:\n        dict: Keyword-mapped observations mapping observation names to nested observations\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/utils/gym_utils.html#utils.gym_utils.GymObservable.load_observation_space","title":"<code>load_observation_space()</code>","text":"<p>Load the observation space internally, and also return this value</p> <p>Returns:</p> Type Description <p>gym.spaces.Dict: Loaded observation space for this object</p> Source code in <code>omnigibson/utils/gym_utils.py</code> <pre><code>def load_observation_space(self):\n\"\"\"\n    Load the observation space internally, and also return this value\n    Returns:\n        gym.spaces.Dict: Loaded observation space for this object\n    \"\"\"\n# Load the observation space and convert it into a gym-compatible dictionary\nself.observation_space = gym.spaces.Dict(self._load_observation_space())\nlog.debug(f\"Loaded obs space dictionary for: {self.__class__.__name__}\")\nreturn self.observation_space\n</code></pre>"},{"location":"reference/utils/gym_utils.html#utils.gym_utils.recursively_generate_flat_dict","title":"<code>recursively_generate_flat_dict(dic, prefix=None)</code>","text":"<p>Helper function to recursively iterate through dictionary / gym.spaces.Dict @dic and flatten any nested elements, such that the result is a flat dictionary mapping keys to values</p> <p>Parameters:</p> Name Type Description Default <code>dic</code> <code>dict or gym.spaces.Dict</code> <p>(Potentially nested) dictionary to convert into a flattened dictionary</p> required <code>prefix</code> <code>None or str</code> <p>Prefix to append to the beginning of all strings in the flattened dictionary. None results in no prefix being applied</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Flattened version of @dic</p> Source code in <code>omnigibson/utils/gym_utils.py</code> <pre><code>def recursively_generate_flat_dict(dic, prefix=None):\n\"\"\"\n    Helper function to recursively iterate through dictionary / gym.spaces.Dict @dic and flatten any nested elements,\n    such that the result is a flat dictionary mapping keys to values\n    Args:\n        dic (dict or gym.spaces.Dict): (Potentially nested) dictionary to convert into a flattened dictionary\n        prefix (None or str): Prefix to append to the beginning of all strings in the flattened dictionary. None results\n            in no prefix being applied\n    Returns:\n        dict: Flattened version of @dic\n    \"\"\"\nout = dict()\nprefix = \"\" if prefix is None else f\"{prefix}::\"\nfor k, v in dic.items():\nif isinstance(v, gym.spaces.Dict) or isinstance(v, dict):\nout.update(recursively_generate_flat_dict(dic=v, prefix=f\"{prefix}{k}\"))\nelif isinstance(v, gym.spaces.Tuple) or isinstance(v, tuple):\nfor i, vv in enumerate(v):\n# Assume no dicts are nested within tuples\nout[f\"{prefix}{k}::{i}\"] = vv\nelse:\n# Add to out dict\nout[f\"{prefix}{k}\"] = v\nreturn out\n</code></pre>"},{"location":"reference/utils/object_state_utils.html","title":"object_state_utils","text":""},{"location":"reference/utils/object_state_utils.html#utils.object_state_utils.calculate_projection_area_and_diagonal","title":"<code>calculate_projection_area_and_diagonal(obj, dims)</code>","text":"<p>Calculate the projection area and the diagonal length when projecting to the plane defined by the input dims E.g. if dims is [0, 1], the points will be projected onto the x-y plane.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DatasetObject</code> <p>Must be PrimType.CLOTH</p> required <code>dims</code> <code>2-array</code> <p>Global axes to project area onto. Options are {0, 1, 2}. E.g. if dims is [0, 1], project onto the x-y plane.</p> required <p>Returns:</p> Name Type Description <code>area</code> <code>float</code> <p>area of the convex hull of the projected points</p> <code>diagonal</code> <code>float</code> <p>diagonal of the convex hull of the projected points</p> Source code in <code>omnigibson/utils/object_state_utils.py</code> <pre><code>def calculate_projection_area_and_diagonal(obj, dims):\n\"\"\"\n    Calculate the projection area and the diagonal length when projecting to the plane defined by the input dims\n    E.g. if dims is [0, 1], the points will be projected onto the x-y plane.\n    Args:\n        obj (DatasetObject): Must be PrimType.CLOTH\n        dims (2-array): Global axes to project area onto. Options are {0, 1, 2}.\n            E.g. if dims is [0, 1], project onto the x-y plane.\n    Returns:\n        area (float): area of the convex hull of the projected points\n        diagonal (float): diagonal of the convex hull of the projected points\n    \"\"\"\ncloth = obj.links[\"base_link\"]\npoints = cloth.keypoint_particle_positions[:, dims]\nhull = ConvexHull(points)\n# When input points are 2-dimensional, this is the area of the convex hull.\n# Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html\narea = hull.volume\ndiagonal = distance_matrix(points[hull.vertices], points[hull.vertices]).max()\nif m.DEBUG_CLOTH_PROJ_VIS:\nimport matplotlib.pyplot as plt\nax = plt.gca()\nax.set_aspect('equal')\nplt.plot(points[:, dims[0]], points[:, dims[1]], 'o')\nfor simplex in hull.simplices:\nplt.plot(points[simplex, dims[0]], points[simplex, dims[1]], 'k-')\nplt.plot(points[hull.vertices, dims[0]], points[hull.vertices, dims[1]], 'r--', lw=2)\nplt.plot(points[hull.vertices[0], dims[0]], points[hull.vertices[0], dims[1]], 'ro')\nplt.show()\nreturn area, diagonal\n</code></pre>"},{"location":"reference/utils/object_state_utils.html#utils.object_state_utils.calculate_projection_area_and_diagonal_maximum","title":"<code>calculate_projection_area_and_diagonal_maximum(obj)</code>","text":"<p>Calculate the maximum projection area and the diagonal length along different axes</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DatasetObject</code> <p>Must be PrimType.CLOTH</p> required <p>Returns:</p> Name Type Description <code>area_max</code> <code>float</code> <p>area of the convex hull of the projected points</p> <code>diagonal_max</code> <code>float</code> <p>diagonal of the convex hull of the projected points</p> Source code in <code>omnigibson/utils/object_state_utils.py</code> <pre><code>def calculate_projection_area_and_diagonal_maximum(obj):\n\"\"\"\n    Calculate the maximum projection area and the diagonal length along different axes\n    Args:\n        obj (DatasetObject): Must be PrimType.CLOTH\n    Returns:\n        area_max (float): area of the convex hull of the projected points\n        diagonal_max (float): diagonal of the convex hull of the projected points\n    \"\"\"\n# use the largest projection area as the unfolded area\narea_max = 0.0\ndiagonal_max = 0.0\ndims_list = [[0, 1], [0, 2], [1, 2]]  # x-y plane, x-z plane, y-z plane\nfor dims in dims_list:\narea, diagonal = calculate_projection_area_and_diagonal(obj, dims)\nif area &gt; area_max:\narea_max = area\ndiagonal_max = diagonal\nreturn area_max, diagonal_max\n</code></pre>"},{"location":"reference/utils/object_state_utils.html#utils.object_state_utils.calculate_smoothness","title":"<code>calculate_smoothness(obj)</code>","text":"<p>Calculate the percantage of surface normals that are sufficiently close to the z-axis.</p> Source code in <code>omnigibson/utils/object_state_utils.py</code> <pre><code>def calculate_smoothness(obj):\n\"\"\"\n    Calculate the percantage of surface normals that are sufficiently close to the z-axis.\n    \"\"\"\ncloth = obj.links[\"base_link\"]\nface_vertex_counts = np.array(cloth.get_attribute(\"faceVertexCounts\"))\nassert (face_vertex_counts == 3).all(), \"cloth prim is expected to only contain triangle faces\"\nface_vertex_indices = np.array(cloth.get_attribute(\"faceVertexIndices\"))\npoints = cloth.particle_positions[face_vertex_indices]\n# Shape [F, 3, 3] where F is the number of faces\npoints = points.reshape((face_vertex_indices.shape[0] // 3, 3, 3))\n# Shape [F, 3]\nv1 = points[:, 2, :] - points[:, 0, :]\nv2 = points[:, 1, :] - points[:, 0, :]\nnormals = np.cross(v1, v2)\nnormals_norm = np.linalg.norm(normals, axis=1)\nvalid_normals = normals[normals_norm.nonzero()] / np.expand_dims(normals_norm[normals_norm.nonzero()], axis=1)\nassert valid_normals.shape[0] &gt; 0\n# projection onto the z-axis\nproj = np.abs(np.dot(valid_normals, np.array([0.0, 0.0, 1.0])))\npercentage = np.mean(proj &gt; np.cos(m.NORMAL_Z_ANGLE_DIFF))\nreturn percentage\n</code></pre>"},{"location":"reference/utils/object_state_utils.html#utils.object_state_utils.sample_kinematics","title":"<code>sample_kinematics(predicate, objA, objB, use_ray_casting_method=True, max_trials=10, z_offset=0.05, skip_falling=False)</code>","text":"<p>Samples the given @predicate kinematic state for @objA with respect to @objB</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>str</code> <p>Name of the predicate to sample, e.g.: \"onTop\"</p> required <code>objA</code> <code>StatefulObject</code> <p>Object whose state should be sampled. e.g.: for sampling a microwave on a cabinet, @objA is the microwave</p> required <code>objB</code> <code>StatefulObject</code> <p>Object who is the reference point for @objA's state. e.g.: for sampling a microwave on a cabinet, @objB is the cabinet</p> required <code>use_ray_casting_method</code> <code>bool</code> <p>Whether to use raycasting for sampling or not</p> <code>True</code> <code>max_trials</code> <code>int</code> <p>Number of attempts for sampling</p> <code>10</code> <code>z_offset</code> <code>float</code> <p>Z-offset to apply to the sampled pose</p> <code>0.05</code> <code>skip_falling</code> <code>bool</code> <p>Whether to let @objA fall after its position is sampled or not</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if successfully sampled, else False</p> Source code in <code>omnigibson/utils/object_state_utils.py</code> <pre><code>def sample_kinematics(\npredicate,\nobjA,\nobjB,\nuse_ray_casting_method=True,\nmax_trials=10,\nz_offset=0.05,\nskip_falling=False,\n):\n\"\"\"\n    Samples the given @predicate kinematic state for @objA with respect to @objB\n    Args:\n        predicate (str): Name of the predicate to sample, e.g.: \"onTop\"\n        objA (StatefulObject): Object whose state should be sampled. e.g.: for sampling a microwave\n            on a cabinet, @objA is the microwave\n        objB (StatefulObject): Object who is the reference point for @objA's state. e.g.: for sampling\n            a microwave on a cabinet, @objB is the cabinet\n        use_ray_casting_method (bool): Whether to use raycasting for sampling or not\n        max_trials (int): Number of attempts for sampling\n        z_offset (float): Z-offset to apply to the sampled pose\n        skip_falling (bool): Whether to let @objA fall after its position is sampled or not\n    Returns:\n        bool: True if successfully sampled, else False\n    \"\"\"\nassert z_offset &gt; 0.5 * 9.81 * (og.sim.get_physics_dt() ** 2) + 0.02,\\\n        f\"z_offset {z_offset} is too small for the current physics_dt {og.sim.get_physics_dt()}\"\n# Run import here to avoid circular imports\n# No supporting surface annotation found, fallback to use ray-casting\nfrom omnigibson.objects.dataset_object import DatasetObject\nif (\nnot isinstance(objB, DatasetObject) or\nlen(objB.supporting_surfaces) == 0 or\npredicate not in objB.supporting_surfaces\n):\nuse_ray_casting_method = True\n# Wake objects accordingly and make sure both are kept still\nobjA.wake()\nobjB.wake()\nobjA.keep_still()\nobjB.keep_still()\n# Save the state of the simulator\nstate = og.sim.dump_state()\n# Attempt sampling\nfor i in range(max_trials):\npos = None\nif hasattr(objA, \"orientations\") and objA.orientations is not None:\norientation = objA.sample_orientation()\nelse:\norientation = np.array([0, 0, 0, 1.0])\n# Orientation needs to be set for stable_z_on_aabb to work correctly\n# Position needs to be set to be very far away because the object's\n# original position might be blocking rays (use_ray_casting_method=True)\nold_pos = np.array([100, 100, 10])\nobjA.set_position_orientation(old_pos, orientation)\nobjA.keep_still()\n# We also need to step physics to make sure the pose propagates downstream (e.g.: to Bounding Box computations)\nog.sim.step_physics()\n# This would slightly change because of the step_physics call.\nold_pos, orientation = objA.get_position_orientation()\nif use_ray_casting_method:\nif predicate == \"onTop\":\nparams = m.ON_TOP_RAY_CASTING_SAMPLING_PARAMS\nelif predicate == \"inside\":\nparams = m.INSIDE_RAY_CASTING_SAMPLING_PARAMS\nelif predicate == \"under\":\nparams = m.UNDER_RAY_CASTING_SAMPLING_PARAMS\nelse:\nraise ValueError(f\"predicate must be onTop, under or inside in order to use ray casting-based \"\nf\"kinematic sampling, but instead got: {predicate}\")\n# Run import here to avoid circular imports\nfrom omnigibson.objects.dataset_object import DatasetObject\nif isinstance(objA, DatasetObject) and objA.prim_type == PrimType.RIGID:\n# Retrieve base CoM frame-aligned bounding box parallel to the XY plane\nparallel_bbox_center, parallel_bbox_orn, parallel_bbox_extents, _ = objA.get_base_aligned_bbox(\nxy_aligned=True\n)\nelse:\naabb_lower, aabb_upper = objA.states[AABB].get_value()\nparallel_bbox_center = (aabb_lower + aabb_upper) / 2.0\nparallel_bbox_orn = np.array([0.0, 0.0, 0.0, 1.0])\nparallel_bbox_extents = aabb_upper - aabb_lower\nif predicate == \"under\":\nstart_points, end_points = sampling_utils.sample_raytest_start_end_symmetric_bimodal_distribution(\nobj=objB,\nnum_samples=1,\naxis_probabilities=[0, 0, 1],\n**params,\n)\nsampling_results = sampling_utils.sample_cuboid_on_object(\nobj=None,\nstart_points=start_points,\nend_points=end_points,\nignore_objs=[objB],\ncuboid_dimensions=parallel_bbox_extents,\nrefuse_downwards=True,\nundo_cuboid_bottom_padding=True,\nmax_angle_with_z_axis=0.17,\nhit_proportion=0.0,  # rays will NOT hit the object itself, but the surface below it.\n)\nelse:\nsampling_results = sampling_utils.sample_cuboid_on_object_symmetric_bimodal_distribution(\nobjB,\nnum_samples=1,\naxis_probabilities=[0, 0, 1],\ncuboid_dimensions=parallel_bbox_extents,\nrefuse_downwards=True,\nundo_cuboid_bottom_padding=True,\nmax_angle_with_z_axis=0.17,\n**params,\n)\nsampled_vector = sampling_results[0][0]\nsampled_quaternion = sampling_results[0][2]\nsampling_success = sampled_vector is not None\nif sampling_success:\n# Move the object from the original parallel bbox to the sampled bbox\nparallel_bbox_rotation = R.from_quat(parallel_bbox_orn)\nsample_rotation = R.from_quat(sampled_quaternion)\noriginal_rotation = R.from_quat(orientation)\n# The additional orientation to be applied should be the delta orientation\n# between the parallel bbox orientation and the sample orientation\nadditional_rotation = sample_rotation * parallel_bbox_rotation.inv()\ncombined_rotation = additional_rotation * original_rotation\norientation = combined_rotation.as_quat()\n# The delta vector between the base CoM frame and the parallel bbox center needs to be rotated\n# by the same additional orientation\ndiff = old_pos - parallel_bbox_center\nrotated_diff = additional_rotation.apply(diff)\npos = sampled_vector + rotated_diff\nelse:\nrandom_idx = np.random.randint(len(objB.supporting_surfaces[predicate].keys()))\nobjB_link_name = list(objB.supporting_surfaces[predicate].keys())[random_idx]\nrandom_height_idx = np.random.randint(len(objB.supporting_surfaces[predicate][objB_link_name]))\nheight, height_map = objB.supporting_surfaces[predicate][objB_link_name][random_height_idx]\nobj_half_size = np.max(objA.aabb_extent) / 2 * 100\nobj_half_size_scaled = np.array([obj_half_size / objB.scale[1], obj_half_size / objB.scale[0]])\nobj_half_size_scaled = np.ceil(obj_half_size_scaled).astype(np.int)\nheight_map_eroded = cv2.erode(height_map, np.ones(obj_half_size_scaled, np.uint8))\nvalid_pos = np.array(height_map_eroded.nonzero())\nif valid_pos.shape[1] != 0:\nrandom_pos_idx = np.random.randint(valid_pos.shape[1])\nrandom_pos = valid_pos[:, random_pos_idx]\ny_map, x_map = random_pos\ny = y_map / 100.0 - 2\nx = x_map / 100.0 - 2\nz = height\npos = np.array([x, y, z])\npos *= objB.scale\n# the supporting surface is defined w.r.t to the link frame, so we need to convert it into\n# the world frame\nlink_pos, link_quat = objB.links[objB_link_name].get_position_orientation()\npos = T.quat2mat(link_quat).dot(pos) + np.array(link_pos)\n# Get the combined AABB.\nlower, _ = objA.states[AABB].get_value()\n# Move the position to a stable Z for the object.\npos[2] += objA.get_position()[2] - lower[2]\nif pos is None:\nsuccess = False\nelse:\npos[2] += z_offset\nobjA.set_position_orientation(pos, orientation)\nobjA.keep_still()\nog.sim.step_physics()\nobjA.keep_still()\nsuccess = len(objA.states[ContactBodies].get_value()) == 0\nif gm.DEBUG:\ndebug_breakpoint(f\"sample_kinematics: {success}\")\nif success:\nbreak\nelse:\nog.sim.load_state(state)\nif success and not skip_falling:\nobjA.set_position_orientation(pos, orientation)\nobjA.keep_still()\n# Let it fall for 0.2 second\nfor _ in range(int(0.2 / og.sim.get_physics_dt())):\nog.sim.step_physics()\nif len(objA.states[ContactBodies].get_value()) &gt; 0:\nbreak\nobjA.keep_still()\n# Render at the end\nog.sim.render()\nreturn success\n</code></pre>"},{"location":"reference/utils/physx_utils.html","title":"physx_utils","text":""},{"location":"reference/utils/physx_utils.html#utils.physx_utils.bind_material","title":"<code>bind_material(prim_path, material_path)</code>","text":"<p>Binds material located at @material_path to the prim located at @prim_path.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Stage path to prim to bind material to</p> required <code>material_path</code> <code>str</code> <p>Stage path to material to be bound</p> required Source code in <code>omnigibson/utils/physx_utils.py</code> <pre><code>def bind_material(prim_path, material_path):\n\"\"\"\n    Binds material located at @material_path to the prim located at @prim_path.\n    Args:\n        prim_path (str): Stage path to prim to bind material to\n        material_path (str): Stage path to material to be bound\n    \"\"\"\nomni.kit.commands.execute(\n\"BindMaterialCommand\",\nprim_path=prim_path,\nmaterial_path=material_path,\nstrength=None,\n)\n</code></pre>"},{"location":"reference/utils/physx_utils.html#utils.physx_utils.create_physx_particle_system","title":"<code>create_physx_particle_system(prim_path, physics_scene_path, particle_contact_offset, visual_only=False, smoothing=True, anisotropy=True, isosurface=True)</code>","text":"<p>Creates an Omniverse physx particle system at @prim_path. For post-processing visualization effects (anisotropy, smoothing, isosurface), see the Omniverse documentation (https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#post-processing-for-fluid-rendering) for more info</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Stage path to where particle system should be created</p> required <code>physics_scene_path</code> <code>str</code> <p>Stage path to where active physicsScene prim is defined</p> required <code>particle_contact_offset</code> <code>float</code> <p>Distance between particles which triggers a collision (m)</p> required <code>visual_only</code> <code>bool</code> <p>If True, will disable collisions between particles and non-particles, as well as self-collisions</p> <code>False</code> <code>smoothing</code> <code>bool</code> <p>Whether to smooth particle positions or not</p> <code>True</code> <code>anisotropy</code> <code>bool</code> <p>Whether to apply anisotropy post-processing when visualizing particles. Stretches generated particles in order to make the particle cluster surface appear smoother. Useful for fluids</p> <code>True</code> <code>isosurface</code> <code>bool</code> <p>Whether to apply isosurface mesh to visualize particles. Uses a monolithic surface that can have materials attached to it, useful for visualizing fluids</p> <code>True</code> <p>Returns:</p> Type Description <p>UsdGeom.PhysxParticleSystem: Generated particle system prim</p> Source code in <code>omnigibson/utils/physx_utils.py</code> <pre><code>def create_physx_particle_system(\nprim_path,\nphysics_scene_path,\nparticle_contact_offset,\nvisual_only=False,\nsmoothing=True,\nanisotropy=True,\nisosurface=True,\n):\n\"\"\"\n    Creates an Omniverse physx particle system at @prim_path. For post-processing visualization effects (anisotropy,\n    smoothing, isosurface), see the Omniverse documentation\n    (https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#post-processing-for-fluid-rendering)\n    for more info\n    Args:\n        prim_path (str): Stage path to where particle system should be created\n        physics_scene_path (str): Stage path to where active physicsScene prim is defined\n        particle_contact_offset (float): Distance between particles which triggers a collision (m)\n        visual_only (bool): If True, will disable collisions between particles and non-particles,\n            as well as self-collisions\n        smoothing (bool): Whether to smooth particle positions or not\n        anisotropy (bool): Whether to apply anisotropy post-processing when visualizing particles. Stretches generated\n            particles in order to make the particle cluster surface appear smoother. Useful for fluids\n        isosurface (bool): Whether to apply isosurface mesh to visualize particles. Uses a monolithic surface that\n            can have materials attached to it, useful for visualizing fluids\n    Returns:\n        UsdGeom.PhysxParticleSystem: Generated particle system prim\n    \"\"\"\n# TODO: Add sanity check to make sure GPU dynamics are enabled\n# Create particle system\nstage = get_current_stage()\nparticle_system = PhysxSchema.PhysxParticleSystem.Define(stage, prim_path)\nparticle_system.CreateSimulationOwnerRel().SetTargets([physics_scene_path])\n# Use a smaller particle size for nicer fluid, and let the sim figure out the other offsets\nparticle_system.CreateParticleContactOffsetAttr().Set(particle_contact_offset)\n# Possibly disable collisions if we're only visual\nif visual_only:\nparticle_system.GetGlobalSelfCollisionEnabledAttr().Set(False)\nparticle_system.GetNonParticleCollisionEnabledAttr().Set(False)\nif anisotropy:\n# apply api and use all defaults\nPhysxSchema.PhysxParticleAnisotropyAPI.Apply(particle_system.GetPrim())\nif smoothing:\n# apply api and use all defaults\nPhysxSchema.PhysxParticleSmoothingAPI.Apply(particle_system.GetPrim())\nif isosurface:\n# apply api and use all defaults\nPhysxSchema.PhysxParticleIsosurfaceAPI.Apply(particle_system.GetPrim())\n# Make sure we're not casting shadows\nprimVarsApi = UsdGeom.PrimvarsAPI(particle_system.GetPrim())\nprimVarsApi.CreatePrimvar(\"doNotCastShadows\", Sdf.ValueTypeNames.Bool).Set(True)\n# tweak anisotropy min, max, and scale to work better with isosurface:\nif anisotropy:\nani_api = PhysxSchema.PhysxParticleAnisotropyAPI.Apply(particle_system.GetPrim())\nani_api.CreateScaleAttr().Set(5.0)\nani_api.CreateMinAttr().Set(1.0)  # avoids gaps in surface\nani_api.CreateMaxAttr().Set(2.0)\nreturn particle_system\n</code></pre>"},{"location":"reference/utils/physx_utils.html#utils.physx_utils.create_physx_particleset_pointinstancer","title":"<code>create_physx_particleset_pointinstancer(name, particle_system_path, physx_particle_system_path, prototype_prim_paths, particle_group, positions, self_collision=True, fluid=False, particle_mass=None, particle_density=None, orientations=None, velocities=None, angular_velocities=None, scales=None, prototype_indices=None, enabled=True)</code>","text":"<p>Creates a particle set instancer based on a UsdGeom.PointInstancer at @prim_path on the current stage, with the specified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for this point instancer</p> required <code>particle_system_path</code> <code>str</code> <p>Stage path to particle system (Scope)</p> required <code>physx_particle_system_path</code> <code>str</code> <p>Stage path to physx particle system (PhysxParticleSystem)</p> required <code>prototype_prim_paths</code> <code>list of str</code> <p>Stage path(s) to the prototypes to reference for this particle set.</p> required <code>particle_group</code> <code>int</code> <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision</p> required <code>positions</code> <code>list of 3-tuple or np.array</code> <p>Particle (x,y,z) positions either as a list or a (N, 3) numpy array</p> required <code>self_collision</code> <code>bool</code> <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p> <code>True</code> <code>fluid</code> <code>bool</code> <p>Whether to simulated the particle set as fluid or not</p> <code>False</code> <code>particle_mass</code> <code>None or float</code> <p>If specified, should be per-particle mass. Otherwise, will be inferred from @density. Note: Either @particle_mass or @particle_density must be specified!</p> <code>None</code> <code>particle_density</code> <code>None or float</code> <p>If specified, should be per-particle density and is used to compute total point set mass. Otherwise, will be inferred from @density. Note: Either @particle_mass or @particle_density must be specified!</p> <code>None</code> <code>orientations</code> <code>None or list of 4-array or np.array</code> <p>Particle (x,y,z,w) quaternion orientations, either as a list or a (N, 4) numpy array. If not specified, all will be set to canonical orientation (0, 0, 0, 1)</p> <code>None</code> <code>velocities</code> <code>None or list of 3-array or np.array</code> <p>Particle (x,y,z) velocities either as a list or a (N, 3) numpy array. If not specified, all will be set to 0</p> <code>None</code> <code>angular_velocities</code> <code>None or list of 3-array or np.array</code> <p>Particle (x,y,z) angular velocities either as a list or a (N, 3) numpy array. If not specified, all will be set to 0</p> <code>None</code> <code>scales</code> <code>None or list of 3-array or np.array</code> <p>Particle (x,y,z) scales either as a list or a (N, 3) numpy array. If not specified, all will be set to 1.0</p> <code>None</code> <code>prototype_indices</code> <code>None or list of int</code> <p>If specified, should specify which prototype should be used for each particle. If None, will use all 0s (i.e.: the first prototype created)</p> <code>None</code> <code>enabled</code> <code>bool</code> <p>Whether to enable this particle instancer. If not enabled, then no physics will be used</p> <code>True</code> <p>Returns:</p> Type Description <code>Usd.Prim</code> <p>UsdGeom.PointInstancer: Created point instancer prim</p> Source code in <code>omnigibson/utils/physx_utils.py</code> <pre><code>def create_physx_particleset_pointinstancer(\nname,\nparticle_system_path,\nphysx_particle_system_path,\nprototype_prim_paths,\nparticle_group,\npositions,\nself_collision=True,\nfluid=False,\nparticle_mass=None,\nparticle_density=None,\norientations=None,\nvelocities=None,\nangular_velocities=None,\nscales=None,\nprototype_indices=None,\nenabled=True,\n) -&gt; Usd.Prim:\n\"\"\"\n    Creates a particle set instancer based on a UsdGeom.PointInstancer at @prim_path on the current stage, with\n    the specified parameters.\n    Args:\n        name (str): Name for this point instancer\n        particle_system_path (str): Stage path to particle system (Scope)\n        physx_particle_system_path (str): Stage path to physx particle system (PhysxParticleSystem)\n        prototype_prim_paths (list of str): Stage path(s) to the prototypes to reference for this particle set.\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision\n        positions (list of 3-tuple or np.array): Particle (x,y,z) positions either as a list or a (N, 3) numpy array\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        fluid (bool): Whether to simulated the particle set as fluid or not\n        particle_mass (None or float): If specified, should be per-particle mass. Otherwise, will be\n            inferred from @density. Note: Either @particle_mass or @particle_density must be specified!\n        particle_density (None or float): If specified, should be per-particle density and is used to compute total\n            point set mass. Otherwise, will be inferred from @density. Note: Either @particle_mass or\n            @particle_density must be specified!\n        orientations (None or list of 4-array or np.array): Particle (x,y,z,w) quaternion orientations, either as a\n            list or a (N, 4) numpy array. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        velocities (None or list of 3-array or np.array): Particle (x,y,z) velocities either as a list or a (N, 3)\n            numpy array. If not specified, all will be set to 0\n        angular_velocities (None or list of 3-array or np.array): Particle (x,y,z) angular velocities either as a\n            list or a (N, 3) numpy array. If not specified, all will be set to 0\n        scales (None or list of 3-array or np.array): Particle (x,y,z) scales either as a list or a (N, 3)\n            numpy array. If not specified, all will be set to 1.0\n        prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n            each particle. If None, will use all 0s (i.e.: the first prototype created)\n        enabled (bool): Whether to enable this particle instancer. If not enabled, then no physics will be used\n    Returns:\n        UsdGeom.PointInstancer: Created point instancer prim\n    \"\"\"\nstage = og.sim.stage\nn_particles = len(positions)\nparticle_system = get_prim_at_path(physx_particle_system_path)\n# Create point instancer scope\nprim_path = f\"{particle_system_path}/{name}\"\nassert not stage.GetPrimAtPath(prim_path), f\"Cannot create an instancer scope, scope already exists at {prim_path}!\"\nstage.DefinePrim(prim_path, \"Scope\")\n# Create point instancer\ninstancer_prim_path = f\"{prim_path}/instancer\"\nassert not stage.GetPrimAtPath(instancer_prim_path), f\"Cannot create a PointInstancer prim, prim already exists at {instancer_prim_path}!\"\ninstancer = UsdGeom.PointInstancer.Define(stage, instancer_prim_path)\nis_isosurface = particle_system.HasAPI(PhysxSchema.PhysxParticleIsosurfaceAPI) and \\\n                    particle_system.GetAttribute(\"physxParticleIsosurface:isosurfaceEnabled\").Get()\n# Add prototype mesh prim paths to the prototypes relationship attribute for this point set\n# We need to make copies of prototypes for each instancer currently because particles won't render properly\n# if multiple instancers share the same prototypes for some reason\nmesh_list = instancer.GetPrototypesRel()\nprototype_prims = []\nfor i, original_path in enumerate(prototype_prim_paths):\nprototype_prim_path = f\"{prim_path}/prototype{i}\"\nomni.kit.commands.execute(\"CopyPrim\", path_from=original_path, path_to=prototype_prim_path)\nprototype_prim = get_prim_at_path(prototype_prim_path)\n# Make sure this prim is invisible if we're using isosurface, and vice versa.\nimageable = UsdGeom.Imageable(prototype_prim)\nif is_isosurface:\nimageable.MakeInvisible()\nelse:\nimageable.MakeVisible()\n# Move the prototype to the graveyard position so that it won't be visible to the agent\n# We can't directly hide the prototype because it will also hide all the generated particles (if not isosurface)\nprototype_prim.GetAttribute(\"xformOp:translate\").Set(m.PROTOTYPE_GRAVEYARD_POS)\nmesh_list.AddTarget(Sdf.Path(prototype_prim_path))\nprototype_prims.append(prototype_prim)\n# Set particle instance default data\nprototype_indices = [0] * n_particles if prototype_indices is None else prototype_indices\nif orientations is None:\norientations = np.zeros((n_particles, 4))\norientations[:, -1] = 1.0\norientations = np.array(orientations)[:, [3, 0, 1, 2]]  # x,y,z,w --&gt; w,x,y,z\nvelocities = np.zeros((n_particles, 3)) if velocities is None else velocities\nangular_velocities = np.zeros((n_particles, 3)) if angular_velocities is None else angular_velocities\nscales = np.ones((n_particles, 3)) if scales is None else scales\nassert particle_mass is not None or particle_density is not None, \\\n        \"Either particle mass or particle density must be specified when creating particle instancer!\"\nparticle_mass = 0.0 if particle_mass is None else particle_mass\nparticle_density = 0.0 if particle_density is None else particle_density\n# Set particle states\ninstancer.GetProtoIndicesAttr().Set(prototype_indices)\ninstancer.GetPositionsAttr().Set(Vt.Vec3fArray.FromNumpy(positions))\ninstancer.GetOrientationsAttr().Set(Vt.QuathArray.FromNumpy(orientations))\ninstancer.GetVelocitiesAttr().Set(Vt.Vec3fArray.FromNumpy(velocities))\ninstancer.GetAngularVelocitiesAttr().Set(Vt.Vec3fArray.FromNumpy(angular_velocities))\ninstancer.GetScalesAttr().Set(Vt.Vec3fArray.FromNumpy(scales))\n# Take a render step to \"lock\" the visuals of the prototypes at the graveyard position\n# This needs to happen AFTER setting particle states\n# We suppress a known warning that we have no control over where omni complains about a prototype\n# not being populated yet\nwith suppress_omni_log(channels=[\"omni.hydra.scene_delegate.plugin\"]):\nog.sim.render()\n# Then we move the prototypes back to zero offset because otherwise all the generated particles will be offset by\n# the graveyard position. At this point, the prototypes themselves no longer appear at the zero offset (locked at\n# the graveyard position), which is desirable because we don't want the agent to see the prototypes themselves.\nfor prototype_prim in prototype_prims:\nprototype_prim.GetAttribute(\"xformOp:translate\").Set((0.0, 0.0, 0.0))\ninstancer_prim = instancer.GetPrim()\nparticleUtils.configure_particle_set(\ninstancer_prim,\nphysx_particle_system_path,\nself_collision,\nfluid,\nparticle_group,\nparticle_mass * n_particles,\nparticle_density,\n)\n# Set whether the instancer is enabled or not\ninstancer_prim.GetAttribute(\"physxParticle:particleEnabled\").Set(enabled)\n# Render three more times to fully propagate changes\n# Omni always complains about a low-level USD thing we have no control over\n# so we suppress the warnings\nwith suppress_omni_log(channels=[\"omni.usd\"]):\nfor i in range(3):\nog.sim.render()\n# Isosurfaces require an additional physics timestep before they're actually rendered\nif is_isosurface:\nog.log.warning(f\"Creating an instancer that uses isosurface {instancer_prim_path}. \"\nf\"The rendering of these particles will have a delay of one timestep.\")\nreturn instancer_prim\n</code></pre>"},{"location":"reference/utils/processing_utils.html","title":"processing_utils","text":""},{"location":"reference/utils/processing_utils.html#utils.processing_utils.ExponentialAverageFilter","title":"<code>ExponentialAverageFilter</code>","text":"<p>         Bases: <code>Filter</code></p> <p>This class uses an exponential average of the form y_n = alpha * x_n + (1 - alpha) * y_{n - 1}. This is an IIR filter.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>class ExponentialAverageFilter(Filter):\n\"\"\"\n    This class uses an exponential average of the form y_n = alpha * x_n + (1 - alpha) * y_{n - 1}.\n    This is an IIR filter.\n    \"\"\"\ndef __init__(self, obs_dim, alpha=0.9):\n\"\"\"\n        Args:\n            obs_dim (int): The dimension of the points to filter.\n            alpha (float): The relative weighting of new samples relative to older samples\n        \"\"\"\nself.obs_dim = obs_dim\nself.avg = np.zeros(obs_dim)\nself.num_samples = 0\nself.alpha = alpha\nsuper().__init__()\ndef estimate(self, observation):\n\"\"\"\n        Do an online hold for state estimation given a recent observation.\n        Args:\n            observation (n-array): New observation to hold internal estimate of state.\n        Returns:\n            n-array: New estimate of state.\n        \"\"\"\nself.avg = self.alpha * observation + (1.0 - self.alpha) * self.avg\nself.num_samples += 1\nreturn np.array(self.avg)\ndef reset(self):\n# Clear internal state\nself.avg *= 0.0\nself.num_samples = 0\n@property\ndef state_size(self):\nreturn super().state_size + self.obs_dim + 1\ndef _dump_state(self):\n# Run super init first\nstate = super()._dump_state()\n# Add info from this filter\nstate[\"avg\"] = np.array(self.avg)\nstate[\"num_samples\"] = self.num_samples\nreturn state\ndef _load_state(self, state):\n# Run super first\nsuper()._load_state(state=state)\n# Load relevant info for this filter\nself.avg = np.array(state[\"avg\"])\nself.num_samples = state[\"num_samples\"]\ndef _serialize(self, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\n# Serialize state for this filter\nreturn np.concatenate([\nstate_flat,\nstate[\"avg\"],\n[state[\"num_samples\"]],\n]).astype(float)\ndef _deserialize(self, state):\n# Run super first\nstate_dict, idx = super()._deserialize(state=state)\n# Deserialize state for this filter\nstate_dict[\"avg\"] = state[idx: idx + self.obs_dim]\nstate_dict[\"num_samples\"] = int(state[idx + self.obs_dim])\nreturn state_dict, idx + self.obs_dim + 1\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.ExponentialAverageFilter.__init__","title":"<code>__init__(obs_dim, alpha=0.9)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>obs_dim</code> <code>int</code> <p>The dimension of the points to filter.</p> required <code>alpha</code> <code>float</code> <p>The relative weighting of new samples relative to older samples</p> <code>0.9</code> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def __init__(self, obs_dim, alpha=0.9):\n\"\"\"\n    Args:\n        obs_dim (int): The dimension of the points to filter.\n        alpha (float): The relative weighting of new samples relative to older samples\n    \"\"\"\nself.obs_dim = obs_dim\nself.avg = np.zeros(obs_dim)\nself.num_samples = 0\nself.alpha = alpha\nsuper().__init__()\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.ExponentialAverageFilter.estimate","title":"<code>estimate(observation)</code>","text":"<p>Do an online hold for state estimation given a recent observation.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>n-array</code> <p>New observation to hold internal estimate of state.</p> required <p>Returns:</p> Type Description <p>n-array: New estimate of state.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def estimate(self, observation):\n\"\"\"\n    Do an online hold for state estimation given a recent observation.\n    Args:\n        observation (n-array): New observation to hold internal estimate of state.\n    Returns:\n        n-array: New estimate of state.\n    \"\"\"\nself.avg = self.alpha * observation + (1.0 - self.alpha) * self.avg\nself.num_samples += 1\nreturn np.array(self.avg)\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.Filter","title":"<code>Filter</code>","text":"<p>         Bases: <code>Serializable</code></p> <p>A base class for filtering a noisy data stream in an online fashion.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>class Filter(Serializable):\n\"\"\"\n    A base class for filtering a noisy data stream in an online fashion.\n    \"\"\"\ndef estimate(self, observation):\n\"\"\"\n        Takes an observation and returns a de-noised estimate.\n        Args:\n            observation (n-array): A current observation.\n        Returns:\n            n-array: De-noised estimate.\n        \"\"\"\nraise NotImplementedError\ndef reset(self):\n\"\"\"\n        Resets this filter. Default is no-op.\n        \"\"\"\npass\n@property\ndef state_size(self):\n# No state by default\nreturn 0\ndef _dump_state(self):\n# Default is no state (empty dict)\nreturn dict()\ndef _load_state(self, state):\n# Default is no state (empty dict), so this is a no-op\npass\ndef _serialize(self, state):\n# Default is no state, so do nothing\nreturn np.array([])\ndef _deserialize(self, state):\n# Default is no state, so do nothing\nreturn dict(), 0\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.Filter.estimate","title":"<code>estimate(observation)</code>","text":"<p>Takes an observation and returns a de-noised estimate.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>n-array</code> <p>A current observation.</p> required <p>Returns:</p> Type Description <p>n-array: De-noised estimate.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def estimate(self, observation):\n\"\"\"\n    Takes an observation and returns a de-noised estimate.\n    Args:\n        observation (n-array): A current observation.\n    Returns:\n        n-array: De-noised estimate.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.Filter.reset","title":"<code>reset()</code>","text":"<p>Resets this filter. Default is no-op.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def reset(self):\n\"\"\"\n    Resets this filter. Default is no-op.\n    \"\"\"\npass\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.MovingAverageFilter","title":"<code>MovingAverageFilter</code>","text":"<p>         Bases: <code>Filter</code></p> <p>This class uses a moving average to de-noise a noisy data stream in an online fashion. This is a FIR filter.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>class MovingAverageFilter(Filter):\n\"\"\"\n    This class uses a moving average to de-noise a noisy data stream in an online fashion.\n    This is a FIR filter.\n    \"\"\"\ndef __init__(self, obs_dim, filter_width):\n\"\"\"\n        Args:\n            obs_dim (int): The dimension of the points to filter.\n            filter_width (int): The number of past samples to take the moving average over.\n        \"\"\"\nself.obs_dim = obs_dim\nassert filter_width &gt; 0, f\"MovingAverageFilter must have a non-zero size! Got: {filter_width}\"\nself.filter_width = filter_width\nself.past_samples = np.zeros((filter_width, obs_dim))\nself.current_idx = 0\nself.fully_filled = False               # Whether the entire filter buffer is filled or not\nsuper().__init__()\ndef estimate(self, observation):\n\"\"\"\n        Do an online hold for state estimation given a recent observation.\n        Args:\n            observation (n-array): New observation to hold internal estimate of state.\n        Returns:\n            n-array: New estimate of state.\n        \"\"\"\n# Write the newest observation at the appropriate index\nself.past_samples[self.current_idx, :] = np.array(observation)\n# Compute value based on whether we're fully filled or not\nif not self.fully_filled:\nval = self.past_samples[:self.current_idx + 1, :].mean(axis=0)\n# Denote that we're fully filled if we're at the end of the buffer\nif self.current_idx == self.filter_width - 1:\nself.fully_filled = True\nelse:\nval = self.past_samples.mean(axis=0)\n# Increment the index to write the next sample to\nself.current_idx = (self.current_idx + 1) % self.filter_width\nreturn val\ndef reset(self):\n# Clear internal state\nself.past_samples *= 0.0\nself.current_idx = 0\nself.fully_filled = False\n@property\ndef state_size(self):\nreturn super().state_size + self.filter_width * self.obs_dim + 2\ndef _dump_state(self):\n# Run super init first\nstate = super()._dump_state()\n# Add info from this filter\nstate[\"past_samples\"] = np.array(self.past_samples)\nstate[\"current_idx\"] = self.current_idx\nstate[\"fully_filled\"] = self.fully_filled\nreturn state\ndef _load_state(self, state):\n# Run super first\nsuper()._load_state(state=state)\n# Load relevant info for this filter\nself.past_samples = np.array(state[\"past_samples\"])\nself.current_idx = state[\"current_idx\"]\nself.fully_filled = state[\"fully_filled\"]\ndef _serialize(self, state):\n# Run super first\nstate_flat = super()._serialize(state=state)\n# Serialize state for this filter\nreturn np.concatenate([\nstate_flat,\nstate[\"past_samples\"].flatten(),\n[state[\"current_idx\"]],\n[state[\"fully_filled\"]],\n]).astype(float)\ndef _deserialize(self, state):\n# Run super first\nstate_dict, idx = super()._deserialize(state=state)\n# Deserialize state for this filter\nsamples_len = self.filter_width * self.obs_dim\nstate_dict[\"past_samples\"] = state[idx: idx + samples_len]\nstate_dict[\"current_idx\"] = int(state[idx + samples_len])\nstate_dict[\"fully_filled\"] = bool(state[idx + samples_len + 1])\nreturn state_dict, idx + samples_len + 2\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.MovingAverageFilter.__init__","title":"<code>__init__(obs_dim, filter_width)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>obs_dim</code> <code>int</code> <p>The dimension of the points to filter.</p> required <code>filter_width</code> <code>int</code> <p>The number of past samples to take the moving average over.</p> required Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def __init__(self, obs_dim, filter_width):\n\"\"\"\n    Args:\n        obs_dim (int): The dimension of the points to filter.\n        filter_width (int): The number of past samples to take the moving average over.\n    \"\"\"\nself.obs_dim = obs_dim\nassert filter_width &gt; 0, f\"MovingAverageFilter must have a non-zero size! Got: {filter_width}\"\nself.filter_width = filter_width\nself.past_samples = np.zeros((filter_width, obs_dim))\nself.current_idx = 0\nself.fully_filled = False               # Whether the entire filter buffer is filled or not\nsuper().__init__()\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.MovingAverageFilter.estimate","title":"<code>estimate(observation)</code>","text":"<p>Do an online hold for state estimation given a recent observation.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>n-array</code> <p>New observation to hold internal estimate of state.</p> required <p>Returns:</p> Type Description <p>n-array: New estimate of state.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def estimate(self, observation):\n\"\"\"\n    Do an online hold for state estimation given a recent observation.\n    Args:\n        observation (n-array): New observation to hold internal estimate of state.\n    Returns:\n        n-array: New estimate of state.\n    \"\"\"\n# Write the newest observation at the appropriate index\nself.past_samples[self.current_idx, :] = np.array(observation)\n# Compute value based on whether we're fully filled or not\nif not self.fully_filled:\nval = self.past_samples[:self.current_idx + 1, :].mean(axis=0)\n# Denote that we're fully filled if we're at the end of the buffer\nif self.current_idx == self.filter_width - 1:\nself.fully_filled = True\nelse:\nval = self.past_samples.mean(axis=0)\n# Increment the index to write the next sample to\nself.current_idx = (self.current_idx + 1) % self.filter_width\nreturn val\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.Subsampler","title":"<code>Subsampler</code>","text":"<p>A base class for subsampling a data stream in an online fashion.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>class Subsampler:\n\"\"\"\n    A base class for subsampling a data stream in an online fashion.\n    \"\"\"\ndef subsample(self, observation):\n\"\"\"\n        Takes an observation and returns the observation, or None, which\n        corresponds to deleting the observation.\n        Args:\n            observation (n-array): A current observation.\n        Returns:\n            None or n-array: No observation if subsampled, otherwise the observation\n        \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.Subsampler.subsample","title":"<code>subsample(observation)</code>","text":"<p>Takes an observation and returns the observation, or None, which corresponds to deleting the observation.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>n-array</code> <p>A current observation.</p> required <p>Returns:</p> Type Description <p>None or n-array: No observation if subsampled, otherwise the observation</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def subsample(self, observation):\n\"\"\"\n    Takes an observation and returns the observation, or None, which\n    corresponds to deleting the observation.\n    Args:\n        observation (n-array): A current observation.\n    Returns:\n        None or n-array: No observation if subsampled, otherwise the observation\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.UniformSubsampler","title":"<code>UniformSubsampler</code>","text":"<p>         Bases: <code>Subsampler</code></p> <p>A class for subsampling a data stream uniformly in time in an online fashion.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>class UniformSubsampler(Subsampler):\n\"\"\"\n    A class for subsampling a data stream uniformly in time in an online fashion.\n    \"\"\"\ndef __init__(self, T):\n\"\"\"\n        Args:\n            T (int): Pick one every T observations.\n        \"\"\"\nself.T = T\nself.counter = 0\nsuper(UniformSubsampler, self).__init__()\ndef subsample(self, observation):\n\"\"\"\n        Returns an observation once every T observations, None otherwise.\n        Args:\n            observation (n-array): A current observation.\n        Returns:\n            None or n-array: The observation, or None.\n        \"\"\"\nself.counter += 1\nif self.counter == self.T:\nself.counter = 0\nreturn observation\nreturn None\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.UniformSubsampler.__init__","title":"<code>__init__(T)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>T</code> <code>int</code> <p>Pick one every T observations.</p> required Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def __init__(self, T):\n\"\"\"\n    Args:\n        T (int): Pick one every T observations.\n    \"\"\"\nself.T = T\nself.counter = 0\nsuper(UniformSubsampler, self).__init__()\n</code></pre>"},{"location":"reference/utils/processing_utils.html#utils.processing_utils.UniformSubsampler.subsample","title":"<code>subsample(observation)</code>","text":"<p>Returns an observation once every T observations, None otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>n-array</code> <p>A current observation.</p> required <p>Returns:</p> Type Description <p>None or n-array: The observation, or None.</p> Source code in <code>omnigibson/utils/processing_utils.py</code> <pre><code>def subsample(self, observation):\n\"\"\"\n    Returns an observation once every T observations, None otherwise.\n    Args:\n        observation (n-array): A current observation.\n    Returns:\n        None or n-array: The observation, or None.\n    \"\"\"\nself.counter += 1\nif self.counter == self.T:\nself.counter = 0\nreturn observation\nreturn None\n</code></pre>"},{"location":"reference/utils/python_utils.html","title":"python_utils","text":"<p>A set of utility functions for general python usage</p>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Recreatable","title":"<code>Recreatable</code>","text":"<p>Simple class that provides an abstract interface automatically saving init args of the classes inheriting it.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class Recreatable(metaclass=RecreatableAbcMeta):\n\"\"\"\n    Simple class that provides an abstract interface automatically saving __init__ args of\n    the classes inheriting it.\n    \"\"\"\ndef get_init_info(self):\n\"\"\"\n        Grabs relevant initialization information for this class instance. Useful for directly\n        reloading an object from this information, using @create_object_from_init_info.\n        Returns:\n            dict: Nested dictionary that contains this object's initialization information\n        \"\"\"\n# Note: self._init_info is procedurally generated via @save_init_info called in metaclass\nreturn self._init_info\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Recreatable.get_init_info","title":"<code>get_init_info()</code>","text":"<p>Grabs relevant initialization information for this class instance. Useful for directly reloading an object from this information, using @create_object_from_init_info.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Nested dictionary that contains this object's initialization information</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def get_init_info(self):\n\"\"\"\n    Grabs relevant initialization information for this class instance. Useful for directly\n    reloading an object from this information, using @create_object_from_init_info.\n    Returns:\n        dict: Nested dictionary that contains this object's initialization information\n    \"\"\"\n# Note: self._init_info is procedurally generated via @save_init_info called in metaclass\nreturn self._init_info\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.RecreatableAbcMeta","title":"<code>RecreatableAbcMeta</code>","text":"<p>         Bases: <code>RecreatableMeta</code>, <code>ABCMeta</code></p> <p>A composite metaclass of both RecreatableMeta and ABCMeta.</p> <p>Adding in ABCMeta to resolve metadata conflicts.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class RecreatableAbcMeta(RecreatableMeta, ABCMeta):\n\"\"\"\n    A composite metaclass of both RecreatableMeta and ABCMeta.\n    Adding in ABCMeta to resolve metadata conflicts.\n    \"\"\"\npass\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.RecreatableMeta","title":"<code>RecreatableMeta</code>","text":"<p>         Bases: <code>type</code></p> <p>Simple metaclass that automatically saves init args of the instances it creates.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class RecreatableMeta(type):\n\"\"\"\n    Simple metaclass that automatically saves __init__ args of the instances it creates.\n    \"\"\"\ndef __new__(cls, clsname, bases, clsdict):\nif \"__init__\" in clsdict:\nclsdict[\"__init__\"] = save_init_info(clsdict[\"__init__\"])\nreturn super().__new__(cls, clsname, bases, clsdict)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Registerable","title":"<code>Registerable</code>","text":"<p>Simple class template that provides an abstract interface for registering classes.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class Registerable:\n\"\"\"\n    Simple class template that provides an abstract interface for registering classes.\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\n\"\"\"\n        Registers all subclasses as part of this registry. This is useful to decouple internal codebase from external\n        user additions. This way, users can add their custom subclasses by simply extending this class,\n        and it will automatically be registered internally. This allows users to then specify their classes\n        directly in string-form in e.g., their config files, without having to manually set the str-to-class mapping\n        in our code.\n        \"\"\"\ncls._register_cls()\n@classmethod\ndef _register_cls(cls):\n\"\"\"\n        Register this class. Can be extended by subclass.\n        \"\"\"\n# print(f\"registering: {cls.__name__}\")\n# print(f\"registry: {cls._cls_registry}\", cls.__name__ not in cls._cls_registry)\n# print(f\"do not register: {cls._do_not_register_classes}\", cls.__name__ not in cls._do_not_register_classes)\n# input()\nif cls.__name__ not in cls._cls_registry and cls.__name__ not in cls._do_not_register_classes:\ncls._cls_registry[cls.__name__] = cls\n@classproperty\ndef _do_not_register_classes(cls):\n\"\"\"\n        Returns:\n            set of str: Name(s) of classes that should not be registered. Default is empty set.\n                Subclasses that shouldn't be added should call super() and then add their own class name to the set\n        \"\"\"\nreturn set()\n@classproperty\ndef _cls_registry(cls):\n\"\"\"\n        Returns:\n            dict: Mapping from all registered class names to their classes. This should be a REFERENCE\n                to some external, global dictionary that will be filled-in at runtime.\n        \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Registerable.__init_subclass__","title":"<code>__init_subclass__(**kwargs)</code>","text":"<p>Registers all subclasses as part of this registry. This is useful to decouple internal codebase from external user additions. This way, users can add their custom subclasses by simply extending this class, and it will automatically be registered internally. This allows users to then specify their classes directly in string-form in e.g., their config files, without having to manually set the str-to-class mapping in our code.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def __init_subclass__(cls, **kwargs):\n\"\"\"\n    Registers all subclasses as part of this registry. This is useful to decouple internal codebase from external\n    user additions. This way, users can add their custom subclasses by simply extending this class,\n    and it will automatically be registered internally. This allows users to then specify their classes\n    directly in string-form in e.g., their config files, without having to manually set the str-to-class mapping\n    in our code.\n    \"\"\"\ncls._register_cls()\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Serializable","title":"<code>Serializable</code>","text":"<p>Simple class that provides an abstract interface to dump / load states, optionally with serialized functionality as well.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class Serializable:\n\"\"\"\n    Simple class that provides an abstract interface to dump / load states, optionally with serialized functionality\n    as well.\n    \"\"\"\n@property\ndef state_size(self):\n\"\"\"\n        Returns:\n            int: Size of this object's serialized state\n        \"\"\"\nraise NotImplementedError()\ndef _dump_state(self):\n\"\"\"\n        Dumps the state of this object in dictionary form (can be empty). Should be implemented by subclass.\n        Returns:\n            dict: Keyword-mapped states of this object\n        \"\"\"\nraise NotImplementedError()\ndef dump_state(self, serialized=False):\n\"\"\"\n        Dumps the state of this object in either dictionary of flattened numerical form.\n        Args:\n            serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n                a (potentially nested) dictionary of states for this object\n        Returns:\n            dict or n-array: Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        \"\"\"\nstate = self._dump_state()\nreturn self.serialize(state=state) if serialized else state\ndef _load_state(self, state):\n\"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to set\n        \"\"\"\nraise NotImplementedError()\ndef load_state(self, state, serialized=False):\n\"\"\"\n        Deserializes and loads this object's state based on @state\n        Args:\n            state (dict or n-array): Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n            serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n                a (potentially nested) dictionary of states for this object\n        \"\"\"\nstate = self.deserialize(state=state) if serialized else state\nself._load_state(state=state)\ndef _serialize(self, state):\n\"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\nraise NotImplementedError()\ndef serialize(self, state):\n\"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\n# Simply returns self._serialize() for now. this is for future proofing\nreturn self._serialize(state=state)\ndef _deserialize(self, state):\n\"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n        Returns:\n            2-tuple:\n                - dict: Keyword-mapped states of this object. Should match structure of output from\n                    self._dump_state()\n                - int: current index of the flattened state vector that is left off. This is helpful for subclasses\n                    that inherit partial deserializations from parent classes, and need to know where the\n                    deserialization left off before continuing.\n        \"\"\"\nraise NotImplementedError\ndef deserialize(self, state):\n\"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n        Returns:\n            dict: Keyword-mapped states of this object. Should match structure of output from\n                self._dump_state()\n        \"\"\"\n# Sanity check the idx with the expected state size\nstate_dict, idx = self._deserialize(state=state)\nassert idx == self.state_size, f\"Invalid state deserialization occurred! Expected {self.state_size} total \" \\\n                                           f\"values to be deserialized, only {idx} were.\"\nreturn state_dict\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Serializable.state_size","title":"<code>state_size</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Size of this object's serialized state</p>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Serializable.deserialize","title":"<code>deserialize(state)</code>","text":"<p>De-serializes flattened 1D numpy array @state into nested dictionary state. Should be implemented by subclass.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>n-array</code> <p>encoded + serialized, 1D numerical np.array capturing this object's state</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped states of this object. Should match structure of output from self._dump_state()</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def deserialize(self, state):\n\"\"\"\n    De-serializes flattened 1D numpy array @state into nested dictionary state.\n    Should be implemented by subclass.\n    Args:\n        state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n    Returns:\n        dict: Keyword-mapped states of this object. Should match structure of output from\n            self._dump_state()\n    \"\"\"\n# Sanity check the idx with the expected state size\nstate_dict, idx = self._deserialize(state=state)\nassert idx == self.state_size, f\"Invalid state deserialization occurred! Expected {self.state_size} total \" \\\n                                       f\"values to be deserialized, only {idx} were.\"\nreturn state_dict\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Serializable.dump_state","title":"<code>dump_state(serialized=False)</code>","text":"<p>Dumps the state of this object in either dictionary of flattened numerical form.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>bool</code> <p>If True, will return the state of this object as a 1D numpy array. Otherewise, will return a (potentially nested) dictionary of states for this object</p> <code>False</code> <p>Returns:</p> Type Description <p>dict or n-array: Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def dump_state(self, serialized=False):\n\"\"\"\n    Dumps the state of this object in either dictionary of flattened numerical form.\n    Args:\n        serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n            a (potentially nested) dictionary of states for this object\n    Returns:\n        dict or n-array: Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n    \"\"\"\nstate = self._dump_state()\nreturn self.serialize(state=state) if serialized else state\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Serializable.load_state","title":"<code>load_state(state, serialized=False)</code>","text":"<p>Deserializes and loads this object's state based on @state</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict or n-array</code> <p>Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p> required <code>serialized</code> <code>bool</code> <p>If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is a (potentially nested) dictionary of states for this object</p> <code>False</code> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def load_state(self, state, serialized=False):\n\"\"\"\n    Deserializes and loads this object's state based on @state\n    Args:\n        state (dict or n-array): Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n            a (potentially nested) dictionary of states for this object\n    \"\"\"\nstate = self.deserialize(state=state) if serialized else state\nself._load_state(state=state)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.Serializable.serialize","title":"<code>serialize(state)</code>","text":"<p>Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency. Should be implemented by subclass.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict</code> <p>Keyword-mapped states of this object to encode. Should match structure of output from self._dump_state()</p> required <p>Returns:</p> Type Description <p>n-array: encoded + serialized, 1D numerical np.array capturing this object's state</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def serialize(self, state):\n\"\"\"\n    Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n    Should be implemented by subclass.\n    Args:\n        state (dict): Keyword-mapped states of this object to encode. Should match structure of output from\n            self._dump_state()\n    Returns:\n        n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n    \"\"\"\n# Simply returns self._serialize() for now. this is for future proofing\nreturn self._serialize(state=state)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance","title":"<code>SerializableNonInstance</code>","text":"<p>Identical to Serializable, but intended for non-instanceable classes</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class SerializableNonInstance:\n\"\"\"\n    Identical to Serializable, but intended for non-instanceable classes\n    \"\"\"\n@classproperty\ndef state_size(cls):\n\"\"\"\n        Returns:\n            int: Size of this object's serialized state\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef _dump_state(cls):\n\"\"\"\n        Dumps the state of this object in dictionary form (can be empty). Should be implemented by subclass.\n        Returns:\n            dict: Keyword-mapped states of this object\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef dump_state(cls, serialized=False):\n\"\"\"\n        Dumps the state of this object in either dictionary of flattened numerical form.\n        Args:\n            serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n                a (potentially nested) dictionary of states for this object\n        Returns:\n            dict or n-array: Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        \"\"\"\nstate = cls._dump_state()\nreturn cls.serialize(state=state) if serialized else state\n@classmethod\ndef _load_state(cls, state):\n\"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to set\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef load_state(cls, state, serialized=False):\n\"\"\"\n        Deserializes and loads this object's state based on @state\n        Args:\n            state (dict or n-array): Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n            serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n                a (potentially nested) dictionary of states for this object\n        \"\"\"\nstate = cls.deserialize(state=state) if serialized else state\ncls._load_state(state=state)\n@classmethod\ndef _serialize(cls, state):\n\"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\nraise NotImplementedError()\n@classmethod\ndef serialize(cls, state):\n\"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n        Args:\n            state (dict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\n# Simply returns self._serialize() for now. this is for future proofing\nreturn cls._serialize(state=state)\n@classmethod\ndef _deserialize(cls, state):\n\"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n        Returns:\n            2-tuple:\n                - dict: Keyword-mapped states of this object. Should match structure of output from\n                    self._dump_state()\n                - int: current index of the flattened state vector that is left off. This is helpful for subclasses\n                    that inherit partial deserializations from parent classes, and need to know where the\n                    deserialization left off before continuing.\n        \"\"\"\nraise NotImplementedError\n@classmethod\ndef deserialize(cls, state):\n\"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n        Returns:\n            dict: Keyword-mapped states of this object. Should match structure of output from\n                self._dump_state()\n        \"\"\"\n# Sanity check the idx with the expected state size\nstate_dict, idx = cls._deserialize(state=state)\nassert idx == cls.state_size, f\"Invalid state deserialization occurred! Expected {cls.state_size} total \" \\\n                                      f\"values to be deserialized, only {idx} were.\"\nreturn state_dict\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.deserialize","title":"<code>deserialize(state)</code>  <code>classmethod</code>","text":"<p>De-serializes flattened 1D numpy array @state into nested dictionary state. Should be implemented by subclass.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>n-array</code> <p>encoded + serialized, 1D numerical np.array capturing this object's state</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped states of this object. Should match structure of output from self._dump_state()</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>@classmethod\ndef deserialize(cls, state):\n\"\"\"\n    De-serializes flattened 1D numpy array @state into nested dictionary state.\n    Should be implemented by subclass.\n    Args:\n        state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n    Returns:\n        dict: Keyword-mapped states of this object. Should match structure of output from\n            self._dump_state()\n    \"\"\"\n# Sanity check the idx with the expected state size\nstate_dict, idx = cls._deserialize(state=state)\nassert idx == cls.state_size, f\"Invalid state deserialization occurred! Expected {cls.state_size} total \" \\\n                                  f\"values to be deserialized, only {idx} were.\"\nreturn state_dict\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.dump_state","title":"<code>dump_state(serialized=False)</code>  <code>classmethod</code>","text":"<p>Dumps the state of this object in either dictionary of flattened numerical form.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>bool</code> <p>If True, will return the state of this object as a 1D numpy array. Otherewise, will return a (potentially nested) dictionary of states for this object</p> <code>False</code> <p>Returns:</p> Type Description <p>dict or n-array: Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>@classmethod\ndef dump_state(cls, serialized=False):\n\"\"\"\n    Dumps the state of this object in either dictionary of flattened numerical form.\n    Args:\n        serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n            a (potentially nested) dictionary of states for this object\n    Returns:\n        dict or n-array: Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n    \"\"\"\nstate = cls._dump_state()\nreturn cls.serialize(state=state) if serialized else state\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.load_state","title":"<code>load_state(state, serialized=False)</code>  <code>classmethod</code>","text":"<p>Deserializes and loads this object's state based on @state</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict or n-array</code> <p>Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p> required <code>serialized</code> <code>bool</code> <p>If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is a (potentially nested) dictionary of states for this object</p> <code>False</code> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>@classmethod\ndef load_state(cls, state, serialized=False):\n\"\"\"\n    Deserializes and loads this object's state based on @state\n    Args:\n        state (dict or n-array): Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n            a (potentially nested) dictionary of states for this object\n    \"\"\"\nstate = cls.deserialize(state=state) if serialized else state\ncls._load_state(state=state)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.serialize","title":"<code>serialize(state)</code>  <code>classmethod</code>","text":"<p>Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency. Should be implemented by subclass.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict</code> <p>Keyword-mapped states of this object to encode. Should match structure of output from self._dump_state()</p> required <p>Returns:</p> Type Description <p>n-array: encoded + serialized, 1D numerical np.array capturing this object's state</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>@classmethod\ndef serialize(cls, state):\n\"\"\"\n    Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n    Should be implemented by subclass.\n    Args:\n        state (dict): Keyword-mapped states of this object to encode. Should match structure of output from\n            self._dump_state()\n    Returns:\n        n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n    \"\"\"\n# Simply returns self._serialize() for now. this is for future proofing\nreturn cls._serialize(state=state)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.state_size","title":"<code>state_size()</code>","text":"<p>Returns:</p> Name Type Description <code>int</code> <p>Size of this object's serialized state</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>@classproperty\ndef state_size(cls):\n\"\"\"\n    Returns:\n        int: Size of this object's serialized state\n    \"\"\"\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamed","title":"<code>UniquelyNamed</code>","text":"<p>Simple class that implements a name property, that must be implemented by a subclass. Note that any @Named entity must be UNIQUE!</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class UniquelyNamed:\n\"\"\"\n    Simple class that implements a name property, that must be implemented by a subclass. Note that any @Named\n    entity must be UNIQUE!\n    \"\"\"\ndef __init__(self, *args, **kwargs):\nglobal NAMES\n# Register this object, making sure it's name is unique\nassert self.name not in NAMES, \\\n            f\"UniquelyNamed object with name {self.name} already exists!\"\nNAMES.add(self.name)\n# def __del__(self):\n#     # Remove this object name from the registry if it's still there\n#     self.remove_names(include_all_owned=True)\ndef remove_names(self, include_all_owned=True, skip_ids=None):\n\"\"\"\n        Checks if self.name exists in the global NAMES registry, and deletes it if so. Possibly also iterates through\n        all owned member variables and checks for their corresponding names if @include_all_owned is True.\n        Args:\n            include_all_owned (bool): If True, will iterate through all owned members of this instance and remove their\n                names as well, if they are UniquelyNamed\n            skip_ids (None or set of int): If specified, will skip over any ids in the specified set that are matched\n                to any attributes found (this compares id(attr) to @skip_ids).\n        \"\"\"\n# Make sure skip_ids is a set so we can pass this into the method, and add the dictionary so we don't\n# get infinite recursive loops\nskip_ids = set() if skip_ids is None else skip_ids\nskip_ids.add(id(self))\n# Check for this name, possibly remove it if it exists\nif self.name in NAMES:\nNAMES.remove(self.name)\n# Also possibly iterate through all owned members and check if those are instances of UniquelyNamed\nif include_all_owned:\nself._remove_names_recursively_from_dict(dic=self.__dict__, skip_ids=skip_ids)\ndef _remove_names_recursively_from_dict(self, dic, skip_ids=None):\n\"\"\"\n        Checks if self.name exists in the global NAMES registry, and deletes it if so\n        Args:\n            skip_ids (None or set): If specified, will skip over any objects in the specified set that are matched\n                to any attributes found.\n        \"\"\"\n# Make sure skip_ids is a set so we can pass this into the method, and add the dictionary so we don't\n# get infinite recursive loops\nskip_ids = set() if skip_ids is None else skip_ids\nskip_ids.add(id(dic))\n# Loop through all values in the inputted dictionary, and check if any of the values are UniquelyNamed\nfor name, val in dic.items():\nif id(val) not in skip_ids:\n# No need to explicitly add val to skip objects because the methods below handle adding it\nif isinstance(val, UniquelyNamed):\nval.remove_names(include_all_owned=True, skip_ids=skip_ids)\nelif isinstance(val, dict):\n# Recursively iterate\nself._remove_names_recursively_from_dict(dic=val, skip_ids=skip_ids)\nelif hasattr(val, \"__dict__\"):\n# Add the attribute and recursively iterate\nskip_ids.add(id(val))\nself._remove_names_recursively_from_dict(dic=val.__dict__, skip_ids=skip_ids)\nelse:\n# Otherwise we just add the value to skip_ids so we don't check it again\nskip_ids.add(id(val))\n@property\ndef name(self):\n\"\"\"\n        Returns:\n            str: Name of this instance. Must be unique!\n        \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamed.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this instance. Must be unique!</p>"},{"location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamed.remove_names","title":"<code>remove_names(include_all_owned=True, skip_ids=None)</code>","text":"<p>Checks if self.name exists in the global NAMES registry, and deletes it if so. Possibly also iterates through all owned member variables and checks for their corresponding names if @include_all_owned is True.</p> <p>Parameters:</p> Name Type Description Default <code>include_all_owned</code> <code>bool</code> <p>If True, will iterate through all owned members of this instance and remove their names as well, if they are UniquelyNamed</p> <code>True</code> <code>skip_ids</code> <code>None or set of int</code> <p>If specified, will skip over any ids in the specified set that are matched to any attributes found (this compares id(attr) to @skip_ids).</p> <code>None</code> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def remove_names(self, include_all_owned=True, skip_ids=None):\n\"\"\"\n    Checks if self.name exists in the global NAMES registry, and deletes it if so. Possibly also iterates through\n    all owned member variables and checks for their corresponding names if @include_all_owned is True.\n    Args:\n        include_all_owned (bool): If True, will iterate through all owned members of this instance and remove their\n            names as well, if they are UniquelyNamed\n        skip_ids (None or set of int): If specified, will skip over any ids in the specified set that are matched\n            to any attributes found (this compares id(attr) to @skip_ids).\n    \"\"\"\n# Make sure skip_ids is a set so we can pass this into the method, and add the dictionary so we don't\n# get infinite recursive loops\nskip_ids = set() if skip_ids is None else skip_ids\nskip_ids.add(id(self))\n# Check for this name, possibly remove it if it exists\nif self.name in NAMES:\nNAMES.remove(self.name)\n# Also possibly iterate through all owned members and check if those are instances of UniquelyNamed\nif include_all_owned:\nself._remove_names_recursively_from_dict(dic=self.__dict__, skip_ids=skip_ids)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamedNonInstance","title":"<code>UniquelyNamedNonInstance</code>","text":"<p>Identical to UniquelyNamed, but intended for non-instanceable classes</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>class UniquelyNamedNonInstance:\n\"\"\"\n    Identical to UniquelyNamed, but intended for non-instanceable classes\n    \"\"\"\ndef __init_subclass__(cls, **kwargs):\nglobal CLASS_NAMES\n# Register this object, making sure it's name is unique\nassert cls.name not in CLASS_NAMES, \\\n            f\"UniquelyNamed class with name {cls.name} already exists!\"\nCLASS_NAMES.add(cls.name)\n@classproperty\ndef name(cls):\n\"\"\"\n        Returns:\n            str: Name of this instance. Must be unique!\n        \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamedNonInstance.name","title":"<code>name()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>Name of this instance. Must be unique!</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>@classproperty\ndef name(cls):\n\"\"\"\n    Returns:\n        str: Name of this instance. Must be unique!\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.assert_valid_key","title":"<code>assert_valid_key(key, valid_keys, name=None)</code>","text":"<p>Helper function that asserts that @key is in dictionary @valid_keys keys. If not, it will raise an error.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>any</code> <p>key to check for in dictionary @dic's keys</p> required <code>valid_keys</code> <code>Iterable</code> <p>contains keys should be checked with @key</p> required <code>name</code> <code>str or None</code> <p>if specified, is the name associated with the key that will be printed out if the key is not found. If None, default is \"value\"</p> <code>None</code> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def assert_valid_key(key, valid_keys, name=None):\n\"\"\"\n    Helper function that asserts that @key is in dictionary @valid_keys keys. If not, it will raise an error.\n    Args:\n        key (any): key to check for in dictionary @dic's keys\n        valid_keys (Iterable): contains keys should be checked with @key\n        name (str or None): if specified, is the name associated with the key that will be printed out if the\n            key is not found. If None, default is \"value\"\n    \"\"\"\nif name is None:\nname = \"value\"\nassert key in valid_keys, \"Invalid {} received! Valid options are: {}, got: {}\".format(\nname, valid_keys.keys() if isinstance(valid_keys, dict) else valid_keys, key)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.camel_case_to_snake_case","title":"<code>camel_case_to_snake_case(camel_case_text)</code>","text":"<p>Helper function to convert a camel case text to snake case, e.g. \"StrawberrySmoothie\" -&gt; \"strawberry_smoothie\"</p> <p>Parameters:</p> Name Type Description Default <code>camel_case_text</code> <code>str</code> <p>Text in camel case</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>snake case text</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def camel_case_to_snake_case(camel_case_text):\n\"\"\"\n    Helper function to convert a camel case text to snake case, e.g. \"StrawberrySmoothie\" -&gt; \"strawberry_smoothie\"\n    Args:\n        camel_case_text (str): Text in camel case\n    Returns:\n        str: snake case text\n    \"\"\"\nreturn re.sub(r'(?&lt;!^)(?=[A-Z])', '_', camel_case_text).lower()\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.clear","title":"<code>clear()</code>","text":"<p>Clear state tied to singleton classes</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def clear():\n\"\"\"\n    Clear state tied to singleton classes\n    \"\"\"\nNAMES.clear()\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.create_class_from_registry_and_config","title":"<code>create_class_from_registry_and_config(cls_name, cls_registry, cfg, cls_type_descriptor)</code>","text":"<p>Helper function to create a class with str type @cls_name, which should be a valid entry in @cls_registry, using kwargs in dictionary form @cfg to pass to the constructor, with @cls_type_name specified for debugging</p> <p>Parameters:</p> Name Type Description Default <code>cls_name</code> <code>str</code> <p>Name of the class to create. This should correspond to the actual class type, in string form</p> required <code>cls_registry</code> <code>dict</code> <p>Class registry. This should map string names of valid classes to create to the actual class type itself</p> required <code>cfg</code> <code>dict</code> <p>Any keyword arguments to pass to the class constructor</p> required <code>cls_type_descriptor</code> <code>str</code> <p>Description of the class type being created. This can be any string and is used solely for debugging purposes</p> required <p>Returns:</p> Name Type Description <code>any</code> <p>Created class instance</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def create_class_from_registry_and_config(cls_name, cls_registry, cfg, cls_type_descriptor):\n\"\"\"\n    Helper function to create a class with str type @cls_name, which should be a valid entry in @cls_registry, using\n    kwargs in dictionary form @cfg to pass to the constructor, with @cls_type_name specified for debugging\n    Args:\n        cls_name (str): Name of the class to create. This should correspond to the actual class type, in string form\n        cls_registry (dict): Class registry. This should map string names of valid classes to create to the\n            actual class type itself\n        cfg (dict): Any keyword arguments to pass to the class constructor\n        cls_type_descriptor (str): Description of the class type being created. This can be any string and is used\n            solely for debugging purposes\n    Returns:\n        any: Created class instance\n    \"\"\"\n# Make sure the requested class type is valid\nassert_valid_key(key=cls_name, valid_keys=cls_registry, name=f\"{cls_type_descriptor} type\")\n# Grab the kwargs relevant for the specific class\ncls = cls_registry[cls_name]\ncls_kwargs = extract_class_init_kwargs_from_dict(cls=cls, dic=cfg, copy=False)\n# Create the class\nreturn cls(**cls_kwargs)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.create_object_from_init_info","title":"<code>create_object_from_init_info(init_info)</code>","text":"<p>Create a new object based on an given init info.</p> <p>Parameters:</p> Name Type Description Default <code>init_info</code> <code>dict</code> <p>Nested dictionary that contains an object's init information.</p> required <p>Returns:</p> Name Type Description <code>any</code> <p>Newly created object.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def create_object_from_init_info(init_info):\n\"\"\"\n    Create a new object based on an given init info.\n    Args:\n        init_info (dict): Nested dictionary that contains an object's init information.\n    Returns:\n        any: Newly created object.\n    \"\"\"\nmodule = import_module(init_info[\"class_module\"])\ncls = getattr(module, init_info[\"class_name\"])\nreturn cls(**init_info[\"args\"], **init_info.get(\"kwargs\", {}))\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.extract_class_init_kwargs_from_dict","title":"<code>extract_class_init_kwargs_from_dict(cls, dic, copy=False)</code>","text":"<p>Helper function to return a dictionary of key-values that specifically correspond to @cls class's init constructor method, from @dic which may or may not contain additional, irrelevant kwargs. Note that @dic may possibly be missing certain kwargs as specified by cls.init. No error will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>object</code> <p>Class from which to grab init kwargs that will be be used as filtering keys for @dic</p> required <code>dic</code> <code>dict</code> <p>Dictionary containing multiple key-values</p> required <code>copy</code> <code>bool</code> <p>If True, will deepcopy all values corresponding to the specified @keys</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Extracted subset dictionary possibly containing only the specified keys from cls.init and their corresponding values</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def extract_class_init_kwargs_from_dict(cls, dic, copy=False):\n\"\"\"\n    Helper function to return a dictionary of key-values that specifically correspond to @cls class's __init__\n    constructor method, from @dic which may or may not contain additional, irrelevant kwargs.\n    Note that @dic may possibly be missing certain kwargs as specified by cls.__init__. No error will be raised.\n    Args:\n        cls (object): Class from which to grab __init__ kwargs that will be be used as filtering keys for @dic\n        dic (dict): Dictionary containing multiple key-values\n        copy (bool): If True, will deepcopy all values corresponding to the specified @keys\n    Returns:\n        dict: Extracted subset dictionary possibly containing only the specified keys from cls.__init__ and their\n            corresponding values\n    \"\"\"\n# extract only relevant kwargs for this specific backbone\nreturn extract_subset_dict(\ndic=dic,\nkeys=get_class_init_kwargs(cls),\ncopy=copy,\n)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.extract_subset_dict","title":"<code>extract_subset_dict(dic, keys, copy=False)</code>","text":"<p>Helper function to extract a subset of dictionary key-values from a current dictionary. Optionally (deep)copies the values extracted from the original @dic if @copy is True.</p> <p>Parameters:</p> Name Type Description Default <code>dic</code> <code>dict</code> <p>Dictionary containing multiple key-values</p> required <code>keys</code> <code>Iterable</code> <p>Specific keys to extract from @dic. If the key doesn't exist in @dic, then the key is skipped</p> required <code>copy</code> <code>bool</code> <p>If True, will deepcopy all values corresponding to the specified @keys</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Extracted subset dictionary containing only the specified @keys and their corresponding values</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def extract_subset_dict(dic, keys, copy=False):\n\"\"\"\n    Helper function to extract a subset of dictionary key-values from a current dictionary. Optionally (deep)copies\n    the values extracted from the original @dic if @copy is True.\n    Args:\n        dic (dict): Dictionary containing multiple key-values\n        keys (Iterable): Specific keys to extract from @dic. If the key doesn't exist in @dic, then the key is skipped\n        copy (bool): If True, will deepcopy all values corresponding to the specified @keys\n    Returns:\n        dict: Extracted subset dictionary containing only the specified @keys and their corresponding values\n    \"\"\"\nsubset = {k: dic[k] for k in keys if k in dic}\nreturn deepcopy(subset) if copy else subset\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.get_class_init_kwargs","title":"<code>get_class_init_kwargs(cls)</code>","text":"<p>Helper function to return a list of all valid keyword arguments (excluding \"self\") for the given @cls class.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>object</code> <p>Class from which to grab init kwargs</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>All keyword arguments (excluding \"self\") specified by @cls init constructor method</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def get_class_init_kwargs(cls):\n\"\"\"\n    Helper function to return a list of all valid keyword arguments (excluding \"self\") for the given @cls class.\n    Args:\n        cls (object): Class from which to grab __init__ kwargs\n    Returns:\n        list: All keyword arguments (excluding \"self\") specified by @cls __init__ constructor method\n    \"\"\"\nreturn list(inspect.signature(cls.__init__).parameters.keys())[1:]\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.get_uuid","title":"<code>get_uuid(name, n_digits=8)</code>","text":"<p>Helper function to create a unique @n_digits uuid given a unique @name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the object or class</p> required <code>n_digits</code> <code>int</code> <p>Number of digits of the uuid, default is 8</p> <code>8</code> <p>Returns:</p> Name Type Description <code>int</code> <p>uuid</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def get_uuid(name, n_digits=8):\n\"\"\"\n    Helper function to create a unique @n_digits uuid given a unique @name\n    Args:\n        name (str): Name of the object or class\n        n_digits (int): Number of digits of the uuid, default is 8\n    Returns:\n        int: uuid\n    \"\"\"\nreturn abs(hash(name)) % (10 ** n_digits)\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.merge_nested_dicts","title":"<code>merge_nested_dicts(base_dict, extra_dict, inplace=False, verbose=False)</code>","text":"<p>Iteratively updates @base_dict with values from @extra_dict. Note: This generates a new dictionary!</p> <p>Parameters:</p> Name Type Description Default <code>base_dict</code> <code>dict</code> <p>Nested base dictionary, which should be updated with all values from @extra_dict</p> required <code>extra_dict</code> <code>dict</code> <p>Nested extra dictionary, whose values will overwrite corresponding ones in @base_dict</p> required <code>inplace</code> <code>bool</code> <p>Whether to modify @base_dict in place or not</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, will print when keys are mismatched</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Updated dictionary</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def merge_nested_dicts(base_dict, extra_dict, inplace=False, verbose=False):\n\"\"\"\n    Iteratively updates @base_dict with values from @extra_dict. Note: This generates a new dictionary!\n    Args:\n        base_dict (dict): Nested base dictionary, which should be updated with all values from @extra_dict\n        extra_dict (dict): Nested extra dictionary, whose values will overwrite corresponding ones in @base_dict\n        inplace (bool): Whether to modify @base_dict in place or not\n        verbose (bool): If True, will print when keys are mismatched\n    Returns:\n        dict: Updated dictionary\n    \"\"\"\n# Loop through all keys in @extra_dict and update the corresponding values in @base_dict\nbase_dict = base_dict if inplace else deepcopy(base_dict)\nfor k, v in extra_dict.items():\nif k not in base_dict:\nbase_dict[k] = v\nelse:\nif isinstance(v, dict) and isinstance(base_dict[k], dict):\nbase_dict[k] = merge_nested_dicts(base_dict[k], v)\nelse:\nnot_equal = base_dict[k] != v\nif isinstance(not_equal, np.ndarray):\nnot_equal = not_equal.any()\nif not_equal and verbose:\nprint(f\"Different values for key {k}: {base_dict[k]}, {v}\\n\")\nbase_dict[k] = np.array(v) if isinstance(v, list) else v\n# Return new dict\nreturn base_dict\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.save_init_info","title":"<code>save_init_info(func)</code>","text":"<p>Decorator to save the init info of an object to object._init_info.</p> <p>_init_info contains class name and class constructor's input args.</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def save_init_info(func):\n\"\"\"\n    Decorator to save the init info of an object to object._init_info.\n    _init_info contains class name and class constructor's input args.\n    \"\"\"\nsig = inspect.signature(func)\n@wraps(func) # preserve func name, docstring, arguments list, etc.\ndef wrapper(self, *args, **kwargs):\nvalues = sig.bind(self, *args, **kwargs)\n# Prevent args of super init from being saved.\nif hasattr(self, \"_init_info\"):\nfunc(*values.args, **values.kwargs)\nreturn\n# Initialize class's self._init_info.\nself._init_info = {}\nself._init_info[\"class_module\"] = self.__class__.__module__\nself._init_info[\"class_name\"] = self.__class__.__name__\nself._init_info[\"args\"] = {}\n# Populate class's self._init_info.\nfor k, p in sig.parameters.items():\nif k == 'self':\ncontinue\nif k in values.arguments:\nval = values.arguments[k]\nif p.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD, inspect.Parameter.KEYWORD_ONLY):\nself._init_info[\"args\"][k] = val\nelif p.kind == inspect.Parameter.VAR_KEYWORD:\nfor kwarg_k, kwarg_val in values.arguments[k].items():\nself._init_info[\"args\"][kwarg_k] = kwarg_val\n# Call the original function.\nfunc(*values.args, **values.kwargs)\nreturn wrapper\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.snake_case_to_camel_case","title":"<code>snake_case_to_camel_case(snake_case_text)</code>","text":"<p>Helper function to convert a snake case text to camel case, e.g. \"strawberry_smoothie\" -&gt; \"StrawberrySmoothie\"</p> <p>Parameters:</p> Name Type Description Default <code>snake_case_text</code> <code>str</code> <p>Text in snake case</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>camel case text</p> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def snake_case_to_camel_case(snake_case_text):\n\"\"\"\n    Helper function to convert a snake case text to camel case, e.g. \"strawberry_smoothie\" -&gt; \"StrawberrySmoothie\"\n    Args:\n        snake_case_text (str): Text in snake case\n    Returns:\n        str: camel case text\n    \"\"\"\nreturn ''.join(item.title() for item in snake_case_text.split('_'))\n</code></pre>"},{"location":"reference/utils/python_utils.html#utils.python_utils.subclass_factory","title":"<code>subclass_factory(name, base_classes, __init__=None, **kwargs)</code>","text":"<p>Programmatically generates a new class type with name @name, subclassing from base classes @base_classes, with corresponding init call @init.</p> <p>NOTE: If init is None (default), the init call from @base_classes will be used instead.</p> <p>cf. https://stackoverflow.com/questions/15247075/how-can-i-dynamically-create-derived-classes-from-a-base-class</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Generated class name</p> required <code>base_classes</code> <code>type, or list of type</code> <p>Base class(es) to use for generating the subclass</p> required <code>__init__</code> <code>None or function</code> <p>Init call to use for the base class when it is instantiated. If None if specified, the newly generated class will automatically inherit the init call from @base_classes</p> <code>None</code> <code>**kwargs</code> <code>any</code> <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class / instance attribute to modify and the values represent the functions / value to set</p> <code>{}</code> Source code in <code>omnigibson/utils/python_utils.py</code> <pre><code>def subclass_factory(name, base_classes, __init__=None, **kwargs):\n\"\"\"\n    Programmatically generates a new class type with name @name, subclassing from base classes @base_classes, with\n    corresponding __init__ call @__init__.\n    NOTE: If __init__ is None (default), the __init__ call from @base_classes will be used instead.\n    cf. https://stackoverflow.com/questions/15247075/how-can-i-dynamically-create-derived-classes-from-a-base-class\n    Args:\n        name (str): Generated class name\n        base_classes (type, or list of type): Base class(es) to use for generating the subclass\n        __init__ (None or function): Init call to use for the base class when it is instantiated. If None if specified,\n            the newly generated class will automatically inherit the __init__ call from @base_classes\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class / instance attribute to modify and the values represent the functions / value to set\n    \"\"\"\n# Standardize base_classes\nbase_classes = tuple(base_classes if isinstance(base_classes, Iterable) else [base_classes])\n# Generate the new class\nif __init__ is not None:\nkwargs[\"__init__\"] = __init__\nreturn type(name, base_classes, kwargs)\n</code></pre>"},{"location":"reference/utils/registry_utils.html","title":"registry_utils","text":"<p>A set of utility functions for registering and tracking objects</p>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry","title":"<code>Registry</code>","text":"<p>         Bases: <code>UniquelyNamed</code></p> <p>Simple class for easily registering and tracking arbitrary objects of the same (or very similar) class types.</p> <p>Elements added are automatically organized by attributes specified by @unique_keys and @group_keys, and can be accessed at runtime by specifying the desired key and indexing value to grab the object(s).</p> i.e.: a single indexing value will return a single object. <p>default: \"name\" -- indexing by object.name (i.e.: every object's name should be unique)</p> i.e.: a single indexing value will return a single object. <p>example: indexing by object.name (every object's name should be unique)</p> i.e.: a single indexing value will return a set of objects. <p>example: indexing by object.in_rooms (many objects can be in a single room)</p> <p>Note that if a object's attribute is an array of values, then it will be stored under ALL of its values.     example: object.in_rooms = [\"kitchen\", \"living_room\"], indexing by in_rooms with a value of either kitchen OR         living room will return this object as part of its set!</p> <p>You can also easily check for membership in this registry, via either the object's name OR the object itself, e.g.:</p> <pre><code>&gt; object.name in registry\n&gt; object in registry\n\nIf the latter, note that default_key attribute will automatically be used to search for the object\n</code></pre> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>class Registry(UniquelyNamed):\n\"\"\"\n    Simple class for easily registering and tracking arbitrary objects of the same (or very similar) class types.\n    Elements added are automatically organized by attributes specified by @unique_keys and @group_keys, and\n    can be accessed at runtime by specifying the desired key and indexing value to grab the object(s).\n    Default_key is a 1-to-1 mapping: i.e.: a single indexing value will return a single object.\n        default: \"name\" -- indexing by object.name (i.e.: every object's name should be unique)\n    Unique_keys are other 1-to-1 mappings: i.e.: a single indexing value will return a single object.\n        example: indexing by object.name (every object's name should be unique)\n    Group_keys are 1-to-many mappings: i.e.: a single indexing value will return a set of objects.\n        example: indexing by object.in_rooms (many objects can be in a single room)\n    Note that if a object's attribute is an array of values, then it will be stored under ALL of its values.\n        example: object.in_rooms = [\"kitchen\", \"living_room\"], indexing by in_rooms with a value of either kitchen OR\n            living room will return this object as part of its set!\n    You can also easily check for membership in this registry, via either the object's name OR the object itself,\n    e.g.:\n        &gt; object.name in registry\n        &gt; object in registry\n        If the latter, note that default_key attribute will automatically be used to search for the object\n    \"\"\"\ndef __init__(\nself,\nname,\nclass_types=object,\ndefault_key=\"name\",\nunique_keys=None,\ngroup_keys=None,\ndefault_value=m.DOES_NOT_EXIST,\n):\n\"\"\"\n        Args:\n            name (str): name of this registry\n            class_types (class or list of class): class expected for all entries in this registry. Default is `object`,\n                meaning any object entered will be accepted. This is used to sanity check added entries using add()\n                to make sure their type is correct (either that the entry itself is a valid class, or that they are an\n                object of the valid class). Note that if a list of classes are passed, any one of the classes are\n                considered a valid type for added objects\n            default_key (str): default key by which to reference a given object. This key should be a\n                publically accessible attribute in a given object (e.g.: object.name) and uniquely identify\n                any entries\n            unique_keys (None or list of str): keys by which to reference a given object. Any key should be a\n                publically accessible attribute in a given object (e.g.: object.name)\n                i.e.: these keys should map to a single object\n            group_keys (None or list of str): keys by which to reference a group of objects, based on the key\n                (e.g.: object.room)\n                i.e.: these keys can map to multiple objects\n                e.g.: default is \"name\" key only, so we will store objects by their object.name attribute\n            default_value (any): Default value to use if the attribute @key does not exist in the object\n        \"\"\"\nself._name = name\nself.class_types = class_types if isinstance(class_types, Iterable) else [class_types]\nself.default_key = default_key\nself.unique_keys = set([] if unique_keys is None else unique_keys)\nself.group_keys = set([] if group_keys is None else group_keys)\nself.default_value = default_value\n# We always add in the \"name\" attribute as well\nself.unique_keys.add(self.default_key)\n# Make sure there's no overlap between the unique and group keys\nassert len(self.unique_keys.intersection(self.group_keys)) == 0,\\\n            f\"Cannot create registry with unique and group object keys that are the same! \" \\\n            f\"Unique keys: {self.unique_keys}, group keys: {self.group_keys}\"\n# Create the dicts programmatically\nfor k in self.unique_keys.union(self.group_keys):\nself.__setattr__(f\"_objects_by_{k}\", dict())\n# Run super init\nsuper().__init__()\n@property\ndef name(self):\nreturn self._name\ndef add(self, obj):\n\"\"\"\n        Adds Instance @obj to this registry\n        Args:\n            obj (any): Instance to add to this registry\n        \"\"\"\n# Make sure that obj is of the correct class type\nassert any([isinstance(obj, class_type) or issubclass(obj, class_type) for class_type in self.class_types]), \\\n            f\"Added object must be either an instance or subclass of one of the following classes: {self.class_types}!\"\nself._add(obj=obj, keys=self.all_keys)\ndef _add(self, obj, keys=None):\n\"\"\"\n        Same as self.add, but allows for selective @keys for adding this object to. Useful for internal things,\n        such as internal updating of mappings\n        Args:\n            obj (any): Instance to add to this registry\n            keys (None or set or list of str): Which object keys to use for adding the object to mappings.\n                None is default, which corresponds to all keys\n        \"\"\"\nkeys = self.all_keys if keys is None else keys\nfor k in keys:\nobj_attr = self._get_obj_attr(obj=obj, attr=k)\n# Standardize input as a list\nobj_attr = obj_attr if \\\n                isinstance(obj_attr, Iterable) and not isinstance(obj_attr, str) else [obj_attr]\n# Loop over all values in this attribute and add to all mappings\nfor attr in obj_attr:\nmapping = self.get_dict(k)\nif k in self.unique_keys:\n# Handle unique case\nif attr in mapping:\nlog.warning(f\"Instance identifier '{k}' should be unique for adding to this registry mapping! Existing {k}: {attr}\")\n# Special case for \"name\" attribute, which should ALWAYS be unique\nif k == \"name\":\nlog.error(f\"For name attribute, objects MUST be unique. Exiting.\")\nexit(-1)\nmapping[attr] = obj\nelse:\n# Not unique case\n# Possibly initialize list\nif attr not in mapping:\nmapping[attr] = set()\nmapping[attr].add(obj)\ndef remove(self, obj):\n\"\"\"\n        Removes object @object from this registry\n        Args:\n            obj (any): Instance to remove from this registry\n        \"\"\"\n# Iterate over all keys\nfor k in self.all_keys:\n# Grab the attribute from the object\nobj_attr = self._get_obj_attr(obj=obj, attr=k)\n# Standardize input as a list\nobj_attr = obj_attr if \\\n                isinstance(obj_attr, Iterable) and not isinstance(obj_attr, str) else [obj_attr]\n# Loop over all values in this attribute and remove them from all mappings\nfor attr in obj_attr:\nmapping = self.get_dict(k)\nif k in self.unique_keys:\n# Handle unique case -- in this case, we just directly pop the value from the dictionary\nmapping.pop(attr)\nelse:\n# Not unique case\n# We remove a value from the resulting set\nmapping[attr].remove(obj)\ndef clear(self):\n\"\"\"\n        Removes all owned objects from this registry\n        \"\"\"\n# Re-create the owned dicts programmatically\nfor k in self.unique_keys.union(self.group_keys):\nself.__setattr__(f\"_objects_by_{k}\", dict())\ndef update(self, keys=None):\n\"\"\"\n        Updates this registry, refreshing all internal mappings in case an object's value was updated\n        Args:\n            keys (None or str or set or list of str): Which object keys to update. None is default, which corresponds\n                to all keys\n        \"\"\"\nobjects = self.objects\nkeys = self.all_keys if keys is None else \\\n            (keys if type(keys) in {tuple, list} else [keys])\n# Delete and re-create all keys mappings\nfor k in keys:\nself.__delattr__(f\"_objects_by_{k}\")\nself.__setattr__(f\"_objects_by_{k}\", dict())\n# Iterate over all objects and re-populate the mappings\nfor obj in objects:\nself._add(obj=obj, keys=[k])\ndef object_is_registered(self, obj):\n\"\"\"\n        Check if a given object @object is registered\n        Args:\n            obj (any): Instance to check if it is internally registered\n        \"\"\"\nreturn obj in self.objects\ndef get_dict(self, key):\n\"\"\"\n        Specific mapping dictionary within this registry corresponding to the mappings of @key.\n            e.g.: if key = \"name\", this will return the dictionary mapping object.name to objects\n        Args:\n            key (str): Key with which to grab mapping dict from\n        Returns:\n            dict: Mapping from identifiers to object(s) based on @key\n        \"\"\"\nreturn getattr(self, f\"_objects_by_{key}\")\ndef get_ids(self, key):\n\"\"\"\n        All identifiers within this registry corresponding to the mappings of @key.\n            e.g.: if key = \"name\", this will return all \"names\" stored internally that index into a object\n        Args:\n            key (str): Key with which to grab all identifiers from\n        Returns:\n            set: All identifiers within this registry corresponding to the mappings of @key.\n        \"\"\"\nreturn set(self.get_dict(key=key).keys())\ndef _get_obj_attr(self, obj, attr):\n\"\"\"\n        Grabs object's @obj's attribute @attr. Additionally checks to see if @obj is a class or a class instance, and\n        uses the correct logic\n        Args:\n            obj (any): Object to grab attribute from\n            attr (str): String name of the attribute to grab\n        Return:\n            any: Attribute @k of @obj\n        \"\"\"\n# We try to grab the object's attribute, and if it fails we fallback to the default value\ntry:\nval = getattr(obj, attr)\nexcept:\nval = self.default_value\nreturn val\n@property\ndef objects(self):\n\"\"\"\n        Get the objects in this registry\n        Returns:\n            list of any: Instances owned by this registry\n        \"\"\"\nreturn list(self.get_dict(self.default_key).values())\n@property\ndef all_keys(self):\n\"\"\"\n        Returns:\n            set of str: All object keys that are valid identification methods to index object(s)\n        \"\"\"\nreturn self.unique_keys.union(self.group_keys)\ndef __call__(self, key, value, default_val=None):\n\"\"\"\n        Grab the object in this registry based on @key and @value\n        Args:\n            key (str): What identification type to use to grab the requested object(s).\n                Should be one of @self.all_keys.\n            value (any): Value to grab. Should be the value of your requested object.&lt;key&gt; attribute\n            default_val (any): Default value to return if @value is not found\n        Returns:\n            any or set of any: requested unique object if @key is one of unique_keys, else a set if\n                @key is one of group_keys\n        \"\"\"\nassert key in self.all_keys,\\\n            f\"Invalid key requested! Valid options are: {self.all_keys}, got: {key}\"\nreturn self.get_dict(key).get(value, default_val)\ndef __contains__(self, obj):\n# Instance can be either a string (default key) OR the object itself\nif isinstance(obj, str):\nobj = self(self.default_key, obj)\nreturn self.object_is_registered(obj=obj)\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.all_keys","title":"<code>all_keys</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <p>set of str: All object keys that are valid identification methods to index object(s)</p>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.objects","title":"<code>objects</code>  <code>property</code>","text":"<p>Get the objects in this registry</p> <p>Returns:</p> Type Description <p>list of any: Instances owned by this registry</p>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.__call__","title":"<code>__call__(key, value, default_val=None)</code>","text":"<p>Grab the object in this registry based on @key and @value</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>What identification type to use to grab the requested object(s). Should be one of @self.all_keys.</p> required <code>value</code> <code>any</code> <p>Value to grab. Should be the value of your requested object. attribute required <code>default_val</code> <code>any</code> <p>Default value to return if @value is not found</p> <code>None</code> <p>Returns:</p> Type Description <p>any or set of any: requested unique object if @key is one of unique_keys, else a set if @key is one of group_keys</p> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def __call__(self, key, value, default_val=None):\n\"\"\"\n    Grab the object in this registry based on @key and @value\n    Args:\n        key (str): What identification type to use to grab the requested object(s).\n            Should be one of @self.all_keys.\n        value (any): Value to grab. Should be the value of your requested object.&lt;key&gt; attribute\n        default_val (any): Default value to return if @value is not found\n    Returns:\n        any or set of any: requested unique object if @key is one of unique_keys, else a set if\n            @key is one of group_keys\n    \"\"\"\nassert key in self.all_keys,\\\n        f\"Invalid key requested! Valid options are: {self.all_keys}, got: {key}\"\nreturn self.get_dict(key).get(value, default_val)\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.__init__","title":"<code>__init__(name, class_types=object, default_key='name', unique_keys=None, group_keys=None, default_value=m.DOES_NOT_EXIST)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of this registry</p> required <code>class_types</code> <code>class or list of class</code> <p>class expected for all entries in this registry. Default is <code>object</code>, meaning any object entered will be accepted. This is used to sanity check added entries using add() to make sure their type is correct (either that the entry itself is a valid class, or that they are an object of the valid class). Note that if a list of classes are passed, any one of the classes are considered a valid type for added objects</p> <code>object</code> <code>default_key</code> <code>str</code> <p>default key by which to reference a given object. This key should be a publically accessible attribute in a given object (e.g.: object.name) and uniquely identify any entries</p> <code>'name'</code> <code>unique_keys</code> <code>None or list of str</code> <p>keys by which to reference a given object. Any key should be a publically accessible attribute in a given object (e.g.: object.name) i.e.: these keys should map to a single object</p> <code>None</code> <code>group_keys</code> <code>None or list of str</code> <p>keys by which to reference a group of objects, based on the key (e.g.: object.room) i.e.: these keys can map to multiple objects</p> <p>e.g.: default is \"name\" key only, so we will store objects by their object.name attribute</p> <code>None</code> <code>default_value</code> <code>any</code> <p>Default value to use if the attribute @key does not exist in the object</p> <code>m.DOES_NOT_EXIST</code> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def __init__(\nself,\nname,\nclass_types=object,\ndefault_key=\"name\",\nunique_keys=None,\ngroup_keys=None,\ndefault_value=m.DOES_NOT_EXIST,\n):\n\"\"\"\n    Args:\n        name (str): name of this registry\n        class_types (class or list of class): class expected for all entries in this registry. Default is `object`,\n            meaning any object entered will be accepted. This is used to sanity check added entries using add()\n            to make sure their type is correct (either that the entry itself is a valid class, or that they are an\n            object of the valid class). Note that if a list of classes are passed, any one of the classes are\n            considered a valid type for added objects\n        default_key (str): default key by which to reference a given object. This key should be a\n            publically accessible attribute in a given object (e.g.: object.name) and uniquely identify\n            any entries\n        unique_keys (None or list of str): keys by which to reference a given object. Any key should be a\n            publically accessible attribute in a given object (e.g.: object.name)\n            i.e.: these keys should map to a single object\n        group_keys (None or list of str): keys by which to reference a group of objects, based on the key\n            (e.g.: object.room)\n            i.e.: these keys can map to multiple objects\n            e.g.: default is \"name\" key only, so we will store objects by their object.name attribute\n        default_value (any): Default value to use if the attribute @key does not exist in the object\n    \"\"\"\nself._name = name\nself.class_types = class_types if isinstance(class_types, Iterable) else [class_types]\nself.default_key = default_key\nself.unique_keys = set([] if unique_keys is None else unique_keys)\nself.group_keys = set([] if group_keys is None else group_keys)\nself.default_value = default_value\n# We always add in the \"name\" attribute as well\nself.unique_keys.add(self.default_key)\n# Make sure there's no overlap between the unique and group keys\nassert len(self.unique_keys.intersection(self.group_keys)) == 0,\\\n        f\"Cannot create registry with unique and group object keys that are the same! \" \\\n        f\"Unique keys: {self.unique_keys}, group keys: {self.group_keys}\"\n# Create the dicts programmatically\nfor k in self.unique_keys.union(self.group_keys):\nself.__setattr__(f\"_objects_by_{k}\", dict())\n# Run super init\nsuper().__init__()\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.add","title":"<code>add(obj)</code>","text":"<p>Adds Instance @obj to this registry</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>any</code> <p>Instance to add to this registry</p> required Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def add(self, obj):\n\"\"\"\n    Adds Instance @obj to this registry\n    Args:\n        obj (any): Instance to add to this registry\n    \"\"\"\n# Make sure that obj is of the correct class type\nassert any([isinstance(obj, class_type) or issubclass(obj, class_type) for class_type in self.class_types]), \\\n        f\"Added object must be either an instance or subclass of one of the following classes: {self.class_types}!\"\nself._add(obj=obj, keys=self.all_keys)\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.clear","title":"<code>clear()</code>","text":"<p>Removes all owned objects from this registry</p> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def clear(self):\n\"\"\"\n    Removes all owned objects from this registry\n    \"\"\"\n# Re-create the owned dicts programmatically\nfor k in self.unique_keys.union(self.group_keys):\nself.__setattr__(f\"_objects_by_{k}\", dict())\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.get_dict","title":"<code>get_dict(key)</code>","text":"<p>Specific mapping dictionary within this registry corresponding to the mappings of @key.     e.g.: if key = \"name\", this will return the dictionary mapping object.name to objects</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key with which to grab mapping dict from</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Mapping from identifiers to object(s) based on @key</p> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def get_dict(self, key):\n\"\"\"\n    Specific mapping dictionary within this registry corresponding to the mappings of @key.\n        e.g.: if key = \"name\", this will return the dictionary mapping object.name to objects\n    Args:\n        key (str): Key with which to grab mapping dict from\n    Returns:\n        dict: Mapping from identifiers to object(s) based on @key\n    \"\"\"\nreturn getattr(self, f\"_objects_by_{key}\")\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.get_ids","title":"<code>get_ids(key)</code>","text":"<p>All identifiers within this registry corresponding to the mappings of @key.     e.g.: if key = \"name\", this will return all \"names\" stored internally that index into a object</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key with which to grab all identifiers from</p> required <p>Returns:</p> Name Type Description <code>set</code> <p>All identifiers within this registry corresponding to the mappings of @key.</p> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def get_ids(self, key):\n\"\"\"\n    All identifiers within this registry corresponding to the mappings of @key.\n        e.g.: if key = \"name\", this will return all \"names\" stored internally that index into a object\n    Args:\n        key (str): Key with which to grab all identifiers from\n    Returns:\n        set: All identifiers within this registry corresponding to the mappings of @key.\n    \"\"\"\nreturn set(self.get_dict(key=key).keys())\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.object_is_registered","title":"<code>object_is_registered(obj)</code>","text":"<p>Check if a given object @object is registered</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>any</code> <p>Instance to check if it is internally registered</p> required Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def object_is_registered(self, obj):\n\"\"\"\n    Check if a given object @object is registered\n    Args:\n        obj (any): Instance to check if it is internally registered\n    \"\"\"\nreturn obj in self.objects\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.remove","title":"<code>remove(obj)</code>","text":"<p>Removes object @object from this registry</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>any</code> <p>Instance to remove from this registry</p> required Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def remove(self, obj):\n\"\"\"\n    Removes object @object from this registry\n    Args:\n        obj (any): Instance to remove from this registry\n    \"\"\"\n# Iterate over all keys\nfor k in self.all_keys:\n# Grab the attribute from the object\nobj_attr = self._get_obj_attr(obj=obj, attr=k)\n# Standardize input as a list\nobj_attr = obj_attr if \\\n            isinstance(obj_attr, Iterable) and not isinstance(obj_attr, str) else [obj_attr]\n# Loop over all values in this attribute and remove them from all mappings\nfor attr in obj_attr:\nmapping = self.get_dict(k)\nif k in self.unique_keys:\n# Handle unique case -- in this case, we just directly pop the value from the dictionary\nmapping.pop(attr)\nelse:\n# Not unique case\n# We remove a value from the resulting set\nmapping[attr].remove(obj)\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.update","title":"<code>update(keys=None)</code>","text":"<p>Updates this registry, refreshing all internal mappings in case an object's value was updated</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>None or str or set or list of str</code> <p>Which object keys to update. None is default, which corresponds to all keys</p> <code>None</code> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>def update(self, keys=None):\n\"\"\"\n    Updates this registry, refreshing all internal mappings in case an object's value was updated\n    Args:\n        keys (None or str or set or list of str): Which object keys to update. None is default, which corresponds\n            to all keys\n    \"\"\"\nobjects = self.objects\nkeys = self.all_keys if keys is None else \\\n        (keys if type(keys) in {tuple, list} else [keys])\n# Delete and re-create all keys mappings\nfor k in keys:\nself.__delattr__(f\"_objects_by_{k}\")\nself.__setattr__(f\"_objects_by_{k}\", dict())\n# Iterate over all objects and re-populate the mappings\nfor obj in objects:\nself._add(obj=obj, keys=[k])\n</code></pre>"},{"location":"reference/utils/registry_utils.html#utils.registry_utils.SerializableRegistry","title":"<code>SerializableRegistry</code>","text":"<p>         Bases: <code>Registry</code>, <code>Serializable</code></p> <p>Registry that is serializable, i.e.: entries contain states that can themselves be serialized /deserialized.</p> <p>Note that this assumes that any objects added to this registry are themselves of @Serializable type!</p> Source code in <code>omnigibson/utils/registry_utils.py</code> <pre><code>class SerializableRegistry(Registry, Serializable):\n\"\"\"\n    Registry that is serializable, i.e.: entries contain states that can themselves be serialized /deserialized.\n    Note that this assumes that any objects added to this registry are themselves of @Serializable type!\n    \"\"\"\ndef add(self, obj):\n# In addition to any other class types, we make sure that the object is a serializable instance / class\nvalidate_class = issubclass if isclass(obj) else isinstance\nassert any([validate_class(obj, class_type) for class_type in (Serializable, SerializableNonInstance)]), \\\n            f\"Added object must be either an instance or subclass of Serializable or SerializableNonInstance!\"\n# Run super like normal\nsuper().add(obj=obj)\n@property\ndef state_size(self):\nreturn sum(obj.state_size for obj in self.objects)\ndef _dump_state(self):\n# Iterate over all objects and grab their states\nstate = dict()\nfor obj in self.objects:\nstate[obj.name] = obj.dump_state(serialized=False)\nreturn state\ndef _load_state(self, state):\n# Iterate over all objects and load their states. Currently the objects and the state don't have to match, i.e.\n# there might be objects in the scene that do not appear in the state dict (a warning will be printed), or\n# the state might contain additional information about objects that are NOT in the scene. For both cases, state\n# loading will be skipped.\nfor obj in self.objects:\nif obj.name not in state:\nlog.warning(f\"Object '{obj.name}' is not in the state dict to load from. Skip loading its state.\")\ncontinue\nobj.load_state(state[obj.name], serialized=False)\ndef _serialize(self, state):\n# Iterate over the entire dict and flatten\nreturn np.concatenate([obj.serialize(state[obj.name]) for obj in self.objects]) if \\\n            len(self.objects) &gt; 0 else np.array([])\ndef _deserialize(self, state):\nstate_dict = dict()\n# Iterate over all the objects and deserialize their individual states, incrementing the index counter\n# along the way\nidx = 0\nfor obj in self.objects:\nlog.debug(f\"obj: {obj.name}, state size: {obj.state_size}, idx: {idx}, passing in state length: {len(state[idx:])}\")\n# We pass in the entire remaining state vector, assuming the object only parses the relevant states\n# at the beginning\nstate_dict[obj.name] = obj.deserialize(state[idx:])\nidx += obj.state_size\nreturn state_dict, idx\n</code></pre>"},{"location":"reference/utils/render_utils.html","title":"render_utils","text":"<p>Set of rendering utility functions when working with Omni</p>"},{"location":"reference/utils/render_utils.html#utils.render_utils.create_pbr_material","title":"<code>create_pbr_material(prim_path)</code>","text":"<p>Creates an omni pbr material prim at the specified @prim_path</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Prim path where the PBR material should be generated</p> required <p>Returns:</p> Type Description <p>Usd.Prim: Generated PBR material prim</p> Source code in <code>omnigibson/utils/render_utils.py</code> <pre><code>def create_pbr_material(prim_path):\n\"\"\"\n    Creates an omni pbr material prim at the specified @prim_path\n    Args:\n        prim_path (str): Prim path where the PBR material should be generated\n    Returns:\n        Usd.Prim: Generated PBR material prim\n    \"\"\"\n# Use DeepWater omni present for rendering water\nmtl_created = []\nomni.kit.commands.execute(\n\"CreateAndBindMdlMaterialFromLibrary\",\nmdl_name=\"OmniPBR.mdl\",\nmtl_name=\"OmniPBR\",\nmtl_created_list=mtl_created,\n)\nmaterial_path = mtl_created[0]\n# Move prim to desired location\nomni.kit.commands.execute(\"MovePrim\", path_from=material_path, path_to=prim_path)\n# Return generated material\nreturn get_prim_at_path(material_path)\n</code></pre>"},{"location":"reference/utils/render_utils.html#utils.render_utils.create_skylight","title":"<code>create_skylight(intensity=500, color=(1.0, 1.0, 1.0))</code>","text":"<p>Creates a skylight object with the requested @color</p> <p>Parameters:</p> Name Type Description Default <code>intensity</code> <code>float</code> <p>Intensity of the generated skylight</p> <code>500</code> <code>color</code> <code>3-array</code> <p>Desired (R,G,B) color to assign to the skylight</p> <code>(1.0, 1.0, 1.0)</code> <p>Returns:</p> Name Type Description <code>LightObject</code> <p>Generated skylight object</p> Source code in <code>omnigibson/utils/render_utils.py</code> <pre><code>def create_skylight(intensity=500, color=(1.0, 1.0, 1.0)):\n\"\"\"\n    Creates a skylight object with the requested @color\n    Args:\n        intensity (float): Intensity of the generated skylight\n        color (3-array): Desired (R,G,B) color to assign to the skylight\n    Returns:\n        LightObject: Generated skylight object\n    \"\"\"\n# Avoid circular imports\nfrom omnigibson.objects.light_object import LightObject\nlight = LightObject(prim_path=\"/World/skylight\", name=\"skylight\", light_type=\"Dome\", intensity=intensity)\nog.sim.import_object(light)\nlight.set_orientation(T.euler2quat([0, 0, -np.pi / 4]))\nlight_prim = light.light_link.prim\nlight_prim.GetAttribute(\"color\").Set(Gf.Vec3f(*color))\nreturn light\n</code></pre>"},{"location":"reference/utils/render_utils.html#utils.render_utils.make_glass","title":"<code>make_glass(prim)</code>","text":"<p>Links the OmniGlass material with EntityPrim, RigidPrim, or VisualGeomPrim @obj, and procedurally generates the necessary OmniGlass material prim if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>EntityPrim or RigidPrim or VisualGeomPrim</code> <p>Desired prim to convert into glass</p> required Source code in <code>omnigibson/utils/render_utils.py</code> <pre><code>def make_glass(prim):\n\"\"\"\n    Links the OmniGlass material with EntityPrim, RigidPrim, or VisualGeomPrim @obj, and procedurally generates\n    the necessary OmniGlass material prim if necessary.\n    Args:\n        prim (EntityPrim or RigidPrim or VisualGeomPrim): Desired prim to convert into glass\n    \"\"\"\n# Generate the set of visual meshes we'll convert into glass\nif isinstance(prim, EntityPrim):\n# Grab all visual meshes from all links\nvisual_meshes = [vm for link in prim.links.values() for vm in link.visual_meshes.values()]\nelif isinstance(prim, RigidPrim):\n# Grab all visual meshes from the link\nvisual_meshes = [vm for vm in prim.visual_meshes.values()]\nelif isinstance(prim, VisualGeomPrim):\n# Just use this visual mesh\nvisual_meshes = [prim]\nelse:\nraise ValueError(f\"Inputted prim must an instance of EntityPrim, RigidPrim, or VisualGeomPrim \"\nf\"in order to be converted into glass!\")\n# Grab the glass material prim; if it doesn't exist, we create it on the fly\nglass_prim_path = \"/Looks/OmniGlass\"\nif not get_prim_at_path(glass_prim_path):\nmtl_created = []\nomni.kit.commands.execute(\n\"CreateAndBindMdlMaterialFromLibrary\",\nmdl_name=\"OmniGlass.mdl\",\nmtl_name=\"OmniGlass\",\nmtl_created_list=mtl_created,\n)\n# Iterate over all meshes and bind the glass material to the mesh\nfor vm in visual_meshes:\nbind_material(vm.prim_path, material_path=glass_prim_path)\n</code></pre>"},{"location":"reference/utils/sampling_utils.html","title":"sampling_utils","text":""},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_cuboid_empty","title":"<code>check_cuboid_empty(hit_normal, bottom_corner_positions, this_cuboid_dimensions, refusal_log)</code>","text":"<p>Check whether the cuboid defined by @this_cuboid_dimensions and @bottom_corner_positions contains empty space or not</p> <p>Parameters:</p> Name Type Description Default <code>hit_normal</code> <code>3-array</code> <p>(x,y,z) normal</p> required <code>bottom_corner_positions</code> <code>4, 3)-array</code> <p>the positions defining the bottom corners of the cuboid being sampled</p> required <code>this_cuboid_dimensions</code> <code>3-array</code> <p>(x,y,z) size of the sampled cuboid</p> required <code>refusal_log</code> <code>list of str</code> <p>Logging array for adding debug logs</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the cuboid is empty, else False</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def check_cuboid_empty(hit_normal, bottom_corner_positions, this_cuboid_dimensions, refusal_log):\n\"\"\"\n    Check whether the cuboid defined by @this_cuboid_dimensions and @bottom_corner_positions contains\n    empty space or not\n    Args:\n        hit_normal (3-array): (x,y,z) normal\n        bottom_corner_positions ((4, 3)-array): the positions defining the bottom corners of the cuboid\n            being sampled\n        this_cuboid_dimensions (3-array): (x,y,z) size of the sampled cuboid\n        refusal_log (list of str): Logging array for adding debug logs\n    Returns:\n        bool: True if the cuboid is empty, else False\n    \"\"\"\nif gm.DEBUG:\ndraw_debug_markers(bottom_corner_positions)\n# Compute top corners.\ntop_corner_positions = bottom_corner_positions + hit_normal * this_cuboid_dimensions[2]\n# We only generate valid rays that have nonzero distances. If the inputted cuboid is flat (i.e.: one dimension\n# is zero, i.e.: it is in fact a rectangle), raise an error\nassert this_cuboid_dimensions[2] != 0, \"Cannot check empty cuboid for cuboid with zero height!\"\n# Get all the top-to-bottom corner pairs.\n# When we cast these rays, we check that the faces &amp; volume of the cuboid are unoccupied.\ntop_to_bottom_pairs = list(itertools.product(top_corner_positions, bottom_corner_positions))\n# Get all the same-height pairs. These also check that the surfaces areas are empty.\nbottom_pairs = list(itertools.combinations(bottom_corner_positions, 2))\ntop_pairs = list(itertools.combinations(top_corner_positions, 2))\n# Combine all these pairs, cast the rays, and make sure the rays don't hit anything.\nall_pairs = np.array(top_to_bottom_pairs + bottom_pairs + top_pairs)\ncheck_cast_results = raytest_batch(start_points=all_pairs[:, 0, :], end_points=all_pairs[:, 1, :])\nif any(ray[\"hit\"] for ray in check_cast_results):\nif gm.DEBUG:\nrefusal_log.append(\"check ray info: %r\" % (check_cast_results))\nreturn False\nreturn True\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_distance_to_plane","title":"<code>check_distance_to_plane(points, plane_centroid, plane_normal, hit_to_plane_threshold, refusal_log)</code>","text":"<p>Calculates whether points are within @hit_to_plane_threshold distance to plane defined by @plane_centroid and @plane_normal</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>k, 3)-array</code> <p>np.array of shape (k, 3)</p> required <code>plane_centroid</code> <code>3-array</code> <p>(x,y,z) points' centroid</p> required <code>plane_normal</code> <code>3-array</code> <p>(x,y,z) normal of the fitted plane</p> required <code>hit_to_plane_threshold</code> <code>float</code> <p>Threshold distance to check between @points and plane</p> required <code>refusal_log</code> <code>dict</code> <p>Debugging dictionary to add error messages to</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all points are within @hit_to_plane_threshold distance to plane, otherwise False</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def check_distance_to_plane(points, plane_centroid, plane_normal, hit_to_plane_threshold, refusal_log):\n\"\"\"\n    Calculates whether points are within @hit_to_plane_threshold distance to plane defined by @plane_centroid\n    and @plane_normal\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n        plane_centroid (3-array): (x,y,z) points' centroid\n        plane_normal (3-array): (x,y,z) normal of the fitted plane\n        hit_to_plane_threshold (float): Threshold distance to check between @points and plane\n        refusal_log (dict): Debugging dictionary to add error messages to\n    Returns:\n        bool: True if all points are within @hit_to_plane_threshold distance to plane, otherwise False\n    \"\"\"\ndistances = get_distance_to_plane(points, plane_centroid, plane_normal)\nif np.any(distances &gt; hit_to_plane_threshold):\nif gm.DEBUG:\nrefusal_log.append(\"distances to plane: %r\" % distances)\nreturn False\nreturn True\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_hit_max_angle_from_z_axis","title":"<code>check_hit_max_angle_from_z_axis(hit_normal, max_angle_with_z_axis, refusal_log)</code>","text":"<p>Check whether the normal @hit_normal deviates from the global z axis by more than @max_angle_with_z_axis</p> <p>Parameters:</p> Name Type Description Default <code>hit_normal</code> <code>3-array</code> <p>Normal vector to check with respect to global z-axis</p> required <code>max_angle_with_z_axis</code> <code>float</code> <p>Maximum acceptable angle between the global z-axis and @hit_normal</p> required <code>refusal_log</code> <code>list of str</code> <p>Logging array for adding debug logs</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the angle between @hit_normal and the global z-axis is less than @max_angle_with_z_axis, otherwise False</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def check_hit_max_angle_from_z_axis(hit_normal, max_angle_with_z_axis, refusal_log):\n\"\"\"\n    Check whether the normal @hit_normal deviates from the global z axis by more than @max_angle_with_z_axis\n    Args:\n        hit_normal (3-array): Normal vector to check with respect to global z-axis\n        max_angle_with_z_axis (float): Maximum acceptable angle between the global z-axis and @hit_normal\n        refusal_log (list of str): Logging array for adding debug logs\n    Returns:\n        bool: True if the angle between @hit_normal and the global z-axis is less than @max_angle_with_z_axis,\n            otherwise False\n    \"\"\"\nhit_angle_with_z = np.arccos(np.clip(np.dot(hit_normal, np.array([0, 0, 1])), -1.0, 1.0))\nif hit_angle_with_z &gt; max_angle_with_z_axis:\nif gm.DEBUG:\nrefusal_log.append(\"normal %r\" % hit_normal)\nreturn False\nreturn True\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_normal_similarity","title":"<code>check_normal_similarity(center_hit_normal, hit_normals, tolerance, refusal_log)</code>","text":"<p>Check whether the normals from @hit_normals are within some @tolerance of @center_hit_normal.</p> <p>Parameters:</p> Name Type Description Default <code>center_hit_normal</code> <code>3-array</code> <p>normal of the center hit point</p> required <code>hit_normals</code> <code>n, 3)-array</code> <p>normals of all the hit points</p> required <code>tolerance</code> <code>float</code> <p>Acceptable deviation between the center hit normal and all normals</p> required <code>refusal_log</code> <code>dict</code> <p>Dictionary to write debugging and log information to</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the normal similarity is acceptable or not</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def check_normal_similarity(center_hit_normal, hit_normals, tolerance, refusal_log):\n\"\"\"\n    Check whether the normals from @hit_normals are within some @tolerance of @center_hit_normal.\n    Args:\n        center_hit_normal (3-array): normal of the center hit point\n        hit_normals ((n, 3)-array): normals of all the hit points\n        tolerance (float): Acceptable deviation between the center hit normal and all normals\n        refusal_log (dict): Dictionary to write debugging and log information to\n    Returns:\n        bool: Whether the normal similarity is acceptable or not\n    \"\"\"\nparallel_hit_main_hit_dot_products = np.clip(\nnp.dot(hit_normals, center_hit_normal)\n/ (np.linalg.norm(hit_normals, axis=1) * np.linalg.norm(center_hit_normal)),\n-1.0,\n1.0,\n)\nparallel_hit_normal_angles_to_hit_normal = np.arccos(parallel_hit_main_hit_dot_products)\nall_rays_hit_with_similar_normal = np.all(\nparallel_hit_normal_angles_to_hit_normal &lt; tolerance\n)\nif not all_rays_hit_with_similar_normal:\nif gm.DEBUG:\nrefusal_log.append(\"angles %r\" % (np.rad2deg(parallel_hit_normal_angles_to_hit_normal),))\nreturn False\nreturn True\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_rays_hit_object","title":"<code>check_rays_hit_object(cast_results, threshold, refusal_log, body_names=None)</code>","text":"<p>Checks whether rays hit a specific object, as specified by a list of @body_names</p> <p>Parameters:</p> Name Type Description Default <code>cast_results</code> <code>list of dict</code> <p>Output from raycast_batch.</p> required <code>threshold</code> <code>float</code> <p>Relative ratio in [0, 1] specifying proportion of rays from @cast_results are required to hit @body_names to count as the object being hit</p> required <code>refusal_log</code> <code>list of str</code> <p>Logging array for adding debug logs</p> required <code>body_names</code> <code>None or list or set of str</code> <p>absolute USD paths to rigid bodies to check for hit. If not specified, then any valid hit will be accepted</p> <code>None</code> <p>Returns:</p> Type Description <p>None or list of bool: Individual T/F for each ray -- whether it hit the object or not</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def check_rays_hit_object(cast_results, threshold, refusal_log, body_names=None):\n\"\"\"\n    Checks whether rays hit a specific object, as specified by a list of @body_names\n    Args:\n        cast_results (list of dict): Output from raycast_batch.\n        threshold (float): Relative ratio in [0, 1] specifying proportion of rays from @cast_results are\n            required to hit @body_names to count as the object being hit\n        refusal_log (list of str): Logging array for adding debug logs\n        body_names (None or list or set of str): absolute USD paths to rigid bodies to check for hit. If not\n            specified, then any valid hit will be accepted\n    Returns:\n        None or list of bool: Individual T/F for each ray -- whether it hit the object or not\n    \"\"\"\nbody_names = None if body_names is None else set(body_names)\nray_hits = [\nray_res[\"hit\"] and\n(body_names is None or ray_res[\"rigidBody\"] in body_names)\nfor ray_res in cast_results\n]\nif sum(ray_hits) / len(cast_results) &lt; threshold:\nif gm.DEBUG:\nrefusal_log.append(f\"{sum(ray_hits)} / {len(cast_results)} &lt; {threshold} hits: {[ray_res['rigidBody'] for ray_res in cast_results if ray_res['hit']]}\")\nreturn None\nreturn ray_hits\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.compute_ray_destination","title":"<code>compute_ray_destination(axis, is_top, start_pos, aabb_min, aabb_max)</code>","text":"<p>Compute the point on the AABB defined by @aabb_min and @aabb_max from shooting a ray at @start_pos in the direction defined by global axis @axis and @is_top</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>Which direction to compute the ray destination. Valid options are {0, 1, 2} -- the x, y, or z axes</p> required <code>is_top</code> <code>bool</code> <p>Whether to shoot in the positive or negative @axis direction</p> required <code>aabb_min</code> <code>3-array</code> <p>(x,y,z) position defining the lower corner of the AABB</p> required <code>aabb_max</code> <code>3-array</code> <p>(x,y,z) position defining the upper corner of the AABB</p> required <p>Returns:</p> Type Description <p>3-array: computed (x,y,z) point on the AABB surface</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def compute_ray_destination(axis, is_top, start_pos, aabb_min, aabb_max):\n\"\"\"\n    Compute the point on the AABB defined by @aabb_min and @aabb_max from shooting a ray at @start_pos\n    in the direction defined by global axis @axis and @is_top\n    Args:\n        axis (int): Which direction to compute the ray destination. Valid options are {0, 1, 2} -- the\n            x, y, or z axes\n        is_top (bool): Whether to shoot in the positive or negative @axis direction\n        aabb_min (3-array): (x,y,z) position defining the lower corner of the AABB\n        aabb_max (3-array): (x,y,z) position defining the upper corner of the AABB\n    Returns:\n        3-array: computed (x,y,z) point on the AABB surface\n    \"\"\"\n# Get the ray casting direction - we want to do it parallel to the sample axis.\nray_direction = np.array([0, 0, 0])\nray_direction[axis] = 1\nray_direction *= -1 if is_top else 1\n# We want to extend our ray until it intersects one of the AABB's faces.\n# Start by getting the distances towards the min and max boundaries of the AABB on each axis.\npoint_to_min = aabb_min - start_pos\npoint_to_max = aabb_max - start_pos\n# Then choose the distance to the point in the correct direction on each axis.\ncloser_point_on_each_axis = np.where(ray_direction &lt; 0, point_to_min, point_to_max)\n# For each axis, find how many times the ray direction should be multiplied to reach the AABB's boundary.\nmultiple_to_face_on_each_axis = closer_point_on_each_axis / ray_direction\n# Choose the minimum of these multiples, e.g. how many times the ray direction should be multiplied\n# to reach the nearest boundary.\nmultiple_to_face = np.min(multiple_to_face_on_each_axis[np.isfinite(multiple_to_face_on_each_axis)])\n# Finally, use the multiple we found to calculate the point on the AABB boundary that we want to cast our\n# ray until.\npoint_on_face = start_pos + ray_direction * multiple_to_face\n# Make sure that we did not end up with all NaNs or infinities due to division issues.\nassert not np.any(np.isnan(point_on_face)) and not np.any(np.isinf(point_on_face))\nreturn point_on_face\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.compute_rotation_from_grid_sample","title":"<code>compute_rotation_from_grid_sample(two_d_grid, projected_hits, cuboid_centroid, this_cuboid_dimensions, hits, refusal_log)</code>","text":"<p>Computes</p> <p>Parameters:</p> Name Type Description Default <code>two_d_grid</code> <code>n, 2</code> <p>(x,y) raycast origin points in the local plane frame</p> required <code>projected_hits</code> <code>k,3)-array</code> <p>Points' positions projected onto the plane generated</p> required <code>cuboid_centroid</code> <code>3-array</code> <p>(x,y,z) sampled position of the hit cuboid centroid in the global frame</p> required <code>this_cuboid_dimensions</code> <code>3-array</code> <p>(x,y,z) size of cuboid being sampled from the grid</p> required <code>hits</code> <code>list of bool</code> <p>whether each point from @two_d_grid is a valid hit or not</p> required <code>refusal_log</code> <code>dict</code> <p>Dictionary to write debugging and log information to</p> required <p>Returns:</p> Type Description <p>None or scipy.Rotation: If successfully hit, returns relative rotation from two_d_grid to generated hit plane. Otherwise, returns None</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def compute_rotation_from_grid_sample(two_d_grid, projected_hits, cuboid_centroid, this_cuboid_dimensions, hits, refusal_log):\n\"\"\"\n    Computes\n    Args:\n        two_d_grid (n, 2): (x,y) raycast origin points in the local plane frame\n        projected_hits ((k,3)-array): Points' positions projected onto the plane generated\n        cuboid_centroid (3-array): (x,y,z) sampled position of the hit cuboid centroid in the global frame\n        this_cuboid_dimensions (3-array): (x,y,z) size of cuboid being sampled from the grid\n        hits (list of bool): whether each point from @two_d_grid is a valid hit or not\n        refusal_log (dict): Dictionary to write debugging and log information to\n    Returns:\n        None or scipy.Rotation: If successfully hit, returns relative rotation from two_d_grid to\n            generated hit plane. Otherwise, returns None\n    \"\"\"\nif np.sum(hits) &lt; 3:\nif gm.DEBUG:\nrefusal_log.append(f\"insufficient hits to compute the rotation of the grid: needs 3, has {np.sum(hits)}\")\nreturn None\ngrid_in_planar_coordinates = two_d_grid.reshape(-1, 2)\ngrid_in_planar_coordinates = grid_in_planar_coordinates[hits]\ngrid_in_object_coordinates = np.zeros((len(grid_in_planar_coordinates), 3))\ngrid_in_object_coordinates[:, :2] = grid_in_planar_coordinates\ngrid_in_object_coordinates[:, 2] = -this_cuboid_dimensions[2] / 2.0\nprojected_hits = projected_hits[hits]\nsampled_grid_relative_vectors = projected_hits - cuboid_centroid\nrotation, _ = R.align_vectors(sampled_grid_relative_vectors, grid_in_object_coordinates)\nreturn rotation\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.draw_debug_markers","title":"<code>draw_debug_markers(hit_positions, radius=0.01)</code>","text":"<p>Helper method to generate and place debug markers at @hit_positions</p> <p>Parameters:</p> Name Type Description Default <code>hit_positions</code> <code>n, 3)-array</code> <p>Desired positions to place markers at</p> required <code>radius</code> <code>float</code> <p>Radius of the generated virtual marker</p> <code>0.01</code> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def draw_debug_markers(hit_positions, radius=0.01):\n\"\"\"\n    Helper method to generate and place debug markers at @hit_positions\n    Args:\n        hit_positions ((n, 3)-array): Desired positions to place markers at\n        radius (float): Radius of the generated virtual marker\n    \"\"\"\n# Import here to avoid circular imports\nfrom omnigibson.objects.primitive_object import PrimitiveObject\ncolor = np.concatenate([np.random.rand(3), [1]])\nfor vec in hit_positions:\ntime_str = str(time.time())\ncur_time = time_str[(time_str.index(\".\") + 1):]\nobj = PrimitiveObject(\nprim_path=f\"/World/debug_marker_{cur_time}\",\nname=f\"debug_marker_{cur_time}\",\nprimitive_type=\"Sphere\",\nvisual_only=True,\nrgba=color,\nradius=radius,\n)\nog.sim.import_object(obj)\nobj.set_position(vec)\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.fit_plane","title":"<code>fit_plane(points, refusal_log)</code>","text":"<p>Fits a plane to the given 3D points. Copied from https://stackoverflow.com/a/18968498</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>k, 3)-array</code> <p>np.array of shape (k, 3)</p> required <code>refusal_log</code> <code>dict</code> <p>Debugging dictionary to add error messages to</p> required <p>Returns:</p> Type Description <p>2-tuple: - 3-array: (x,y,z) points' centroid - 3-array: (x,y,z) normal of the fitted plane</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def fit_plane(points, refusal_log):\n\"\"\"\n    Fits a plane to the given 3D points.\n    Copied from https://stackoverflow.com/a/18968498\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n        refusal_log (dict): Debugging dictionary to add error messages to\n    Returns:\n        2-tuple:\n            - 3-array: (x,y,z) points' centroid\n            - 3-array: (x,y,z) normal of the fitted plane\n    \"\"\"\nif points.shape[0] &lt; points.shape[1]:\nif gm.DEBUG:\nrefusal_log.append(f\"insufficient points to fit a 3D plane: needs 3, has {points.shape[0]}.\")\nreturn None, None\nctr = points.mean(axis=0)\nx = points - ctr\nnormal = np.linalg.svd(np.dot(x.T, x))[0][:, -1]\nnormal /= np.linalg.norm(normal)\nreturn ctr, normal\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.get_distance_to_plane","title":"<code>get_distance_to_plane(points, plane_centroid, plane_normal)</code>","text":"<p>Computes distance from @points to plane defined by @plane_centroid and @plane_normal</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>k, 3)-array</code> <p>np.array of shape (k, 3)</p> required <code>plane_centroid</code> <code>3-array</code> <p>(x,y,z) points' centroid</p> required <code>plane_normal</code> <code>3-array</code> <p>(x,y,z) normal of the fitted plane</p> required <p>Returns:</p> Type Description <p>k-array: Absolute distances from each point to the plane</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def get_distance_to_plane(points, plane_centroid, plane_normal):\n\"\"\"\n    Computes distance from @points to plane defined by @plane_centroid and @plane_normal\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n        plane_centroid (3-array): (x,y,z) points' centroid\n        plane_normal (3-array): (x,y,z) normal of the fitted plane\n    Returns:\n        k-array: Absolute distances from each point to the plane\n    \"\"\"\nreturn np.abs(np.dot(points - plane_centroid, plane_normal))\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.get_parallel_rays","title":"<code>get_parallel_rays(source, destination, offset, new_ray_per_horizontal_distance)</code>","text":"<p>Given an input ray described by a source and a destination, sample parallel rays around it as the center.</p> <p>The parallel rays start at the corners of a square of edge length <code>offset</code> centered on <code>source</code>, with the square orthogonal to the ray direction. That is, the cast rays are the height edges of a square-base cuboid with bases centered on <code>source</code> and <code>destination</code>.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>3-array</code> <p>(x,y,z) source of the ray to sample parallel rays of.</p> required <code>destination</code> <code>3-array</code> <p>Source of the ray to sample parallel rays of.</p> required <code>offset</code> <code>float</code> <p>Orthogonal distance of parallel rays from input ray.</p> required <code>new_ray_per_horizontal_distance</code> <code>float</code> <p>Step in offset beyond which an additional split will be applied in the parallel ray grid (which at minimum is 3x3 at the AABB corners &amp; center).</p> required <p>Returns:</p> Type Description <p>3-tuple: - list: generated sources from the original ray - list: generated destinations from the original ray - (W, H, 3)-array: unflattened, untransformed grid of parallel rays in object coordinates</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def get_parallel_rays(\nsource, destination, offset, new_ray_per_horizontal_distance\n):\n\"\"\"\n    Given an input ray described by a source and a destination, sample parallel rays around it as the center.\n    The parallel rays start at the corners of a square of edge length `offset` centered on `source`, with the square\n    orthogonal to the ray direction. That is, the cast rays are the height edges of a square-base cuboid with bases\n    centered on `source` and `destination`.\n    Args:\n        source (3-array): (x,y,z) source of the ray to sample parallel rays of.\n        destination (3-array): Source of the ray to sample parallel rays of.\n        offset (float): Orthogonal distance of parallel rays from input ray.\n        new_ray_per_horizontal_distance (float): Step in offset beyond which an additional split will be applied in the\n            parallel ray grid (which at minimum is 3x3 at the AABB corners &amp; center).\n    Returns:\n        3-tuple:\n            - list: generated sources from the original ray\n            - list: generated destinations from the original ray\n            - (W, H, 3)-array: unflattened, untransformed grid of parallel rays in object coordinates\n    \"\"\"\nray_direction = destination - source\n# Get an orthogonal vector using a random vector.\nrandom_vector = np.random.rand(3)\northogonal_vector_1 = np.cross(ray_direction, random_vector)\northogonal_vector_1 /= np.linalg.norm(orthogonal_vector_1)\n# Get a second vector orthogonal to both the ray and the first vector.\northogonal_vector_2 = -np.cross(ray_direction, orthogonal_vector_1)\northogonal_vector_2 /= np.linalg.norm(orthogonal_vector_2)\northogonal_vectors = np.array([orthogonal_vector_1, orthogonal_vector_2])\nassert np.all(np.isfinite(orthogonal_vectors))\n# Convert the offset into a 2-vector if it already isn't one.\noffset = np.array([1, 1]) * offset\n# Compute the grid of rays\nsteps = (offset / new_ray_per_horizontal_distance).astype(int) * 2 + 1\nsteps = np.maximum(steps, 3)\nx_range = np.linspace(-offset[0], offset[0], steps[0])\ny_range = np.linspace(-offset[1], offset[1], steps[1])\nray_grid = np.dstack(np.meshgrid(x_range, y_range, indexing=\"ij\"))\nray_grid_flattened = ray_grid.reshape(-1, 2)\n# Apply the grid onto the orthogonal vectors to obtain the rays in the world frame.\nsources = [source + np.dot(offsets, orthogonal_vectors) for offsets in ray_grid_flattened]\ndestinations = [destination + np.dot(offsets, orthogonal_vectors) for offsets in ray_grid_flattened]\nreturn sources, destinations, ray_grid\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.get_projection_onto_plane","title":"<code>get_projection_onto_plane(points, plane_centroid, plane_normal)</code>","text":"<p>Computes @points' projection onto the plane defined by @plane_centroid and @plane_normal</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>k, 3)-array</code> <p>np.array of shape (k, 3)</p> required <code>plane_centroid</code> <code>3-array</code> <p>(x,y,z) points' centroid</p> required <code>plane_normal</code> <code>3-array</code> <p>(x,y,z) normal of the fitted plane</p> required <p>Returns:</p> Type Description <p>(k,3)-array: Points' positions projected onto the plane</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def get_projection_onto_plane(points, plane_centroid, plane_normal):\n\"\"\"\n    Computes @points' projection onto the plane defined by @plane_centroid and @plane_normal\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n        plane_centroid (3-array): (x,y,z) points' centroid\n        plane_normal (3-array): (x,y,z) normal of the fitted plane\n    Returns:\n        (k,3)-array: Points' positions projected onto the plane\n    \"\"\"\ndistances_to_plane = get_distance_to_plane(points, plane_centroid, plane_normal)\nreturn points - np.outer(distances_to_plane, plane_normal)\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.raytest","title":"<code>raytest(start_point, end_point, only_closest=True, ignore_bodies=None, ignore_collisions=None)</code>","text":"<p>Computes raytest collision for ray cast from @start_point to @end_point</p> <p>Parameters:</p> Name Type Description Default <code>start_point</code> <code>3-array</code> <p>(x,y,z) global start location of the ray</p> required <code>end_point</code> <code>3-array</code> <p>(x,y,z) global end location of the ray</p> required <code>only_closest</code> <code>bool</code> <p>Whether we report the first (closest) hit from the ray or grab all hits</p> <code>True</code> <code>ignore_bodies</code> <code>None or list of str</code> <p>If specified, specifies absolute USD paths to rigid bodies whose collisions should be ignored</p> <code>None</code> <code>ignore_collisions</code> <code>None or list of str</code> <p>If specified, specifies absolute USD paths to collision geoms whose collisions should be ignored</p> <code>None</code> <p>Returns:</p> Type Description <p>dict or list of dict: Results for this raytest. If @only_closest=True, then we only return the information from the closest hit. Otherwise, we return an (unordered) list of information for all hits encountered. Each dict is composed of:</p> <p>\"hit\" (bool): Whether an object was hit or not \"position\" (3-array): Location of the hit position \"normal\" (3-array): normal vector of the face hit \"distance\" (float): distance from @start_point the hit occurred \"collision\" (str): absolute USD path to the collision body hit \"rigidBody\" (str): absolute USD path to the associated rigid body hit</p> <p>Note that only \"hit\" = False exists in the dict if no hit was found</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def raytest(\nstart_point,\nend_point,\nonly_closest=True,\nignore_bodies=None,\nignore_collisions=None,\n):\n\"\"\"\n    Computes raytest collision for ray cast from @start_point to @end_point\n    Args:\n        start_point (3-array): (x,y,z) global start location of the ray\n        end_point (3-array): (x,y,z) global end location of the ray\n        only_closest (bool): Whether we report the first (closest) hit from the ray or grab all hits\n        ignore_bodies (None or list of str): If specified, specifies absolute USD paths to rigid bodies\n            whose collisions should be ignored\n        ignore_collisions (None or list of str): If specified, specifies absolute USD paths to collision geoms\n            whose collisions should be ignored\n    Returns:\n        dict or list of dict: Results for this raytest. If @only_closest=True, then we only return the information from\n            the closest hit. Otherwise, we return an (unordered) list of information for all hits encountered.\n            Each dict is composed of:\n            \"hit\" (bool): Whether an object was hit or not\n            \"position\" (3-array): Location of the hit position\n            \"normal\" (3-array): normal vector of the face hit\n            \"distance\" (float): distance from @start_point the hit occurred\n            \"collision\" (str): absolute USD path to the collision body hit\n            \"rigidBody\" (str): absolute USD path to the associated rigid body hit\n            Note that only \"hit\" = False exists in the dict if no hit was found\n    \"\"\"\n# Make sure start point, end point are numpy arrays\nstart_point, end_point = np.array(start_point), np.array(end_point)\npoint_diff = end_point - start_point\ndistance = np.linalg.norm(point_diff)\ndirection = point_diff / distance\n# For efficiency's sake, we handle special case of no ignore_bodies, ignore_collisions, and closest_hit\nif only_closest and ignore_bodies is None and ignore_collisions is None:\nreturn og.sim.psqi.raycast_closest(\norigin=start_point,\ndir=direction,\ndistance=distance,\n)\nelse:\n# Compose callback function for finding raycasts\nhits = []\nignore_bodies = set() if ignore_bodies is None else set(ignore_bodies)\nignore_collisions = set() if ignore_collisions is None else set(ignore_collisions)\ndef callback(hit):\n# Only add to hits if we're not ignoring this body or collision\nif hit.rigid_body not in ignore_bodies and hit.collision not in ignore_collisions:\nhits.append({\n\"hit\": True,\n\"position\": np.array(hit.position),\n\"normal\": np.array(hit.normal),\n\"distance\": hit.distance,\n\"collision\": hit.collision,\n\"rigidBody\": hit.rigid_body,\n})\n# We always want to continue traversing to collect all hits\nreturn True\n# Grab all collisions\nog.sim.psqi.raycast_all(\norigin=start_point,\ndir=direction,\ndistance=distance,\nreportFn=callback,\n)\n# If we only want the closest, we need to sort these hits, otherwise we return them all\nif only_closest:\n# Return the empty hit dictionary if our ray did not hit anything, otherwise we return the closest\nreturn {\"hit\": False} if len(hits) == 0 else sorted(hits, key=lambda hit: hit[\"distance\"])[0]\nelse:\n# Return all hits (list)\nreturn hits\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.raytest_batch","title":"<code>raytest_batch(start_points, end_points, only_closest=True, ignore_bodies=None, ignore_collisions=None)</code>","text":"<p>Computes raytest collisions for a set of rays cast from @start_points to @end_points.</p> <p>Parameters:</p> Name Type Description Default <code>start_points</code> <code>list of 3-array</code> <p>Array of start locations to cast rays, where each is (x,y,z) global start location of the ray</p> required <code>end_points</code> <code>list of 3-array</code> <p>Array of end locations to cast rays, where each is (x,y,z) global end location of the ray</p> required <code>only_closest</code> <code>bool</code> <p>Whether we report the first (closest) hit from the ray or grab all hits</p> <code>True</code> <code>ignore_bodies</code> <code>None or list of str</code> <p>If specified, specifies absolute USD paths to rigid bodies whose collisions should be ignored</p> <code>None</code> <code>ignore_collisions</code> <code>None or list of str</code> <p>If specified, specifies absolute USD paths to collision geoms whose collisions should be ignored</p> <code>None</code> <p>Returns:</p> Type Description <p>list of dict or list of list of dict: Results for all rays, where each entry corresponds to the result for the ith ray cast. If @only_closest=True, each entry in the list is the closest hit. Otherwise, each entry is its own (unordered) list of hits for that ray. Each dict is composed of:</p> <p>\"hit\" (bool): Whether an object was hit or not \"position\" (3-array): Location of the hit position \"normal\" (3-array): normal vector of the face hit \"distance\" (float): distance from @start_point the hit occurred \"collision\" (str): absolute USD path to the collision body hit \"rigidBody\" (str): absolute USD path to the associated rigid body hit</p> <p>Note that only \"hit\" = False exists in the dict if no hit was found</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def raytest_batch(start_points, end_points, only_closest=True, ignore_bodies=None, ignore_collisions=None):\n\"\"\"\n    Computes raytest collisions for a set of rays cast from @start_points to @end_points.\n    Args:\n        start_points (list of 3-array): Array of start locations to cast rays, where each is (x,y,z) global\n            start location of the ray\n        end_points (list of 3-array): Array of end locations to cast rays, where each is (x,y,z) global\n            end location of the ray\n        only_closest (bool): Whether we report the first (closest) hit from the ray or grab all hits\n        ignore_bodies (None or list of str): If specified, specifies absolute USD paths to rigid bodies\n            whose collisions should be ignored\n        ignore_collisions (None or list of str): If specified, specifies absolute USD paths to collision geoms\n            whose collisions should be ignored\n    Returns:\n        list of dict or list of list of dict: Results for all rays, where each entry corresponds to the result for the\n            ith ray cast. If @only_closest=True, each entry in the list is the closest hit. Otherwise, each entry is\n            its own (unordered) list of hits for that ray. Each dict is composed of:\n            \"hit\" (bool): Whether an object was hit or not\n            \"position\" (3-array): Location of the hit position\n            \"normal\" (3-array): normal vector of the face hit\n            \"distance\" (float): distance from @start_point the hit occurred\n            \"collision\" (str): absolute USD path to the collision body hit\n            \"rigidBody\" (str): absolute USD path to the associated rigid body hit\n            Note that only \"hit\" = False exists in the dict if no hit was found\n    \"\"\"\n# For now, we do a naive for loop over individual raytests until a better API comes out\nresults = []\nfor start_point, end_point in zip(start_points, end_points):\nresults.append(raytest(\nstart_point=start_point,\nend_point=end_point,\nonly_closest=only_closest,\nignore_bodies=ignore_bodies,\nignore_collisions=ignore_collisions,\n))\nreturn results\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_cuboid_on_object","title":"<code>sample_cuboid_on_object(obj, start_points, end_points, cuboid_dimensions, ignore_objs=None, new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE, hit_proportion=m.DEFAULT_HIT_PROPORTION, max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS, parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE, hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD, cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING, undo_cuboid_bottom_padding=True, verify_cuboid_empty=True, refuse_downwards=False)</code>","text":"<p>Samples points on an object's surface using ray casting.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DatasetObject</code> <p>The object to sample points on.</p> required <code>start_points</code> <code>n, s, 3)-array</code> <p>(num_samples, max_sampling_attempts, 3) shaped array representing the start points for raycasting defined in the world frame</p> required <code>end_points</code> <code>n, s, 3)-array</code> <p>(num_samples, max_sampling_attempts, 3) shaped array representing the end points for raycasting defined in the world frame</p> required <code>cuboid_dimensions</code> <code>n, 3)-array</code> <p>Float sequence of len 3, the size of the empty cuboid we are trying to sample. Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to sample points (instead of cuboids) for significantly better performance. This applies when the user wants to sample very small particles.</p> required <code>ignore_objs</code> <code>None or list of EntityPrim</code> <p>If @obj is None, this can be used to filter objects when checking for valid cuboid locations. Any sampled rays that hit an object in @ignore_objs will be ignored. If None, no filtering will be used</p> <code>None</code> <code>new_ray_per_horizontal_distance</code> <code>float</code> <p>per this distance of the cuboid dimension, increase the grid size of the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to the size of the sampled cuboid.</p> <code>m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE</code> <code>hit_proportion</code> <code>float</code> <p>the minimum percentage of the hits required across the grid.</p> <code>m.DEFAULT_HIT_PROPORTION</code> <code>max_angle_with_z_axis</code> <code>float</code> <p>maximum angle between hit normal and positive Z axis allowed. Can be used to disallow downward-facing hits when refuse_downwards=True.</p> <code>m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS</code> <code>parallel_ray_normal_angle_tolerance</code> <code>float</code> <p>maximum angle difference between the normal of the center hit and the normal of other hits allowed.</p> <code>m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE</code> <code>hit_to_plane_threshold</code> <code>float</code> <p>how far any given hit position can be from the least-squares fit plane to all of the hit positions before the sample is rejected.</p> <code>m.DEFAULT_HIT_TO_PLANE_THRESHOLD</code> <code>cuboid_bottom_padding</code> <code>float</code> <p>additional padding applied to the bottom of the cuboid. This is needed for the emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove the padding after the emptiness check.</p> <code>m.DEFAULT_CUBOID_BOTTOM_PADDING</code> <code>undo_cuboid_bottom_padding</code> <code>bool</code> <p>Whether the bottom padding that's applied to the cuboid should be removed before return. Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will simply make the sampler undo the padding prior to returning.</p> <code>True</code> <code>verify_cuboid_empty</code> <code>bool</code> <p>Whether to filter out sampled cuboid locations that are not collision-free. Note that this check will only potentially occur if nonzero cuboid dimensions are specified.</p> <code>True</code> <code>refuse_downwards</code> <code>bool</code> <p>whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.</p> <code>False</code> <p>Returns:</p> Type Description <p>list of tuple: list of length num_samples elements where each element is a tuple in the form of (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions are set to None when no successful sampling happens within the max number of attempts. Refusal details are only filled if the gm.DEBUG flag is globally set to True.</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def sample_cuboid_on_object(\nobj,\nstart_points,\nend_points,\ncuboid_dimensions,\nignore_objs=None,\nnew_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE,\nhit_proportion=m.DEFAULT_HIT_PROPORTION,\nmax_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS,\nparallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE,\nhit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD,\ncuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING,\nundo_cuboid_bottom_padding=True,\nverify_cuboid_empty=True,\nrefuse_downwards=False,\n):\n\"\"\"\n    Samples points on an object's surface using ray casting.\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        start_points ((n, s, 3)-array): (num_samples, max_sampling_attempts, 3) shaped array representing the start points for\n            raycasting defined in the world frame\n        end_points ((n, s, 3)-array): (num_samples, max_sampling_attempts, 3) shaped array representing the end points for\n            raycasting defined in the world frame\n        cuboid_dimensions ((n, 3)-array): Float sequence of len 3, the size of the empty cuboid we are trying to sample.\n            Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using\n            the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to\n            sample points (instead of cuboids) for significantly better performance. This applies when the user wants\n            to sample very small particles.\n        ignore_objs (None or list of EntityPrim): If @obj is None, this can be used to filter objects when checking\n            for valid cuboid locations. Any sampled rays that hit an object in @ignore_objs will be ignored. If None,\n            no filtering will be used\n        new_ray_per_horizontal_distance (float): per this distance of the cuboid dimension, increase the grid size of\n            the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to\n            the size of the sampled cuboid.\n        hit_proportion (float): the minimum percentage of the hits required across the grid.\n        max_angle_with_z_axis (float): maximum angle between hit normal and positive Z axis allowed. Can be used to\n            disallow downward-facing hits when refuse_downwards=True.\n        parallel_ray_normal_angle_tolerance (float): maximum angle difference between the normal of the center hit\n            and the normal of other hits allowed.\n        hit_to_plane_threshold (float): how far any given hit position can be from the least-squares fit plane to\n            all of the hit positions before the sample is rejected.\n        cuboid_bottom_padding (float): additional padding applied to the bottom of the cuboid. This is needed for the\n            emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove\n            the padding after the emptiness check.\n        undo_cuboid_bottom_padding (bool): Whether the bottom padding that's applied to the cuboid should be removed before return.\n            Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still\n            be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise\n            the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will\n            simply make the sampler undo the padding prior to returning.\n        verify_cuboid_empty (bool): Whether to filter out sampled cuboid locations that are not collision-free. Note\n            that this check will only potentially occur if nonzero cuboid dimensions are specified.\n        refuse_downwards (bool): whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.\n    Returns:\n        list of tuple: list of length num_samples elements where each element is a tuple in the form of\n            (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions\n            are set to None when no successful sampling happens within the max number of attempts. Refusal details are only\n            filled if the gm.DEBUG flag is globally set to True.\n    \"\"\"\nassert start_points.shape == end_points.shape, \\\n        \"the start and end points of raycasting are expected to have the same shape.\"\nnum_samples = start_points.shape[0]\ncuboid_dimensions = np.array(cuboid_dimensions)\nif np.any(cuboid_dimensions &gt; 50.0):\nprint(\"WARNING: Trying to sample for a very large cuboid (at least one dimensions &gt; 50).\"\n\"This will take a prohibitively large amount of time!\")\nassert cuboid_dimensions.ndim &lt;= 2\nassert cuboid_dimensions.shape[-1] == 3, \"Cuboid dimensions need to contain all three dimensions.\"\nif cuboid_dimensions.ndim == 2:\nassert cuboid_dimensions.shape[0] == num_samples, \"Need as many offsets as samples requested.\"\nresults = [(None, None, None, None, defaultdict(list)) for _ in range(num_samples)]\nrigid_bodies = None if obj is None else {link.prim_path for link in obj.links.values()}\nignore_rigid_bodies = None if ignore_objs is None else \\\n        {link.prim_path for ignore_obj in ignore_objs for link in ignore_obj.links.values()}\nfor i in range(num_samples):\nrefusal_reasons = results[i][4]\n# Try each sampled position in the AABB.\nfor start_pos, end_pos in zip(start_points[i], end_points[i]):\n# If we have a list of cuboid dimensions, pick the one that corresponds to this particular sample.\nthis_cuboid_dimensions = cuboid_dimensions if cuboid_dimensions.ndim == 1 else cuboid_dimensions[i]\nzero_cuboid_dimension = (this_cuboid_dimensions == 0.0).all()\nif not zero_cuboid_dimension:\n# Make sure we have valid (nonzero) x and y values\nassert (this_cuboid_dimensions[:-1] &gt; 0).all(), \\\n                    f\"Cuboid x and y dimensions must not be zero if z dimension is nonzero! Got: {this_cuboid_dimensions}\"\n# Obtain the parallel rays using the direction sampling method.\nsources, destinations, grid = get_parallel_rays(\nstart_pos, end_pos, this_cuboid_dimensions[:2] / 2.0, new_ray_per_horizontal_distance,\n)\nsources = np.array(sources)\ndestinations = np.array(destinations)\nelse:\nsources = np.array([start_pos])\ndestinations = np.array([end_pos])\n# Time to cast the rays.\ncast_results = raytest_batch(start_points=sources, end_points=destinations, ignore_bodies=ignore_rigid_bodies)\n# Check whether sufficient number of rays hit the object\nhits = check_rays_hit_object(\ncast_results, hit_proportion, refusal_reasons[\"missed_object\"], rigid_bodies)\nif hits is None:\ncontinue\ncenter_idx = int(len(hits) / 2)\n# Only consider objects whose center idx has a ray hit\nif not hits[center_idx]:\ncontinue\nfiltered_cast_results = []\nfiltered_center_idx = None\nfor idx, hit in enumerate(hits):\nif hit:\nfiltered_cast_results.append(cast_results[idx])\nif idx == center_idx:\nfiltered_center_idx = len(filtered_cast_results) - 1\n# Process the hit positions and normals.\nhit_positions = np.array([ray_res[\"position\"] for ray_res in filtered_cast_results])\nhit_normals = np.array([ray_res[\"normal\"] for ray_res in filtered_cast_results])\nhit_normals /= np.linalg.norm(hit_normals, axis=1, keepdims=True)\nassert filtered_center_idx is not None\nhit_link = filtered_cast_results[filtered_center_idx][\"rigidBody\"]\ncenter_hit_pos = hit_positions[filtered_center_idx]\ncenter_hit_normal = hit_normals[filtered_center_idx]\n# Reject anything facing more than 45deg downwards if requested.\nif refuse_downwards:\nif not check_hit_max_angle_from_z_axis(\ncenter_hit_normal, max_angle_with_z_axis, refusal_reasons[\"downward_normal\"]\n):\ncontinue\n# Check that none of the parallel rays' hit normal differs from center ray by more than threshold.\nif not zero_cuboid_dimension:\nif not check_normal_similarity(center_hit_normal, hit_normals, parallel_ray_normal_angle_tolerance, refusal_reasons[\"hit_normal_similarity\"]):\ncontinue\n# Fit a plane to the points.\nplane_centroid, plane_normal = fit_plane(hit_positions, refusal_reasons[\"fit_plane\"])\nif plane_centroid is None:\ncontinue\n# The fit_plane normal can be facing either direction on the normal axis, but we want it to face away from\n# the object for purposes of normal checking and padding. To do this:\n# We get a vector from the centroid towards the center ray source, and flip the plane normal to match it.\n# The cosine has positive sign if the two vectors are similar and a negative one if not.\nplane_to_source = sources[center_idx] - plane_centroid\nplane_normal *= np.sign(np.dot(plane_to_source, plane_normal))\n# Check that the plane normal is similar to the hit normal\nif not check_normal_similarity(\ncenter_hit_normal, plane_normal[None, :], parallel_ray_normal_angle_tolerance, refusal_reasons[\"plane_normal_similarity\"]\n):\ncontinue\n# Check that the points are all within some acceptable distance of the plane.\nif not check_distance_to_plane(\nhit_positions, plane_centroid, plane_normal, hit_to_plane_threshold, refusal_reasons[\"dist_to_plane\"]\n):\ncontinue\n# Get projection of the base onto the plane, fit a rotation, and compute the new center hit / corners.\nhit_positions = np.array([ray_res.get(\"position\", np.zeros(3)) for ray_res in cast_results])\nprojected_hits = get_projection_onto_plane(hit_positions, plane_centroid, plane_normal)\npadding = cuboid_bottom_padding * plane_normal\nprojected_hits += padding\ncenter_projected_hit = projected_hits[center_idx]\ncuboid_centroid = center_projected_hit + plane_normal * this_cuboid_dimensions[2] / 2.0\nrotation = compute_rotation_from_grid_sample(\ngrid, projected_hits, cuboid_centroid, this_cuboid_dimensions,\nhits, refusal_reasons[\"rotation_not_computable\"])\n# Make sure there are enough hit points that can be used for alignment to find the rotation\nif rotation is None:\ncontinue\ncorner_positions = cuboid_centroid[None, :] + (\nrotation.apply(\n0.5\n* this_cuboid_dimensions\n* np.array(\n[\n[1, 1, -1],\n[-1, 1, -1],\n[-1, -1, -1],\n[1, -1, -1],\n]\n)\n)\n)\n# Now we use the cuboid's diagonals to check that the cuboid is actually empty\nif verify_cuboid_empty and not check_cuboid_empty(\nplane_normal,\ncorner_positions,\nthis_cuboid_dimensions,\nrefusal_reasons[\"cuboid_not_empty\"],\n):\ncontinue\nif undo_cuboid_bottom_padding:\ncuboid_centroid -= padding\nelse:\ncuboid_centroid = center_hit_pos\nif not undo_cuboid_bottom_padding:\npadding = cuboid_bottom_padding * center_hit_normal\ncuboid_centroid += padding\nplane_normal = np.zeros(3)\nrotation = R.from_quat([0, 0, 0, 1])\n# We've found a nice attachment point. Continue onto next point to sample.\nresults[i] = (cuboid_centroid, plane_normal, rotation.as_quat(), hit_link, refusal_reasons)\nbreak\nif gm.DEBUG:\nprint(\"Sampling rejection reasons:\")\ncounter = Counter()\nfor instance in results:\nfor reason, refusals in instance[-1].items():\ncounter[reason] += len(refusals)\nprint(\"\\n\".join(\"%s: %d\" % pair for pair in counter.items()))\nreturn results\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_cuboid_on_object_full_grid_topdown","title":"<code>sample_cuboid_on_object_full_grid_topdown(obj, ray_spacing, cuboid_dimensions, new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE, hit_proportion=m.DEFAULT_HIT_PROPORTION, aabb_offset=m.DEFAULT_AABB_OFFSET, max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS, parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE, hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD, cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING, undo_cuboid_bottom_padding=True, verify_cuboid_empty=True, refuse_downwards=False)</code>","text":"<p>Samples points on an object's surface using ray casting. Rays are sampled with a dense grid from top down.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DatasetObject</code> <p>The object to sample points on.</p> required <code>ray_spacing</code> <code>float</code> <p>spacing between the rays, or equivalently, size of the grid cell, when sampling the start and end points. This implicitly determines the number of cuboids that will be sampled.</p> required <code>cuboid_dimensions</code> <code>n, 3)-array</code> <p>Float sequence of len 3, the size of the empty cuboid we are trying to sample. Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to sample points (instead of cuboids) for significantly better performance. This applies when the user wants to sample very small particles.</p> required <code>new_ray_per_horizontal_distance</code> <code>float</code> <p>per this distance of the cuboid dimension, increase the grid size of the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to the size of the sampled cuboid.</p> <code>m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE</code> <code>hit_proportion</code> <code>float</code> <p>the minimum percentage of the hits required across the grid.</p> <code>m.DEFAULT_HIT_PROPORTION</code> <code>aabb_offset</code> <code>float or 3-array</code> <p>padding for AABB to initiate ray-testing.</p> <code>m.DEFAULT_AABB_OFFSET</code> <code>max_angle_with_z_axis</code> <code>float</code> <p>maximum angle between hit normal and positive Z axis allowed. Can be used to disallow downward-facing hits when refuse_downwards=True.</p> <code>m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS</code> <code>parallel_ray_normal_angle_tolerance</code> <code>float</code> <p>maximum angle difference between the normal of the center hit and the normal of other hits allowed.</p> <code>m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE</code> <code>hit_to_plane_threshold</code> <code>float</code> <p>how far any given hit position can be from the least-squares fit plane to all of the hit positions before the sample is rejected.</p> <code>m.DEFAULT_HIT_TO_PLANE_THRESHOLD</code> <code>cuboid_bottom_padding</code> <code>float</code> <p>additional padding applied to the bottom of the cuboid. This is needed for the emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove the padding after the emptiness check.</p> <code>m.DEFAULT_CUBOID_BOTTOM_PADDING</code> <code>undo_cuboid_bottom_padding</code> <code>bool</code> <p>Whether the bottom padding that's applied to the cuboid should be removed before return. Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will simply make the sampler undo the padding prior to returning.</p> <code>True</code> <code>verify_cuboid_empty</code> <code>bool</code> <p>Whether to filter out sampled cuboid locations that are not collision-free. Note that this check will only potentially occur if nonzero cuboid dimensions are specified.</p> <code>True</code> <code>refuse_downwards</code> <code>bool</code> <p>whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.</p> <code>False</code> <p>Returns:</p> Type Description <p>list of tuple: list of length num_samples elements where each element is a tuple in the form of (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions are set to None when no successful sampling happens within the max number of attempts. Refusal details are only filled if the gm.DEBUG flag is globally set to True.</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def sample_cuboid_on_object_full_grid_topdown(\nobj,\nray_spacing,\ncuboid_dimensions,\nnew_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE,\nhit_proportion=m.DEFAULT_HIT_PROPORTION,\naabb_offset=m.DEFAULT_AABB_OFFSET,\nmax_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS,\nparallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE,\nhit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD,\ncuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING,\nundo_cuboid_bottom_padding=True,\nverify_cuboid_empty=True,\nrefuse_downwards=False,\n):\n\"\"\"\n    Samples points on an object's surface using ray casting.\n    Rays are sampled with a dense grid from top down.\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        ray_spacing (float): spacing between the rays, or equivalently, size of the grid cell, when sampling the\n            start and end points. This implicitly determines the number of cuboids that will be sampled.\n        cuboid_dimensions ((n, 3)-array): Float sequence of len 3, the size of the empty cuboid we are trying to sample.\n            Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using\n            the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to\n            sample points (instead of cuboids) for significantly better performance. This applies when the user wants\n            to sample very small particles.\n        new_ray_per_horizontal_distance (float): per this distance of the cuboid dimension, increase the grid size of\n            the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to\n            the size of the sampled cuboid.\n        hit_proportion (float): the minimum percentage of the hits required across the grid.\n        aabb_offset (float or 3-array): padding for AABB to initiate ray-testing.\n        max_angle_with_z_axis (float): maximum angle between hit normal and positive Z axis allowed. Can be used to\n            disallow downward-facing hits when refuse_downwards=True.\n        parallel_ray_normal_angle_tolerance (float): maximum angle difference between the normal of the center hit\n            and the normal of other hits allowed.\n        hit_to_plane_threshold (float): how far any given hit position can be from the least-squares fit plane to\n            all of the hit positions before the sample is rejected.\n        cuboid_bottom_padding (float): additional padding applied to the bottom of the cuboid. This is needed for the\n            emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove\n            the padding after the emptiness check.\n        undo_cuboid_bottom_padding (bool): Whether the bottom padding that's applied to the cuboid should be removed before return.\n            Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still\n            be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise\n            the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will\n            simply make the sampler undo the padding prior to returning.\n        verify_cuboid_empty (bool): Whether to filter out sampled cuboid locations that are not collision-free. Note\n            that this check will only potentially occur if nonzero cuboid dimensions are specified.\n        refuse_downwards (bool): whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.\n    Returns:\n        list of tuple: list of length num_samples elements where each element is a tuple in the form of\n            (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions\n            are set to None when no successful sampling happens within the max number of attempts. Refusal details are only\n            filled if the gm.DEBUG flag is globally set to True.\n    \"\"\"\nstart_points, end_points = sample_raytest_start_end_full_grid_topdown(\nobj,\nray_spacing,\naabb_offset=aabb_offset,\n)\nreturn sample_cuboid_on_object(\nobj,\nstart_points,\nend_points,\ncuboid_dimensions,\nnew_ray_per_horizontal_distance=new_ray_per_horizontal_distance,\nhit_proportion=hit_proportion,\nmax_angle_with_z_axis=max_angle_with_z_axis,\nparallel_ray_normal_angle_tolerance=parallel_ray_normal_angle_tolerance,\nhit_to_plane_threshold=hit_to_plane_threshold,\ncuboid_bottom_padding=cuboid_bottom_padding,\nundo_cuboid_bottom_padding=undo_cuboid_bottom_padding,\nverify_cuboid_empty=verify_cuboid_empty,\nrefuse_downwards=refuse_downwards,\n)\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_cuboid_on_object_symmetric_bimodal_distribution","title":"<code>sample_cuboid_on_object_symmetric_bimodal_distribution(obj, num_samples, cuboid_dimensions, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities, new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE, hit_proportion=m.DEFAULT_HIT_PROPORTION, aabb_offset=m.DEFAULT_AABB_OFFSET, max_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS, max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS, parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE, hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD, cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING, undo_cuboid_bottom_padding=True, verify_cuboid_empty=True, refuse_downwards=False)</code>","text":"<p>Samples points on an object's surface using ray casting. Rays are sampled with a symmetric bimodal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DatasetObject</code> <p>The object to sample points on.</p> required <code>num_samples</code> <code>int</code> <p>the number of points to try to sample.</p> required <code>cuboid_dimensions</code> <code>n, 3)-array</code> <p>Float sequence of len 3, the size of the empty cuboid we are trying to sample. Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to sample points (instead of cuboids) for significantly better performance. This applies when the user wants to sample very small particles.</p> required <code>bimodal_mean_fraction</code> <code>float</code> <p>the mean of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p> required <code>bimodal_stdev_fraction</code> <code>float</code> <p>the standard deviation of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p> required <code>axis_probabilities</code> <code>3-array</code> <p>the probability of ray casting along each axis.</p> required <code>new_ray_per_horizontal_distance</code> <code>float</code> <p>per this distance of the cuboid dimension, increase the grid size of the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to the size of the sampled cuboid.</p> <code>m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE</code> <code>hit_proportion</code> <code>float</code> <p>the minimum percentage of the hits required across the grid.</p> <code>m.DEFAULT_HIT_PROPORTION</code> <code>aabb_offset</code> <code>float or 3-array</code> <p>padding for AABB to initiate ray-testing.</p> <code>m.DEFAULT_AABB_OFFSET</code> <code>max_sampling_attempts</code> <code>int</code> <p>how many times sampling will be attempted for each requested point.</p> <code>m.DEFAULT_MAX_SAMPLING_ATTEMPTS</code> <code>max_angle_with_z_axis</code> <code>float</code> <p>maximum angle between hit normal and positive Z axis allowed. Can be used to disallow downward-facing hits when refuse_downwards=True.</p> <code>m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS</code> <code>parallel_ray_normal_angle_tolerance</code> <code>float</code> <p>maximum angle difference between the normal of the center hit and the normal of other hits allowed.</p> <code>m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE</code> <code>hit_to_plane_threshold</code> <code>float</code> <p>how far any given hit position can be from the least-squares fit plane to all of the hit positions before the sample is rejected.</p> <code>m.DEFAULT_HIT_TO_PLANE_THRESHOLD</code> <code>cuboid_bottom_padding</code> <code>float</code> <p>additional padding applied to the bottom of the cuboid. This is needed for the emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove the padding after the emptiness check.</p> <code>m.DEFAULT_CUBOID_BOTTOM_PADDING</code> <code>undo_cuboid_bottom_padding</code> <code>bool</code> <p>Whether the bottom padding that's applied to the cuboid should be removed before return. Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will simply make the sampler undo the padding prior to returning.</p> <code>True</code> <code>verify_cuboid_empty</code> <code>bool</code> <p>Whether to filter out sampled cuboid locations that are not collision-free. Note that this check will only potentially occur if nonzero cuboid dimensions are specified.</p> <code>True</code> <code>refuse_downwards</code> <code>bool</code> <p>whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.</p> <code>False</code> <p>Returns:</p> Type Description <p>list of tuple: list of length num_samples elements where each element is a tuple in the form of (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions are set to None when no successful sampling happens within the max number of attempts. Refusal details are only filled if the gm.DEBUG flag is globally set to True.</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def sample_cuboid_on_object_symmetric_bimodal_distribution(\nobj,\nnum_samples,\ncuboid_dimensions,\nbimodal_mean_fraction,\nbimodal_stdev_fraction,\naxis_probabilities,\nnew_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE,\nhit_proportion=m.DEFAULT_HIT_PROPORTION,\naabb_offset=m.DEFAULT_AABB_OFFSET,\nmax_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS,\nmax_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS,\nparallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE,\nhit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD,\ncuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING,\nundo_cuboid_bottom_padding=True,\nverify_cuboid_empty=True,\nrefuse_downwards=False,\n):\n\"\"\"\n    Samples points on an object's surface using ray casting.\n    Rays are sampled with a symmetric bimodal distribution.\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        num_samples (int): the number of points to try to sample.\n        cuboid_dimensions ((n, 3)-array): Float sequence of len 3, the size of the empty cuboid we are trying to sample.\n            Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using\n            the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to\n            sample points (instead of cuboids) for significantly better performance. This applies when the user wants\n            to sample very small particles.\n        bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the\n            min-max range.\n        bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a\n            fraction of the min-max range.\n        axis_probabilities (3-array): the probability of ray casting along each axis.\n        new_ray_per_horizontal_distance (float): per this distance of the cuboid dimension, increase the grid size of\n            the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to\n            the size of the sampled cuboid.\n        hit_proportion (float): the minimum percentage of the hits required across the grid.\n        aabb_offset (float or 3-array): padding for AABB to initiate ray-testing.\n        max_sampling_attempts (int): how many times sampling will be attempted for each requested point.\n        max_angle_with_z_axis (float): maximum angle between hit normal and positive Z axis allowed. Can be used to\n            disallow downward-facing hits when refuse_downwards=True.\n        parallel_ray_normal_angle_tolerance (float): maximum angle difference between the normal of the center hit\n            and the normal of other hits allowed.\n        hit_to_plane_threshold (float): how far any given hit position can be from the least-squares fit plane to\n            all of the hit positions before the sample is rejected.\n        cuboid_bottom_padding (float): additional padding applied to the bottom of the cuboid. This is needed for the\n            emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove\n            the padding after the emptiness check.\n        undo_cuboid_bottom_padding (bool): Whether the bottom padding that's applied to the cuboid should be removed before return.\n            Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still\n            be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise\n            the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will\n            simply make the sampler undo the padding prior to returning.\n        verify_cuboid_empty (bool): Whether to filter out sampled cuboid locations that are not collision-free. Note\n            that this check will only potentially occur if nonzero cuboid dimensions are specified.\n        refuse_downwards (bool): whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.\n    Returns:\n        list of tuple: list of length num_samples elements where each element is a tuple in the form of\n            (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions\n            are set to None when no successful sampling happens within the max number of attempts. Refusal details are only\n            filled if the gm.DEBUG flag is globally set to True.\n    \"\"\"\nstart_points, end_points = sample_raytest_start_end_symmetric_bimodal_distribution(\nobj,\nnum_samples,\nbimodal_mean_fraction,\nbimodal_stdev_fraction,\naxis_probabilities,\naabb_offset=aabb_offset,\nmax_sampling_attempts=max_sampling_attempts,\n)\nreturn sample_cuboid_on_object(\nobj,\nstart_points,\nend_points,\ncuboid_dimensions,\nnew_ray_per_horizontal_distance=new_ray_per_horizontal_distance,\nhit_proportion=hit_proportion,\nmax_angle_with_z_axis=max_angle_with_z_axis,\nparallel_ray_normal_angle_tolerance=parallel_ray_normal_angle_tolerance,\nhit_to_plane_threshold=hit_to_plane_threshold,\ncuboid_bottom_padding=cuboid_bottom_padding,\nundo_cuboid_bottom_padding=undo_cuboid_bottom_padding,\nverify_cuboid_empty=verify_cuboid_empty,\nrefuse_downwards=refuse_downwards,\n)\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_origin_positions","title":"<code>sample_origin_positions(mins, maxes, count, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities)</code>","text":"<p>Sample ray casting origin positions with a given distribution.</p> <p>The way the sampling works is that for each particle, it will sample two coordinates uniformly and one using a symmetric, bimodal truncated normal distribution. This way, the particles will mostly be close to the faces of the AABB (given a correctly parameterized bimodal truncated normal) and will be spread across each face, but there will still be a small number of particles spawned inside the object if it has an interior.</p> <p>Parameters:</p> Name Type Description Default <code>mins</code> <code>3-array</code> <p>the minimum coordinate along each axis.</p> required <code>maxes</code> <code>3-array</code> <p>the maximum coordinate along each axis.</p> required <code>count</code> <code>int</code> <p>Number of origins to sample.</p> required <code>bimodal_mean_fraction</code> <code>float</code> <p>the mean of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p> required <code>bimodal_stdev_fraction</code> <code>float</code> <p>the standard deviation of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p> required <code>axis_probabilities</code> <code>3-array</code> <p>the probability of ray casting along each axis.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>List where each element is (ray cast axis index, bool whether the axis was sampled from the top side, [x, y, z]) tuples.</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def sample_origin_positions(mins, maxes, count, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities):\n\"\"\"\n    Sample ray casting origin positions with a given distribution.\n    The way the sampling works is that for each particle, it will sample two coordinates uniformly and one\n    using a symmetric, bimodal truncated normal distribution. This way, the particles will mostly be close to the faces\n    of the AABB (given a correctly parameterized bimodal truncated normal) and will be spread across each face,\n    but there will still be a small number of particles spawned inside the object if it has an interior.\n    Args:\n        mins (3-array): the minimum coordinate along each axis.\n        maxes (3-array): the maximum coordinate along each axis.\n        count (int): Number of origins to sample.\n        bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the\n            min-max range.\n        bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a\n            fraction of the min-max range.\n        axis_probabilities (3-array): the probability of ray casting along each axis.\n    Returns:\n        list: List where each element is (ray cast axis index, bool whether the axis was sampled from the top side,\n            [x, y, z]) tuples.\n    \"\"\"\nassert len(mins.shape) == 1\nassert mins.shape == maxes.shape\nresults = []\nfor i in range(count):\n# Get the uniform sample first.\nposition = np.random.rand(3)\n# Sample the bimodal normal.\nbottom = (0 - bimodal_mean_fraction) / bimodal_stdev_fraction\ntop = (1 - bimodal_mean_fraction) / bimodal_stdev_fraction\nbimodal_sample = truncnorm.rvs(bottom, top, loc=bimodal_mean_fraction, scale=bimodal_stdev_fraction)\n# Pick which axis the bimodal normal sample should go to.\nbimodal_axis = np.random.choice([0, 1, 2], p=axis_probabilities)\n# Choose which side of the axis to sample from. We only sample from the top for the Z axis.\nif bimodal_axis == 2:\nbimodal_axis_top_side = True\nelse:\nbimodal_axis_top_side = np.random.choice([True, False])\n# Move sample based on chosen side.\nposition[bimodal_axis] = bimodal_sample if bimodal_axis_top_side else 1 - bimodal_sample\n# Scale the position from the standard normal range to the min-max range.\nscaled_position = mins + (maxes - mins) * position\n# Save the result.\nresults.append((bimodal_axis, bimodal_axis_top_side, scaled_position))\nreturn results\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_raytest_start_end_full_grid_topdown","title":"<code>sample_raytest_start_end_full_grid_topdown(obj, ray_spacing, aabb_offset=m.DEFAULT_AABB_OFFSET)</code>","text":"<p>Sample the start points and end points around a given object by a dense grid from top down.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DatasetObject</code> <p>The object to sample points on.</p> required <code>ray_spacing</code> <code>float</code> <p>spacing between the rays, or equivalently, size of the grid cell</p> required <code>aabb_offset</code> <code>float or numpy array</code> <p>padding for AABB to initiate ray-testing.</p> <code>m.DEFAULT_AABB_OFFSET</code> <p>Returns:</p> Type Description <p>2-tuple: - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for     raycasting defined in the world frame - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for     raycasting defined in the world frame</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def sample_raytest_start_end_full_grid_topdown(\nobj,\nray_spacing,\naabb_offset=m.DEFAULT_AABB_OFFSET,\n):\n\"\"\"\n    Sample the start points and end points around a given object by a dense grid from top down.\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        ray_spacing (float): spacing between the rays, or equivalently, size of the grid cell\n        aabb_offset (float or numpy array): padding for AABB to initiate ray-testing.\n    Returns:\n        2-tuple:\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for\n                raycasting defined in the world frame\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for\n                raycasting defined in the world frame\n    \"\"\"\nbbox_center, bbox_orn, bbox_bf_extent, _ = obj.get_base_aligned_bbox(xy_aligned=True, fallback_to_aabb=True)\nhalf_extent_with_offset = (bbox_bf_extent / 2) + aabb_offset\nx = np.linspace(-half_extent_with_offset[0], half_extent_with_offset[0], int(half_extent_with_offset[0] * 2 / ray_spacing))\ny = np.linspace(-half_extent_with_offset[1], half_extent_with_offset[1], int(half_extent_with_offset[1] * 2 / ray_spacing))\nn_rays = len(x) * len(y)\nstart_points = np.stack([\nnp.tile(x, len(y)),\nnp.repeat(y, len(x)),\nnp.ones(n_rays) * half_extent_with_offset[2],\n]).T\nend_points = np.copy(start_points)\nend_points[:, 2] = -half_extent_with_offset[2]\n# Convert the points into the world frame\nto_wf_transform = T.pose2mat((bbox_center, bbox_orn))\nstart_points = trimesh.transformations.transform_points(start_points, to_wf_transform)\nend_points = trimesh.transformations.transform_points(end_points, to_wf_transform)\nstart_points = np.expand_dims(start_points, axis=1)\nend_points = np.expand_dims(end_points, axis=1)\nreturn start_points, end_points\n</code></pre>"},{"location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_raytest_start_end_symmetric_bimodal_distribution","title":"<code>sample_raytest_start_end_symmetric_bimodal_distribution(obj, num_samples, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities, aabb_offset=m.DEFAULT_AABB_OFFSET, max_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS)</code>","text":"<p>Sample the start points and end points around a given object by a symmetric bimodal distribution</p> <p>obj (DatasetObject): The object to sample points on. num_samples (int): the number of points to try to sample. bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the     min-max range. bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a     fraction of the min-max range. axis_probabilities (3-array): probability of ray casting along each axis. aabb_offset (float or 3-array): padding for AABB to initiate ray-testing. max_sampling_attempts (int): how many times sampling will be attempted for each requested point.</p> <p>Returns:</p> Type Description <p>2-tuple: - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for     raycasting defined in the world frame - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for     raycasting defined in the world frame</p> Source code in <code>omnigibson/utils/sampling_utils.py</code> <pre><code>def sample_raytest_start_end_symmetric_bimodal_distribution(\nobj,\nnum_samples,\nbimodal_mean_fraction,\nbimodal_stdev_fraction,\naxis_probabilities,\naabb_offset=m.DEFAULT_AABB_OFFSET,\nmax_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS,\n):\n\"\"\"\n    Sample the start points and end points around a given object by a symmetric bimodal distribution\n    obj (DatasetObject): The object to sample points on.\n    num_samples (int): the number of points to try to sample.\n    bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the\n        min-max range.\n    bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a\n        fraction of the min-max range.\n    axis_probabilities (3-array): probability of ray casting along each axis.\n    aabb_offset (float or 3-array): padding for AABB to initiate ray-testing.\n    max_sampling_attempts (int): how many times sampling will be attempted for each requested point.\n    Returns:\n        2-tuple:\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for\n                raycasting defined in the world frame\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for\n                raycasting defined in the world frame\n    \"\"\"\nbbox_center, bbox_orn, bbox_bf_extent, _ = obj.get_base_aligned_bbox(xy_aligned=True, fallback_to_aabb=True)\nhalf_extent_with_offset = (bbox_bf_extent / 2) + aabb_offset\nstart_points = np.zeros((num_samples, max_sampling_attempts, 3))\nend_points = np.zeros((num_samples, max_sampling_attempts, 3))\nfor i in range(num_samples):\n# Sample the starting positions in advance.\n# TODO: Narrow down the sampling domain so that we don't sample scenarios where the center is in-domain but the\n# full extent isn't. Currently a lot of samples are being wasted because of this.\nsamples = sample_origin_positions(\n-half_extent_with_offset,\nhalf_extent_with_offset,\nmax_sampling_attempts,\nbimodal_mean_fraction,\nbimodal_stdev_fraction,\naxis_probabilities,\n)\n# Try each sampled position in the AABB.\nfor j, (axis, is_top, start_point) in enumerate(samples):\n# Compute the ray's destination using the sampling &amp; AABB information.\nend_point = compute_ray_destination(\naxis, is_top, start_point, -half_extent_with_offset, half_extent_with_offset\n)\nstart_points[i][j] = start_point\nend_points[i][j] = end_point\n# Convert the points into the world frame\norig_shape = start_points.shape\nto_wf_transform = T.pose2mat((bbox_center, bbox_orn))\nstart_points = trimesh.transformations.transform_points(start_points.reshape(-1, 3), to_wf_transform).reshape(orig_shape)\nend_points = trimesh.transformations.transform_points(end_points.reshape(-1, 3), to_wf_transform).reshape(orig_shape)\nreturn start_points, end_points\n</code></pre>"},{"location":"reference/utils/sim_utils.html","title":"sim_utils","text":""},{"location":"reference/utils/sim_utils.html#utils.sim_utils.check_collision","title":"<code>check_collision(prims=None, prims_check=None, prims_exclude=None, step_physics=False)</code>","text":"<p>Checks if any valid collisions occurred during the most recent physics timestep associated with prims @prims</p> <p>Parameters:</p> Name Type Description Default <code>prims</code> <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code> <p>Prim(s) to check for collision. If None, will check against all objects currently in the scene.</p> <code>None</code> <code>prims_check</code> <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code> <p>If specified, will only check for collisions with these specific prim(s)</p> <code>None</code> <code>prims_exclude</code> <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code> <p>If specified, will explicitly ignore any collisions with these specific prim(s)</p> <code>None</code> <code>step_physics</code> <code>bool</code> <p>Whether to step the physics first before checking collisions. Default is False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if a valid collision has occurred, else False</p> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def check_collision(prims=None, prims_check=None, prims_exclude=None, step_physics=False):\n\"\"\"\n    Checks if any valid collisions occurred during the most recent physics timestep associated with prims @prims\n    Args:\n        prims (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) to check for collision.\n            If None, will check against all objects currently in the scene.\n        prims_check (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            only check for collisions with these specific prim(s)\n        prims_exclude (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            explicitly ignore any collisions with these specific prim(s)\n        step_physics (bool): Whether to step the physics first before checking collisions. Default is False\n    Returns:\n        bool: True if a valid collision has occurred, else False\n    \"\"\"\nreturn len(get_collisions(\nprims=prims,\nprims_check=prims_check,\nprims_exclude=prims_exclude,\nstep_physics=step_physics)) &gt; 0\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.check_deletable_prim","title":"<code>check_deletable_prim(prim_path)</code>","text":"<p>Checks whether the prim defined at @prim_path can be deleted.</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Path defining which prim should be checked for deletion</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the prim can be deleted or not</p> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def check_deletable_prim(prim_path):\n\"\"\"\n    Checks whether the prim defined at @prim_path can be deleted.\n    Args:\n        prim_path (str): Path defining which prim should be checked for deletion\n    Returns:\n        bool: Whether the prim can be deleted or not\n    \"\"\"\nif is_prim_no_delete(prim_path):\nreturn False\nif is_prim_ancestral(prim_path):\nreturn False\nif get_prim_type_name(prim_path=prim_path) == \"PhysicsScene\":\nreturn False\nif prim_path == \"/World\":\nreturn False\nif prim_path == \"/\":\nreturn False\n# Don't remove any /Render prims as that can cause crashes\nif prim_path.startswith(\"/Render\"):\nreturn False\nreturn True\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.filter_collisions","title":"<code>filter_collisions(collisions, filter_prims)</code>","text":"<p>Filters collision pairs @collisions based on a set of prims @filter_prims.</p> <p>Parameters:</p> Name Type Description Default <code>collisions</code> <code>set of 2-tuple</code> <p>Collision pairs that should be filtered</p> required <code>filter_prims</code> <code>EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code> <p>Prim(s) specifying which collisions to filter for. Any collisions that include prims from this filter set will be removed</p> required <p>Returns:</p> Type Description <p>set of 2-tuple: Filtered collision pairs</p> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def filter_collisions(collisions, filter_prims):\n\"\"\"\n    Filters collision pairs @collisions based on a set of prims @filter_prims.\n    Args:\n        collisions (set of 2-tuple): Collision pairs that should be filtered\n        filter_prims (EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) specifying which\n            collisions to filter for. Any collisions that include prims from this filter\n            set will be removed\n    Returns:\n        set of 2-tuple: Filtered collision pairs\n    \"\"\"\npaths = prims_to_rigid_prim_set(filter_prims)\nfiltered_collisions = set()\nfor pair in collisions:\nif set(pair).isdisjoint(paths):\nfiltered_collisions.add(pair)\nreturn filtered_collisions\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.get_collisions","title":"<code>get_collisions(prims=None, prims_check=None, prims_exclude=None, step_physics=False)</code>","text":"<p>Grab collisions that occurred during the most recent physics timestep associated with prims @prims</p> <p>Parameters:</p> Name Type Description Default <code>prims</code> <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code> <p>Prim(s) to check for collision. If None, will check against all objects currently in the scene.</p> <code>None</code> <code>prims_check</code> <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code> <p>If specified, will only check for collisions with these specific prim(s)</p> <code>None</code> <code>prims_exclude</code> <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code> <p>If specified, will explicitly ignore any collisions with these specific prim(s)</p> <code>None</code> <code>step_physics</code> <code>bool</code> <p>Whether to step the physics first before checking collisions. Default is False</p> <code>False</code> <p>Returns:</p> Type Description <p>set of 2-tuple: Unique collision pairs occurring in the simulation at the current timestep between the specified prim(s), represented by their prim_paths</p> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def get_collisions(prims=None, prims_check=None, prims_exclude=None, step_physics=False):\n\"\"\"\n    Grab collisions that occurred during the most recent physics timestep associated with prims @prims\n    Args:\n        prims (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) to check for collision.\n            If None, will check against all objects currently in the scene.\n        prims_check (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            only check for collisions with these specific prim(s)\n        prims_exclude (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            explicitly ignore any collisions with these specific prim(s)\n        step_physics (bool): Whether to step the physics first before checking collisions. Default is False\n    Returns:\n        set of 2-tuple: Unique collision pairs occurring in the simulation at the current timestep between the\n            specified prim(s), represented by their prim_paths\n    \"\"\"\n# Make sure sim is playing\nassert og.sim.is_playing(), \"Cannot get collisions while sim is not playing!\"\n# Optionally step physics and then update contacts\nif step_physics:\nog.sim.step_physics()\n# Standardize inputs\nprims = og.sim.scene.objects if prims is None else prims if isinstance(prims, Iterable) else [prims]\nprims_check = [] if prims_check is None else prims_check if isinstance(prims_check, Iterable) else [prims_check]\nprims_exclude = [] if prims_exclude is None else prims_exclude if isinstance(prims_exclude, Iterable) else [prims_exclude]\n# Convert into prim paths to check for collision\ndef get_paths_from_rigid_prims(inp_prims):\nreturn {prim.prim_path for prim in inp_prims}\ndef get_contacts(inp_prims):\nreturn {(c.body0, c.body1) for prim in inp_prims for c in prim.contact_list()}\nrprims = prims_to_rigid_prim_set(prims)\nrprims_check = prims_to_rigid_prim_set(prims_check)\nrprims_exclude = prims_to_rigid_prim_set(prims_exclude)\npaths = get_paths_from_rigid_prims(rprims)\npaths_check = get_paths_from_rigid_prims(rprims_check)\npaths_exclude = get_paths_from_rigid_prims(rprims_exclude)\n# Run sanity checks\nassert paths_check.isdisjoint(paths_exclude), \\\n        f\"Paths to check and paths to ignore collisions for should be mutually exclusive! \" \\\n        f\"paths_check: {paths_check}, paths_exclude: {paths_exclude}\"\n# Determine whether we're checking / filtering any collision from collision set A\nshould_check_collisions = len(paths_check) &gt; 0\nshould_filter_collisions = len(paths_exclude) &gt; 0\n# Get all collisions from the objects set\ncollisions = get_contacts(rprims)\n# Only run the following (expensive) code if we are actively using filtering criteria\nif should_check_collisions or should_filter_collisions:\n# First filter out unnecessary collisions\nif should_filter_collisions:\n# First filter pass, remove the intersection of the main contacts and the contacts from the exclusion set minus\n# the intersection between the exclusion and normal set\n# This filters out any matching collisions in the exclusion set that are NOT an overlap\n# between @rprims and @rprims_exclude\nrprims_exclude_intersect = rprims_exclude.intersection(rprims)\nexclude_disjoint_collisions = get_contacts(rprims_exclude - rprims_exclude_intersect)\ncollisions.difference_update(exclude_disjoint_collisions)\n# Second filter pass, we remove collisions that may include self-collisions\n# This is a bit more tricky because we need to actually look at the individual contact pairs to determine\n# whether it's a collision (which may include a self-collision) that should be filtered\n# We do this by grabbing the contacts of the intersection between the exclusion and normal rprims sets,\n# and then making sure the resulting contact pair sets are completely disjoint from the paths intersection\nexclude_intersect_collisions = get_contacts(rprims_exclude_intersect)\ncollisions.difference_update({pair for pair in exclude_intersect_collisions if paths.issuperset(set(pair))})\n# Now, we additionally check for explicit collisions, filtering out any that do not meet this criteria\n# This is essentially the inverse of the filter collision process, where we do two passes again, but for each\n# case we look at the union rather than the subtraction of the two sets\nif should_check_collisions:\n# First check pass, keep the intersection of the main contacts and the contacts from the check set minus\n# the intersection between the check and normal set\n# This keeps any matching collisions in the check set that overlap between @rprims and @rprims_check\nrprims_check_intersect = rprims_check.intersection(rprims)\ncheck_disjoint_collisions = get_contacts(rprims_check - rprims_check_intersect)\nvalid_other_collisions = collisions.intersection(check_disjoint_collisions)\n# Second check pass, we additionally keep collisions that may include self-collisions\n# This is a bit more tricky because we need to actually look at the individual contact pairs to determine\n# whether it's a collision (which may include a self-collision) that should be kept\n# We do this by grabbing the contacts of the intersection between the check and normal rprims sets,\n# and then making sure the resulting contact pair sets is strictly a subset of the original set\n# Lastly, we only keep the intersection of this resulting set with the original collision set, so that\n# any previously filtered collisions are respected\ncheck_intersect_collisions = get_contacts(rprims_check_intersect)\nvalid_intersect_collisions = collisions.intersection({pair for pair in check_intersect_collisions if paths.issuperset(set(pair))})\n# Collisions is union of valid other and valid self collisions\ncollisions = valid_other_collisions.union(valid_intersect_collisions)\n# Only going into this if it is for logging --&gt; efficiency\nif gm.DEBUG:\nfor item in collisions:\nlog.debug(\"linkA:{}, linkB:{}\".format(item[0], item[1]))\nreturn collisions\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.land_object","title":"<code>land_object(obj, pos, quat=None, z_offset=None)</code>","text":"<p>Land the object at the specified position @pos, given a valid position and orientation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object to place in the environment</p> required <code>pos</code> <code>3-array</code> <p>Global (x,y,z) location to place the object</p> required <code>quat</code> <code>None or 4-array</code> <p>Optional (x,y,z,w) quaternion orientation when placing the object. If None, a random orientation about the z-axis will be sampled</p> <code>None</code> <code>z_offset</code> <code>None or float</code> <p>Optional additional z_offset to apply</p> <code>None</code> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def land_object(obj, pos, quat=None, z_offset=None):\n\"\"\"\n    Land the object at the specified position @pos, given a valid position and orientation.\n    Args:\n        obj (BaseObject): Object to place in the environment\n        pos (3-array): Global (x,y,z) location to place the object\n        quat (None or 4-array): Optional (x,y,z,w) quaternion orientation when placing the object.\n            If None, a random orientation about the z-axis will be sampled\n        z_offset (None or float): Optional additional z_offset to apply\n    \"\"\"\n# Make sure sim is playing\nassert og.sim.is_playing(), \"Cannot land object while sim is not playing!\"\n# Set the object's pose\nquat = T.euler2quat([0, 0, np.random.uniform(0, np.pi * 2)]) if quat is None else quat\nplace_base_pose(obj, pos, quat, z_offset)\nobj.keep_still()\n# Check to make sure we landed successfully\n# land for maximum 1 second, should fall down ~5 meters\nland_success = False\nmax_simulator_step = int(1.0 / og.sim.get_rendering_dt())\nfor _ in range(max_simulator_step):\n# Run a sim step and see if we have any contacts\nog.sim.step()\nland_success = check_collision(prims=obj)\nif land_success:\n# Once we're successful, we can break immediately\nlog.info(f\"Landed object {obj.name} successfully!\")\nbreak\n# Print out warning in case we failed to land the object successfully\nif not land_success:\nlog.warning(f\"Object {obj.name} failed to land.\")\nobj.keep_still()\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.place_base_pose","title":"<code>place_base_pose(obj, pos, quat=None, z_offset=None)</code>","text":"<p>Place the object so that its base (z-min) rests at the location of @pos</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object to place in the environment</p> required <code>pos</code> <code>3-array</code> <p>Global (x,y,z) location to place the base of the robot</p> required <code>quat</code> <code>None or 4-array</code> <p>Optional (x,y,z,w) quaternion orientation when placing the object. If None, the object's current orientation will be used</p> <code>None</code> <code>z_offset</code> <code>None or float</code> <p>Optional additional z_offset to apply</p> <code>None</code> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def place_base_pose(obj, pos, quat=None, z_offset=None):\n\"\"\"\n    Place the object so that its base (z-min) rests at the location of @pos\n    Args:\n        obj (BaseObject): Object to place in the environment\n        pos (3-array): Global (x,y,z) location to place the base of the robot\n        quat (None or 4-array): Optional (x,y,z,w) quaternion orientation when placing the object.\n            If None, the object's current orientation will be used\n        z_offset (None or float): Optional additional z_offset to apply\n    \"\"\"\n# avoid circular dependency\nfrom omnigibson.object_states import AABB\n# Make sure AABB is up-to-date before grabbing value\nget_physx_simulation_interface().fetch_results()\nBoundingBoxAPI.clear()\nobj.states[AABB].clear_cache()\nlower, _ = obj.states[AABB].get_value()\ncur_pos = obj.get_position()\nz_diff = cur_pos[2] - lower[2]\nobj.set_position_orientation(pos + np.array([0, 0, z_diff if z_offset is None else z_diff + z_offset]), quat)\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.prims_to_rigid_prim_set","title":"<code>prims_to_rigid_prim_set(inp_prims)</code>","text":"<p>Converts prims @inp_prims into its corresponding set of rigid prims</p> <p>Parameters:</p> Name Type Description Default <code>inp_prims</code> <code>list of RigidPrim or EntityPrim</code> <p>Arbitrary prims</p> required <p>Returns:</p> Type Description <p>set of RigidPrim: Aggregated set of RigidPrims from @inp_prims</p> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def prims_to_rigid_prim_set(inp_prims):\n\"\"\"\n    Converts prims @inp_prims into its corresponding set of rigid prims\n    Args:\n        inp_prims (list of RigidPrim or EntityPrim): Arbitrary prims\n    Returns:\n        set of RigidPrim: Aggregated set of RigidPrims from @inp_prims\n    \"\"\"\n# Avoid circular imports\nfrom omnigibson.prims.entity_prim import EntityPrim\nfrom omnigibson.prims.rigid_prim import RigidPrim\nout = set()\nfor prim in inp_prims:\nif isinstance(prim, EntityPrim):\nout.update({link for link in prim.links.values()})\nelif isinstance(prim, RigidPrim):\nout.add(prim)\nelse:\nraise ValueError(f\"Inputted prims must be either EntityPrim or RigidPrim instances \"\nf\"when getting collisions! Type: {type(prim)}\")\nreturn out\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.set_carb_setting","title":"<code>set_carb_setting(carb_settings, setting, value)</code>","text":"<p>Convenience function to set settings.</p> <p>Parameters:</p> Name Type Description Default <code>setting</code> <code>str</code> <p>Name of setting to change.</p> required <code>value</code> <code>Any</code> <p>New value for the setting.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the type of value does not match setting type.</p> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def set_carb_setting(carb_settings, setting, value):\n\"\"\"\n    Convenience function to set settings.\n    Args:\n        setting (str): Name of setting to change.\n        value (Any): New value for the setting.\n    Raises:\n        TypeError: If the type of value does not match setting type.\n    \"\"\"\nif isinstance(value, str):\ncarb_settings.set_string(setting, value)\nelif isinstance(value, bool):\ncarb_settings.set_bool(setting, value)\nelif isinstance(value, int):\ncarb_settings.set_int(setting, value)\nelif isinstance(value, float):\ncarb_settings.set_float(setting, value)\nelif isinstance(value, Iterable) and not isinstance(value, dict):\nif len(value) == 0:\nraise TypeError(f\"Array of type {type(value)} must be nonzero.\")\nif isinstance(value[0], str):\ncarb_settings.set_string_array(setting, value)\nelif isinstance(value[0], bool):\ncarb_settings.set_bool_array(setting, value)\nelif isinstance(value[0], int):\ncarb_settings.set_int_array(setting, value)\nelif isinstance(value[0], float):\ncarb_settings.set_float_array(setting, value)\nelse:\nraise TypeError(f\"Value of type {type(value)} is not supported.\")\nelse:\nraise TypeError(f\"Value of type {type(value)} is not supported.\")\n</code></pre>"},{"location":"reference/utils/sim_utils.html#utils.sim_utils.test_valid_pose","title":"<code>test_valid_pose(obj, pos, quat=None, z_offset=None)</code>","text":"<p>Test if the object can be placed with no collision.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BaseObject</code> <p>Object to place in the environment</p> required <code>pos</code> <code>3-array</code> <p>Global (x,y,z) location to place the object</p> required <code>quat</code> <code>None or 4-array</code> <p>Optional (x,y,z,w) quaternion orientation when placing the object. If None, the object's current orientation will be used</p> <code>None</code> <code>z_offset</code> <code>None or float</code> <p>Optional additional z_offset to apply</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the placed object position is valid</p> Source code in <code>omnigibson/utils/sim_utils.py</code> <pre><code>def test_valid_pose(obj, pos, quat=None, z_offset=None):\n\"\"\"\n    Test if the object can be placed with no collision.\n    Args:\n        obj (BaseObject): Object to place in the environment\n        pos (3-array): Global (x,y,z) location to place the object\n        quat (None or 4-array): Optional (x,y,z,w) quaternion orientation when placing the object.\n            If None, the object's current orientation will be used\n        z_offset (None or float): Optional additional z_offset to apply\n    Returns:\n        bool: Whether the placed object position is valid\n    \"\"\"\n# Make sure sim is playing\nassert og.sim.is_playing(), \"Cannot test valid pose while sim is not playing!\"\n# Store state before checking object position\nstate = og.sim.scene.dump_state(serialized=False)\n# Set the pose of the object\nplace_base_pose(obj, pos, quat, z_offset)\nobj.keep_still()\n# Check whether we're in collision after taking a single physics step\nin_collision = check_collision(prims=obj, step_physics=True)\n# Restore state after checking the collision\nog.sim.load_state(state, serialized=False)\n# Valid if there are no collisions\nreturn not in_collision\n</code></pre>"},{"location":"reference/utils/transform_utils.html","title":"transform_utils","text":"<p>Utility functions of matrix and vector transformations.</p> <p>NOTE: convention for quaternions is (x, y, z, w)</p>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.anorm","title":"<code>anorm(x, axis=None, keepdims=False)</code>","text":"<p>Compute L2 norms alogn specified axes.</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def anorm(x, axis=None, keepdims=False):\n\"\"\"Compute L2 norms alogn specified axes.\"\"\"\nreturn np.linalg.norm(x, axis=axis, keepdims=keepdims)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.axisangle2quat","title":"<code>axisangle2quat(vec)</code>","text":"<p>Converts scaled axis-angle to quat.</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>np.array</code> <p>(ax,ay,az) axis-angle exponential coordinates</p> required <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) vec4 float angles</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def axisangle2quat(vec):\n\"\"\"\n    Converts scaled axis-angle to quat.\n    Args:\n        vec (np.array): (ax,ay,az) axis-angle exponential coordinates\n    Returns:\n        np.array: (x,y,z,w) vec4 float angles\n    \"\"\"\n# Grab angle\nangle = np.linalg.norm(vec)\n# handle zero-rotation case\nif math.isclose(angle, 0.0):\nreturn np.array([0.0, 0.0, 0.0, 1.0])\n# otherwise convert like normal\nreturn R.from_rotvec(vec).as_quat()\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.cartesian_to_polar","title":"<code>cartesian_to_polar(x, y)</code>","text":"<p>Convert cartesian coordinate to polar coordinate</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def cartesian_to_polar(x, y):\n\"\"\"Convert cartesian coordinate to polar coordinate\"\"\"\nrho = np.sqrt(x ** 2 + y ** 2)\nphi = np.arctan2(y, x)\nreturn rho, phi\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.clip_rotation","title":"<code>clip_rotation(quat, limit)</code>","text":"<p>Limits a (delta) rotation to a specified limit</p> <p>Converts rotation to axis-angle, clips, then re-converts back into quaternion</p> <p>Parameters:</p> Name Type Description Default <code>quat</code> <code>np.array</code> <p>(x,y,z,w) rotation being clipped</p> required <code>limit</code> <code>float</code> <p>Value to limit rotation by -- magnitude (scalar, in radians)</p> required <p>Returns:</p> Type Description <p>2-tuple:</p> <ul> <li>(np.array) Clipped rotation quaternion (x, y, z, w)</li> <li>(bool) whether the value was clipped or not</li> </ul> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def clip_rotation(quat, limit):\n\"\"\"\n    Limits a (delta) rotation to a specified limit\n    Converts rotation to axis-angle, clips, then re-converts back into quaternion\n    Args:\n        quat (np.array): (x,y,z,w) rotation being clipped\n        limit (float): Value to limit rotation by -- magnitude (scalar, in radians)\n    Returns:\n        2-tuple:\n            - (np.array) Clipped rotation quaternion (x, y, z, w)\n            - (bool) whether the value was clipped or not\n    \"\"\"\nclipped = False\n# First, normalize the quaternion\nquat = quat / np.linalg.norm(quat)\nden = np.sqrt(max(1 - quat[3] * quat[3], 0))\nif den == 0:\n# This is a zero degree rotation, immediately return\nreturn quat, clipped\nelse:\n# This is all other cases\nx = quat[0] / den\ny = quat[1] / den\nz = quat[2] / den\na = 2 * math.acos(quat[3])\n# Clip rotation if necessary and return clipped quat\nif abs(a) &gt; limit:\na = limit * np.sign(a) / 2\nsa = math.sin(a)\nca = math.cos(a)\nquat = np.array([x * sa, y * sa, z * sa, ca])\nclipped = True\nreturn quat, clipped\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.clip_translation","title":"<code>clip_translation(dpos, limit)</code>","text":"<p>Limits a translation (delta position) to a specified limit</p> <p>Scales down the norm of the dpos to 'limit' if norm(dpos) &gt; limit, else returns immediately</p> <p>Parameters:</p> Name Type Description Default <code>dpos</code> <code>n-array</code> <p>n-dim Translation being clipped (e,g.: (x, y, z)) -- numpy array</p> required <code>limit</code> <code>float</code> <p>Value to limit translation by -- magnitude (scalar, in same units as input)</p> required <p>Returns:</p> Type Description <p>2-tuple:</p> <ul> <li>(np.array) Clipped translation (same dimension as inputs)</li> <li>(bool) whether the value was clipped or not</li> </ul> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def clip_translation(dpos, limit):\n\"\"\"\n    Limits a translation (delta position) to a specified limit\n    Scales down the norm of the dpos to 'limit' if norm(dpos) &gt; limit, else returns immediately\n    Args:\n        dpos (n-array): n-dim Translation being clipped (e,g.: (x, y, z)) -- numpy array\n        limit (float): Value to limit translation by -- magnitude (scalar, in same units as input)\n    Returns:\n        2-tuple:\n            - (np.array) Clipped translation (same dimension as inputs)\n            - (bool) whether the value was clipped or not\n    \"\"\"\ninput_norm = np.linalg.norm(dpos)\nreturn (dpos * limit / input_norm, True) if input_norm &gt; limit else (dpos, False)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.convert_quat","title":"<code>convert_quat(q, to='xyzw')</code>","text":"<p>Converts quaternion from one convention to another. The convention to convert TO is specified as an optional argument. If to == 'xyzw', then the input is in 'wxyz' format, and vice-versa.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>np.array</code> <p>a 4-dim array corresponding to a quaternion</p> required <code>to</code> <code>str</code> <p>either 'xyzw' or 'wxyz', determining which convention to convert to.</p> <code>'xyzw'</code> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def convert_quat(q, to=\"xyzw\"):\n\"\"\"\n    Converts quaternion from one convention to another.\n    The convention to convert TO is specified as an optional argument.\n    If to == 'xyzw', then the input is in 'wxyz' format, and vice-versa.\n    Args:\n        q (np.array): a 4-dim array corresponding to a quaternion\n        to (str): either 'xyzw' or 'wxyz', determining which convention to convert to.\n    \"\"\"\nif to == \"xyzw\":\nreturn q[[1, 2, 3, 0]]\nif to == \"wxyz\":\nreturn q[[3, 0, 1, 2]]\nraise Exception(\"convert_quat: choose a valid `to` argument (xyzw or wxyz)\")\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.euler2mat","title":"<code>euler2mat(euler)</code>","text":"<p>Converts euler angles into rotation matrix form</p> <p>Parameters:</p> Name Type Description Default <code>euler</code> <code>np.array</code> <p>(r,p,y) angles</p> required <p>Returns:</p> Type Description <p>np.array: 3x3 rotation matrix</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>[Invalid input shape]</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def euler2mat(euler):\n\"\"\"\n    Converts euler angles into rotation matrix form\n    Args:\n        euler (np.array): (r,p,y) angles\n    Returns:\n        np.array: 3x3 rotation matrix\n    Raises:\n        AssertionError: [Invalid input shape]\n    \"\"\"\neuler = np.asarray(euler, dtype=np.float64)\nassert euler.shape[-1] == 3, \"Invalid shaped euler {}\".format(euler)\nreturn R.from_euler(\"xyz\", euler).as_matrix()\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.euler2quat","title":"<code>euler2quat(euler)</code>","text":"<p>Converts euler angles into quaternion form</p> <p>Parameters:</p> Name Type Description Default <code>euler</code> <code>np.array</code> <p>(r,p,y) angles</p> required <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) float quaternion angles</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>[Invalid input shape]</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def euler2quat(euler):\n\"\"\"\n    Converts euler angles into quaternion form\n    Args:\n        euler (np.array): (r,p,y) angles\n    Returns:\n        np.array: (x,y,z,w) float quaternion angles\n    Raises:\n        AssertionError: [Invalid input shape]\n    \"\"\"\nreturn R.from_euler(\"xyz\", euler).as_quat()\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.ewma_vectorized","title":"<code>ewma_vectorized(data, alpha, offset=None, dtype=None, order='C', out=None)</code>","text":"<p>Calculates the exponential moving average over a vector. Will fail for large inputs.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Iterable</code> <p>Input data</p> required <code>alpha</code> <code>float</code> <p>scalar in range (0,1) The alpha parameter for the moving average.</p> required <code>offset</code> <code>None or float</code> <p>If specified, the offset for the moving average. None defaults to data[0].</p> <code>None</code> <code>dtype</code> <code>None or type</code> <p>Data type used for calculations. If None, defaults to float64 unless data.dtype is float32, then it will use float32.</p> <code>None</code> <code>order</code> <code>None or str</code> <p>Order to use when flattening the data. Valid options are {'C', 'F', 'A'}. None defaults to 'C'.</p> <code>'C'</code> <code>out</code> <code>None or np.array</code> <p>If specified, the location into which the result is stored. If provided, it must have the same shape as the input. If not provided or <code>None</code>, a freshly-allocated array is returned.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: Exponential moving average from @data</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def ewma_vectorized(data, alpha, offset=None, dtype=None, order=\"C\", out=None):\n\"\"\"\n    Calculates the exponential moving average over a vector.\n    Will fail for large inputs.\n    Args:\n        data (Iterable): Input data\n        alpha (float): scalar in range (0,1)\n            The alpha parameter for the moving average.\n        offset (None or float): If specified, the offset for the moving average. None defaults to data[0].\n        dtype (None or type): Data type used for calculations. If None, defaults to float64 unless\n            data.dtype is float32, then it will use float32.\n        order (None or str): Order to use when flattening the data. Valid options are {'C', 'F', 'A'}.\n            None defaults to 'C'.\n        out (None or np.array): If specified, the location into which the result is stored. If provided, it must have\n            the same shape as the input. If not provided or `None`,\n            a freshly-allocated array is returned.\n    Returns:\n        np.array: Exponential moving average from @data\n    \"\"\"\ndata = np.array(data, copy=False)\nif dtype is None:\nif data.dtype == np.float32:\ndtype = np.float32\nelse:\ndtype = np.float64\nelse:\ndtype = np.dtype(dtype)\nif data.ndim &gt; 1:\n# flatten input\ndata = data.reshape(-1, order)\nif out is None:\nout = np.empty_like(data, dtype=dtype)\nelse:\nassert out.shape == data.shape\nassert out.dtype == dtype\nif data.size &lt; 1:\n# empty input, return empty array\nreturn out\nif offset is None:\noffset = data[0]\nalpha = np.array(alpha, copy=False).astype(dtype, copy=False)\n# scaling_factors -&gt; 0 as len(data) gets large\n# this leads to divide-by-zeros below\nscaling_factors = np.power(1.0 - alpha, np.arange(data.size + 1, dtype=dtype), dtype=dtype)\n# create cumulative sum array\nnp.multiply(data, (alpha * scaling_factors[-2]) / scaling_factors[:-1], dtype=dtype, out=out)\nnp.cumsum(out, dtype=dtype, out=out)\n# cumsums / scaling\nout /= scaling_factors[-2::-1]\nif offset != 0:\noffset = np.array(offset, copy=False).astype(dtype, copy=False)\n# add offsets\nout += offset * scaling_factors[1:]\nreturn out\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.force_in_A_to_force_in_B","title":"<code>force_in_A_to_force_in_B(force_A, torque_A, pose_A_in_B)</code>","text":"<p>Converts linear and rotational force at a point in frame A to the equivalent in frame B.</p> <p>Parameters:</p> Name Type Description Default <code>force_A</code> <code>np.array</code> <p>(fx,fy,fz) linear force in A</p> required <code>torque_A</code> <code>np.array</code> <p>(tx,ty,tz) rotational force (moment) in A</p> required <code>pose_A_in_B</code> <code>np.array</code> <p>4x4 matrix corresponding to the pose of A in frame B</p> required <p>Returns:</p> Type Description <p>2-tuple:</p> <ul> <li>(np.array) (fx,fy,fz) linear forces in frame B</li> <li>(np.array) (tx,ty,tz) moments in frame B</li> </ul> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def force_in_A_to_force_in_B(force_A, torque_A, pose_A_in_B):\n\"\"\"\n    Converts linear and rotational force at a point in frame A to the equivalent in frame B.\n    Args:\n        force_A (np.array): (fx,fy,fz) linear force in A\n        torque_A (np.array): (tx,ty,tz) rotational force (moment) in A\n        pose_A_in_B (np.array): 4x4 matrix corresponding to the pose of A in frame B\n    Returns:\n        2-tuple:\n            - (np.array) (fx,fy,fz) linear forces in frame B\n            - (np.array) (tx,ty,tz) moments in frame B\n    \"\"\"\npos_A_in_B = pose_A_in_B[:3, 3]\nrot_A_in_B = pose_A_in_B[:3, :3]\nskew_symm = _skew_symmetric_translation(pos_A_in_B)\nforce_B = rot_A_in_B.T.dot(force_A)\ntorque_B = -rot_A_in_B.T.dot(skew_symm.dot(force_A)) + rot_A_in_B.T.dot(torque_A)\nreturn force_B, torque_B\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.frustum","title":"<code>frustum(left, right, bottom, top, znear, zfar)</code>","text":"<p>Create view frustum matrix.</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def frustum(left, right, bottom, top, znear, zfar):\n\"\"\"Create view frustum matrix.\"\"\"\nassert right != left\nassert bottom != top\nassert znear != zfar\nM = np.zeros((4, 4), dtype=np.float32)\nM[0, 0] = +2.0 * znear / (right - left)\nM[2, 0] = (right + left) / (right - left)\nM[1, 1] = +2.0 * znear / (top - bottom)\n# TODO: Put this back to 3,1\n# M[3, 1] = (top + bottom) / (top - bottom)\nM[2, 1] = (top + bottom) / (top - bottom)\nM[2, 2] = -(zfar + znear) / (zfar - znear)\nM[3, 2] = -2.0 * znear * zfar / (zfar - znear)\nM[2, 3] = -1.0\nreturn M\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.get_orientation_diff_in_radian","title":"<code>get_orientation_diff_in_radian(orn0, orn1)</code>","text":"<p>Returns the difference between two quaternion orientations in radian</p> <p>Parameters:</p> Name Type Description Default <code>orn0</code> <code>np.array</code> <p>(x, y, z, w)</p> required <code>orn1</code> <code>np.array</code> <p>(x, y, z, w)</p> required <p>Returns:</p> Name Type Description <code>orn_diff</code> <code>float</code> <p>orientation difference in radian</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def get_orientation_diff_in_radian(orn0, orn1):\n\"\"\"\n    Returns the difference between two quaternion orientations in radian\n    Args:\n        orn0 (np.array): (x, y, z, w)\n        orn1 (np.array): (x, y, z, w)\n    Returns:\n        orn_diff (float): orientation difference in radian\n    \"\"\"\nvec0 = quat2axisangle(orn0)\nvec0 /= np.linalg.norm(vec0)\nvec1 = quat2axisangle(orn1)\nvec1 /= np.linalg.norm(vec1)\nreturn np.arccos(np.dot(vec0, vec1))\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.get_orientation_error","title":"<code>get_orientation_error(target_orn, current_orn)</code>","text":"<p>Returns the difference between two quaternion orientations as a 3 DOF numpy array. For use in an impedance controller / task-space PD controller.</p> <p>Parameters:</p> Name Type Description Default <code>target_orn</code> <code>np.array</code> <p>(x, y, z, w) desired quaternion orientation</p> required <code>current_orn</code> <code>np.array</code> <p>(x, y, z, w) current quaternion orientation</p> required <p>Returns:</p> Name Type Description <code>orn_error</code> <code>np.array</code> <p>(ax,ay,az) current orientation error, corresponds to (target_orn - current_orn)</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def get_orientation_error(target_orn, current_orn):\n\"\"\"\n    Returns the difference between two quaternion orientations as a 3 DOF numpy array.\n    For use in an impedance controller / task-space PD controller.\n    Args:\n        target_orn (np.array): (x, y, z, w) desired quaternion orientation\n        current_orn (np.array): (x, y, z, w) current quaternion orientation\n    Returns:\n        orn_error (np.array): (ax,ay,az) current orientation error, corresponds to\n            (target_orn - current_orn)\n    \"\"\"\ncurrent_orn = np.array([current_orn[3], current_orn[0], current_orn[1], current_orn[2]])\ntarget_orn = np.array([target_orn[3], target_orn[0], target_orn[1], target_orn[2]])\npinv = np.zeros((3, 4))\npinv[0, :] = [-current_orn[1], current_orn[0], -current_orn[3], current_orn[2]]\npinv[1, :] = [-current_orn[2], current_orn[3], current_orn[0], -current_orn[1]]\npinv[2, :] = [-current_orn[3], -current_orn[2], current_orn[1], current_orn[0]]\norn_error = 2.0 * pinv.dot(np.array(target_orn))\nreturn orn_error\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.get_pose_error","title":"<code>get_pose_error(target_pose, current_pose)</code>","text":"<p>Computes the error corresponding to target pose - current pose as a 6-dim vector. The first 3 components correspond to translational error while the last 3 components correspond to the rotational error.</p> <p>Parameters:</p> Name Type Description Default <code>target_pose</code> <code>np.array</code> <p>a 4x4 homogenous matrix for the target pose</p> required <code>current_pose</code> <code>np.array</code> <p>a 4x4 homogenous matrix for the current pose</p> required <p>Returns:</p> Type Description <p>np.array: 6-dim pose error.</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def get_pose_error(target_pose, current_pose):\n\"\"\"\n    Computes the error corresponding to target pose - current pose as a 6-dim vector.\n    The first 3 components correspond to translational error while the last 3 components\n    correspond to the rotational error.\n    Args:\n        target_pose (np.array): a 4x4 homogenous matrix for the target pose\n        current_pose (np.array): a 4x4 homogenous matrix for the current pose\n    Returns:\n        np.array: 6-dim pose error.\n    \"\"\"\nerror = np.zeros(6)\n# compute translational error\ntarget_pos = target_pose[:3, 3]\ncurrent_pos = current_pose[:3, 3]\npos_err = target_pos - current_pos\n# compute rotational error\nr1 = current_pose[:3, 0]\nr2 = current_pose[:3, 1]\nr3 = current_pose[:3, 2]\nr1d = target_pose[:3, 0]\nr2d = target_pose[:3, 1]\nr3d = target_pose[:3, 2]\nrot_err = 0.5 * (np.cross(r1, r1d) + np.cross(r2, r2d) + np.cross(r3, r3d))\nerror[:3] = pos_err\nerror[3:] = rot_err\nreturn error\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.l2_distance","title":"<code>l2_distance(v1, v2)</code>","text":"<p>Returns the L2 distance between vector v1 and v2.</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def l2_distance(v1, v2):\n\"\"\"Returns the L2 distance between vector v1 and v2.\"\"\"\nreturn np.linalg.norm(np.array(v1) - np.array(v2))\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.make_pose","title":"<code>make_pose(translation, rotation)</code>","text":"<p>Makes a homogeneous pose matrix from a translation vector and a rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>translation</code> <code>np.array</code> <p>(x,y,z) translation value</p> required <code>rotation</code> <code>np.array</code> <p>a 3x3 matrix representing rotation</p> required <p>Returns:</p> Name Type Description <code>pose</code> <code>np.array</code> <p>a 4x4 homogeneous matrix</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def make_pose(translation, rotation):\n\"\"\"\n    Makes a homogeneous pose matrix from a translation vector and a rotation matrix.\n    Args:\n        translation (np.array): (x,y,z) translation value\n        rotation (np.array): a 3x3 matrix representing rotation\n    Returns:\n        pose (np.array): a 4x4 homogeneous matrix\n    \"\"\"\npose = np.zeros((4, 4))\npose[:3, :3] = rotation\npose[:3, 3] = translation\npose[3, 3] = 1.0\nreturn pose\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.mat2euler","title":"<code>mat2euler(rmat)</code>","text":"<p>Converts given rotation matrix to euler angles in radian.</p> <p>Parameters:</p> Name Type Description Default <code>rmat</code> <code>np.array</code> <p>3x3 rotation matrix</p> required <p>Returns:</p> Type Description <p>np.array: (r,p,y) converted euler angles in radian vec3 float</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def mat2euler(rmat):\n\"\"\"\n    Converts given rotation matrix to euler angles in radian.\n    Args:\n        rmat (np.array): 3x3 rotation matrix\n    Returns:\n        np.array: (r,p,y) converted euler angles in radian vec3 float\n    \"\"\"\nM = np.array(rmat, dtype=np.float32, copy=False)[:3, :3]\nreturn R.from_matrix(M).as_euler(\"xyz\")\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.mat2pose","title":"<code>mat2pose(hmat)</code>","text":"<p>Converts a homogeneous 4x4 matrix into pose.</p> <p>Parameters:</p> Name Type Description Default <code>hmat</code> <code>np.array</code> <p>a 4x4 homogeneous matrix</p> required <p>Returns:</p> Type Description <p>2-tuple:</p> <ul> <li>(np.array) (x,y,z) position array in cartesian coordinates</li> <li>(np.array) (x,y,z,w) orientation array in quaternion form</li> </ul> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def mat2pose(hmat):\n\"\"\"\n    Converts a homogeneous 4x4 matrix into pose.\n    Args:\n        hmat (np.array): a 4x4 homogeneous matrix\n    Returns:\n        2-tuple:\n            - (np.array) (x,y,z) position array in cartesian coordinates\n            - (np.array) (x,y,z,w) orientation array in quaternion form\n    \"\"\"\npos = hmat[:3, 3]\norn = mat2quat(hmat[:3, :3])\nreturn pos, orn\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.mat2quat","title":"<code>mat2quat(rmat)</code>","text":"<p>Converts given rotation matrix to quaternion.</p> <p>Parameters:</p> Name Type Description Default <code>rmat</code> <code>np.array</code> <p>(..., 3, 3) rotation matrix</p> required <p>Returns:</p> Type Description <p>np.array: (..., 4) (x,y,z,w) float quaternion angles</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def mat2quat(rmat):\n\"\"\"\n    Converts given rotation matrix to quaternion.\n    Args:\n        rmat (np.array): (..., 3, 3) rotation matrix\n    Returns:\n        np.array: (..., 4) (x,y,z,w) float quaternion angles\n    \"\"\"\nreturn R.from_matrix(rmat).as_quat()\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.mat4","title":"<code>mat4(array)</code>","text":"<p>Converts an array to 4x4 matrix.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>n-array</code> <p>the array in form of vec, list, or tuple</p> required <p>Returns:</p> Type Description <p>np.array: a 4x4 numpy matrix</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def mat4(array):\n\"\"\"\n    Converts an array to 4x4 matrix.\n    Args:\n        array (n-array): the array in form of vec, list, or tuple\n    Returns:\n        np.array: a 4x4 numpy matrix\n    \"\"\"\nreturn np.array(array, dtype=np.float32).reshape((4, 4))\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.matrix_inverse","title":"<code>matrix_inverse(matrix)</code>","text":"<p>Helper function to have an efficient matrix inversion function.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>np.array</code> <p>2d-array representing a matrix</p> required <p>Returns:</p> Type Description <p>np.array: 2d-array representing the matrix inverse</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def matrix_inverse(matrix):\n\"\"\"\n    Helper function to have an efficient matrix inversion function.\n    Args:\n        matrix (np.array): 2d-array representing a matrix\n    Returns:\n        np.array: 2d-array representing the matrix inverse\n    \"\"\"\nreturn np.linalg.inv(matrix)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.normalize","title":"<code>normalize(v, axis=None, eps=1e-10)</code>","text":"<p>L2 Normalize along specified axes.</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def normalize(v, axis=None, eps=1e-10):\n\"\"\"L2 Normalize along specified axes.\"\"\"\nreturn v / max(anorm(v, axis=axis, keepdims=True), eps)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.ortho","title":"<code>ortho(left, right, bottom, top, znear, zfar)</code>","text":"<p>Create orthonormal projection matrix.</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def ortho(left, right, bottom, top, znear, zfar):\n\"\"\"Create orthonormal projection matrix.\"\"\"\nassert right != left\nassert bottom != top\nassert znear != zfar\nM = np.zeros((4, 4), dtype=np.float32)\nM[0, 0] = 2.0 / (right - left)\nM[1, 1] = 2.0 / (top - bottom)\nM[2, 2] = -2.0 / (zfar - znear)\nM[3, 0] = -(right + left) / (right - left)\nM[3, 1] = -(top + bottom) / (top - bottom)\nM[3, 2] = -(zfar + znear) / (zfar - znear)\nM[3, 3] = 1.0\nreturn M\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.perspective","title":"<code>perspective(fovy, aspect, znear, zfar)</code>","text":"<p>Create perspective projection matrix.</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def perspective(fovy, aspect, znear, zfar):\n\"\"\"Create perspective projection matrix.\"\"\"\n# fovy is in degree\nassert znear != zfar\nh = np.tan(fovy / 360.0 * np.pi) * znear\nw = h * aspect\nreturn frustum(-w, w, -h, h, znear, zfar)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.pose2mat","title":"<code>pose2mat(pose)</code>","text":"<p>Converts pose to homogeneous matrix.</p> <p>Parameters:</p> Name Type Description Default <code>pose</code> <code>2-tuple</code> <p>a (pos, orn) tuple where pos is vec3 float cartesian, and orn is vec4 float quaternion.</p> required <p>Returns:</p> Type Description <p>np.array: 4x4 homogeneous matrix</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def pose2mat(pose):\n\"\"\"\n    Converts pose to homogeneous matrix.\n    Args:\n        pose (2-tuple): a (pos, orn) tuple where pos is vec3 float cartesian, and\n            orn is vec4 float quaternion.\n    Returns:\n        np.array: 4x4 homogeneous matrix\n    \"\"\"\nhomo_pose_mat = np.zeros((4, 4), dtype=np.float32)\nhomo_pose_mat[:3, :3] = quat2mat(pose[1])\nhomo_pose_mat[:3, 3] = np.array(pose[0], dtype=np.float32)\nhomo_pose_mat[3, 3] = 1.0\nreturn homo_pose_mat\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.pose_in_A_to_pose_in_B","title":"<code>pose_in_A_to_pose_in_B(pose_A, pose_A_in_B)</code>","text":"<p>Converts a homogenous matrix corresponding to a point C in frame A to a homogenous matrix corresponding to the same point C in frame B.</p> <p>Parameters:</p> Name Type Description Default <code>pose_A</code> <code>np.array</code> <p>4x4 matrix corresponding to the pose of C in frame A</p> required <code>pose_A_in_B</code> <code>np.array</code> <p>4x4 matrix corresponding to the pose of A in frame B</p> required <p>Returns:</p> Type Description <p>np.array: 4x4 matrix corresponding to the pose of C in frame B</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def pose_in_A_to_pose_in_B(pose_A, pose_A_in_B):\n\"\"\"\n    Converts a homogenous matrix corresponding to a point C in frame A\n    to a homogenous matrix corresponding to the same point C in frame B.\n    Args:\n        pose_A (np.array): 4x4 matrix corresponding to the pose of C in frame A\n        pose_A_in_B (np.array): 4x4 matrix corresponding to the pose of A in frame B\n    Returns:\n        np.array: 4x4 matrix corresponding to the pose of C in frame B\n    \"\"\"\n# pose of A in B takes a point in A and transforms it to a point in C.\n# pose of C in B = pose of A in B * pose of C in A\n# take a point in C, transform it to A, then to B\n# T_B^C = T_A^C * T_B^A\nreturn pose_A_in_B.dot(pose_A)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.pose_inv","title":"<code>pose_inv(pose_mat)</code>","text":"<p>Computes the inverse of a homogeneous matrix corresponding to the pose of some frame B in frame A. The inverse is the pose of frame A in frame B.</p> <p>Parameters:</p> Name Type Description Default <code>pose_mat</code> <code>np.array</code> <p>4x4 matrix for the pose to inverse</p> required <p>Returns:</p> Type Description <p>np.array: 4x4 matrix for the inverse pose</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def pose_inv(pose_mat):\n\"\"\"\n    Computes the inverse of a homogeneous matrix corresponding to the pose of some\n    frame B in frame A. The inverse is the pose of frame A in frame B.\n    Args:\n        pose_mat (np.array): 4x4 matrix for the pose to inverse\n    Returns:\n        np.array: 4x4 matrix for the inverse pose\n    \"\"\"\n# Note, the inverse of a pose matrix is the following\n# [R t; 0 1]^-1 = [R.T -R.T*t; 0 1]\n# Intuitively, this makes sense.\n# The original pose matrix translates by t, then rotates by R.\n# We just invert the rotation by applying R-1 = R.T, and also translate back.\n# Since we apply translation first before rotation, we need to translate by\n# -t in the original frame, which is -R-1*t in the new frame, and then rotate back by\n# R-1 to align the axis again.\npose_inv = np.zeros((4, 4))\npose_inv[:3, :3] = pose_mat[:3, :3].T\npose_inv[:3, 3] = -pose_inv[:3, :3].dot(pose_mat[:3, 3])\npose_inv[3, 3] = 1.0\nreturn pose_inv\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.pose_transform","title":"<code>pose_transform(pos1, quat1, pos0, quat0)</code>","text":"<p>Conducts forward transform from pose (pos0, quat0) to pose (pos1, quat1):</p> <p>pose1 @ pose0, NOT pose0 @ pose1</p> <p>Parameters:</p> Name Type Description Default <code>pos1</code> <p>(x,y,z) position to transform</p> required <code>quat1</code> <p>(x,y,z,w) orientation to transform</p> required <code>pos0</code> <p>(x,y,z) initial position</p> required <code>quat0</code> <p>(x,y,z,w) initial orientation</p> required Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def pose_transform(pos1, quat1, pos0, quat0):\n\"\"\"\n    Conducts forward transform from pose (pos0, quat0) to pose (pos1, quat1):\n    pose1 @ pose0, NOT pose0 @ pose1\n    Args:\n        pos1: (x,y,z) position to transform\n        quat1: (x,y,z,w) orientation to transform\n        pos0: (x,y,z) initial position\n        quat0: (x,y,z,w) initial orientation\n    \"\"\"\n# Get poses\nmat0 = pose2mat((pos0, quat0))\nmat1 = pose2mat((pos1, quat1))\n# Multiply and convert back to pos, quat\nreturn mat2pose(mat1 @ mat0)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat2axisangle","title":"<code>quat2axisangle(quat)</code>","text":"<p>Converts quaternion to axis-angle format. Returns a unit vector direction scaled by its angle in radians.</p> <p>Parameters:</p> Name Type Description Default <code>quat</code> <code>np.array</code> <p>(x,y,z,w) vec4 float angles</p> required <p>Returns:</p> Type Description <p>np.array: (ax,ay,az) axis-angle exponential coordinates</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat2axisangle(quat):\n\"\"\"\n    Converts quaternion to axis-angle format.\n    Returns a unit vector direction scaled by its angle in radians.\n    Args:\n        quat (np.array): (x,y,z,w) vec4 float angles\n    Returns:\n        np.array: (ax,ay,az) axis-angle exponential coordinates\n    \"\"\"\nreturn R.from_quat(quat).as_rotvec()\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat2euler","title":"<code>quat2euler(quat)</code>","text":"<p>Converts euler angles into quaternion form</p> <p>Parameters:</p> Name Type Description Default <code>quat</code> <code>np.array</code> <p>(x,y,z,w) float quaternion angles</p> required <p>Returns:</p> Type Description <p>np.array: (r,p,y) angles</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>[Invalid input shape]</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat2euler(quat):\n\"\"\"\n    Converts euler angles into quaternion form\n    Args:\n        quat (np.array): (x,y,z,w) float quaternion angles\n    Returns:\n        np.array: (r,p,y) angles\n    Raises:\n        AssertionError: [Invalid input shape]\n    \"\"\"\nreturn R.from_quat(quat).as_euler(\"xyz\")\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat2mat","title":"<code>quat2mat(quaternion)</code>","text":"<p>Converts given quaternion to matrix.</p> <p>Parameters:</p> Name Type Description Default <code>quaternion</code> <code>np.array</code> <p>(x,y,z,w) vec4 float angles</p> required <p>Returns:</p> Type Description <p>np.array: 3x3 rotation matrix</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat2mat(quaternion):\n\"\"\"\n    Converts given quaternion to matrix.\n    Args:\n        quaternion (np.array): (x,y,z,w) vec4 float angles\n    Returns:\n        np.array: 3x3 rotation matrix\n    \"\"\"\nreturn R.from_quat(quaternion).as_matrix()\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat_conjugate","title":"<code>quat_conjugate(quaternion)</code>","text":"<p>Return conjugate of quaternion.</p> <p>E.g.:</p> <p>q0 = random_quaternion() q1 = quat_conjugate(q0) q1[3] == q0[3] and all(q1[:3] == -q0[:3]) True</p> <p>Parameters:</p> Name Type Description Default <code>quaternion</code> <code>np.array</code> <p>(x,y,z,w) quaternion</p> required <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) quaternion conjugate</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat_conjugate(quaternion):\n\"\"\"\n    Return conjugate of quaternion.\n    E.g.:\n    &gt;&gt;&gt; q0 = random_quaternion()\n    &gt;&gt;&gt; q1 = quat_conjugate(q0)\n    &gt;&gt;&gt; q1[3] == q0[3] and all(q1[:3] == -q0[:3])\n    True\n    Args:\n        quaternion (np.array): (x,y,z,w) quaternion\n    Returns:\n        np.array: (x,y,z,w) quaternion conjugate\n    \"\"\"\nreturn np.array(\n(-quaternion[0], -quaternion[1], -quaternion[2], quaternion[3]),\ndtype=np.float32,\n)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat_distance","title":"<code>quat_distance(quaternion1, quaternion0)</code>","text":"<p>Returns distance between two quaternions, such that distance * quaternion0 = quaternion1</p> <p>Parameters:</p> Name Type Description Default <code>quaternion1</code> <code>np.array</code> <p>(x,y,z,w) quaternion</p> required <code>quaternion0</code> <code>np.array</code> <p>(x,y,z,w) quaternion</p> required <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) quaternion distance</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat_distance(quaternion1, quaternion0):\n\"\"\"\n    Returns distance between two quaternions, such that distance * quaternion0 = quaternion1\n    Args:\n        quaternion1 (np.array): (x,y,z,w) quaternion\n        quaternion0 (np.array): (x,y,z,w) quaternion\n    Returns:\n        np.array: (x,y,z,w) quaternion distance\n    \"\"\"\nreturn quat_multiply(quaternion1, quat_inverse(quaternion0))\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat_inverse","title":"<code>quat_inverse(quaternion)</code>","text":"<p>Return inverse of quaternion.</p> <p>E.g.:</p> <p>q0 = random_quaternion() q1 = quat_inverse(q0) np.allclose(quat_multiply(q0, q1), [0, 0, 0, 1]) True</p> <p>Parameters:</p> Name Type Description Default <code>quaternion</code> <code>np.array</code> <p>(x,y,z,w) quaternion</p> required <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) quaternion inverse</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat_inverse(quaternion):\n\"\"\"\n    Return inverse of quaternion.\n    E.g.:\n    &gt;&gt;&gt; q0 = random_quaternion()\n    &gt;&gt;&gt; q1 = quat_inverse(q0)\n    &gt;&gt;&gt; np.allclose(quat_multiply(q0, q1), [0, 0, 0, 1])\n    True\n    Args:\n        quaternion (np.array): (x,y,z,w) quaternion\n    Returns:\n        np.array: (x,y,z,w) quaternion inverse\n    \"\"\"\nreturn quat_conjugate(quaternion) / np.dot(quaternion, quaternion)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat_multiply","title":"<code>quat_multiply(quaternion1, quaternion0)</code>","text":"<p>Return multiplication of two quaternions (q1 * q0).</p> <p>E.g.:</p> <p>q = quat_multiply([1, -2, 3, 4], [-5, 6, 7, 8]) np.allclose(q, [-44, -14, 48, 28]) True</p> <p>Parameters:</p> Name Type Description Default <code>quaternion1</code> <code>np.array</code> <p>(x,y,z,w) quaternion</p> required <code>quaternion0</code> <code>np.array</code> <p>(x,y,z,w) quaternion</p> required <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) multiplied quaternion</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat_multiply(quaternion1, quaternion0):\n\"\"\"\n    Return multiplication of two quaternions (q1 * q0).\n    E.g.:\n    &gt;&gt;&gt; q = quat_multiply([1, -2, 3, 4], [-5, 6, 7, 8])\n    &gt;&gt;&gt; np.allclose(q, [-44, -14, 48, 28])\n    True\n    Args:\n        quaternion1 (np.array): (x,y,z,w) quaternion\n        quaternion0 (np.array): (x,y,z,w) quaternion\n    Returns:\n        np.array: (x,y,z,w) multiplied quaternion\n    \"\"\"\nx0, y0, z0, w0 = quaternion0\nx1, y1, z1, w1 = quaternion1\nreturn np.array(\n(\nx1 * w0 + y1 * z0 - z1 * y0 + w1 * x0,\n-x1 * z0 + y1 * w0 + z1 * x0 + w1 * y0,\nx1 * y0 - y1 * x0 + z1 * w0 + w1 * z0,\n-x1 * x0 - y1 * y0 - z1 * z0 + w1 * w0,\n),\ndtype=np.float32,\n)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.quat_slerp","title":"<code>quat_slerp(quat0, quat1, fraction, shortestpath=True)</code>","text":"<p>Return spherical linear interpolation between two quaternions.</p> <p>E.g.:</p> <p>q0 = random_quat() q1 = random_quat() q = quat_slerp(q0, q1, 0.0) np.allclose(q, q0) True</p> <p>q = quat_slerp(q0, q1, 1.0) np.allclose(q, q1) True</p> <p>q = quat_slerp(q0, q1, 0.5) angle = math.acos(np.dot(q0, q)) np.allclose(2.0, math.acos(np.dot(q0, q1)) / angle) or         np.allclose(2.0, math.acos(-np.dot(q0, q1)) / angle) True</p> <p>Parameters:</p> Name Type Description Default <code>quat0</code> <code>np.array</code> <p>(x,y,z,w) quaternion startpoint</p> required <code>quat1</code> <code>np.array</code> <p>(x,y,z,w) quaternion endpoint</p> required <code>fraction</code> <code>float</code> <p>fraction of interpolation to calculate</p> required <code>shortestpath</code> <code>bool</code> <p>If True, will calculate the shortest path</p> <code>True</code> <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) quaternion distance</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def quat_slerp(quat0, quat1, fraction, shortestpath=True):\n\"\"\"\n    Return spherical linear interpolation between two quaternions.\n    E.g.:\n    &gt;&gt;&gt; q0 = random_quat()\n    &gt;&gt;&gt; q1 = random_quat()\n    &gt;&gt;&gt; q = quat_slerp(q0, q1, 0.0)\n    &gt;&gt;&gt; np.allclose(q, q0)\n    True\n    &gt;&gt;&gt; q = quat_slerp(q0, q1, 1.0)\n    &gt;&gt;&gt; np.allclose(q, q1)\n    True\n    &gt;&gt;&gt; q = quat_slerp(q0, q1, 0.5)\n    &gt;&gt;&gt; angle = math.acos(np.dot(q0, q))\n    &gt;&gt;&gt; np.allclose(2.0, math.acos(np.dot(q0, q1)) / angle) or \\\n        np.allclose(2.0, math.acos(-np.dot(q0, q1)) / angle)\n    True\n    Args:\n        quat0 (np.array): (x,y,z,w) quaternion startpoint\n        quat1 (np.array): (x,y,z,w) quaternion endpoint\n        fraction (float): fraction of interpolation to calculate\n        shortestpath (bool): If True, will calculate the shortest path\n    Returns:\n        np.array: (x,y,z,w) quaternion distance\n    \"\"\"\nq0 = unit_vector(quat0[:4])\nq1 = unit_vector(quat1[:4])\nif fraction == 0.0:\nreturn q0\nelif fraction == 1.0:\nreturn q1\nd = np.dot(q0, q1)\nif abs(abs(d) - 1.0) &lt; EPS:\nreturn q0\nif shortestpath and d &lt; 0.0:\n# invert rotation\nd = -d\nq1 *= -1.0\nangle = math.acos(np.clip(d, -1, 1))\nif abs(angle) &lt; EPS:\nreturn q0\nisin = 1.0 / math.sin(angle)\nq0 *= math.sin((1.0 - fraction) * angle) * isin\nq1 *= math.sin(fraction * angle) * isin\nq0 += q1\nreturn q0\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.random_axis_angle","title":"<code>random_axis_angle(angle_limit=None, random_state=None)</code>","text":"<p>Samples an axis-angle rotation by first sampling a random axis and then sampling an angle. If @angle_limit is provided, the size of the rotation angle is constrained.</p> <p>If @random_state is provided (instance of np.random.RandomState), it will be used to generate random numbers.</p> <p>Parameters:</p> Name Type Description Default <code>angle_limit</code> <code>None or float</code> <p>If set, determines magnitude limit of angles to generate</p> <code>None</code> <code>random_state</code> <code>None or RandomState</code> <p>RNG to use if specified</p> <code>None</code> <p>Raises:</p> Type Description <code>AssertionError</code> <p>[Invalid RNG]</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def random_axis_angle(angle_limit=None, random_state=None):\n\"\"\"\n    Samples an axis-angle rotation by first sampling a random axis\n    and then sampling an angle. If @angle_limit is provided, the size\n    of the rotation angle is constrained.\n    If @random_state is provided (instance of np.random.RandomState), it\n    will be used to generate random numbers.\n    Args:\n        angle_limit (None or float): If set, determines magnitude limit of angles to generate\n        random_state (None or RandomState): RNG to use if specified\n    Raises:\n        AssertionError: [Invalid RNG]\n    \"\"\"\nif angle_limit is None:\nangle_limit = 2.0 * np.pi\nif random_state is not None:\nassert isinstance(random_state, np.random.RandomState)\nnpr = random_state\nelse:\nnpr = np.random\n# sample random axis using a normalized sample from spherical Gaussian.\n# see (http://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/)\n# for why it works.\nrandom_axis = npr.randn(3)\nrandom_axis /= np.linalg.norm(random_axis)\nrandom_angle = npr.uniform(low=0.0, high=angle_limit)\nreturn random_axis, random_angle\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.random_quat","title":"<code>random_quat(rand=None)</code>","text":"<p>Return uniform random unit quaternion.</p> <p>E.g.:</p> <p>q = random_quat() np.allclose(1.0, vector_norm(q)) True q = random_quat(np.random.random(3)) q.shape (4,)</p> <p>Parameters:</p> Name Type Description Default <code>rand</code> <code>3-array or None</code> <p>If specified, must be three independent random variables that are uniformly distributed between 0 and 1.</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: (x,y,z,w) random quaternion</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def random_quat(rand=None):\n\"\"\"\n    Return uniform random unit quaternion.\n    E.g.:\n    &gt;&gt;&gt; q = random_quat()\n    &gt;&gt;&gt; np.allclose(1.0, vector_norm(q))\n    True\n    &gt;&gt;&gt; q = random_quat(np.random.random(3))\n    &gt;&gt;&gt; q.shape\n    (4,)\n    Args:\n        rand (3-array or None): If specified, must be three independent random variables that are uniformly distributed\n            between 0 and 1.\n    Returns:\n        np.array: (x,y,z,w) random quaternion\n    \"\"\"\nif rand is None:\nrand = np.random.rand(3)\nelse:\nassert len(rand) == 3\nr1 = np.sqrt(1.0 - rand[0])\nr2 = np.sqrt(rand[0])\npi2 = math.pi * 2.0\nt1 = pi2 * rand[1]\nt2 = pi2 * rand[2]\nreturn np.array(\n(np.sin(t1) * r1, np.cos(t1) * r1, np.sin(t2) * r2, np.cos(t2) * r2),\ndtype=np.float32,\n)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.relative_pose_transform","title":"<code>relative_pose_transform(pos1, quat1, pos0, quat0)</code>","text":"<p>Computes relative forward transform from pose (pos0, quat0) to pose (pos1, quat1), i.e.: solves:</p> <p>pose1 = pose0 @ transform</p> <p>Parameters:</p> Name Type Description Default <code>pos1</code> <p>(x,y,z) position to transform</p> required <code>quat1</code> <p>(x,y,z,w) orientation to transform</p> required <code>pos0</code> <p>(x,y,z) initial position</p> required <code>quat0</code> <p>(x,y,z,w) initial orientation</p> required Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def relative_pose_transform(pos1, quat1, pos0, quat0):\n\"\"\"\n    Computes relative forward transform from pose (pos0, quat0) to pose (pos1, quat1), i.e.: solves:\n    pose1 = pose0 @ transform\n    Args:\n        pos1: (x,y,z) position to transform\n        quat1: (x,y,z,w) orientation to transform\n        pos0: (x,y,z) initial position\n        quat0: (x,y,z,w) initial orientation\n    \"\"\"\n# Get poses\nmat0 = pose2mat((pos0, quat0))\nmat1 = pose2mat((pos1, quat1))\n# Invert pose0 and calculate transform\nreturn mat2pose(pose_inv(mat0) @ mat1)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.rotation_matrix","title":"<code>rotation_matrix(angle, direction, point=None)</code>","text":"<p>Returns matrix to rotate about axis defined by point and direction.</p> <p>E.g.:     &gt;&gt;&gt; angle = (random.random() - 0.5) * (2math.pi)     &gt;&gt;&gt; direc = numpy.random.random(3) - 0.5     &gt;&gt;&gt; point = numpy.random.random(3) - 0.5     &gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)     &gt;&gt;&gt; R1 = rotation_matrix(angle-2math.pi, direc, point)     &gt;&gt;&gt; is_same_transform(R0, R1)     True</p> <pre><code>&gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)\n&gt;&gt;&gt; R1 = rotation_matrix(-angle, -direc, point)\n&gt;&gt;&gt; is_same_transform(R0, R1)\nTrue\n\n&gt;&gt;&gt; I = numpy.identity(4, numpy.float32)\n&gt;&gt;&gt; numpy.allclose(I, rotation_matrix(math.pi*2, direc))\nTrue\n\n&gt;&gt;&gt; numpy.allclose(2., numpy.trace(rotation_matrix(math.pi/2,\n...                                                direc, point)))\nTrue\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>Magnitude of rotation</p> required <code>direction</code> <code>np.array</code> <p>(ax,ay,az) axis about which to rotate</p> required <code>point</code> <code>None or np.array</code> <p>If specified, is the (x,y,z) point about which the rotation will occur</p> <code>None</code> <p>Returns:</p> Type Description <p>np.array: 4x4 homogeneous matrix that includes the desired rotation</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def rotation_matrix(angle, direction, point=None):\n\"\"\"\n    Returns matrix to rotate about axis defined by point and direction.\n    E.g.:\n        &gt;&gt;&gt; angle = (random.random() - 0.5) * (2*math.pi)\n        &gt;&gt;&gt; direc = numpy.random.random(3) - 0.5\n        &gt;&gt;&gt; point = numpy.random.random(3) - 0.5\n        &gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)\n        &gt;&gt;&gt; R1 = rotation_matrix(angle-2*math.pi, direc, point)\n        &gt;&gt;&gt; is_same_transform(R0, R1)\n        True\n        &gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)\n        &gt;&gt;&gt; R1 = rotation_matrix(-angle, -direc, point)\n        &gt;&gt;&gt; is_same_transform(R0, R1)\n        True\n        &gt;&gt;&gt; I = numpy.identity(4, numpy.float32)\n        &gt;&gt;&gt; numpy.allclose(I, rotation_matrix(math.pi*2, direc))\n        True\n        &gt;&gt;&gt; numpy.allclose(2., numpy.trace(rotation_matrix(math.pi/2,\n        ...                                                direc, point)))\n        True\n    Args:\n        angle (float): Magnitude of rotation\n        direction (np.array): (ax,ay,az) axis about which to rotate\n        point (None or np.array): If specified, is the (x,y,z) point about which the rotation will occur\n    Returns:\n        np.array: 4x4 homogeneous matrix that includes the desired rotation\n    \"\"\"\nsina = math.sin(angle)\ncosa = math.cos(angle)\ndirection = unit_vector(direction[:3])\n# rotation matrix around unit vector\nR = np.array(((cosa, 0.0, 0.0), (0.0, cosa, 0.0), (0.0, 0.0, cosa)), dtype=np.float32)\nR += np.outer(direction, direction) * (1.0 - cosa)\ndirection *= sina\nR += np.array(\n(\n(0.0, -direction[2], direction[1]),\n(direction[2], 0.0, -direction[0]),\n(-direction[1], direction[0], 0.0),\n),\ndtype=np.float32,\n)\nM = np.identity(4)\nM[:3, :3] = R\nif point is not None:\n# rotation not around origin\npoint = np.array(point[:3], dtype=np.float32, copy=False)\nM[:3, 3] = point - np.dot(R, point)\nreturn M\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.unit_vector","title":"<code>unit_vector(data, axis=None, out=None)</code>","text":"<p>Returns ndarray normalized by length, i.e. eucledian norm, along axis.</p> <p>E.g.:     &gt;&gt;&gt; v0 = numpy.random.random(3)     &gt;&gt;&gt; v1 = unit_vector(v0)     &gt;&gt;&gt; numpy.allclose(v1, v0 / numpy.linalg.norm(v0))     True</p> <pre><code>&gt;&gt;&gt; v0 = numpy.random.rand(5, 4, 3)\n&gt;&gt;&gt; v1 = unit_vector(v0, axis=-1)\n&gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=2)), 2)\n&gt;&gt;&gt; numpy.allclose(v1, v2)\nTrue\n\n&gt;&gt;&gt; v1 = unit_vector(v0, axis=1)\n&gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=1)), 1)\n&gt;&gt;&gt; numpy.allclose(v1, v2)\nTrue\n\n&gt;&gt;&gt; v1 = numpy.empty((5, 4, 3), dtype=numpy.float32)\n&gt;&gt;&gt; unit_vector(v0, axis=1, out=v1)\n&gt;&gt;&gt; numpy.allclose(v1, v2)\nTrue\n\n&gt;&gt;&gt; list(unit_vector([]))\n[]\n\n&gt;&gt;&gt; list(unit_vector([1.0]))\n[1.0]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>np.array</code> <p>data to normalize</p> required <code>axis</code> <code>None or int</code> <p>If specified, determines specific axis along data to normalize</p> <code>None</code> <code>out</code> <code>None or np.array</code> <p>If specified, will store computation in this variable</p> <code>None</code> <p>Returns:</p> Type Description <p>None or np.array: If @out is not specified, will return normalized vector. Otherwise, stores the output in @out</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def unit_vector(data, axis=None, out=None):\n\"\"\"\n    Returns ndarray normalized by length, i.e. eucledian norm, along axis.\n    E.g.:\n        &gt;&gt;&gt; v0 = numpy.random.random(3)\n        &gt;&gt;&gt; v1 = unit_vector(v0)\n        &gt;&gt;&gt; numpy.allclose(v1, v0 / numpy.linalg.norm(v0))\n        True\n        &gt;&gt;&gt; v0 = numpy.random.rand(5, 4, 3)\n        &gt;&gt;&gt; v1 = unit_vector(v0, axis=-1)\n        &gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=2)), 2)\n        &gt;&gt;&gt; numpy.allclose(v1, v2)\n        True\n        &gt;&gt;&gt; v1 = unit_vector(v0, axis=1)\n        &gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=1)), 1)\n        &gt;&gt;&gt; numpy.allclose(v1, v2)\n        True\n        &gt;&gt;&gt; v1 = numpy.empty((5, 4, 3), dtype=numpy.float32)\n        &gt;&gt;&gt; unit_vector(v0, axis=1, out=v1)\n        &gt;&gt;&gt; numpy.allclose(v1, v2)\n        True\n        &gt;&gt;&gt; list(unit_vector([]))\n        []\n        &gt;&gt;&gt; list(unit_vector([1.0]))\n        [1.0]\n    Args:\n        data (np.array): data to normalize\n        axis (None or int): If specified, determines specific axis along data to normalize\n        out (None or np.array): If specified, will store computation in this variable\n    Returns:\n        None or np.array: If @out is not specified, will return normalized vector. Otherwise, stores the output in @out\n    \"\"\"\nif out is None:\ndata = np.array(data, dtype=np.float32, copy=True)\nif data.ndim == 1:\ndata /= math.sqrt(np.dot(data, data))\nreturn data\nelse:\nif out is not data:\nout[:] = np.array(data, copy=False)\ndata = out\nlength = np.atleast_1d(np.sum(data * data, axis))\nnp.sqrt(length, length)\nif axis is not None:\nlength = np.expand_dims(length, axis)\ndata /= length\nif out is None:\nreturn data\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.vec","title":"<code>vec(values)</code>","text":"<p>Converts value tuple into a numpy vector.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>n-array</code> <p>a tuple of numbers</p> required <p>Returns:</p> Type Description <p>np.array: vector of given values</p> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def vec(values):\n\"\"\"\n    Converts value tuple into a numpy vector.\n    Args:\n        values (n-array): a tuple of numbers\n    Returns:\n        np.array: vector of given values\n    \"\"\"\nreturn np.array(values, dtype=np.float32)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.vec2quat","title":"<code>vec2quat(vec, up=(0, 0, 1.0))</code>","text":"<p>Converts given 3d-direction vector @vec to quaternion orientation with respect to another direction vector @up</p> <p>Parameters:</p> Name Type Description Default <code>vec</code> <code>3-array</code> <p>(x,y,z) direction vector (possible non-normalized)</p> required <code>up</code> <code>3-array</code> <p>(x,y,z) direction vector representing the canonical up direction (possible non-normalized)</p> <code>(0, 0, 1.0)</code> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def vec2quat(vec, up=(0, 0, 1.0)):\n\"\"\"\n    Converts given 3d-direction vector @vec to quaternion orientation with respect to another direction vector @up\n    Args:\n        vec (3-array): (x,y,z) direction vector (possible non-normalized)\n        up (3-array): (x,y,z) direction vector representing the canonical up direction (possible non-normalized)\n    \"\"\"\n# See https://stackoverflow.com/questions/15873996/converting-a-direction-vector-to-a-quaternion-rotation\n# Take cross product of @up and @vec to get @s_n, and then cross @vec and @s_n to get @u_n\n# Then compose 3x3 rotation matrix and convert into quaternion\nvec_n = vec / np.linalg.norm(vec)       # x\nup_n = up / np.linalg.norm(up)\ns_n = np.cross(up_n, vec_n)             # y\nu_n = np.cross(vec_n, s_n)              # z\nreturn mat2quat(np.array([vec_n, s_n, u_n]).T)\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.vecs2axisangle","title":"<code>vecs2axisangle(vec0, vec1)</code>","text":"<p>Converts the angle from unnormalized 3D vectors @vec0 to @vec1 into an axis-angle representation of the angle</p> <p>Parameters:</p> Name Type Description Default <code>vec0</code> <code>3-array</code> <p>(x,y,z) 3D vector, possibly unnormalized</p> required <code>vec1</code> <code>3-array</code> <p>(x,y,z) 3D vector, possibly unnormalized</p> required Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def vecs2axisangle(vec0, vec1):\n\"\"\"\n    Converts the angle from unnormalized 3D vectors @vec0 to @vec1 into an axis-angle representation of the angle\n    Args:\n        vec0 (3-array): (x,y,z) 3D vector, possibly unnormalized\n        vec1 (3-array): (x,y,z) 3D vector, possibly unnormalized\n    \"\"\"\n# Normalize vectors\nvec0 = normalize(vec0)\nvec1 = normalize(vec1)\n# Get cross product for direction of angle, and multiply by arcos of the dot product which is the angle\nreturn np.cross(vec0, vec1) * np.arccos(np.dot(vec0, vec1))\n</code></pre>"},{"location":"reference/utils/transform_utils.html#utils.transform_utils.vel_in_A_to_vel_in_B","title":"<code>vel_in_A_to_vel_in_B(vel_A, ang_vel_A, pose_A_in_B)</code>","text":"<p>Converts linear and angular velocity of a point in frame A to the equivalent in frame B.</p> <p>Parameters:</p> Name Type Description Default <code>vel_A</code> <code>np.array</code> <p>(vx,vy,vz) linear velocity in A</p> required <code>ang_vel_A</code> <code>np.array</code> <p>(wx,wy,wz) angular velocity in A</p> required <code>pose_A_in_B</code> <code>np.array</code> <p>4x4 matrix corresponding to the pose of A in frame B</p> required <p>Returns:</p> Type Description <p>2-tuple:</p> <ul> <li>(np.array) (vx,vy,vz) linear velocities in frame B</li> <li>(np.array) (wx,wy,wz) angular velocities in frame B</li> </ul> Source code in <code>omnigibson/utils/transform_utils.py</code> <pre><code>def vel_in_A_to_vel_in_B(vel_A, ang_vel_A, pose_A_in_B):\n\"\"\"\n    Converts linear and angular velocity of a point in frame A to the equivalent in frame B.\n    Args:\n        vel_A (np.array): (vx,vy,vz) linear velocity in A\n        ang_vel_A (np.array): (wx,wy,wz) angular velocity in A\n        pose_A_in_B (np.array): 4x4 matrix corresponding to the pose of A in frame B\n    Returns:\n        2-tuple:\n            - (np.array) (vx,vy,vz) linear velocities in frame B\n            - (np.array) (wx,wy,wz) angular velocities in frame B\n    \"\"\"\npos_A_in_B = pose_A_in_B[:3, 3]\nrot_A_in_B = pose_A_in_B[:3, :3]\nskew_symm = _skew_symmetric_translation(pos_A_in_B)\nvel_B = rot_A_in_B.dot(vel_A) + skew_symm.dot(rot_A_in_B.dot(ang_vel_A))\nang_vel_B = rot_A_in_B.dot(ang_vel_A)\nreturn vel_B, ang_vel_B\n</code></pre>"},{"location":"reference/utils/ui_utils.html","title":"ui_utils","text":"<p>Helper classes and functions for streamlining user interactions</p>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover","title":"<code>CameraMover</code>","text":"<p>A helper class for manipulating a camera via the keyboard. Utilizes carb keyboard callbacks to move the camera around.</p> <p>Parameters:</p> Name Type Description Default <code>cam</code> <code>VisionSensor</code> <p>The camera vision sensor to manipulate via the keyboard</p> required <code>delta</code> <code>float</code> <p>Change (m) per keypress when moving the camera</p> <code>0.25</code> <code>save_dir</code> <code>str</code> <p>Absolute path to where recorded images should be stored. Default is /imgs <code>f\"{og.root_path}'/../images'\"</code> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>class CameraMover:\n\"\"\"\n    A helper class for manipulating a camera via the keyboard. Utilizes carb keyboard callbacks to move\n    the camera around.\n    Args:\n        cam (VisionSensor): The camera vision sensor to manipulate via the keyboard\n        delta (float): Change (m) per keypress when moving the camera\n        save_dir (str): Absolute path to where recorded images should be stored. Default is &lt;OMNIGIBSON_PATH&gt;/imgs\n    \"\"\"\ndef __init__(self, cam, delta=0.25, save_dir=f\"{og.root_path}/../images\"):\nself.cam = cam\nself.delta = delta\nself.light_val = gm.FORCE_LIGHT_INTENSITY\nself.save_dir = save_dir\nself._appwindow = omni.appwindow.get_default_app_window()\nself._input = carb.input.acquire_input_interface()\nself._keyboard = self._appwindow.get_keyboard()\nself._sub_keyboard = self._input.subscribe_to_keyboard_events(self._keyboard, self._sub_keyboard_event)\ndef set_save_dir(self, save_dir):\n\"\"\"\n        Sets the absolute path corresponding to the image directory where recorded images from this CameraMover\n        should be saved\n        Args:\n            save_dir (str): Absolute path to where recorded images should be stored\n        \"\"\"\nself.save_dir = save_dir\ndef change_light(self, delta):\nself.light_val += delta\nself.set_lights(self.light_val)\ndef set_lights(self, intensity):\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nworld = get_prim_at_path(\"/World\")\nfor prim in world.GetChildren():\nfor prim_child in prim.GetChildren():\nfor prim_child_child in prim_child.GetChildren():\nif \"Light\" in prim_child_child.GetPrimTypeInfo().GetTypeName():\nprim_child_child.GetAttribute(\"intensity\").Set(intensity)\ndef print_info(self):\n\"\"\"\n        Prints keyboard command info out to the user\n        \"\"\"\nprint(\"*\" * 40)\nprint(\"CameraMover! Commands:\")\nprint()\nprint(f\"\\t Right Click + Drag: Rotate camera\")\nprint(f\"\\t W / S : Move camera forward / backward\")\nprint(f\"\\t A / D : Move camera left / right\")\nprint(f\"\\t T / G : Move camera up / down\")\nprint(f\"\\t 9 / 0 : Increase / decrease the lights\")\nprint(f\"\\t P : Print current camera pose\")\nprint(f\"\\t O: Save the current camera view as an image\")\ndef print_cam_pose(self):\n\"\"\"\n        Prints out the camera pose as (position, quaternion) in the world frame\n        \"\"\"\nprint(f\"cam pose: {self.cam.get_position_orientation()}\")\ndef get_image(self):\n\"\"\"\n        Helper function for quickly grabbing the currently viewed RGB image\n        Returns:\n            np.array: (H, W, 3) sized RGB image array\n        \"\"\"\nreturn self.cam.get_obs()[\"rgb\"][:, :, :-1]\ndef record_image(self, fpath=None):\n\"\"\"\n        Saves the currently viewed image and writes it to disk\n        Args:\n            fpath (None or str): If specified, the absolute fpath to the image save location. Default is located in\n                self.save_dir\n        \"\"\"\nog.log.info(\"Recording image...\")\n# Use default fpath if not specified\nif fpath is None:\ntimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\nfpath = f\"{self.save_dir}/og_{timestamp}.png\"\n# Make sure save path directory exists, and then save the image to that location\nPath(Path(fpath).parent).mkdir(parents=True, exist_ok=True)\nImage.fromarray(self.get_image()).save(fpath)\nog.log.info(f\"Saved current viewer camera image to {fpath}.\")\ndef record_trajectory(self, poses, fps, steps_per_frame=1, fpath=None):\n\"\"\"\n        Moves the viewer camera through the poses specified by @poses and records the resulting trajectory to an mp4\n        video file on disk.\n        Args:\n            poses (list of 2-tuple): List of global (position, quaternion) values to set the viewer camera to defining\n                this trajectory\n            fps (int): Frames per second when recording this video\n            steps_per_frame (int): How many sim steps should occur between each frame being recorded. Minimum and\n                default is 1.\n            fpath (None or str): If specified, the absolute fpath to the video save location. Default is located in\n                self.save_dir\n        \"\"\"\nog.log.info(\"Recording trajectory...\")\n# Use default fpath if not specified\nif fpath is None:\ntimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\nfpath = f\"{self.save_dir}/og_{timestamp}.mp4\"\n# Make sure save path directory exists, and then create the video writer\nPath(Path(fpath).parent).mkdir(parents=True, exist_ok=True)\nvideo_writer = imageio.get_writer(fpath, fps=fps)\n# Iterate through all desired poses, and record the trajectory\nfor i, (pos, quat) in enumerate(poses):\nself.cam.set_position_orientation(position=pos, orientation=quat)\nog.sim.step()\nif i % steps_per_frame == 0:\nvideo_writer.append_data(self.get_image())\n# Close writer\nvideo_writer.close()\nog.log.info(f\"Saved camera trajectory video to {fpath}.\")\ndef record_trajectory_from_waypoints(self, waypoints, per_step_distance, fps, steps_per_frame=1, fpath=None):\n\"\"\"\n        Moves the viewer camera through the waypoints specified by @waypoints and records the resulting trajectory to\n        an mp4 video file on disk.\n        Args:\n            waypoints (np.array): (n, 3) global position waypoint values to set the viewer camera to defining this trajectory\n            per_step_distance (float): How much distance (in m) should be approximately covered per trajectory step.\n                This will determine the path length between individual waypoints\n            fps (int): Frames per second when recording this video\n            steps_per_frame (int): How many sim steps should occur between each frame being recorded. Minimum and\n                default is 1.\n            fpath (None or str): If specified, the absolute fpath to the video save location. Default is located in\n                self.save_dir\n        \"\"\"\n# Create splines and their derivatives\nn_waypoints = len(waypoints)\nsplines = [CubicSpline(range(n_waypoints), waypoints[:, i], bc_type='clamped') for i in range(3)]\ndsplines = [spline.derivative() for spline in splines]\n# Function help get arc derivative\ndef arc_derivative(u):\nreturn np.sqrt(np.sum([dspline(u) ** 2 for dspline in dsplines]))\n# Function to help get interpolated positions\ndef get_interpolated_positions(step):\nassert step &lt; n_waypoints - 1\ndist = quad(func=arc_derivative, a=step, b=step + 1)[0]\npath_length = int(dist / per_step_distance)\ninterpolated_points = np.zeros((path_length, 3))\nfor i in range(path_length):\ncurr_step = step + (i / path_length)\ninterpolated_points[i, :] = np.array([spline(curr_step) for spline in splines])\nreturn interpolated_points\n# Iterate over all waypoints and infer the resulting trajectory, recording the resulting poses\nposes = []\nfor i in range(n_waypoints - 1):\npositions = get_interpolated_positions(step=i)\nfor j in range(len(positions) - 1):\n# Get direction vector from the current to the following point\ndirection = positions[j + 1] - positions[j]\ndirection = direction / np.linalg.norm(direction)\n# Infer tilt and pan angles from this direction\nxy_direction = direction[:2] / np.linalg.norm(direction[:2])\nz = direction[2]\npan_angle = np.arctan2(-xy_direction[0], xy_direction[1])\ntilt_angle = np.arcsin(z)\n# Infer global quat orientation from these angles\nquat = T.euler2quat([np.pi / 2 - tilt_angle, 0.0, pan_angle])\nposes.append([positions[j], quat])\n# Record the generated trajectory\nself.record_trajectory(poses=poses, fps=fps, steps_per_frame=steps_per_frame, fpath=fpath)\ndef set_delta(self, delta):\n\"\"\"\n        Sets the delta value (how much the camera moves with each keypress) for this CameraMover\n        Args:\n            delta (float): Change (m) per keypress when moving the camera\n        \"\"\"\nself.delta = delta\ndef set_cam(self, cam):\n\"\"\"\n        Sets the active camera sensor for this CameraMover\n        Args:\n            cam (VisionSensor): The camera vision sensor to manipulate via the keyboard\n        \"\"\"\nself.cam = cam\n@property\ndef input_to_function(self):\n\"\"\"\n        Returns:\n            dict: Mapping from relevant keypresses to corresponding function call to use\n        \"\"\"\nreturn {\ncarb.input.KeyboardInput.O: lambda: self.record_image(fpath=None),\ncarb.input.KeyboardInput.P: lambda: self.print_cam_pose(),\ncarb.input.KeyboardInput.KEY_9: lambda: self.change_light(delta=-2e4),\ncarb.input.KeyboardInput.KEY_0: lambda: self.change_light(delta=2e4),\n}\n@property\ndef input_to_command(self):\n\"\"\"\n        Returns:\n            dict: Mapping from relevant keypresses to corresponding delta command to apply to the camera pose\n        \"\"\"\nreturn {\ncarb.input.KeyboardInput.D: np.array([self.delta, 0, 0]),\ncarb.input.KeyboardInput.A: np.array([-self.delta, 0, 0]),\ncarb.input.KeyboardInput.W: np.array([0, 0, -self.delta]),\ncarb.input.KeyboardInput.S: np.array([0, 0, self.delta]),\ncarb.input.KeyboardInput.T: np.array([0, self.delta, 0]),\ncarb.input.KeyboardInput.G: np.array([0, -self.delta, 0]),\n}\ndef _sub_keyboard_event(self, event, *args, **kwargs):\n\"\"\"\n        Handle keyboard events. Note: The signature is pulled directly from omni.\n        Args:\n            event (int): keyboard event type\n        \"\"\"\nif event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\nif event.type == carb.input.KeyboardEventType.KEY_PRESS and event.input in self.input_to_function:\nself.input_to_function[event.input]()\nelse:\ncommand = self.input_to_command.get(event.input, None)\nif command is not None:\n# Convert to world frame to move the camera\ntransform = T.quat2mat(self.cam.get_orientation())\ndelta_pos_global = transform @ command\nself.cam.set_position(self.cam.get_position() + delta_pos_global)\nreturn True\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.input_to_command","title":"<code>input_to_command</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Mapping from relevant keypresses to corresponding delta command to apply to the camera pose</p>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.input_to_function","title":"<code>input_to_function</code>  <code>property</code>","text":"<p>Returns:</p> Name Type Description <code>dict</code> <p>Mapping from relevant keypresses to corresponding function call to use</p>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.get_image","title":"<code>get_image()</code>","text":"<p>Helper function for quickly grabbing the currently viewed RGB image</p> <p>Returns:</p> Type Description <p>np.array: (H, W, 3) sized RGB image array</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def get_image(self):\n\"\"\"\n    Helper function for quickly grabbing the currently viewed RGB image\n    Returns:\n        np.array: (H, W, 3) sized RGB image array\n    \"\"\"\nreturn self.cam.get_obs()[\"rgb\"][:, :, :-1]\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.print_cam_pose","title":"<code>print_cam_pose()</code>","text":"<p>Prints out the camera pose as (position, quaternion) in the world frame</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def print_cam_pose(self):\n\"\"\"\n    Prints out the camera pose as (position, quaternion) in the world frame\n    \"\"\"\nprint(f\"cam pose: {self.cam.get_position_orientation()}\")\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.print_info","title":"<code>print_info()</code>","text":"<p>Prints keyboard command info out to the user</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def print_info(self):\n\"\"\"\n    Prints keyboard command info out to the user\n    \"\"\"\nprint(\"*\" * 40)\nprint(\"CameraMover! Commands:\")\nprint()\nprint(f\"\\t Right Click + Drag: Rotate camera\")\nprint(f\"\\t W / S : Move camera forward / backward\")\nprint(f\"\\t A / D : Move camera left / right\")\nprint(f\"\\t T / G : Move camera up / down\")\nprint(f\"\\t 9 / 0 : Increase / decrease the lights\")\nprint(f\"\\t P : Print current camera pose\")\nprint(f\"\\t O: Save the current camera view as an image\")\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.record_image","title":"<code>record_image(fpath=None)</code>","text":"<p>Saves the currently viewed image and writes it to disk</p> <p>Parameters:</p> Name Type Description Default <code>fpath</code> <code>None or str</code> <p>If specified, the absolute fpath to the image save location. Default is located in self.save_dir</p> <code>None</code> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def record_image(self, fpath=None):\n\"\"\"\n    Saves the currently viewed image and writes it to disk\n    Args:\n        fpath (None or str): If specified, the absolute fpath to the image save location. Default is located in\n            self.save_dir\n    \"\"\"\nog.log.info(\"Recording image...\")\n# Use default fpath if not specified\nif fpath is None:\ntimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\nfpath = f\"{self.save_dir}/og_{timestamp}.png\"\n# Make sure save path directory exists, and then save the image to that location\nPath(Path(fpath).parent).mkdir(parents=True, exist_ok=True)\nImage.fromarray(self.get_image()).save(fpath)\nog.log.info(f\"Saved current viewer camera image to {fpath}.\")\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.record_trajectory","title":"<code>record_trajectory(poses, fps, steps_per_frame=1, fpath=None)</code>","text":"<p>Moves the viewer camera through the poses specified by @poses and records the resulting trajectory to an mp4 video file on disk.</p> <p>Parameters:</p> Name Type Description Default <code>poses</code> <code>list of 2-tuple</code> <p>List of global (position, quaternion) values to set the viewer camera to defining this trajectory</p> required <code>fps</code> <code>int</code> <p>Frames per second when recording this video</p> required <code>steps_per_frame</code> <code>int</code> <p>How many sim steps should occur between each frame being recorded. Minimum and default is 1.</p> <code>1</code> <code>fpath</code> <code>None or str</code> <p>If specified, the absolute fpath to the video save location. Default is located in self.save_dir</p> <code>None</code> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def record_trajectory(self, poses, fps, steps_per_frame=1, fpath=None):\n\"\"\"\n    Moves the viewer camera through the poses specified by @poses and records the resulting trajectory to an mp4\n    video file on disk.\n    Args:\n        poses (list of 2-tuple): List of global (position, quaternion) values to set the viewer camera to defining\n            this trajectory\n        fps (int): Frames per second when recording this video\n        steps_per_frame (int): How many sim steps should occur between each frame being recorded. Minimum and\n            default is 1.\n        fpath (None or str): If specified, the absolute fpath to the video save location. Default is located in\n            self.save_dir\n    \"\"\"\nog.log.info(\"Recording trajectory...\")\n# Use default fpath if not specified\nif fpath is None:\ntimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\nfpath = f\"{self.save_dir}/og_{timestamp}.mp4\"\n# Make sure save path directory exists, and then create the video writer\nPath(Path(fpath).parent).mkdir(parents=True, exist_ok=True)\nvideo_writer = imageio.get_writer(fpath, fps=fps)\n# Iterate through all desired poses, and record the trajectory\nfor i, (pos, quat) in enumerate(poses):\nself.cam.set_position_orientation(position=pos, orientation=quat)\nog.sim.step()\nif i % steps_per_frame == 0:\nvideo_writer.append_data(self.get_image())\n# Close writer\nvideo_writer.close()\nog.log.info(f\"Saved camera trajectory video to {fpath}.\")\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.record_trajectory_from_waypoints","title":"<code>record_trajectory_from_waypoints(waypoints, per_step_distance, fps, steps_per_frame=1, fpath=None)</code>","text":"<p>Moves the viewer camera through the waypoints specified by @waypoints and records the resulting trajectory to an mp4 video file on disk.</p> <p>Parameters:</p> Name Type Description Default <code>waypoints</code> <code>np.array</code> <p>(n, 3) global position waypoint values to set the viewer camera to defining this trajectory</p> required <code>per_step_distance</code> <code>float</code> <p>How much distance (in m) should be approximately covered per trajectory step. This will determine the path length between individual waypoints</p> required <code>fps</code> <code>int</code> <p>Frames per second when recording this video</p> required <code>steps_per_frame</code> <code>int</code> <p>How many sim steps should occur between each frame being recorded. Minimum and default is 1.</p> <code>1</code> <code>fpath</code> <code>None or str</code> <p>If specified, the absolute fpath to the video save location. Default is located in self.save_dir</p> <code>None</code> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def record_trajectory_from_waypoints(self, waypoints, per_step_distance, fps, steps_per_frame=1, fpath=None):\n\"\"\"\n    Moves the viewer camera through the waypoints specified by @waypoints and records the resulting trajectory to\n    an mp4 video file on disk.\n    Args:\n        waypoints (np.array): (n, 3) global position waypoint values to set the viewer camera to defining this trajectory\n        per_step_distance (float): How much distance (in m) should be approximately covered per trajectory step.\n            This will determine the path length between individual waypoints\n        fps (int): Frames per second when recording this video\n        steps_per_frame (int): How many sim steps should occur between each frame being recorded. Minimum and\n            default is 1.\n        fpath (None or str): If specified, the absolute fpath to the video save location. Default is located in\n            self.save_dir\n    \"\"\"\n# Create splines and their derivatives\nn_waypoints = len(waypoints)\nsplines = [CubicSpline(range(n_waypoints), waypoints[:, i], bc_type='clamped') for i in range(3)]\ndsplines = [spline.derivative() for spline in splines]\n# Function help get arc derivative\ndef arc_derivative(u):\nreturn np.sqrt(np.sum([dspline(u) ** 2 for dspline in dsplines]))\n# Function to help get interpolated positions\ndef get_interpolated_positions(step):\nassert step &lt; n_waypoints - 1\ndist = quad(func=arc_derivative, a=step, b=step + 1)[0]\npath_length = int(dist / per_step_distance)\ninterpolated_points = np.zeros((path_length, 3))\nfor i in range(path_length):\ncurr_step = step + (i / path_length)\ninterpolated_points[i, :] = np.array([spline(curr_step) for spline in splines])\nreturn interpolated_points\n# Iterate over all waypoints and infer the resulting trajectory, recording the resulting poses\nposes = []\nfor i in range(n_waypoints - 1):\npositions = get_interpolated_positions(step=i)\nfor j in range(len(positions) - 1):\n# Get direction vector from the current to the following point\ndirection = positions[j + 1] - positions[j]\ndirection = direction / np.linalg.norm(direction)\n# Infer tilt and pan angles from this direction\nxy_direction = direction[:2] / np.linalg.norm(direction[:2])\nz = direction[2]\npan_angle = np.arctan2(-xy_direction[0], xy_direction[1])\ntilt_angle = np.arcsin(z)\n# Infer global quat orientation from these angles\nquat = T.euler2quat([np.pi / 2 - tilt_angle, 0.0, pan_angle])\nposes.append([positions[j], quat])\n# Record the generated trajectory\nself.record_trajectory(poses=poses, fps=fps, steps_per_frame=steps_per_frame, fpath=fpath)\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.set_cam","title":"<code>set_cam(cam)</code>","text":"<p>Sets the active camera sensor for this CameraMover</p> <p>Parameters:</p> Name Type Description Default <code>cam</code> <code>VisionSensor</code> <p>The camera vision sensor to manipulate via the keyboard</p> required Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def set_cam(self, cam):\n\"\"\"\n    Sets the active camera sensor for this CameraMover\n    Args:\n        cam (VisionSensor): The camera vision sensor to manipulate via the keyboard\n    \"\"\"\nself.cam = cam\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.set_delta","title":"<code>set_delta(delta)</code>","text":"<p>Sets the delta value (how much the camera moves with each keypress) for this CameraMover</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>Change (m) per keypress when moving the camera</p> required Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def set_delta(self, delta):\n\"\"\"\n    Sets the delta value (how much the camera moves with each keypress) for this CameraMover\n    Args:\n        delta (float): Change (m) per keypress when moving the camera\n    \"\"\"\nself.delta = delta\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.set_save_dir","title":"<code>set_save_dir(save_dir)</code>","text":"<p>Sets the absolute path corresponding to the image directory where recorded images from this CameraMover should be saved</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>str</code> <p>Absolute path to where recorded images should be stored</p> required Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def set_save_dir(self, save_dir):\n\"\"\"\n    Sets the absolute path corresponding to the image directory where recorded images from this CameraMover\n    should be saved\n    Args:\n        save_dir (str): Absolute path to where recorded images should be stored\n    \"\"\"\nself.save_dir = save_dir\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler","title":"<code>KeyboardEventHandler</code>","text":"<p>Simple singleton class for handing keyboard events</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>class KeyboardEventHandler:\n\"\"\"\n    Simple singleton class for handing keyboard events\n    \"\"\"\n# Global keyboard callbacks\nKEYBOARD_CALLBACKS = dict()\n# ID assigned to meta callback method for this class\n_CALLBACK_ID = None\ndef __init__(self):\nraise ValueError(\"Cannot create an instance of keyboard event handler!\")\n@classmethod\ndef initialize(cls):\n\"\"\"\n        Hook up a meta function callback to the omni backend\n        \"\"\"\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\ncls._CALLBACK_ID = input_interface.subscribe_to_keyboard_events(keyboard, cls._meta_callback)\n@classmethod\ndef reset(cls):\n\"\"\"\n        Resets this callback interface by removing all current callback functions\n        \"\"\"\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\ninput_interface.unsubscribe_to_keyboard_events(keyboard, cls._CALLBACK_ID)\ncls.KEYBOARD_CALLBACKS = dict()\ncls._CALLBACK_ID = None\n@classmethod\ndef add_keyboard_callback(cls, key, callback_fn):\n\"\"\"\n        Registers a keyboard callback function with omni, mapping a keypress from @key to run the callback_function\n        @callback_fn\n        Args:\n            key (carb.input.KeyboardInput): key to associate with the callback\n            callback_fn (function): Callback function to call if the key @key is pressed or repeated. Note that this\n                function's signature should be:\n                callback_fn() --&gt; None\n        \"\"\"\n# Initialize the interface if not initialized yet\nif cls._CALLBACK_ID is None:\ncls.initialize()\n# Add the callback\ncls.KEYBOARD_CALLBACKS[key] = callback_fn\n@classmethod\ndef _meta_callback(cls, event, *args, **kwargs):\n\"\"\"\n        Meta callback function that is hooked up to omni's backend\n        \"\"\"\n# Check if we've received a key press or repeat\nif event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\n# Run the specific callback\ncls.KEYBOARD_CALLBACKS.get(event.input, lambda: None)()\n# Always return True\nreturn True\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler.add_keyboard_callback","title":"<code>add_keyboard_callback(key, callback_fn)</code>  <code>classmethod</code>","text":"<p>Registers a keyboard callback function with omni, mapping a keypress from @key to run the callback_function @callback_fn</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>carb.input.KeyboardInput</code> <p>key to associate with the callback</p> required <code>callback_fn</code> <code>function</code> <p>Callback function to call if the key @key is pressed or repeated. Note that this function's signature should be:</p> <p>callback_fn() --&gt; None</p> required Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>@classmethod\ndef add_keyboard_callback(cls, key, callback_fn):\n\"\"\"\n    Registers a keyboard callback function with omni, mapping a keypress from @key to run the callback_function\n    @callback_fn\n    Args:\n        key (carb.input.KeyboardInput): key to associate with the callback\n        callback_fn (function): Callback function to call if the key @key is pressed or repeated. Note that this\n            function's signature should be:\n            callback_fn() --&gt; None\n    \"\"\"\n# Initialize the interface if not initialized yet\nif cls._CALLBACK_ID is None:\ncls.initialize()\n# Add the callback\ncls.KEYBOARD_CALLBACKS[key] = callback_fn\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler.initialize","title":"<code>initialize()</code>  <code>classmethod</code>","text":"<p>Hook up a meta function callback to the omni backend</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>@classmethod\ndef initialize(cls):\n\"\"\"\n    Hook up a meta function callback to the omni backend\n    \"\"\"\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\ncls._CALLBACK_ID = input_interface.subscribe_to_keyboard_events(keyboard, cls._meta_callback)\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler.reset","title":"<code>reset()</code>  <code>classmethod</code>","text":"<p>Resets this callback interface by removing all current callback functions</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>@classmethod\ndef reset(cls):\n\"\"\"\n    Resets this callback interface by removing all current callback functions\n    \"\"\"\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\ninput_interface.unsubscribe_to_keyboard_events(keyboard, cls._CALLBACK_ID)\ncls.KEYBOARD_CALLBACKS = dict()\ncls._CALLBACK_ID = None\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController","title":"<code>KeyboardRobotController</code>","text":"<p>Simple class for controlling OmniGibson robots using keyboard commands</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>class KeyboardRobotController:\n\"\"\"\n    Simple class for controlling OmniGibson robots using keyboard commands\n    \"\"\"\ndef __init__(self, robot):\n\"\"\"\n        Args:\n            robot (BaseRobot): robot to control\n        \"\"\"\n# Store relevant info from robot\nself.robot = robot\nself.action_dim = robot.action_dim\nself.controller_info = dict()\nidx = 0\nfor name, controller in robot._controllers.items():\nself.controller_info[name] = {\n\"name\": type(controller).__name__,\n\"start_idx\": idx,\n\"dofs\": controller.dof_idx,\n\"command_dim\": controller.command_dim,\n}\nidx += controller.command_dim\n# Other persistent variables we need to keep track of\nself.joint_names = [name for name in robot.joints.keys()]  # Ordered list of joint names belonging to the robot\nself.joint_command_idx = None   # Indices of joints being directly controlled in the action array\nself.joint_control_idx = None  # Indices of joints being directly controlled in the actual joint array\nself.active_joint_command_idx_idx = 0   # Which index within the joint_command_idx variable is being controlled by the user\nself.current_joint = -1  # Active joint being controlled for joint control\nself.ik_arms = []               # List of arm controller names to be controlled by IK\nself.active_arm_idx = 0         # Which index within self.ik_arms is actively being controlled (only relevant for IK)\nself.binary_grippers = []           # Grippers being controlled using multi-finger binary controller\nself.active_gripper_idx = 0     # Which index within self.binary_grippers is actively being controlled\nself.gripper_direction = None  # Flips between -1 and 1, per arm controlled by multi-finger binary control\nself.persistent_gripper_action = None  # Persistent gripper commands, per arm controlled by multi-finger binary control\n# i.e.: if using binary gripper control and when no keypress is active, the gripper action should still the last executed gripper action\nself.keypress_mapping = None    # Maps omni keybindings to information for controlling various parts of the robot\nself.current_keypress = None    # Current key that is being pressed\nself.active_action = None       # Current action information based on the current keypress\nself.toggling_gripper = False   # Whether we should toggle the gripper during the next action\n# Populate the keypress mapping dictionary\nself.populate_keypress_mapping()\n# Register the keyboard callback function\nself.register_keyboard_handler()\ndef register_keyboard_handler(self):\n\"\"\"\n        Sets up the keyboard callback functionality with omniverse\n        \"\"\"\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\nsub_keyboard = input_interface.subscribe_to_keyboard_events(keyboard, self.keyboard_event_handler)\ndef generate_ik_keypress_mapping(self, controller_info):\n\"\"\"\n        Generates a dictionary for keypress mappings for IK control, based on the inputted @controller_info\n        Args:\n            controller_info (dict): Dictionary of controller information for the specific robot arm to control\n                with IK\n        Returns:\n            dict: Populated keypress mappings for IK to control the specified controller\n        \"\"\"\nmapping = {}\nmapping[carb.input.KeyboardInput.UP] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.DOWN] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.RIGHT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.LEFT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.P] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.SEMICOLON] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.N] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.B] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.O] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.U] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.V] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.C] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": -0.5}\nreturn mapping\ndef populate_keypress_mapping(self):\n\"\"\"\n        Populates the mapping @self.keypress_mapping, which maps keypresses to action info:\n            keypress:\n                idx: &lt;int&gt;\n                val: &lt;float&gt;\n        \"\"\"\nself.keypress_mapping = {}\nself.joint_command_idx = []\nself.joint_control_idx = []\nself.gripper_direction = {}\nself.persistent_gripper_action = {}\n# Add mapping for joint control directions (no index because these are inferred at runtime)\nself.keypress_mapping[carb.input.KeyboardInput.RIGHT_BRACKET] = {\"idx\": None, \"val\": 0.1}\nself.keypress_mapping[carb.input.KeyboardInput.LEFT_BRACKET] = {\"idx\": None, \"val\": -0.1}\n# Iterate over all controller info and populate mapping\nfor component, info in self.controller_info.items():\nif info[\"name\"] == \"JointController\":\nfor i in range(info[\"command_dim\"]):\ncmd_idx = info[\"start_idx\"] + i\nself.joint_command_idx.append(cmd_idx)\nself.joint_control_idx += info[\"dofs\"].tolist()\nelif info[\"name\"] == \"DifferentialDriveController\":\nself.keypress_mapping[carb.input.KeyboardInput.I] = {\"idx\": info[\"start_idx\"] + 0, \"val\": 0.4}\nself.keypress_mapping[carb.input.KeyboardInput.K] = {\"idx\": info[\"start_idx\"] + 0, \"val\": -0.4}\nself.keypress_mapping[carb.input.KeyboardInput.L] = {\"idx\": info[\"start_idx\"] + 1, \"val\": -0.2}\nself.keypress_mapping[carb.input.KeyboardInput.J] = {\"idx\": info[\"start_idx\"] + 1, \"val\": 0.2}\nelif info[\"name\"] == \"InverseKinematicsController\":\nself.ik_arms.append(component)\nself.keypress_mapping.update(self.generate_ik_keypress_mapping(controller_info=info))\nelif info[\"name\"] == \"MultiFingerGripperController\":\nif info[\"command_dim\"] &gt; 1:\nfor i in range(info[\"command_dim\"]):\ncmd_idx = info[\"start_idx\"] + i\nself.joint_command_idx.append(cmd_idx)\nself.joint_control_idx += info[\"dofs\"].tolist()\nelse:\nself.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": info[\"start_idx\"], \"val\": 1.0}\nself.gripper_direction[component] = 1.0\nself.persistent_gripper_action[component] = 1.0\nself.binary_grippers.append(component)\nelif info[\"name\"] == \"NullJointController\":\n# We won't send actions if using a null gripper controller\nself.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": None, \"val\": None}\nelse:\nraise ValueError(\"Unknown controller name received: {}\".format(info[\"name\"]))\ndef keyboard_event_handler(self, event, *args, **kwargs):\n# Check if we've received a key press or repeat\nif event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\n# Handle special cases\nif event.input in {carb.input.KeyboardInput.KEY_1, carb.input.KeyboardInput.KEY_2} and len(self.joint_control_idx) &gt; 1:\n# Update joint and print out new joint being controlled\nself.active_joint_command_idx_idx = max(0, self.active_joint_command_idx_idx - 1) \\\n                    if event.input == carb.input.KeyboardInput.KEY_1 \\\n                    else min(len(self.joint_control_idx) - 1, self.active_joint_command_idx_idx + 1)\nprint(f\"Now controlling joint {self.joint_names[self.joint_control_idx[self.active_joint_command_idx_idx]]}\")\nelif event.input in {carb.input.KeyboardInput.KEY_3, carb.input.KeyboardInput.KEY_4} and len(self.ik_arms) &gt; 1:\n# Update arm, update keypress mapping, and print out new arm being controlled\nself.active_arm_idx = max(0, self.active_arm_idx - 1) \\\n                    if event.input == carb.input.KeyboardInput.KEY_3 \\\n                    else min(len(self.ik_arms) - 1, self.active_arm_idx + 1)\nnew_arm = self.ik_arms[self.active_arm_idx]\nself.keypress_mapping.update(self.generate_ik_keypress_mapping(self.controller_info[new_arm]))\nprint(f\"Now controlling arm {new_arm} with IK\")\nelif event.input in {carb.input.KeyboardInput.KEY_5, carb.input.KeyboardInput.KEY_6} and len(self.binary_grippers) &gt; 1:\n# Update gripper, update keypress mapping, and print out new gripper being controlled\nself.active_gripper_idx = max(0, self.active_gripper_idx - 1) \\\n                    if event.input == carb.input.KeyboardInput.KEY_5 \\\n                    else min(len(self.binary_grippers) - 1, self.active_gripper_idx + 1)\nprint(f\"Now controlling gripper {self.binary_grippers[self.active_gripper_idx]} with binary toggling\")\nelif event.input == carb.input.KeyboardInput.R:\n# Render the sensors from the robot's camera and lidar\nself.robot.visualize_sensors()\nelif event.input == carb.input.KeyboardInput.ESCAPE:\n# Terminate immediately\nog.shutdown()\nelse:\n# Handle all other actions and update accordingly\nself.active_action = self.keypress_mapping.get(event.input, None)\nif event.type == carb.input.KeyboardEventType.KEY_PRESS:\n# Store the current keypress\nself.current_keypress = event.input\n# Also store whether we pressed the key for toggling gripper actions\nif event.input == carb.input.KeyboardInput.T:\nself.toggling_gripper = True\n# If we release a key, clear the active action and keypress\nelif event.type == carb.input.KeyboardEventType.KEY_RELEASE:\nself.active_action = None\nself.current_keypress = None\n# Callback always needs to return True\nreturn True\ndef get_random_action(self):\n\"\"\"\n        Returns:\n            n-array: Generated random action vector (normalized)\n        \"\"\"\nreturn np.random.uniform(-1, 1, self.action_dim)\ndef get_teleop_action(self):\n\"\"\"\n        Returns:\n            n-array: Generated action vector based on received user inputs from the keyboard\n        \"\"\"\naction = np.zeros(self.action_dim)\n# Handle the action if any key is actively being pressed\nif self.active_action is not None:\nidx, val = self.active_action[\"idx\"], self.active_action[\"val\"]\n# Only handle the action if the value is specified\nif val is not None:\n# If there is no index, the user is controlling a joint with \"[\" and \"]\"\nif idx is None and len(self.joint_command_idx) != 0:\nidx = self.joint_command_idx[self.active_joint_command_idx_idx]\n# Set the action\nif idx is not None:\naction[idx] = val\n# Possibly set the persistent gripper action\nif len(self.binary_grippers) &gt; 0 and self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] is not None:\nfor i, binary_gripper in enumerate(self.binary_grippers):\n# Possibly update the stored value if the toggle gripper key has been pressed and\n# it's the active gripper being controlled\nif self.toggling_gripper and i == self.active_gripper_idx:\n# We toggle the gripper direction or this gripper\nself.gripper_direction[binary_gripper] *= -1.0\nself.persistent_gripper_action[binary_gripper] = \\\n                        self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] * self.gripper_direction[binary_gripper]\n# Clear the toggling gripper flag\nself.toggling_gripper = False\n# Set the persistent action\naction[self.controller_info[binary_gripper][\"start_idx\"]] = self.persistent_gripper_action[binary_gripper]\n# Print out the user what is being pressed / controlled\nsys.stdout.write(\"\\033[K\")\nkeypress_str = self.current_keypress.__str__().split(\".\")[-1]\nprint(\"Pressed {}. Action: {}\".format(keypress_str, action))\nsys.stdout.write(\"\\033[F\")\n# Return action\nreturn action\n@staticmethod\ndef print_keyboard_teleop_info():\n\"\"\"\n        Prints out relevant information for teleop controlling a robot\n        \"\"\"\ndef print_command(char, info):\nchar += \" \" * (10 - len(char))\nprint(\"{}\\t{}\".format(char, info))\nprint()\nprint(\"*\" * 30)\nprint(\"Controlling the Robot Using the Keyboard\")\nprint(\"*\" * 30)\nprint()\nprint(\"Joint Control\")\nprint_command(\"1, 2\", \"decrement / increment the joint to control\")\nprint_command(\"[, ]\", \"move the joint backwards, forwards, respectively\")\nprint()\nprint(\"Differential Drive Control\")\nprint_command(\"i, k\", \"turn left, right\")\nprint_command(\"l, j\", \"move forward, backwards\")\nprint()\nprint(\"Inverse Kinematics Control\")\nprint_command(\"3, 4\", \"toggle between the different arm(s) to control\")\nprint_command(u\"\\u2190, \\u2192\", \"translate arm eef along x-axis\")\nprint_command(u\"\\u2191, \\u2193\", \"translate arm eef along y-axis\")\nprint_command(\"p, ;\", \"translate arm eef along z-axis\")\nprint_command(\"n, b\", \"rotate arm eef about x-axis\")\nprint_command(\"o, u\", \"rotate arm eef about y-axis\")\nprint_command(\"v, c\", \"rotate arm eef about z-axis\")\nprint()\nprint(\"Boolean Gripper Control\")\nprint_command(\"5, 6\", \"toggle between the different gripper(s) using binary control\")\nprint_command(\"t\", \"toggle gripper (open/close)\")\nprint()\nprint(\"Sensor Rendering\")\nprint_command(\"r\", \"render the onboard sensors (RGB, Depth, Normals, Instance Segmentation, Occupancy Map\")\nprint()\nprint(\"*\" * 30)\nprint()\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.__init__","title":"<code>__init__(robot)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>robot</code> <code>BaseRobot</code> <p>robot to control</p> required Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def __init__(self, robot):\n\"\"\"\n    Args:\n        robot (BaseRobot): robot to control\n    \"\"\"\n# Store relevant info from robot\nself.robot = robot\nself.action_dim = robot.action_dim\nself.controller_info = dict()\nidx = 0\nfor name, controller in robot._controllers.items():\nself.controller_info[name] = {\n\"name\": type(controller).__name__,\n\"start_idx\": idx,\n\"dofs\": controller.dof_idx,\n\"command_dim\": controller.command_dim,\n}\nidx += controller.command_dim\n# Other persistent variables we need to keep track of\nself.joint_names = [name for name in robot.joints.keys()]  # Ordered list of joint names belonging to the robot\nself.joint_command_idx = None   # Indices of joints being directly controlled in the action array\nself.joint_control_idx = None  # Indices of joints being directly controlled in the actual joint array\nself.active_joint_command_idx_idx = 0   # Which index within the joint_command_idx variable is being controlled by the user\nself.current_joint = -1  # Active joint being controlled for joint control\nself.ik_arms = []               # List of arm controller names to be controlled by IK\nself.active_arm_idx = 0         # Which index within self.ik_arms is actively being controlled (only relevant for IK)\nself.binary_grippers = []           # Grippers being controlled using multi-finger binary controller\nself.active_gripper_idx = 0     # Which index within self.binary_grippers is actively being controlled\nself.gripper_direction = None  # Flips between -1 and 1, per arm controlled by multi-finger binary control\nself.persistent_gripper_action = None  # Persistent gripper commands, per arm controlled by multi-finger binary control\n# i.e.: if using binary gripper control and when no keypress is active, the gripper action should still the last executed gripper action\nself.keypress_mapping = None    # Maps omni keybindings to information for controlling various parts of the robot\nself.current_keypress = None    # Current key that is being pressed\nself.active_action = None       # Current action information based on the current keypress\nself.toggling_gripper = False   # Whether we should toggle the gripper during the next action\n# Populate the keypress mapping dictionary\nself.populate_keypress_mapping()\n# Register the keyboard callback function\nself.register_keyboard_handler()\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.generate_ik_keypress_mapping","title":"<code>generate_ik_keypress_mapping(controller_info)</code>","text":"<p>Generates a dictionary for keypress mappings for IK control, based on the inputted @controller_info</p> <p>Parameters:</p> Name Type Description Default <code>controller_info</code> <code>dict</code> <p>Dictionary of controller information for the specific robot arm to control with IK</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Populated keypress mappings for IK to control the specified controller</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def generate_ik_keypress_mapping(self, controller_info):\n\"\"\"\n    Generates a dictionary for keypress mappings for IK control, based on the inputted @controller_info\n    Args:\n        controller_info (dict): Dictionary of controller information for the specific robot arm to control\n            with IK\n    Returns:\n        dict: Populated keypress mappings for IK to control the specified controller\n    \"\"\"\nmapping = {}\nmapping[carb.input.KeyboardInput.UP] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.DOWN] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.RIGHT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.LEFT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.P] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.SEMICOLON] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.N] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.B] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.O] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.U] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": -0.5}\nmapping[carb.input.KeyboardInput.V] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": 0.5}\nmapping[carb.input.KeyboardInput.C] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": -0.5}\nreturn mapping\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.get_random_action","title":"<code>get_random_action()</code>","text":"<p>Returns:</p> Type Description <p>n-array: Generated random action vector (normalized)</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def get_random_action(self):\n\"\"\"\n    Returns:\n        n-array: Generated random action vector (normalized)\n    \"\"\"\nreturn np.random.uniform(-1, 1, self.action_dim)\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.get_teleop_action","title":"<code>get_teleop_action()</code>","text":"<p>Returns:</p> Type Description <p>n-array: Generated action vector based on received user inputs from the keyboard</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def get_teleop_action(self):\n\"\"\"\n    Returns:\n        n-array: Generated action vector based on received user inputs from the keyboard\n    \"\"\"\naction = np.zeros(self.action_dim)\n# Handle the action if any key is actively being pressed\nif self.active_action is not None:\nidx, val = self.active_action[\"idx\"], self.active_action[\"val\"]\n# Only handle the action if the value is specified\nif val is not None:\n# If there is no index, the user is controlling a joint with \"[\" and \"]\"\nif idx is None and len(self.joint_command_idx) != 0:\nidx = self.joint_command_idx[self.active_joint_command_idx_idx]\n# Set the action\nif idx is not None:\naction[idx] = val\n# Possibly set the persistent gripper action\nif len(self.binary_grippers) &gt; 0 and self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] is not None:\nfor i, binary_gripper in enumerate(self.binary_grippers):\n# Possibly update the stored value if the toggle gripper key has been pressed and\n# it's the active gripper being controlled\nif self.toggling_gripper and i == self.active_gripper_idx:\n# We toggle the gripper direction or this gripper\nself.gripper_direction[binary_gripper] *= -1.0\nself.persistent_gripper_action[binary_gripper] = \\\n                    self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] * self.gripper_direction[binary_gripper]\n# Clear the toggling gripper flag\nself.toggling_gripper = False\n# Set the persistent action\naction[self.controller_info[binary_gripper][\"start_idx\"]] = self.persistent_gripper_action[binary_gripper]\n# Print out the user what is being pressed / controlled\nsys.stdout.write(\"\\033[K\")\nkeypress_str = self.current_keypress.__str__().split(\".\")[-1]\nprint(\"Pressed {}. Action: {}\".format(keypress_str, action))\nsys.stdout.write(\"\\033[F\")\n# Return action\nreturn action\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.populate_keypress_mapping","title":"<code>populate_keypress_mapping()</code>","text":"<p>Populates the mapping @self.keypress_mapping, which maps keypresses to action info:</p> <pre><code>keypress:\n    idx: &lt;int&gt;\n    val: &lt;float&gt;\n</code></pre> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def populate_keypress_mapping(self):\n\"\"\"\n    Populates the mapping @self.keypress_mapping, which maps keypresses to action info:\n        keypress:\n            idx: &lt;int&gt;\n            val: &lt;float&gt;\n    \"\"\"\nself.keypress_mapping = {}\nself.joint_command_idx = []\nself.joint_control_idx = []\nself.gripper_direction = {}\nself.persistent_gripper_action = {}\n# Add mapping for joint control directions (no index because these are inferred at runtime)\nself.keypress_mapping[carb.input.KeyboardInput.RIGHT_BRACKET] = {\"idx\": None, \"val\": 0.1}\nself.keypress_mapping[carb.input.KeyboardInput.LEFT_BRACKET] = {\"idx\": None, \"val\": -0.1}\n# Iterate over all controller info and populate mapping\nfor component, info in self.controller_info.items():\nif info[\"name\"] == \"JointController\":\nfor i in range(info[\"command_dim\"]):\ncmd_idx = info[\"start_idx\"] + i\nself.joint_command_idx.append(cmd_idx)\nself.joint_control_idx += info[\"dofs\"].tolist()\nelif info[\"name\"] == \"DifferentialDriveController\":\nself.keypress_mapping[carb.input.KeyboardInput.I] = {\"idx\": info[\"start_idx\"] + 0, \"val\": 0.4}\nself.keypress_mapping[carb.input.KeyboardInput.K] = {\"idx\": info[\"start_idx\"] + 0, \"val\": -0.4}\nself.keypress_mapping[carb.input.KeyboardInput.L] = {\"idx\": info[\"start_idx\"] + 1, \"val\": -0.2}\nself.keypress_mapping[carb.input.KeyboardInput.J] = {\"idx\": info[\"start_idx\"] + 1, \"val\": 0.2}\nelif info[\"name\"] == \"InverseKinematicsController\":\nself.ik_arms.append(component)\nself.keypress_mapping.update(self.generate_ik_keypress_mapping(controller_info=info))\nelif info[\"name\"] == \"MultiFingerGripperController\":\nif info[\"command_dim\"] &gt; 1:\nfor i in range(info[\"command_dim\"]):\ncmd_idx = info[\"start_idx\"] + i\nself.joint_command_idx.append(cmd_idx)\nself.joint_control_idx += info[\"dofs\"].tolist()\nelse:\nself.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": info[\"start_idx\"], \"val\": 1.0}\nself.gripper_direction[component] = 1.0\nself.persistent_gripper_action[component] = 1.0\nself.binary_grippers.append(component)\nelif info[\"name\"] == \"NullJointController\":\n# We won't send actions if using a null gripper controller\nself.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": None, \"val\": None}\nelse:\nraise ValueError(\"Unknown controller name received: {}\".format(info[\"name\"]))\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.print_keyboard_teleop_info","title":"<code>print_keyboard_teleop_info()</code>  <code>staticmethod</code>","text":"<p>Prints out relevant information for teleop controlling a robot</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>@staticmethod\ndef print_keyboard_teleop_info():\n\"\"\"\n    Prints out relevant information for teleop controlling a robot\n    \"\"\"\ndef print_command(char, info):\nchar += \" \" * (10 - len(char))\nprint(\"{}\\t{}\".format(char, info))\nprint()\nprint(\"*\" * 30)\nprint(\"Controlling the Robot Using the Keyboard\")\nprint(\"*\" * 30)\nprint()\nprint(\"Joint Control\")\nprint_command(\"1, 2\", \"decrement / increment the joint to control\")\nprint_command(\"[, ]\", \"move the joint backwards, forwards, respectively\")\nprint()\nprint(\"Differential Drive Control\")\nprint_command(\"i, k\", \"turn left, right\")\nprint_command(\"l, j\", \"move forward, backwards\")\nprint()\nprint(\"Inverse Kinematics Control\")\nprint_command(\"3, 4\", \"toggle between the different arm(s) to control\")\nprint_command(u\"\\u2190, \\u2192\", \"translate arm eef along x-axis\")\nprint_command(u\"\\u2191, \\u2193\", \"translate arm eef along y-axis\")\nprint_command(\"p, ;\", \"translate arm eef along z-axis\")\nprint_command(\"n, b\", \"rotate arm eef about x-axis\")\nprint_command(\"o, u\", \"rotate arm eef about y-axis\")\nprint_command(\"v, c\", \"rotate arm eef about z-axis\")\nprint()\nprint(\"Boolean Gripper Control\")\nprint_command(\"5, 6\", \"toggle between the different gripper(s) using binary control\")\nprint_command(\"t\", \"toggle gripper (open/close)\")\nprint()\nprint(\"Sensor Rendering\")\nprint_command(\"r\", \"render the onboard sensors (RGB, Depth, Normals, Instance Segmentation, Occupancy Map\")\nprint()\nprint(\"*\" * 30)\nprint()\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.register_keyboard_handler","title":"<code>register_keyboard_handler()</code>","text":"<p>Sets up the keyboard callback functionality with omniverse</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def register_keyboard_handler(self):\n\"\"\"\n    Sets up the keyboard callback functionality with omniverse\n    \"\"\"\nappwindow = omni.appwindow.get_default_app_window()\ninput_interface = carb.input.acquire_input_interface()\nkeyboard = appwindow.get_keyboard()\nsub_keyboard = input_interface.subscribe_to_keyboard_events(keyboard, self.keyboard_event_handler)\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.choose_from_options","title":"<code>choose_from_options(options, name, random_selection=False)</code>","text":"<p>Prints out options from a list, and returns the requested option.</p> <p>Parameters:</p> Name Type Description Default <code>options</code> <code>dict or list</code> <p>options to choose from. If dict, the value entries are assumed to be docstrings explaining the individual options</p> required <code>name</code> <code>str</code> <p>name of the options</p> required <code>random_selection</code> <code>bool</code> <p>if the selection is random (for automatic demo execution). Default False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Requested option</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def choose_from_options(options, name, random_selection=False):\n\"\"\"\n    Prints out options from a list, and returns the requested option.\n    Args:\n        options (dict or list): options to choose from. If dict, the value entries are assumed to be docstrings\n            explaining the individual options\n        name (str): name of the options\n        random_selection (bool): if the selection is random (for automatic demo execution). Default False\n    Returns:\n        str: Requested option\n    \"\"\"\n# Select robot\nprint(\"\\nHere is a list of available {}s:\\n\".format(name))\nfor k, option in enumerate(options):\ndocstring = \": {}\".format(options[option]) if isinstance(options, dict) else \"\"\nprint(\"[{}] {}{}\".format(k + 1, option, docstring))\nprint()\nif not random_selection:\ntry:\ns = input(\"Choose a {} (enter a number from 1 to {}): \".format(name, len(options)))\n# parse input into a number within range\nk = min(max(int(s), 1), len(options)) - 1\nexcept:\nk = 0\nprint(\"Input is not valid. Use {} by default.\".format(list(options)[k]))\nelse:\nk = random.choice(range(len(options)))\n# Return requested option\nreturn list(options)[k]\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.create_module_logger","title":"<code>create_module_logger(module_name)</code>","text":"<p>Creates and returns a logger for logging statements from the module represented by @module_name</p> <p>module_name (str): Module to create the logger for. Should be the module's <code>__name__</code> variable</p> <p>Returns:</p> Name Type Description <code>Logger</code> <p>Created logger for the module</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def create_module_logger(module_name):\n\"\"\"\n    Creates and returns a logger for logging statements from the module represented by @module_name\n    Args:\n    module_name (str): Module to create the logger for. Should be the module's `__name__` variable\n    Returns:\n        Logger: Created logger for the module\n    \"\"\"\nreturn logging.getLogger(module_name)\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.disclaimer","title":"<code>disclaimer(msg)</code>","text":"<p>Prints a disclaimer message, i.e.: \"We know this doesn't work; it's an omni issue; we expect it to be fixed in the next release!</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def disclaimer(msg):\n\"\"\"\n    Prints a disclaimer message, i.e.: \"We know this doesn't work; it's an omni issue; we expect it to be fixed in the\n    next release!\n    \"\"\"\nif gm.SHOW_DISCLAIMERS:\nprint(\"****** DISCLAIMER ******\")\nprint(\"Isaac Sim / Omniverse has some significant limitations and bugs in its current release.\")\nprint(\"This message has popped up because a potential feature in OmniGibson relies upon a feature in Omniverse that \"\n\"is yet to be released publically. Currently, the expected behavior may not be fully functional, but \"\n\"should be resolved by the next Isaac Sim release.\")\nprint(f\"Exact Limitation: {msg}\")\nprint(\"************************\")\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.dock_window","title":"<code>dock_window(space, name, location, ratio=0.5)</code>","text":"<p>Method for docking a specific GUI window in a specified location within the workspace</p> <p>Parameters:</p> Name Type Description Default <code>space</code> <code>WindowHandle</code> <p>Handle to the docking space to dock the window specified by @name</p> required <code>name</code> <code>str</code> <p>Name of a window to dock</p> required <code>location</code> <code>omni.ui.DockPosition</code> <p>docking position for placing the window specified by @name</p> required <code>ratio</code> <code>float</code> <p>Ratio when splitting the docking space between the pre-existing and newly added window</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>WindowHandle</code> <p>Handle to the docking space that the window specified by @name was placed in</p> Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>def dock_window(space, name, location, ratio=0.5):\n\"\"\"\n    Method for docking a specific GUI window in a specified location within the workspace\n    Args:\n        space (WindowHandle): Handle to the docking space to dock the window specified by @name\n        name (str): Name of a window to dock\n        location (omni.ui.DockPosition): docking position for placing the window specified by @name\n        ratio (float): Ratio when splitting the docking space between the pre-existing and newly added window\n    Returns:\n        WindowHandle: Handle to the docking space that the window specified by @name was placed in\n    \"\"\"\nwindow = omni.ui.Workspace.get_window(name)\nif window and space:\nwindow.dock_in(space, location, ratio=ratio)\nreturn window\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.suppress_loggers","title":"<code>suppress_loggers(logger_names)</code>","text":"<p>A context scope for temporarily suppressing logging for certain omni channels.</p> <p>Parameters:</p> Name Type Description Default <code>logger_names</code> <code>list of str</code> <p>Logger name(s) whose corresponding loggers should be suppressed</p> required Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>@contextlib.contextmanager\ndef suppress_loggers(logger_names):\n\"\"\"\n    A context scope for temporarily suppressing logging for certain omni channels.\n    Args:\n        logger_names (list of str): Logger name(s) whose corresponding loggers should be suppressed\n    \"\"\"\nif not gm.DEBUG:\n# Store prior states so we can restore them after this context exits\nlogger_levels = {name: logging.getLogger(name).getEffectiveLevel() for name in logger_names}\n# Suppress the loggers (only output fatal messages)\nfor name in logger_names:\nlogging.getLogger(name).setLevel(logging.FATAL)\nyield\nif not gm.DEBUG:\n# Unsuppress the loggers\nfor name in logger_names:\nlogging.getLogger(name).setLevel(logger_levels[name])\n</code></pre>"},{"location":"reference/utils/ui_utils.html#utils.ui_utils.suppress_omni_log","title":"<code>suppress_omni_log(channels)</code>","text":"<p>A context scope for temporarily suppressing logging for certain omni channels.</p> <p>Parameters:</p> Name Type Description Default <code>channels</code> <code>None or list of str</code> <p>Logging channel(s) to suppress. If None, will globally disable logger</p> required Source code in <code>omnigibson/utils/ui_utils.py</code> <pre><code>@contextlib.contextmanager\ndef suppress_omni_log(channels):\n\"\"\"\n    A context scope for temporarily suppressing logging for certain omni channels.\n    Args:\n        channels (None or list of str): Logging channel(s) to suppress. If None, will globally disable logger\n    \"\"\"\n# Record the state to restore to after the context exists\nlog = omni.log.get_log()\nif gm.DEBUG:\n# Do nothing\npass\nelif channels is None:\n# Globally disable log\nlog.enabled = False\nelse:\n# For some reason, all enabled states always return False even if the logging is clearly enabled for the\n# given channel, so we assume all channels are enabled\n# We do, however, check what behavior was assigned to this channel, since we force an override during this context\nchannel_behavior = {channel: log.get_channel_enabled(channel)[2] for channel in channels}\n# Suppress the channels\nfor channel in channels:\nlog.set_channel_enabled(channel, False, omni.log.SettingBehavior.OVERRIDE)\nyield\nif gm.DEBUG:\n# Do nothing\npass\nelif channels is None:\n# Globally re-enable log\nlog.enabled = True\nelse:\n# Unsuppress the channels\nfor channel in channels:\nlog.set_channel_enabled(channel, True, channel_behavior[channel])\n</code></pre>"},{"location":"reference/utils/usd_utils.html","title":"usd_utils","text":""},{"location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI","title":"<code>BoundingBoxAPI</code>","text":"<p>Class containing class methods to facilitate bounding box handling</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>class BoundingBoxAPI:\n\"\"\"\n    Class containing class methods to facilitate bounding box handling\n    \"\"\"\n# Non-flatcache-compatible cache -- this is a direct omni API-based object\nCACHE_NON_FLATCACHE = None\n# Flatcache-compatible cache -- this is a dictionary mapping prim paths to corresponding AABBs\nCACHE_FLATCACHE = dict()\n@classmethod\ndef compute_aabb(cls, prim):\n\"\"\"\n        Computes the AABB (world-frame oriented) for @prim.\n        NOTE: If @prim is an EntityPrim (i.e.: owns multiple links), then the computed bounding box will be\n        the subsequent aggregate over all the links.\n        Args:\n            prim (XFormPrim): Prim to calculate AABB for\n        Returns:\n            2-tuple:\n                - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n                - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n        \"\"\"\n# Use the correct API to calculate AABB based on whether flatcache is enabled or not\nreturn cls._compute_flatcache_aabb(prim=prim) if gm.ENABLE_FLATCACHE else \\\n            cls._compute_non_flatcache_aabb(prim_path=prim.prim_path)\n@classmethod\ndef _compute_flatcache_aabb(cls, prim):\n\"\"\"\n        Computes the AABB (world-frame oriented) for @prim. This an API compatible with flatcache, which manually\n        updates the @prim's transforms on the USD stage before computing its AABB\n        Args:\n            prim (XFormPrim): Prim to calculate AABB for\n        Returns:\n            2-tuple:\n                - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n                - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n        \"\"\"\n# Run imports here to avoid circular imports\nfrom omnigibson.prims import EntityPrim, RigidPrim, XFormPrim\n# Simply grab the AABB if it's already been cached\nif prim in cls.CACHE_FLATCACHE:\nreturn cls.CACHE_FLATCACHE[prim]\n# Next, process the AABB depending on the type of prim it is\nif isinstance(prim, EntityPrim):\nobj = prim\nelif isinstance(prim, RigidPrim):\n# Find the obj owning this link\nobj = og.sim.scene.object_registry(\"prim_path\", \"/\".join(prim.prim_path.split(\"/\")[:-1]))\nelif isinstance(prim, XFormPrim):\n# See if this XForm belongs to any object\nobj = og.sim.scene.object_registry(\"prim_path\", \"/\".join(prim.prim_path.split(\"/\")[:2]), None)\nelse:\nraise ValueError(f\"Inputted prim must be an instance of EntityPrim, RigidPrim, or XFormPrim \"\nf\"in order to calculate AABB!\")\n# Update tfs for the object that owns this prim\nif obj is not None:\nFlatcacheAPI.sync_raw_object_transforms_in_usd(prim=obj)\n# Compute the AABB and cache it internally\nval = cls._compute_non_flatcache_aabb(prim_path=prim.prim_path)\ncls.CACHE_FLATCACHE[prim] = val\nreturn val\n@classmethod\ndef _compute_non_flatcache_aabb(cls, prim_path):\n\"\"\"\n        Computes the AABB (world-frame oriented) for the prim specified at @prim_path using the underlying omniverse\n        API.\n        NOTE: This is NOT compatible with flatcache and will result in incorrect values if flatcache is enabled!! See:\n        https://docs.omniverse.nvidia.com/app_code/prod_extensions/ext_physics.html#physx-short-flatcache-also-known-as-fabric-rename-in-next-release\n        Args:\n            prim_path (str): Path to the prim to calculate AABB for\n        Returns:\n            2-tuple:\n                - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n                - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n        \"\"\"\n# Create cache if it doesn't already exist\nif cls.CACHE_NON_FLATCACHE is None:\ncls.CACHE_NON_FLATCACHE = create_bbox_cache(use_extents_hint=False)\n# Grab aabb\naabb = compute_aabb(bbox_cache=cls.CACHE_NON_FLATCACHE, prim_path=prim_path)\n# Sanity check values\nif np.any(aabb[3:] &lt; aabb[:3]):\nraise ValueError(f\"Got invalid aabb values: low={aabb[:3]}, high={aabb[3:]}\")\nreturn aabb[:3], aabb[3:]\n@classmethod\ndef compute_center_extent(cls, prim):\n\"\"\"\n        Computes the AABB (world-frame oriented) for @prim, and convert it into the center and extent values\n        Args:\n            prim (XFormPrim): Prim to calculate AABB for\n        Returns:\n            2-tuple:\n                - 3-array: center position (x,y,z) of world-coordinate frame aligned bounding box\n                - 3-array: end-to-end extent size (x,y,z) of world-coordinate frame aligned bounding box\n        \"\"\"\nlow, high = cls.compute_aabb(prim=prim)\nreturn (low + high) / 2.0, high - low\n@classmethod\ndef clear(cls):\n\"\"\"\n        Clears the internal state of this BoundingBoxAPI. This should occur at least once per sim step.\n        \"\"\"\ncls.CACHE_NON_FLATCACHE = None\ncls.CACHE_FLATCACHE = dict()\n@classmethod\ndef aabb_contains_point(cls, point, container):\n\"\"\"\n        Returns true if the point is contained in the container AABB\n        Args:\n            point (tuple): (x,y,z) position in world-coordinates\n            container (tuple):\n                - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n                - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n        Returns:\n            bool: True if AABB contains @point, otherwise False\n        \"\"\"\nlower, upper = container\nreturn np.less_equal(lower, point).all() and np.less_equal(point, upper).all()\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.aabb_contains_point","title":"<code>aabb_contains_point(point, container)</code>  <code>classmethod</code>","text":"<p>Returns true if the point is contained in the container AABB</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>tuple</code> <p>(x,y,z) position in world-coordinates</p> required <code>container</code> <code>tuple</code> <ul> <li>3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box</li> <li>3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box</li> </ul> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if AABB contains @point, otherwise False</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef aabb_contains_point(cls, point, container):\n\"\"\"\n    Returns true if the point is contained in the container AABB\n    Args:\n        point (tuple): (x,y,z) position in world-coordinates\n        container (tuple):\n            - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n            - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n    Returns:\n        bool: True if AABB contains @point, otherwise False\n    \"\"\"\nlower, upper = container\nreturn np.less_equal(lower, point).all() and np.less_equal(point, upper).all()\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.clear","title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clears the internal state of this BoundingBoxAPI. This should occur at least once per sim step.</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef clear(cls):\n\"\"\"\n    Clears the internal state of this BoundingBoxAPI. This should occur at least once per sim step.\n    \"\"\"\ncls.CACHE_NON_FLATCACHE = None\ncls.CACHE_FLATCACHE = dict()\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.compute_aabb","title":"<code>compute_aabb(prim)</code>  <code>classmethod</code>","text":"<p>Computes the AABB (world-frame oriented) for @prim.</p> <p>NOTE: If @prim is an EntityPrim (i.e.: owns multiple links), then the computed bounding box will be the subsequent aggregate over all the links.</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>XFormPrim</code> <p>Prim to calculate AABB for</p> required <p>Returns:</p> Type Description <p>2-tuple: - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef compute_aabb(cls, prim):\n\"\"\"\n    Computes the AABB (world-frame oriented) for @prim.\n    NOTE: If @prim is an EntityPrim (i.e.: owns multiple links), then the computed bounding box will be\n    the subsequent aggregate over all the links.\n    Args:\n        prim (XFormPrim): Prim to calculate AABB for\n    Returns:\n        2-tuple:\n            - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n            - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n    \"\"\"\n# Use the correct API to calculate AABB based on whether flatcache is enabled or not\nreturn cls._compute_flatcache_aabb(prim=prim) if gm.ENABLE_FLATCACHE else \\\n        cls._compute_non_flatcache_aabb(prim_path=prim.prim_path)\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.compute_center_extent","title":"<code>compute_center_extent(prim)</code>  <code>classmethod</code>","text":"<p>Computes the AABB (world-frame oriented) for @prim, and convert it into the center and extent values</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>XFormPrim</code> <p>Prim to calculate AABB for</p> required <p>Returns:</p> Type Description <p>2-tuple: - 3-array: center position (x,y,z) of world-coordinate frame aligned bounding box - 3-array: end-to-end extent size (x,y,z) of world-coordinate frame aligned bounding box</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef compute_center_extent(cls, prim):\n\"\"\"\n    Computes the AABB (world-frame oriented) for @prim, and convert it into the center and extent values\n    Args:\n        prim (XFormPrim): Prim to calculate AABB for\n    Returns:\n        2-tuple:\n            - 3-array: center position (x,y,z) of world-coordinate frame aligned bounding box\n            - 3-array: end-to-end extent size (x,y,z) of world-coordinate frame aligned bounding box\n    \"\"\"\nlow, high = cls.compute_aabb(prim=prim)\nreturn (low + high) / 2.0, high - low\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.CollisionAPI","title":"<code>CollisionAPI</code>","text":"<p>Class containing class methods to facilitate collision handling, e.g. collision groups</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>class CollisionAPI:\n\"\"\"\n    Class containing class methods to facilitate collision handling, e.g. collision groups\n    \"\"\"\nACTIVE_COLLISION_GROUPS = {}\n@classmethod\ndef add_to_collision_group(cls, col_group, prim_path, create_if_not_exist=False):\n\"\"\"\n        Adds the prim and all nested prims specified by @prim_path to the global collision group @col_group. If @col_group\n        does not exist, then it will either be created if @create_if_not_exist is True, otherwise will raise an Error.\n        Args:\n            col_group (str): Name of the collision group to assign the prim at @prim_path to\n            prim_path (str): Prim (and all nested prims) to assign to this @col_group\n            create_if_not_exist (bool): True if @col_group should be created if it does not already exist, otherwise an\n                error will be raised\n        \"\"\"\n# TODO: This slows things down and / or crashes the sim with large number of objects. Skipping this for now, look into this later\npass\n# # Check if collision group exists or not\n# if col_group not in cls.ACTIVE_COLLISION_GROUPS:\n#     # Raise error if we don't explicitly want to create a new group\n#     if not create_if_not_exist:\n#         raise ValueError(f\"Collision group {col_group} not found in current registry, and create_if_not_exist\"\n#                          f\"was set to False!\")\n#     # Otherwise, create the new group\n#     col_group_name = f\"/World/collisionGroup_{col_group}\"\n#     group = UsdPhysics.CollisionGroup.Define(get_current_stage(), col_group_name)\n#     group.GetFilteredGroupsRel().AddTarget(col_group_name)  # Make sure that we can collide within our own group\n#     cls.ACTIVE_COLLISION_GROUPS[col_group] = group\n#\n# # Add this prim to the collision group\n# cls.ACTIVE_COLLISION_GROUPS[col_group].GetCollidersCollectionAPI().GetIncludesRel().AddTarget(prim_path)\n@classmethod\ndef clear(cls):\n\"\"\"\n        Clears the internal state of this CollisionAPI\n        \"\"\"\ncls.ACTIVE_COLLISION_GROUPS = {}\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.CollisionAPI.add_to_collision_group","title":"<code>add_to_collision_group(col_group, prim_path, create_if_not_exist=False)</code>  <code>classmethod</code>","text":"<p>Adds the prim and all nested prims specified by @prim_path to the global collision group @col_group. If @col_group does not exist, then it will either be created if @create_if_not_exist is True, otherwise will raise an Error.</p> <p>Parameters:</p> Name Type Description Default <code>col_group</code> <code>str</code> <p>Name of the collision group to assign the prim at @prim_path to</p> required <code>prim_path</code> <code>str</code> <p>Prim (and all nested prims) to assign to this @col_group</p> required <code>create_if_not_exist</code> <code>bool</code> <p>True if @col_group should be created if it does not already exist, otherwise an error will be raised</p> <code>False</code> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef add_to_collision_group(cls, col_group, prim_path, create_if_not_exist=False):\n\"\"\"\n    Adds the prim and all nested prims specified by @prim_path to the global collision group @col_group. If @col_group\n    does not exist, then it will either be created if @create_if_not_exist is True, otherwise will raise an Error.\n    Args:\n        col_group (str): Name of the collision group to assign the prim at @prim_path to\n        prim_path (str): Prim (and all nested prims) to assign to this @col_group\n        create_if_not_exist (bool): True if @col_group should be created if it does not already exist, otherwise an\n            error will be raised\n    \"\"\"\n# TODO: This slows things down and / or crashes the sim with large number of objects. Skipping this for now, look into this later\npass\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.CollisionAPI.clear","title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clears the internal state of this CollisionAPI</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef clear(cls):\n\"\"\"\n    Clears the internal state of this CollisionAPI\n    \"\"\"\ncls.ACTIVE_COLLISION_GROUPS = {}\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.FlatcacheAPI","title":"<code>FlatcacheAPI</code>","text":"<p>Monolithic class for leveraging functionality meant to be used EXCLUSIVELY with flatcache.</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>class FlatcacheAPI:\n\"\"\"\n    Monolithic class for leveraging functionality meant to be used EXCLUSIVELY with flatcache.\n    \"\"\"\n# Modified prims since transition from sim being stopped to sim being played occurred\n# This should get cleared every time og.sim.stop() gets called\nMODIFIED_PRIMS = set()\n@classmethod\ndef sync_raw_object_transforms_in_usd(cls, prim):\n\"\"\"\n        Manually synchronizes the per-link local raw transforms per-joint raw states from entity prim @prim using\n        dynamic control interface as the ground truth.\n        NOTE: This slightly abuses the dynamic control - usd integration, and should ONLY be used if flatcache\n        is active, since the USD is not R/W at runtime and so we can write directly to child link poses on the USD\n        without breaking the simulation!\n        Args:\n            prim (EntityPrim): prim whose owned links and joints should have their raw local states updated to match the\n                \"true\" values found from the dynamic control interface\n        \"\"\"\n# Make sure flatcache is enabled -- this should NEVER be called otherwise!!\nassert gm.ENABLE_FLATCACHE, \"Syncing raw object transforms should only occur if flatcache is being used!\"\n# We're somewhat abusing low-level dynamic control - physx - usd integration, but we (supposedly) know\n# what we're doing so we suppress logging so we don't see any error messages :D\nwith suppress_omni_log([\"omni.physx.plugin\"]):\n# Import here to avoid circular imports\nfrom omnigibson.prims.xform_prim import XFormPrim\n# 1. For every link, update its xformOp properties based on the delta_tf between object frame and link frame\nobj_pos, obj_quat = XFormPrim.get_local_pose(prim)\nfor link in prim.links.values():\nrel_pos, rel_quat = T.relative_pose_transform(*link.get_position_orientation(), obj_pos, obj_quat)\nXFormPrim.set_local_pose(link, rel_pos, rel_quat)\n# 2. For every joint, update its linear / angular joint state\nif prim.n_joints &gt; 0:\njoints_pos = prim.get_joint_positions()\nfor joint, joint_pos in zip(prim.joints.values(), joints_pos):\nstate_name = \"linear\" if joint.joint_type == JointType.JOINT_PRISMATIC else \"angular\"\njoint_pos = joint_pos if joint.joint_type == JointType.JOINT_PRISMATIC else joint_pos * 180.0 / np.pi\njoint.set_attribute(f\"state:{state_name}:physics:position\", float(joint_pos))\n# Update the simulation without taking any time\n# This is needed because physx complains that we're manually writing to child links' poses, and will\n# subsequently not respect any additional writes to the object pose before an additional step is taken.\n# So we take a \"zero\" length step so that any additional writes to the object's pose at the current\n# timestep are respected\nog.sim.pi.update_simulation(elapsedStep=0, currentTime=og.sim.current_time)\n# Add this prim to the set of modified prims\ncls.MODIFIED_PRIMS.add(prim)\n@classmethod\ndef reset_raw_object_transforms_in_usd(cls, prim):\n\"\"\"\n        Manually resets the per-link local raw transforms and per-joint raw states from entity prim @prim to be zero.\n        NOTE: This slightly abuses the dynamic control - usd integration, and should ONLY be used if flatcache\n        is active, since the USD is not R/W at runtime and so we can write directly to child link poses on the USD\n        without breaking the simulation!\n        Args:\n            prim (EntityPrim): prim whose owned links and joints should have their local values reset to be zero\n        \"\"\"\n# Make sure flatcache is enabled -- this should NEVER be called otherwise!!\nassert gm.ENABLE_FLATCACHE, \"Resetting raw object transforms should only occur if flatcache is being used!\"\n# We're somewhat abusing low-level dynamic control - physx - usd integration, but we (supposedly) know\n# what we're doing so we suppress logging so we don't see any error messages :D\nwith suppress_omni_log([\"omni.physx.plugin\"]):\n# Import here to avoid circular imports\nfrom omnigibson.prims.xform_prim import XFormPrim\n# 1. For every link, update its xformOp properties to be 0\nfor link in prim.links.values():\nXFormPrim.set_local_pose(link, np.zeros(3), np.array([0, 0, 0, 1.0]))\n# 2. For every joint, update its linear / angular joint state to be 0\nif prim.n_joints &gt; 0:\nfor joint in prim.joints.values():\nstate_name = \"linear\" if joint.joint_type == JointType.JOINT_PRISMATIC else \"angular\"\njoint.set_attribute(f\"state:{state_name}:physics:position\", 0.0)\n# Update the simulation without taking any time\n# This is needed because physx complains that we're manually writing to child links' poses, and will\n# subsequently not respect any additional writes to the object pose before an additional step is taken.\n# So we take a \"zero\" length step so that any additional writes to the object's pose at the current\n# timestep are respected\nog.sim.pi.update_simulation(elapsedStep=0, currentTime=og.sim.current_time)\n@classmethod\ndef reset(cls):\n\"\"\"\n        Resets the internal state of this FlatcacheAPI.This should only occur when the simulator is stopped\n        \"\"\"\n# For any prim transforms that were manually updated, we need to restore their original transforms\nfor prim in cls.MODIFIED_PRIMS:\ncls.reset_raw_object_transforms_in_usd(prim)\ncls.FLATCACHE_MODIFIED_PRIMS = set()\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.FlatcacheAPI.reset","title":"<code>reset()</code>  <code>classmethod</code>","text":"<p>Resets the internal state of this FlatcacheAPI.This should only occur when the simulator is stopped</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef reset(cls):\n\"\"\"\n    Resets the internal state of this FlatcacheAPI.This should only occur when the simulator is stopped\n    \"\"\"\n# For any prim transforms that were manually updated, we need to restore their original transforms\nfor prim in cls.MODIFIED_PRIMS:\ncls.reset_raw_object_transforms_in_usd(prim)\ncls.FLATCACHE_MODIFIED_PRIMS = set()\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.FlatcacheAPI.reset_raw_object_transforms_in_usd","title":"<code>reset_raw_object_transforms_in_usd(prim)</code>  <code>classmethod</code>","text":"<p>Manually resets the per-link local raw transforms and per-joint raw states from entity prim @prim to be zero.</p> <p>NOTE: This slightly abuses the dynamic control - usd integration, and should ONLY be used if flatcache is active, since the USD is not R/W at runtime and so we can write directly to child link poses on the USD without breaking the simulation!</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>EntityPrim</code> <p>prim whose owned links and joints should have their local values reset to be zero</p> required Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef reset_raw_object_transforms_in_usd(cls, prim):\n\"\"\"\n    Manually resets the per-link local raw transforms and per-joint raw states from entity prim @prim to be zero.\n    NOTE: This slightly abuses the dynamic control - usd integration, and should ONLY be used if flatcache\n    is active, since the USD is not R/W at runtime and so we can write directly to child link poses on the USD\n    without breaking the simulation!\n    Args:\n        prim (EntityPrim): prim whose owned links and joints should have their local values reset to be zero\n    \"\"\"\n# Make sure flatcache is enabled -- this should NEVER be called otherwise!!\nassert gm.ENABLE_FLATCACHE, \"Resetting raw object transforms should only occur if flatcache is being used!\"\n# We're somewhat abusing low-level dynamic control - physx - usd integration, but we (supposedly) know\n# what we're doing so we suppress logging so we don't see any error messages :D\nwith suppress_omni_log([\"omni.physx.plugin\"]):\n# Import here to avoid circular imports\nfrom omnigibson.prims.xform_prim import XFormPrim\n# 1. For every link, update its xformOp properties to be 0\nfor link in prim.links.values():\nXFormPrim.set_local_pose(link, np.zeros(3), np.array([0, 0, 0, 1.0]))\n# 2. For every joint, update its linear / angular joint state to be 0\nif prim.n_joints &gt; 0:\nfor joint in prim.joints.values():\nstate_name = \"linear\" if joint.joint_type == JointType.JOINT_PRISMATIC else \"angular\"\njoint.set_attribute(f\"state:{state_name}:physics:position\", 0.0)\n# Update the simulation without taking any time\n# This is needed because physx complains that we're manually writing to child links' poses, and will\n# subsequently not respect any additional writes to the object pose before an additional step is taken.\n# So we take a \"zero\" length step so that any additional writes to the object's pose at the current\n# timestep are respected\nog.sim.pi.update_simulation(elapsedStep=0, currentTime=og.sim.current_time)\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.FlatcacheAPI.sync_raw_object_transforms_in_usd","title":"<code>sync_raw_object_transforms_in_usd(prim)</code>  <code>classmethod</code>","text":"<p>Manually synchronizes the per-link local raw transforms per-joint raw states from entity prim @prim using dynamic control interface as the ground truth.</p> <p>NOTE: This slightly abuses the dynamic control - usd integration, and should ONLY be used if flatcache is active, since the USD is not R/W at runtime and so we can write directly to child link poses on the USD without breaking the simulation!</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>EntityPrim</code> <p>prim whose owned links and joints should have their raw local states updated to match the \"true\" values found from the dynamic control interface</p> required Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>@classmethod\ndef sync_raw_object_transforms_in_usd(cls, prim):\n\"\"\"\n    Manually synchronizes the per-link local raw transforms per-joint raw states from entity prim @prim using\n    dynamic control interface as the ground truth.\n    NOTE: This slightly abuses the dynamic control - usd integration, and should ONLY be used if flatcache\n    is active, since the USD is not R/W at runtime and so we can write directly to child link poses on the USD\n    without breaking the simulation!\n    Args:\n        prim (EntityPrim): prim whose owned links and joints should have their raw local states updated to match the\n            \"true\" values found from the dynamic control interface\n    \"\"\"\n# Make sure flatcache is enabled -- this should NEVER be called otherwise!!\nassert gm.ENABLE_FLATCACHE, \"Syncing raw object transforms should only occur if flatcache is being used!\"\n# We're somewhat abusing low-level dynamic control - physx - usd integration, but we (supposedly) know\n# what we're doing so we suppress logging so we don't see any error messages :D\nwith suppress_omni_log([\"omni.physx.plugin\"]):\n# Import here to avoid circular imports\nfrom omnigibson.prims.xform_prim import XFormPrim\n# 1. For every link, update its xformOp properties based on the delta_tf between object frame and link frame\nobj_pos, obj_quat = XFormPrim.get_local_pose(prim)\nfor link in prim.links.values():\nrel_pos, rel_quat = T.relative_pose_transform(*link.get_position_orientation(), obj_pos, obj_quat)\nXFormPrim.set_local_pose(link, rel_pos, rel_quat)\n# 2. For every joint, update its linear / angular joint state\nif prim.n_joints &gt; 0:\njoints_pos = prim.get_joint_positions()\nfor joint, joint_pos in zip(prim.joints.values(), joints_pos):\nstate_name = \"linear\" if joint.joint_type == JointType.JOINT_PRISMATIC else \"angular\"\njoint_pos = joint_pos if joint.joint_type == JointType.JOINT_PRISMATIC else joint_pos * 180.0 / np.pi\njoint.set_attribute(f\"state:{state_name}:physics:position\", float(joint_pos))\n# Update the simulation without taking any time\n# This is needed because physx complains that we're manually writing to child links' poses, and will\n# subsequently not respect any additional writes to the object pose before an additional step is taken.\n# So we take a \"zero\" length step so that any additional writes to the object's pose at the current\n# timestep are respected\nog.sim.pi.update_simulation(elapsedStep=0, currentTime=og.sim.current_time)\n# Add this prim to the set of modified prims\ncls.MODIFIED_PRIMS.add(prim)\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.add_asset_to_stage","title":"<code>add_asset_to_stage(asset_path, prim_path)</code>","text":"<p>Adds asset file (either USD or OBJ) at @asset_path at the location @prim_path</p> <p>Parameters:</p> Name Type Description Default <code>asset_path</code> <code>str</code> <p>Absolute or relative path to the asset file to load</p> required <code>prim_path</code> <code>str</code> <p>Where loaded asset should exist on the stage</p> required <p>Returns:</p> Type Description <p>Usd.Prim: Loaded prim as a USD prim</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def add_asset_to_stage(asset_path, prim_path):\n\"\"\"\n    Adds asset file (either USD or OBJ) at @asset_path at the location @prim_path\n    Args:\n        asset_path (str): Absolute or relative path to the asset file to load\n        prim_path (str): Where loaded asset should exist on the stage\n    Returns:\n        Usd.Prim: Loaded prim as a USD prim\n    \"\"\"\n# Make sure this is actually a supported asset type\nassert asset_path[-4:].lower() in {\".usd\", \".obj\"}, f\"Cannot load a non-USD or non-OBJ file as a USD prim!\"\nasset_type = asset_path[-3:]\n# Make sure the path exists\nassert os.path.exists(asset_path), f\"Cannot load {asset_type.upper()} file {asset_path} because it does not exist!\"\n# Add reference to stage and grab prim\nadd_reference_to_stage(usd_path=asset_path, prim_path=prim_path)\nprim = get_prim_at_path(prim_path)\n# Make sure prim was loaded correctly\nassert prim, f\"Failed to load {asset_type.upper()} object from path: {asset_path}\"\nreturn prim\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.array_to_vtarray","title":"<code>array_to_vtarray(arr, element_type)</code>","text":"<p>Converts array @arr into a Vt-typed array, where each individual element of type @element_type.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>n-array</code> <p>An array of values. Can be, e.g., a list, or numpy array</p> required <code>element_type</code> <code>type</code> <p>Per-element type to convert the elements from @arr into. Valid options are keys of GF_TO_VT_MAPPING</p> required <p>Returns:</p> Type Description <p>Vt.Array: Vt-typed array, of specified type corresponding to @element_type</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def array_to_vtarray(arr, element_type):\n\"\"\"\n    Converts array @arr into a Vt-typed array, where each individual element of type @element_type.\n    Args:\n        arr (n-array): An array of values. Can be, e.g., a list, or numpy array\n        element_type (type): Per-element type to convert the elements from @arr into.\n            Valid options are keys of GF_TO_VT_MAPPING\n    Returns:\n        Vt.Array: Vt-typed array, of specified type corresponding to @element_type\n    \"\"\"\n# Make sure array type is valid\nassert_valid_key(key=element_type, valid_keys=GF_TO_VT_MAPPING, name=\"array element type\")\n# Construct list of values\narr_list = []\n# Check first to see if elements are vectors or not. If this is an iterable value that is not a string,\n# then this is a vector and we have to map it to the correct type via *\nis_vec_element = (isinstance(arr[0], Iterable)) and (not isinstance(arr[0], str))\n# Loop over array and set values\nfor ele in arr:\narr_list.append(element_type(*ele) if is_vec_element else ele)\nreturn GF_TO_VT_MAPPING[element_type](arr_list)\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.clear","title":"<code>clear()</code>","text":"<p>Clear state tied to singleton classes</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def clear():\n\"\"\"\n    Clear state tied to singleton classes\n    \"\"\"\nCollisionAPI.clear()\nBoundingBoxAPI.clear()\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.create_joint","title":"<code>create_joint(prim_path, joint_type, body0=None, body1=None, enabled=True, joint_frame_in_parent_frame_pos=None, joint_frame_in_parent_frame_quat=None, joint_frame_in_child_frame_pos=None, joint_frame_in_child_frame_quat=None, break_force=None, break_torque=None)</code>","text":"<p>Creates a joint between @body0 and @body1 of specified type @joint_type</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>absolute path to where the joint will be created</p> required <code>joint_type</code> <code>str</code> <p>type of joint to create. Valid options are: \"FixedJoint\", \"Joint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"             (equivalently, one of JointType)</p> required <code>body0</code> <code>str or None</code> <p>absolute path to the first body's prim. At least @body0 or @body1 must be specified.</p> <code>None</code> <code>body1</code> <code>str or None</code> <p>absolute path to the second body's prim. At least @body0 or @body1 must be specified.</p> <code>None</code> <code>enabled</code> <code>bool</code> <p>whether to enable this joint or not.</p> <code>True</code> <code>joint_frame_in_parent_frame_pos</code> <code>np.ndarray or None</code> <p>relative position of the joint frame to the parent frame (body0).</p> <code>None</code> <code>joint_frame_in_parent_frame_quat</code> <code>np.ndarray or None</code> <p>relative orientation of the joint frame to the parent frame (body0).</p> <code>None</code> <code>joint_frame_in_child_frame_pos</code> <code>np.ndarray or None</code> <p>relative position of the joint frame to the child frame (body1).</p> <code>None</code> <code>joint_frame_in_child_frame_quat</code> <code>np.ndarray or None</code> <p>relative orientation of the joint frame to the child frame (body1).</p> <code>None</code> <code>break_force</code> <code>float or None</code> <p>break force for linear dofs, unit is Newton.</p> <code>None</code> <code>break_torque</code> <code>float or None</code> <p>break torque for angular dofs, unit is Newton-meter.</p> <code>None</code> <p>Returns:</p> Type Description <p>Usd.Prim: Created joint prim</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def create_joint(prim_path, joint_type, body0=None, body1=None, enabled=True,\njoint_frame_in_parent_frame_pos=None, joint_frame_in_parent_frame_quat=None,\njoint_frame_in_child_frame_pos=None, joint_frame_in_child_frame_quat=None,\nbreak_force=None, break_torque=None):\n\"\"\"\n    Creates a joint between @body0 and @body1 of specified type @joint_type\n    Args:\n        prim_path (str): absolute path to where the joint will be created\n        joint_type (str): type of joint to create. Valid options are:\n            \"FixedJoint\", \"Joint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"\n                        (equivalently, one of JointType)\n        body0 (str or None): absolute path to the first body's prim. At least @body0 or @body1 must be specified.\n        body1 (str or None): absolute path to the second body's prim. At least @body0 or @body1 must be specified.\n        enabled (bool): whether to enable this joint or not.\n        joint_frame_in_parent_frame_pos (np.ndarray or None): relative position of the joint frame to the parent frame (body0).\n        joint_frame_in_parent_frame_quat (np.ndarray or None): relative orientation of the joint frame to the parent frame (body0).\n        joint_frame_in_child_frame_pos (np.ndarray or None): relative position of the joint frame to the child frame (body1).\n        joint_frame_in_child_frame_quat (np.ndarray or None): relative orientation of the joint frame to the child frame (body1).\n        break_force (float or None): break force for linear dofs, unit is Newton.\n        break_torque (float or None): break torque for angular dofs, unit is Newton-meter.\n    Returns:\n        Usd.Prim: Created joint prim\n    \"\"\"\n# Make sure we have valid joint_type\nassert JointType.is_valid(joint_type=joint_type), \\\n        f\"Invalid joint specified for creation: {joint_type}\"\n# Make sure at least body0 or body1 is specified\nassert body0 is not None or body1 is not None, \\\n        f\"At least either body0 or body1 must be specified when creating a joint!\"\n# Create the joint\njoint = UsdPhysics.__dict__[joint_type].Define(og.sim.stage, prim_path)\n# Possibly add body0, body1 targets\nif body0 is not None:\nassert is_prim_path_valid(body0), f\"Invalid body0 path specified: {body0}\"\njoint.GetBody0Rel().SetTargets([Sdf.Path(body0)])\nif body1 is not None:\nassert is_prim_path_valid(body1), f\"Invalid body1 path specified: {body1}\"\njoint.GetBody1Rel().SetTargets([Sdf.Path(body1)])\n# Get the prim pointed to at this path\njoint_prim = get_prim_at_path(prim_path)\n# Apply joint API interface\nPhysxSchema.PhysxJointAPI.Apply(joint_prim)\n# We need to step rendering once to auto-fill the local pose before overwriting it.\n# Note that for some reason, if multi_gpu is used, this line will crash if create_joint is called during on_contact\n# callback, e.g. when an attachment joint is being created due to contacts.\nog.sim.render()\nif joint_frame_in_parent_frame_pos is not None:\njoint_prim.GetAttribute(\"physics:localPos0\").Set(Gf.Vec3f(*joint_frame_in_parent_frame_pos))\nif joint_frame_in_parent_frame_quat is not None:\njoint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*joint_frame_in_parent_frame_quat[[3, 0, 1, 2]]))\nif joint_frame_in_child_frame_pos is not None:\njoint_prim.GetAttribute(\"physics:localPos1\").Set(Gf.Vec3f(*joint_frame_in_child_frame_pos))\nif joint_frame_in_child_frame_quat is not None:\njoint_prim.GetAttribute(\"physics:localRot1\").Set(Gf.Quatf(*joint_frame_in_child_frame_quat[[3, 0, 1, 2]]))\nif break_force is not None:\njoint_prim.GetAttribute(\"physics:breakForce\").Set(break_force)\nif break_torque is not None:\njoint_prim.GetAttribute(\"physics:breakTorque\").Set(break_torque)\n# Possibly (un-/)enable this joint\njoint_prim.GetAttribute(\"physics:jointEnabled\").Set(enabled)\n# We update the simulation now without stepping physics if sim is playing so we can bypass the snapping warning from PhysicsUSD\nif og.sim.is_playing():\nwith suppress_omni_log(channels=[\"omni.physx.plugin\"]):\nog.sim.pi.update_simulation(elapsedStep=0, currentTime=og.sim.current_time)\n# Return this joint\nreturn joint_prim\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.create_mesh_prim_with_default_xform","title":"<code>create_mesh_prim_with_default_xform(primitive_type, prim_path, u_patches=None, v_patches=None)</code>","text":"<p>Creates a mesh prim of the specified @primitive_type at the specified @prim_path</p> <p>Parameters:</p> Name Type Description Default <code>primitive_type</code> <code>str</code> <p>Primitive mesh type, should be one of PRIMITIVE_MESH_TYPES to be valid</p> required <code>prim_path</code> <code>str</code> <p>Destination prim path to store the mesh prim</p> required <code>u_patches</code> <code>int or None</code> <p>If specified, should be an integer that represents how many segments to create in the u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.</p> <code>None</code> <code>v_patches</code> <code>int or None</code> <p>If specified, should be an integer that represents how many segments to create in the v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created. Both u_patches and v_patches need to be specified for them to be effective.</p> <code>None</code> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def create_mesh_prim_with_default_xform(primitive_type, prim_path, u_patches=None, v_patches=None):\n\"\"\"\n    Creates a mesh prim of the specified @primitive_type at the specified @prim_path\n    Args:\n        primitive_type (str): Primitive mesh type, should be one of PRIMITIVE_MESH_TYPES to be valid\n        prim_path (str): Destination prim path to store the mesh prim\n        u_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n        v_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n            Both u_patches and v_patches need to be specified for them to be effective.\n    \"\"\"\nassert primitive_type in PRIMITIVE_MESH_TYPES, \"Invalid primitive mesh type: {primitive_type}\"\nevaluator = MESH_PRIM_TYPE_TO_EVALUATOR_MAPPING[primitive_type]\nu_backup = carb.settings.get_settings().get(evaluator.SETTING_U_SCALE)\nv_backup = carb.settings.get_settings().get(evaluator.SETTING_V_SCALE)\nhs_backup = carb.settings.get_settings().get(evaluator.SETTING_OBJECT_HALF_SCALE)\ncarb.settings.get_settings().set(evaluator.SETTING_U_SCALE, 1)\ncarb.settings.get_settings().set(evaluator.SETTING_V_SCALE, 1)\n# Default half_scale (i.e. half-extent, half_height, radius) is 1.\n# TODO (eric): change it to 0.5 once the mesh generator API accepts floating-number HALF_SCALE\n#  (currently it only accepts integer-number and floors 0.5 into 0).\ncarb.settings.get_settings().set(evaluator.SETTING_OBJECT_HALF_SCALE, 1)\nif u_patches is not None and v_patches is not None:\nomni.kit.commands.execute(\n\"CreateMeshPrimWithDefaultXform\",\nprim_type=primitive_type,\nprim_path=prim_path,\nu_patches=u_patches,\nv_patches=v_patches,\n)\nelse:\nomni.kit.commands.execute(\n\"CreateMeshPrimWithDefaultXform\",\nprim_type=primitive_type,\nprim_path=prim_path,\n)\ncarb.settings.get_settings().set(evaluator.SETTING_U_SCALE, u_backup)\ncarb.settings.get_settings().set(evaluator.SETTING_V_SCALE, v_backup)\ncarb.settings.get_settings().set(evaluator.SETTING_OBJECT_HALF_SCALE, hs_backup)\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.create_primitive_mesh","title":"<code>create_primitive_mesh(prim_path, primitive_type, extents=1.0, u_patches=None, v_patches=None)</code>","text":"<p>Helper function that generates a UsdGeom.Mesh prim at specified @prim_path of type @primitive_type.</p> <p>NOTE: Generated mesh prim will, by default, have extents equaling [1, 1, 1]</p> <p>Parameters:</p> Name Type Description Default <code>prim_path</code> <code>str</code> <p>Where the loaded mesh should exist on the stage</p> required <code>primitive_type</code> <code>str</code> <p>Type of primitive mesh to create. Should be one of:</p> required <code>extents</code> <code>float or 3-array</code> <p>Specifies the extents of the generated mesh. Default is 1.0, i.e.: generated mesh will be in be contained in a [1,1,1] sized bounding box</p> <code>1.0</code> <code>u_patches</code> <code>int or None</code> <p>If specified, should be an integer that represents how many segments to create in the u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.</p> <code>None</code> <code>v_patches</code> <code>int or None</code> <p>If specified, should be an integer that represents how many segments to create in the v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created. Both u_patches and v_patches need to be specified for them to be effective.</p> <code>None</code> <p>Returns:</p> Type Description <p>UsdGeom.Mesh: Generated primitive mesh as a prim on the active stage</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def create_primitive_mesh(prim_path, primitive_type, extents=1.0, u_patches=None, v_patches=None):\n\"\"\"\n    Helper function that generates a UsdGeom.Mesh prim at specified @prim_path of type @primitive_type.\n    NOTE: Generated mesh prim will, by default, have extents equaling [1, 1, 1]\n    Args:\n        prim_path (str): Where the loaded mesh should exist on the stage\n        primitive_type (str): Type of primitive mesh to create. Should be one of:\n            {\"Cone\", \"Cube\", \"Cylinder\", \"Disk\", \"Plane\", \"Sphere\", \"Torus\"}\n        extents (float or 3-array): Specifies the extents of the generated mesh. Default is 1.0, i.e.:\n            generated mesh will be in be contained in a [1,1,1] sized bounding box\n        u_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n        v_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n            Both u_patches and v_patches need to be specified for them to be effective.\n    Returns:\n        UsdGeom.Mesh: Generated primitive mesh as a prim on the active stage\n    \"\"\"\nassert_valid_key(key=primitive_type, valid_keys=PRIMITIVE_MESH_TYPES, name=\"primitive mesh type\")\ncreate_mesh_prim_with_default_xform(primitive_type, prim_path, u_patches=u_patches, v_patches=v_patches)\nmesh = UsdGeom.Mesh.Define(og.sim.stage, prim_path)\n# Modify the points and normals attributes so that total extents is the desired\n# This means multiplying omni's default by extents * 50.0, as the native mesh generated has extents [-0.01, 0.01]\n# -- i.e.: 2cm-wide mesh\nextents = np.ones(3) * extents if isinstance(extents, float) else np.array(extents)\nfor attr in (mesh.GetPointsAttr(), mesh.GetNormalsAttr()):\nvals = np.array(attr.Get()).astype(np.float64)\nattr.Set(Vt.Vec3fArray([Gf.Vec3f(*(val * extents * 50.0)) for val in vals]))\nmesh.GetExtentAttr().Set(Vt.Vec3fArray([Gf.Vec3f(*(-extents / 2.0)), Gf.Vec3f(*(extents / 2.0))]))\nreturn mesh\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.get_camera_params","title":"<code>get_camera_params(viewport)</code>","text":"<p>Get active camera intrinsic and extrinsic parameters.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Keyword-mapped values of the active camera's parameters:</p> <p>pose (numpy.ndarray): camera position in world coordinates, fov (float): horizontal field of view in radians focal_length (float) horizontal_aperture (float) view_projection_matrix (numpy.ndarray(dtype=float64, shape=(4, 4))) resolution (dict): resolution as a dict with 'width' and 'height'. clipping_range (tuple(float, float)): Near and Far clipping values.</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def get_camera_params(viewport):\n\"\"\"\n    Get active camera intrinsic and extrinsic parameters.\n    Returns:\n        dict: Keyword-mapped values of the active camera's parameters:\n            pose (numpy.ndarray): camera position in world coordinates,\n            fov (float): horizontal field of view in radians\n            focal_length (float)\n            horizontal_aperture (float)\n            view_projection_matrix (numpy.ndarray(dtype=float64, shape=(4, 4)))\n            resolution (dict): resolution as a dict with 'width' and 'height'.\n            clipping_range (tuple(float, float)): Near and Far clipping values.\n    \"\"\"\nstage = omni.usd.get_context().get_stage()\nprim = stage.GetPrimAtPath(viewport.get_active_camera())\nprim_tf = omni.usd.get_world_transform_matrix(prim)\nview_params = helpers.get_view_params(viewport)\nfov = 2 * math.atan(view_params[\"horizontal_aperture\"] / (2 * view_params[\"focal_length\"]))\nview_proj_mat = helpers.get_view_proj_mat(view_params)\nreturn {\n\"pose\": np.array(prim_tf),\n\"fov\": fov,\n\"focal_length\": view_params[\"focal_length\"],\n\"horizontal_aperture\": view_params[\"horizontal_aperture\"],\n\"view_projection_matrix\": view_proj_mat,\n\"resolution\": {\"width\": view_params[\"width\"], \"height\": view_params[\"height\"]},\n\"clipping_range\": view_params[\"clipping_range\"],\n}\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.get_prim_nested_children","title":"<code>get_prim_nested_children(prim)</code>","text":"<p>Grabs all nested prims starting from root @prim via depth-first-search</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>Usd.Prim</code> <p>root prim from which to search for nested children prims</p> required <p>Returns:</p> Type Description <p>list of Usd.Prim: nested prims</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def get_prim_nested_children(prim):\n\"\"\"\n    Grabs all nested prims starting from root @prim via depth-first-search\n    Args:\n        prim (Usd.Prim): root prim from which to search for nested children prims\n    Returns:\n        list of Usd.Prim: nested prims\n    \"\"\"\nprims = []\nfor child in get_prim_children(prim):\nprims.append(child)\nprims += get_prim_nested_children(prim=child)\nreturn prims\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.get_semantic_objects_pose","title":"<code>get_semantic_objects_pose()</code>","text":"<p>Get pose of all objects with a semantic label.</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def get_semantic_objects_pose():\n\"\"\"\n    Get pose of all objects with a semantic label.\n    \"\"\"\nstage = omni.usd.get_context().get_stage()\nmappings = helpers.get_instance_mappings()\npose = []\nfor m in mappings:\nprim_path = m[1]\nprim = stage.GetPrimAtPath(prim_path)\nprim_tf = omni.usd.get_world_transform_matrix(prim)\npose.append((str(prim_path), m[2], str(m[3]), np.array(prim_tf)))\nreturn pose\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.get_world_prim","title":"<code>get_world_prim()</code>","text":"<p>Returns:</p> Type Description <p>Usd.Prim: Active world prim in the current stage</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def get_world_prim():\n\"\"\"\n    Returns:\n        Usd.Prim: Active world prim in the current stage\n    \"\"\"\nreturn get_prim_at_path(\"/World\")\n</code></pre>"},{"location":"reference/utils/usd_utils.html#utils.usd_utils.mesh_prim_to_trimesh_mesh","title":"<code>mesh_prim_to_trimesh_mesh(mesh_prim)</code>","text":"<p>Generates trimesh mesh from @mesh_prim</p> <p>Parameters:</p> Name Type Description Default <code>mesh_prim</code> <code>Usd.Prim</code> <p>Mesh prim to convert into trimesh mesh</p> required <p>Returns:</p> Type Description <p>trimesh.Trimesh: Generated trimesh mesh</p> Source code in <code>omnigibson/utils/usd_utils.py</code> <pre><code>def mesh_prim_to_trimesh_mesh(mesh_prim):\n\"\"\"\n    Generates trimesh mesh from @mesh_prim\n    Args:\n        mesh_prim (Usd.Prim): Mesh prim to convert into trimesh mesh\n    Returns:\n        trimesh.Trimesh: Generated trimesh mesh\n    \"\"\"\nface_vertex_counts = np.array(mesh_prim.GetAttribute(\"faceVertexCounts\").Get())\nvertices = np.array(mesh_prim.GetAttribute(\"points\").Get())\nface_indices = np.array(mesh_prim.GetAttribute(\"faceVertexIndices\").Get())\nfaces = []\ni = 0\nfor count in face_vertex_counts:\nfor j in range(count - 2):\nfaces.append([face_indices[i], face_indices[i + j + 1], face_indices[i + j + 2]])\ni += count\nreturn trimesh.Trimesh(vertices=vertices, faces=faces)\n</code></pre>"},{"location":"reference/utils/vision_utils.html","title":"vision_utils","text":""},{"location":"reference/utils/vision_utils.html#utils.vision_utils.RandomScale","title":"<code>RandomScale</code>","text":"<p>Rescale the input PIL.Image to the given size.</p> <p>Parameters:</p> Name Type Description Default <code>minsize</code> <code>sequence or int</code> <p>Desired min output size. If size is a sequence like (w, h), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height &gt; width, then image will be rescaled to (size * height / width, size)</p> required <code>maxsize</code> <code>sequence or int</code> <p>Desired max output size. If size is a sequence like (w, h), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height &gt; width, then image will be rescaled to (size * height / width, size)</p> required <code>interpolation</code> <code>int</code> <p>Desired interpolation. Default is <code>PIL.Image.BILINEAR</code></p> <code>Image.BILINEAR</code> Source code in <code>omnigibson/utils/vision_utils.py</code> <pre><code>class RandomScale:\n\"\"\"Rescale the input PIL.Image to the given size.\n    Args:\n        minsize (sequence or int): Desired min output size. If size is a sequence like\n            (w, h), output size will be matched to this. If size is an int,\n            smaller edge of the image will be matched to this number.\n            i.e, if height &gt; width, then image will be rescaled to\n            (size * height / width, size)\n        maxsize (sequence or int): Desired max output size. If size is a sequence like\n            (w, h), output size will be matched to this. If size is an int,\n            smaller edge of the image will be matched to this number.\n            i.e, if height &gt; width, then image will be rescaled to\n            (size * height / width, size)\n        interpolation (int, optional): Desired interpolation. Default is ``PIL.Image.BILINEAR``\n    \"\"\"\ndef __init__(self, minsize, maxsize, interpolation=Image.BILINEAR):\nassert isinstance(minsize, int)\nassert isinstance(maxsize, int)\nself.minsize = minsize\nself.maxsize = maxsize\nself.interpolation = interpolation\ndef __call__(self, img):\n\"\"\"\n        Args:\n            img (PIL.Image): Image to be scaled.\n        Returns:\n            PIL.Image: Rescaled image.\n        \"\"\"\nsize = random.randint(self.minsize, self.maxsize)\nif isinstance(size, int):\nw, h = img.size\nif (w &lt;= h and w == size) or (h &lt;= w and h == size):\nreturn img\nif w &lt; h:\now = size\noh = int(size * h / w)\nreturn img.resize((ow, oh), self.interpolation)\nelse:\noh = size\now = int(size * w / h)\nreturn img.resize((ow, oh), self.interpolation)\nelse:\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/utils/vision_utils.html#utils.vision_utils.RandomScale.__call__","title":"<code>__call__(img)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>img</code> <code>PIL.Image</code> <p>Image to be scaled.</p> required <p>Returns:</p> Type Description <p>PIL.Image: Rescaled image.</p> Source code in <code>omnigibson/utils/vision_utils.py</code> <pre><code>def __call__(self, img):\n\"\"\"\n    Args:\n        img (PIL.Image): Image to be scaled.\n    Returns:\n        PIL.Image: Rescaled image.\n    \"\"\"\nsize = random.randint(self.minsize, self.maxsize)\nif isinstance(size, int):\nw, h = img.size\nif (w &lt;= h and w == size) or (h &lt;= w and h == size):\nreturn img\nif w &lt; h:\now = size\noh = int(size * h / w)\nreturn img.resize((ow, oh), self.interpolation)\nelse:\noh = size\now = int(size * w / h)\nreturn img.resize((ow, oh), self.interpolation)\nelse:\nraise NotImplementedError()\n</code></pre>"},{"location":"reference/utils/vision_utils.html#utils.vision_utils.randomize_colors","title":"<code>randomize_colors(N, bright=True)</code>","text":"<p>Modified from https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py#L59 Generate random colors. To get visually distinct colors, generate them in HSV space then convert to RGB.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>int</code> <p>Number of colors to generate</p> required <p>Returns:</p> Name Type Description <code>bright</code> <code>bool</code> <p>whether to increase the brightness of the colors or not</p> Source code in <code>omnigibson/utils/vision_utils.py</code> <pre><code>def randomize_colors(N, bright=True):\n\"\"\"\n    Modified from https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py#L59\n    Generate random colors.\n    To get visually distinct colors, generate them in HSV space then\n    convert to RGB.\n    Args:\n        N (int): Number of colors to generate\n    Returns:\n        bright (bool): whether to increase the brightness of the colors or not\n    \"\"\"\nbrightness = 1.0 if bright else 0.5\nhsv = [(1.0 * i / N, 1, brightness) for i in range(N)]\ncolors = np.array(list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv)))\nrstate = np.random.RandomState(seed=20)\nnp.random.shuffle(colors)\ncolors[0] = [0, 0, 0]  # First color is black\nreturn colors\n</code></pre>"},{"location":"reference/utils/vision_utils.html#utils.vision_utils.segmentation_to_rgb","title":"<code>segmentation_to_rgb(seg_im, N, colors=None)</code>","text":"<p>Helper function to visualize segmentations as RGB frames. NOTE: assumes that geom IDs go up to N at most - if not, multiple geoms might be assigned to the same color.</p> <p>Parameters:</p> Name Type Description Default <code>seg_im</code> <code>W, H)-array</code> <p>Segmentation image</p> required <code>N</code> <code>int</code> <p>Maximum segmentation ID from @seg_im</p> required <code>colors</code> <code>None or list of 3-array</code> <p>If specified, colors to apply to different segmentation IDs. Otherwise, will be generated randomly</p> <code>None</code> Source code in <code>omnigibson/utils/vision_utils.py</code> <pre><code>def segmentation_to_rgb(seg_im, N, colors=None):\n\"\"\"\n    Helper function to visualize segmentations as RGB frames.\n    NOTE: assumes that geom IDs go up to N at most - if not,\n    multiple geoms might be assigned to the same color.\n    Args:\n        seg_im ((W, H)-array): Segmentation image\n        N (int): Maximum segmentation ID from @seg_im\n        colors (None or list of 3-array): If specified, colors to apply\n            to different segmentation IDs. Otherwise, will be generated randomly\n    \"\"\"\n# ensure all values lie within [0, N]\nseg_im = np.mod(seg_im, N)\nif colors is None:\nuse_colors = randomize_colors(N=N, bright=True)\nelse:\nuse_colors = colors\nif N &lt;= 256:\nreturn (255.0 * use_colors[seg_im]).astype(np.uint8)\nelse:\nreturn (use_colors[seg_im]).astype(np.float)\n</code></pre>"},{"location":"reference/wrappers/index.html","title":"wrappers","text":""},{"location":"reference/wrappers/wrapper_base.html","title":"wrapper_base","text":"<p>This file contains the base wrapper class for OmnOmniGibson environments Wrappers are useful for data collection and logging. Highly recommended.</p>"},{"location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper","title":"<code>BaseWrapper</code>","text":"<p>Base class for all wrappers in OmniGibson</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>OmniGibsonEnv</code> <p>The environment to wrap.</p> required Source code in <code>omnigibson/wrappers/wrapper_base.py</code> <pre><code>class BaseWrapper:\n\"\"\"\n    Base class for all wrappers in OmniGibson\n    Args:\n        env (OmniGibsonEnv): The environment to wrap.\n    \"\"\"\ndef __init__(self, env):\nself.env = env\n@classmethod\ndef class_name(cls):\nreturn cls.__name__\ndef _warn_double_wrap(self):\n\"\"\"\n        Utility function that checks if we're accidentally trying to double wrap an env\n        Raises:\n            Exception: [Double wrapping env]\n        \"\"\"\nenv = self.env\nwhile True:\nif isinstance(env, BaseWrapper):\nif env.class_name() == self.class_name():\nraise Exception(\"Attempted to double wrap with Wrapper: {}\".format(self.__class__.__name__))\nenv = env.env\nelse:\nbreak\ndef step(self, action):\n\"\"\"\n        By default, run the normal environment step() function\n        Args:\n            action (np.array): action to take in environment\n        Returns:\n            4-tuple:\n                - (dict) observations from the environment\n                - (float) reward from the environment\n                - (bool) whether the current episode is completed or not\n                - (dict) misc information\n        \"\"\"\nreturn self.env.step(action)\ndef reset(self):\n\"\"\"\n        By default, run the normal environment reset() function\n        Returns:\n            dict: Environment observation space after reset occurs\n        \"\"\"\nreturn self.env.reset()\ndef observation_spec(self):\n\"\"\"\n        By default, grabs the normal environment observation_spec\n        Returns:\n            dict: Observations from the environment\n        \"\"\"\nreturn self.env.observation_spec()\n@property\ndef unwrapped(self):\n\"\"\"\n        Grabs unwrapped environment\n        Returns:\n            env (OmniGibsonEnv): The unwrapped environment\n        \"\"\"\nif hasattr(self.env, \"unwrapped\"):\nreturn self.env.unwrapped\nelse:\nreturn self.env\n# this method is a fallback option on any methods the original env might support\ndef __getattr__(self, attr):\n# using getattr ensures that both __getattribute__ and __getattr__ (fallback) get called\n# (see https://stackoverflow.com/questions/3278077/difference-between-getattr-vs-getattribute)\norig_attr = getattr(self.env, attr)\nif callable(orig_attr):\ndef hooked(*args, **kwargs):\nresult = orig_attr(*args, **kwargs)\n# prevent wrapped_class from becoming unwrapped\nif result == self.env:\nreturn self\nreturn result\nreturn hooked\nelse:\nreturn orig_attr\n</code></pre>"},{"location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.unwrapped","title":"<code>unwrapped</code>  <code>property</code>","text":"<p>Grabs unwrapped environment</p> <p>Returns:</p> Name Type Description <code>env</code> <code>OmniGibsonEnv</code> <p>The unwrapped environment</p>"},{"location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.observation_spec","title":"<code>observation_spec()</code>","text":"<p>By default, grabs the normal environment observation_spec</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Observations from the environment</p> Source code in <code>omnigibson/wrappers/wrapper_base.py</code> <pre><code>def observation_spec(self):\n\"\"\"\n    By default, grabs the normal environment observation_spec\n    Returns:\n        dict: Observations from the environment\n    \"\"\"\nreturn self.env.observation_spec()\n</code></pre>"},{"location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.reset","title":"<code>reset()</code>","text":"<p>By default, run the normal environment reset() function</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Environment observation space after reset occurs</p> Source code in <code>omnigibson/wrappers/wrapper_base.py</code> <pre><code>def reset(self):\n\"\"\"\n    By default, run the normal environment reset() function\n    Returns:\n        dict: Environment observation space after reset occurs\n    \"\"\"\nreturn self.env.reset()\n</code></pre>"},{"location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.step","title":"<code>step(action)</code>","text":"<p>By default, run the normal environment step() function</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>np.array</code> <p>action to take in environment</p> required <p>Returns:</p> Type Description <p>4-tuple: - (dict) observations from the environment - (float) reward from the environment - (bool) whether the current episode is completed or not - (dict) misc information</p> Source code in <code>omnigibson/wrappers/wrapper_base.py</code> <pre><code>def step(self, action):\n\"\"\"\n    By default, run the normal environment step() function\n    Args:\n        action (np.array): action to take in environment\n    Returns:\n        4-tuple:\n            - (dict) observations from the environment\n            - (float) reward from the environment\n            - (bool) whether the current episode is completed or not\n            - (dict) misc information\n    \"\"\"\nreturn self.env.step(action)\n</code></pre>"},{"location":"src/examples/index.html","title":"Index","text":""},{"location":"src/examples/index.html#code-examples","title":"Code Examples","text":"<p>The following examples illustrate the use of OmniGibson.</p> <p>If you are interested in just getting started as an end-user, you only need check out <code>./environments</code>.</p> <p>If you are looking for examples of BEHAVIOR, the benchmark of household activities that uses OmniGibson, please check the BEHAVIOR repository at https://github.com/StanfordVL/behavior.</p> <ul> <li>environments: how to instantiate OmniGibson environments with interactive or static scenes, optionally with a scene selector.</li> <li>learning: how to train RL policies for robot navigation using stable baselines 3, and how to save and replay demos of agents for imitation learning.</li> <li>objects: how to create, load, and place objects to predefined locations or using a logic sampler (e.g. onTop(A, B)), how to change texture as a function of the temperature, and how to generate the minimum volume bounding boxes of objects.</li> <li>object_states: how to change various objects states, including dusty, stained, (water sources) toggled on, (cleaning tool) soaked, sliced, and temprature, and how to save and reload object states.</li> <li>observations: how to generate different observation modalities such as RGB, depth, LiDAR, segmentation, etc.</li> <li>renderer: how to use the renderer directly, without the physics engine.</li> <li>robots: how to (keyboard) control robots with differential drive controllers, IK controllers and sampling-based motion planners.</li> <li>ros: how to run ROS with OmniGibson as if it is the real world.</li> <li>scenes: how to load interactive and non-interactive scenes, how to use domain randomization (of object models and/or texture), and how to create a tour video of the scenes.</li> <li>vr: how to use OmniGibson with VR.</li> <li>web_ui: how to start a web server that hosts OmniGibson environments.</li> </ul>"}]}