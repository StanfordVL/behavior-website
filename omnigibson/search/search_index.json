{"config":{"lang":["en"],"separator":"[\\s\\-]+"},"docs":[{"title":"\ud83e\uddf1 Building Blocks","text":"<p><code>OmniGibson</code> ships with many demo scripts highlighting its modularity and diverse feature set intended as a set of building blocks enabling your research. Let's try them out!</p>","location":"getting_started/building_blocks.html"},{"title":"\u2699\ufe0f A quick word about macros","text":"Why macros? <p>Macros enforce global behavior that is consistent within an individual python process but can differ between processes. This is useful because globally enabling all of <code>OmniGibson</code>'s features can cause unecessary slowdowns (1), and so configuring the macros for your specific use case can optimize performance.</p>  <ol> <li>For example, Omniverse provides a so-called <code>flatcache</code> feature which provides significant performance boosts, but cannot be used when fluids or soft bodies are present. So, we ideally should always have <code>gm.USE_FLATCACHE=True</code> unless we have fluids or soft bodies in our environment.</li> </ol> <p><code>macros</code> define a globally available set of magic numbers or flags set throughout <code>OmniGibson</code>. These can either be directly set in <code>omnigibson.macros.py</code>, or can be programmatically modified at runtime via:</p> <pre><code>from omnigibson.macros import gm, macros\n\ngm.&lt;GLOBAL_MACRO&gt; = &lt;VALUE&gt; # (1)!\nmacros.&lt;OG_DIRECTORY&gt;.&lt;OG_MODULE&gt;.&lt;MODULE_MACRO&gt; = &lt;VALUE&gt; # (2)!\n</code></pre> <ol> <li><code>gm</code> refers to the \"global\" macros -- i.e.: settings that generally impact the entire <code>OmniGibson</code> stack. These are usually the only settings you may need to modify.</li> <li><code>macros</code> captures all remaining macros defined throughout <code>OmniGibson</code>'s codebase -- these are often hardcoded default settings or magic numbers defined in a specific module. These can also be overridden, but we recommend inspecting the module first to understand how it is used.</li> </ol> <p>Many of our examples set various <code>macros</code> settings at the beginning of the script, and is a good way to understand use cases for modifying them!</p>","location":"getting_started/building_blocks.html#a-quick-word-about-macros"},{"title":"\ud83c\udf0e Environments","text":"<p>These examples showcase the full <code>OmniGibson</code> stack in use, and the types of environments immediately supported.</p>","location":"getting_started/building_blocks.html#environments"},{"title":"BEHAVIOR Task Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to instantiate a BEHAVIOR task</li> <li>Understanding how a pre-defined configuration file is used</li> </ul>  <pre><code>python -m omnigibson.examples.environments.behavior_env_demo\n</code></pre> <p>This demo instantiates one of our BEHAVIOR tasks (and optionally sampling object locations online) in a fully-populated scene and loads a <code>Fetch</code> robot. The robot executes random actions and the environment is reset periodically.</p>  behavior_env_demo.py <pre><code>import logging\nimport os\n\nimport yaml\n\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.ui_utils import choose_from_options\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Generates a BEHAVIOR Task environment from a pre-defined configuration file.\n\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Ask the user whether they want online object sampling or not\n    sampling_options = {\n        False: \"Use a pre-sampled cached BEHAVIOR activity scene\",\n        True: \"Sample the BEHAVIOR activity in an online fashion\",\n    }\n    should_sample = choose_from_options(options=sampling_options, name=\"online object sampling\", random_selection=random_selection)\n\n    # Load the pre-selected configuration and set the online_sampling flag\n    config_filename = os.path.join(og.example_config_path, \"fetch_behavior.yaml\")\n    cfg = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n    cfg[\"task\"][\"online_object_sampling\"] = should_sample\n\n    # If we're online sampling, make sure global contacts are enabled so we can accurately detect kinematic changes\n    if should_sample:\n        gm.ENABLE_GLOBAL_CONTACT_REPORTING = True\n\n    # Load the environment\n    env = og.Environment(configs=cfg)\n\n    # Allow user to move camera more easily\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Run a simple loop and reset periodically\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#behavior-task-demo"},{"title":"Navigation Task Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to instantiate a navigation task</li> <li>Understanding how a pre-defined configuration file is used</li> </ul>  <pre><code>python -m omnigibson.examples.environments.navigation_env_demo\n</code></pre> <p>This demo instantiates one of our navigation tasks in a fully-populated scene and loads a <code>Turtlebot</code> robot. The robot executes random actions and the environment is reset periodically.</p>  navigation_env_demo.py <pre><code>import logging\nimport os\n\nimport yaml\n\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.ui_utils import choose_from_options\n\n# Use flatcache for performance speedups unless we're using GPU dynamics\nif not gm.USE_GPU_DYNAMICS:\n    gm.ENABLE_FLATCACHE = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select a type of scene and loads a turtlebot into it, generating a Point-Goal navigation\n    task within the environment.\n\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Infer which config to load based on the scene selected\n    scene_options = {\n        \"InteractiveTraversableScene\": \"Rs_int scene with fully interactive objects\",\n        \"StaticTraversableScene\": \"Adrian scene mesh with no interactive objects\",\n    }\n    scene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n    config_name = \"turtlebot_nav\" if scene_type == \"InteractiveTraversableScene\" else \"turtlebot_static_nav\"\n    config_filename = os.path.join(og.example_config_path, f\"{config_name}.yaml\")\n    config = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n\n    # If the scene type is interactive, also check if we want to quick load or full load the scene\n    if scene_type == \"InteractiveTraversableScene\":\n        load_options = {\n            \"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n            \"Full\": \"Load all interactive objects in the scene\",\n        }\n        load_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\n        if load_mode == \"Quick\":\n            config[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n\n    # Load the environment\n    env = og.Environment(configs=config)\n\n    # Allow user to move camera more easily\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Run a simple loop and reset periodically\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#navigation-task-demo"},{"title":"Config Selection Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how pre-defined configuration files are used</li> </ul>  <pre><code>python -m omnigibson.examples.environments.config_selector\n</code></pre> <p>This demo allows you to choose one of our environment configuration files, loads the environment, and then cycles the environment periodically.</p>  config_selector.py <pre><code>import logging\nimport os\n\nimport yaml\n\nimport omnigibson as og\nfrom omnigibson.utils.asset_utils import folder_is_hidden\nfrom omnigibson.utils.ui_utils import choose_from_options\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select any available interactive scene and loads a turtlebot into it.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Grab all configs and choose one to load\n    og_config_path = og.example_config_path\n    available_configs = sorted(\n        [\n            f\n            for f in os.listdir(og_config_path)\n            if (not folder_is_hidden(f) and os.path.isfile(os.path.join(og_config_path, f)))\n        ]\n    )\n    config_id = choose_from_options(options=available_configs, name=\"config file\", random_selection=random_selection)\n    logging.info(\"Using config file \" + config_id)\n    config_filename = os.path.join(og.example_config_path, config_id)\n    config = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n\n    load_options = {\n        \"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n        \"Full\": \"Load all interactive objects in the scene\",\n    }\n    load_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\n    if load_mode == \"Quick\":\n        config[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n\n    # Load the environment\n    env = og.Environment(configs=config)\n\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            for robot_name in action.keys():\n                action[robot_name] = action[robot_name] * 0.05\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#config-selection-demo"},{"title":"\ud83e\uddd1\u200d\ud83c\udfeb Learning","text":"<p>These examples showcase how <code>OmniGibson</code> can be used to train embodied AI agents.</p>","location":"getting_started/building_blocks.html#learning"},{"title":"Reinforcement Learning Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to hook up <code>OmniGibson</code> to an external algorithm</li> <li>Understanding how to train and evaluate a policy</li> </ul>  <pre><code>python -m omnigibson.examples.learning.stable_baselines3_ppo_example\n</code></pre> <p>This demo loads a BEHAVIOR task with a <code>Fetch</code> robot, and trains / evaluates the agent using Stable Baseline3's PPO algorithm.</p>  stable_baselines3_ppo_example.py <pre><code>\"\"\"\nExample training code using stable-baselines3 PPO for one BEHAVIOR activity.\nNote that due to the sparsity of the reward, this training code will not converge and achieve task success.\nThis only serves as a starting point that users can further build upon.\n\"\"\"\n\nimport argparse\nimport logging\nimport os, time, cv2\n\nimport omnigibson as og\nfrom omnigibson import example_config_path\n\nlog = logging.getLogger(__name__)\n\ntry:\n    import gym\n    import torch as th\n    import torch.nn as nn\n    from stable_baselines3 import PPO\n    from stable_baselines3.common.evaluation import evaluate_policy\n    from stable_baselines3.common.preprocessing import maybe_transpose\n    from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n    from stable_baselines3.common.utils import set_random_seed\n    from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n\nexcept ModuleNotFoundError:\n    log.error(\"stable-baselines3 is not installed. You would need to do: pip install stable-baselines3\")\n    exit(1)\n\n\nclass CustomCombinedExtractor(BaseFeaturesExtractor):\n    def __init__(self, observation_space: gym.spaces.Dict):\n        # We do not know features-dim here before going over all the items,\n        # so put something dummy for now. PyTorch requires calling\n        super(CustomCombinedExtractor, self).__init__(observation_space, features_dim=1)\n        self.debug_length = 10\n        self.debug_mode = True\n        extractors = {}\n        self.step_index = 0\n        self.img_save_dir = 'img_save_dir'\n        os.makedirs(self.img_save_dir, exist_ok=True)\n        total_concat_size = 0\n        feature_size = 128\n        for key, subspace in observation_space.spaces.items():\n            if key in [\"rgb\", \"ins_seg\"]:\n                print(subspace.shape)\n                n_input_channels = subspace.shape[2]  # channel last\n                cnn = nn.Sequential(\n                    nn.Conv2d(n_input_channels, 4, kernel_size=8, stride=4, padding=0),\n                    nn.ReLU(),\n                    nn.MaxPool2d(2),\n                    nn.Conv2d(4, 8, kernel_size=4, stride=2, padding=0),\n                    nn.ReLU(),\n                    nn.MaxPool2d(2),\n                    nn.Conv2d(8, 4, kernel_size=3, stride=1, padding=0),\n                    nn.ReLU(),\n                    nn.Flatten(),\n                )\n                test_tensor = th.zeros([subspace.shape[2], subspace.shape[0], subspace.shape[1]])\n                with th.no_grad():\n                    n_flatten = cnn(test_tensor[None]).shape[1]\n                fc = nn.Sequential(nn.Linear(n_flatten, feature_size), nn.ReLU())\n                extractors[key] = nn.Sequential(cnn, fc)\n            elif key in [\"accum_reward\", 'obj_joint']:\n                extractors[key] = nn.Sequential(nn.Linear(subspace.shape[0], feature_size))\n            else:\n                continue\n            total_concat_size += feature_size\n        self.extractors = nn.ModuleDict(extractors)\n\n        # Update the features dim manually\n        self._features_dim = total_concat_size\n\n    def forward(self, observations) -&gt; th.Tensor:\n        encoded_tensor_list = []\n        self.step_index += 1\n\n        # self.extractors contain nn.Modules that do all the processing.\n        for key, extractor in self.extractors.items():\n            if key in [\"rgb\",]:\n                if self.debug_mode:\n                    cv2.imwrite(os.path.join(self.img_save_dir, '{0:06d}.png'.format(self.step_index % self.debug_length)), cv2.cvtColor((observations[key][0].cpu().numpy()*255).astype('uint8'), cv2.COLOR_RGB2BGR))\n                observations[key] = observations[key].permute((0, 3, 1, 2))\n            elif key in [\"ins_seg\"]:\n                observations[key] = observations[key].permute((0, 3, 1, 2)) / 500.\n            elif key in ['accum_reward', 'obj_joint']:\n                if len(observations[key].shape) == 3:\n                    observations[key] = observations[key].squeeze(-1)  # [:, :, 0]\n            else:\n                continue\n\n            encoded_tensor_list.append(extractor(observations[key]))\n\n        feature = th.cat(encoded_tensor_list, dim=1)\n        return feature\n\n\ndef main():\n    # Parse args\n    parser = argparse.ArgumentParser(description=\"Train or evaluate a PPO agent in BEHAVIOR\")\n    parser.add_argument(\n        \"--config\",\n        type=str,\n        default=f\"{example_config_path}/fetch_behavior.yaml\",\n        help=\"Absolute path to desired OmniGibson environment config to load\",\n    )\n\n    parser.add_argument(\n        \"--checkpoint\",\n        type=str,\n        default=None,\n        help=\"Absolute path to desired PPO checkpoint to load for evaluation\",\n    )\n\n    parser.add_argument(\n        \"--eval\",\n        action=\"store_true\",\n        help=\"If set, will evaluate the PPO agent found from --checkpoint\",\n    )\n\n    args = parser.parse_args()\n    tensorboard_log_dir = os.path.join(\"log_dir\", time.strftime(\"%Y%m%d-%H%M%S\"))\n    os.makedirs(tensorboard_log_dir, exist_ok=True)\n    prefix = ''\n    seed = 0\n\n    env = og.Environment(configs=args.config, action_timestep=1 / 60., physics_timestep=1 / 60.)\n\n    # If we're evaluating, hide the ceilings and enable camera teleoperation so the user can easily\n    # visualize the rollouts dynamically\n    if args.eval:\n        ceiling = env.scene.object_registry(\"name\", \"ceilings\")\n        ceiling.visible = False\n        og.sim.enable_viewer_camera_teleoperation()\n\n    # Set the set\n    set_random_seed(seed)\n    env.reset()\n\n    policy_kwargs = dict(\n        features_extractor_class=CustomCombinedExtractor,\n    )\n\n    os.makedirs(tensorboard_log_dir, exist_ok=True)\n\n    if args.eval:\n        assert args.checkpoint is not None, \"If evaluating a PPO policy, @checkpoint argument must be specified!\"\n        model = PPO.load(args.checkpoint)\n        print(\"Starting evaluation...\")\n        mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=50)\n        print(\"Finished evaluation!\")\n        log.info(f\"Mean reward: {mean_reward} +/- {std_reward:.2f}\")\n\n    else:\n        model = PPO(\n            \"MultiInputPolicy\",\n            env,\n            verbose=1,\n            tensorboard_log=tensorboard_log_dir,\n            policy_kwargs=policy_kwargs,\n            n_steps=20 * 10,\n            batch_size=8,\n            device='cuda',\n        )\n        checkpoint_callback = CheckpointCallback(save_freq=1000, save_path=tensorboard_log_dir, name_prefix=prefix)\n        log.debug(model.policy)\n        print(model)\n\n        print(\"Starting training...\")\n        model.learn(total_timesteps=10000000, callback=checkpoint_callback,\n                    eval_env=env, eval_freq=1000,\n                    n_eval_episodes=20)\n        print(\"Finished training!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#reinforcement-learning-demo"},{"title":"\ud83c\udfd4\ufe0f Scenes","text":"<p>These examples showcase how to leverage <code>OmniGibson</code>'s large-scale, diverse scenes shipped with the BEHAVIOR dataset.</p>","location":"getting_started/building_blocks.html#scenes"},{"title":"Scene Selector Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load a scene into <code>OmniGibson</code></li> <li>Accessing all BEHAVIOR dataset scenes</li> </ul>  <pre><code>python -m omnigibson.examples.scenes.scene_selector\n</code></pre> <p>This demo lets you choose a scene from the BEHAVIOR dataset, loads it along with a <code>Turtlebot</code> robot, and cycles the resulting environment periodically.</p>  scene_selector.py <pre><code>import logging\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.asset_utils import get_available_g_scenes, get_available_og_scenes\nfrom omnigibson.utils.ui_utils import choose_from_options\n\n# Don't use GPU dynamics and Use flatcache for performance boost\ngm.USE_GPU_DYNAMICS = False\ngm.ENABLE_FLATCACHE = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select any available non-interactive scene and loads a turtlebot into it.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose the scene type to load\n    scene_options = {\n        \"InteractiveTraversableScene\": \"Procedurally generated scene with fully interactive objects\",\n        \"StaticTraversableScene\": \"Monolithic scene mesh with no interactive objects\",\n    }\n    scene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n\n    # Choose the scene model to load\n    scenes = get_available_og_scenes() if scene_type == \"InteractiveTraversableScene\" else get_available_g_scenes()\n    scene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\n    print(f\"scene model: {scene_model}\")\n\n    cfg = {\n        \"scene\": {\n            \"type\": scene_type,\n            \"scene_model\": scene_model,\n        },\n        \"robots\": [\n            {\n                \"type\": \"Turtlebot\",\n                \"obs_modalities\": [\"scan\", \"rgb\", \"depth\"],\n                \"action_type\": \"continuous\",\n                \"action_normalize\": True,\n            }\n        ],\n    }\n\n    # If the scene type is interactive, also check if we want to quick load or full load the scene\n    if scene_type == \"InteractiveTraversableScene\":\n        load_options = {\n            \"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n            \"Full\": \"Load all interactive objects in the scene\",\n        }\n        load_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\n        if load_mode == \"Quick\":\n            cfg[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n\n    # Load the environment\n    env = og.Environment(configs=cfg)\n\n    # Allow user to move camera more easily\n    if not headless:\n        og.sim.enable_viewer_camera_teleoperation()\n\n    # Run a simple loop and reset periodically\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#scene-selector-demo"},{"title":"Traversability Map Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to leverage traversability map information from BEHAVIOR dataset scenes</li> </ul>  <pre><code>python -m omnigibson.examples.scenes.traversability_map_example\n</code></pre> <p>This demo lets you choose a scene from the BEHAVIOR dataset, and generates its corresponding traversability map.</p>  traversability_map_example.py <pre><code>import logging\nimport os\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\nfrom omnigibson.utils.asset_utils import get_og_scene_path, get_available_og_scenes\nfrom omnigibson.utils.ui_utils import choose_from_options\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Traversable map demo\n    Loads the floor plan and obstacles for the requested scene, and overlays them in a visual figure such that the\n    highlighted area reflects the traversable (free-space) area\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    scenes = get_available_og_scenes()\n    scene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\n    print(f\"Generating traversability map for scene {scene_model}\")\n\n    trav_map_size = 200\n    trav_map_erosion = 2\n\n    trav_map = Image.open(os.path.join(get_og_scene_path(scene_model), \"layout\", \"floor_trav_0.png\"))\n    trav_map = np.array(trav_map.resize((trav_map_size, trav_map_size)))\n    trav_map = cv2.erode(trav_map, np.ones((trav_map_erosion, trav_map_erosion)))\n\n    if not headless:\n        plt.figure(figsize=(12, 12))\n        plt.imshow(trav_map)\n        plt.title(f\"Traversable area of {scene_model} scene\")\n\n    if not headless:\n        plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#traversability-map-demo"},{"title":"\ud83c\udfbe Objects","text":"<p>These examples showcase how to leverage objects in <code>OmniGibson</code>.</p>","location":"getting_started/building_blocks.html#objects"},{"title":"Load Object Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load an object into <code>OmniGibson</code></li> <li>Accessing all BEHAVIOR dataset asset categories and models</li> </ul>  <pre><code>python -m omnigibson.examples.objects.load_object_selector\n</code></pre> <p>This demo lets you choose a specific object from the BEHAVIOR dataset, and loads the requested object into an environment.</p>  load_object_selector.py <pre><code>import logging\nimport numpy as np\nfrom collections import OrderedDict\nimport omnigibson as og\nfrom omnigibson.utils.asset_utils import (\n    get_all_object_categories,\n    get_og_avg_category_specs,\n    get_object_models_of_category,\n)\nfrom omnigibson.utils.ui_utils import choose_from_options\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    This demo shows how to load any scaled objects from the iG object model dataset\n    The user selects an object model to load\n    The objects can be loaded into an empty scene, an interactive scene (iG) or a static scene (Gibson)\n    The example also shows how to use the Environment API or directly the Simulator API, loading objects and robots\n    and executing actions\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n    scene_options = [\"Scene\", \"InteractiveTraversableScene\", \"StaticTraversableScene\"]\n    scene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n\n    # -- Choose the object to load --\n\n    # Select a category to load\n    available_obj_categories = get_all_object_categories()\n    obj_category = choose_from_options(options=available_obj_categories, name=\"object category\", random_selection=random_selection)\n\n    # Select a model to load\n    available_obj_models = get_object_models_of_category(obj_category)\n    obj_model = choose_from_options(options=available_obj_models, name=\"object model\", random_selection=random_selection)\n\n    # Load the specs of the object categories, e.g., common scaling factor\n    avg_category_spec = get_og_avg_category_specs()\n\n    # Create and load this object into the simulator\n    obj_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"obj\",\n        category=obj_category,\n        model=obj_model,\n        bounding_box=avg_category_spec.get(obj_category),\n        fit_avg_dim_volume=True,\n        position=[0.5, -0.5, 1.01],\n    )\n\n    cfg = {\n        \"scene\": {\n            \"type\": scene_type,\n        },\n        \"objects\": [obj_cfg],\n    }\n    if scene_type == \"InteractiveTraversableScene\":\n        cfg[\"scene\"][\"scene_model\"] = \"Rs_int\"\n    elif scene_type == \"StaticTraversableScene\":\n        cfg[\"scene\"][\"scene_model\"] = \"Adrian\"\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n\n    # Step through the environment\n    max_steps = 100 if short_exec else 10000\n    for i in range(max_steps):\n        env.step(np.array([]))\n\n    # Always close the environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#load-object-demo"},{"title":"Object Visualizer Demo","text":"<p>This demo is useful for...</p> <ul> <li>Viewing objects' textures as rendered in <code>OmniGibson</code></li> <li>Viewing articulated objects' range of motion</li> <li>Understanding how to reference object instances from the environment</li> <li>Understanding how to set object poses and joint states</li> </ul>  <pre><code>python -m omnigibson.examples.objects.visualize_object\n</code></pre> <p>This demo lets you choose a specific object from the BEHAVIOR dataset, and rotates the object in-place. If the object is articulated, it additionally moves its joints through its full range of motion.</p>  visualize_object.py <pre><code>import argparse\nimport logging\nfrom collections import OrderedDict\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson.utils.asset_utils import (\n    get_all_object_categories,\n    get_object_models_of_category,\n)\nfrom omnigibson.utils.ui_utils import choose_from_options\nimport omnigibson.utils.transform_utils as T\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Visualizes object as specified by its USD path, @usd_path. If None if specified, will instead\n    result in an object selection from OmniGibson's object dataset\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Assuming that if random_selection=True, headless=True, short_exec=True, we are calling it from tests and we\n    # do not want to parse args (it would fail because the calling function is pytest \"testfile.py\")\n    usd_path = None\n    if not (random_selection and headless and short_exec):\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            \"--usd_path\",\n            default=None,\n            help=\"USD Model to load\",\n        )\n        args = parser.parse_args()\n        usd_path = args.usd_path\n\n    # Define objects to load\n    light0_cfg = OrderedDict(\n        type=\"LightObject\",\n        light_type=\"Sphere\",\n        name=\"sphere_light0\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, -2.0, 2.0],\n    )\n\n    light1_cfg = OrderedDict(\n        type=\"LightObject\",\n        light_type=\"Sphere\",\n        name=\"sphere_light1\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, 2.0, 2.0],\n    )\n\n    # Make sure we have a valid usd path\n    if usd_path is None:\n        # Select a category to load\n        available_obj_categories = get_all_object_categories()\n        obj_category = choose_from_options(options=available_obj_categories, name=\"object category\",\n                                           random_selection=random_selection)\n\n        # Select a model to load\n        available_obj_models = get_object_models_of_category(obj_category)\n        obj_model = choose_from_options(options=available_obj_models, name=\"object model\",\n                                        random_selection=random_selection)\n\n        kwargs = {\n            \"type\": \"DatasetObject\",\n            \"category\": obj_category,\n            \"model\": obj_model,\n        }\n    else:\n        kwargs = {\n            \"type\": \"USDObject\",\n            \"usd_path\": usd_path,\n        }\n\n    # Import the desired object\n    obj_cfg = OrderedDict(\n        **kwargs,\n        name=\"obj\",\n        usd_path=usd_path,\n        visual_only=True,\n        position=[0, 0, 10.0],\n    )\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [light0_cfg, light1_cfg, obj_cfg],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg)\n\n    # Set camera to appropriate viewing pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.00913503, -1.95750906,  1.36407314]),\n        orientation=np.array([0.6350064 , 0.        , 0.        , 0.77250687]),\n    )\n\n    # Grab the object references\n    obj = env.scene.object_registry(\"name\", \"obj\")\n\n    # Standardize the scale of the object so it fits in a [1,1,1] box -- note that we have to stop the simulator\n    # in order to set the scale\n    extents = obj.aabb_extent\n    og.sim.stop()\n    obj.scale = (np.ones(3) / extents).min()\n    og.sim.play()\n    env.step(np.array([]))\n\n    # Move the object so that its center is at [0, 0, 1]\n    center_offset = obj.aabb_center - obj.get_position() + np.array([0, 0, 1.0])\n    obj.set_position(center_offset)\n\n    # Allow the user to easily move the camera around\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Rotate the object in place\n    steps_per_rotate = 360\n    steps_per_joint = steps_per_rotate / 10\n    max_steps = 100 if short_exec else 10000\n    for i in range(max_steps):\n        z_angle = (2 * np.pi * (i % steps_per_rotate) / steps_per_rotate)\n        quat = T.euler2quat(np.array([0, 0, z_angle]))\n        pos = T.quat2mat(quat) @ center_offset\n        if obj.n_dof &gt; 0:\n            frac = (i % steps_per_joint) / steps_per_joint\n            j_frac = -1.0 + 2.0 * frac if (i // steps_per_joint) % 2 == 0 else 1.0 - 2.0 * frac\n            obj.set_joint_positions(positions=j_frac * np.ones(obj.n_dof), normalized=True, target=False)\n            obj.keep_still()\n        obj.set_position_orientation(position=pos, orientation=quat)\n        env.step(np.array([]))\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#object-visualizer-demo"},{"title":"Highlight Object","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to highlight individual objects within a cluttered scene</li> <li>Understanding how to access groups of objects from the environment</li> </ul>  <pre><code>python -m omnigibson.examples.objects.highlight_objects\n</code></pre> <p>This demo lets you choose a specific object from the BEHAVIOR dataset, and rotates the object in-place. If the object is articulated, it additionally moves its joints through its full range of motion.</p>  highlight_objects.py <pre><code>\"\"\"\nGenerate example top-down segmentation map via renderer\n\"\"\"\nimport logging\nimport numpy as np\nimport omnigibson as og\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Highlights visually all object instances of some given category and then removes the highlighting\n    It also demonstrates how to apply an action on all instances of objects of a given category\n    ONLY WORKS WITH OPTIMIZED RENDERING (not on Mac)\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"InteractiveTraversableScene\",\n            \"scene_model\": \"Rs_int\",\n        }\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg)\n\n    # Grab all window objects\n    windows = og.sim.scene.object_registry(\"category\", \"window\")\n\n    # Step environment while toggling window highlighting\n    i = 0\n    highlighted = False\n    max_steps = -1 if not short_exec else 1000\n    while i != max_steps:\n        env.step(np.array([]))\n        if i % 50 == 0:\n            highlighted = not highlighted\n            logging.info(f\"Toggling window highlight to: {highlighted}\")\n            for window in windows:\n                # Note that this property is R/W!\n                window.highlighted = highlighted\n        i += 1\n\n    # Always close the environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#highlight-object"},{"title":"Draw Object Bounding Box Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to access observations from a <code>GymObservable</code> object (1)</li> <li>Understanding how to access objects' bounding box information</li> <li>Understanding how to dynamically modify vision modalities</li> </ul>  <ol> <li><code>Environment</code>, all sensors extending from <code>BaseSensor</code>, and all objects extending from <code>BaseObject</code> (which includes all robots extending from <code>BaseRobot</code>!) are <code>GymObservable</code> objects!</li> </ol> <pre><code>python -m omnigibson.examples.objects.draw_bounding_box\n</code></pre> <p>This demo loads a door object and banana object, and partially obscures the banana with the door. It generates both \"loose\" and \"tight\" bounding boxes (where the latter respects occlusions) for both objects, and dumps them to an image on disk.</p>  draw_bounding_box.py <pre><code>import logging\nimport matplotlib.pyplot as plt\nfrom collections import OrderedDict\n\nimport numpy as np\nimport omnigibson as og\nfrom omni.isaac.synthetic_utils.visualization import colorize_bboxes\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Shows how to obtain the bounding box of an articulated object.\n    Draws the bounding box around the loaded object, a cabinet, and writes the visualized image to disk at the\n    current directory named 'bbox_2d_[loose / tight]_img.png'.\n\n    NOTE: In the GUI, bounding boxes can be natively viewed by clicking on the sensor ((*)) icon at the top,\n    and then selecting the appropriate bounding box modalities, and clicking \"Show\". See:\n\n    https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator/visualization.html#the-visualizer\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Specify objects to load\n    banana_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"banana\",\n        category=\"banana\",\n        model=\"09_0\",\n        scale=[3.0, 5.0, 2.0],\n        position=[-0.906661, -0.545106,  0.136824],\n        orientation=[0, 0, 0.76040583, -0.6494482 ],\n    )\n\n    door_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"door\",\n        category=\"door\",\n        model=\"8930\",\n        position=[-2.0, 0, 0.70000001],\n        orientation=[0, 0, -0.38268343,  0.92387953],\n    )\n\n    # Create the scene config to load -- empty scene with a few objects\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [banana_cfg, door_cfg],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set camera to appropriate viewing pose\n    cam = og.sim.viewer_camera\n    cam.set_position_orientation(\n        position=np.array([-4.62785 , -0.418575,  0.933943]),\n        orientation=np.array([ 0.52196595, -0.4231939 , -0.46640436,  0.5752612 ]),\n    )\n\n    # Add bounding boxes to camera sensor\n    bbox_modalities = [\"bbox_3d\", \"bbox_2d_loose\", \"bbox_2d_tight\"]\n    for bbox_modality in bbox_modalities:\n        cam.add_modality(bbox_modality)\n\n    # Take a few steps to let objects settle\n    for i in range(100):\n        env.step(np.array([]))\n\n    # Grab observations from viewer camera and write them to disk\n    obs = cam.get_obs()\n\n    for bbox_modality in bbox_modalities:\n        # Print out each of the modalities\n        print(f\"Observation modality {bbox_modality}:\")\n        print(obs[bbox_modality])\n\n        # Also write the 2d loose bounding box to disk\n        if \"3d\" not in bbox_modality:\n            colorized_img = colorize_bboxes(bboxes_2d_data=obs[bbox_modality], bboxes_2d_rgb=obs[\"rgb\"], num_channels=4)\n            plt.imsave(f\"{bbox_modality}_img.png\", colorized_img)\n\n    # Always close environment down at end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#draw-object-bounding-box-demo"},{"title":"\ud83c\udf21\ufe0f Object States","text":"<p>These examples showcase <code>OmniGibson</code>'s powerful object states functionality, which captures both individual and relational kinematic and non-kinematic states.</p>","location":"getting_started/building_blocks.html#object-states"},{"title":"Attachment Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to leverage the <code>Attached</code> state</li> <li>Understanding how to enable objects to be <code>attachable</code></li> </ul>  <pre><code>python -m omnigibson.examples.object_states.attachment_demo\n</code></pre> <p>This demo loads an apple and a fridge, and showcases how they may or may not be attached upon contact based on their assigned attachment types.</p>  attachment_demo.py <pre><code>import numpy as np\nimport yaml\nfrom collections import OrderedDict\n\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.ui_utils import choose_from_options\nfrom omnigibson.object_states.attachment import AttachmentType\nfrom omnigibson.object_states import Attached\n\n# Make sure object states are enabled and global contact reporting is enabled\ngm.ENABLE_OBJECT_STATES = True\ngm.ENABLE_GLOBAL_CONTACT_REPORTING = True\n\n\ndef setup_scene_for_abilities(abilities1, abilities2):\n    # Make sure simulation is stopped\n    og.sim.stop()\n\n    cfg = yaml.load(open(f\"{og.example_config_path}/default_cfg.yaml\", \"r\"), Loader=yaml.FullLoader)\n\n    # Add objects that we want to create\n    light_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=5000,\n        position=[0, 0, 1.0],\n    )\n\n    apple_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"apple\",\n        category=\"apple\",\n        model=\"00_0\",\n        abilities=abilities1,\n        position=[0, 0, 0.04],\n    )\n\n    fridge_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"fridge\",\n        category=\"fridge\",\n        model=\"12252\",\n        abilities=abilities2,\n        position=[2, 0, 0.8],\n    )\n\n    cfg[\"objects\"] = [light_cfg, apple_cfg, fridge_cfg]\n\n    # Recreate the environment (this will automatically override the old environment instance)\n    # We load the default config, which is simply an Scene with no objects loaded in by default\n    env = og.Environment(configs=cfg)\n\n    # Grab apple and fridge\n    apple = env.scene.object_registry(\"name\", \"apple\")\n    fridge = env.scene.object_registry(\"name\", \"fridge\")\n\n    # Set viewer camera pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.972333, -2.0899  ,  1.0654  ]),\n        orientation=np.array([ 0.60682517, -0.24656188, -0.28443909,  0.70004632]),\n    )\n\n    # Take a few steps\n    for _ in range(5):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n    return env, apple, fridge\n\n\ndef demo_sticky_attachment():\n    ######################################################################################\n    # Sticky attachment\n    #   can attach if touching and at least one object has the sticky attachment type.\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.STICKY}},\n        abilities2={})\n    assert Attached in obj1.states\n\n    # Obj1 moves towards obj2 and they are attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        og.sim.step()\n\n    assert obj1.states[Attached].get_value(obj2)\n\n    # Apply a large force to obj1 but the two objects cannot move much because obj2 is heavy.\n    obj1.set_linear_velocity(velocity=np.array([10.0, 0, 50.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n    # Unattach obj1 and obj2.\n    obj1.states[Attached].set_value(obj2, False)\n    assert not obj1.states[Attached].get_value(obj2)\n\n    # Obj1 moves away from obj2.\n    # obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n\ndef demo_symmetric_attachment():\n    ######################################################################################\n    # Symmetric attachment\n    #   can attach if touching and both objects have the symmetric attachment type and the same attachment category\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.SYMMETRIC, \"attachment_category\": \"magnet\"}},\n        abilities2={\"attachable\": {\"attachment_type\": AttachmentType.SYMMETRIC, \"attachment_category\": \"magnet\"}})\n    assert Attached in obj1.states\n    assert Attached in obj2.states\n\n    # Obj1 moves towards obj2 and they are attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n    assert obj1.states[Attached].get_value(obj2)\n    assert obj2.states[Attached].get_value(obj1)\n\n    # Apply a large force to obj1 but the two objects cannot move much because obj2 is heavy.\n    obj1.set_linear_velocity(velocity=np.array([10.0, 0, 50.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n    # Unattach obj1 and obj2.\n    obj1.states[Attached].set_value(obj2, False)\n    assert not obj1.states[Attached].get_value(obj2)\n    assert not obj2.states[Attached].get_value(obj1)\n\n    # Obj1 moves away from obj2.\n    obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n\ndef demo_failed_symmetric_attachment_missing_symmetric():\n    ######################################################################################\n    # Symmetric attachment - FAIL because only 1 object has the symmetric attachment type\n    #   can attach if touching and both objects have the symmetric attachment type and the same attachment category\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.SYMMETRIC, \"attachment_category\": \"magnet\"}},\n        abilities2={})\n    assert Attached in obj1.states\n    assert Attached not in obj2.states\n\n    # Obj1 moves towards obj2 but they are NOT attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n    assert not obj1.states[Attached].get_value(obj2)\n\n    # Obj1 moves away from obj2.\n    obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n\ndef demo_failed_symmetric_attachment_diff_categories():\n    ######################################################################################\n    # Symmetric attachment - FAIL because the two objects have different attachment category\n    #   can attach if touching and both objects have the symmetric attachment type and the same attachment category\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.SYMMETRIC, \"attachment_category\": \"magnet\"}},\n        abilities2={\"attachable\": {\"attachment_type\": AttachmentType.SYMMETRIC, \"attachment_category\": \"velcro\"}})\n    assert Attached in obj1.states\n    assert Attached in obj2.states\n\n    # Obj1 moves towards obj2 but they are NOT attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n    assert not obj1.states[Attached].get_value(obj2)\n\n    # Obj1 moves away from obj2.\n    obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n\ndef demo_male_female_attachment():\n    ######################################################################################\n    # Male / female attachment\n    #   can attach if touching, both have the opposite end (male / female) but the same attachment category\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.MALE, \"attachment_category\": \"usb\"}},\n        abilities2={\"attachable\": {\"attachment_type\": AttachmentType.FEMALE, \"attachment_category\": \"usb\"}})\n    assert Attached in obj1.states\n    assert Attached in obj2.states\n\n    # Obj1 moves towards obj2 and they are attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n    assert obj1.states[Attached].get_value(obj2)\n    assert obj2.states[Attached].get_value(obj1)\n\n    # Apply a large force to obj1 but the two objects cannot move much because obj2 is heavy.\n    obj1.set_linear_velocity(velocity=np.array([10.0, 0, 50.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n    # Unattach obj1 and obj2.\n    obj1.states[Attached].set_value(obj2, False)\n    assert not obj1.states[Attached].get_value(obj2)\n    assert not obj2.states[Attached].get_value(obj1)\n\n    # Obj1 moves away from obj2.\n    obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n\ndef demo_failed_male_female_attachment_missing_opposite_end():\n    ######################################################################################\n    # Male / female attachment - FAIL because both objects are male.\n    #   can attach if touching, both have the opposite end (male / female) but the same attachment category\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.MALE, \"attachment_category\": \"usb\"}},\n        abilities2={\"attachable\": {\"attachment_type\": AttachmentType.MALE, \"attachment_category\": \"usb\"}})\n    assert Attached in obj1.states\n    assert Attached in obj2.states\n\n    # Obj1 moves towards obj2 and but they are NOT attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n    assert not obj1.states[Attached].get_value(obj2)\n\n    # Obj1 moves away from obj2.\n    obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n\ndef demo_failed_male_female_attachment_diff_categories():\n    ######################################################################################\n    # Male / female attachment - FAIL because the two objects have different attachment category\n    #   can attach if touching, both have the opposite end (male / female) but the same attachment category\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.MALE, \"attachment_category\": \"usb\"}},\n        abilities2={\"attachable\": {\"attachment_type\": AttachmentType.FEMALE, \"attachment_category\": \"hdmi\"}})\n    assert Attached in obj1.states\n    assert Attached in obj2.states\n\n    # Obj1 moves towards obj2 and but they are NOT attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n    assert not obj1.states[Attached].get_value(obj2)\n\n    # Obj1 moves away from obj2.\n    obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n\ndef demo_male_female_attachment_dump_load():\n    ######################################################################################\n    # Male / female attachment with dump_state and load_state\n    #   can attach if touching, both have the opposite end (male / female) but the same attachment category\n    ######################################################################################\n    env, obj1, obj2 = setup_scene_for_abilities(\n        abilities1={\"attachable\": {\"attachment_type\": AttachmentType.MALE, \"attachment_category\": \"usb\"}},\n        abilities2={\"attachable\": {\"attachment_type\": AttachmentType.FEMALE, \"attachment_category\": \"usb\"}})\n    assert Attached in obj1.states\n    assert Attached in obj2.states\n\n    # Obj1 moves towards obj2 and they are attached together.\n    obj1.set_linear_velocity(velocity=np.array([3.0, 0, 3.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n    assert obj1.states[Attached].get_value(obj2)\n    assert obj2.states[Attached].get_value(obj1)\n\n    # Save the state.\n    state = og.sim.dump_state()\n\n    # Apply a large force to obj1 but the two objects cannot move much because obj2 is heavy.\n    obj1.set_linear_velocity(velocity=np.array([10.0, 0, 50.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n    # Unattach obj1 and obj2.\n    obj1.states[Attached].set_value(obj2, False)\n    assert not obj1.states[Attached].get_value(obj2)\n    assert not obj2.states[Attached].get_value(obj1)\n\n    # Obj1 moves away from obj2.\n    obj1.set_linear_velocity(velocity=np.array([-2.0, 0, 1.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\n    # Load the state where the two objects are attached.\n    og.sim.load_state(state)\n\n    # Attached state should be restored correctly\n    assert obj1.states[Attached].get_value(obj2)\n    assert obj2.states[Attached].get_value(obj1)\n\n    # Apply a large force to obj1 but the two objects cannot move much because obj2 is heavy.\n    obj1.set_linear_velocity(velocity=np.array([10.0, 0, 50.0]))\n    for i in range(100):\n        env.step(np.array([]))  # empty action array since action space is 0 (no robots in the env)\n\ndemo_names_to_demos = {\n    \"demo_sticky_attachment\": demo_sticky_attachment,\n    \"demo_symmetric_attachment\": demo_symmetric_attachment,\n    \"demo_failed_symmetric_attachment_missing_symmetric\": demo_failed_symmetric_attachment_missing_symmetric,\n    \"demo_failed_symmetric_attachment_diff_categories\": demo_failed_symmetric_attachment_diff_categories,\n    \"demo_male_female_attachment\": demo_male_female_attachment,\n    \"demo_failed_male_female_attachment_missing_opposite_end\": demo_failed_male_female_attachment_missing_opposite_end,\n    \"demo_failed_male_female_attachment_diff_categories\": demo_failed_male_female_attachment_diff_categories,\n    \"demo_male_female_attachment_dump_load\": demo_male_female_attachment_dump_load,\n}\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    # Loop indefinitely and choose different examples to run\n    for i in range(len(demo_names_to_demos)):\n        demo_name = choose_from_options(options=list(demo_names_to_demos.keys()), name=\"attachment demo\")\n        # Run the demo\n        demo_names_to_demos[demo_name]()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#attachment-demo"},{"title":"Cleaning Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how <code>WaterSource</code>-enabled objects can be toggled on to generate water particles</li> <li>Understanding how to programmatically generate <code>Stain</code> and <code>Dusty</code> particles on objects</li> <li>Understanding how particles can be removed via a <code>ParticleRemover</code> object</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.cleaning_demo\n</code></pre> <p>This demo first loads a basic cube object with the ability to remove particles into fully populated scene, and then spawns dust and stain particles on various objects and turns on the sink. You can then move (1) the cube object around to first absorb water particles so that it's \"soaked\" with water, and then can drag it across objects with dust or stain particles to remove them.</p> <ol> <li>Manipulate the object by holding down <code>Shift</code> and then <code>Left-click + Drag</code>!</li> </ol>  cleaning_demo.py <pre><code>import logging\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\nfrom omnigibson.systems import DustSystem, StainSystem, WaterSystem\nfrom omnigibson.utils.constants import ParticleModifyMethod\n\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of a cleaning task\n    Loads an interactive scene and sets all object surface to be dirty\n    Loads also a cleaning tool that can be soaked in water and used to clean objects if moved manually\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- Rs_int with only a few object categories loaded, as\n    # well as a custom block object that will be used as a cleaning tool\n    def check_water_saturation(obj):\n        return obj.states[object_states.Saturated].get_value(WaterSystem)\n\n    cfg = {\n        \"scene\": {\n            \"type\": \"InteractiveTraversableScene\",\n            \"scene_model\": \"Rs_int\",\n            \"load_object_categories\": [\"floors\", \"walls\", \"ceilings\", \"breakfast_table\", \"bottom_cabinet\", \"sink\", \"stove\", \"fridge\", \"window\"],\n        },\n        \"objects\": [\n            # A cleaning tool (cuboid) with the ability to be saturated and remove stain, dust, and water particles\n            {\n                \"type\": \"PrimitiveObject\",\n                \"name\": \"block\",\n                \"primitive_type\": \"Cube\",\n                \"scale\": [0.15, 0.1, 0.03],\n                \"rgba\": [0.5, 1.0, 1.0, 1.0],\n                \"abilities\": {\n                    \"saturable\": {},\n                    \"particleRemover\": {\n                        \"method\": ParticleModifyMethod.ADJACENCY,\n                        \"conditions\": {\n                            # For a specific particle system, this specifies what conditions are required in order for the\n                            # particle applier / remover to apply / remover particles associated with that system\n                            # The list should contain functions with signature condition() --&gt; bool,\n                            # where True means the condition is satisfied\n                            # In this case, we only allow our cleaning tool to remove stains and dust particles if\n                            # the object is saturated with water, i.e.: it's \"soaked\" with water particles\n                            StainSystem: [check_water_saturation],\n                            DustSystem: [check_water_saturation],\n                            WaterSystem: [],\n                        },\n                    },\n                },\n                \"position\": [-1.4, 3.0, 1.5],\n            },\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set everything that can go dirty and activate the water sources\n    dusty_objects = env.scene.object_registry(\"category\", \"breakfast_table\")\n    stained_objects = env.scene.object_registry(\"category\", \"bottom_cabinet\")\n    water_source_objects = env.scene.get_objects_with_state(object_states.WaterSource)\n\n    for obj in dusty_objects:\n        logging.info(f\"Setting object {obj.name} to be Dusty\")\n        obj.states[object_states.Covered].set_value(DustSystem, True)\n\n    for obj in stained_objects:\n        logging.info(f\"Setting object {obj.name} to be Stained\")\n        obj.states[object_states.Covered].set_value(StainSystem, True)\n\n    for obj in water_source_objects:\n        if object_states.ToggledOn in obj.states:\n            logging.info(f\"Setting water source object {obj} to be ToggledOn\")\n            obj.states[object_states.ToggledOn].set_value(True)\n\n    # Set the camera to be in a good position\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.825556,  2.42499 ,  1.04104 ]),\n        orientation=np.array([0.56919735, 0.09896035, 0.13981109, 0.80416049]),\n    )\n\n    max_steps = -1 if not short_exec else 1000\n    step = 0\n    try:\n        for i in range(200):\n            env.step(np.array([]))\n        while step != max_steps:\n            env.step(np.array([]))      # Empty action since no robots in the environment\n            step += 1\n    finally:\n        # Always close environment at the end\n        env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#cleaning-demo"},{"title":"Simple Cleaning Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how <code>WaterSource</code>-enabled objects can be toggled on to generate water particles</li> <li>Understanding how to programmatically generate <code>Stain</code> and <code>Dusty</code> particles on objects</li> <li>Understanding how particles can be removed via a <code>ParticleRemover</code> object</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.cleaning_demo_simple\n</code></pre> <p>This demo is similar in functionality to the full cleaning demo, but instead of loading a fully populated scene only a select few objects are loaded. In this case, the loaded <code>scrub_brush</code> object is the <code>ParticleRemover</code> object. As before, you can move (1) the brush around to first absorb water particles so that it's \"soaked\" with water, and then can drag it across objects with dust or stain particles to remove them.</p> <ol> <li>Manipulate the object by holding down <code>Shift</code> and then <code>Left-click + Drag</code>!</li> </ol>  cleaning_demo_simple.py <pre><code>import logging\nfrom collections import OrderedDict\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\nfrom omnigibson.systems import DustSystem, StainSystem, WaterSystem\nfrom omnigibson.utils.constants import ParticleModifyMethod\n\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of a cleaning task that resets after everything has been cleaned\n    Loads an empty scene with a sink, a dusty table and a dirty and stained bowl, and a cleaning tool\n    If everything is cleaned, or after N steps, the scene resets to the initial state\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        }\n    }\n\n    # Define objects to load into the environment\n    sink_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"sink\",\n        category=\"sink\",\n        model=\"sink_1\",\n        scale=[0.8, 0.8, 0.8],\n        abilities={\"toggleable\": {}, \"waterSource\": {}, \"waterSink\": {}},\n        position=[-0.7, 0, 0.53],\n    )\n\n    def check_water_saturation(obj):\n        return obj.states[object_states.Saturated].get_value(WaterSystem)\n\n    brush_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"brush\",\n        category=\"scrub_brush\",\n        model=\"scrub_brush_000\",\n        avg_obj_dims={\"size\": [0.1, 0.1, 0.1], \"density\": 67.0},\n        fit_avg_dim_volume=True,\n        position=[1.0, 0, 0.4],\n        abilities={\n            \"saturable\": {},\n            \"particleRemover\": {\n                \"method\": ParticleModifyMethod.ADJACENCY,\n                \"conditions\": {\n                    # For a specific particle system, this specifies what conditions are required in order for the\n                    # particle applier / remover to apply / remover particles associated with that system\n                    # The list should contain functions with signature condition() --&gt; bool,\n                    # where True means the condition is satisfied\n                    # In this case, we only allow our cleaning tool to remove stains and dust particles if\n                    # the object is saturated with water, i.e.: it's \"soaked\" with water particles\n                    StainSystem: [check_water_saturation],\n                    DustSystem: [check_water_saturation],\n                    WaterSystem: [],\n                },\n            },\n        },\n    )\n\n    # Desk that's dusty\n    desk_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"desk\",\n        category=\"breakfast_table\",\n        model=\"19203\",\n        scale=[0.8, 0.8, 0.8],\n        position=[1.0, 0, 0.48],\n    )\n\n    # Bowl with stains\n    bowl_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"bowl\",\n        category=\"bowl\",\n        model=\"68_0\",\n        scale=np.array([0.8, 0.8, 0.8]),\n        position=[-1.0, 0, 0.48],\n    )\n\n    cfg[\"objects\"] = [sink_cfg, brush_cfg, desk_cfg, bowl_cfg]\n\n    # Create the environment!\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set camera to ideal angle for viewing objects\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.782289, -0.633009,  1.4475  ]),\n        orientation=np.array([ 0.48871723, -0.24618907, -0.37654978,  0.74750028]),\n    )\n\n    # Take a few steps to let the objects settle, and then sanity check the initial state\n    for _ in range(10):\n        env.step(np.array([]))              # Empty action since no robots are in the scene\n\n    sink = env.scene.object_registry(\"name\", \"sink\")\n    brush = env.scene.object_registry(\"name\", \"brush\")\n    desk = env.scene.object_registry(\"name\", \"desk\")\n    bowl = env.scene.object_registry(\"name\", \"bowl\")\n\n    assert sink.states[object_states.ToggledOn].set_value(True)\n    assert desk.states[object_states.Covered].set_value(DustSystem, True)\n    assert bowl.states[object_states.OnTop].set_value(desk, True, use_ray_casting_method=True)\n    assert brush.states[object_states.OnTop].set_value(desk, True, use_ray_casting_method=True)\n    assert bowl.states[object_states.Covered].set_value(StainSystem, True)\n\n    # Take a step, and save the state\n    env.step(np.array([]))\n    initial_state = og.sim.dump_state()\n\n    # Main simulation loop.\n    max_steps = 1000\n    max_iterations = -1 if not short_exec else 1\n    iteration = 0\n    try:\n        while iteration != max_iterations:\n            # Keep stepping until table or bowl are clean, or we reach 1000 steps\n            steps = 0\n            while (\n                desk.states[object_states.Covered].get_value(DustSystem)\n                and bowl.states[object_states.Covered].get_value(StainSystem)\n                and steps != max_steps\n            ):\n                steps += 1\n                env.step(np.array([]))\n                logging.info(f\"Step {steps}\")\n\n            if not desk.states[object_states.Covered].get_value(DustSystem):\n                logging.info(\"Reset because Table cleaned\")\n            elif not bowl.states[object_states.Covered].get_value(StainSystem):\n                logging.info(\"Reset because Bowl cleaned\")\n            else:\n                logging.info(\"Reset because max steps\")\n\n            # Reset to the initial state\n            og.sim.load_state(initial_state)\n\n            iteration += 1\n\n    finally:\n        # Always shut down environment at the end\n        env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#simple-cleaning-demo"},{"title":"Folded Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load a softbody (cloth) version of a BEHAVIOR dataset object</li> <li>Understanding how to enable cloth objects to be <code>foldable</code> </li> <li>Understanding the current heuristics used for gauging a cloth's \"foldness\"</li> </ul>   <p>This is a beta feature</p> <p>Our <code>Folded</code> state is still a WIP, and should not be used to accurately capture the full semantics of folding cloth-enabled objects.</p>  <pre><code>python -m omnigibson.examples.object_states.folded_state_demo\n</code></pre> <p>This demo loads in three different cloth objects, and allows you to manipulate them (1) while printing out their <code>Folded</code> state status in real-time.</p> <ol> <li>Manipulate the object by holding down <code>Shift</code> and then <code>Left-click + Drag</code>!</li> </ol>  folded_state_demo.py <pre><code>from omnigibson.utils.constants import PrimType\nfrom omnigibson.object_states import Folded\nfrom omnigibson.macros import gm\nimport logging\n\nimport omnigibson as og\n\n# Make sure object states and GPU dynamics are enabled (GPU dynamics needed for cloth)\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of cloth objects that can potentially be folded.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene + custom cloth object\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"carpet\",\n                \"category\": \"carpet\",\n                \"model\": \"carpet_0\",\n                \"prim_type\": PrimType.CLOTH,\n                \"abilities\": {\"foldable\": {}},\n                \"position\": [0, 0, 0.5],\n            },\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"dishtowel\",\n                \"category\": \"dishtowel\",\n                \"model\": \"Tag_Dishtowel_Basket_Weave_Red\",\n                \"prim_type\": PrimType.CLOTH,\n                \"scale\": 5.0,\n                \"abilities\": {\"foldable\": {}},\n                \"position\": [1, 1, 0.5],\n            },\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"shirt\",\n                \"category\": \"t-shirt\",\n                \"model\": \"t-shirt_000\",\n                \"prim_type\": PrimType.CLOTH,\n                \"scale\": 0.05,\n                \"abilities\": {\"foldable\": {}},\n                \"position\": [-1, 1, 0.5],\n                \"orientation\": [0.7071, 0., 0.7071, 0.],\n            },\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n\n    # Grab object references\n    carpet = env.scene.object_registry(\"name\", \"carpet\")\n    dishtowel = env.scene.object_registry(\"name\", \"dishtowel\")\n    shirt = env.scene.object_registry(\"name\", \"shirt\")\n\n    max_steps = 100 if short_exec else -1\n    steps = 0\n\n    # Criterion #1: the area of the convex hull of the projection of points onto the x-y plane should be reduced\n    # Criterion #2: the diagonal of the convex hull of the projection of points onto the x-y plane should be reduced\n    # Criterion #3: the face normals of the cloth should mostly point along the z-axis\n    while steps != max_steps:\n        og.sim.step()\n\n        flag_area_reduction, flag_diagonal_reduction = carpet.states[Folded].check_projection_area_and_diagonal()\n        flag_smoothness = carpet.states[Folded].check_smoothness()\n        folded = flag_area_reduction and flag_diagonal_reduction and flag_smoothness\n        info = 'carpet: [folded] %d [A] %d [D] %d [S] %d' % (folded, flag_area_reduction, flag_diagonal_reduction, flag_smoothness)\n\n        flag_area_reduction, flag_diagonal_reduction = dishtowel.states[Folded].check_projection_area_and_diagonal()\n        flag_smoothness = dishtowel.states[Folded].check_smoothness()\n        folded = flag_area_reduction and flag_diagonal_reduction and flag_smoothness\n        info += \" || dishtowel: [folded] %d [A] %d [D] %d [S] %d\" % (folded, flag_area_reduction, flag_diagonal_reduction, flag_smoothness)\n\n        flag_area_reduction, flag_diagonal_reduction = shirt.states[Folded].check_projection_area_and_diagonal()\n        flag_smoothness = shirt.states[Folded].check_smoothness()\n        folded = flag_area_reduction and flag_diagonal_reduction and flag_smoothness\n        info += \" || tshirt: [folded] %d [A] %d [D] %d [S] %d\" % (folded, flag_area_reduction, flag_diagonal_reduction, flag_smoothness)\n\n        print(info)\n        steps += 1\n\n    # Shut down env at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#folded-demo"},{"title":"Temperature Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to dynamically sample kinematic states for BEHAVIOR dataset objects</li> <li>Understanding how temperature changes are propagated to individual objects from individual heat sources or sinks</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.temperature_demo\n</code></pre> <p>This demo loads in various heat sources and sinks, and places an apple within close proximity to each of them. As the environment steps, each apple's temperature is printed in real-time, showcasing <code>OmniGibson</code>'s rudimentary temperature dynamics.</p>  temperature_demo.py <pre><code>import logging\nfrom collections import OrderedDict\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of temperature change\n    Loads a stove, a microwave and an oven, all toggled on, and five frozen apples\n    The user can move the apples to see them change from frozen, to normal temperature, to cooked and burnt\n    This demo also shows how to load objects ToggledOn and how to set the initial temperature of an object\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Define specific objects we want to load in with the scene directly\n    obj_configs = []\n\n    # Light\n    obj_configs.append(OrderedDict(\n        type=\"LightObject\",\n        light_type=\"Sphere\",\n        name=\"light\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, -2.0, 1.0],\n    ))\n\n    # Stove\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"stove\",\n        category=\"stove\",\n        model=\"101943\",\n        position=[0, 0, 0.65],\n    ))\n\n    # Microwave\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"microwave\",\n        category=\"microwave\",\n        model=\"7128\",\n        scale=0.25,\n        position=[2.5, 0, 0.094],\n    ))\n\n    # Oven\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"oven\",\n        category=\"oven\",\n        model=\"7120\",\n        position=[-1.25, 0, 0.80],\n    ))\n\n    # Tray\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"tray\",\n        category=\"tray\",\n        model=\"tray_000\",\n        scale=0.15,\n        position=[0, 0, 1.24],\n    ))\n\n    # Fridge\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"fridge\",\n        category=\"fridge\",\n        model=\"12252\",\n        abilities={\n            \"coldSource\": {\n                \"temperature\": -100.0,\n                \"requires_inside\": True,\n            }\n        },\n        position=[1.25, 0, 0.90],\n    ))\n\n    # 5 Apples\n    for i in range(5):\n        obj_configs.append(OrderedDict(\n            type=\"DatasetObject\",\n            name=f\"apple{i}\",\n            category=\"apple\",\n            model=\"00_0\",\n            position=[0, i * 0.05, 1.65],\n        ))\n\n    # Create the scene config to load -- empty scene with desired objects\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": obj_configs,\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n\n    # Get reference to relevant objects\n    stove = env.scene.object_registry(\"name\", \"stove\")\n    microwave = env.scene.object_registry(\"name\", \"microwave\")\n    oven = env.scene.object_registry(\"name\", \"oven\")\n    tray = env.scene.object_registry(\"name\", \"tray\")\n    fridge = env.scene.object_registry(\"name\", \"fridge\")\n    apples = list(env.scene.object_registry(\"category\", \"apple\"))\n\n    # Set camera to appropriate viewing pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([ 0.46938863, -3.97887141,  1.64106008]),\n        orientation=np.array([0.63311689, 0.00127259, 0.00155577, 0.77405359]),\n    )\n\n    # Let objects settle\n    for _ in range(25):\n        env.step(np.array([]))\n\n    # Turn on all scene objects\n    stove.states[object_states.ToggledOn].set_value(True)\n    microwave.states[object_states.ToggledOn].set_value(True)\n    oven.states[object_states.ToggledOn].set_value(True)\n\n    # Set initial temperature of the apples to -50 degrees Celsius, and move the apples to different objects\n    for apple in apples:\n        apple.states[object_states.Temperature].set_value(-50)\n    apples[0].states[object_states.Inside].set_value(oven, True, use_ray_casting_method=True)\n    apples[1].set_position(stove.links[\"heat_source_link\"].get_position() + np.array([0, 0, 0.1]))\n    apples[2].states[object_states.OnTop].set_value(tray, True, use_ray_casting_method=True)\n    apples[3].states[object_states.Inside].set_value(fridge, True, use_ray_casting_method=True)\n    apples[4].states[object_states.Inside].set_value(microwave, True, use_ray_casting_method=True)\n\n    steps = 0\n    max_steps = -1 if not short_exec else 1000\n\n    # Main recording loop\n    locations = [f'{loc:&gt;20}' for loc in [\"Inside oven\", \"On stove\", \"On tray\", \"Inside fridge\", \"Inside microwave\"]]\n    print()\n    print(f\"{'Apple location:':&lt;20}\", *locations)\n    while steps != max_steps:\n        env.step(np.array([]))\n        temps = [f\"{apple.states[object_states.Temperature].get_value():&gt;20.2f}\" for apple in apples]\n        print(f\"{'Apple temperature:':&lt;20}\", *temps, end=\"\\r\")\n        steps += 1\n\n    # Always close env at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#temperature-demo"},{"title":"Heat Source or Sink Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how a heat source (or sink) is visualized in <code>OmniGibson</code></li> <li>Understanding how dynamic fire visuals are generated in real-time</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.heat_source_or_sink_demo\n</code></pre> <p>This demo loads in a stove and toggles its <code>HeatSource</code> on and off, showcasing the dynamic fire visuals available in <code>OmniGibson</code>.</p>  heat_source_or_sink_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\n\n\ndef main():\n    # Create the scene config to load -- empty scene with a stove object added\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"stove\",\n                \"category\": \"stove\",\n                \"model\": \"101908\",\n                \"abilities\": {\n                    \"heatSource\": {\"requires_toggled_on\": True},\n                    \"toggleable\": {},\n                },\n                \"position\": [0, 0, 0.4],\n            }\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Get reference to stove object\n    stove = env.scene.object_registry(\"name\", \"stove\")\n\n    # Set camera to appropriate viewing pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.0792399, -1.30104, 1.51981]),\n        orientation=np.array([0.54897692, 0.00110359, 0.00168013, 0.83583509]),\n    )\n\n    # Make sure necessary object states are included with the stove\n    assert object_states.HeatSourceOrSink in stove.states\n    assert object_states.ToggledOn in stove.states\n\n    # Take a few steps so that visibility propagates\n    for _ in range(5):\n        env.step(np.array([]))\n\n    # Heat source is off.\n    print(\"Heat source is OFF.\")\n    heat_source_state, heat_source_position = stove.states[object_states.HeatSourceOrSink].get_value()\n    assert not heat_source_state\n\n    # Toggle on stove, notify user\n    input(\"Heat source will now turn ON: Press ENTER to continue.\")\n    stove.states[object_states.ToggledOn].set_value(True)\n\n    assert stove.states[object_states.ToggledOn].get_value()\n\n    # Need to take a step to update the state.\n    env.step(np.array([]))\n\n    # Heat source is on\n    heat_source_state, heat_source_position = stove.states[object_states.HeatSourceOrSink].get_value()\n    assert heat_source_state\n    for _ in range(500):\n        env.step(np.array([]))\n\n    # Toggle off stove, notify user\n    input(\"Heat source will now turn OFF: Press ENTER to continue.\")\n    stove.states[object_states.ToggledOn].set_value(False)\n    assert not stove.states[object_states.ToggledOn].get_value()\n    for _ in range(200):\n        env.step(np.array([]))\n\n    # Move stove, notify user\n    input(\"Heat source is now moving: Press ENTER to continue.\")\n    stove.set_position(np.array([0, 1.0, 0.4]))\n    for i in range(100):\n        env.step(np.array([]))\n\n    # Toggle on stove again, notify user\n    input(\"Heat source will now turn ON: Press ENTER to continue.\")\n    stove.states[object_states.ToggledOn].set_value(True)\n    assert stove.states[object_states.ToggledOn].get_value()\n    for i in range(500):\n        env.step(np.array([]))\n\n    # Shutdown environment at end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#heat-source-or-sink-demo"},{"title":"Heated Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how temperature modifications can cause objects' visual changes</li> <li>Understanding how dynamic steam visuals are generated in real-time</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.heated_state_demo\n</code></pre> <p>This demo loads in three bowls, and immediately sets their temperatures past their <code>Heated</code> threshold. Steam is generated in real-time from these objects, and then disappears once the temperature of the objects drops below their <code>Heated</code> threshold.</p>  heated_state_demo.py <pre><code>import numpy as np\nfrom collections import OrderedDict\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\n\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\n\n\ndef main():\n    # Define object configurations for objects to load -- we want to load a light and three bowls\n    obj_configs = []\n\n    obj_configs.append(OrderedDict(\n        type=\"LightObject\",\n        light_type=\"Sphere\",\n        name=\"light\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, -2.0, 1.0],\n    ))\n\n    for i, (scale, x) in enumerate(zip([0.5, 1.0, 2.0], [-0.6, 0, 0.8])):\n        obj_configs.append(OrderedDict(\n            type=\"DatasetObject\",\n            name=f\"bowl{i}\",\n            category=\"bowl\",\n            model=\"68_0\",\n            scale=scale,\n            abilities={\"heatable\": {}},\n            position=[x, 0, 0.2],\n        ))\n\n    # Create the scene config to load -- empty scene with light object and bowls\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": obj_configs,\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set camera to appropriate viewing pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([ 0.182103, -2.07295 ,  0.14017 ]),\n        orientation=np.array([0.77787037, 0.00267566, 0.00216149, 0.62841535]),\n    )\n\n    # Grab reference to objects of relevance\n    objs = list(env.scene.object_registry(\"category\", \"bowl\"))\n\n    def report_states(objs):\n        for obj in objs:\n            print(\"=\" * 20)\n            print(\"object:\", obj.name)\n            print(\"temperature:\", obj.states[object_states.Temperature].get_value())\n            print(\"obj is heated:\", obj.states[object_states.Heated].get_value())\n\n    # Report default states\n    print(\"==== Initial state ====\")\n    report_states(objs)\n\n    # Notify user that we're about to heat the object\n    input(\"Objects will be heated, and steam will slowly rise. Press ENTER to continue.\")\n\n    # Heated.\n    for obj in objs:\n        obj.states[object_states.Temperature].set_value(50)\n    env.step(np.array([]))\n    report_states(objs)\n\n    # Take a look at the steam effect.\n    # After a while, objects will be below the Steam temperature threshold.\n    print(\"==== Objects are now heated... ====\")\n    print()\n    for _ in range(2000):\n        env.step(np.array([]))\n        # Also print temperatures\n        temps = [f\"{obj.states[object_states.Temperature].get_value():&gt;7.2f}\" for obj in objs]\n        print(f\"obj temps:\", *temps, end=\"\\r\")\n    print()\n\n    # Objects are not heated anymore.\n    print(\"==== Objects are no longer heated... ====\")\n    report_states(objs)\n\n    # Close environment at the end\n    input(\"Demo completed. Press ENTER to shutdown environment.\")\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#heated-demo"},{"title":"Object Texture Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how different object states can result in texture changes</li> <li>Understanding how to enable objects with texture-changing states</li> <li>Understanding how to dynamically modify object states</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.object_state_texture_demo\n</code></pre> <p>This demo loads in a single object, and then dynamically modifies its state so that its texture changes with each modification.</p>  object_state_texture_demo.py <pre><code>import numpy as np\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm, macros\nfrom omnigibson.systems import WaterSystem\nfrom omnigibson.utils.constants import ParticleModifyMethod\n\n# Make sure object states are enabled\ngm.ENABLE_OBJECT_STATES = True\n\n\ndef main():\n    # Create the scene config to load -- empty scene plus a light and a cabinet\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n            \"floor_plane_visible\": True,\n        },\n        \"objects\": [\n            {\n                \"type\": \"LightObject\",\n                \"name\": \"light\",\n                \"light_type\": \"Sphere\",\n                \"radius\": 0.01,\n                \"intensity\": 1e5,\n                \"position\": [-2.0, -2.0, 1.0],\n            },\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"cabinet\",\n                \"category\": \"bottom_cabinet\",\n                \"model\": \"45087\",\n                \"abilities\": {\n                    \"freezable\": {},\n                    \"cookable\": {},\n                    \"burnable\": {},\n                    \"saturable\": {},\n                    \"toggleable\": {},\n                    \"particleRemover\": {\n                        \"method\": ParticleModifyMethod.ADJACENCY,\n                        \"conditions\": {\n                            # For a specific particle system, this specifies what conditions are required in order for the\n                            # particle applier / remover to apply / remover particles associated with that system\n                            # The list should contain functions with signature condition() --&gt; bool,\n                            # where True means the condition is satisfied\n                            # In this case, we only allow our cabinet to absorb water, with no conditions needed.\n                            # This is needed for the Saturated (\"saturable\") state so that we can modify the texture\n                            # according to the water.\n                            # NOTE: This will only change color if gm.ENABLE_HQ_RENDERING and gm.USE_GPU_DYNAMICS is\n                            # enabled!\n                            WaterSystem: [],\n                        },\n            },\n                },\n                \"position\": [0, 0, 0.55],\n            },\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set camera to appropriate viewing pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([ 1.7789 , -1.68822,  1.13551]),\n        orientation=np.array([0.57065614, 0.20331904, 0.267029  , 0.74947212]),\n    )\n\n    # Grab reference to object of interest\n    obj = env.scene.object_registry(\"name\", \"cabinet\")\n\n    # Make sure all the appropriate states are in the object\n    assert object_states.Frozen in obj.states\n    assert object_states.Cooked in obj.states\n    assert object_states.Burnt in obj.states\n    assert object_states.Saturated in obj.states\n    assert object_states.ToggledOn in obj.states\n\n    def report_states():\n        # Make sure states are propagated before printing\n        for i in range(5):\n            env.step(np.array([]))\n\n        print(\"=\" * 20)\n        print(\"temperature:\", obj.states[object_states.Temperature].get_value())\n        print(\"obj is frozen:\", obj.states[object_states.Frozen].get_value())\n        print(\"obj is cooked:\", obj.states[object_states.Cooked].get_value())\n        print(\"obj is burnt:\", obj.states[object_states.Burnt].get_value())\n        print(\"obj is soaked:\", obj.states[object_states.Saturated].get_value(WaterSystem))\n        print(\"obj is toggledon:\", obj.states[object_states.ToggledOn].get_value())\n        print(\"obj textures:\", obj.get_textures())\n\n    # Report default states\n    print(\"==== Initial state ====\")\n    report_states()\n\n    # Notify user that we're about to freeze the object, and then freeze the object\n    input(\"\\nObject will be frozen. Press ENTER to continue.\")\n    obj.states[object_states.Temperature].set_value(-50)\n    report_states()\n\n    # Notify user that we're about to cook the object, and then cook the object\n    input(\"\\nObject will be cooked. Press ENTER to continue.\")\n    obj.states[object_states.Temperature].set_value(100)\n    report_states()\n\n    # Notify user that we're about to burn the object, and then burn the object\n    input(\"\\nObject will be burned. Press ENTER to continue.\")\n    obj.states[object_states.Temperature].set_value(250)\n    report_states()\n\n    # Notify user that we're about to reset the object to its default state, and then reset state\n    input(\"\\nObject will be reset to default state. Press ENTER to continue.\")\n    obj.states[object_states.Temperature].set_value(macros.object_states.temperature.DEFAULT_TEMPERATURE)\n    obj.states[object_states.MaxTemperature].set_value(macros.object_states.temperature.DEFAULT_TEMPERATURE)\n    report_states()\n\n    # Notify user that we're about to soak the object, and then soak the object\n    input(\"\\nObject will be saturated with water. Press ENTER to continue.\")\n    obj.states[object_states.Saturated].set_value(WaterSystem, True)\n    report_states()\n\n    # Notify user that we're about to unsoak the object, and then unsoak the object\n    input(\"\\nObject will be unsaturated with water. Press ENTER to continue.\")\n    obj.states[object_states.Saturated].set_value(WaterSystem, False)\n    report_states()\n\n    # Notify user that we're about to toggle on the object, and then toggle on the object\n    input(\"\\nObject will be toggled on. Press ENTER to continue.\")\n    obj.states[object_states.ToggledOn].set_value(True)\n    report_states()\n\n    # Notify user that we're about to toggle off the object, and then toggle off the object\n    input(\"\\nObject will be toggled off. Press ENTER to continue.\")\n    obj.states[object_states.ToggledOn].set_value(False)\n    report_states()\n\n    # Close environment at the end\n    input(\"Demo completed. Press ENTER to shutdown environment.\")\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#object-texture-demo"},{"title":"Particle Applier and Remover Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how a <code>ParticleRemover</code> or <code>ParticleApplier</code> object can be generated</li> <li>Understanding how particles can be dynamically generated on objects</li> <li>Understanding different methods for applying and removing particles via the <code>ParticleRemover</code> or <code>ParticleApplier</code> object</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.particle_applier_remover_demo\n</code></pre> <p>This demo loads in a washtowel and table and lets you choose the ability configuration to enable the washtowel with. The washtowel will then proceed to either remove and generate particles dynamically on the table while moving.</p>  particle_applier_remover_demo.py <pre><code>import logging\nimport numpy as np\nimport omnigibson as og\nfrom omnigibson.object_states import Covered\nfrom omnigibson.objects import DatasetObject\nfrom omnigibson.macros import gm, macros\nfrom omnigibson.systems import *\nfrom omnigibson.utils.usd_utils import create_joint\nfrom omnigibson.utils.ui_utils import choose_from_options\nfrom omnigibson.utils.constants import ParticleModifyMethod\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom pxr import Gf\n\n# Set macros for this example\nmacros.object_states.particle_modifier.VISUAL_PARTICLES_REMOVAL_LIMIT = 1000\nmacros.object_states.particle_modifier.FLUID_PARTICLES_REMOVAL_LIMIT = 8000\nmacros.object_states.particle_modifier.MAX_VISUAL_PARTICLES_APPLIED_PER_STEP = 10\nmacros.object_states.particle_modifier.MAX_FLUID_PARTICLES_APPLIED_PER_STEP = 40\nStainSystem._N_PARTICLES_PER_GROUP = 300\n\n# Make sure object states and GPU dynamics are enabled (GPU dynamics needed for fluids)\ngm.ENABLE_OBJECT_STATES = True\ngm.USE_GPU_DYNAMICS = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of ParticleApplier and ParticleRemover object states, which enable objects to either apply arbitrary\n    particles and remove arbitrary particles from the simulator, respectively.\n\n    Loads an empty scene with a table, and starts clean to allow particles to be applied or pre-covers the table\n    with particles to be removed. The ParticleApplier / ParticleRemover state is applied to an imported cloth object\n    and allowed to interact with the table, applying / removing particles from the table.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose what configuration to load\n    modifier_type = choose_from_options(\n        options={\n            \"particleApplier\": \"Demo object's ability to apply particles in the simulator\",\n            \"particleRemover\": \"Demo object's ability to remove particles from the simulator\",\n        },\n        name=\"particle modifier type\",\n        random_selection=random_selection,\n    )\n\n    modification_metalink = {\n        \"particleApplier\": \"particleapplication_link\",\n        \"particleRemover\": \"particleremover_link\",\n    }\n\n    particle_mapping = {system.name: system for system in [StainSystem, WaterSystem]}\n    particle_type = choose_from_options(\n        options={name: f\"{name} particles will be applied or removed from the simulator\" for name in particle_mapping},\n        name=\"particle type\",\n        random_selection=random_selection,\n    )\n    particle_system = particle_mapping[particle_type]\n\n    modification_method = {\n        \"Adjacency\": ParticleModifyMethod.ADJACENCY,\n        \"Projection\": ParticleModifyMethod.PROJECTION,\n    }\n\n    projection_mesh_params = {\n        \"Adjacency\": None,\n        \"Projection\": {\n            # Either Cone or Cylinder; shape of the projection where particles can be applied / removed\n            \"type\": \"Cone\",\n            # Size of the cone\n            \"extents\": np.array([0.375, 0.375, 0.75]),\n        },\n    }\n\n    method_type = choose_from_options(\n        options={\n            \"Adjacency\": \"Close proximity to the object will be used to determine whether particles can be applied / removed\",\n            \"Projection\": \"A Cone or Cylinder shape protruding from the object will be used to determine whether particles can be applied / removed\",\n        },\n        name=\"modifier method type\",\n        random_selection=random_selection,\n    )\n\n    # Create the ability kwargs to pass to the object state\n    abilities = {\n        modifier_type: {\n            \"method\": modification_method[method_type],\n            \"conditions\": {\n                # For a specific particle system, this specifies what conditions are required in order for the\n                # particle applier / remover to apply / remover particles associated with that system\n                # The list should contain functions with signature condition() --&gt; bool,\n                # where True means the condition is satisified\n                particle_system: [],\n            },\n            \"projection_mesh_params\": projection_mesh_params[method_type],\n        }\n    }\n\n    # Define objects to load: a light, table, and cloth\n    light_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, -2.0, 2.0],\n    )\n\n    table_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"table\",\n        category=\"breakfast_table\",\n        model=\"265851637a59eb2f882f822c83877cbc\",\n        scale=[4.0, 4.0, 4.0],\n        position=[0, 0, 0.7],\n    )\n\n    # Create the scene config to load -- empty scene with a light and table\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [light_cfg, table_cfg],\n    }\n\n    # Sanity check inputs: Remover + Adjacency + Fluid will not work because we are using a visual_only\n    # object, so contacts will not be triggered with this object\n\n    # Load the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Grab references to table\n    table = env.scene.object_registry(\"name\", \"table\")\n\n    # Set the viewer camera appropriately\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-1.11136405, -1.12709412,  1.99587299]),\n        orientation=np.array([ 0.44662832, -0.17829795, -0.32506992,  0.81428652]),\n    )\n\n    # Let objects settle first\n    for _ in range(10):\n        env.step(np.array([]))\n\n    # If we're using a projection volume, we manually add in the required metalink required in order to use the volume\n    modifier = DatasetObject(\n        prim_path=\"/World/modifier\",\n        name=\"modifier\",\n        category=\"dishtowel\",\n        model=\"Tag_Dishtowel_Basket_Weave_Red\",\n        scale=np.ones(3) * 2.0,\n        visual_only=method_type == \"Projection\" or particle_system == StainSystem,  # Fluid + adjacency requires the object to have collision geoms active\n        abilities=abilities,\n    )\n    modifier_root_link_path = f\"{modifier.prim_path}/base_link\"\n    modifier._prim = modifier._load(og.sim)\n    if method_type == \"Projection\":\n        metalink_path = f\"{modifier.prim_path}/{modification_metalink[modifier_type]}\"\n        og.sim.stage.DefinePrim(metalink_path, \"Xform\")\n        joint_prim = create_joint(\n            prim_path=f\"{modifier_root_link_path}/{modification_metalink[modifier_type]}_joint\",\n            body0=modifier_root_link_path,\n            body1=metalink_path,\n            joint_type=\"FixedJoint\",\n            enabled=True,\n        )\n        local_area_quat = np.array([0, 0.707, 0, 0.707])    # Needs to rotated so the metalink points downwards from cloth\n        joint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*(local_area_quat[[3, 0, 1, 2]])))\n    modifier._post_load()\n    modifier._loaded = True\n    og.sim.import_object(modifier)\n    modifier.set_position(np.array([0, 0, 5.0]))\n\n    # Take a step to make sure all objects are properly initialized\n    for _ in range(25):\n        env.step(np.array([]))\n\n    # If we're removing particles, set the table's covered state to be True\n    if modifier_type == \"particleRemover\":\n        table.states[Covered].set_value(particle_system, True)\n\n        # Take a few steps to let particles settle\n        for _ in range(25):\n            env.step(np.array([]))\n\n    # Enable camera teleoperation for convenience\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Set the modifier object to be in position to modify particles\n    if method_type == \"Projection\":\n        # Higher z to showcase projection volume at work\n        z = 1.85\n    elif particle_system == StainSystem:\n        # Lower z needed to allow for adjacency bounding box to overlap properly\n        z = 1.175\n    else:\n        # Higher z needed for actual physical interaction to accomodate non-negligible particle radius\n        z = 1.22\n    modifier.keep_still()\n    modifier.set_position_orientation(\n        position=np.array([0, 0.3, z]),\n        orientation=np.array([0, 0, 0, 1.0]),\n    )\n\n    # Move object in square around table\n    deltas = [\n        [150, np.array([-0.01, 0, 0])],\n        [60, np.array([0, -0.01, 0])],\n        [150, np.array([0.01, 0, 0])],\n        [60, np.array([0, 0.01, 0])],\n    ]\n    for t, delta in deltas:\n        for i in range(t):\n            modifier.set_position(modifier.get_position() + delta)\n            # env.step(np.array([]))\n            og.sim.step()\n\n    # Always shut down environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#particle-applier-and-remover-demo"},{"title":"Kinematics Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to dynamically sample kinematic states for BEHAVIOR dataset objects</li> <li>Understanding how to import additional objects after the environment is created</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.sample_kinematics_demo\n</code></pre> <p>This demo procedurally generates a mini populated scene, spawning in a cabinet and placing boxes in its shelves, and then generating a microwave on a cabinet with a plate and apples sampled both inside and on top of it.</p>  sample_kinematics_demo.py <pre><code>import logging\nimport os\n\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson import object_states\nfrom omnigibson.macros import gm\nfrom omnigibson.objects import DatasetObject\n\n\n# Make sure object states and global contact reporting are enabled\ngm.ENABLE_OBJECT_STATES = True\ngm.ENABLE_GLOBAL_CONTACT_REPORTING = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo to use the raycasting-based sampler to load objects onTop and/or inside another\n    Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet\n    Then loads a shelf and cracker boxes inside of it\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        }\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n    env.step([])\n\n    # Sample microwave and boxes\n    sample_boxes_on_shelf(env)\n    sample_microwave_plates_apples(env)\n\n    max_steps = 100 if short_exec else -1\n    step = 0\n    while step != max_steps:\n        env.step(np.array([]))\n        step += 1\n\n    # Always close environment at the end\n    env.close()\n\n\ndef sample_microwave_plates_apples(env):\n    # Load cabinet, set position manually, and step 100 times\n    logging.info(\"Loading cabinet and microwave\")\n\n    microwave = DatasetObject(\n        prim_path=\"/World/microwave\",\n        name=\"microwave\",\n        category=\"microwave\",\n        model=\"7128\",\n        scale=0.5,\n    )\n    og.sim.import_object(microwave)\n    microwave.set_position(np.array([0, 0, 5.0]))\n    env.step(np.array([]))              # One step is needed for the object to be fully initialized\n\n    cabinet = DatasetObject(\n        prim_path=\"/World/cabinet\",\n        name=\"cabinet\",\n        category=\"bottom_cabinet\",\n        model=\"46380\",\n    )\n\n    og.sim.import_object(cabinet)\n    z_offset = -cabinet.aabb_center[2] + cabinet.aabb_extent[2] / 2\n    cabinet.set_position(np.array([1.0, 0, z_offset]))\n    env.step(np.array([]))              # One step is needed for the object to be fully initialized\n\n    # Set microwave on top of the cabinet, open it, and step 100 times\n    logging.info(\"Placing microwave OnTop of the cabinet\")\n    assert microwave.states[object_states.OnTop].set_value(cabinet, True, use_ray_casting_method=True)\n    assert microwave.states[object_states.Open].set_value(True)\n    logging.info(\"Microwave loaded and placed\")\n    for _ in range(50):\n        env.step(np.array([]))\n\n    logging.info(\"Loading plates\")\n    n_plates = 2\n    n_apples = 2\n    for i in range(n_plates):\n        plate = DatasetObject(\n            prim_path=f\"/World/plate{i}\",\n            name=f\"plate{i}\",\n            category=\"plate\",\n            model=\"plate_000\",\n            bounding_box=np.array([0.25, 0.25, 0.05]),\n        )\n        og.sim.import_object(plate)\n        env.step(np.array([]))              # One step is needed for the object to be fully initialized\n\n        # Put the 1st plate in the microwave\n        if i == 0:\n            logging.info(\"Loading plate Inside the microwave\")\n            assert plate.states[object_states.Inside].set_value(microwave, True, use_ray_casting_method=True)\n        else:\n            logging.info(\"Loading plate OnTop the microwave\")\n            assert plate.states[object_states.OnTop].set_value(microwave, True, use_ray_casting_method=True)\n\n        logging.info(\"Plate %d loaded and placed.\" % i)\n        for _ in range(50):\n            env.step(np.array([]))\n\n        logging.info(\"Loading three apples OnTop of the plate\")\n        for j in range(n_apples):\n            apple = DatasetObject(\n                prim_path=f\"/World/apple{i * n_apples + j}\",\n                name=f\"apple{i * n_apples + j}\",\n                category=\"apple\",\n                model=\"00_0\",\n            )\n            og.sim.import_object(apple)\n            env.step(np.array([]))  # One step is needed for the object to be fully initialized\n            assert apple.states[object_states.OnTop].set_value(plate, True, use_ray_casting_method=True)\n            logging.info(\"Apple %d loaded and placed.\" % j)\n            for _ in range(50):\n                env.step(np.array([]))\n\n\ndef sample_boxes_on_shelf(env):\n    shelf = DatasetObject(\n        prim_path=f\"/World/shelf\",\n        name=f\"shelf\",\n        category=\"shelf\",\n        model=\"1170df5b9512c1d92f6bce2b7e6c12b7\",\n        bounding_box=np.array([1.0, 0.4, 2.0]),\n    )\n    og.sim.import_object(shelf)\n    z_offset = -shelf.aabb_center[2] + shelf.aabb_extent[2] / 2\n    shelf.set_position(np.array([-1.0, 0, z_offset]))\n    env.step(np.array([]))  # One step is needed for the object to be fully initialized\n\n    logging.info(\"Shelf placed\")\n    for _ in range(50):\n        env.step(np.array([]))\n\n    for i in range(5):\n        box = DatasetObject(\n            prim_path=f\"/World/box{i}\",\n            name=f\"box{i}\",\n            category=\"cracker_box\",\n            model=\"cracker_box_000\",\n            bounding_box=np.array([0.2, 0.05, 0.3]),\n        )\n        og.sim.import_object(box)\n        env.step(np.array([]))  # One step is needed for the object to be fully initialized\n        box.states[object_states.Inside].set_value(shelf, True, use_ray_casting_method=True)\n        logging.info(f\"Box {i} placed.\")\n\n        for _ in range(50):\n            env.step(np.array([]))\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#kinematics-demo"},{"title":"Slicing Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how slicing works in <code>OmniGibson</code></li> <li>Understanding how to access individual objects once the environment is created</li> </ul>  <pre><code>python -m omnigibson.examples.object_states.slicing_demo\n</code></pre> <p>This demo spawns an apple on a table with a knife above it, and lets the knife fall to \"cut\" the apple in half.</p>  slicing_demo.py <pre><code>import logging\nimport numpy as np\nfrom collections import OrderedDict\n\nimport omnigibson as og\nfrom omnigibson.macros import gm\nimport omnigibson.utils.transform_utils as T\n\n# Make sure object states, contact reporting, and transition rules are enabled\ngm.ENABLE_OBJECT_STATES = True\ngm.ENABLE_GLOBAL_CONTACT_REPORTING = True\ngm.ENABLE_TRANSITION_RULES = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo to use the raycasting-based sampler to load objects onTop and/or inside another\n    Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet\n    Then loads a shelf and cracker boxes inside of it\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene with table, knife, and apple\n    table_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"table\",\n        category=\"breakfast_table\",\n        model=\"19203\",\n        scale=0.9,\n        position=[0, 0, 0.532],\n    )\n\n    apple_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"apple\",\n        category=\"apple\",\n        model=\"00_0\",\n        scale=1.5,\n        position=[0.085, 0,  0.90],\n    )\n\n    knife_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"knife\",\n        category=\"table_knife\",\n        model=\"4\",\n        scale=2.5,\n        position=[0, 0, 10.0],\n    )\n\n    light0_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light0\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=4000.0,\n        position=[1.217, -0.848, 1.388],\n    )\n\n    light1_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light1\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=4000.0,\n        position=[-1.217, 0.848, 1.388],\n    )\n\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [table_cfg, apple_cfg, knife_cfg, light0_cfg, light1_cfg]\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Grab reference to apple and knife\n    apple = env.scene.object_registry(\"name\", \"apple\")\n    knife = env.scene.object_registry(\"name\", \"knife\")\n\n    # Update the simulator's viewer camera's pose so it points towards the table\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([ 0.544888, -0.412084,  1.11569 ]),\n        orientation=np.array([0.54757518, 0.27792802, 0.35721896, 0.70378409]),\n    )\n\n    # Let apple settle\n    for _ in range(50):\n        env.step(np.array([]))\n\n    knife.keep_still()\n    knife.set_position_orientation(\n        position=apple.get_position() + np.array([-0.15, 0.0, 0.2]),\n        orientation=T.euler2quat([-np.pi / 2, 0, 0]),\n    )\n\n    input(\"The knife will fall on the apple and slice it. Press [ENTER] to continue.\")\n\n    # Step simulation for a bit so that apple is sliced\n    for i in range(1000):\n        env.step(np.array([]))\n\n    input(\"Apple has been sliced! Press [ENTER] to terminate the demo.\")\n\n    # Always close environment at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#slicing-demo"},{"title":"\ud83e\udd16 Robots","text":"<p>These examples showcase how to interact and leverage robot objects in <code>OmniGibson</code>.</p>","location":"getting_started/building_blocks.html#robots"},{"title":"Robot Visualizer Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to load a robot into <code>OmniGibson</code> after an environment is created</li> <li>Accessing all <code>OmniGibson</code> robot models</li> <li>Viewing robots' low-level joint motion</li> </ul>  <pre><code>python -m omnigibson.examples.robots.all_robots_visualizer\n</code></pre> <p>This demo iterates over all robots in <code>OmniGibson</code>, loading each one into an empty scene and randomly moving its joints for a brief amount of time.</p>  all_robots_visualizer.py <pre><code>import logging\n\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson.robots import REGISTERED_ROBOTS\nfrom omnigibson.scenes import Scene\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Robot demo\n    Loads all robots in an empty scene, generate random actions\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n    # Create empty scene with no robots in it initially\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        }\n    }\n\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Iterate over all robots and demo their motion\n    for robot_name, robot_cls in REGISTERED_ROBOTS.items():\n        # Create and import robot\n        robot = robot_cls(\n            prim_path=f\"/World/{robot_name}\",\n            name=robot_name,\n            obs_modalities=[],              # We're just moving robots around so don't load any observation modalities\n        )\n        og.sim.import_object(robot)\n\n        # At least one step is always needed while sim is playing for any imported object to be fully initialized\n        og.sim.play()\n        og.sim.step()\n\n        # Reset robot and make sure it's not moving\n        robot.reset()\n        robot.keep_still()\n\n        # Log information\n        logging.info(f\"Loaded {robot_name}\")\n        logging.info(f\"Moving {robot_name}\")\n\n        if not headless:\n            # Set viewer in front facing robot\n            og.sim.viewer_camera.set_position_orientation(\n                position=np.array([ 2.69918369, -3.63686664,  4.57894564]),\n                orientation=np.array([0.39592411, 0.1348514 , 0.29286304, 0.85982   ]),\n            )\n\n        og.sim.enable_viewer_camera_teleoperation()\n\n        # Hold still briefly so viewer can see robot\n        for _ in range(100):\n            og.sim.step()\n\n        # Then apply random actions for a bit\n        for _ in range(30):\n            action = np.random.uniform(-1, 1, robot.action_dim)\n            for _ in range(10):\n                env.step(action)\n\n        # Re-import the scene\n        og.sim.stop()\n        og.sim.import_scene(Scene())\n\n    # Always shut down the environment cleanly at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#robot-visualizer-demo"},{"title":"Robot Control Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how different controllers can be used to control robots</li> <li>Understanding how to teleoperate a robot through external commands</li> </ul>  <pre><code>python -m omnigibson.examples.robots.robot_control_example\n</code></pre> <p>This demo lets you choose a robot and the set of controllers to control the robot, and then lets you teleoperate the robot using your keyboard.</p>  robot_control_example.py <pre><code>\"\"\"\nExample script demo'ing robot control.\n\nOptions for random actions, as well as selection of robot action space\n\"\"\"\nimport logging\nfrom collections import OrderedDict\n\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.robots import REGISTERED_ROBOTS\nfrom omnigibson.utils.ui_utils import choose_from_options, KeyboardRobotController\n\n\nCONTROL_MODES = OrderedDict(\n    random=\"Use autonomous random actions (default)\",\n    teleop=\"Use keyboard control\",\n)\n\nSCENES = OrderedDict(\n    Rs_int=\"Realistic interactive home environment (default)\",\n    empty=\"Empty environment with no objects\",\n)\n\n# Don't use GPU dynamics and Use flatcache for performance boost\ngm.USE_GPU_DYNAMICS = False\ngm.ENABLE_FLATCACHE = True\n\n\ndef choose_controllers(robot, random_selection=False):\n    \"\"\"\n    For a given robot, iterates over all components of the robot, and returns the requested controller type for each\n    component.\n\n    :param robot: BaseRobot, robot class from which to infer relevant valid controller options\n    :param random_selection: bool, if the selection is random (for automatic demo execution). Default False\n\n    :return OrderedDict: Mapping from individual robot component (e.g.: base, arm, etc.) to selected controller names\n    \"\"\"\n    # Create new dict to store responses from user\n    controller_choices = OrderedDict()\n\n    # Grab the default controller config so we have the registry of all possible controller options\n    default_config = robot._default_controller_config\n\n    # Iterate over all components in robot\n    for component, controller_options in default_config.items():\n        # Select controller\n        options = list(sorted(controller_options.keys()))\n        choice = choose_from_options(\n            options=options, name=\"{} controller\".format(component), random_selection=random_selection\n        )\n\n        # Add to user responses\n        controller_choices[component] = choice\n\n    return controller_choices\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Robot control demo with selection\n    Queries the user to select a robot, the controllers, a scene and a type of input (random actions or teleop)\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose scene to load\n    scene_model = choose_from_options(options=SCENES, name=\"scene\", random_selection=random_selection)\n\n    # Choose robot to create\n    robot_name = choose_from_options(\n        options=list(sorted(REGISTERED_ROBOTS.keys())), name=\"robot\", random_selection=random_selection\n    )\n\n    # Create the config for generating the environment we want\n    scene_cfg = OrderedDict()\n    if scene_model == \"empty\":\n        scene_cfg[\"type\"] = \"Scene\"\n    else:\n        scene_cfg[\"type\"] = \"InteractiveTraversableScene\"\n        scene_cfg[\"scene_model\"] = scene_model\n\n    # Add the robot we want to load\n    robot0_cfg = OrderedDict()\n    robot0_cfg[\"type\"] = robot_name\n    robot0_cfg[\"obs_modalities\"] = [\"rgb\", \"depth\", \"seg_instance\", \"normal\", \"scan\", \"occupancy_grid\"]\n    robot0_cfg[\"action_type\"] = \"continuous\"\n    robot0_cfg[\"action_normalize\"] = True\n\n    # Compile config\n    cfg = OrderedDict(scene=scene_cfg, robots=[robot0_cfg])\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Choose robot controller to use\n    robot = env.robots[0]\n    controller_choices = choose_controllers(robot=robot, random_selection=random_selection)\n\n    # Choose control mode\n    if random_selection:\n        control_mode = \"random\"\n    else:\n        control_mode = choose_from_options(options=CONTROL_MODES, name=\"control mode\")\n\n    # Update the control mode of the robot\n    controller_config = {component: {\"name\": name} for component, name in controller_choices.items()}\n    robot.reload_controllers(controller_config=controller_config)\n\n    # Update the simulator's viewer camera's pose so it points towards the robot\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([1.46949, -3.97358, 2.21529]),\n        orientation=np.array([0.56829048, 0.09569975, 0.13571846, 0.80589577]),\n    )\n\n    # Reset environment\n    env.reset()\n\n    # Create teleop controller\n    action_generator = KeyboardRobotController(robot=robot)\n\n    # Print out relevant keyboard info if using keyboard teleop\n    if control_mode == \"teleop\":\n        action_generator.print_keyboard_teleop_info()\n\n    # Other helpful user info\n    print(\"Running demo.\")\n    print(\"Press ESC to quit\")\n\n    # Loop control until user quits\n    max_steps = -1 if not short_exec else 100\n    step = 0\n    while step != max_steps:\n        action = action_generator.get_random_action() if control_mode == \"random\" else action_generator.get_teleop_action()\n        for _ in range(10):\n            env.step(action=action)\n            step += 1\n\n    # Always shut down the environment cleanly at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#robot-control-demo"},{"title":"Robot Grasping Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding the difference between <code>physical</code> and <code>sticky</code> (1) grasping</li> <li>Understanding how to teleoperate a robot through external commands</li> </ul>  <ol> <li><code>physical</code> means natural friction is required to hold objects, <code>sticky</code> means that objects are constrained to the robot's gripper once contact is made</li> </ol> <pre><code>python -m omnigibson.examples.robots.grasping_mode_example\n</code></pre> <p>This demo lets you choose a grasping mode and then loads a <code>Fetch</code> robot and a cube on a table. You can then teleoperate the robot to grasp the cube, observing the difference is grasping behavior based on the grasping mode chosen.</p>  grasping_mode_example.py <pre><code>\"\"\"\nExample script demo'ing robot manipulation control with grasping.\n\"\"\"\nimport logging\nfrom collections import OrderedDict\n\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson.macros import gm\nfrom omnigibson.utils.ui_utils import choose_from_options, KeyboardRobotController\n\nGRASPING_MODES = OrderedDict(\n    sticky=\"Sticky Mitten - Objects are magnetized when they touch the fingers and a CLOSE command is given\",\n    physical=\"Physical Grasping - No additional grasping assistance applied\",\n)\n\n# Don't use GPU dynamics and Use flatcache for performance boost\ngm.USE_GPU_DYNAMICS = False\ngm.ENABLE_FLATCACHE = True\n\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Robot grasping mode demo with selection\n    Queries the user to select a type of grasping mode and GUI\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose type of grasping\n    grasping_mode = choose_from_options(options=GRASPING_MODES, name=\"grasping mode\", random_selection=random_selection)\n\n    # Create environment configuration to use\n    scene_cfg = OrderedDict(type=\"Scene\")\n    robot0_cfg = OrderedDict(\n        type=\"Fetch\",\n        obs_modalities=[\"rgb\"],     # we're just doing a grasping demo so we don't need all observation modalities\n        action_type=\"continuous\",\n        action_normalize=True,\n        grasping_mode=grasping_mode,\n    )\n\n    # Define objects to load\n    table_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"table\",\n        category=\"breakfast_table\",\n        model=\"1b4e6f9dd22a8c628ef9d976af675b86\",\n        bounding_box=[0.5, 0.5, 0.8],\n        fit_avg_dim_volume=False,\n        fixed_base=True,\n        position=[0.7, -0.1, 0.6],\n        orientation=[0, 0, 0.707, 0.707],\n    )\n\n    chair_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"chair\",\n        category=\"straight_chair\",\n        model=\"2a8d87523e23a01d5f40874aec1ee3a6\",\n        bounding_box=None,\n        fit_avg_dim_volume=True,\n        fixed_base=False,\n        position=[0.45, 0.65, 0.425],\n        orientation=[0, 0, -0.9990215, -0.0442276],\n    )\n\n    box_cfg = OrderedDict(\n        type=\"PrimitiveObject\",\n        name=\"box\",\n        primitive_type=\"Cube\",\n        rgba=[1.0, 0, 0, 1.0],\n        size=0.05,\n        position=[0.53, -0.1, 0.97],\n    )\n\n    # Compile config\n    cfg = OrderedDict(scene=scene_cfg, robots=[robot0_cfg], objects=[table_cfg, chair_cfg, box_cfg])\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Reset the robot\n    robot = env.robots[0]\n    robot.set_position([0, 0, 0])\n    robot.reset()\n    robot.keep_still()\n\n    # Update the simulator's viewer camera's pose so it points towards the robot\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-2.39951,  2.26469,  2.66227]),\n        orientation=np.array([-0.23898481,  0.48475231,  0.75464013, -0.37204802]),\n    )\n\n    # Create teleop controller\n    action_generator = KeyboardRobotController(robot=robot)\n\n    # Print out relevant keyboard info if using keyboard teleop\n    action_generator.print_keyboard_teleop_info()\n\n    # Other helpful user info\n    print(\"Running demo with grasping mode {}.\".format(grasping_mode))\n    print(\"Press ESC to quit\")\n\n    # Loop control until user quits\n    max_steps = -1 if not short_exec else 100\n    step = 0\n    while step != max_steps:\n        action = action_generator.get_random_action() if random_selection else action_generator.get_teleop_action()\n        for _ in range(10):\n            env.step(action)\n            step += 1\n\n    # Always shut down the environment cleanly at the end\n    env.close()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#robot-grasping-demo"},{"title":"\ud83e\uddf0 Simulator","text":"<p>These examples showcase useful functionality from <code>OmniGibson</code>'s monolithic <code>Simulator</code> object.</p>  What's the difference between <code>Environment</code> and <code>Simulator</code>? <p>The <code>Simulator</code> class is a lower-level object that:</p> <ul> <li>handles importing scenes and objects into the actual simulation</li> <li>directly interfaces with the underlying physics engine</li> </ul> <p>The <code>Environment</code> class thinly wraps the <code>Simulator</code>'s core functionality, by:</p> <ul> <li>providing convenience functions for automatically importing a predefined scene, object(s), and robot(s) (via the <code>cfg</code> argument), as well as a <code>task</code></li> <li>providing a OpenAI Gym interface for stepping through the simulation</li> </ul> <p>While most of the core functionality in <code>Environment</code> (as well as more fine-grained physics control) can be replicated via direct calls to <code>Simulator</code> (<code>og.sim</code>), it requires deeper understanding of <code>OmniGibson</code>'s infrastructure and is not recommended for new users.</p>","location":"getting_started/building_blocks.html#simulator"},{"title":"State Saving and Loading Demo","text":"<p>This demo is useful for...</p> <ul> <li>Understanding how to interact with objects using the mouse</li> <li>Understanding how to save the active simulator state to a file</li> <li>Understanding how to restore the simulator state from a given file</li> </ul>  <pre><code>python -m omnigibson.examples.simulator.sim_save_load_example\n</code></pre> <p>This demo loads a stripped-down scene with the <code>Turtlebot</code> robot, and lets you interact with objects to modify the scene. The state is then saved, written to a <code>.json</code> file, and then restored in the simulation.</p>  sim_save_load_example.py <pre><code>import os\nimport logging\nimport numpy as np\n\nimport omnigibson as og\nfrom omnigibson.utils.ui_utils import KeyboardEventHandler\nimport carb\n\nTEST_OUT_PATH = \"\"  # Define output directory here.\n\ndef main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select whether they are saving or loading an environment, and interactively\n    shows how an environment can be saved or restored.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    cfg = {\n        \"scene\": {\n            \"type\": \"InteractiveTraversableScene\",\n            \"scene_model\": \"Rs_int\",\n            \"load_object_categories\": [\"floors\", \"walls\", \"bed\", \"bottom_cabinet\", \"chair\"],\n        },\n        \"robots\": [\n            {\n                \"type\": \"Turtlebot\",\n                \"obs_modalities\": [\"rgb\", \"depth\"],\n            },\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg)\n\n    # Set the camera to a good angle\n    def set_camera_pose():\n        og.sim.viewer_camera.set_position_orientation(\n            position=np.array([-0.229375, -3.40576 ,  7.26143 ]),\n            orientation=np.array([ 0.27619733, -0.00230233, -0.00801152,  0.9610648 ]),\n        )\n    set_camera_pose()\n\n    # Give user instructions, and then loop until completed\n    completed = short_exec\n    if not short_exec and not random_selection:\n        # Notify user to manipulate environment until ready, then press Z to exit\n        print()\n        print(\"Modify the scene by SHIFT + left clicking objects and dragging them. Once finished, press Z.\")\n        # Register callback so user knows to press space once they're done manipulating the scene\n        def complete_loop():\n            nonlocal completed\n            completed = True\n        KeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\n    while not completed:\n        env.step(np.random.uniform(-1, 1, env.robots[0].action_dim))\n\n    print(\"Completed scene modification, saving scene...\")\n    save_path = os.path.join(TEST_OUT_PATH, \"saved_stage.json\")\n    og.sim.save(json_path=save_path)\n\n    print(\"Re-loading scene...\")\n    og.sim.restore(json_path=save_path)\n\n    # Take a sim step and play\n    og.sim.step()\n    og.sim.play()\n    set_camera_pose()\n\n    # Loop until user terminates\n    completed = short_exec\n    if not short_exec and not random_selection:\n        # Notify user to manipulate environment until ready, then press Z to exit\n        print()\n        print(\"View reloaded scene. Once finished, press Z.\")\n        # Register callback so user knows to press space once they're done manipulating the scene\n        KeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\n    while not completed:\n        env.step(np.zeros(env.robots[0].action_dim))\n\n    # Shutdown omnigibson at the end\n    og.shutdown()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>","location":"getting_started/building_blocks.html#state-saving-and-loading-demo"},{"title":"\ud83d\udee0\ufe0f Installation","text":"","location":"getting_started/installation.html"},{"title":"\ud83d\uddd2\ufe0f Requirements","text":"<p>Please make sure your system meets the following specs:</p> <ul> <li> OS: Ubuntu 18.04+</li> <li> RAM: 32GB+</li> <li> GPU: NVIDIA RTX 2070+</li> <li> VRAM: 8GB+</li> </ul>  Why these specs? <p><code>OmniGibson</code> is built upon NVIDIA's Omniverse and Isaac Sim platforms, so we inherit their dependencies. For more information, please see Isaac Sim's Requirements.</p>","location":"getting_started/installation.html#requirements"},{"title":"\ud83d\udcbb Setup","text":"<p>You can quickly get <code>OmniGibson</code> immediately up and running from our pre-built \ud83d\udc33 docker image:</p>  Need to install docker or NVIDIA docker? <pre><code># Install docker\ncurl https://get.docker.com | sh &amp;&amp; sudo systemctl --now enable docker\n\n# Install nvidia-docker runtime\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\\n    &amp;&amp; curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \\\n    sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\nsudo apt-get update\nsudo apt-get install -y nvidia-docker2 # install\nsudo systemctl restart docker # restart docker engine\n</code></pre>  <p>Install our docker launching scripts: <pre><code>curl -LJO https://raw.githubusercontent.com/StanfordVL/OmniGibson/main/docker/run_docker.sh\ncurl -LJO https://raw.githubusercontent.com/StanfordVL/OmniGibson/main/docker/run_docker_gui.sh\nchmod a+x run_docker.sh\nchmod a+x run_docker_gui.sh\n</code></pre></p>  What is being installed? <p>Our docker image automatically ships with a pre-configured conda virtual environment named <code>omnigibson</code> with Isaac Sim and <code>OmniGibson</code> pre-installed. Upon running the first time, our scene and object assets will automatically be downloaded as well. (1)</p>  <ol> <li>\ud83d\udcca Worried about dataset size? We will ask whether you want to install our small demo dataset or full dataset of assets!</li> </ol> <p>Then, simply launch the desired script:</p> HeadlessGUI   <pre><code>sudo ./run_docker.sh &lt;DATA_PATH&gt; # (1)!\n</code></pre> <ol> <li><code>&lt;DATA_PATH&gt;</code> specifies where data will be stored on your machine (if no <code>&lt;DATA_PATH&gt;</code> is specified, it defaults to <code>./omnigibson_data</code>). This needs to be called each time the docker container is run!</li> </ol>   <pre><code>sudo ./run_docker_gui.sh &lt;DATA_PATH&gt; # (1)!\n</code></pre> <ol> <li><code>&lt;DATA_PATH&gt;</code> specifies where data will be stored on your machine (if no <code>&lt;DATA_PATH&gt;</code> is specified, it defaults to <code>./omnigibson_data</code>). This needs to be called each time the docker container is run!</li> </ol>     Are you using NFS or AFS? <p>Docker containers are unable to access NFS or AFS drives, so if <code>run_docker.sh</code> or <code>run_docker_gui.sh</code> are located on an NFS / AFS partition, please set <code>&lt;DATA_PATH&gt;</code> to an alternative data directory located on a non-NFS / AFS partition.</p>   Advanced: Installing from Source <p>This method is recommended for deeper users looking to develop upon <code>OmniGibson</code> or use it extensively for research. </p> <ol> <li> <p>Install Conda</p> </li> <li> <p>Install NVIDIA's Isaac Sim platform (1)</p> </li> <li> <p>Export IsaacSim directory path as an environment variable: (2)</p> <pre><code>export ISAAC_SIM_PATH = &lt;YOUR_PATH_TO_ISAAC_SIM&gt;\n</code></pre> </li> <li> <p>Clone <code>OmniGibson</code> and move into the directory:</p> <pre><code>git clone https://github.com/StanfordVL/OmniGibson.git\ncd OmniGibson\n</code></pre> </li> <li> <p>Run the command to setup a virtual conda environment to run <code>OmniGibson</code>:</p> <pre><code>chmod +x setup_conda_env.sh\n./setup_conda_env.sh\n</code></pre> </li> <li> <p>This will automatically create an dump you into a conda env called <code>omnigibson</code>. If you need to activate this environment later, simply call:</p> <pre><code>conda activate omnigibson\n</code></pre> </li> <li> <p>\ud83c\udf89 Congrats! You installed <code>OmniGibson</code> successfully.  </p> </li> </ol>  <ol> <li> <p>Be sure keep track of where you choose Omniverse to write package files! By default this should be <code>~/.local/share/ov/pkg</code></p> </li> <li> <p>If you installed Isaac Sim to the default location, this is <code>~/.local/share/ov/pkg/isaac_sim-2022.1.1</code></p> </li> </ol>","location":"getting_started/installation.html#setup"},{"title":"\ud83c\udf0e Explore <code>OmniGibson</code>!","text":"Expect slowdown during first execution <p>Omniverse requires some one-time startup setup (up to ~5 minutes) when <code>OmniGibson</code> is imported for the first time. This is expected behavior, and should only occur once!</p>  <p><code>OmniGibson</code> is now successfully installed! Try exploring some of our new scenes interactively:</p> <pre><code>python -m omnigibson.examples.scenes.scene_selector # (1)!\n</code></pre> <ol> <li>This demo lets you choose a scene and interactively move around using your keyboard and mouse. Hold down <code>Shift</code> and then <code>Left-click + Drag</code> an object to apply forces!</li> </ol> <p>You can also try teleoperating one of our robots:</p> <pre><code>python -m omnigibson.examples.robots.robot_control_example # (1)!\n</code></pre> <ol> <li>This demo lets you choose a scene, robot, and set of controllers, and then teleoperate the robot using your keyboard.</li> </ol>  <p>Next: Get quickly familiarized with <code>OmniGibson</code> from our Quickstart Guide!</p>","location":"getting_started/installation.html#explore-omnigibson"},{"title":"\ud83d\ude80 Quickstart","text":"<p>Let's quickly create an environment programmatically!</p> <p><code>OmniGibson</code>'s workflow is straightforward: define the configuration of scene, object(s), robot(s), and task you'd like to load, and then instantiate our <code>Environment</code> class with that config.</p> <p>Let's start with the following:</p> <pre><code>import omnigibson as og # (1)!\n\n# Start with an empty configuration\ncfg = dict()\n</code></pre> <ol> <li>All python scripts should start with this line! This allows access to key global variables through the top-level package.</li> </ol>","location":"getting_started/quickstart.html"},{"title":"\ud83c\udfd4\ufe0f Defining a scene","text":"<p>Next, let's define a scene:</p> <pre><code>cfg[\"scene\"] = {\n    \"type\": \"Scene\", # (1)!\n    \"floor_plane_visible\": True, # (2)!\n}\n</code></pre> <ol> <li>Our configuration gets parsed automatically and generates the appropriate class instance based on <code>type</code> (the string form of the class name). In this case, we're generating the most basic scene, which only consists of a floor plane. Check out all of our available <code>Scene</code> classes!</li> <li>In addition to specifying <code>type</code>, the remaining keyword-arguments get passed directly into the class constructor. So for the base <code>Scene</code> class, you could optionally specify <code>\"use_floor_plane\"</code> and <code>\"floor_plane_visible\"</code>, whereas for the more powerful <code>InteractiveTraversableScene</code> class (which loads a curated, preconfigured scene) you can additionally specify options for filtering objects, such as <code>\"load_object_categories\"</code> and <code>\"load_room_types\"</code>. You can see all available keyword-arguments by viewing the individual <code>Scene</code> class you'd like to load!</li> </ol>","location":"getting_started/quickstart.html#defining-a-scene"},{"title":"\ud83c\udfbe Defining objects","text":"<p>We can optionally define some objects to load into our scene:</p> <pre><code>cfg[\"objects\"] = [ # (1)!\n    {\n        \"type\": \"USDObject\", # (2)!\n        \"name\": \"ghost_apple\", # (3)!\n        \"usd_path\": f\"{og.og_dataset_path}/objects/apple/00_0/usd/00_0.usd\",\n        \"category\": \"apple\", # (4)!\n        \"visual_only\": True, # (5)!\n        \"scale\": [2.0, 1.0, 2.0], # (6)!\n        \"position\": [3.0, 0, 2.0], # (7)!\n        \"orientation\": [0, 0, 0, 1.0], # (8)!\n    },\n    {\n        \"type\": \"DatasetObject\", # (9)!\n        \"name\": \"delicious_apple\",\n        \"category\": \"apple\",\n        \"model\": \"00_0\", # (10)!\n        \"position\": [0, 0, 1.0],\n    },\n    {\n        \"type\": \"PrimitiveObject\", # (11)!\n        \"name\": \"incredible_box\",\n        \"primitive_type\": \"Cube\", # (12)!\n        \"rgba\": [0, 1.0, 1.0, 1.0], # (13)!\n        \"scale\": [0.5, 0.5, 0.1],\n        \"fixed_base\": True, # (14)!\n        \"position\": [-1.0, 0, 1.0],\n        \"orientation\": [0, 0, 0.707, 0.707],\n    },\n    {\n        \"type\": \"LightObject\", # (15)!\n        \"name\": \"brilliant_light\",\n        \"light_type\": \"Sphere\", # (16)!\n        \"intensity\": 50000, # (17)!\n        \"radius\": 0.1 # (18)!\n        \"position\": [3.0, 3.0, 4.0],\n    },\n]\n</code></pre> <ol> <li>Unlike the <code>\"scene\"</code> sub-config, we can define an arbitrary number of objects to load, so this is a <code>list</code> of <code>dict</code> istead of a single nested <code>dict</code>.</li> <li><code>OmniGibson</code> supports multiple object classes, and we showcase an instance of each core class here. A <code>USDObject</code> is our most generic object class, and generates an object sourced from the <code>usd_path</code> argument.</li> <li>All objects must define the <code>name</code> argument! This is because <code>OmniGibson</code> enforces a global unique naming scheme, and so any created objects must have unique names assigned to them.</li> <li><code>category</code> is used by all object classes to assign semantic segmentation IDs.</li> <li><code>visual_only</code> is used by all object classes and defines whether the object is subject to both gravity and collisions.</li> <li><code>scale</code> is used by all object classes and defines the global (x,y,z) relative scale of the object.</li> <li><code>position</code> is used by all object classes and defines the initial (x,y,z) position of the object in the global frame.</li> <li><code>orientation</code> is used by all object classes and defines the initial (x,y,z,w) quaternion orientation of the object in the global frame.</li> <li>A <code>DatasetObject</code> is an object pulled directly from our BEHAVIOR dataset. It includes metadata and annotations not found on a generic <code>USDObject</code>.</li> <li>Instead of explicitly defining the hardcoded path to the dataset USD model, <code>model</code> (in conjunction with <code>category</code>) is used to infer the exact dataset object to load. In this case this is the exact same underlying raw USD asset that was loaded above as a <code>USDObject</code>!</li> <li>A <code>PrimitiveObject</code> is a programmatically generated object defining a convex primitive shape.</li> <li><code>primitive_type</code> defines what primitive shape to load -- see <code>PrimitiveObject</code> for available options!</li> <li>Because this object is programmatically generated, we can also specify the color to assign to this primitive object.</li> <li><code>fixed_base</code> is used by all object classes and determines whether the generated object is fixed relative to the world frame. Useful for fixing in place large objects, such as furniture or structures.</li> <li>A <code>LightObject</code> is a programmatically generated light source. It is used to directly illuminate the given scene.</li> <li><code>light_type</code> defines what light shape to load -- see <code>LightObject</code> for available options!</li> <li><code>intensity</code> defines how bright the generated light source should be.</li> <li><code>radius</code> is used by <code>Sphere</code> lights and determines their relative size.</li> </ol>","location":"getting_started/quickstart.html#defining-objects"},{"title":"\ud83e\udd16 Defining robots","text":"<p>We can also optionally define robots to load into our scene:</p> <pre><code>cfg[\"robots\"] = [ # (1)!\n    {\n        \"type\": \"Fetch\", # (2)!\n        \"name\": \"baby_robot\",\n        \"obs_modalities\": [\"scan\", \"rgb\", \"depth\"], # (3)!\n    },\n]\n</code></pre> <ol> <li>Like the <code>\"objects\"</code> sub-config, we can define an arbitrary number of robots to load, so this is a <code>list</code> of <code>dict</code>.</li> <li><code>OmniGibson</code> supports multiple robot classes, where each class represents a specific robot model. Check out our <code>robots</code> to view all available robot classes!</li> <li>Execute <code>print(og.ALL_SENSOR_MODALITIES)</code> for a list of all available observation modalities!</li> </ol>","location":"getting_started/quickstart.html#defining-robots"},{"title":"\ud83d\udccb Defining a task","text":"<p>Lastly, we can optionally define a task to load into our scene. Since we're just getting started, let's load a \"Dummy\" task: (1)</p> <ol> <li>Note: this is the task that is loaded anyways even if we don't explicitly define a task in our config!</li> </ol> <pre><code>cfg[\"task\"] = {\n    \"type\": \"DummyTask\", # (1)!\n    \"termination_config\": dict(), # (2)!\n    \"reward_config\": dict(), # (3)!\n}\n</code></pre> <ol> <li>Check out all of <code>OmniGibson</code>'s available tasks!</li> <li><code>termination_config</code> configures the termination conditions for this task. It maps specific <code>TerminationCondition</code> arguments to their corresponding values to set.</li> <li><code>reward_config</code> configures the reward functions for this task. It maps specific <code>RewardFunction</code> arguments to their corresponding values to set.</li> </ol>","location":"getting_started/quickstart.html#defining-a-task"},{"title":"\ud83c\udf00 Creating the environment","text":"<p>We're all set! Let's load the config and create our environment:</p> <pre><code>env = og.Environment(cfg)\n</code></pre> <p>Once the environment loads, we can interface with our environment similar to OpenAI's Gym interface:</p> <pre><code>obs, rew, done, info = env.step(env.action_space.sample())\n</code></pre>  What happens if we have no robot loaded? <p>Even if we have no robot loaded, we still need to define an \"action\" to pass into the environment. In this case, our action space is 0, so you can simply pass <code>[]</code> or <code>np.array([])</code> into the <code>env.step()</code> call!</p>   my_first_env.py <pre><code>import omnigibson as og\n\ncfg = dict()\n\n# Define scene\ncfg[\"scene\"] = {\n    \"type\": \"Scene\",\n    \"floor_plane_visible\": True,\n}\n\n# Define objects\ncfg[\"objects\"] = [\n    {\n        \"type\": \"USDObject\",\n        \"name\": \"ghost_apple\",\n        \"usd_path\": f\"{og.og_dataset_path}/objects/apple/00_0/usd/00_0.usd\",\n        \"category\": \"apple\",\n        \"visual_only\": True,\n        \"scale\": [2.0, 1.0, 2.0],\n        \"position\": [3.0, 0, 2.0],\n        \"orientation\": [0, 0, 0, 1.0],\n    },\n    {\n        \"type\": \"DatasetObject\",\n        \"name\": \"delicious_apple\",\n        \"category\": \"apple\",\n        \"model\": \"00_0\",\n        \"position\": [0, 0, 1.0],\n    },\n    {\n        \"type\": \"PrimitiveObject\",\n        \"name\": \"incredible_box\",\n        \"primitive_type\": \"Cube\",\n        \"rgba\": [0, 1.0, 1.0, 1.0],\n        \"scale\": [0.5, 0.5, 0.1],\n        \"fixed_base\": True,\n        \"position\": [-1.0, 0, 1.0],\n        \"orientation\": [0, 0, 0.707, 0.707],\n    },\n    {\n        \"type\": \"LightObject\",\n        \"name\": \"brilliant_light\",\n        \"light_type\": \"Sphere\",\n        \"intensity\": 50000,\n        \"radius\": 0.1\n        \"position\": [3.0, 3.0, 4.0],\n    },\n\n# Define robots\ncfg[\"robots\"] = [\n    {\n        \"type\": \"Fetch\",\n        \"name\": \"skynet_robot\",\n        \"obs_modalities\": [\"scan\", \"rgb\", \"depth\"],\n    },\n]\n\n# Define task\ncfg[\"task\"] = {\n    \"type\": \"DummyTask\",\n    \"termination_config\": dict(),\n    \"reward_config\": dict(),\n}\n\n# Create the environment\nenv = og.Environment(cfg)\n\n# Allow camera teleoperation\nog.sim.enable_viewer_camera_teleoperation()\n\n# Step!\nfor _ in range(10000):\n    obs, rew, done, info = env.step(env.action_space.sample())\n</code></pre>","location":"getting_started/quickstart.html#creating-the-environment"},{"title":"\ud83d\udc40 Looking around","text":"<p>Look around by:</p> <ul> <li><code>Left-CLICK + Drag</code>: Tilt</li> <li><code>Scroll-Wheel-CLICK + Drag</code>: Pan</li> <li><code>Scroll-Wheel UP / DOWN</code>: Zoom</li> </ul> <p>Or, for more fine-grained control, run: <pre><code>og.sim.enable_viewer_camera_teleoperation() # (1)!\n</code></pre></p> <ol> <li>This allows you to move the camera precisely with your keyboard, record camera poses, and dynamically modify lights!</li> </ol> <p>Or, for programmatic control, directly set the viewer camera's global pose:</p> <pre><code>og.sim.viewer_camera.set_position_orientation(&lt;POSITION&gt;, &lt;ORIENTATION&gt;)\n</code></pre>  <p>Next: Check out some of <code>OmniGibson</code>'s breadth of features from our Building Block examples!</p>","location":"getting_started/quickstart.html#looking-around"},{"title":"SUMMARY","text":"<ul> <li>app_omni</li> <li>controllers<ul> <li>controller_base</li> <li>dd_controller</li> <li>ik_controller</li> <li>joint_controller</li> <li>multi_finger_gripper_controller</li> <li>null_joint_controller</li> </ul> </li> <li>envs<ul> <li>env_base</li> </ul> </li> <li>examples<ul> <li>blender_demo_transition_machine</li> <li>environments<ul> <li>behavior_env_demo</li> <li>config_selector</li> <li>navigation_env_demo</li> </ul> </li> <li>learning<ul> <li>stable_baselines3_ppo_example</li> </ul> </li> <li>object_states<ul> <li>attachment_demo</li> <li>blender_demo</li> <li>cleaning_demo</li> <li>cleaning_demo_simple</li> <li>folded_state_demo</li> <li>heat_source_or_sink_demo</li> <li>heated_state_demo</li> <li>object_state_texture_demo</li> <li>particle_applier_remover_demo</li> <li>sample_kinematics_demo</li> <li>slicing_demo</li> <li>temperature_demo</li> </ul> </li> <li>objects<ul> <li>draw_bounding_box</li> <li>highlight_objects</li> <li>load_object_selector</li> <li>visualize_object</li> </ul> </li> <li>renderer_settings<ul> <li>renderer_settings_example</li> </ul> </li> <li>robots<ul> <li>advanced<ul> <li>ik_example</li> </ul> </li> <li>all_robots_visualizer</li> <li>grasping_mode_example</li> <li>robot_control_example</li> </ul> </li> <li>scenes<ul> <li>scene_selector</li> <li>traversability_map_example</li> </ul> </li> <li>simulator<ul> <li>sim_save_load_example</li> </ul> </li> </ul> </li> <li>macros</li> <li>maps<ul> <li>map_base</li> <li>segmentation_map</li> <li>traversable_map</li> </ul> </li> <li>object_states<ul> <li>aabb</li> <li>adjacency</li> <li>attachment</li> <li>burnt</li> <li>contact_bodies</li> <li>contact_subscribed_state_mixin</li> <li>cooked</li> <li>covered</li> <li>factory</li> <li>filled</li> <li>fluid_sink</li> <li>fluid_source</li> <li>folded</li> <li>frozen</li> <li>heat_source_or_sink</li> <li>heated</li> <li>inside</li> <li>kinematics</li> <li>link_based_state_mixin</li> <li>max_temperature</li> <li>next_to</li> <li>object_state_base</li> <li>on_top</li> <li>open</li> <li>particle_modifier</li> <li>pose</li> <li>robot_related_states</li> <li>room_states</li> <li>saturated</li> <li>sliced</li> <li>slicer</li> <li>temperature</li> <li>toggle</li> <li>touching</li> <li>under</li> <li>water_sink</li> <li>water_source</li> </ul> </li> <li>objects<ul> <li>controllable_object</li> <li>dataset_object</li> <li>light_object</li> <li>object_base</li> <li>primitive_object</li> <li>stateful_object</li> <li>usd_object</li> </ul> </li> <li>prims<ul> <li>cloth_prim</li> <li>entity_prim</li> <li>geom_prim</li> <li>joint_prim</li> <li>material_prim</li> <li>prim_base</li> <li>rigid_prim</li> <li>xform_prim</li> </ul> </li> <li>renderer_settings<ul> <li>common_settings</li> <li>path_tracing_settings</li> <li>post_processing_settings</li> <li>real_time_settings</li> <li>renderer_settings</li> <li>settings_base</li> </ul> </li> <li>reward_functions<ul> <li>collision_reward</li> <li>point_goal_reward</li> <li>potential_reward</li> <li>reaching_goal_reward</li> <li>reward_function_base</li> </ul> </li> <li>robots<ul> <li>active_camera_robot</li> <li>fetch</li> <li>freight</li> <li>husky</li> <li>locobot</li> <li>locomotion_robot</li> <li>manipulation_robot</li> <li>robot_base</li> <li>tiago</li> <li>turtlebot</li> <li>two_wheel_robot</li> </ul> </li> <li>scenes<ul> <li>interactive_traversable_scene</li> <li>scene_base</li> <li>static_traversable_scene</li> <li>traversable_scene</li> </ul> </li> <li>scripts<ul> <li>setup</li> </ul> </li> <li>sensors<ul> <li>dropout_sensor_noise</li> <li>scan_sensor</li> <li>sensor_base</li> <li>sensor_noise_base</li> <li>vision_sensor</li> </ul> </li> <li>simulator</li> <li>systems<ul> <li>macro_particle_system</li> <li>micro_particle_system</li> <li>particle_system_base</li> <li>system_base</li> </ul> </li> <li>tasks<ul> <li>bddl_backend</li> <li>behavior_task</li> <li>dummy_task</li> <li>furniture_closing_task</li> <li>point_navigation_obstacle_task</li> <li>point_navigation_task</li> <li>point_reaching_task</li> <li>task_base</li> </ul> </li> <li>termination_conditions<ul> <li>falling</li> <li>max_collision</li> <li>point_goal</li> <li>predicate_goal</li> <li>reaching_goal</li> <li>termination_condition_base</li> <li>timeout</li> </ul> </li> <li>transition_rules</li> <li>utils<ul> <li>asset_utils</li> <li>config_utils</li> <li>constants</li> <li>control_utils</li> <li>deprecated_utils</li> <li>geometry_utils</li> <li>git_utils</li> <li>gym_utils</li> <li>object_state_utils</li> <li>physx_utils</li> <li>processing_utils</li> <li>python_utils</li> <li>registry_utils</li> <li>render_utils</li> <li>sampling_utils</li> <li>sim_utils</li> <li>transform_utils</li> <li>ui_utils</li> <li>usd_utils</li> <li>vision_utils</li> </ul> </li> <li>wrappers<ul> <li>wrapper_base</li> </ul> </li> </ul>","location":"reference/SUMMARY.html"},{"title":"app_omni","text":"","location":"reference/app_omni.html"},{"title":"<code>OmniApp</code>","text":"<p>Helper class to launch Omniverse Toolkit.</p> <p>Omniverse loads various plugins at runtime which cannot be imported unless the Toolkit is already running. Thus, it is necessary to launch the Toolkit first from your python application and then import everything else.</p> <p>Parameters:</p>    Name Type Description Default     <code>config</code>  <code>dict</code>  <p>A dictionary containing the configuration for the app. (default: None)</p>  required    <code>experience</code>  <code>str</code>  <p>Path to the application config loaded by the launcher (default: \"\", will load app/omni.isaac.sim.python.kit if left blank)</p>  <code>''</code>      Source code in <code>omnigibson/app_omni.py</code> <pre><code>class OmniApp:\n    \"\"\"Helper class to launch Omniverse Toolkit.\n\n    Omniverse loads various plugins at runtime which cannot be imported unless\n    the Toolkit is already running. Thus, it is necessary to launch the Toolkit first from\n    your python application and then import everything else.\n\n    Args:\n        config (dict): A dictionary containing the configuration for the app. (default: None)\n        experience (str): Path to the application config loaded by the launcher (default: \"\", will load app/omni.isaac.sim.python.kit if left blank)\n    \"\"\"\n\n    DEFAULT_LAUNCHER_CONFIG = {\n        \"headless\": True,\n        \"active_gpu\": None,\n        \"multi_gpu\": True,\n        \"sync_loads\": True,\n        \"width\": 1280,\n        \"height\": 720,\n        \"window_width\": 1440,\n        \"window_height\": 900,\n        \"display_options\": 3094,\n        \"subdiv_refinement_level\": 0,\n        \"renderer\": \"RayTracedLighting\",  # Can also be PathTracing\n        \"anti_aliasing\": 3,\n        \"samples_per_pixel_per_frame\": 64,\n        \"denoiser\": True,\n        \"max_bounces\": 4,\n        \"max_specular_transmission_bounces\": 6,\n        \"max_volume_bounces\": 4,\n        \"open_usd\": None,\n        \"livesync_usd\": None,\n        \"memory_report\": False,\n    }\n    \"\"\"\n    The config variable is a dictionary containing the following entries\n\n    Args:\n        headless (bool): Disable UI when running. Defaults to True\n        active_gpu (int): Specify the GPU to use when running, set to None to use default value which is usually the first gpu, default is None\n        multi_gpu (bool): Set to true to enable Multi GPU support, Defaults to true\n        sync_loads (bool): When enabled, will pause rendering until all assets are loaded. Defaults to True\n        width (int): Width of the viewport and generated images. Defaults to 1280\n        height (int): Height of the viewport and generated images. Defaults to 720\n        window_width (int): Width of the application window, independent of viewport, defaults to 1440,\n        window_height (int): Height of the application window, independent of viewport, defaults to 900,\n        display_options (int): used to specify whats visible in the stage by default. Defaults to 3094 so extra objects do not appear in synthetic data. 3286 is another good default, used for the regular isaac-sim editor experience\n        subdiv_refinement_level (int): Number of subdivisons to perform on supported geometry. Defaults to 0\n        renderer (str): Rendering mode, can be  `RayTracedLighting` or `PathTracing`. Defaults to `PathTracing`\n        anti_aliasing (int): Antialiasing mode, 0: Disabled, 1: TAA, 2: FXAA, 3: DLSS, 4:RTXAA\n        samples_per_pixel_per_frame (int): The number of samples to render per frame, increase for improved quality, used for `PathTracing` only. Defaults to 64\n        denoiser (bool):  Enable this to use AI denoising to improve image quality, used for `PathTracing` only. Defaults to True\n        max_bounces (int): Maximum number of bounces, used for `PathTracing` only. Defaults to 4\n        max_specular_transmission_bounces (int): Maximum number of bounces for specular or transmission, used for `PathTracing` only. Defaults to 6\n        max_volume_bounces (int): Maximum number of bounces for volumetric materials, used for `PathTracing` only. Defaults to 4\n        open_usd (str): This is the name of the usd to open when the app starts. It will not be saved over. Default is None and an empty stage is created on startup.\n        livesync_usd (str): This is the location of the usd that you want to do your interactive work in.  The existing file is overwritten. Default is None\n        memory_report (bool): Set to true to print a memory usage report on exit. Default is False\n    \"\"\"\n\n    def __init__(self, launch_config: dict = None, experience: str = \"\", debug: bool = False) -&gt; None:\n\n        # Initialize variables\n        self.debug = debug\n        self._exiting = False\n        self.config = dict()\n        self._framework = None\n\n        # Load omni extensions\n        self._load_omni_extensions(launch_config=launch_config, experience=experience)\n\n        # Get Omniverse application\n        self._app = omni.kit.app.get_app()\n        self._start_app()\n\n        # once app starts, we can set / load settings\n        from omni.isaac.kit.utils import open_stage, create_new_stage, set_livesync_stage\n        self._carb_settings = carb.settings.get_settings()\n\n        # apply render settings specified in config\n        self.reset_render_settings()\n        set_carb_setting(self._carb_settings, \"/persistent/simulation/defaultMetersPerUnit\", 1.0)\n        self._app.print_and_log(\"Simulation App Starting\")\n        self._app.update()\n\n        # Possibly open a USD file, otherwise create a new stage\n        self.open_usd = self.config.get(\"open_usd\")\n        if self.open_usd is not None:\n            print(\"Opening usd file at \", self.open_usd, \" ...\", end=\"\")\n            if open_stage(self.open_usd) is False:\n                print(\"Could not open\", self.open_usd, \"creating a new empty stage\")\n                create_new_stage()\n            else:\n                print(\"Done.\")\n        else:\n            print(\"Creating empty stage\")\n            create_new_stage()\n\n        # Possibly open a livesync USD file\n        self.livesync_usd = self.config.get(\"livesync_usd\")\n        if self.livesync_usd != None:\n            print(\"Saving a temp livesync stage at \", self.livesync_usd, \" ...\", end=\"\")\n            if set_livesync_stage(self.livesync_usd, True):\n                print(\"Done.\")\n            else:\n                print(\"Could not save usd file to \", self.livesync_usd)\n\n        # Update the app\n        self._app.update()\n        # Dock floating UIs\n        self._prepare_ui()\n        if self.config.get(\"memory_report\"):\n            from omni.isaac.core.utils.statistics import get_memory_stats\n\n            self.start_memory_stats = get_memory_stats()\n        # Notify toolkit is running\n        self._app.print_and_log(\"Simulation App Startup Complete\")\n\n    def _load_omni_extensions(self, launch_config=None, experience=\"\"):\n        \"\"\"\n        Loads omniverse extensions into this App, based on the settings speciifed by @experience\n\n        :param launch_config: dict, settings for generating this app\n        :param experience: str, path to extension settings file for this app\n        \"\"\"\n        # Load omnigibson module now to prevent circular imports\n        import omnigibson\n\n        # Sanity check to see if any extra omniverse modules are loaded\n        # Warn users if so because this will usually cause issues.\n        # Base list of modules that can be loaded before kit app starts, might need to be updated in the future\n        ok_list = [\n            \"omni\",\n            \"omni.isaac\",\n            \"omni.isaac.kit\",\n            \"omni.isaac.kit.simulation_app\",\n            \"omni.kit\",\n            \"omni.kit.app\",\n            \"omni.kit.app.impl\",\n            \"omni.kit.app.impl.app_iface\",\n            \"omni.kit.app.impl.telemetry_helpers\",\n            \"omni.ext\",\n            \"omni.ext.impl\",\n            \"omni.ext._extensions\",\n            \"omni.ext.impl._internal\",\n            \"omni.ext.impl.leak_detection\",\n            \"omni.kit.app._app\",\n        ]\n        r = re.compile(\"omni.*|pxr.*\")\n        found_modules = list(filter(r.match, list(sys.modules.keys())))\n        result = []\n        for item in found_modules:\n            if item not in ok_list:\n                result.append(item)\n        # Made this a warning instead of an error as the above list might be incomplete\n        if len(result):\n            carb.log_warn(\n                f\"Modules: {result} were loaded before SimulationApp was started and might not be loaded correctly.\"\n            )\n            carb.log_warn(\n                \"Please check to make sure no extra omniverse or pxr modules are imported before the call to SimulationApp(...)\"\n            )\n\n        # Initialize variables\n        builtins.ISAAC_LAUNCHED_FROM_TERMINAL = False\n        self._exiting = False\n\n        # Override settings from input config\n        self.config = self.DEFAULT_LAUNCHER_CONFIG\n        if experience == \"\":\n            experience = f'{omnigibson.root_path}/configs/apps/omni.isaac.sim.python.kit'\n        self.config.update({\"experience\": experience})\n        if launch_config is not None:\n            self.config.update(launch_config)\n        if builtins.ISAAC_LAUNCHED_FROM_JUPYTER:\n            if self.config[\"headless\"] is False:\n                carb.log_warn(\"Non-headless mode not supported with jupyter notebooks\")\n                self.config.update({\"headless\": True})\n\n        # Load omniverse application plugins\n        self._framework = carb.get_framework()\n        self._framework.load_plugins(\n            loaded_file_wildcards=[\"omni.kit.app.plugin\"],\n            search_paths=[os.path.abspath(f'{os.environ[\"CARB_APP_PATH\"]}/plugins')],\n        )\n\n    def __del__(self):\n        \"\"\"Destructor for the class.\"\"\"\n        if self._exiting is False and sys.meta_path is None:\n            print(\n                \"\\033[91m\"\n                + \"ERROR: Python exiting while SimulationApp was still running, Please call close() on the SimulationApp object to exit cleanly\"\n                + \"\\033[0m\"\n            )\n        pass\n\n    \"\"\"\n    Private methods\n    \"\"\"\n\n    def _start_app(self) -&gt; None:\n        \"\"\"Launch the Omniverse application.\"\"\"\n        exe_path = os.path.abspath(f'{os.environ[\"CARB_APP_PATH\"]}')\n        # input arguments to the application\n        args = [\n            os.path.abspath(__file__),\n            f'{self.config[\"experience\"]}',\n            f\"--/app/tokens/exe-path={exe_path}\",  # this is needed so dlss lib is found\n            f'--/persistent/app/viewport/displayOptions={self.config[\"display_options\"]}',  # hide extra stuff in viewport\n            # Forces kit to not render until all USD files are loaded\n            f'--/rtx/materialDb/syncLoads={self.config[\"sync_loads\"]}',\n            f'--/rtx/hydra/materialSyncLoads={self.config[\"sync_loads\"]}'\n            f'--/omni.kit.plugin/syncUsdLoads={self.config[\"sync_loads\"]}',\n            f'--/app/renderer/resolution/width={self.config[\"width\"]}',\n            f'--/app/renderer/resolution/height={self.config[\"height\"]}',\n            f'--/app/window/width={self.config[\"window_width\"]}',\n            f'--/app/window/height={self.config[\"window_height\"]}',\n            f'--/renderer/multiGpu/enabled={self.config[\"multi_gpu\"]}',\n            \"--ext-folder\",\n            f'{os.path.abspath(os.environ[\"ISAAC_PATH\"])}/exts',  # adding to json doesn't work\n        ]\n        if self.config.get(\"active_gpu\") is not None:\n            args.append(f'--/renderer/activeGpu={self.config[\"active_gpu\"]}')\n        # parse any extra command line args here\n        # user script should provide its own help, otherwise we default to printing the kit app help output\n        parser = argparse.ArgumentParser(add_help=False)\n        parsed_args, unknown_args = parser.parse_known_args()\n        # is user did not request portable root,\n        # we still run apps as portable to prevent them writing extra files to user directory\n        if \"--portable-root\" not in unknown_args:\n            args.append(\"--portable\")\n        if self.config.get(\"headless\") and \"--no-window\" not in unknown_args:\n            args.append(\"--no-window\")\n\n        # get the effective uid of this process, if its root, then we automatically add the allow root flag\n        # if the flag is already in unknown_args, we don't need to add it again.\n        if sys.platform.startswith(\"linux\"):\n            if os.geteuid() == 0 and \"--allow-root\" not in unknown_args:\n                args.append(\"--allow-root\")\n\n        # pass all extra arguments onto the main kit app\n        print(\"Passing the following args to the base kit application: \", unknown_args)\n        args.extend(unknown_args)\n        self.app.startup(\"kit\", os.environ[\"CARB_APP_PATH\"], args)\n        # if user called with -h kit auto exits so we force exit the script here as well\n        if \"-h\" in unknown_args or \"--help\" in unknown_args:\n            sys.exit()\n\n    def _set_render_settings(self, default: bool = False) -&gt; None:\n        \"\"\"Set render settings to those in config.\n\n        Note:\n            This should be used in case a new stage is opened and the desired config needs\n            to be re-applied.\n\n        Args:\n            default (bool, optional): Whether to setup RTX default or non-default settings. Defaults to False.\n        \"\"\"\n        # Define mode to configure settings into.\n        if default:\n            rtx_mode = \"/rtx-defaults\"\n        else:\n            rtx_mode = \"/rtx\"\n\n        # Set renderer mode.\n        set_carb_setting(self._carb_settings, rtx_mode + \"/rendermode\", self.config[\"renderer\"])\n        # Raytrace mode settings\n        set_carb_setting(self._carb_settings, rtx_mode + \"/post/aa/op\", self.config[\"anti_aliasing\"])\n        # Pathtrace mode settings\n        set_carb_setting(self._carb_settings, rtx_mode + \"/pathtracing/spp\", self.config[\"samples_per_pixel_per_frame\"])\n        set_carb_setting(\n            self._carb_settings, rtx_mode + \"/pathtracing/totalSpp\", self.config[\"samples_per_pixel_per_frame\"]\n        )\n        set_carb_setting(\n            self._carb_settings, rtx_mode + \"/pathtracing/clampSpp\", self.config[\"samples_per_pixel_per_frame\"]\n        )\n        set_carb_setting(self._carb_settings, rtx_mode + \"/pathtracing/maxBounces\", self.config[\"max_bounces\"])\n        set_carb_setting(\n            self._carb_settings,\n            rtx_mode + \"/pathtracing/maxSpecularAndTransmissionBounces\",\n            self.config[\"max_specular_transmission_bounces\"],\n        )\n        set_carb_setting(\n            self._carb_settings, rtx_mode + \"/pathtracing/maxVolumeBounces\", self.config[\"max_volume_bounces\"]\n        )\n        set_carb_setting(self._carb_settings, rtx_mode + \"/pathtracing/optixDenoiser/enabled\", self.config[\"denoiser\"])\n        set_carb_setting(\n            self._carb_settings, rtx_mode + \"/hydra/subdivision/refinementLevel\", self.config[\"subdiv_refinement_level\"]\n        )\n\n        # Experimental, forces kit to not render until all USD files are loaded\n        set_carb_setting(self._carb_settings, rtx_mode + \"/materialDb/syncLoads\", self.config[\"sync_loads\"])\n        set_carb_setting(self._carb_settings, rtx_mode + \"/hydra/materialSyncLoads\", self.config[\"sync_loads\"])\n        set_carb_setting(self._carb_settings, \"/omni.kit.plugin/syncUsdLoads\", self.config[\"sync_loads\"])\n\n    def _prepare_ui(self) -&gt; None:\n        \"\"\"Dock the windows in the UI if they exist.\"\"\"\n        import omni.ui\n\n        # Method for docking a particular window to a location\n        def dock_window(space, name, location, ratio=0.5):\n            window = omni.ui.Workspace.get_window(name)\n            if window and space:\n                window.dock_in(space, location, ratio=ratio)\n            return window\n\n        # Acquire the main docking station\n        main_dockspace = omni.ui.Workspace.get_window(\"DockSpace\")\n        # Acquire the docking space for viewport\n        view = dock_window(main_dockspace, \"Viewport\", omni.ui.DockPosition.TOP)\n        self._app.update()\n\n        # If we're in debug mode, we keep all the extension windows and dock them appropriately\n        if self.debug:\n            console = dock_window(view, \"Console\", omni.ui.DockPosition.BOTTOM, 0.3)\n            dock_window(view, \"Main ToolBar\", omni.ui.DockPosition.LEFT)\n            self._app.update()\n            # Acquire the docking window where `Stage` tab is present and add tabs\n            render = dock_window(main_dockspace, \"Render Settings\", omni.ui.DockPosition.RIGHT, 0.3)\n            dock_window(render, \"Stage\", omni.ui.DockPosition.SAME)\n            dock_window(render, \"Layer\", omni.ui.DockPosition.SAME)\n            dock_window(console, \"Content\", omni.ui.DockPosition.SAME)\n            self._app.update()\n            dock_window(render, \"Property\", omni.ui.DockPosition.BOTTOM)\n            self._app.update()\n            hide_window_names = m.DEFAULT_HIDE_WINDOWS\n\n        # Otherwise, we remove all components that aren't the viewer\n        else:\n            hide_window_names = [\"Console\", \"Main ToolBar\", \"Stage\", \"Layer\", \"Property\", \"Render Settings\", \"Content\", \"Flow\", \"Semantics Schema Editor\"]\n\n        # Hide all requested windows\n        for name in hide_window_names:\n            window = omni.ui.Workspace.get_window(name)\n            if window is not None:\n                window.visible = False\n                self._app.update()\n\n    \"\"\"\n    Public methods\n    \"\"\"\n\n    def update(self) -&gt; None:\n        \"\"\"\n        Convenience function to step the application forward one frame\n        \"\"\"\n        self._app.update()\n        return\n\n    def set_setting(self, setting: str, value) -&gt; None:\n        \"\"\"\n        Set a carbonite setting\n\n        Args:\n            setting (str): carb setting path\n            value: value to set the setting to, type is used to properly set the setting.\n        \"\"\"\n        set_carb_setting(self._carb_settings, setting, value)\n\n    def reset_render_settings(self):\n        \"\"\"Reset render settings to those in config.\n\n        Note:\n            This should be used in case a new stage is opened and the desired config needs\n            to be re-applied.\n        \"\"\"\n        # Set rtx-default renderder settings\n        self._set_render_settings(default=True)\n        # Set rtx settings renderer settings\n        self._set_render_settings(default=False)\n\n    def close(self) -&gt; None:\n        \"\"\"Close the running Omniverse Toolkit.\"\"\"\n        # workaround for exit issues, clean the stage first:\n        omni.usd.get_context().close_stage()\n        omni.kit.app.get_app().update()\n        # check if exited already\n        if not self._exiting:\n            self._exiting = True\n            self._app.print_and_log(\"Simulation App Shutting Down\")\n            if self.config.get(\"memory_report\"):\n                from pprint import pprint\n                from omni.isaac.core.utils.statistics import get_memory_stats, get_memory_delta\n\n                self.end_memory_stats = get_memory_stats()\n                print(\"Memory usage delta:\\n\")\n                pprint(get_memory_delta(self.start_memory_stats, self.end_memory_stats))\n\n            # We are exisitng but something is still loading, wait for it to load to avoid a deadlock\n            from omni.isaac.kit.utils import is_stage_loading\n\n            if is_stage_loading():\n                print(\"   Waiting for USD resource operations to complete (this may take a few seconds)\")\n            while is_stage_loading():\n                self._app.update()\n            self._app.shutdown()\n            self._framework.unload_all_plugins()\n            # Force all omni module to unload on close\n            # This prevents crash on exit\n            for m in list(sys.modules.keys()):\n                if \"omni\" in m and m != \"omni.kit.app\":\n                    del sys.modules[m]\n            print(\"Simulation App Shutdown Complete\")\n\n    def is_running(self) -&gt; bool:\n        \"\"\"\n            bool: convenience function to see if app is running. True if running, False otherwise\n        \"\"\"\n        # If there is no stage, we can assume that the app is about to close\n        return self._app.is_running() and not self.is_exiting() and self.context.get_stage() is not None\n\n    def is_exiting(self) -&gt; bool:\n        \"\"\"\n            bool: True if close() was called previously, False otherwise\n        \"\"\"\n        return self._exiting\n\n    @property\n    def app(self) -&gt; omni.kit.app.IApp:\n        \"\"\"\n            omni.kit.app.IApp: omniverse kit application object\n        \"\"\"\n        return self._app\n\n    @property\n    def context(self) -&gt; omni.usd.UsdContext:\n        \"\"\"\n            omni.usd.UsdContext: the current USD context\n        \"\"\"\n        return omni.usd.get_context()\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp"},{"title":"<code>DEFAULT_LAUNCHER_CONFIG = {'headless': True, 'active_gpu': None, 'multi_gpu': True, 'sync_loads': True, 'width': 1280, 'height': 720, 'window_width': 1440, 'window_height': 900, 'display_options': 3094, 'subdiv_refinement_level': 0, 'renderer': 'RayTracedLighting', 'anti_aliasing': 3, 'samples_per_pixel_per_frame': 64, 'denoiser': True, 'max_bounces': 4, 'max_specular_transmission_bounces': 6, 'max_volume_bounces': 4, 'open_usd': None, 'livesync_usd': None, 'memory_report': False}</code>  <code>class-attribute</code>","text":"<p>The config variable is a dictionary containing the following entries</p> <p>Parameters:</p>    Name Type Description Default     <code>headless</code>  <code>bool</code>  <p>Disable UI when running. Defaults to True</p>  required    <code>active_gpu</code>  <code>int</code>  <p>Specify the GPU to use when running, set to None to use default value which is usually the first gpu, default is None</p>  required    <code>multi_gpu</code>  <code>bool</code>  <p>Set to true to enable Multi GPU support, Defaults to true</p>  required    <code>sync_loads</code>  <code>bool</code>  <p>When enabled, will pause rendering until all assets are loaded. Defaults to True</p>  required    <code>width</code>  <code>int</code>  <p>Width of the viewport and generated images. Defaults to 1280</p>  required    <code>height</code>  <code>int</code>  <p>Height of the viewport and generated images. Defaults to 720</p>  required    <code>window_width</code>  <code>int</code>  <p>Width of the application window, independent of viewport, defaults to 1440,</p>  required    <code>window_height</code>  <code>int</code>  <p>Height of the application window, independent of viewport, defaults to 900,</p>  required    <code>display_options</code>  <code>int</code>  <p>used to specify whats visible in the stage by default. Defaults to 3094 so extra objects do not appear in synthetic data. 3286 is another good default, used for the regular isaac-sim editor experience</p>  required    <code>subdiv_refinement_level</code>  <code>int</code>  <p>Number of subdivisons to perform on supported geometry. Defaults to 0</p>  required    <code>renderer</code>  <code>str</code>  <p>Rendering mode, can be  <code>RayTracedLighting</code> or <code>PathTracing</code>. Defaults to <code>PathTracing</code></p>  required    <code>anti_aliasing</code>  <code>int</code>  <p>Antialiasing mode, 0: Disabled, 1: TAA, 2: FXAA, 3: DLSS, 4:RTXAA</p>  required    <code>samples_per_pixel_per_frame</code>  <code>int</code>  <p>The number of samples to render per frame, increase for improved quality, used for <code>PathTracing</code> only. Defaults to 64</p>  required    <code>denoiser</code>  <code>bool</code>  <p>Enable this to use AI denoising to improve image quality, used for <code>PathTracing</code> only. Defaults to True</p>  required    <code>max_bounces</code>  <code>int</code>  <p>Maximum number of bounces, used for <code>PathTracing</code> only. Defaults to 4</p>  required    <code>max_specular_transmission_bounces</code>  <code>int</code>  <p>Maximum number of bounces for specular or transmission, used for <code>PathTracing</code> only. Defaults to 6</p>  required    <code>max_volume_bounces</code>  <code>int</code>  <p>Maximum number of bounces for volumetric materials, used for <code>PathTracing</code> only. Defaults to 4</p>  required    <code>open_usd</code>  <code>str</code>  <p>This is the name of the usd to open when the app starts. It will not be saved over. Default is None and an empty stage is created on startup.</p>  required    <code>livesync_usd</code>  <code>str</code>  <p>This is the location of the usd that you want to do your interactive work in.  The existing file is overwritten. Default is None</p>  required    <code>memory_report</code>  <code>bool</code>  <p>Set to true to print a memory usage report on exit. Default is False</p>  required","location":"reference/app_omni.html#app_omni.OmniApp.DEFAULT_LAUNCHER_CONFIG"},{"title":"<code>app: omni.kit.app.IApp</code>  <code>property</code>","text":"<p>omni.kit.app.IApp: omniverse kit application object</p>","location":"reference/app_omni.html#app_omni.OmniApp.app"},{"title":"<code>context: omni.usd.UsdContext</code>  <code>property</code>","text":"<p>omni.usd.UsdContext: the current USD context</p>","location":"reference/app_omni.html#app_omni.OmniApp.context"},{"title":"<code>__del__()</code>","text":"<p>Destructor for the class.</p>  Source code in <code>omnigibson/app_omni.py</code> <pre><code>def __del__(self):\n    \"\"\"Destructor for the class.\"\"\"\n    if self._exiting is False and sys.meta_path is None:\n        print(\n            \"\\033[91m\"\n            + \"ERROR: Python exiting while SimulationApp was still running, Please call close() on the SimulationApp object to exit cleanly\"\n            + \"\\033[0m\"\n        )\n    pass\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp.__del__"},{"title":"<code>close()</code>","text":"<p>Close the running Omniverse Toolkit.</p>  Source code in <code>omnigibson/app_omni.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the running Omniverse Toolkit.\"\"\"\n    # workaround for exit issues, clean the stage first:\n    omni.usd.get_context().close_stage()\n    omni.kit.app.get_app().update()\n    # check if exited already\n    if not self._exiting:\n        self._exiting = True\n        self._app.print_and_log(\"Simulation App Shutting Down\")\n        if self.config.get(\"memory_report\"):\n            from pprint import pprint\n            from omni.isaac.core.utils.statistics import get_memory_stats, get_memory_delta\n\n            self.end_memory_stats = get_memory_stats()\n            print(\"Memory usage delta:\\n\")\n            pprint(get_memory_delta(self.start_memory_stats, self.end_memory_stats))\n\n        # We are exisitng but something is still loading, wait for it to load to avoid a deadlock\n        from omni.isaac.kit.utils import is_stage_loading\n\n        if is_stage_loading():\n            print(\"   Waiting for USD resource operations to complete (this may take a few seconds)\")\n        while is_stage_loading():\n            self._app.update()\n        self._app.shutdown()\n        self._framework.unload_all_plugins()\n        # Force all omni module to unload on close\n        # This prevents crash on exit\n        for m in list(sys.modules.keys()):\n            if \"omni\" in m and m != \"omni.kit.app\":\n                del sys.modules[m]\n        print(\"Simulation App Shutdown Complete\")\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp.close"},{"title":"<code>is_exiting()</code>","text":"<p>bool: True if close() was called previously, False otherwise</p>  Source code in <code>omnigibson/app_omni.py</code> <pre><code>def is_exiting(self) -&gt; bool:\n    \"\"\"\n        bool: True if close() was called previously, False otherwise\n    \"\"\"\n    return self._exiting\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp.is_exiting"},{"title":"<code>is_running()</code>","text":"<p>bool: convenience function to see if app is running. True if running, False otherwise</p>  Source code in <code>omnigibson/app_omni.py</code> <pre><code>def is_running(self) -&gt; bool:\n    \"\"\"\n        bool: convenience function to see if app is running. True if running, False otherwise\n    \"\"\"\n    # If there is no stage, we can assume that the app is about to close\n    return self._app.is_running() and not self.is_exiting() and self.context.get_stage() is not None\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp.is_running"},{"title":"<code>reset_render_settings()</code>","text":"<p>Reset render settings to those in config.</p>  Note <p>This should be used in case a new stage is opened and the desired config needs to be re-applied.</p>   Source code in <code>omnigibson/app_omni.py</code> <pre><code>def reset_render_settings(self):\n    \"\"\"Reset render settings to those in config.\n\n    Note:\n        This should be used in case a new stage is opened and the desired config needs\n        to be re-applied.\n    \"\"\"\n    # Set rtx-default renderder settings\n    self._set_render_settings(default=True)\n    # Set rtx settings renderer settings\n    self._set_render_settings(default=False)\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp.reset_render_settings"},{"title":"<code>set_setting(setting, value)</code>","text":"<p>Set a carbonite setting</p> <p>Parameters:</p>    Name Type Description Default     <code>setting</code>  <code>str</code>  <p>carb setting path</p>  required    <code>value</code>   <p>value to set the setting to, type is used to properly set the setting.</p>  required      Source code in <code>omnigibson/app_omni.py</code> <pre><code>def set_setting(self, setting: str, value) -&gt; None:\n    \"\"\"\n    Set a carbonite setting\n\n    Args:\n        setting (str): carb setting path\n        value: value to set the setting to, type is used to properly set the setting.\n    \"\"\"\n    set_carb_setting(self._carb_settings, setting, value)\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp.set_setting"},{"title":"<code>update()</code>","text":"<p>Convenience function to step the application forward one frame</p>  Source code in <code>omnigibson/app_omni.py</code> <pre><code>def update(self) -&gt; None:\n    \"\"\"\n    Convenience function to step the application forward one frame\n    \"\"\"\n    self._app.update()\n    return\n</code></pre>","location":"reference/app_omni.html#app_omni.OmniApp.update"},{"title":"<code>set_carb_setting(carb_settings, setting, value)</code>","text":"<p>Convenience function to set settings.</p> <p>Parameters:</p>    Name Type Description Default     <code>setting</code>  <code>str</code>  <p>Name of setting to change.</p>  required    <code>value</code>  <code>Any</code>  <p>New value for the setting.</p>  required     <p>Raises:</p>    Type Description      <code>TypeError</code>  <p>If the type of value does not match setting type.</p>     Source code in <code>omnigibson/app_omni.py</code> <pre><code>def set_carb_setting(carb_settings: carb.settings.ISettings, setting: str, value: Any) -&gt; None:\n    \"\"\"\n    Convenience function to set settings.\n\n    Args:\n        setting (str): Name of setting to change.\n        value (Any): New value for the setting.\n\n    Raises:\n        TypeError: If the type of value does not match setting type.\n    \"\"\"\n    if isinstance(value, str):\n        carb_settings.set_string(setting, value)\n    elif isinstance(value, bool):\n        carb_settings.set_bool(setting, value)\n    elif isinstance(value, int):\n        carb_settings.set_int(setting, value)\n    elif isinstance(value, float):\n        carb_settings.set_float(setting, value)\n    elif isinstance(value, Iterable) and not isinstance(value, dict):\n        if len(value) == 0:\n            raise TypeError(f\"Array of type {type(value)} must be nonzero.\")\n        if isinstance(value[0], str):\n            carb_settings.set_string_array(setting, value)\n        elif isinstance(value[0], bool):\n            carb_settings.set_bool_array(setting, value)\n        elif isinstance(value[0], int):\n            carb_settings.set_int_array(setting, value)\n        elif isinstance(value[0], float):\n            carb_settings.set_float_array(setting, value)\n        else:\n            raise TypeError(f\"Value of type {type(value)} is not supported.\")\n    else:\n        raise TypeError(f\"Value of type {type(value)} is not supported.\")\n</code></pre>","location":"reference/app_omni.html#app_omni.set_carb_setting"},{"title":"macros","text":"<p>Set of macros to use globally for OmniGibson. These are generally magic numbers that were tuned heuristically.</p> <p>NOTE: This is generally decentralized -- the monolithic @settings variable is created here with some global values, but submodules within OmniGibson may import this dictionary and add to it dynamically</p>","location":"reference/macros.html"},{"title":"<code>create_module_macros(module_path)</code>","text":"<p>Creates a dictionary that can be populated with module macros based on the module's @module_path</p> <p>Parameters:</p>    Name Type Description Default     <code>module_path</code>  <code>str</code>  <p>Relative path from the package root directory pointing to the module. This will be parsed to generate the appropriate sub-macros dictionary, e.g., for module \"dirty\" in omnigibson/object_states_dirty.py, this would generate a dictionary existing at macros.object_states.dirty</p>  required     <p>Returns:</p>    Name Type Description     <code>Dict</code>   <p>addict dictionary which can be populated with values</p>     Source code in <code>omnigibson/macros.py</code> <pre><code>def create_module_macros(module_path):\n    \"\"\"\n    Creates a dictionary that can be populated with module macros based on the module's @module_path\n\n    Args:\n        module_path (str): Relative path from the package root directory pointing to the module. This will be parsed\n            to generate the appropriate sub-macros dictionary, e.g., for module \"dirty\" in\n            omnigibson/object_states_dirty.py, this would generate a dictionary existing at macros.object_states.dirty\n\n    Returns:\n        Dict: addict dictionary which can be populated with values\n    \"\"\"\n    # Sanity check module path, make sure omnigibson/ is in the path\n    assert \"omnigibson/\" in module_path, \\\n        f\"module_path is expected to be a filepath including the omnigibson root directory, got: {module_path}!\"\n\n    # Trim the .py, and anything before and including omnigibson/, and split into its appropriate parts\n    subsections = module_path[:-3].split(\"omnigibson/\")[-1].split(\"/\")\n\n    # Create and return the generated sub-dictionary\n    def _recursively_get_or_create_dict(dic, keys):\n        # If no entry is in @keys, it returns @dic\n        # Otherwise, checks whether the dictionary contains the first entry in @keys, if so, it grabs the\n        # corresponding nested dictionary, otherwise, generates a new Dict() as the value\n        # It then recurisvely calls this function with the new dic and the remaining keys\n        if len(keys) == 0:\n            return dic\n        else:\n            key = keys[0]\n            if key not in dic:\n                dic[key] = Dict()\n            return _recursively_get_or_create_dict(dic=dic[key], keys=keys[1:])\n\n    return _recursively_get_or_create_dict(dic=macros, keys=subsections)\n</code></pre>","location":"reference/macros.html#macros.create_module_macros"},{"title":"simulator","text":"","location":"reference/simulator.html"},{"title":"<code>Simulator</code>","text":"<p>         Bases: <code>SimulationContext</code>, <code>Serializable</code></p> <p>Simulator class for directly interfacing with the physx physics engine.</p>  This is a monolithic class. <p>All created Simulator() instances will reference the same underlying Simulator object</p>  <p>Parameters:</p>    Name Type Description Default     <code>gravity</code>  <code>float</code>  <p>gravity on z direction.</p>  <code>9.81</code>    <code>physics_dt</code>  <code>float</code>  <p>dt between physics steps. Defaults to 1.0 / 60.0.</p>  <code>1.0 / 60.0</code>    <code>rendering_dt</code>  <code>float</code>  <p>dt between rendering steps. Note: rendering means rendering a frame of the current application and not only rendering a frame to the viewports/ cameras. So UI elements of Isaac Sim will be refereshed with this dt as well if running non-headless. Defaults to 1.0 / 60.0.</p>  <code>1.0 / 60.0</code>    <code>stage_units_in_meters</code>  <code>float</code>  <p>The metric units of assets. This will affect gravity value..etc. Defaults to 0.01.</p>  <code>1.0</code>    <code>viewer_width</code>  <code>int</code>  <p>width of the camera image, in pixels</p>  <code>gm.DEFAULT_VIEWER_WIDTH</code>    <code>viewer_height</code>  <code>int</code>  <p>height of the camera image, in pixels</p>  <code>gm.DEFAULT_VIEWER_HEIGHT</code>    <code>device</code>  <code>None or str</code>  <p>specifies the device to be used if running on the gpu with torch backend</p>  <code>None</code>      Source code in <code>omnigibson/simulator.py</code> <pre><code>class Simulator(SimulationContext, Serializable):\n    \"\"\"\n    Simulator class for directly interfacing with the physx physics engine.\n\n    NOTE: This is a monolithic class.\n        All created Simulator() instances will reference the same underlying Simulator object\n\n    Args:\n        gravity (float): gravity on z direction.\n        physics_dt (float): dt between physics steps. Defaults to 1.0 / 60.0.\n        rendering_dt (float): dt between rendering steps. Note: rendering means rendering a frame of the current\n            application and not only rendering a frame to the viewports/ cameras. So UI elements of Isaac Sim will\n            be refereshed with this dt as well if running non-headless. Defaults to 1.0 / 60.0.\n        stage_units_in_meters (float): The metric units of assets. This will affect gravity value..etc.\n            Defaults to 0.01.\n        viewer_width (int): width of the camera image, in pixels\n        viewer_height (int): height of the camera image, in pixels\n        device (None or str): specifies the device to be used if running on the gpu with torch backend\n        \"\"\"\n    _world_initialized = False\n\n    def __init__(\n            self,\n            gravity=9.81,\n            physics_dt=1.0 / 60.0,\n            rendering_dt=1.0 / 60.0,\n            stage_units_in_meters=1.0,\n            viewer_width=gm.DEFAULT_VIEWER_WIDTH,\n            viewer_height=gm.DEFAULT_VIEWER_HEIGHT,\n            device=None,\n    ):\n        super().__init__(\n            physics_dt=physics_dt,\n            rendering_dt=rendering_dt,\n            stage_units_in_meters=stage_units_in_meters,\n            device=device,\n        )\n\n        if self._world_initialized:\n            return\n        Simulator._world_initialized = True\n        self._dc_interface = _dynamic_control.acquire_dynamic_control_interface()\n        set_camera_view()\n        self._data_logger = DataLogger()\n        self._contact_callback = self._physics_context._physx_sim_interface.subscribe_contact_report_events(self._on_contact)\n\n        # Store other internal vars\n        self.gravity = gravity\n\n        # Store other references to variables that will be initialized later\n        self._viewer = None\n        self._viewer_camera = None\n        self._camera_mover = None\n        self._scene = None\n\n        # Initialize viewer\n        # TODO: Make this toggleable so we don't always have a viewer if we don't want to\n        self._set_viewer_settings()\n        self.viewer_width = viewer_width\n        self.viewer_height = viewer_height\n\n        # List of objects that need to be initialized during whenever the next sim step occurs\n        self._objects_to_initialize = []\n\n        # Set of categories that can be grasped by assisted grasping\n        self.object_state_types = get_states_by_dependency_order()\n\n        # Set of all non-Omniverse transition rules to apply.\n        self._transition_rules = DEFAULT_RULES\n\n        # Toggle simulator state once so that downstream omni features can be used without bugs\n        # e.g.: particle sampling, which for some reason requires sim.play() to be called at least once\n        self.play()\n        self.stop()\n\n        # Finally, update the physics settings\n        # This needs to be done now, after an initial step + stop for some reason if we want to use GPU\n        # dynamics, otherwise we get very strange behavior, e.g., PhysX complains about invalid transforms\n        # and crashes\n        self._set_physics_engine_settings()\n\n    def __new__(\n        cls,\n        gravity=9.81,\n        physics_dt=1.0 / 60.0,\n        rendering_dt=1.0 / 60.0,\n        stage_units_in_meters=1.0,\n        viewer_width=gm.DEFAULT_VIEWER_WIDTH,\n        viewer_height=gm.DEFAULT_VIEWER_HEIGHT,\n        device_idx=0,\n    ):\n        # Overwrite since we have different kwargs\n        if Simulator._instance is None:\n            Simulator._instance = object.__new__(cls)\n        else:\n            carb.log_info(\"Simulator is defined already, returning the previously defined one\")\n        return Simulator._instance\n\n    def _set_viewer_camera(self, prim_path=\"/World/viewer_camera\"):\n        \"\"\"\n        Creates a camera prim dedicated for this viewer at @prim_path if it doesn't exist,\n        and sets this camera as the active camera for the viewer\n\n        Args:\n            prim_path (str): Path to check for / create the viewer camera\n        \"\"\"\n        vp = acquire_viewport_interface()\n        viewers_to_names = {vp.get_viewport_window(h): vp.get_viewport_window_name(h) for h in vp.get_instance_list()}\n        self._viewer_camera = VisionSensor(\n            prim_path=prim_path,\n            name=prim_path.split(\"/\")[-1],                  # Assume name is the lowest-level name in the prim_path\n            modalities=\"rgb\",\n            image_height=self.viewer_height,\n            image_width=self.viewer_width,\n            viewport_name=viewers_to_names[self._viewer],\n        )\n        if not self._viewer_camera.loaded:\n            self._viewer_camera.load(simulator=self)\n\n        # We update its clipping range and focal length so we get a good FOV and so that it doesn't clip\n        # nearby objects (default min is 1 m)\n        self._viewer_camera.clipping_range = [0.001, 10000000.0]\n        self._viewer_camera.focal_length = 17.0\n\n        # Initialize the sensor\n        self._viewer_camera.initialize()\n\n        # Also need to potentially update our camera mover if it already exists\n        if self._camera_mover is not None:\n            self._camera_mover.set_cam(cam=self._viewer_camera)\n\n    def _set_physics_engine_settings(self):\n        \"\"\"\n        Set the physics engine with specified settings\n        \"\"\"\n        assert self.is_stopped(), f\"Cannot set simulator physics settings while simulation is playing!\"\n        self._physics_context.set_gravity(value=-self.gravity)\n        # Also make sure we invert the collision group filter settings so that different collision groups cannot\n        # collide with each other, and modify settings for speed optimization\n        self._physics_context.set_invert_collision_group_filter(True)\n        self._physics_context.enable_ccd(gm.ENABLE_CCD)\n        self._physics_context.enable_flatcache(gm.ENABLE_FLATCACHE)\n\n        # Enable GPU dynamics based on whether we need omni particles feature\n        if gm.USE_GPU_DYNAMICS:\n            self._physics_context.enable_gpu_dynamics(True)\n            self._physics_context.set_broadphase_type(\"GPU\")\n        else:\n            self._physics_context.enable_gpu_dynamics(False)\n            self._physics_context.set_broadphase_type(\"MBP\")\n\n        # Set GPU Pairs capacity and other GPU settings\n        self._physics_context.set_gpu_found_lost_pairs_capacity(gm.GPU_PAIRS_CAPACITY)\n        self._physics_context.set_gpu_found_lost_aggregate_pairs_capacity(gm.GPU_AGGR_PAIRS_CAPACITY)\n        self._physics_context.set_gpu_total_aggregate_pairs_capacity(gm.GPU_AGGR_PAIRS_CAPACITY)\n        self._physics_context.set_gpu_max_particle_contacts(gm.GPU_MAX_PARTICLE_CONTACTS)\n\n    @property\n    def viewer_visibility(self):\n        \"\"\"\n        Returns:\n            bool: Whether the viewer is visible or not\n        \"\"\"\n        return self._viewer_camera.viewer_visibility\n\n    @viewer_visibility.setter\n    def viewer_visibility(self, visible):\n        \"\"\"\n        Sets whether the viewer should be visible or not in the Omni UI\n\n        Args:\n            visible (bool): Whether the viewer should be visible or not\n        \"\"\"\n        self._viewer_camera.viewer_visibility = visible\n\n    @property\n    def viewer_height(self):\n        \"\"\"\n        Returns:\n            int: viewer height of this sensor, in pixels\n        \"\"\"\n        # If the viewer camera hasn't been created yet, utilize the default width\n        return gm.DEFAULT_VIEWER_HEIGHT if self._viewer_camera is None else self._viewer_camera.image_height\n\n    @viewer_height.setter\n    def viewer_height(self, height):\n        \"\"\"\n        Sets the viewer height @height for this sensor\n\n        Args:\n            height (int): viewer height, in pixels\n        \"\"\"\n        self._viewer_camera.image_height = height\n\n    @property\n    def viewer_width(self):\n        \"\"\"\n        Returns:\n            int: viewer width of this sensor, in pixels\n        \"\"\"\n        # If the viewer camera hasn't been created yet, utilize the default height\n        return gm.DEFAULT_VIEWER_WIDTH if self._viewer_camera is None else self._viewer_camera.image_width\n\n    @viewer_width.setter\n    def viewer_width(self, width):\n        \"\"\"\n        Sets the viewer width @width for this sensor\n\n        Args:\n            width (int): viewer width, in pixels\n        \"\"\"\n        self._viewer_camera.image_width = width\n\n    def _set_viewer_settings(self):\n        \"\"\"\n        Initializes a reference to the viewer in the App, and sets the frame size\n        \"\"\"\n        # Store reference to viewer (see https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/reference_python_snippets.html#get-camera-parameters)\n        viewport = acquire_viewport_interface()\n        viewport_handle = viewport.get_instance(\"Viewport\")\n        self._viewer = viewport.get_viewport_window(viewport_handle)\n\n        # Set viewer camera and frame size\n        self._set_viewer_camera()\n\n    def enable_viewer_camera_teleoperation(self):\n        \"\"\"\n        Enables keyboard control of the active viewer camera for this simulation\n        \"\"\"\n        self._camera_mover = CameraMover(cam=self._viewer_camera)\n        self._camera_mover.print_info()\n\n    def import_scene(self, scene):\n        \"\"\"\n        Import a scene into the simulator. A scene could be a synthetic one or a realistic Gibson Environment.\n\n        Args:\n            scene (Scene): a scene object to load\n        \"\"\"\n        assert self.is_stopped(), \"Simulator must be stopped while importing a scene!\"\n        assert isinstance(scene, Scene), \"import_scene can only be called with Scene\"\n\n        # Clear the existing scene if any\n        self.clear()\n\n        self._scene = scene\n        self._scene.load(self)\n\n        # Make sure simulator is not running, then start it so that we can initialize the scene\n        assert self.is_stopped(), \"Simulator must be stopped after importing a scene!\"\n        self.play()\n\n        # Initialize the scene\n        self._scene.initialize()\n\n        # Need to one more step for particle systems to work\n        self.step()\n        self.stop()\n\n    def initialize_object_on_next_sim_step(self, obj):\n        \"\"\"\n        Initializes the object upon the next simulation step\n\n        Args:\n            obj (BasePrim): Object to initialize as soon as a new sim step is called\n        \"\"\"\n        self._objects_to_initialize.append(obj)\n\n    def import_object(self, obj, register=True, auto_initialize=True):\n        \"\"\"\n        Import an object into the simulator.\n\n        Args:\n            obj (BaseObject): an object to load\n            register (bool): whether to register this object internally in the scene registry\n            auto_initialize (bool): If True, will auto-initialize the requested object on the next simulation step.\n                Otherwise, we assume that the object will call initialize() on its own!\n        \"\"\"\n        assert isinstance(obj, BaseObject), \"import_object can only be called with BaseObject\"\n\n        # Make sure scene is loaded -- objects should not be loaded unless we have a reference to a scene\n        assert self.scene is not None, \"import_object needs to be called after import_scene\"\n\n        # Load the object in omniverse by adding it to the scene\n        self.scene.add_object(obj, self, register=register, _is_call_from_simulator=True)\n\n        # Lastly, additionally add this object automatically to be initialized as soon as another simulator step occurs\n        # if requested\n        if auto_initialize:\n            self.initialize_object_on_next_sim_step(obj=obj)\n\n    def remove_object(self, obj):\n        \"\"\"\n        Remove a non-robot object from the simulator.\n\n        Args:\n            obj (BaseObject): a non-robot object to load\n        \"\"\"\n        self._scene.remove_object(obj, simulator=self)\n        self.app.update()\n\n    def _non_physics_step(self):\n        \"\"\"\n        Complete any non-physics steps such as state updates.\n        \"\"\"\n        assert not self.is_stopped(), f\"Simulator must not be stopped in order to run non physics step!\"\n        # Check to see if any objects should be initialized (only done IF we're playing)\n        if len(self._objects_to_initialize) &gt; 0 and self.is_playing():\n            for obj in self._objects_to_initialize:\n                obj.initialize()\n            self._objects_to_initialize = []\n            # Also update the scene registry\n            # TODO: A better place to put this perhaps?\n            self._scene.object_registry.update(keys=\"root_handle\")\n\n        # Propagate states if the feature is enabled\n        if gm.ENABLE_OBJECT_STATES:\n\n            # Cache values from all of the micro and macro particle systems.\n            # This is used to store system-wide state which can be queried\n            # by the object state system.\n            for system in self.scene.systems:\n                system.cache()\n\n            # Step the object states in global topological order (if the scene exists).\n            if self.scene is not None:\n                for state_type in self.object_state_types:\n                    for obj in self.scene.get_objects_with_state(state_type):\n                        # Only update objects that have been initialized so far\n                        if obj.initialized:\n                            obj.states[state_type].update()\n\n            # Perform system level updates to the micro and macro particle systems.\n            # This allows for the states to handle changes in response to changes\n            # induced by the object state system.\n            for system in self.scene.systems:\n                system.update()\n\n            for obj in self.scene.objects:\n                # Only update visuals for objects that have been initialized so far\n                if isinstance(obj, StatefulObject) and obj.initialized:\n                    obj.update_visuals()\n\n    def _omni_update_step(self):\n        \"\"\"\n        Step any omni-related things\n        \"\"\"\n        # Clear the bounding box cache so that it gets updated during the next time it's called\n        BoundingBoxAPI.clear()\n\n    def _transition_rule_step(self):\n        \"\"\"\n        Applies all internal non-Omniverse transition rules.\n        \"\"\"\n        # Create a dict from rule to filter to objects we care about.\n        obj_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n        for obj in self.scene.objects + self.scene.robots:\n            for rule in self._transition_rules:\n                for fname, f in rule.individual_filters.items():\n                    if f(obj):\n                        obj_dict[rule][\"individual\"][fname].append(obj)\n                for fname, f in rule.group_filters.items():\n                    if f(obj):\n                        obj_dict[rule][\"group\"][fname].append(obj)\n\n        # For each rule, create a subset of the dict and apply it if applicable.\n        added_obj_attrs = []\n        removed_objs = []\n        for rule in self._transition_rules:\n            # Skip any rule that has no objects\n            if rule not in obj_dict:\n                continue\n            # Skip any rule that has no group filters if it requires group filters\n            group_f_objs = dict()\n            if rule.requires_group_filters:\n                group_f_objs = obj_dict[rule][\"group\"]\n                if len(group_f_objs) == 0:\n                    continue\n\n            # Skip any rule that is missing an individual filter if it requires individual filters\n            if rule.requires_individual_filters:\n                individual_f_objs = obj_dict[rule][\"individual\"]\n                if not all(fname in individual_f_objs for fname in rule.individual_filters.keys()):\n                    continue\n                # Get all cartesian cross product over all individual filter objects, and then attempt the transition rule.\n                # If objects are to be added / removed, the transition function is\n                # expected to return an instance of TransitionResults containing\n                # information about those objects.\n                # TODO: Consider optimizing itertools.product.\n                # TODO: Track what needs to be added / removed at the Scene object level.\n                # Comments from a PR on possible changes:\n                # - Addition / removal tracking on the Scene object.\n                # - Check if the objects are still in the scene in each step.\n                for obj_tuple in itertools.product(*list(individual_f_objs.values())):\n                    individual_objects = {fname: obj for fname, obj in zip(individual_f_objs.keys(), obj_tuple)}\n                    did_transition, transition_output = rule.process(individual_objects=individual_objects, group_objects=group_f_objs)\n                    if transition_output is not None:\n                        # Transition output is a TransitionResults object\n                        added_obj_attrs.extend(transition_output.add)\n                        removed_objs.extend(transition_output.remove)\n            else:\n                # We try the transition rule once, since there's no cartesian cross product of combinations from the\n                # individual filters we need to handle\n                did_transition, transition_output = rule.process(individual_objects=dict(), group_objects=group_f_objs)\n                if transition_output is not None:\n                    added_obj_attrs.extend(transition_output.add)\n                    removed_objs.extend(transition_output.remove)\n\n        # Process all transition results.\n        if len(removed_objs) &gt; 0:\n            disclaimer(\n                f\"We are attempting to remove objects during the transition rule phase of the simulator step.\\n\"\n                f\"However, Omniverse currently has a bug when using GPU dynamics where a segfault will occur if an \"\n                f\"object in contact with another object is attempted to be removed.\\n\"\n                f\"This bug should be fixed by the next Omniverse release.\\n\"\n                f\"In the meantime, we instead teleport these objects to a graveyard location located far outside of \"\n                f\"the scene.\"\n            )\n        for i, removed_obj in enumerate(removed_objs):\n            # TODO: Ideally we want to remove objects, but because of Omniverse's bug on GPU physics, we simply move\n            # the objects into a graveyard for now\n            # self.remove_object(removed_obj)\n            removed_obj.set_position(np.array(m.OBJECT_GRAVEYARD_POS) + np.ones(3) * i)\n\n        for added_obj_attr in added_obj_attrs:\n            new_obj = added_obj_attr.obj\n            self.import_object(added_obj_attr.obj)\n            pos, orn = added_obj_attr.pos, added_obj_attr.orn\n            new_obj.set_position_orientation(position=pos, orientation=orn)\n\n    def reset_scene(self):\n        \"\"\"\n        Resets ths scene (if it exists) and its corresponding objects\n        \"\"\"\n        if self.scene is not None and self.scene.initialized:\n            self.scene.reset()\n\n    def play(self):\n        super().play()\n\n        # Update all object / robot handles\n        if self.scene is not None and self.scene.initialized:\n            for obj in self.scene.objects:\n                # Only need to update handles if object is already initialized as well\n                if obj.initialized:\n                    obj.update_handles()\n\n            for robot in self.scene.robots:\n                # Only need to update handles if robot is already initialized as well\n                if robot.initialized:\n                    robot.update_handles()\n\n        # Check to see if any objects should be initialized\n        if len(self._objects_to_initialize) &gt; 0:\n            for obj in self._objects_to_initialize:\n                obj.initialize()\n            self._objects_to_initialize = []\n            # Also update the scene registry\n            # TODO: A better place to put this perhaps?\n            self._scene.object_registry.update(keys=\"root_handle\")\n\n    @property\n    def n_physics_timesteps_per_render(self):\n        \"\"\"\n        Number of physics timesteps per rendering timestep. rendering_dt has to be a multiple of physics_dt.\n\n        Returns:\n            int: Discrete number of physics timesteps to take per step\n        \"\"\"\n        n_physics_timesteps_per_render = self.get_rendering_dt() / self.get_physics_dt()\n        assert n_physics_timesteps_per_render.is_integer(), \"render_timestep must be a multiple of physics_timestep\"\n        return int(n_physics_timesteps_per_render)\n\n    def step(self, render=True, force_playing=False):\n        \"\"\"\n        Step the simulation at self.render_timestep\n\n        Args:\n            render (bool): Whether rendering should occur or not\n            force_playing (bool): If True, will force physics to propagate (i.e.: set simulation, if paused / stopped,\n                to \"play\" mode)\n        \"\"\"\n        # Possibly force playing\n        if force_playing and not self.is_playing():\n            self.play()\n\n        if render:\n            super().step(render=True)\n        else:\n            for i in range(self.n_physics_timesteps_per_render):\n                super().step(render=False)\n\n        # Additionally run non physics things if we have a valid scene\n        if self._scene is not None:\n            self._omni_update_step()\n            if self.is_playing():\n                self._non_physics_step()\n                if gm.ENABLE_TRANSITION_RULES:\n                    self._transition_rule_step()\n\n        # TODO (eric): After stage changes (e.g. pose, texture change), it will take two super().step(render=True) for\n        #  the result to propagate to the rendering. We could have called super().render() here but it will introduce\n        #  a big performance regression.\n\n    def step_physics(self):\n        \"\"\"\n        Step the physics a single step.\n        \"\"\"\n        self._physics_context._step(current_time=self.current_time)\n\n    def _on_contact(self, contact_headers, contact_data):\n        \"\"\"\n        This callback will be invoked after every PHYSICS step if there is any contact.\n        For each of the pair of objects in each contact, we invoke the on_contact function for each of its states\n        that subclass ContactSubscribedStateMixin. These states update based on contact events.\n        \"\"\"\n        for contact_header in contact_headers:\n            actor0 = str(PhysicsSchemaTools.intToSdfPath(contact_header.actor0))\n            actor1 = str(PhysicsSchemaTools.intToSdfPath(contact_header.actor1))\n            # actor0/1 are prim paths for links that are in contact. Find the corresponding objects.\n            actor0_obj = self._scene.object_registry(\"prim_path\", \"/\".join(actor0.split(\"/\")[:-1]))\n            actor1_obj = self._scene.object_registry(\"prim_path\", \"/\".join(actor1.split(\"/\")[:-1]))\n            if actor0_obj is None or actor1_obj is None or not actor0_obj.initialized or not actor1_obj.initialized:\n                continue\n\n            for obj0, obj1 in [(actor0_obj, actor1_obj), (actor1_obj, actor0_obj)]:\n                if not isinstance(obj0, StatefulObject):\n                    continue\n                for state_type in obj0.states:\n                    if not issubclass(state_type, ContactSubscribedStateMixin):\n                        continue\n                    obj0.states[state_type].on_contact(obj1, contact_header, contact_data)\n\n    def is_paused(self):\n        \"\"\"\n        Returns:\n            bool: True if the simulator is paused, otherwise False\n        \"\"\"\n        return not (self.is_stopped() or self.is_playing())\n\n    @contextlib.contextmanager\n    def stopped(self):\n        \"\"\"\n        A context scope for making sure the simulator is stopped during execution within this scope.\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n        # Infer what state we're currently in, then stop, yield, and then restore the original state\n        sim_is_playing, sim_is_paused = self.is_playing(), self.is_paused()\n        if sim_is_playing or sim_is_paused:\n            og.sim.stop()\n        yield\n        if sim_is_playing: og.sim.play()\n        elif sim_is_paused: og.sim.pause()\n\n    @contextlib.contextmanager\n    def playing(self):\n        \"\"\"\n        A context scope for making sure the simulator is playing during execution within this scope.\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n        # Infer what state we're currently in, then stop, yield, and then restore the original state\n        sim_is_stopped, sim_is_paused = self.is_stopped(), self.is_paused()\n        if sim_is_stopped or sim_is_paused:\n            og.sim.play()\n        yield\n        if sim_is_stopped: og.sim.stop()\n        elif sim_is_paused: og.sim.pause()\n\n    @contextlib.contextmanager\n    def paused(self):\n        \"\"\"\n        A context scope for making sure the simulator is paused during execution within this scope.\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n        # Infer what state we're currently in, then stop, yield, and then restore the original state\n        sim_is_stopped, sim_is_playing = self.is_stopped(), self.is_playing()\n        if sim_is_stopped or sim_is_playing:\n            og.sim.pause()\n        yield\n        if sim_is_stopped: og.sim.stop()\n        elif sim_is_playing: og.sim.play()\n\n    @contextlib.contextmanager\n    def slowed(self, dt):\n        \"\"\"\n        A context scope for making the simulator simulation dt slowed, e.g.: for taking micro-steps for propagating\n        instantaneous kinematics with minimal impact on physics propagation.\n\n        NOTE: This will set both the physics dt and rendering dt to the same value during this scope.\n\n        Upon leaving the scope, the prior simulator state is restored.\n        \"\"\"\n        # Set dt, yield, then restore the original dt\n        physics_dt, rendering_dt = self.get_physics_dt(), self.get_rendering_dt()\n        self.set_simulation_dt(physics_dt=dt, rendering_dt=dt)\n        yield\n        self.set_simulation_dt(physics_dt=physics_dt, rendering_dt=rendering_dt)\n\n    @classmethod\n    def clear_instance(cls):\n        SimulationContext.clear_instance()\n        Simulator._world_initialized = None\n        return\n\n    def __del__(self):\n        SimulationContext.__del__(self)\n        Simulator._world_initialized = None\n        return\n\n    @property\n    def dc(self):\n        \"\"\"\n        Returns:\n            _dynamic_control.DynamicControl: Dynamic control interface\n        \"\"\"\n        return self._dc_interface\n\n    @property\n    def scene(self):\n        \"\"\"\n        Returns:\n            None or Scene: Scene currently loaded in this simulator. If no scene is loaded, returns None\n        \"\"\"\n        return self._scene\n\n    @property\n    def viewer(self):\n        \"\"\"\n        Returns:\n            ViewportWindow: Active viewport window instance shown in the omni UI\n        \"\"\"\n        return self._viewer\n\n    @property\n    def viewer_camera(self):\n        \"\"\"\n        Returns:\n            VisionSensor: Active camera sensor corresponding to the active viewport window instance shown in the omni UI\n        \"\"\"\n        return self._viewer_camera\n\n    @property\n    def world_prim(self):\n        \"\"\"\n        Returns:\n            Usd.Prim: Prim at /World\n        \"\"\"\n        return get_prim_at_path(prim_path=\"/World\")\n\n    def _clear_state(self):\n        \"\"\"\n        Clears the internal state of this simulation\n        \"\"\"\n        # Clear uniquely named items and other internal states\n        clear_pu()\n        clear_uu()\n\n    def clear(self) -&gt; None:\n        \"\"\"\n        Clears the stage leaving the PhysicsScene only if under /World.\n        \"\"\"\n        # Stop the physics\n        self.stop()\n\n        self._scene = None\n        self._data_logger = DataLogger()\n\n        # Load dummy stage, but don't clear sim to prevent circular loops\n        self.load_stage(usd_path=f\"{og.assets_path}/models/misc/clear_stage.usd\")\n\n    def restore(self, json_path):\n        \"\"\"\n        Restore a simulation environment from @json_path.\n\n        Args:\n            json_path (str): Full path of JSON file to load, which contains information\n                to recreate a scene.\n        \"\"\"\n        if not json_path.endswith(\".json\"):\n            logging.error(f\"You have to define the full json_path to load from. Got: {json_path}\")\n            return\n\n        # Clear the current stage\n        self.clear()\n\n        # Load the info from the json\n        with open(json_path, \"r\") as f:\n            scene_info = json.load(f)\n        init_info = scene_info[\"init_info\"]\n        state = scene_info[\"state\"]\n\n        # Override the init info with our json path\n        init_info[\"args\"][\"scene_file\"] = json_path\n\n        # Also make sure we have any additional modifications necessary from the specific scene\n        og.REGISTERED_SCENES[init_info[\"class_name\"]].modify_init_info_for_restoring(init_info=init_info)\n\n        # Recreate and import the saved scene\n        recreated_scene = create_object_from_init_info(init_info)\n        self.import_scene(scene=recreated_scene)\n\n        # Start the simulation and restore the dynamic state of the scene and then pause again\n        self.play()\n        self.load_state(state, serialized=False)\n\n        logging.info(\"The saved simulation environment loaded.\")\n\n        return\n\n    def save(self, json_path):\n        \"\"\"\n        Saves the current simulation environment to @json_path.\n\n        Args:\n            json_path (str): Full path of JSON file to save (should end with .json), which contains information\n                to recreate the current scene.\n        \"\"\"\n        # Make sure the sim is not stopped, since we need to grab joint states\n        assert not self.is_stopped(), \"Simulator cannot be stopped when saving to USD!\"\n\n        # Make sure there are no objects in the initialization queue, if not, terminate early and notify user\n        # Also run other sanity checks before saving\n        if len(self._objects_to_initialize) &gt; 0:\n            logging.error(\"There are still objects to initialize! Please take one additional sim step and then save.\")\n            return\n        if not self.scene:\n            logging.warning(\"Scene has not been loaded. Nothing to save.\")\n            return\n        if not json_path.endswith(\".json\"):\n            logging.error(f\"You have to define the full json_path to save the scene to. Got: {json_path}\")\n            return\n\n        # Update scene info\n        self.scene.update_objects_info()\n\n        # Dump saved current state and also scene init info\n        scene_info = {\n            \"state\": self.scene.dump_state(serialized=False),\n            \"init_info\": self.scene.get_init_info(),\n            \"objects_info\": self.scene.get_objects_info(),\n        }\n\n        # Write this to the json file\n        Path(os.path.dirname(json_path)).mkdir(parents=True, exist_ok=True)\n        with open(json_path, \"w+\") as f:\n            json.dump(scene_info, f, cls=NumpyEncoder, indent=4)\n\n        logging.info(\"The current simulation environment saved.\")\n\n        return\n\n    def get_data_logger(self):\n        \"\"\"\n        Returns the data logger of the world.\n\n        Returns:\n            DataLogger: Data logger associated with this world\n        \"\"\"\n        return self._data_logger\n\n    def load_stage(self, usd_path):\n        \"\"\"\n        Open the stage specified by USD file at @usd_path\n\n        Args:\n            usd_path (str): Absolute filepath to USD stage that should be loaded\n        \"\"\"\n        # Stop the physics if we're playing\n        if not self.is_stopped():\n            logging.warning(\"Stopping simulation in order to load stage.\")\n            self.stop()\n\n        # Store physics dt and rendering dt to reuse later\n        # Note that the stage may have been deleted previously; if so, we use the default values\n        # of 1/60, 1/60\n        try:\n            physics_dt = self.get_physics_dt()\n        except:\n            print(\"WARNING: Invalid or non-existent physics scene found. Setting physics dt to 1/60.\")\n            physics_dt = 1/60.\n        rendering_dt = self.get_rendering_dt()\n\n        # Clear simulation state\n        self._clear_state()\n\n        open_stage(usd_path=usd_path)\n\n        # Re-initialize necessary internal vars\n        self._app = omni.kit.app.get_app_interface()\n        self._framework = carb.get_framework()\n        self._timeline = omni.timeline.get_timeline_interface()\n        self._timeline.set_auto_update(True)\n        self._dynamic_control = _dynamic_control.acquire_dynamic_control_interface()\n        self._cached_rate_limit_enabled = self._settings.get_as_bool(\"/app/runLoops/main/rateLimitEnabled\")\n        self._cached_rate_limit_frequency = self._settings.get_as_int(\"/app/runLoops/main/rateLimitFrequency\")\n        self._cached_min_frame_rate = self._settings.get_as_int(\"persistent/simulation/minFrameRate\")\n        self._loop_runner = omni_loop.acquire_loop_interface()\n\n        self._init_stage(\n            physics_dt=physics_dt,\n            rendering_dt=rendering_dt,\n            stage_units_in_meters=self._initial_stage_units_in_meters,\n        )\n        self._set_physics_engine_settings()\n        self._setup_default_callback_fns()\n        self._stage_open_callback = (\n            omni.usd.get_context().get_stage_event_stream().create_subscription_to_pop(self._stage_open_callback_fn)\n        )\n        self._contact_callback = self._physics_context._physx_sim_interface.subscribe_contact_report_events(self._on_contact)\n\n        # Set the viewer camera, and then set its default pose\n        self._set_viewer_camera()\n        self.viewer_camera.set_position_orientation(\n            position=np.array(m.DEFAULT_VIEWER_CAMERA_POS),\n            orientation=np.array(m.DEFAULT_VIEWER_CAMERA_QUAT),\n        )\n\n    def close(self):\n        \"\"\"\n        Shuts down the OmniGibson application\n        \"\"\"\n        self._app.shutdown()\n\n    @property\n    def device(self):\n        \"\"\"\n        Returns:\n            device (None or str): Device used in simulation backend\n        \"\"\"\n        return self._device\n\n    @device.setter\n    def device(self, device):\n        \"\"\"\n        Sets the device used for sim backend\n\n        Args:\n            device (None or str): Device to set for the simulation backend\n        \"\"\"\n        self._device = device\n        if self._device is not None and \"cuda\" in self._device:\n            device_id = self._settings.get_as_int(\"/physics/cudaDevice\")\n            self._device = f\"cuda:{device_id}\"\n\n    @property\n    def state_size(self):\n        # Total state size is the state size of our scene\n        return self._scene.state_size\n\n    def _dump_state(self):\n        # Default state is from the scene\n        return self._scene.dump_state(serialized=False)\n\n    def _load_state(self, state):\n        # Default state is from the scene\n        self._scene.load_state(state=state, serialized=False)\n\n    def load_state(self, state, serialized=False):\n        # We need to make sure the simulator is playing since joint states only get updated when playing\n        assert self.is_playing()\n\n        # Run super\n        super().load_state(state=state, serialized=serialized)\n\n        # Highlight that at the current step, the non-kinematic states are potentially inaccurate because a sim\n        # step is needed to propagate specific states in physics backend\n        # TODO: This should be resolved in a future omniverse release!\n        disclaimer(\"Attempting to load simulator state.\\n\"\n                   \"Currently, omniverse does not support exclusively stepping kinematics, so we cannot update some \"\n                   \"of our object states relying on updated kinematics until a simulator step is taken!\\n\"\n                   \"Object states such as OnTop, Inside, etc. relying on relative spatial information will inaccurate\"\n                   \"until a single sim step is taken.\\n\"\n                   \"This should be resolved by the next NVIDIA Isaac Sim release.\")\n\n    def _serialize(self, state):\n        # Default state is from the scene\n        return self._scene.serialize(state=state)\n\n    def _deserialize(self, state):\n        # Default state is from the scene\n        return self._scene.deserialize(state=state), self._scene.state_size\n</code></pre>","location":"reference/simulator.html#simulator.Simulator"},{"title":"<code>dc</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>_dynamic_control.DynamicControl: Dynamic control interface</p>","location":"reference/simulator.html#simulator.Simulator.dc"},{"title":"<code>device</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>device</code>  <code>None or str</code>  <p>Device used in simulation backend</p>","location":"reference/simulator.html#simulator.Simulator.device"},{"title":"<code>n_physics_timesteps_per_render</code>  <code>property</code>","text":"<p>Number of physics timesteps per rendering timestep. rendering_dt has to be a multiple of physics_dt.</p> <p>Returns:</p>    Name Type Description     <code>int</code>   <p>Discrete number of physics timesteps to take per step</p>","location":"reference/simulator.html#simulator.Simulator.n_physics_timesteps_per_render"},{"title":"<code>scene</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or Scene: Scene currently loaded in this simulator. If no scene is loaded, returns None</p>","location":"reference/simulator.html#simulator.Simulator.scene"},{"title":"<code>viewer</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>ViewportWindow</code>   <p>Active viewport window instance shown in the omni UI</p>","location":"reference/simulator.html#simulator.Simulator.viewer"},{"title":"<code>viewer_camera</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>VisionSensor</code>   <p>Active camera sensor corresponding to the active viewport window instance shown in the omni UI</p>","location":"reference/simulator.html#simulator.Simulator.viewer_camera"},{"title":"<code>viewer_height</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>viewer height of this sensor, in pixels</p>","location":"reference/simulator.html#simulator.Simulator.viewer_height"},{"title":"<code>viewer_visibility</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether the viewer is visible or not</p>","location":"reference/simulator.html#simulator.Simulator.viewer_visibility"},{"title":"<code>viewer_width</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>viewer width of this sensor, in pixels</p>","location":"reference/simulator.html#simulator.Simulator.viewer_width"},{"title":"<code>world_prim</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>Usd.Prim: Prim at /World</p>","location":"reference/simulator.html#simulator.Simulator.world_prim"},{"title":"<code>clear()</code>","text":"<p>Clears the stage leaving the PhysicsScene only if under /World.</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clears the stage leaving the PhysicsScene only if under /World.\n    \"\"\"\n    # Stop the physics\n    self.stop()\n\n    self._scene = None\n    self._data_logger = DataLogger()\n\n    # Load dummy stage, but don't clear sim to prevent circular loops\n    self.load_stage(usd_path=f\"{og.assets_path}/models/misc/clear_stage.usd\")\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.clear"},{"title":"<code>close()</code>","text":"<p>Shuts down the OmniGibson application</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>def close(self):\n    \"\"\"\n    Shuts down the OmniGibson application\n    \"\"\"\n    self._app.shutdown()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.close"},{"title":"<code>enable_viewer_camera_teleoperation()</code>","text":"<p>Enables keyboard control of the active viewer camera for this simulation</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>def enable_viewer_camera_teleoperation(self):\n    \"\"\"\n    Enables keyboard control of the active viewer camera for this simulation\n    \"\"\"\n    self._camera_mover = CameraMover(cam=self._viewer_camera)\n    self._camera_mover.print_info()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.enable_viewer_camera_teleoperation"},{"title":"<code>get_data_logger()</code>","text":"<p>Returns the data logger of the world.</p> <p>Returns:</p>    Name Type Description     <code>DataLogger</code>   <p>Data logger associated with this world</p>     Source code in <code>omnigibson/simulator.py</code> <pre><code>def get_data_logger(self):\n    \"\"\"\n    Returns the data logger of the world.\n\n    Returns:\n        DataLogger: Data logger associated with this world\n    \"\"\"\n    return self._data_logger\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.get_data_logger"},{"title":"<code>import_object(obj, register=True, auto_initialize=True)</code>","text":"<p>Import an object into the simulator.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>an object to load</p>  required    <code>register</code>  <code>bool</code>  <p>whether to register this object internally in the scene registry</p>  <code>True</code>    <code>auto_initialize</code>  <code>bool</code>  <p>If True, will auto-initialize the requested object on the next simulation step. Otherwise, we assume that the object will call initialize() on its own!</p>  <code>True</code>      Source code in <code>omnigibson/simulator.py</code> <pre><code>def import_object(self, obj, register=True, auto_initialize=True):\n    \"\"\"\n    Import an object into the simulator.\n\n    Args:\n        obj (BaseObject): an object to load\n        register (bool): whether to register this object internally in the scene registry\n        auto_initialize (bool): If True, will auto-initialize the requested object on the next simulation step.\n            Otherwise, we assume that the object will call initialize() on its own!\n    \"\"\"\n    assert isinstance(obj, BaseObject), \"import_object can only be called with BaseObject\"\n\n    # Make sure scene is loaded -- objects should not be loaded unless we have a reference to a scene\n    assert self.scene is not None, \"import_object needs to be called after import_scene\"\n\n    # Load the object in omniverse by adding it to the scene\n    self.scene.add_object(obj, self, register=register, _is_call_from_simulator=True)\n\n    # Lastly, additionally add this object automatically to be initialized as soon as another simulator step occurs\n    # if requested\n    if auto_initialize:\n        self.initialize_object_on_next_sim_step(obj=obj)\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.import_object"},{"title":"<code>import_scene(scene)</code>","text":"<p>Import a scene into the simulator. A scene could be a synthetic one or a realistic Gibson Environment.</p> <p>Parameters:</p>    Name Type Description Default     <code>scene</code>  <code>Scene</code>  <p>a scene object to load</p>  required      Source code in <code>omnigibson/simulator.py</code> <pre><code>def import_scene(self, scene):\n    \"\"\"\n    Import a scene into the simulator. A scene could be a synthetic one or a realistic Gibson Environment.\n\n    Args:\n        scene (Scene): a scene object to load\n    \"\"\"\n    assert self.is_stopped(), \"Simulator must be stopped while importing a scene!\"\n    assert isinstance(scene, Scene), \"import_scene can only be called with Scene\"\n\n    # Clear the existing scene if any\n    self.clear()\n\n    self._scene = scene\n    self._scene.load(self)\n\n    # Make sure simulator is not running, then start it so that we can initialize the scene\n    assert self.is_stopped(), \"Simulator must be stopped after importing a scene!\"\n    self.play()\n\n    # Initialize the scene\n    self._scene.initialize()\n\n    # Need to one more step for particle systems to work\n    self.step()\n    self.stop()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.import_scene"},{"title":"<code>initialize_object_on_next_sim_step(obj)</code>","text":"<p>Initializes the object upon the next simulation step</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BasePrim</code>  <p>Object to initialize as soon as a new sim step is called</p>  required      Source code in <code>omnigibson/simulator.py</code> <pre><code>def initialize_object_on_next_sim_step(self, obj):\n    \"\"\"\n    Initializes the object upon the next simulation step\n\n    Args:\n        obj (BasePrim): Object to initialize as soon as a new sim step is called\n    \"\"\"\n    self._objects_to_initialize.append(obj)\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.initialize_object_on_next_sim_step"},{"title":"<code>is_paused()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if the simulator is paused, otherwise False</p>     Source code in <code>omnigibson/simulator.py</code> <pre><code>def is_paused(self):\n    \"\"\"\n    Returns:\n        bool: True if the simulator is paused, otherwise False\n    \"\"\"\n    return not (self.is_stopped() or self.is_playing())\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.is_paused"},{"title":"<code>load_stage(usd_path)</code>","text":"<p>Open the stage specified by USD file at @usd_path</p> <p>Parameters:</p>    Name Type Description Default     <code>usd_path</code>  <code>str</code>  <p>Absolute filepath to USD stage that should be loaded</p>  required      Source code in <code>omnigibson/simulator.py</code> <pre><code>def load_stage(self, usd_path):\n    \"\"\"\n    Open the stage specified by USD file at @usd_path\n\n    Args:\n        usd_path (str): Absolute filepath to USD stage that should be loaded\n    \"\"\"\n    # Stop the physics if we're playing\n    if not self.is_stopped():\n        logging.warning(\"Stopping simulation in order to load stage.\")\n        self.stop()\n\n    # Store physics dt and rendering dt to reuse later\n    # Note that the stage may have been deleted previously; if so, we use the default values\n    # of 1/60, 1/60\n    try:\n        physics_dt = self.get_physics_dt()\n    except:\n        print(\"WARNING: Invalid or non-existent physics scene found. Setting physics dt to 1/60.\")\n        physics_dt = 1/60.\n    rendering_dt = self.get_rendering_dt()\n\n    # Clear simulation state\n    self._clear_state()\n\n    open_stage(usd_path=usd_path)\n\n    # Re-initialize necessary internal vars\n    self._app = omni.kit.app.get_app_interface()\n    self._framework = carb.get_framework()\n    self._timeline = omni.timeline.get_timeline_interface()\n    self._timeline.set_auto_update(True)\n    self._dynamic_control = _dynamic_control.acquire_dynamic_control_interface()\n    self._cached_rate_limit_enabled = self._settings.get_as_bool(\"/app/runLoops/main/rateLimitEnabled\")\n    self._cached_rate_limit_frequency = self._settings.get_as_int(\"/app/runLoops/main/rateLimitFrequency\")\n    self._cached_min_frame_rate = self._settings.get_as_int(\"persistent/simulation/minFrameRate\")\n    self._loop_runner = omni_loop.acquire_loop_interface()\n\n    self._init_stage(\n        physics_dt=physics_dt,\n        rendering_dt=rendering_dt,\n        stage_units_in_meters=self._initial_stage_units_in_meters,\n    )\n    self._set_physics_engine_settings()\n    self._setup_default_callback_fns()\n    self._stage_open_callback = (\n        omni.usd.get_context().get_stage_event_stream().create_subscription_to_pop(self._stage_open_callback_fn)\n    )\n    self._contact_callback = self._physics_context._physx_sim_interface.subscribe_contact_report_events(self._on_contact)\n\n    # Set the viewer camera, and then set its default pose\n    self._set_viewer_camera()\n    self.viewer_camera.set_position_orientation(\n        position=np.array(m.DEFAULT_VIEWER_CAMERA_POS),\n        orientation=np.array(m.DEFAULT_VIEWER_CAMERA_QUAT),\n    )\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.load_stage"},{"title":"<code>paused()</code>","text":"<p>A context scope for making sure the simulator is paused during execution within this scope. Upon leaving the scope, the prior simulator state is restored.</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef paused(self):\n    \"\"\"\n    A context scope for making sure the simulator is paused during execution within this scope.\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n    # Infer what state we're currently in, then stop, yield, and then restore the original state\n    sim_is_stopped, sim_is_playing = self.is_stopped(), self.is_playing()\n    if sim_is_stopped or sim_is_playing:\n        og.sim.pause()\n    yield\n    if sim_is_stopped: og.sim.stop()\n    elif sim_is_playing: og.sim.play()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.paused"},{"title":"<code>playing()</code>","text":"<p>A context scope for making sure the simulator is playing during execution within this scope. Upon leaving the scope, the prior simulator state is restored.</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef playing(self):\n    \"\"\"\n    A context scope for making sure the simulator is playing during execution within this scope.\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n    # Infer what state we're currently in, then stop, yield, and then restore the original state\n    sim_is_stopped, sim_is_paused = self.is_stopped(), self.is_paused()\n    if sim_is_stopped or sim_is_paused:\n        og.sim.play()\n    yield\n    if sim_is_stopped: og.sim.stop()\n    elif sim_is_paused: og.sim.pause()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.playing"},{"title":"<code>remove_object(obj)</code>","text":"<p>Remove a non-robot object from the simulator.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>a non-robot object to load</p>  required      Source code in <code>omnigibson/simulator.py</code> <pre><code>def remove_object(self, obj):\n    \"\"\"\n    Remove a non-robot object from the simulator.\n\n    Args:\n        obj (BaseObject): a non-robot object to load\n    \"\"\"\n    self._scene.remove_object(obj, simulator=self)\n    self.app.update()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.remove_object"},{"title":"<code>reset_scene()</code>","text":"<p>Resets ths scene (if it exists) and its corresponding objects</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>def reset_scene(self):\n    \"\"\"\n    Resets ths scene (if it exists) and its corresponding objects\n    \"\"\"\n    if self.scene is not None and self.scene.initialized:\n        self.scene.reset()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.reset_scene"},{"title":"<code>restore(json_path)</code>","text":"<p>Restore a simulation environment from @json_path.</p> <p>Parameters:</p>    Name Type Description Default     <code>json_path</code>  <code>str</code>  <p>Full path of JSON file to load, which contains information to recreate a scene.</p>  required      Source code in <code>omnigibson/simulator.py</code> <pre><code>def restore(self, json_path):\n    \"\"\"\n    Restore a simulation environment from @json_path.\n\n    Args:\n        json_path (str): Full path of JSON file to load, which contains information\n            to recreate a scene.\n    \"\"\"\n    if not json_path.endswith(\".json\"):\n        logging.error(f\"You have to define the full json_path to load from. Got: {json_path}\")\n        return\n\n    # Clear the current stage\n    self.clear()\n\n    # Load the info from the json\n    with open(json_path, \"r\") as f:\n        scene_info = json.load(f)\n    init_info = scene_info[\"init_info\"]\n    state = scene_info[\"state\"]\n\n    # Override the init info with our json path\n    init_info[\"args\"][\"scene_file\"] = json_path\n\n    # Also make sure we have any additional modifications necessary from the specific scene\n    og.REGISTERED_SCENES[init_info[\"class_name\"]].modify_init_info_for_restoring(init_info=init_info)\n\n    # Recreate and import the saved scene\n    recreated_scene = create_object_from_init_info(init_info)\n    self.import_scene(scene=recreated_scene)\n\n    # Start the simulation and restore the dynamic state of the scene and then pause again\n    self.play()\n    self.load_state(state, serialized=False)\n\n    logging.info(\"The saved simulation environment loaded.\")\n\n    return\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.restore"},{"title":"<code>save(json_path)</code>","text":"<p>Saves the current simulation environment to @json_path.</p> <p>Parameters:</p>    Name Type Description Default     <code>json_path</code>  <code>str</code>  <p>Full path of JSON file to save (should end with .json), which contains information to recreate the current scene.</p>  required      Source code in <code>omnigibson/simulator.py</code> <pre><code>def save(self, json_path):\n    \"\"\"\n    Saves the current simulation environment to @json_path.\n\n    Args:\n        json_path (str): Full path of JSON file to save (should end with .json), which contains information\n            to recreate the current scene.\n    \"\"\"\n    # Make sure the sim is not stopped, since we need to grab joint states\n    assert not self.is_stopped(), \"Simulator cannot be stopped when saving to USD!\"\n\n    # Make sure there are no objects in the initialization queue, if not, terminate early and notify user\n    # Also run other sanity checks before saving\n    if len(self._objects_to_initialize) &gt; 0:\n        logging.error(\"There are still objects to initialize! Please take one additional sim step and then save.\")\n        return\n    if not self.scene:\n        logging.warning(\"Scene has not been loaded. Nothing to save.\")\n        return\n    if not json_path.endswith(\".json\"):\n        logging.error(f\"You have to define the full json_path to save the scene to. Got: {json_path}\")\n        return\n\n    # Update scene info\n    self.scene.update_objects_info()\n\n    # Dump saved current state and also scene init info\n    scene_info = {\n        \"state\": self.scene.dump_state(serialized=False),\n        \"init_info\": self.scene.get_init_info(),\n        \"objects_info\": self.scene.get_objects_info(),\n    }\n\n    # Write this to the json file\n    Path(os.path.dirname(json_path)).mkdir(parents=True, exist_ok=True)\n    with open(json_path, \"w+\") as f:\n        json.dump(scene_info, f, cls=NumpyEncoder, indent=4)\n\n    logging.info(\"The current simulation environment saved.\")\n\n    return\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.save"},{"title":"<code>slowed(dt)</code>","text":"<p>A context scope for making the simulator simulation dt slowed, e.g.: for taking micro-steps for propagating instantaneous kinematics with minimal impact on physics propagation.</p> <p>NOTE: This will set both the physics dt and rendering dt to the same value during this scope.</p> <p>Upon leaving the scope, the prior simulator state is restored.</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef slowed(self, dt):\n    \"\"\"\n    A context scope for making the simulator simulation dt slowed, e.g.: for taking micro-steps for propagating\n    instantaneous kinematics with minimal impact on physics propagation.\n\n    NOTE: This will set both the physics dt and rendering dt to the same value during this scope.\n\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n    # Set dt, yield, then restore the original dt\n    physics_dt, rendering_dt = self.get_physics_dt(), self.get_rendering_dt()\n    self.set_simulation_dt(physics_dt=dt, rendering_dt=dt)\n    yield\n    self.set_simulation_dt(physics_dt=physics_dt, rendering_dt=rendering_dt)\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.slowed"},{"title":"<code>step(render=True, force_playing=False)</code>","text":"<p>Step the simulation at self.render_timestep</p> <p>Parameters:</p>    Name Type Description Default     <code>render</code>  <code>bool</code>  <p>Whether rendering should occur or not</p>  <code>True</code>    <code>force_playing</code>  <code>bool</code>  <p>If True, will force physics to propagate (i.e.: set simulation, if paused / stopped, to \"play\" mode)</p>  <code>False</code>      Source code in <code>omnigibson/simulator.py</code> <pre><code>def step(self, render=True, force_playing=False):\n    \"\"\"\n    Step the simulation at self.render_timestep\n\n    Args:\n        render (bool): Whether rendering should occur or not\n        force_playing (bool): If True, will force physics to propagate (i.e.: set simulation, if paused / stopped,\n            to \"play\" mode)\n    \"\"\"\n    # Possibly force playing\n    if force_playing and not self.is_playing():\n        self.play()\n\n    if render:\n        super().step(render=True)\n    else:\n        for i in range(self.n_physics_timesteps_per_render):\n            super().step(render=False)\n\n    # Additionally run non physics things if we have a valid scene\n    if self._scene is not None:\n        self._omni_update_step()\n        if self.is_playing():\n            self._non_physics_step()\n            if gm.ENABLE_TRANSITION_RULES:\n                self._transition_rule_step()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.step"},{"title":"<code>step_physics()</code>","text":"<p>Step the physics a single step.</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>def step_physics(self):\n    \"\"\"\n    Step the physics a single step.\n    \"\"\"\n    self._physics_context._step(current_time=self.current_time)\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.step_physics"},{"title":"<code>stopped()</code>","text":"<p>A context scope for making sure the simulator is stopped during execution within this scope. Upon leaving the scope, the prior simulator state is restored.</p>  Source code in <code>omnigibson/simulator.py</code> <pre><code>@contextlib.contextmanager\ndef stopped(self):\n    \"\"\"\n    A context scope for making sure the simulator is stopped during execution within this scope.\n    Upon leaving the scope, the prior simulator state is restored.\n    \"\"\"\n    # Infer what state we're currently in, then stop, yield, and then restore the original state\n    sim_is_playing, sim_is_paused = self.is_playing(), self.is_paused()\n    if sim_is_playing or sim_is_paused:\n        og.sim.stop()\n    yield\n    if sim_is_playing: og.sim.play()\n    elif sim_is_paused: og.sim.pause()\n</code></pre>","location":"reference/simulator.html#simulator.Simulator.stopped"},{"title":"transition_rules","text":"","location":"reference/transition_rules.html"},{"title":"<code>AbilityFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Filter for object abilities.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class AbilityFilter(BaseFilter):\n    \"\"\"Filter for object abilities.\"\"\"\n\n    def __init__(self, ability):\n        self.ability = ability\n\n    def __call__(self, obj):\n        return self.ability in obj._abilities\n</code></pre>","location":"reference/transition_rules.html#transition_rules.AbilityFilter"},{"title":"<code>AndFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Logical-and of a set of filters.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class AndFilter(BaseFilter):\n    \"\"\"Logical-and of a set of filters.\"\"\"\n\n    def __init__(self, filters):\n        self.filters = filters\n\n    def __call__(self, obj):\n        return all(f(obj) for f in self.filters)\n</code></pre>","location":"reference/transition_rules.html#transition_rules.AndFilter"},{"title":"<code>BaseFilter</code>","text":"<p>Defines a filter to apply to objects.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class BaseFilter(metaclass=ABCMeta):\n    \"\"\"Defines a filter to apply to objects.\"\"\"\n    # Class global variable for maintaining cached state\n    # Maps tuple of unique filter inputs to cached output value (T / F)\n    state = None\n\n    @classmethod\n    def __new__(cls, *args, **kwargs):\n        \"\"\"\n        Initializes the cached state for this filter if it doesn't already exist\n        \"\"\"\n        if cls.state is None:\n            cls.state = OrderedDict()\n\n        return super(BaseFilter, cls).__new__(cls)\n\n    @classmethod\n    def update(cls):\n        \"\"\"\n        Updates the internal state by checking the filter status on all filter inputs\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def __call__(self, obj):\n        \"\"\"Returns true if the given object passes the filter.\"\"\"\n        return False\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseFilter"},{"title":"<code>__call__(obj)</code>  <code>abstractmethod</code>","text":"<p>Returns true if the given object passes the filter.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef __call__(self, obj):\n    \"\"\"Returns true if the given object passes the filter.\"\"\"\n    return False\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseFilter.__call__"},{"title":"<code>__new__(*args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Initializes the cached state for this filter if it doesn't already exist</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@classmethod\ndef __new__(cls, *args, **kwargs):\n    \"\"\"\n    Initializes the cached state for this filter if it doesn't already exist\n    \"\"\"\n    if cls.state is None:\n        cls.state = OrderedDict()\n\n    return super(BaseFilter, cls).__new__(cls)\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseFilter.__new__"},{"title":"<code>update()</code>  <code>classmethod</code>","text":"<p>Updates the internal state by checking the filter status on all filter inputs</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@classmethod\ndef update(cls):\n    \"\"\"\n    Updates the internal state by checking the filter status on all filter inputs\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseFilter.update"},{"title":"<code>BaseTransitionRule</code>","text":"<p>Defines a set of categories of objects and how to transition their states.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class BaseTransitionRule(metaclass=ABCMeta):\n    \"\"\"\n    Defines a set of categories of objects and how to transition their states.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, individual_filters=None, group_filters=None):\n        \"\"\"\n        TransitionRule ctor.\n\n        Args:\n            individual_filters (None or dict): Individual object filters that this filter cares about.\n                For each name, filter key-value pair, the global transition rule step will produce tuples of valid\n                filtered objects such that the cross product over all individual filter outputs occur.\n                For example, if the individual filters are:\n\n                    {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n\n                the transition rule step will produce all 2-tuples of valid (apple, knife) combinations:\n\n                    {\"apple\": apple_i, \"knife\": knife_j}\n\n                based on the current instances of each object type in the scene and pass them to @self.condition as the\n                @individual_objects entry.\n                If None is specified, then no filter will be applied\n\n            group_filters (None or dict): Group object filters that this filter cares about. For each name, filter\n                key-value pair, the global transition rule step will produce a single dictionary of valid filtered\n                objects.\n                For example, if the group filters are:\n\n                    {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n\n                the transition rule step will produce the following dictionary:\n\n                    {\"apple\": [apple0, apple1, ...], \"knife\": [knife0, knife1, ...]}\n\n                based on the current instances of each object type in the scene and pass them to @self.condition\n                as the @group_objects entry.\n                If None is specified, then no filter will be applied\n        \"\"\"\n        # Make sure at least one set of filters is specified -- in general, there should never be a rule\n        # where no filter is specified\n        assert not (individual_filters is None and group_filters is None),\\\n            \"At least one of individual_filters or group_filters must be specified!\"\n\n        # Store the filters\n        self.individual_filters = dict() if individual_filters is None else individual_filters\n        self.group_filters = dict() if group_filters is None else group_filters\n\n    def process(self, individual_objects, group_objects):\n        \"\"\"\n        Processes this transition rule at the current simulator step. If @condition evaluates to True, then\n        @transition will be executed.\n\n        Args:\n            individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n                object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n            group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n                object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n\n        Returns:\n            2-tuple:\n                - bool: Whether @self.condition is met\n                - None or TransitionResults: Output from @self.transition (None if it was never executed)\n        \"\"\"\n        should_transition = self.condition(individual_objects=individual_objects, group_objects=group_objects)\n        return should_transition, \\\n            self.transition(individual_objects=individual_objects, group_objects=group_objects) \\\n            if should_transition else None\n\n    @property\n    def requires_individual_filters(self):\n        \"\"\"\n        Returns:\n            bool: Whether this transition rule requires any specific filters\n        \"\"\"\n        return len(self.individual_filters) &gt; 0\n\n    @property\n    def requires_group_filters(self):\n        \"\"\"\n        Returns:\n            bool: Whether this transition rule requires any group filters\n        \"\"\"\n        return len(self.group_filters) &gt; 0\n\n    @abstractmethod\n    def condition(self, individual_objects, group_objects):\n        \"\"\"\n        Returns True if the rule applies to the object tuple.\n\n        Args:\n            individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n                object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n            group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n                object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n\n        Returns:\n            bool: Whether the condition is met or not\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def transition(self, individual_objects, group_objects):\n        \"\"\"\n        Rule to apply for each set of objects satisfying the condition.\n\n        Args:\n            individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n                object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n            group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n                object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n                satisfy the filter, then this will be an empty dictionary\n\n        Returns:\n            TransitionResults: results from the executed transition\n        \"\"\"\n        pass\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseTransitionRule"},{"title":"<code>requires_group_filters</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this transition rule requires any group filters</p>","location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.requires_group_filters"},{"title":"<code>requires_individual_filters</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this transition rule requires any specific filters</p>","location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.requires_individual_filters"},{"title":"<code>__init__(individual_filters=None, group_filters=None)</code>  <code>abstractmethod</code>","text":"<p>TransitionRule ctor.</p> <p>Parameters:</p>    Name Type Description Default     <code>individual_filters</code>  <code>None or dict</code>  <p>Individual object filters that this filter cares about. For each name, filter key-value pair, the global transition rule step will produce tuples of valid filtered objects such that the cross product over all individual filter outputs occur. For example, if the individual filters are:</p> <pre><code>{\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n</code></pre> <p>the transition rule step will produce all 2-tuples of valid (apple, knife) combinations:</p> <pre><code>{\"apple\": apple_i, \"knife\": knife_j}\n</code></pre> <p>based on the current instances of each object type in the scene and pass them to @self.condition as the @individual_objects entry. If None is specified, then no filter will be applied</p>  <code>None</code>    <code>group_filters</code>  <code>None or dict</code>  <p>Group object filters that this filter cares about. For each name, filter key-value pair, the global transition rule step will produce a single dictionary of valid filtered objects. For example, if the group filters are:</p> <pre><code>{\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n</code></pre> <p>the transition rule step will produce the following dictionary:</p> <pre><code>{\"apple\": [apple0, apple1, ...], \"knife\": [knife0, knife1, ...]}\n</code></pre> <p>based on the current instances of each object type in the scene and pass them to @self.condition as the @group_objects entry. If None is specified, then no filter will be applied</p>  <code>None</code>      Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef __init__(self, individual_filters=None, group_filters=None):\n    \"\"\"\n    TransitionRule ctor.\n\n    Args:\n        individual_filters (None or dict): Individual object filters that this filter cares about.\n            For each name, filter key-value pair, the global transition rule step will produce tuples of valid\n            filtered objects such that the cross product over all individual filter outputs occur.\n            For example, if the individual filters are:\n\n                {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n\n            the transition rule step will produce all 2-tuples of valid (apple, knife) combinations:\n\n                {\"apple\": apple_i, \"knife\": knife_j}\n\n            based on the current instances of each object type in the scene and pass them to @self.condition as the\n            @individual_objects entry.\n            If None is specified, then no filter will be applied\n\n        group_filters (None or dict): Group object filters that this filter cares about. For each name, filter\n            key-value pair, the global transition rule step will produce a single dictionary of valid filtered\n            objects.\n            For example, if the group filters are:\n\n                {\"apple\": CategoryFilter(\"apple\"), \"knife\": CategoryFilter(\"knife\")},\n\n            the transition rule step will produce the following dictionary:\n\n                {\"apple\": [apple0, apple1, ...], \"knife\": [knife0, knife1, ...]}\n\n            based on the current instances of each object type in the scene and pass them to @self.condition\n            as the @group_objects entry.\n            If None is specified, then no filter will be applied\n    \"\"\"\n    # Make sure at least one set of filters is specified -- in general, there should never be a rule\n    # where no filter is specified\n    assert not (individual_filters is None and group_filters is None),\\\n        \"At least one of individual_filters or group_filters must be specified!\"\n\n    # Store the filters\n    self.individual_filters = dict() if individual_filters is None else individual_filters\n    self.group_filters = dict() if group_filters is None else group_filters\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.__init__"},{"title":"<code>condition(individual_objects, group_objects)</code>  <code>abstractmethod</code>","text":"<p>Returns True if the rule applies to the object tuple.</p> <p>Parameters:</p>    Name Type Description Default     <code>individual_objects</code>  <code>dict</code>  <p>Dictionary mapping corresponding keys from @individual_filters to individual object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values satisfy the filter, then this will be an empty dictionary</p>  required    <code>group_objects</code>  <code>dict</code>  <p>Dictionary mapping corresponding keys from @group_filters to a list of individual object instances where the filter is satisfied. Note: if @self.group_filters is None or no values satisfy the filter, then this will be an empty dictionary</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether the condition is met or not</p>     Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef condition(self, individual_objects, group_objects):\n    \"\"\"\n    Returns True if the rule applies to the object tuple.\n\n    Args:\n        individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n            object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n        group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n            object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n\n    Returns:\n        bool: Whether the condition is met or not\n    \"\"\"\n    pass\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.condition"},{"title":"<code>process(individual_objects, group_objects)</code>","text":"<p>Processes this transition rule at the current simulator step. If @condition evaluates to True, then @transition will be executed.</p> <p>Parameters:</p>    Name Type Description Default     <code>individual_objects</code>  <code>dict</code>  <p>Dictionary mapping corresponding keys from @individual_filters to individual object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values satisfy the filter, then this will be an empty dictionary</p>  required    <code>group_objects</code>  <code>dict</code>  <p>Dictionary mapping corresponding keys from @group_filters to a list of individual object instances where the filter is satisfied. Note: if @self.group_filters is None or no values satisfy the filter, then this will be an empty dictionary</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - bool: Whether @self.condition is met - None or TransitionResults: Output from @self.transition (None if it was never executed)</p>     Source code in <code>omnigibson/transition_rules.py</code> <pre><code>def process(self, individual_objects, group_objects):\n    \"\"\"\n    Processes this transition rule at the current simulator step. If @condition evaluates to True, then\n    @transition will be executed.\n\n    Args:\n        individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n            object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n        group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n            object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n\n    Returns:\n        2-tuple:\n            - bool: Whether @self.condition is met\n            - None or TransitionResults: Output from @self.transition (None if it was never executed)\n    \"\"\"\n    should_transition = self.condition(individual_objects=individual_objects, group_objects=group_objects)\n    return should_transition, \\\n        self.transition(individual_objects=individual_objects, group_objects=group_objects) \\\n        if should_transition else None\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.process"},{"title":"<code>transition(individual_objects, group_objects)</code>  <code>abstractmethod</code>","text":"<p>Rule to apply for each set of objects satisfying the condition.</p> <p>Parameters:</p>    Name Type Description Default     <code>individual_objects</code>  <code>dict</code>  <p>Dictionary mapping corresponding keys from @individual_filters to individual object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values satisfy the filter, then this will be an empty dictionary</p>  required    <code>group_objects</code>  <code>dict</code>  <p>Dictionary mapping corresponding keys from @group_filters to a list of individual object instances where the filter is satisfied. Note: if @self.group_filters is None or no values satisfy the filter, then this will be an empty dictionary</p>  required     <p>Returns:</p>    Name Type Description     <code>TransitionResults</code>   <p>results from the executed transition</p>     Source code in <code>omnigibson/transition_rules.py</code> <pre><code>@abstractmethod\ndef transition(self, individual_objects, group_objects):\n    \"\"\"\n    Rule to apply for each set of objects satisfying the condition.\n\n    Args:\n        individual_objects (dict): Dictionary mapping corresponding keys from @individual_filters to individual\n            object instances where the filter is satisfied. Note: if @self.individual_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n        group_objects (dict): Dictionary mapping corresponding keys from @group_filters to a list of individual\n            object instances where the filter is satisfied. Note: if @self.group_filters is None or no values\n            satisfy the filter, then this will be an empty dictionary\n\n    Returns:\n        TransitionResults: results from the executed transition\n    \"\"\"\n    pass\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BaseTransitionRule.transition"},{"title":"<code>BlenderRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class BlenderRule(BaseTransitionRule):\n    def __init__(self, output_fluid, fluid_requirements=None, obj_requirements=None):\n        \"\"\"\n        Transition rule to apply when objects are blended together\n\n        Args:\n            output_fluid (FluidSystem): Fluid to generate once all the input ingredients are blended\n            fluid_requirements (None or dict): If specified, should map fluid system to the minimum number of fluid\n                particles required in order to successfully blend\n            obj_requirements (None or dict): If specified, should map object category names to minimum number of that\n                type of object rqeuired in order to successfully blend\n        \"\"\"\n        # We want to filter for any object that is included in @obj_requirements and also separately for blender\n        individual_filters = {\"blender\": CategoryFilter(\"blender\")}\n        group_filters = {category: CategoryFilter(category) for category in obj_requirements.keys()}\n\n        # Store internal variables\n        self.output_fluid = output_fluid\n        self.fluid_requirements = fluid_requirements\n        self.obj_requirements = obj_requirements\n\n        # Store a cached dictionary to check blender volumes so we don't have to do this later\n        self._check_in_volume = OrderedDict()\n\n        # Call super method\n        super().__init__(individual_filters=individual_filters, group_filters=group_filters)\n\n    def condition(self, individual_objects, group_objects):\n        # TODO: Check blender if both toggled on and lid is closed!\n\n        blender = individual_objects[\"blender\"]\n        # If this blender doesn't exist in our volume checker, we add it\n        if blender.name not in self._check_in_volume:\n            self._check_in_volume[blender.name] = lambda pos: blender.states[Filled].check_in_volume(pos.reshape(-1, 3))\n\n        # Check to see which objects are inside the blender container\n        for obj_category, objs in group_objects.items():\n            inside_objs = []\n            for obj in objs:\n                if obj.states[Inside].get_value(blender):\n                    inside_objs.append(obj)\n            # Make sure the number of objects inside meets the required threshold, else we trigger a failure\n            if len(inside_objs) &lt; self.obj_requirements[obj_category]:\n                return False\n            # We mutate the group_objects in place so that we only keep the ones inside the blender\n            group_objects[obj_category] = inside_objs\n\n        # Check whether we have sufficient fluids as well\n        for system, n_min_particles in self.fluid_requirements.items():\n            if len(system.particle_instancers) &gt; 0:\n                particle_positions = np.concatenate([inst.particle_positions for inst in system.particle_instancers.values()], axis=0)\n                n_particles_in_volume = np.sum(self._check_in_volume[blender.name](particle_positions))\n                if n_particles_in_volume &lt; n_min_particles:\n                    return False\n            else:\n                # Fluid doesn't even exist yet, so we know the condition is not met\n                return False\n\n        # Our condition is whether we have sufficient ingredients or not\n        return True\n\n    def transition(self, individual_objects, group_objects):\n        t_results = TransitionResults()\n        blender = individual_objects[\"blender\"]\n        # For every object in group_objects, we remove them from the simulator\n        for i, (obj_category, objs) in enumerate(group_objects.items()):\n            for j, obj in enumerate(objs):\n                t_results.remove.append(obj)\n\n        # Hide all fluid particles that are inside the blender\n        for system in self.fluid_requirements.keys():\n            # No need to check for whether particle instancers exist because they must due to @self.condition passing!\n            for inst in system.particle_instancers.values():\n                indices = self._check_in_volume[blender.name](inst.particle_positions).nonzero()[0]\n                current_visibilities = inst.particle_visibilities\n                current_visibilities[indices] = 0\n                inst.particle_visibilities = current_visibilities\n\n        # Spawn in blended fluid!\n        blender.states[Filled].set_value(self.output_fluid, True)\n\n        return t_results\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BlenderRule"},{"title":"<code>__init__(output_fluid, fluid_requirements=None, obj_requirements=None)</code>","text":"<p>Transition rule to apply when objects are blended together</p> <p>Parameters:</p>    Name Type Description Default     <code>output_fluid</code>  <code>FluidSystem</code>  <p>Fluid to generate once all the input ingredients are blended</p>  required    <code>fluid_requirements</code>  <code>None or dict</code>  <p>If specified, should map fluid system to the minimum number of fluid particles required in order to successfully blend</p>  <code>None</code>    <code>obj_requirements</code>  <code>None or dict</code>  <p>If specified, should map object category names to minimum number of that type of object rqeuired in order to successfully blend</p>  <code>None</code>      Source code in <code>omnigibson/transition_rules.py</code> <pre><code>def __init__(self, output_fluid, fluid_requirements=None, obj_requirements=None):\n    \"\"\"\n    Transition rule to apply when objects are blended together\n\n    Args:\n        output_fluid (FluidSystem): Fluid to generate once all the input ingredients are blended\n        fluid_requirements (None or dict): If specified, should map fluid system to the minimum number of fluid\n            particles required in order to successfully blend\n        obj_requirements (None or dict): If specified, should map object category names to minimum number of that\n            type of object rqeuired in order to successfully blend\n    \"\"\"\n    # We want to filter for any object that is included in @obj_requirements and also separately for blender\n    individual_filters = {\"blender\": CategoryFilter(\"blender\")}\n    group_filters = {category: CategoryFilter(category) for category in obj_requirements.keys()}\n\n    # Store internal variables\n    self.output_fluid = output_fluid\n    self.fluid_requirements = fluid_requirements\n    self.obj_requirements = obj_requirements\n\n    # Store a cached dictionary to check blender volumes so we don't have to do this later\n    self._check_in_volume = OrderedDict()\n\n    # Call super method\n    super().__init__(individual_filters=individual_filters, group_filters=group_filters)\n</code></pre>","location":"reference/transition_rules.html#transition_rules.BlenderRule.__init__"},{"title":"<code>CategoryFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Filter for object categories.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class CategoryFilter(BaseFilter):\n    \"\"\"Filter for object categories.\"\"\"\n\n    def __init__(self, category):\n        self.category = category\n\n    def __call__(self, obj):\n        return obj.category == self.category\n</code></pre>","location":"reference/transition_rules.html#transition_rules.CategoryFilter"},{"title":"<code>ContainerGarbageRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>Rule to apply to a container to turn what remain inside into garbage.</p> <p>This rule is used as a catch-all rule for containers to turn objects inside the container that did not match any other legitimate rules all into a single garbage object.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class ContainerGarbageRule(BaseTransitionRule):\n    \"\"\"\n    Rule to apply to a container to turn what remain inside into garbage.\n\n    This rule is used as a catch-all rule for containers to turn objects inside\n    the container that did not match any other legitimate rules all into a\n    single garbage object.\n    \"\"\"\n\n    def __init__(self, garbage_obj_attrs, container_filter):\n        \"\"\"Ctor for ContainerGarbageRule.\n\n        Args:\n            garbage_obj_attrs: (ObjectAttrs) a namedtuple containing the\n                attributes of garbage objects to be created.\n            container_filter: (BaseFilter) a filter for the container.\n        \"\"\"\n        super(ContainerGarbageRule, self).__init__((container_filter,))\n        self.obj_attrs = garbage_obj_attrs\n        self._cached_contained_objs = None\n        self._counter = 0\n\n    def condition(self, container_obj):\n        if (\n            ToggledOn in container_obj.states and\n            not container_obj.states[ToggledOn].get_value()\n        ):\n            return False\n        self._cached_contained_objs = _contained_objects(og.sim.scene, container_obj)\n        # Skip in case only a garbage object is inside the container.\n        if len(self._cached_contained_objs) == 1:\n            contained_obj = self._cached_contained_objs[0]\n            if (contained_obj.category == self.obj_attrs.category\n                    and contained_obj.name.startswith(self.obj_attrs.name)):\n                return False\n        return bool(self._cached_contained_objs)\n\n    def transition(self, container_obj):\n        t_results = TransitionResults()\n\n        # Create a single garbage object to be added.\n        all_pos, all_orn = [], []\n        for contained_obj in self._cached_contained_objs:\n            pos, orn = contained_obj.get_position_orientation()\n            all_pos.append(pos)\n            all_orn.append(orn)\n\n        category = self.obj_attrs.category\n        model = self.obj_attrs.model\n        name = f\"{self.obj_attrs.name}_{self._counter}\"\n        self._counter += 1\n        scale = self.obj_attrs.scale\n\n        model_root_path = f\"{og_dataset_path}/objects/{category}/{model}\"\n        usd_path = f\"{model_root_path}/usd/{model}.usd\"\n\n        garbage_obj = DatasetObject(\n            prim_path=f\"/World/{name}\",\n            usd_path=usd_path,\n            category=category,\n            name=f\"{name}\",\n            scale=scale)\n\n        garbage_obj_attrs = ObjectAttrs(\n            obj=garbage_obj, pos=np.mean(all_pos, axis=0), orn=np.mean(all_orn, axis=0))\n        t_results.add.append(garbage_obj_attrs)\n\n        # Remove all contained objects.\n        for contained_obj in self._cached_contained_objs:\n            t_results.remove.append(contained_obj)\n\n        # Turn off the container after the transition and reset things.\n        if ToggledOn in container_obj.states:\n            container_obj.states[ToggledOn].set_value(False)\n        self._cached_contained_objs = None\n        return t_results\n</code></pre>","location":"reference/transition_rules.html#transition_rules.ContainerGarbageRule"},{"title":"<code>__init__(garbage_obj_attrs, container_filter)</code>","text":"<p>Ctor for ContainerGarbageRule.</p> <p>Parameters:</p>    Name Type Description Default     <code>garbage_obj_attrs</code>   <p>(ObjectAttrs) a namedtuple containing the attributes of garbage objects to be created.</p>  required    <code>container_filter</code>   <p>(BaseFilter) a filter for the container.</p>  required      Source code in <code>omnigibson/transition_rules.py</code> <pre><code>def __init__(self, garbage_obj_attrs, container_filter):\n    \"\"\"Ctor for ContainerGarbageRule.\n\n    Args:\n        garbage_obj_attrs: (ObjectAttrs) a namedtuple containing the\n            attributes of garbage objects to be created.\n        container_filter: (BaseFilter) a filter for the container.\n    \"\"\"\n    super(ContainerGarbageRule, self).__init__((container_filter,))\n    self.obj_attrs = garbage_obj_attrs\n    self._cached_contained_objs = None\n    self._counter = 0\n</code></pre>","location":"reference/transition_rules.html#transition_rules.ContainerGarbageRule.__init__"},{"title":"<code>ContainerRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>Rule to apply to a container and a set of objects that may be inside.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class ContainerRule(BaseTransitionRule):\n    \"\"\"\n    Rule to apply to a container and a set of objects that may be inside.\n    \"\"\"\n\n    def __init__(self, trigger_steps, final_obj_attrs, container_filter, *contained_filters):\n        # Should be in this order to have the container object come first.\n        super(ContainerRule, self).__init__((container_filter, *contained_filters))\n        self.obj_attrs = final_obj_attrs\n        self.trigger_steps = trigger_steps\n        self._current_steps = 1\n        self._counter = 0\n\n    def condition(self, container_obj, *contained_objs):\n        if (\n            ToggledOn in container_obj.states and\n            not container_obj.states[ToggledOn].get_value()\n        ):\n            return False\n        # Check all objects inside the container against the expected objects.\n        all_contained_objs = _contained_objects(og.sim.scene, container_obj)\n        contained_prim_paths = set(obj.prim_path for obj in contained_objs)\n        all_contained_prim_paths = set(obj.prim_path for obj in all_contained_objs)\n        if contained_prim_paths != all_contained_prim_paths:\n            return False\n        # Check if the trigger step has been reached.\n        if self._current_steps &lt; self.trigger_steps:\n            self._current_steps += 1\n            return False\n        self._current_steps = 1\n        return True\n\n    def transition(self, container_obj, *contained_objs):\n        t_results = TransitionResults()\n\n        # Create a new object to be added.\n        all_pos, all_orn = [], []\n        for contained_obj in contained_objs:\n            pos, orn = contained_obj.get_position_orientation()\n            all_pos.append(pos)\n            all_orn.append(orn)\n\n        category = self.obj_attrs.category\n        model = self.obj_attrs.model\n        name = f\"{self.obj_attrs.name}_{self._counter}\"\n        self._counter += 1\n        scale = self.obj_attrs.scale\n\n        model_root_path = f\"{og_dataset_path}/objects/{category}/{model}\"\n        usd_path = f\"{model_root_path}/usd/{model}.usd\"\n\n        final_obj = DatasetObject(\n            prim_path=f\"/World/{name}\",\n            usd_path=usd_path,\n            category=category,\n            name=f\"{name}\",\n            scale=scale)\n\n        final_obj_attrs = ObjectAttrs(\n            obj=final_obj, pos=np.mean(all_pos, axis=0), orn=np.mean(all_orn, axis=0))\n        t_results.add.append(final_obj_attrs)\n\n        # Delete all objects inside the container.\n        for contained_obj in contained_objs:\n            t_results.remove.append(contained_obj)\n\n        # Turn off the container, otherwise things would turn into garbage.\n        if ToggledOn in container_obj.states:\n            container_obj.states[ToggledOn].set_value(False)\n        print(f\"Applied {ContainerRule.__name__} to {container_obj}\")\n        return t_results\n</code></pre>","location":"reference/transition_rules.html#transition_rules.ContainerRule"},{"title":"<code>GenericTransitionRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>A generic transition rule template used typically for simple rules.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class GenericTransitionRule(BaseTransitionRule):\n    \"\"\"\n    A generic transition rule template used typically for simple rules.\n    \"\"\"\n\n    def __init__(self, individual_filters, group_filters, condition_fn, transition_fn):\n        super(GenericTransitionRule, self).__init__(individual_filters, group_filters)\n        self.condition_fn = condition_fn\n        self.transition_fn = transition_fn\n\n    def condition(self, individual_objects, group_objects):\n        return self.condition_fn(individual_objects, group_objects)\n\n    def transition(self, individual_objects, group_objects):\n        return self.transition_fn(individual_objects, group_objects)\n</code></pre>","location":"reference/transition_rules.html#transition_rules.GenericTransitionRule"},{"title":"<code>OrFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Logical-or of a set of filters.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class OrFilter(BaseFilter):\n    \"\"\"Logical-or of a set of filters.\"\"\"\n\n    def __init__(self, filters):\n        self.filters = filters\n\n    def __call__(self, obj):\n        return any(f(obj) for f in self.filters)\n</code></pre>","location":"reference/transition_rules.html#transition_rules.OrFilter"},{"title":"<code>SlicingRule</code>","text":"<p>         Bases: <code>BaseTransitionRule</code></p> <p>Transition rule to apply to sliced / slicer object pairs.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class SlicingRule(BaseTransitionRule):\n    \"\"\"\n    Transition rule to apply to sliced / slicer object pairs.\n    \"\"\"\n\n    def __init__(self):\n        # Define an individual filter dictionary so we can track all valid combos of slicer - sliceable\n        individual_filters = {ability: AbilityFilter(ability) for ability in (\"sliceable\", \"slicer\")}\n\n        # Run super\n        super().__init__(individual_filters=individual_filters)\n\n    def condition(self, individual_objects, group_objects):\n        slicer_obj, sliced_obj = individual_objects[\"slicer\"], individual_objects[\"sliceable\"]\n        slicer_position = slicer_obj.states[Slicer].get_link_position()\n        if slicer_position is None:\n            return False\n\n        contact_list = slicer_obj.states[ContactBodies].get_value()\n        sliced_link_paths = {link.prim_path for link in sliced_obj.links.values()}\n        hit_obj = False\n        for c in contact_list:\n            if not set(c).isdisjoint(sliced_link_paths):\n                hit_obj = True\n                break\n        if not hit_obj:\n            return False\n\n        # Slicer may contact the same body in multiple points, so cut once since removing the object from the simulator\n        return Sliced in sliced_obj.states and not sliced_obj.states[Sliced].get_value()\n\n    def transition(self, individual_objects, group_objects):\n        slicer_obj, sliced_obj = individual_objects[\"slicer\"], individual_objects[\"sliceable\"]\n        # Object parts offset annotation are w.r.t the base link of the whole object.\n        sliced_obj.states[Sliced].set_value(True)\n        pos, orn = sliced_obj.get_position_orientation()\n\n        t_results = TransitionResults()\n\n        # Load object parts.\n        for _, part_idx in enumerate(sliced_obj.metadata[\"object_parts\"]):\n            # List of dicts gets replaced by {'0':dict, '1':dict, ...}.\n            part = sliced_obj.metadata[\"object_parts\"][part_idx]\n            part_category = part[\"category\"]\n            part_model = part[\"model\"]\n            # Scale the offset accordingly.\n            part_pos = part[\"pos\"] * sliced_obj.scale\n            part_orn = part[\"orn\"]\n            part_obj_name = f\"{sliced_obj.name}_part_{part_idx}\"\n            model_root_path = f\"{og_dataset_path}/objects/{part_category}/{part_model}\"\n            usd_path = f\"{model_root_path}/usd/{part_model}.usd\"\n\n            # Calculate global part pose.\n            part_pos = np.array(part_pos) + pos\n            part_orn = T.quat_multiply(np.array(part_orn), orn)\n\n            # Circular import.\n            from omnigibson.objects.dataset_object import DatasetObject\n\n            part_obj = DatasetObject(\n                prim_path=f\"/World/{part_obj_name}\",\n                usd_path=usd_path,\n                category=part_category,\n                name=part_obj_name,\n                scale=sliced_obj.scale,\n                abilities={}\n            )\n\n            # Add the new object to the results.\n            new_obj_attrs = ObjectAttrs(\n                obj=part_obj, pos=np.array(part_pos), orn=np.array(part_orn))\n            t_results.add.append(new_obj_attrs)\n\n        # Delete original object from stage.\n        t_results.remove.append(sliced_obj)\n\n        return t_results\n</code></pre>","location":"reference/transition_rules.html#transition_rules.SlicingRule"},{"title":"<code>StateFilter</code>","text":"<p>         Bases: <code>BaseFilter</code></p> <p>Filter for object states.</p>  Source code in <code>omnigibson/transition_rules.py</code> <pre><code>class StateFilter(BaseFilter):\n    \"\"\"Filter for object states.\"\"\"\n\n    def __init__(self, state_type, state_value):\n        self.state_type = state_type\n        self.state_value = state_value\n\n    def __call__(self, obj):\n        if self.state_type not in obj.states:\n            return False\n        return obj.states[self.state_type].get_value() == self.state_value\n</code></pre>","location":"reference/transition_rules.html#transition_rules.StateFilter"},{"title":"controllers","text":"","location":"reference/controllers/index.html"},{"title":"<code>create_controller(name, **kwargs)</code>","text":"<p>Creates a controller of type @name with corresponding necessary keyword arguments @kwargs</p> <p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>type of controller to use (e.g. JointController, InverseKinematicsController, etc.)</p>  required    <code>**kwargs</code>   <p>Any relevant keyword arguments to pass to the controller</p>  <code>{}</code>     <p>Returns:</p>    Name Type Description     <code>Controller</code>   <p>created controller</p>     Source code in <code>controllers/__init__.py</code> <pre><code>def create_controller(name, **kwargs):\n    \"\"\"\n    Creates a controller of type @name with corresponding necessary keyword arguments @kwargs\n\n    Args:\n        name (str): type of controller to use (e.g. JointController, InverseKinematicsController, etc.)\n        **kwargs: Any relevant keyword arguments to pass to the controller\n\n    Returns:\n        Controller: created controller\n    \"\"\"\n    assert_valid_key(key=name, valid_keys=REGISTERED_CONTROLLERS, name=\"controller\")\n    controller_cls = REGISTERED_CONTROLLERS[name]\n\n    return controller_cls(**kwargs)\n</code></pre>","location":"reference/controllers/index.html#controllers.create_controller"},{"title":"controller_base","text":"","location":"reference/controllers/controller_base.html"},{"title":"<code>BaseController</code>","text":"<p>         Bases: <code>Serializable</code>, <code>Registerable</code>, <code>Recreatable</code></p> <p>An abstract class with interface for mapping specific types of commands to deployable control signals.</p>  Source code in <code>controllers/controller_base.py</code> <pre><code>class BaseController(Serializable, Registerable, Recreatable):\n    \"\"\"\n    An abstract class with interface for mapping specific types of commands to deployable control signals.\n    \"\"\"\n\n    def __init__(\n        self,\n        control_freq,\n        control_limits,\n        dof_idx,\n        command_input_limits=\"default\",\n        command_output_limits=\"default\",\n    ):\n        \"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n        \"\"\"\n        # Store arguments\n        self._control_freq = control_freq\n        self._control_limits = {}\n        for motor_type in {\"position\", \"velocity\", \"effort\"}:\n            if motor_type not in control_limits:\n                continue\n\n            self._control_limits[ControlType.get_type(motor_type)] = [\n                np.array(control_limits[motor_type][0]),\n                np.array(control_limits[motor_type][1]),\n            ]\n        assert \"has_limit\" in control_limits, \"Expected has_limit specified in control_limits, but does not exist.\"\n        self._dof_has_limits = control_limits[\"has_limit\"]\n        self._dof_idx = np.array(dof_idx, dtype=int)\n\n        # Initialize some other variables that will be filled in during runtime\n        self._control = None\n        self._command = None\n        self._command_scale_factor = None\n        self._command_output_transform = None\n        self._command_input_transform = None\n\n        # Standardize command input / output limits to be (min_array, max_array)\n        command_input_limits = (-1.0, 1.0) if command_input_limits == \"default\" else command_input_limits\n        command_output_limits = (\n            (\n                np.array(self._control_limits[self.control_type][0])[self.dof_idx],\n                np.array(self._control_limits[self.control_type][1])[self.dof_idx],\n            )\n            if command_output_limits == \"default\"\n            else command_output_limits\n        )\n        self._command_input_limits = (\n            None\n            if command_input_limits is None\n            else (\n                self.nums2array(command_input_limits[0], self.command_dim),\n                self.nums2array(command_input_limits[1], self.command_dim),\n            )\n        )\n        self._command_output_limits = (\n            None\n            if command_output_limits is None\n            else (\n                self.nums2array(command_output_limits[0], self.command_dim),\n                self.nums2array(command_output_limits[1], self.command_dim),\n            )\n        )\n\n    def _preprocess_command(self, command):\n        \"\"\"\n        Clips + scales inputted @command according to self.command_input_limits and self.command_output_limits.\n        If self.command_input_limits is None, then no clipping will occur. If either self.command_input_limits\n        or self.command_output_limits is None, then no scaling will occur.\n\n        Args:\n            command (Array[float] or float): Inputted command vector\n\n        Returns:\n            Array[float]: Processed command vector\n        \"\"\"\n        # Make sure command is a np.array\n        command = np.array([command]) if type(command) in {int, float} else np.array(command)\n        # We only clip and / or scale if self.command_input_limits exists\n        if self._command_input_limits is not None:\n            # Clip\n            command = command.clip(*self._command_input_limits)\n            if self._command_output_limits is not None:\n                # If we haven't calculated how to scale the command, do that now (once)\n                if self._command_scale_factor is None:\n                    self._command_scale_factor = abs(\n                        self._command_output_limits[1] - self._command_output_limits[0]\n                    ) / abs(self._command_input_limits[1] - self._command_input_limits[0])\n                    self._command_output_transform = (\n                        self._command_output_limits[1] + self._command_output_limits[0]\n                    ) / 2.0\n                    self._command_input_transform = (self._command_input_limits[1] + self._command_input_limits[0]) / 2.0\n                # Scale command\n                command = (\n                    command - self._command_input_transform\n                ) * self._command_scale_factor + self._command_output_transform\n\n        # Return processed command\n        return command\n\n    def update_command(self, command):\n        \"\"\"\n        Updates inputted @command internally.\n\n        Args:\n            command (Array[float]): inputted command to store internally in this controller\n        \"\"\"\n        # Sanity check the command\n        assert len(command) == self.command_dim, \"Commands must be dimension {}, got dim {} instead.\".format(\n            self.command_dim, len(command)\n        )\n        # Preprocess and store inputted command\n        self._command = self._preprocess_command(np.array(command))\n\n    def clip_control(self, control):\n        \"\"\"\n        Clips the inputted @control signal based on @control_limits.\n\n        Args:\n            control (Array[float]): control signal to clip\n\n        Returns:\n            Array[float]: Clipped control signal\n        \"\"\"\n        clipped_control = control.clip(\n            self._control_limits[self.control_type][0][self.dof_idx],\n            self._control_limits[self.control_type][1][self.dof_idx],\n        )\n        idx = (\n            self._dof_has_limits[self.dof_idx]\n            if self.control_type == ControlType.POSITION\n            else [True] * self.control_dim\n        )\n        control[idx] = clipped_control[idx]\n        return control\n\n    def step(self, control_dict):\n        \"\"\"\n        Take a controller step.\n\n        Args:\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation\n\n        Returns:\n            Array[float]: numpy array of outputted control signals\n        \"\"\"\n        control = self._command_to_control(command=self._command, control_dict=control_dict)\n        self._control = self.clip_control(control=control)\n        return self._control\n\n    def reset(self):\n        \"\"\"\n        Resets this controller. Should be implemented by subclass.\n        \"\"\"\n        raise NotImplementedError\n\n    def _dump_state(self):\n        # Default is no state (empty dict)\n        return OrderedDict()\n\n    def _load_state(self, state):\n        # Default is no state (empty dict), so this is a no-op\n        pass\n\n    def _serialize(self, state):\n        # Default is no state, so do nothing\n        return np.array([])\n\n    def _deserialize(self, state):\n        # Default is no state, so do nothing\n        return OrderedDict(), 0\n\n    def _command_to_control(self, command, control_dict):\n        \"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) control signal.\n        Should be implemented by subclass.\n\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation\n\n        Returns:\n            Array[float]: outputted (non-clipped!) control signal to deploy\n        \"\"\"\n        raise NotImplementedError\n\n    @staticmethod\n    def nums2array(nums, dim):\n        \"\"\"\n        Convert input @nums into numpy array of length @dim. If @nums is a single number, broadcasts it to the\n        corresponding dimension size @dim before converting into a numpy array\n\n        Args:\n            nums (numeric or Iterable): Either single value or array of numbers\n            dim (int): Size of array to broadcast input to\n\n        Returns:\n            np.array: Array filled with values specified in @nums\n        \"\"\"\n        # First run sanity check to make sure no strings are being inputted\n        if isinstance(nums, str):\n            raise TypeError(\"Error: Only numeric inputs are supported for this function, nums2array!\")\n\n        # Check if input is an Iterable, if so, we simply convert the input to np.array and return\n        # Else, input is a single value, so we map to a numpy array of correct size and return\n        return np.array(nums) if isinstance(nums, Iterable) else np.ones(dim) * nums\n\n    @property\n    def state_size(self):\n        # Default is no state, so return 0\n        return 0\n\n    @property\n    def control(self):\n        \"\"\"\n        Returns:\n            n-array: Array of most recent controls deployed by this controller\n        \"\"\"\n        return self._control\n\n    @property\n    def control_freq(self):\n        \"\"\"\n        Returns:\n            float: Control frequency (Hz) of this controller\n        \"\"\"\n        return self._control_freq\n\n    @property\n    def control_dim(self):\n        \"\"\"\n        Returns:\n            int: Expected size of outputted controls\n        \"\"\"\n        return len(self.dof_idx)\n\n    @property\n    def control_type(self):\n        \"\"\"\n        Returns:\n            ControlType: Type of control returned by this controller\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def command_input_limits(self):\n        \"\"\"\n        Returns:\n            None or 2-tuple: If specified, returns (min, max) command input limits for this controller, where\n                @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None\n        \"\"\"\n        return self._command_input_limits\n\n    @property\n    def command_output_limits(self):\n        \"\"\"\n        Returns:\n            None or 2-tuple: If specified, returns (min, max) command output limits for this controller, where\n                @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None\n        \"\"\"\n        return self._command_output_limits\n\n    @property\n    def command_dim(self):\n        \"\"\"\n        Returns:\n            int: Expected size of inputted commands\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def dof_idx(self):\n        \"\"\"\n        Returns:\n            Array[int]: DOF indices corresponding to the specific DOFs being controlled by this robot\n        \"\"\"\n        return np.array(self._dof_idx)\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseController\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_CONTROLLERS\n        return REGISTERED_CONTROLLERS\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController"},{"title":"<code>command_dim</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Expected size of inputted commands</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.command_dim"},{"title":"<code>command_input_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or 2-tuple: If specified, returns (min, max) command input limits for this controller, where @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.command_input_limits"},{"title":"<code>command_output_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or 2-tuple: If specified, returns (min, max) command output limits for this controller, where @min and @max are numpy float arrays of length self.command_dim. Otherwise, returns None</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.command_output_limits"},{"title":"<code>control</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Array of most recent controls deployed by this controller</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control"},{"title":"<code>control_dim</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Expected size of outputted controls</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control_dim"},{"title":"<code>control_freq</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Control frequency (Hz) of this controller</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control_freq"},{"title":"<code>control_type</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>ControlType</code>   <p>Type of control returned by this controller</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.control_type"},{"title":"<code>dof_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>Array[int]: DOF indices corresponding to the specific DOFs being controlled by this robot</p>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.dof_idx"},{"title":"<code>__init__(control_freq, control_limits, dof_idx, command_input_limits='default', command_output_limits='default')</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>control_freq</code>  <code>int</code>  <p>controller loop frequency</p>  required    <code>control_limits</code>  <code>Dict[str, Tuple[Array[float], Array[float]]]</code>  <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p>  required    <code>dof_idx</code>  <code>Array[int]</code>  <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p>  required    <code>command_input_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p>  <code>'default'</code>    <code>command_output_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p>  <code>'default'</code>      Source code in <code>controllers/controller_base.py</code> <pre><code>def __init__(\n    self,\n    control_freq,\n    control_limits,\n    dof_idx,\n    command_input_limits=\"default\",\n    command_output_limits=\"default\",\n):\n    \"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n    \"\"\"\n    # Store arguments\n    self._control_freq = control_freq\n    self._control_limits = {}\n    for motor_type in {\"position\", \"velocity\", \"effort\"}:\n        if motor_type not in control_limits:\n            continue\n\n        self._control_limits[ControlType.get_type(motor_type)] = [\n            np.array(control_limits[motor_type][0]),\n            np.array(control_limits[motor_type][1]),\n        ]\n    assert \"has_limit\" in control_limits, \"Expected has_limit specified in control_limits, but does not exist.\"\n    self._dof_has_limits = control_limits[\"has_limit\"]\n    self._dof_idx = np.array(dof_idx, dtype=int)\n\n    # Initialize some other variables that will be filled in during runtime\n    self._control = None\n    self._command = None\n    self._command_scale_factor = None\n    self._command_output_transform = None\n    self._command_input_transform = None\n\n    # Standardize command input / output limits to be (min_array, max_array)\n    command_input_limits = (-1.0, 1.0) if command_input_limits == \"default\" else command_input_limits\n    command_output_limits = (\n        (\n            np.array(self._control_limits[self.control_type][0])[self.dof_idx],\n            np.array(self._control_limits[self.control_type][1])[self.dof_idx],\n        )\n        if command_output_limits == \"default\"\n        else command_output_limits\n    )\n    self._command_input_limits = (\n        None\n        if command_input_limits is None\n        else (\n            self.nums2array(command_input_limits[0], self.command_dim),\n            self.nums2array(command_input_limits[1], self.command_dim),\n        )\n    )\n    self._command_output_limits = (\n        None\n        if command_output_limits is None\n        else (\n            self.nums2array(command_output_limits[0], self.command_dim),\n            self.nums2array(command_output_limits[1], self.command_dim),\n        )\n    )\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.__init__"},{"title":"<code>clip_control(control)</code>","text":"<p>Clips the inputted @control signal based on @control_limits.</p> <p>Parameters:</p>    Name Type Description Default     <code>control</code>  <code>Array[float]</code>  <p>control signal to clip</p>  required     <p>Returns:</p>    Type Description       <p>Array[float]: Clipped control signal</p>     Source code in <code>controllers/controller_base.py</code> <pre><code>def clip_control(self, control):\n    \"\"\"\n    Clips the inputted @control signal based on @control_limits.\n\n    Args:\n        control (Array[float]): control signal to clip\n\n    Returns:\n        Array[float]: Clipped control signal\n    \"\"\"\n    clipped_control = control.clip(\n        self._control_limits[self.control_type][0][self.dof_idx],\n        self._control_limits[self.control_type][1][self.dof_idx],\n    )\n    idx = (\n        self._dof_has_limits[self.dof_idx]\n        if self.control_type == ControlType.POSITION\n        else [True] * self.control_dim\n    )\n    control[idx] = clipped_control[idx]\n    return control\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.clip_control"},{"title":"<code>nums2array(nums, dim)</code>  <code>staticmethod</code>","text":"<p>Convert input @nums into numpy array of length @dim. If @nums is a single number, broadcasts it to the corresponding dimension size @dim before converting into a numpy array</p> <p>Parameters:</p>    Name Type Description Default     <code>nums</code>  <code>numeric or Iterable</code>  <p>Either single value or array of numbers</p>  required    <code>dim</code>  <code>int</code>  <p>Size of array to broadcast input to</p>  required     <p>Returns:</p>    Type Description       <p>np.array: Array filled with values specified in @nums</p>     Source code in <code>controllers/controller_base.py</code> <pre><code>@staticmethod\ndef nums2array(nums, dim):\n    \"\"\"\n    Convert input @nums into numpy array of length @dim. If @nums is a single number, broadcasts it to the\n    corresponding dimension size @dim before converting into a numpy array\n\n    Args:\n        nums (numeric or Iterable): Either single value or array of numbers\n        dim (int): Size of array to broadcast input to\n\n    Returns:\n        np.array: Array filled with values specified in @nums\n    \"\"\"\n    # First run sanity check to make sure no strings are being inputted\n    if isinstance(nums, str):\n        raise TypeError(\"Error: Only numeric inputs are supported for this function, nums2array!\")\n\n    # Check if input is an Iterable, if so, we simply convert the input to np.array and return\n    # Else, input is a single value, so we map to a numpy array of correct size and return\n    return np.array(nums) if isinstance(nums, Iterable) else np.ones(dim) * nums\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.nums2array"},{"title":"<code>reset()</code>","text":"<p>Resets this controller. Should be implemented by subclass.</p>  Source code in <code>controllers/controller_base.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Resets this controller. Should be implemented by subclass.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.reset"},{"title":"<code>step(control_dict)</code>","text":"<p>Take a controller step.</p> <p>Parameters:</p>    Name Type Description Default     <code>control_dict</code>  <code>Dict[str, Any]</code>  <p>dictionary that should include any relevant keyword-mapped states necessary for controller computation</p>  required     <p>Returns:</p>    Type Description       <p>Array[float]: numpy array of outputted control signals</p>     Source code in <code>controllers/controller_base.py</code> <pre><code>def step(self, control_dict):\n    \"\"\"\n    Take a controller step.\n\n    Args:\n        control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n            states necessary for controller computation\n\n    Returns:\n        Array[float]: numpy array of outputted control signals\n    \"\"\"\n    control = self._command_to_control(command=self._command, control_dict=control_dict)\n    self._control = self.clip_control(control=control)\n    return self._control\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.step"},{"title":"<code>update_command(command)</code>","text":"<p>Updates inputted @command internally.</p> <p>Parameters:</p>    Name Type Description Default     <code>command</code>  <code>Array[float]</code>  <p>inputted command to store internally in this controller</p>  required      Source code in <code>controllers/controller_base.py</code> <pre><code>def update_command(self, command):\n    \"\"\"\n    Updates inputted @command internally.\n\n    Args:\n        command (Array[float]): inputted command to store internally in this controller\n    \"\"\"\n    # Sanity check the command\n    assert len(command) == self.command_dim, \"Commands must be dimension {}, got dim {} instead.\".format(\n        self.command_dim, len(command)\n    )\n    # Preprocess and store inputted command\n    self._command = self._preprocess_command(np.array(command))\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.BaseController.update_command"},{"title":"<code>ControlType</code>","text":"Source code in <code>controllers/controller_base.py</code> <pre><code>class ControlType:\n    POSITION = 0\n    VELOCITY = 1\n    EFFORT = 2\n    _MAPPING = {\n        \"position\": POSITION,\n        \"velocity\": VELOCITY,\n        \"effort\": EFFORT,\n    }\n    VALID_TYPES = set(_MAPPING.values())\n    VALID_TYPES_STR = set(_MAPPING.keys())\n\n    @classmethod\n    def get_type(cls, type_str):\n        \"\"\"\n        Args:\n            type_str (str): One of \"position\", \"velocity\", or \"effort\" (any case), and maps it\n                to the corresponding type\n\n        Returns:\n            ControlType: control type corresponding to the associated string\n        \"\"\"\n        assert_valid_key(key=type_str.lower(), valid_keys=cls._MAPPING, name=\"control type\")\n        return cls._MAPPING[type_str.lower()]\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.ControlType"},{"title":"<code>get_type(type_str)</code>  <code>classmethod</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>type_str</code>  <code>str</code>  <p>One of \"position\", \"velocity\", or \"effort\" (any case), and maps it to the corresponding type</p>  required     <p>Returns:</p>    Name Type Description     <code>ControlType</code>   <p>control type corresponding to the associated string</p>     Source code in <code>controllers/controller_base.py</code> <pre><code>@classmethod\ndef get_type(cls, type_str):\n    \"\"\"\n    Args:\n        type_str (str): One of \"position\", \"velocity\", or \"effort\" (any case), and maps it\n            to the corresponding type\n\n    Returns:\n        ControlType: control type corresponding to the associated string\n    \"\"\"\n    assert_valid_key(key=type_str.lower(), valid_keys=cls._MAPPING, name=\"control type\")\n    return cls._MAPPING[type_str.lower()]\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.ControlType.get_type"},{"title":"<code>GripperController</code>","text":"<p>         Bases: <code>BaseController</code></p> <p>Controller to control a gripper. All implemented controllers that encompass gripper capabilities should extend from this class.</p>  Source code in <code>controllers/controller_base.py</code> <pre><code>class GripperController(BaseController):\n    \"\"\"\n    Controller to control a gripper. All implemented controllers that encompass gripper capabilities\n    should extend from this class.\n    \"\"\"\n\n    def __init_subclass__(cls, **kwargs):\n        # Register as part of gripper controllers\n        super().__init_subclass__(**kwargs)\n        register_gripper_controller(cls)\n\n    def is_grasping(self):\n        \"\"\"\n        Checks whether the current state of this gripper being controlled is in a grasping state.\n        Should be implemented by subclass.\n\n        Returns:\n            IsGraspingState: Grasping state of gripper\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"GripperController\")\n        return classes\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.GripperController"},{"title":"<code>is_grasping()</code>","text":"<p>Checks whether the current state of this gripper being controlled is in a grasping state. Should be implemented by subclass.</p> <p>Returns:</p>    Name Type Description     <code>IsGraspingState</code>   <p>Grasping state of gripper</p>     Source code in <code>controllers/controller_base.py</code> <pre><code>def is_grasping(self):\n    \"\"\"\n    Checks whether the current state of this gripper being controlled is in a grasping state.\n    Should be implemented by subclass.\n\n    Returns:\n        IsGraspingState: Grasping state of gripper\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.GripperController.is_grasping"},{"title":"<code>LocomotionController</code>","text":"<p>         Bases: <code>BaseController</code></p> <p>Controller to control locomotion. All implemented controllers that encompass locomotion capabilities should extend from this class.</p>  Source code in <code>controllers/controller_base.py</code> <pre><code>class LocomotionController(BaseController):\n    \"\"\"\n    Controller to control locomotion. All implemented controllers that encompass locomotion capabilities should extend\n    from this class.\n    \"\"\"\n\n    def __init_subclass__(cls, **kwargs):\n        # Register as part of locomotion controllers\n        super().__init_subclass__(**kwargs)\n        register_locomotion_controller(cls)\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"LocomotionController\")\n        return classes\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.LocomotionController"},{"title":"<code>ManipulationController</code>","text":"<p>         Bases: <code>BaseController</code></p> <p>Controller to control manipulation. All implemented controllers that encompass manipulation capabilities should extend from this class.</p>  Source code in <code>controllers/controller_base.py</code> <pre><code>class ManipulationController(BaseController):\n    \"\"\"\n    Controller to control manipulation. All implemented controllers that encompass manipulation capabilities\n    should extend from this class.\n    \"\"\"\n\n    def __init_subclass__(cls, **kwargs):\n        # Register as part of manipulation controllers\n        super().__init_subclass__(**kwargs)\n        register_manipulation_controller(cls)\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"ManipulationController\")\n        return classes\n</code></pre>","location":"reference/controllers/controller_base.html#controllers.controller_base.ManipulationController"},{"title":"dd_controller","text":"","location":"reference/controllers/dd_controller.html"},{"title":"<code>DifferentialDriveController</code>","text":"<p>         Bases: <code>LocomotionController</code></p> <p>Differential drive (DD) controller for controlling two independently controlled wheeled joints.</p>  Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits</li> <li>Convert desired (lin_vel, ang_vel) command into (left, right) wheel joint velocity control signals</li> <li>Clips the resulting command by the joint velocity limits</li> </ol>   Source code in <code>controllers/dd_controller.py</code> <pre><code>class DifferentialDriveController(LocomotionController):\n    \"\"\"\n    Differential drive (DD) controller for controlling two independently controlled wheeled joints.\n\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2. Convert desired (lin_vel, ang_vel) command into (left, right) wheel joint velocity control signals\n        3. Clips the resulting command by the joint velocity limits\n    \"\"\"\n\n    def __init__(\n        self,\n        wheel_radius,\n        wheel_axle_length,\n        control_freq,\n        control_limits,\n        dof_idx,\n        command_input_limits=\"default\",\n        command_output_limits=\"default\",\n    ):\n        \"\"\"\n        Args:\n            wheel_radius (float): radius of the wheels (both assumed to be same radius)\n            wheel_axle_length (float): perpendicular distance between the two wheels\n            control_freq (int): controller loop frequency\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the maximum linear and angular velocities calculated from @wheel_radius, @wheel_axle_length, and\n                @control_limits velocity limits entry\n        \"\"\"\n        # Store internal variables\n        self._wheel_radius = wheel_radius\n        self._wheel_axle_halflength = wheel_axle_length / 2.0\n\n        # If we're using default command output limits, map this to maximum linear / angular velocities\n        if command_output_limits == \"default\":\n            min_vels = control_limits[\"velocity\"][0][dof_idx]\n            assert (\n                min_vels[0] == min_vels[1]\n            ), \"Differential drive requires both wheel joints to have same min velocities!\"\n            max_vels = control_limits[\"velocity\"][1][dof_idx]\n            assert (\n                max_vels[0] == max_vels[1]\n            ), \"Differential drive requires both wheel joints to have same max velocities!\"\n            assert abs(min_vels[0]) == abs(\n                max_vels[0]\n            ), \"Differential drive requires both wheel joints to have same min and max absolute velocities!\"\n            max_lin_vel = max_vels[0] * wheel_radius\n            max_ang_vel = max_lin_vel * 2.0 / wheel_axle_length\n            command_output_limits = ((-max_lin_vel, -max_ang_vel), (max_lin_vel, max_ang_vel))\n\n        # Run super init\n        super().__init__(\n            control_freq=control_freq,\n            control_limits=control_limits,\n            dof_idx=dof_idx,\n            command_input_limits=command_input_limits,\n            command_output_limits=command_output_limits,\n        )\n\n    def reset(self):\n        # No-op\n        pass\n\n    def _command_to_control(self, command, control_dict):\n        \"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) joint control signal.\n        This processes converts the desired (lin_vel, ang_vel) command into (left, right) wheel joint velocity control\n        signals.\n\n        Args:\n            command (Array[float]): desired (already preprocessed) 2D command to convert into control signals\n                Consists of desired (lin_vel, ang_vel) of the controlled body\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n\n        Returns:\n            Array[float]: outputted (non-clipped!) velocity control signal to deploy\n                to the [left, right] wheel joints\n        \"\"\"\n        lin_vel, ang_vel = command\n\n        # Convert to wheel velocities\n        left_wheel_joint_vel = (lin_vel - ang_vel * self._wheel_axle_halflength) / self._wheel_radius\n        right_wheel_joint_vel = (lin_vel + ang_vel * self._wheel_axle_halflength) / self._wheel_radius\n\n        # Return desired velocities\n        return np.array([left_wheel_joint_vel, right_wheel_joint_vel])\n\n    @property\n    def control_type(self):\n        return ControlType.VELOCITY\n\n    @property\n    def command_dim(self):\n        # [lin_vel, ang_vel]\n        return 2\n</code></pre>","location":"reference/controllers/dd_controller.html#controllers.dd_controller.DifferentialDriveController"},{"title":"<code>__init__(wheel_radius, wheel_axle_length, control_freq, control_limits, dof_idx, command_input_limits='default', command_output_limits='default')</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>wheel_radius</code>  <code>float</code>  <p>radius of the wheels (both assumed to be same radius)</p>  required    <code>wheel_axle_length</code>  <code>float</code>  <p>perpendicular distance between the two wheels</p>  required    <code>control_freq</code>  <code>int</code>  <p>controller loop frequency</p>  required    <code>control_limits</code>  <code>Dict[str, Tuple[Array[float], Array[float]]]</code>  <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p>  required    <code>dof_idx</code>  <code>Array[int]</code>  <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p>  required    <code>command_input_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p>  <code>'default'</code>    <code>command_output_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the maximum linear and angular velocities calculated from @wheel_radius, @wheel_axle_length, and @control_limits velocity limits entry</p>  <code>'default'</code>      Source code in <code>controllers/dd_controller.py</code> <pre><code>def __init__(\n    self,\n    wheel_radius,\n    wheel_axle_length,\n    control_freq,\n    control_limits,\n    dof_idx,\n    command_input_limits=\"default\",\n    command_output_limits=\"default\",\n):\n    \"\"\"\n    Args:\n        wheel_radius (float): radius of the wheels (both assumed to be same radius)\n        wheel_axle_length (float): perpendicular distance between the two wheels\n        control_freq (int): controller loop frequency\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the maximum linear and angular velocities calculated from @wheel_radius, @wheel_axle_length, and\n            @control_limits velocity limits entry\n    \"\"\"\n    # Store internal variables\n    self._wheel_radius = wheel_radius\n    self._wheel_axle_halflength = wheel_axle_length / 2.0\n\n    # If we're using default command output limits, map this to maximum linear / angular velocities\n    if command_output_limits == \"default\":\n        min_vels = control_limits[\"velocity\"][0][dof_idx]\n        assert (\n            min_vels[0] == min_vels[1]\n        ), \"Differential drive requires both wheel joints to have same min velocities!\"\n        max_vels = control_limits[\"velocity\"][1][dof_idx]\n        assert (\n            max_vels[0] == max_vels[1]\n        ), \"Differential drive requires both wheel joints to have same max velocities!\"\n        assert abs(min_vels[0]) == abs(\n            max_vels[0]\n        ), \"Differential drive requires both wheel joints to have same min and max absolute velocities!\"\n        max_lin_vel = max_vels[0] * wheel_radius\n        max_ang_vel = max_lin_vel * 2.0 / wheel_axle_length\n        command_output_limits = ((-max_lin_vel, -max_ang_vel), (max_lin_vel, max_ang_vel))\n\n    # Run super init\n    super().__init__(\n        control_freq=control_freq,\n        control_limits=control_limits,\n        dof_idx=dof_idx,\n        command_input_limits=command_input_limits,\n        command_output_limits=command_output_limits,\n    )\n</code></pre>","location":"reference/controllers/dd_controller.html#controllers.dd_controller.DifferentialDriveController.__init__"},{"title":"ik_controller","text":"","location":"reference/controllers/ik_controller.html"},{"title":"<code>InverseKinematicsController</code>","text":"<p>         Bases: <code>ManipulationController</code></p> <p>Controller class to convert (delta) EEF commands into joint velocities using Inverse Kinematics (IK).</p>  Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits</li> <li>Run Inverse Kinematics to back out joint velocities for a desired task frame command</li> <li>Clips the resulting command by the motor (velocity) limits</li> </ol>   Source code in <code>controllers/ik_controller.py</code> <pre><code>class InverseKinematicsController(ManipulationController):\n    \"\"\"\n    Controller class to convert (delta) EEF commands into joint velocities using Inverse Kinematics (IK).\n\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2. Run Inverse Kinematics to back out joint velocities for a desired task frame command\n        3. Clips the resulting command by the motor (velocity) limits\n    \"\"\"\n\n    def __init__(\n        self,\n        task_name,\n        robot_description_path,\n        robot_urdf_path,\n        eef_name,\n        control_freq,\n        default_joint_pos,          # TODO: Currently doesn't do anything in Lula\n        control_limits,\n        dof_idx,\n        command_input_limits=\"default\",\n        command_output_limits=((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5)),\n        motor_type=\"velocity\",\n        kv=2.0,\n        mode=\"pose_delta_ori\",\n        smoothing_filter_size=None,\n        workspace_pose_limiter=None,\n    ):\n        \"\"\"\n        Args:\n            task_name (str): name assigned to this task frame for computing IK control. During control calculations,\n                the inputted control_dict should include entries named &lt;@task_name&gt;_pos_relative and\n                &lt;@task_name&gt;_quat_relative. See self._command_to_control() for what these values should entail.\n            robot_description_path (str): path to robot descriptor yaml file\n            robot_urdf_path (str): path to robot urdf file\n            eef_name (str): end effector frame name\n            control_freq (int): controller loop frequency\n            default_joint_pos (Array[float]): default joint positions, used as part of nullspace controller in IK.\n                Note that this should correspond to ALL the joints; the exact indices will be extracted via @dof_idx\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                    control signal. Should specify per-dof type limits, i.e.:\n\n                    \"position\": [[min], [max]]\n                    \"velocity\": [[min], [max]]\n                    \"effort\": [[min], [max]]\n                    \"has_limit\": [...bool...]\n\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            motor_type (str): type of motor being controlled, one of {position, velocity}\n            kv (float): Gain applied to error between IK-commanded joint positions and current joint positions if\n                using @motor_type = velocity\n            mode (str): mode to use when computing IK. In all cases, position commands are 3DOF delta (dx,dy,dz)\n                cartesian values, relative to the robot base frame. Valid options are:\n                    - \"pose_absolute_ori\": 6DOF (dx,dy,dz,ax,ay,az) control over pose,\n                        where the orientation is given in absolute axis-angle coordinates\n                    - \"pose_delta_ori\": 6DOF (dx,dy,dz,dax,day,daz) control over pose\n                    - \"position_fixed_ori\": 3DOF (dx,dy,dz) control over position,\n                        with orientation commands being kept as fixed initial absolute orientation\n                    - \"position_compliant_ori\": 3DOF (dx,dy,dz) control over position,\n                        with orientation commands automatically being sent as 0s (so can drift over time)\n            smoothing_filter_size (None or int): if specified, sets the size of a moving average filter to apply\n                on all outputted IK joint positions.\n            workspace_pose_limiter (None or function): if specified, callback method that should clip absolute\n                target (x,y,z) cartesian position and absolute quaternion orientation (x,y,z,w) to a specific workspace\n                range (i.e.: this can be unique to each robot, and implemented by each embodiment).\n                Function signature should be:\n\n                    def limiter(command_pos: Array[float], command_quat: Array[float], control_dict: Dict[str, Any]) --&gt; Tuple[Array[float], Array[float]]\n\n                where pos_command is (x,y,z) cartesian position values, command_quat is (x,y,z,w) quarternion orientation\n                values, and the returned tuple is the processed (pos, quat) command.\n        \"\"\"\n        # Store arguments\n        control_dim = len(dof_idx)\n        assert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\n        self._motor_type = motor_type.lower()\n        self.control_filter = (\n            None\n            if smoothing_filter_size in {None, 0}\n            else MovingAverageFilter(obs_dim=control_dim, filter_width=smoothing_filter_size)\n        )\n        assert mode in IK_MODES, \"Invalid ik mode specified! Valid options are: {IK_MODES}, got: {mode}\"\n        self.mode = mode\n        self.kv = kv\n        self.workspace_pose_limiter = workspace_pose_limiter\n        self.task_name = task_name\n        self.default_joint_pos = default_joint_pos[dof_idx]\n\n        # Create the lula IKSolver\n        self.solver = IKSolver(\n            robot_description_path=robot_description_path,\n            robot_urdf_path=robot_urdf_path,\n            eef_name=eef_name,\n            default_joint_pos=default_joint_pos,\n        )\n\n        # Other variables that will be filled in at runtime\n        self._quat_target = None\n\n        # If the mode is set as absolute orientation and using default config,\n        # change input and output limits accordingly.\n        # By default, the input limits are set as 1, so we modify this to have a correct range.\n        # The output orientation limits are also set to be values assuming delta commands, so those are updated too\n        if self.mode == \"pose_absolute_ori\":\n            if command_input_limits is not None:\n                if command_input_limits == \"default\":\n                    command_input_limits = [\n                        [-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n                        [1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n                    ]\n                else:\n                    command_input_limits[0][3:] = -np.pi\n                    command_input_limits[1][3:] = np.pi\n            if command_output_limits is not None:\n                if command_output_limits == \"default\":\n                    command_output_limits = [\n                        [-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n                        [1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n                    ]\n                else:\n                    command_output_limits[0][3:] = -np.pi\n                    command_output_limits[1][3:] = np.pi\n\n        # Run super init\n        super().__init__(\n            control_freq=control_freq,\n            control_limits=control_limits,\n            dof_idx=dof_idx,\n            command_input_limits=command_input_limits,\n            command_output_limits=command_output_limits,\n        )\n\n    def reset(self):\n        # Reset the filter and clear internal control state\n        if self.control_filter is not None:\n            self.control_filter.reset()\n        self._quat_target = None\n\n    @property\n    def state_size(self):\n        # Add 4 for internal quat target and the state size from the control filter\n        return super().state_size + 4 + self.control_filter.state_size\n\n    def _dump_state(self):\n        # Run super first\n        state = super()._dump_state()\n\n        # Add internal quaternion target and filter state\n        state[\"quat_target\"] = self._quat_target\n        state[\"control_filter\"] = self.control_filter.dump_state(serialized=False)\n\n        return state\n\n    def _load_state(self, state):\n        # Run super first\n        super()._load_state(state=state)\n\n        # Load relevant info for this controller\n        self._quat_target = state[\"quat_target\"]\n        self.control_filter.load_state(state[\"control_filter\"], serialized=False)\n\n    def _serialize(self, state):\n        # Run super first\n        state_flat = super()._serialize(state=state)\n\n        # Serialize state for this controller\n        return np.concatenate([\n            state_flat,\n            np.zeros(4) if state[\"quat_target\"] is None else state[\"quat_target\"],      # Encode None as zeros for consistent serialization size\n            self.control_filter.serialize(state=state[\"control_filter\"]),\n        ]).astype(float)\n\n    def _deserialize(self, state):\n        # Run super first\n        state_dict, idx = super()._deserialize(state=state)\n\n        # Deserialize state for this controller\n        state_dict[\"quat_target\"] = None if np.all(state[idx: idx + 4] == 0.0) else state[idx: idx + 4]\n        state_dict[\"control_filter\"] = self.control_filter.deserialize(state=state[idx + 4: idx + 4 + self.control_filter.state_size])\n\n        return state_dict, idx + 4 + self.control_filter.state_size\n\n    def _command_to_control(self, command, control_dict):\n        \"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) joint control signal.\n        This processes the command based on self.mode, possibly clips the command based on self.workspace_pose_limiter,\n\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals\n                Is one of:\n                    (dx,dy,dz) - desired delta cartesian position\n                    (dx,dy,dz,dax,day,daz) - desired delta cartesian position and delta axis-angle orientation\n                    (dx,dy,dz,ax,ay,az) - desired delta cartesian position and global axis-angle orientation\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n                    joint_position: Array of current joint positions\n                    base_pos: (x,y,z) cartesian position of the robot's base relative to the static global frame\n                    base_quat: (x,y,z,w) quaternion orientation of the robot's base relative to the static global frame\n                    &lt;@self.task_name&gt;_pos_relative: (x,y,z) relative cartesian position of the desired task frame to\n                        control, computed in its local frame (e.g.: robot base frame)\n                    &lt;@self.task_name&gt;_quat_relative: (x,y,z,w) relative quaternion orientation of the desired task\n                        frame to control, computed in its local frame (e.g.: robot base frame)\n\n        Returns:\n            Array[float]: outputted (non-clipped!) velocity control signal to deploy\n        \"\"\"\n        # Grab important info from control dict\n        pos_relative = np.array(control_dict[\"{}_pos_relative\".format(self.task_name)])\n        quat_relative = np.array(control_dict[\"{}_quat_relative\".format(self.task_name)])\n\n        # The first three values of the command are always the (delta) position, convert to absolute values\n        dpos = command[:3]\n        target_pos = pos_relative + dpos\n\n        # Compute orientation\n        if self.mode == \"position_fixed_ori\":\n            # We need to grab the current robot orientation as the commanded orientation if there is none saved\n            if self._quat_target is None:\n                self._quat_target = quat_relative\n            target_quat = self._quat_target\n        elif self.mode == \"position_compliant_ori\":\n            # Target quat is simply the current robot orientation\n            target_quat = quat_relative\n        elif self.mode == \"pose_absolute_ori\":\n            # Received \"delta\" ori is in fact the desired absolute orientation\n            target_quat = T.axisangle2quat(command[3:])\n        else:  # pose_delta_ori control\n            # Grab dori and compute target ori\n            dori = T.quat2mat(T.axisangle2quat(command[3:]))\n            target_quat = T.mat2quat(dori @ T.quat2mat(quat_relative))\n\n        # Possibly limit to workspace if specified\n        if self.workspace_pose_limiter is not None:\n            target_pos, target_quat = self.workspace_pose_limiter(target_pos, target_quat, control_dict)\n\n        # Calculate and return IK-backed out joint angles\n        current_joint_pos = control_dict[\"joint_position\"][self.dof_idx]\n        target_joint_pos = self.solver.solve(\n            target_pos=target_pos,\n            target_quat=target_quat,\n            initial_joint_pos=current_joint_pos,\n        )\n\n        if target_joint_pos is None:\n            # Print warning that we couldn't find a valid solution, and return the current joint configuration\n            # instead so that we execute a no-op control\n            print(f\"Could not find valid IK configuration! Returning no-op control instead.\")\n            target_joint_pos = current_joint_pos\n\n        # Optionally pass through smoothing filter for better stability\n        if self.control_filter is not None:\n            target_joint_pos = self.control_filter.estimate(target_joint_pos)\n\n        # Grab the resulting error and scale it by the velocity gain, or else simply use the target_joint_pos\n        u = -self.kv * (current_joint_pos - target_joint_pos) if \\\n            self.control_type == ControlType.VELOCITY else target_joint_pos\n\n        # Return these commanded velocities (this only includes the relevant dof idx)\n        return u\n\n    @property\n    def control_type(self):\n        return ControlType.get_type(type_str=self._motor_type)\n\n    @property\n    def command_dim(self):\n        return IK_MODE_COMMAND_DIMS[self.mode]\n</code></pre>","location":"reference/controllers/ik_controller.html#controllers.ik_controller.InverseKinematicsController"},{"title":"<code>__init__(task_name, robot_description_path, robot_urdf_path, eef_name, control_freq, default_joint_pos, control_limits, dof_idx, command_input_limits='default', command_output_limits=((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5)), motor_type='velocity', kv=2.0, mode='pose_delta_ori', smoothing_filter_size=None, workspace_pose_limiter=None)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>task_name</code>  <code>str</code>  <p>name assigned to this task frame for computing IK control. During control calculations, the inputted control_dict should include entries named &lt;@task_name&gt;_pos_relative and &lt;@task_name&gt;_quat_relative. See self._command_to_control() for what these values should entail.</p>  required    <code>robot_description_path</code>  <code>str</code>  <p>path to robot descriptor yaml file</p>  required    <code>robot_urdf_path</code>  <code>str</code>  <p>path to robot urdf file</p>  required    <code>eef_name</code>  <code>str</code>  <p>end effector frame name</p>  required    <code>control_freq</code>  <code>int</code>  <p>controller loop frequency</p>  required    <code>default_joint_pos</code>  <code>Array[float]</code>  <p>default joint positions, used as part of nullspace controller in IK. Note that this should correspond to ALL the joints; the exact indices will be extracted via @dof_idx</p>  required    <code>control_limits</code>  <code>Dict[str, Tuple[Array[float], Array[float]]]</code>  <p>The min/max limits to the outputted     control signal. Should specify per-dof type limits, i.e.:</p> <pre><code>\"position\": [[min], [max]]\n\"velocity\": [[min], [max]]\n\"effort\": [[min], [max]]\n\"has_limit\": [...bool...]\n</code></pre> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p>  required    <code>dof_idx</code>  <code>Array[int]</code>  <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p>  required    <code>command_input_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p>  <code>'default'</code>    <code>command_output_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p>  <code>((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5))</code>    <code>motor_type</code>  <code>str</code>  <p>type of motor being controlled, one of {position, velocity}</p>  <code>'velocity'</code>    <code>kv</code>  <code>float</code>  <p>Gain applied to error between IK-commanded joint positions and current joint positions if using @motor_type = velocity</p>  <code>2.0</code>    <code>mode</code>  <code>str</code>  <p>mode to use when computing IK. In all cases, position commands are 3DOF delta (dx,dy,dz) cartesian values, relative to the robot base frame. Valid options are:     - \"pose_absolute_ori\": 6DOF (dx,dy,dz,ax,ay,az) control over pose,         where the orientation is given in absolute axis-angle coordinates     - \"pose_delta_ori\": 6DOF (dx,dy,dz,dax,day,daz) control over pose     - \"position_fixed_ori\": 3DOF (dx,dy,dz) control over position,         with orientation commands being kept as fixed initial absolute orientation     - \"position_compliant_ori\": 3DOF (dx,dy,dz) control over position,         with orientation commands automatically being sent as 0s (so can drift over time)</p>  <code>'pose_delta_ori'</code>    <code>smoothing_filter_size</code>  <code>None or int</code>  <p>if specified, sets the size of a moving average filter to apply on all outputted IK joint positions.</p>  <code>None</code>    <code>workspace_pose_limiter</code>  <code>None or function</code>  <p>if specified, callback method that should clip absolute target (x,y,z) cartesian position and absolute quaternion orientation (x,y,z,w) to a specific workspace range (i.e.: this can be unique to each robot, and implemented by each embodiment). Function signature should be:</p> <pre><code>def limiter(command_pos: Array[float], command_quat: Array[float], control_dict: Dict[str, Any]) --&gt; Tuple[Array[float], Array[float]]\n</code></pre> <p>where pos_command is (x,y,z) cartesian position values, command_quat is (x,y,z,w) quarternion orientation values, and the returned tuple is the processed (pos, quat) command.</p>  <code>None</code>      Source code in <code>controllers/ik_controller.py</code> <pre><code>def __init__(\n    self,\n    task_name,\n    robot_description_path,\n    robot_urdf_path,\n    eef_name,\n    control_freq,\n    default_joint_pos,          # TODO: Currently doesn't do anything in Lula\n    control_limits,\n    dof_idx,\n    command_input_limits=\"default\",\n    command_output_limits=((-0.2, -0.2, -0.2, -0.5, -0.5, -0.5), (0.2, 0.2, 0.2, 0.5, 0.5, 0.5)),\n    motor_type=\"velocity\",\n    kv=2.0,\n    mode=\"pose_delta_ori\",\n    smoothing_filter_size=None,\n    workspace_pose_limiter=None,\n):\n    \"\"\"\n    Args:\n        task_name (str): name assigned to this task frame for computing IK control. During control calculations,\n            the inputted control_dict should include entries named &lt;@task_name&gt;_pos_relative and\n            &lt;@task_name&gt;_quat_relative. See self._command_to_control() for what these values should entail.\n        robot_description_path (str): path to robot descriptor yaml file\n        robot_urdf_path (str): path to robot urdf file\n        eef_name (str): end effector frame name\n        control_freq (int): controller loop frequency\n        default_joint_pos (Array[float]): default joint positions, used as part of nullspace controller in IK.\n            Note that this should correspond to ALL the joints; the exact indices will be extracted via @dof_idx\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        motor_type (str): type of motor being controlled, one of {position, velocity}\n        kv (float): Gain applied to error between IK-commanded joint positions and current joint positions if\n            using @motor_type = velocity\n        mode (str): mode to use when computing IK. In all cases, position commands are 3DOF delta (dx,dy,dz)\n            cartesian values, relative to the robot base frame. Valid options are:\n                - \"pose_absolute_ori\": 6DOF (dx,dy,dz,ax,ay,az) control over pose,\n                    where the orientation is given in absolute axis-angle coordinates\n                - \"pose_delta_ori\": 6DOF (dx,dy,dz,dax,day,daz) control over pose\n                - \"position_fixed_ori\": 3DOF (dx,dy,dz) control over position,\n                    with orientation commands being kept as fixed initial absolute orientation\n                - \"position_compliant_ori\": 3DOF (dx,dy,dz) control over position,\n                    with orientation commands automatically being sent as 0s (so can drift over time)\n        smoothing_filter_size (None or int): if specified, sets the size of a moving average filter to apply\n            on all outputted IK joint positions.\n        workspace_pose_limiter (None or function): if specified, callback method that should clip absolute\n            target (x,y,z) cartesian position and absolute quaternion orientation (x,y,z,w) to a specific workspace\n            range (i.e.: this can be unique to each robot, and implemented by each embodiment).\n            Function signature should be:\n\n                def limiter(command_pos: Array[float], command_quat: Array[float], control_dict: Dict[str, Any]) --&gt; Tuple[Array[float], Array[float]]\n\n            where pos_command is (x,y,z) cartesian position values, command_quat is (x,y,z,w) quarternion orientation\n            values, and the returned tuple is the processed (pos, quat) command.\n    \"\"\"\n    # Store arguments\n    control_dim = len(dof_idx)\n    assert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\n    self._motor_type = motor_type.lower()\n    self.control_filter = (\n        None\n        if smoothing_filter_size in {None, 0}\n        else MovingAverageFilter(obs_dim=control_dim, filter_width=smoothing_filter_size)\n    )\n    assert mode in IK_MODES, \"Invalid ik mode specified! Valid options are: {IK_MODES}, got: {mode}\"\n    self.mode = mode\n    self.kv = kv\n    self.workspace_pose_limiter = workspace_pose_limiter\n    self.task_name = task_name\n    self.default_joint_pos = default_joint_pos[dof_idx]\n\n    # Create the lula IKSolver\n    self.solver = IKSolver(\n        robot_description_path=robot_description_path,\n        robot_urdf_path=robot_urdf_path,\n        eef_name=eef_name,\n        default_joint_pos=default_joint_pos,\n    )\n\n    # Other variables that will be filled in at runtime\n    self._quat_target = None\n\n    # If the mode is set as absolute orientation and using default config,\n    # change input and output limits accordingly.\n    # By default, the input limits are set as 1, so we modify this to have a correct range.\n    # The output orientation limits are also set to be values assuming delta commands, so those are updated too\n    if self.mode == \"pose_absolute_ori\":\n        if command_input_limits is not None:\n            if command_input_limits == \"default\":\n                command_input_limits = [\n                    [-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n                    [1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n                ]\n            else:\n                command_input_limits[0][3:] = -np.pi\n                command_input_limits[1][3:] = np.pi\n        if command_output_limits is not None:\n            if command_output_limits == \"default\":\n                command_output_limits = [\n                    [-1.0, -1.0, -1.0, -np.pi, -np.pi, -np.pi],\n                    [1.0, 1.0, 1.0, np.pi, np.pi, np.pi],\n                ]\n            else:\n                command_output_limits[0][3:] = -np.pi\n                command_output_limits[1][3:] = np.pi\n\n    # Run super init\n    super().__init__(\n        control_freq=control_freq,\n        control_limits=control_limits,\n        dof_idx=dof_idx,\n        command_input_limits=command_input_limits,\n        command_output_limits=command_output_limits,\n    )\n</code></pre>","location":"reference/controllers/ik_controller.html#controllers.ik_controller.InverseKinematicsController.__init__"},{"title":"joint_controller","text":"","location":"reference/controllers/joint_controller.html"},{"title":"<code>JointController</code>","text":"<p>         Bases: <code>LocomotionController</code>, <code>ManipulationController</code>, <code>GripperController</code></p> <p>Controller class for joint control. Because omniverse can handle direct position / velocity / effort control signals, this is merely a pass-through operation from command to control (with clipping / scaling built in).</p>  Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits 2a. If using delta commands, then adds the command to the current joint state 2b. Clips the resulting command by the motor limits</li> </ol>   Source code in <code>controllers/joint_controller.py</code> <pre><code>class JointController(LocomotionController, ManipulationController, GripperController):\n    \"\"\"\n    Controller class for joint control. Because omniverse can handle direct position / velocity / effort\n    control signals, this is merely a pass-through operation from command to control (with clipping / scaling built in).\n\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2a. If using delta commands, then adds the command to the current joint state\n        2b. Clips the resulting command by the motor limits\n    \"\"\"\n\n    def __init__(\n        self,\n        control_freq,\n        motor_type,\n        control_limits,\n        dof_idx,\n        command_input_limits=\"default\",\n        command_output_limits=\"default\",\n        use_delta_commands=False,\n        compute_delta_in_quat_space=None,\n    ):\n        \"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            motor_type (str): type of motor being controlled, one of {position, velocity, effort}\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            use_delta_commands (bool): whether inputted commands should be interpreted as delta or absolute values\n            compute_delta_in_quat_space (None or List[(rx_idx, ry_idx, rz_idx), ...]): if specified, groups of\n                joints that need to be processed in quaternion space to avoid gimbal lock issues normally faced by\n                3 DOF rotation joints. Each group needs to consist of three idxes corresponding to the indices in\n                the input space. This is only used in the delta_commands mode.\n        \"\"\"\n        # Store arguments\n        assert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\n        self._motor_type = motor_type.lower()\n        self._use_delta_commands = use_delta_commands\n        self._compute_delta_in_quat_space = [] if compute_delta_in_quat_space is None else compute_delta_in_quat_space\n\n        # When in delta mode, it doesn't make sense to infer output range using the joint limits (since that's an\n        # absolute range and our values are relative). So reject the default mode option in that case.\n        assert not (\n            self._use_delta_commands and command_output_limits == \"default\"\n        ), \"Cannot use 'default' command output limits in delta commands mode of JointController. Try None instead.\"\n\n        # Run super init\n        super().__init__(\n            control_freq=control_freq,\n            control_limits=control_limits,\n            dof_idx=dof_idx,\n            command_input_limits=command_input_limits,\n            command_output_limits=command_output_limits,\n        )\n\n    def reset(self):\n        # Nothing to reset.\n        pass\n\n    def _command_to_control(self, command, control_dict):\n        \"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) joint control signal\n\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n                    joint_position: Array of current joint positions\n                    joint_velocity: Array of current joint velocities\n                    joint_effort: Array of current joint effort\n\n        Returns:\n            Array[float]: outputted (non-clipped!) control signal to deploy\n        \"\"\"\n        # If we're using delta commands, add this value\n        if self._use_delta_commands:\n            # Compute the base value for the command.\n            base_value = control_dict[\"joint_{}\".format(self._motor_type)][self.dof_idx]\n\n            # Apply the command to the base value.\n            u = base_value + command\n\n            # Correct any gimbal lock issues using the compute_delta_in_quat_space group.\n            for rx_ind, ry_ind, rz_ind in self._compute_delta_in_quat_space:\n                # Grab the starting rotations of these joints.\n                start_rots = base_value[[rx_ind, ry_ind, rz_ind]]\n\n                # Grab the delta rotations.\n                delta_rots = command[[rx_ind, ry_ind, rz_ind]]\n\n                # Compute the final rotations in the quaternion space.\n                _, end_quat = T.pose_transform(np.zeros(3), T.euler2quat(delta_rots),\n                                               np.zeros(3), T.euler2quat(start_rots))\n                end_rots = T.quat2euler(end_quat)\n\n                # Update the command\n                u[[rx_ind, ry_ind, rz_ind]] = end_rots\n\n        # Otherwise, control is simply the command itself\n        else:\n            u = command\n\n        # Return control\n        return u\n\n    def is_grasping(self):\n        # No good heuristic to determine grasping, so return UNKNOWN\n        return IsGraspingState.UNKNOWN\n\n    @property\n    def use_delta_commands(self):\n        \"\"\"\n        Returns:\n            bool: Whether this controller is using delta commands or not\n        \"\"\"\n        return self._use_delta_commands\n\n    @property\n    def control_type(self):\n        return ControlType.get_type(type_str=self._motor_type)\n\n    @property\n    def command_dim(self):\n        return len(self.dof_idx)\n</code></pre>","location":"reference/controllers/joint_controller.html#controllers.joint_controller.JointController"},{"title":"<code>use_delta_commands</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this controller is using delta commands or not</p>","location":"reference/controllers/joint_controller.html#controllers.joint_controller.JointController.use_delta_commands"},{"title":"<code>__init__(control_freq, motor_type, control_limits, dof_idx, command_input_limits='default', command_output_limits='default', use_delta_commands=False, compute_delta_in_quat_space=None)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>control_freq</code>  <code>int</code>  <p>controller loop frequency</p>  required    <code>motor_type</code>  <code>str</code>  <p>type of motor being controlled, one of {position, velocity, effort}</p>  required    <code>control_limits</code>  <code>Dict[str, Tuple[Array[float], Array[float]]]</code>  <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p>  required    <code>dof_idx</code>  <code>Array[int]</code>  <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p>  required    <code>command_input_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p>  <code>'default'</code>    <code>command_output_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p>  <code>'default'</code>    <code>use_delta_commands</code>  <code>bool</code>  <p>whether inputted commands should be interpreted as delta or absolute values</p>  <code>False</code>    <code>compute_delta_in_quat_space</code>  <code>None or List[(rx_idx, ry_idx, rz_idx), ...]</code>  <p>if specified, groups of joints that need to be processed in quaternion space to avoid gimbal lock issues normally faced by 3 DOF rotation joints. Each group needs to consist of three idxes corresponding to the indices in the input space. This is only used in the delta_commands mode.</p>  <code>None</code>      Source code in <code>controllers/joint_controller.py</code> <pre><code>def __init__(\n    self,\n    control_freq,\n    motor_type,\n    control_limits,\n    dof_idx,\n    command_input_limits=\"default\",\n    command_output_limits=\"default\",\n    use_delta_commands=False,\n    compute_delta_in_quat_space=None,\n):\n    \"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        motor_type (str): type of motor being controlled, one of {position, velocity, effort}\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        use_delta_commands (bool): whether inputted commands should be interpreted as delta or absolute values\n        compute_delta_in_quat_space (None or List[(rx_idx, ry_idx, rz_idx), ...]): if specified, groups of\n            joints that need to be processed in quaternion space to avoid gimbal lock issues normally faced by\n            3 DOF rotation joints. Each group needs to consist of three idxes corresponding to the indices in\n            the input space. This is only used in the delta_commands mode.\n    \"\"\"\n    # Store arguments\n    assert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\n    self._motor_type = motor_type.lower()\n    self._use_delta_commands = use_delta_commands\n    self._compute_delta_in_quat_space = [] if compute_delta_in_quat_space is None else compute_delta_in_quat_space\n\n    # When in delta mode, it doesn't make sense to infer output range using the joint limits (since that's an\n    # absolute range and our values are relative). So reject the default mode option in that case.\n    assert not (\n        self._use_delta_commands and command_output_limits == \"default\"\n    ), \"Cannot use 'default' command output limits in delta commands mode of JointController. Try None instead.\"\n\n    # Run super init\n    super().__init__(\n        control_freq=control_freq,\n        control_limits=control_limits,\n        dof_idx=dof_idx,\n        command_input_limits=command_input_limits,\n        command_output_limits=command_output_limits,\n    )\n</code></pre>","location":"reference/controllers/joint_controller.html#controllers.joint_controller.JointController.__init__"},{"title":"multi_finger_gripper_controller","text":"","location":"reference/controllers/multi_finger_gripper_controller.html"},{"title":"<code>MultiFingerGripperController</code>","text":"<p>         Bases: <code>GripperController</code></p> <p>Controller class for multi finger gripper control. This either interprets an input as a binary command (open / close), continuous command (open / close with scaled velocities), or per-joint continuous command</p>  Each controller step consists of the following <ol> <li>Clip + Scale inputted command according to @command_input_limits and @command_output_limits 2a. Convert command into gripper joint control signals 2b. Clips the resulting control by the motor limits</li> </ol>   Source code in <code>controllers/multi_finger_gripper_controller.py</code> <pre><code>class MultiFingerGripperController(GripperController):\n    \"\"\"\n    Controller class for multi finger gripper control. This either interprets an input as a binary\n    command (open / close), continuous command (open / close with scaled velocities), or per-joint continuous command\n\n    Each controller step consists of the following:\n        1. Clip + Scale inputted command according to @command_input_limits and @command_output_limits\n        2a. Convert command into gripper joint control signals\n        2b. Clips the resulting control by the motor limits\n    \"\"\"\n\n    def __init__(\n        self,\n        control_freq,\n        motor_type,\n        control_limits,\n        dof_idx,\n        command_input_limits=\"default\",\n        command_output_limits=\"default\",\n        inverted=False,\n        mode=\"binary\",\n        limit_tolerance=0.001,\n    ):\n        \"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            inverted (bool): whether or not the command direction (grasp is negative) and the control direction are\n                inverted, e.g. to grasp you need to move the joint in the positive direction.\n            mode (str): mode for this controller. Valid options are:\n\n                \"binary\": 1D command, if preprocessed value &gt; 0 is interpreted as an max open\n                    (send max pos / vel / tor signal), otherwise send max close control signals\n                \"smooth\": 1D command, sends symmetric signal to both finger joints equal to the preprocessed commands\n                \"independent\": 2D command, sends independent signals to each finger joint equal to the preprocessed command\n\n            limit_tolerance (float): sets the tolerance from the joint limit ends, below which controls will be zeroed\n                out if the control is using velocity or torque control\n        \"\"\"\n        # Store arguments\n        assert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\n        self._motor_type = motor_type.lower()\n        assert_valid_key(key=mode, valid_keys=VALID_MODES, name=\"mode for multi finger gripper\")\n        self._inverted = inverted\n        self._mode = mode\n        self._limit_tolerance = limit_tolerance\n\n        # Create other args to be filled in at runtime\n        self._is_grasping = IsGraspingState.FALSE\n\n        # If we're using binary signal, we override the command output limits\n        if mode == \"binary\":\n            command_output_limits = (-1.0, 1.0)\n\n        # Run super init\n        super().__init__(\n            control_freq=control_freq,\n            control_limits=control_limits,\n            dof_idx=dof_idx,\n            command_input_limits=command_input_limits,\n            command_output_limits=command_output_limits,\n        )\n\n    def reset(self):\n        # reset grasping state\n        self._is_grasping = IsGraspingState.FALSE\n\n    def _preprocess_command(self, command):\n        # We extend this method to make sure command is always 2D\n        if self._mode != \"independent\":\n            command = (\n                np.array([command] * self.command_dim)\n                if type(command) in {int, float}\n                else np.array([command[0]] * self.command_dim)\n            )\n\n        # Flip the command if the direction is inverted.\n        if self._inverted:\n            command = self._command_input_limits[1] - (command - self._command_input_limits[0])\n\n        # Return from super method\n        return super()._preprocess_command(command=command)\n\n    def _command_to_control(self, command, control_dict):\n        \"\"\"\n        Converts the (already preprocessed) inputted @command into deployable (non-clipped!) gripper\n        joint control signal\n\n        Args:\n            command (Array[float]): desired (already preprocessed) command to convert into control signals.\n                This should always be 2D command for each gripper joint\n            control_dict (Dict[str, Any]): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n                    joint_position: Array of current joint positions\n                    joint_velocity: Array of current joint velocities\n\n        Returns:\n            Array[float]: outputted (non-clipped!) control signal to deploy\n        \"\"\"\n        joint_pos = control_dict[\"joint_position\"][self.dof_idx]\n        # Choose what to do based on control mode\n        if self._mode == \"binary\":\n            # Use max control signal\n            u = (\n                self._control_limits[ControlType.get_type(self._motor_type)][1][self.dof_idx]\n                if command[0] &gt;= 0.0\n                else self._control_limits[ControlType.get_type(self._motor_type)][0][self.dof_idx]\n            )\n        else:\n            # Use continuous signal\n            u = command\n\n        # If we're near the joint limits and we're using velocity / torque control, we zero out the action\n        if self._motor_type in {\"velocity\", \"torque\"}:\n            violate_upper_limit = (\n                joint_pos &gt; self._control_limits[ControlType.POSITION][1][self.dof_idx] - self._limit_tolerance\n            )\n            violate_lower_limit = (\n                joint_pos &lt; self._control_limits[ControlType.POSITION][0][self.dof_idx] + self._limit_tolerance\n            )\n            violation = np.logical_or(violate_upper_limit * (u &gt; 0), violate_lower_limit * (u &lt; 0))\n            u *= ~violation\n\n        # Update whether we're grasping or not\n        self._update_grasping_state(control_dict=control_dict)\n\n        # Return control\n        return u\n\n    def _update_grasping_state(self, control_dict):\n        \"\"\"\n        Updates internal inferred grasping state of the gripper being controlled by this gripper controller\n\n        Args:\n            control_dict (dict): dictionary that should include any relevant keyword-mapped\n                states necessary for controller computation. Must include the following keys:\n\n                    joint_position: Array of current joint positions\n                    joint_velocity: Array of current joint velocities\n        \"\"\"\n        # Calculate grasping state based on mode of this controller\n\n        # Independent mode of MultiFingerGripperController does not have any good heuristics to determine is_grasping\n        if self._mode == \"independent\":\n            is_grasping = IsGraspingState.UNKNOWN\n\n        # No control has been issued before -- we assume not grasping\n        elif self._control is None:\n            is_grasping = IsGraspingState.FALSE\n\n        else:\n            assert np.all(\n                self._control == self._control[0]\n            ), f\"MultiFingerGripperController has different values in the command for non-independent mode: {self._control}\"\n\n            assert m.POS_TOLERANCE &gt; self._limit_tolerance, (\n                \"Joint position tolerance for is_grasping heuristics checking is smaller than or equal to the \"\n                \"gripper controller's tolerance of zero-ing out velocities, which makes the heuristics invalid.\"\n            )\n\n            finger_pos = control_dict[\"joint_position\"][self.dof_idx]\n\n            # For joint position control, if the desired positions are the same as the current positions, is_grasping unknown\n            if (\n                    self._motor_type == \"position\"\n                    and np.mean(np.abs(finger_pos - self._control)) &lt; m.POS_TOLERANCE\n            ):\n                is_grasping = IsGraspingState.UNKNOWN\n\n            # For joint velocity / torque control, if the desired velocities / torques are zeros, is_grasping unknown\n            elif (\n                    self._motor_type in {\"velocity\", \"torque\"}\n                    and np.mean(np.abs(self._control)) &lt; m.VEL_TOLERANCE\n            ):\n                is_grasping = IsGraspingState.UNKNOWN\n\n            # Otherwise, the last control signal intends to \"move\" the gripper\n            else:\n                finger_vel = control_dict[\"joint_velocity\"][self.dof_idx]\n                min_pos = self._control_limits[ControlType.POSITION][0][self.dof_idx]\n                max_pos = self._control_limits[ControlType.POSITION][1][self.dof_idx]\n\n                # Make sure we don't have any invalid values (i.e.: fingers should be within the limits)\n                assert np.all(\n                    (min_pos &lt;= finger_pos) * (finger_pos &lt;= max_pos)\n                ), f\"Got invalid finger joint positions when checking for grasp! \" \\\n                   f\"min: {min_pos}, max: {max_pos}, finger_pos: {finger_pos}\"\n\n                # Check distance from both ends of the joint limits\n                dist_from_lower_limit = finger_pos - min_pos\n                dist_from_upper_limit = max_pos - finger_pos\n\n                # If the joint positions are not near the joint limits with some tolerance (m.POS_TOLERANCE)\n                valid_grasp_pos = (\n                        np.mean(dist_from_lower_limit) &gt; m.POS_TOLERANCE\n                        and np.mean(dist_from_upper_limit) &gt; m.POS_TOLERANCE\n                )\n\n                # And the joint velocities are close to zero with some tolerance (m.VEL_TOLERANCE)\n                valid_grasp_vel = np.all(np.abs(finger_vel) &lt; m.VEL_TOLERANCE)\n\n                # Then the gripper is grasping something, which stops the gripper from reaching its desired state\n                is_grasping = (\n                    IsGraspingState.TRUE if valid_grasp_pos and valid_grasp_vel else IsGraspingState.FALSE\n                )\n\n        # Store calculated state\n        self._is_grasping = is_grasping\n\n    def is_grasping(self):\n        # Return cached value\n        return self._is_grasping\n\n    @property\n    def control_type(self):\n        return ControlType.get_type(type_str=self._motor_type)\n\n    @property\n    def command_dim(self):\n        return len(self.dof_idx) if self._mode == \"independent\" else 1\n</code></pre>","location":"reference/controllers/multi_finger_gripper_controller.html#controllers.multi_finger_gripper_controller.MultiFingerGripperController"},{"title":"<code>__init__(control_freq, motor_type, control_limits, dof_idx, command_input_limits='default', command_output_limits='default', inverted=False, mode='binary', limit_tolerance=0.001)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>control_freq</code>  <code>int</code>  <p>controller loop frequency</p>  required    <code>control_limits</code>  <code>Dict[str, Tuple[Array[float], Array[float]]]</code>  <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p>  required    <code>dof_idx</code>  <code>Array[int]</code>  <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p>  required    <code>command_input_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p>  <code>'default'</code>    <code>command_output_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p>  <code>'default'</code>    <code>inverted</code>  <code>bool</code>  <p>whether or not the command direction (grasp is negative) and the control direction are inverted, e.g. to grasp you need to move the joint in the positive direction.</p>  <code>False</code>    <code>mode</code>  <code>str</code>  <p>mode for this controller. Valid options are:</p> <p>\"binary\": 1D command, if preprocessed value &gt; 0 is interpreted as an max open     (send max pos / vel / tor signal), otherwise send max close control signals \"smooth\": 1D command, sends symmetric signal to both finger joints equal to the preprocessed commands \"independent\": 2D command, sends independent signals to each finger joint equal to the preprocessed command</p>  <code>'binary'</code>    <code>limit_tolerance</code>  <code>float</code>  <p>sets the tolerance from the joint limit ends, below which controls will be zeroed out if the control is using velocity or torque control</p>  <code>0.001</code>      Source code in <code>controllers/multi_finger_gripper_controller.py</code> <pre><code>def __init__(\n    self,\n    control_freq,\n    motor_type,\n    control_limits,\n    dof_idx,\n    command_input_limits=\"default\",\n    command_output_limits=\"default\",\n    inverted=False,\n    mode=\"binary\",\n    limit_tolerance=0.001,\n):\n    \"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        inverted (bool): whether or not the command direction (grasp is negative) and the control direction are\n            inverted, e.g. to grasp you need to move the joint in the positive direction.\n        mode (str): mode for this controller. Valid options are:\n\n            \"binary\": 1D command, if preprocessed value &gt; 0 is interpreted as an max open\n                (send max pos / vel / tor signal), otherwise send max close control signals\n            \"smooth\": 1D command, sends symmetric signal to both finger joints equal to the preprocessed commands\n            \"independent\": 2D command, sends independent signals to each finger joint equal to the preprocessed command\n\n        limit_tolerance (float): sets the tolerance from the joint limit ends, below which controls will be zeroed\n            out if the control is using velocity or torque control\n    \"\"\"\n    # Store arguments\n    assert_valid_key(key=motor_type.lower(), valid_keys=ControlType.VALID_TYPES_STR, name=\"motor_type\")\n    self._motor_type = motor_type.lower()\n    assert_valid_key(key=mode, valid_keys=VALID_MODES, name=\"mode for multi finger gripper\")\n    self._inverted = inverted\n    self._mode = mode\n    self._limit_tolerance = limit_tolerance\n\n    # Create other args to be filled in at runtime\n    self._is_grasping = IsGraspingState.FALSE\n\n    # If we're using binary signal, we override the command output limits\n    if mode == \"binary\":\n        command_output_limits = (-1.0, 1.0)\n\n    # Run super init\n    super().__init__(\n        control_freq=control_freq,\n        control_limits=control_limits,\n        dof_idx=dof_idx,\n        command_input_limits=command_input_limits,\n        command_output_limits=command_output_limits,\n    )\n</code></pre>","location":"reference/controllers/multi_finger_gripper_controller.html#controllers.multi_finger_gripper_controller.MultiFingerGripperController.__init__"},{"title":"null_joint_controller","text":"","location":"reference/controllers/null_joint_controller.html"},{"title":"<code>NullJointController</code>","text":"<p>         Bases: <code>JointController</code></p> <p>Dummy Controller class for a null-type of joint control (i.e.: no control or constant pass-through control). This class has a zero-size command space, and returns either an empty array for control if dof_idx is None else constant values as specified by @default_command (if not specified, uses zeros)</p>  Source code in <code>controllers/null_joint_controller.py</code> <pre><code>class NullJointController(JointController):\n    \"\"\"\n    Dummy Controller class for a null-type of joint control (i.e.: no control or constant pass-through control).\n    This class has a zero-size command space, and returns either an empty array for control if dof_idx is None\n    else constant values as specified by @default_command (if not specified, uses zeros)\n    \"\"\"\n\n    def __init__(\n        self,\n        control_freq,\n        motor_type,\n        control_limits,\n        dof_idx,\n        command_input_limits=\"default\",\n        command_output_limits=\"default\",\n        default_command=None,\n    ):\n        \"\"\"\n        Args:\n            control_freq (int): controller loop frequency\n            control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n                control signal. Should specify per-dof type limits, i.e.:\n\n                \"position\": [[min], [max]]\n                \"velocity\": [[min], [max]]\n                \"effort\": [[min], [max]]\n                \"has_limit\": [...bool...]\n\n                Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n            dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n                controller-relevant values during control computations\n            command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n                If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n            command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n                if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n                then all inputted command values will be scaled from the input range to the output range.\n                If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n                to the @control_limits entry corresponding to self.control_type\n            default_command (None or n-array): if specified, should be the same length as @dof_idx, specifying\n                the default control for this controller to output\n        \"\"\"\n        # Store values\n        self._default_command = np.zeros(len(dof_idx)) if default_command is None else np.array(default_command)\n\n        # Run super init\n        super().__init__(\n            control_freq=control_freq,\n            motor_type=motor_type,\n            control_limits=control_limits,\n            dof_idx=dof_idx,\n            command_input_limits=command_input_limits,\n            command_output_limits=command_output_limits,\n        )\n\n    def _preprocess_command(self, command):\n        # Set the command to be internal stored default value\n        return np.array(self._default_command)\n\n    def update_default_command(self, command):\n        \"\"\"\n        Updates the internal default command value.\n\n        Args:\n            command (n-array): New default command values to set for this controller.\n                Should be of dimension @command_dim\n        \"\"\"\n        assert len(command) == self.command_dim, \\\n            f\"Default control must be length: {self.command_dim}, got length: {len(command)}\"\n\n        self._default_command = np.array(command)\n</code></pre>","location":"reference/controllers/null_joint_controller.html#controllers.null_joint_controller.NullJointController"},{"title":"<code>__init__(control_freq, motor_type, control_limits, dof_idx, command_input_limits='default', command_output_limits='default', default_command=None)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>control_freq</code>  <code>int</code>  <p>controller loop frequency</p>  required    <code>control_limits</code>  <code>Dict[str, Tuple[Array[float], Array[float]]]</code>  <p>The min/max limits to the outputted control signal. Should specify per-dof type limits, i.e.:</p> <p>\"position\": [[min], [max]] \"velocity\": [[min], [max]] \"effort\": [[min], [max]] \"has_limit\": [...bool...]</p> <p>Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.</p>  required    <code>dof_idx</code>  <code>Array[int]</code>  <p>specific dof indices controlled by this robot. Used for inferring controller-relevant values during control computations</p>  required    <code>command_input_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max acceptable inputted command. Values outside this range will be clipped. If None, no clipping will be used. If \"default\", range will be set to (-1, 1)</p>  <code>'default'</code>    <code>command_output_limits</code>  <code>None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]</code>  <p>if set, is the min/max scaled command. If both this value and @command_input_limits is not None, then all inputted command values will be scaled from the input range to the output range. If either is None, no scaling will be used. If \"default\", then this range will automatically be set to the @control_limits entry corresponding to self.control_type</p>  <code>'default'</code>    <code>default_command</code>  <code>None or n-array</code>  <p>if specified, should be the same length as @dof_idx, specifying the default control for this controller to output</p>  <code>None</code>      Source code in <code>controllers/null_joint_controller.py</code> <pre><code>def __init__(\n    self,\n    control_freq,\n    motor_type,\n    control_limits,\n    dof_idx,\n    command_input_limits=\"default\",\n    command_output_limits=\"default\",\n    default_command=None,\n):\n    \"\"\"\n    Args:\n        control_freq (int): controller loop frequency\n        control_limits (Dict[str, Tuple[Array[float], Array[float]]]): The min/max limits to the outputted\n            control signal. Should specify per-dof type limits, i.e.:\n\n            \"position\": [[min], [max]]\n            \"velocity\": [[min], [max]]\n            \"effort\": [[min], [max]]\n            \"has_limit\": [...bool...]\n\n            Values outside of this range will be clipped, if the corresponding joint index in has_limit is True.\n        dof_idx (Array[int]): specific dof indices controlled by this robot. Used for inferring\n            controller-relevant values during control computations\n        command_input_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max acceptable inputted command. Values outside this range will be clipped.\n            If None, no clipping will be used. If \"default\", range will be set to (-1, 1)\n        command_output_limits (None or \"default\" or Tuple[float, float] or Tuple[Array[float], Array[float]]):\n            if set, is the min/max scaled command. If both this value and @command_input_limits is not None,\n            then all inputted command values will be scaled from the input range to the output range.\n            If either is None, no scaling will be used. If \"default\", then this range will automatically be set\n            to the @control_limits entry corresponding to self.control_type\n        default_command (None or n-array): if specified, should be the same length as @dof_idx, specifying\n            the default control for this controller to output\n    \"\"\"\n    # Store values\n    self._default_command = np.zeros(len(dof_idx)) if default_command is None else np.array(default_command)\n\n    # Run super init\n    super().__init__(\n        control_freq=control_freq,\n        motor_type=motor_type,\n        control_limits=control_limits,\n        dof_idx=dof_idx,\n        command_input_limits=command_input_limits,\n        command_output_limits=command_output_limits,\n    )\n</code></pre>","location":"reference/controllers/null_joint_controller.html#controllers.null_joint_controller.NullJointController.__init__"},{"title":"<code>update_default_command(command)</code>","text":"<p>Updates the internal default command value.</p> <p>Parameters:</p>    Name Type Description Default     <code>command</code>  <code>n-array</code>  <p>New default command values to set for this controller. Should be of dimension @command_dim</p>  required      Source code in <code>controllers/null_joint_controller.py</code> <pre><code>def update_default_command(self, command):\n    \"\"\"\n    Updates the internal default command value.\n\n    Args:\n        command (n-array): New default command values to set for this controller.\n            Should be of dimension @command_dim\n    \"\"\"\n    assert len(command) == self.command_dim, \\\n        f\"Default control must be length: {self.command_dim}, got length: {len(command)}\"\n\n    self._default_command = np.array(command)\n</code></pre>","location":"reference/controllers/null_joint_controller.html#controllers.null_joint_controller.NullJointController.update_default_command"},{"title":"envs","text":"","location":"reference/envs/index.html"},{"title":"env_base","text":"","location":"reference/envs/env_base.html"},{"title":"<code>Environment</code>","text":"<p>         Bases: <code>gym.Env</code>, <code>GymObservable</code>, <code>Recreatable</code></p> <p>Core environment class that handles loading scene, robot(s), and task, following OpenAI Gym interface.</p>  Source code in <code>envs/env_base.py</code> <pre><code>class Environment(gym.Env, GymObservable, Recreatable):\n    \"\"\"\n    Core environment class that handles loading scene, robot(s), and task, following OpenAI Gym interface.\n    \"\"\"\n    def __init__(\n        self,\n        configs,\n        action_timestep=1 / 60.0,\n        physics_timestep=1 / 60.0,\n        device=None,\n        automatic_reset=False,\n    ):\n        \"\"\"\n        Args:\n            configs (str or dict or list of str or dict): config_file path(s) or raw config dictionaries.\n                If multiple configs are specified, they will be merged sequentially in the order specified.\n                This allows procedural generation of a \"full\" config from small sub-configs.\n            action_timestep (float): environment executes action per action_timestep second\n            physics_timestep: physics timestep for physx\n            device (None or str): specifies the device to be used if running on the gpu with torch backend\n            automatic_reset (bool): whether to automatic reset after an episode finishes\n        \"\"\"\n        # Call super first\n        super().__init__()\n\n        # Store settings and other initialized values\n        self._automatic_reset = automatic_reset\n        self.action_timestep = action_timestep\n\n        # Initialize other placeholders that will be filled in later\n        self._initial_pos_z_offset = None                   # how high to offset object placement to account for one action step of dropping\n        self._task = None\n        self._loaded = None\n        self._current_episode = 0\n\n        # Variables reset at the beginning of each episode\n        self._current_step = 0\n\n        # Convert config file(s) into a single parsed dict\n        configs = configs if isinstance(configs, list) or isinstance(configs, tuple) else [configs]\n\n        # Initial default config\n        self.config = self.default_config\n\n        # Merge in specified configs\n        for config in configs:\n            merge_nested_dicts(base_dict=self.config, extra_dict=parse_config(config), inplace=True)\n\n        # Set the simulator settings\n        og.sim.set_simulation_dt(physics_dt=physics_timestep, rendering_dt=action_timestep)\n        og.sim.viewer_width = self.render_config[\"viewer_width\"]\n        og.sim.viewer_height = self.render_config[\"viewer_height\"]\n        og.sim.device = device\n\n        # Load this environment\n        self.load()\n\n    def reload(self, configs, overwrite_old=True):\n        \"\"\"\n        Reload using another set of config file(s).\n        This allows one to change the configuration and hot-reload the environment on the fly.\n\n        Args:\n            configs (str or list of str): config_file path(s). If multiple configs are specified, they will\n                be merged sequentially in the order specified. This allows procedural generation of a \"full\" config from\n                small sub-configs.\n            overwrite_old (bool): If True, will overwrite the internal self.config with @configs. Otherwise, will\n                merge in the new config(s) into the pre-existing one. Setting this to False allows for minor\n                modifications to be made without having to specify entire configs during each reload.\n        \"\"\"\n        # Convert config file(s) into a single parsed dict\n        configs = [configs] if isinstance(configs, str) else configs\n\n        # Initial default config\n        new_config = self.default_config\n\n        # Merge in specified configs\n        for config in configs:\n            merge_nested_dicts(base_dict=new_config, extra_dict=parse_config(config), inplace=True)\n\n        # Either merge in or overwrite the old config\n        if overwrite_old:\n            self.config = new_config\n        else:\n            merge_nested_dicts(base_dict=self.config, extra_dict=new_config, inplace=True)\n\n        # Load this environment again\n        self.load()\n\n    def reload_model(self, scene_model):\n        \"\"\"\n        Reload another scene model.\n        This allows one to change the scene on the fly.\n\n        Args:\n            scene_model (str): new scene model to load (eg.: Rs_int)\n        \"\"\"\n        self.scene_config[\"model\"] = scene_model\n        self.load()\n\n    def _load_variables(self):\n        \"\"\"\n        Load variables from config\n        \"\"\"\n        # Store additional variables after config has been loaded fully\n        self._initial_pos_z_offset = self.env_config[\"initial_pos_z_offset\"]\n\n        # Reset bookkeeping variables\n        self._reset_variables()\n        self._current_episode = 0           # Manually set this to 0 since resetting actually increments this\n\n        # - Potentially overwrite the USD entry for the scene if none is specified and we're online sampling -\n\n        # Make sure the requested scene is valid\n        scene_type = self.scene_config[\"type\"]\n        assert_valid_key(key=scene_type, valid_keys=REGISTERED_SCENES, name=\"scene type\")\n\n        # If we're using a BehaviorTask, we may load a pre-cached scene configuration\n        if self.task_config[\"type\"] == \"BehaviorTask\":\n            scene_instance, scene_file = self.scene_config[\"scene_instance\"], self.scene_config[\"scene_file\"]\n            if scene_file is None and scene_instance is None and not self.task_config[\"online_object_sampling\"]:\n                scene_instance = \"{}_task_{}_{}_{}_fixed_furniture_template\".format(\n                    self.scene_config[\"scene_model\"],\n                    self.task_config[\"activity_name\"],\n                    self.task_config[\"activity_definition_id\"],\n                    self.task_config[\"activity_instance_id\"],\n                )\n            # Update the value in the scene config\n            self.scene_config[\"scene_instance\"] = scene_instance\n\n        # - Additionally run some sanity checks on these values -\n\n        # Check to make sure our z offset is valid -- check that the distance travelled over 1 action timestep is\n        # less than the offset we set (dist = 0.5 * gravity * (t^2))\n        drop_distance = 0.5 * 9.8 * (self.action_timestep ** 2)\n        assert drop_distance &lt; self._initial_pos_z_offset, \"initial_pos_z_offset is too small for collision checking\"\n\n    def _load_task(self):\n        \"\"\"\n        Load task\n        \"\"\"\n        # Sanity check task to make sure it's valid\n        task_type = self.task_config[\"type\"]\n        assert_valid_key(key=task_type, valid_keys=REGISTERED_TASKS, name=\"task type\")\n\n        # Grab the kwargs relevant for the specific task and create the task\n        self._task = create_class_from_registry_and_config(\n            cls_name=self.task_config[\"type\"],\n            cls_registry=REGISTERED_TASKS,\n            cfg=self.task_config,\n            cls_type_descriptor=\"task\",\n        )\n\n        assert og.sim.is_stopped(), \"sim should be stopped when load_task starts\"\n        og.sim.play()\n\n        # Load task. Should load additinal task-relevant objects and configure the scene into its default initial state\n        self._task.load(env=self)\n\n        # Update the initial scene state\n        self.scene.update_initial_state()\n\n        og.sim.stop()\n\n    def _load_scene(self):\n        \"\"\"\n        Load the scene and robot specified in the config file.\n        \"\"\"\n        # Create the scene from our scene config\n        scene = create_class_from_registry_and_config(\n            cls_name=self.scene_config[\"type\"],\n            cls_registry=REGISTERED_SCENES,\n            cfg=self.scene_config,\n            cls_type_descriptor=\"scene\",\n        )\n        og.sim.import_scene(scene)\n\n    def _load_robots(self):\n        \"\"\"\n        Load robots into the scene\n        \"\"\"\n        # Only actually load robots if no robot has been imported from the scene loading directly yet\n        if len(self.scene.robots) == 0:\n            # Iterate over all robots to generate in the robot config\n            for i, robot_config in enumerate(self.robots_config):\n                # Add a name for the robot if necessary\n                if \"name\" not in robot_config:\n                    robot_config[\"name\"] = f\"robot{i}\"\n                # Set prim path\n                robot_config[\"prim_path\"] = f\"/World/{robot_config['name']}\"\n                # Make sure robot exists, grab its corresponding kwargs, and create / import the robot\n                robot = create_class_from_registry_and_config(\n                    cls_name=robot_config[\"type\"],\n                    cls_registry=REGISTERED_ROBOTS,\n                    cfg=robot_config,\n                    cls_type_descriptor=\"robot\",\n                )\n                # Import the robot into the simulator\n                og.sim.import_object(robot)\n\n    def _load_objects(self):\n        \"\"\"\n        Load any additional custom objects into the scene\n        \"\"\"\n        for i, obj_config in enumerate(self.objects_config):\n            # Add a name for the object if necessary\n            if \"name\" not in obj_config:\n                obj_config[\"name\"] = f\"obj{i}\"\n            # Set prim path if not specified\n            if \"prim_path\" not in obj_config:\n                obj_config[\"prim_path\"] = f\"/World/{obj_config['name']}\"\n            # Pop the desired position and orientation\n            position, orientation = obj_config.pop(\"position\", None), obj_config.pop(\"orientation\", None)\n            # Make sure robot exists, grab its corresponding kwargs, and create / import the robot\n            obj = create_class_from_registry_and_config(\n                cls_name=obj_config[\"type\"],\n                cls_registry=REGISTERED_OBJECTS,\n                cfg=obj_config,\n                cls_type_descriptor=\"object\",\n            )\n            # Import the robot into the simulator and set the pose\n            og.sim.import_object(obj)\n            obj.set_position_orientation(position=position, orientation=orientation)\n\n    def _load_observation_space(self):\n        # Grab robot(s) and task obs spaces\n        obs_space = OrderedDict()\n\n        for robot in self.robots:\n            # Load the observation space for the robot\n            obs_space[robot.name] = robot.load_observation_space()\n\n        # Also load the task obs space\n        obs_space[\"task\"] = self._task.load_observation_space()\n        return obs_space\n\n    def _load_action_space(self):\n        \"\"\"\n        Load action space for each robot\n        \"\"\"\n        self.action_space = gym.spaces.Dict({robot.name: robot.action_space for robot in self.robots})\n\n    def load(self):\n        \"\"\"\n        Load the scene and robot specified in the config file.\n        \"\"\"\n        # This environment is not loaded\n        self._loaded = False\n\n        # Load config variables\n        self._load_variables()\n\n        # Load the scene, robots, and task\n        self._load_scene()\n        self._load_robots()\n        self._load_objects()\n        self._load_task()\n\n        og.sim.play()\n        self.reset()\n\n        # Load the obs / action spaces\n        self.load_observation_space()\n        self._load_action_space()\n\n        # Denote that the scene is loaded\n        self._loaded = True\n\n    def close(self):\n        \"\"\"\n        Clean up the environment and shut down the simulation.\n        \"\"\"\n        og.sim.close()\n\n    def get_obs(self):\n        \"\"\"\n        Get the current environment observation.\n\n        Returns:\n            OrderedDict: Keyword-mapped observations, which are possibly nested\n        \"\"\"\n        obs = OrderedDict()\n\n        # Grab all observations from each robot\n        for robot in self.robots:\n            obs[robot.name] = robot.get_obs()\n\n        # Add task observations\n        obs[\"task\"] = self._task.get_obs(env=self)\n\n        return obs\n\n    def _populate_info(self, info):\n        \"\"\"\n        Populate info dictionary with any useful information.\n\n        Args:\n            info (dict): Information dictionary to populate\n\n        Returns:\n            dict: Information dictionary with added info\n        \"\"\"\n        info[\"episode_length\"] = self._current_step\n\n    def step(self, action):\n        \"\"\"\n        Apply robot's action and return the next state, reward, done and info,\n        following OpenAI Gym's convention\n\n        Args:\n            action (gym.spaces.Dict or dict or np.array): robot actions. If a dict is specified, each entry should\n                map robot name to corresponding action. If a np.array, it should be the flattened, concatenated set\n                of actions\n\n        Returns:\n            4-tuple:\n                - OrderedDict: state, i.e. next observation\n                - float: reward, i.e. reward at this current timestep\n                - bool: done, i.e. whether this episode is terminated\n                - OrderedDict: info, i.e. dictionary with any useful information\n        \"\"\"\n        # If the action is not a dictionary, convert into a dictionary\n        if not isinstance(action, dict) and not isinstance(action, gym.spaces.Dict):\n            action_dict = OrderedDict()\n            idx = 0\n            for robot in self.robots:\n                action_dim = robot.action_dim\n                action_dict[robot.name] = action[idx: idx + action_dim]\n                idx += action_dim\n        else:\n            # Our inputted action is the action dictionary\n            action_dict = action\n\n        # Iterate over all robots and apply actions\n        for robot in self.robots:\n            robot.apply_action(action_dict[robot.name])\n\n        # Run simulation step\n        og.sim.step()\n\n        # Grab observations\n        obs = self.get_obs()\n\n        # Grab reward, done, and info, and populate with internal info\n        reward, done, info = self.task.step(self, action)\n        self._populate_info(info)\n\n        if done and self._automatic_reset:\n            # Add lost observation to our information dict, and reset\n            info[\"last_observation\"] = obs\n            obs = self.reset()\n\n        # Increment step\n        self._current_step += 1\n\n        return obs, reward, done, info\n\n    def _reset_variables(self):\n        \"\"\"\n        Reset bookkeeping variables for the next new episode.\n        \"\"\"\n        self._current_episode += 1\n        self._current_step = 0\n\n    # TODO: Match super class signature?\n    def reset(self):\n        \"\"\"\n        Reset episode.\n        \"\"\"\n        # Stop and restart the simulation\n        og.sim.stop()\n        og.sim.play()\n\n        # Reset the task\n        self.task.reset(self)\n\n        # Reset internal variables\n        self._reset_variables()\n\n        # Run a single simulator step to make sure we can grab updated observations\n        og.sim.step()\n\n        # Grab and return observations\n        obs = self.get_obs()\n\n        if self.observation_space is not None and not self.observation_space.contains(obs):\n            # Print out all observations for all robots and task\n            for robot in self.robots:\n                for key, value in self.observation_space[robot.name].items():\n                    logging.error((\"obs_space\", key, value.dtype, value.shape))\n                    logging.error((\"obs\", key, obs[robot.name][key].dtype, obs[robot.name][key].shape))\n            for key, value in self.observation_space[\"task\"].items():\n                logging.error((\"obs_space\", key, value.dtype, value.shape))\n                logging.error((\"obs\", key, obs[\"task\"][key].dtype, obs[\"task\"][key].shape))\n            raise ValueError(\"Observation space does not match returned observations!\")\n\n        return obs\n\n    @property\n    def episode_steps(self):\n        \"\"\"\n        Returns:\n            int: Current number of steps in episode\n        \"\"\"\n        return self._current_step\n\n    @property\n    def initial_pos_z_offset(self):\n        \"\"\"\n        Returns:\n            float: how high to offset object placement to test valid pose &amp; account for one action step of dropping\n        \"\"\"\n        return self._initial_pos_z_offset\n\n    @property\n    def task(self):\n        \"\"\"\n        Returns:\n            BaseTask: Active task instance\n        \"\"\"\n        return self._task\n\n    @property\n    def scene(self):\n        \"\"\"\n        Returns:\n            Scene: Active scene in this environment\n        \"\"\"\n        return og.sim.scene\n\n    @property\n    def robots(self):\n        \"\"\"\n        Returns:\n            list of BaseRobot: Robots in the current scene\n        \"\"\"\n        return self.scene.robots\n\n    @property\n    def env_config(self):\n        \"\"\"\n        Returns:\n            dict: Environment-specific configuration kwargs\n        \"\"\"\n        return self.config[\"env\"]\n\n    @property\n    def render_config(self):\n        \"\"\"\n        Returns:\n            dict: Render-specific configuration kwargs\n        \"\"\"\n        return self.config[\"render\"]\n\n    @property\n    def scene_config(self):\n        \"\"\"\n        Returns:\n            dict: Scene-specific configuration kwargs\n        \"\"\"\n        return self.config[\"scene\"]\n\n    @property\n    def robots_config(self):\n        \"\"\"\n        Returns:\n            dict: Robot-specific configuration kwargs\n        \"\"\"\n        return self.config[\"robots\"]\n\n    @property\n    def objects_config(self):\n        \"\"\"\n        Returns:\n            dict: Object-specific configuration kwargs\n        \"\"\"\n        return self.config[\"objects\"]\n\n    @property\n    def task_config(self):\n        \"\"\"\n        Returns:\n            dict: Task-specific configuration kwargs\n        \"\"\"\n        return self.config[\"task\"]\n\n    @property\n    def default_config(self):\n        \"\"\"\n        Returns:\n            dict: Default configuration for this environment. May not be fully specified (i.e.: still requires @config\n                to be specified during environment creation)\n        \"\"\"\n        return {\n            # Environment kwargs\n            \"env\": {\n                \"initial_pos_z_offset\": 0.1,\n            },\n\n            # Rendering kwargs\n            \"render\": {\n                \"viewer_width\": 1280,\n                \"viewer_height\": 720,\n            },\n\n            # Scene kwargs\n            \"scene\": {\n                # Traversibility map kwargs\n                \"waypoint_resolution\": 0.2,\n                \"num_waypoints\": 10,\n                \"build_graph\": False,\n                \"trav_map_resolution\": 0.1,\n                \"trav_map_erosion\": 2,\n                \"trav_map_with_objects\": True,\n                \"scene_instance\": None,\n                \"scene_file\": None,\n            },\n\n            # Robot kwargs\n            \"robots\": [],   # no robots by default\n\n            # Object kwargs\n            \"objects\": [],  # no objects by default\n\n            # Task kwargs\n            \"task\": {\n                \"type\": \"DummyTask\",\n\n                # If we're using a BehaviorTask\n                \"activity_definition_id\": 0,\n                \"activity_instance_id\": 0,\n            }\n        }\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment"},{"title":"<code>default_config</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Default configuration for this environment. May not be fully specified (i.e.: still requires @config to be specified during environment creation)</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.default_config"},{"title":"<code>env_config</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Environment-specific configuration kwargs</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.env_config"},{"title":"<code>episode_steps</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Current number of steps in episode</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.episode_steps"},{"title":"<code>initial_pos_z_offset</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>how high to offset object placement to test valid pose &amp; account for one action step of dropping</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.initial_pos_z_offset"},{"title":"<code>objects_config</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Object-specific configuration kwargs</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.objects_config"},{"title":"<code>render_config</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Render-specific configuration kwargs</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.render_config"},{"title":"<code>robots</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>list of BaseRobot: Robots in the current scene</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.robots"},{"title":"<code>robots_config</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Robot-specific configuration kwargs</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.robots_config"},{"title":"<code>scene</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>Scene</code>   <p>Active scene in this environment</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.scene"},{"title":"<code>scene_config</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Scene-specific configuration kwargs</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.scene_config"},{"title":"<code>task</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>BaseTask</code>   <p>Active task instance</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.task"},{"title":"<code>task_config</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Task-specific configuration kwargs</p>","location":"reference/envs/env_base.html#envs.env_base.Environment.task_config"},{"title":"<code>__init__(configs, action_timestep=1 / 60.0, physics_timestep=1 / 60.0, device=None, automatic_reset=False)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>configs</code>  <code>str or dict or list of str or dict</code>  <p>config_file path(s) or raw config dictionaries. If multiple configs are specified, they will be merged sequentially in the order specified. This allows procedural generation of a \"full\" config from small sub-configs.</p>  required    <code>action_timestep</code>  <code>float</code>  <p>environment executes action per action_timestep second</p>  <code>1 / 60.0</code>    <code>physics_timestep</code>   <p>physics timestep for physx</p>  <code>1 / 60.0</code>    <code>device</code>  <code>None or str</code>  <p>specifies the device to be used if running on the gpu with torch backend</p>  <code>None</code>    <code>automatic_reset</code>  <code>bool</code>  <p>whether to automatic reset after an episode finishes</p>  <code>False</code>      Source code in <code>envs/env_base.py</code> <pre><code>def __init__(\n    self,\n    configs,\n    action_timestep=1 / 60.0,\n    physics_timestep=1 / 60.0,\n    device=None,\n    automatic_reset=False,\n):\n    \"\"\"\n    Args:\n        configs (str or dict or list of str or dict): config_file path(s) or raw config dictionaries.\n            If multiple configs are specified, they will be merged sequentially in the order specified.\n            This allows procedural generation of a \"full\" config from small sub-configs.\n        action_timestep (float): environment executes action per action_timestep second\n        physics_timestep: physics timestep for physx\n        device (None or str): specifies the device to be used if running on the gpu with torch backend\n        automatic_reset (bool): whether to automatic reset after an episode finishes\n    \"\"\"\n    # Call super first\n    super().__init__()\n\n    # Store settings and other initialized values\n    self._automatic_reset = automatic_reset\n    self.action_timestep = action_timestep\n\n    # Initialize other placeholders that will be filled in later\n    self._initial_pos_z_offset = None                   # how high to offset object placement to account for one action step of dropping\n    self._task = None\n    self._loaded = None\n    self._current_episode = 0\n\n    # Variables reset at the beginning of each episode\n    self._current_step = 0\n\n    # Convert config file(s) into a single parsed dict\n    configs = configs if isinstance(configs, list) or isinstance(configs, tuple) else [configs]\n\n    # Initial default config\n    self.config = self.default_config\n\n    # Merge in specified configs\n    for config in configs:\n        merge_nested_dicts(base_dict=self.config, extra_dict=parse_config(config), inplace=True)\n\n    # Set the simulator settings\n    og.sim.set_simulation_dt(physics_dt=physics_timestep, rendering_dt=action_timestep)\n    og.sim.viewer_width = self.render_config[\"viewer_width\"]\n    og.sim.viewer_height = self.render_config[\"viewer_height\"]\n    og.sim.device = device\n\n    # Load this environment\n    self.load()\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.__init__"},{"title":"<code>close()</code>","text":"<p>Clean up the environment and shut down the simulation.</p>  Source code in <code>envs/env_base.py</code> <pre><code>def close(self):\n    \"\"\"\n    Clean up the environment and shut down the simulation.\n    \"\"\"\n    og.sim.close()\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.close"},{"title":"<code>get_obs()</code>","text":"<p>Get the current environment observation.</p> <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Keyword-mapped observations, which are possibly nested</p>     Source code in <code>envs/env_base.py</code> <pre><code>def get_obs(self):\n    \"\"\"\n    Get the current environment observation.\n\n    Returns:\n        OrderedDict: Keyword-mapped observations, which are possibly nested\n    \"\"\"\n    obs = OrderedDict()\n\n    # Grab all observations from each robot\n    for robot in self.robots:\n        obs[robot.name] = robot.get_obs()\n\n    # Add task observations\n    obs[\"task\"] = self._task.get_obs(env=self)\n\n    return obs\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.get_obs"},{"title":"<code>load()</code>","text":"<p>Load the scene and robot specified in the config file.</p>  Source code in <code>envs/env_base.py</code> <pre><code>def load(self):\n    \"\"\"\n    Load the scene and robot specified in the config file.\n    \"\"\"\n    # This environment is not loaded\n    self._loaded = False\n\n    # Load config variables\n    self._load_variables()\n\n    # Load the scene, robots, and task\n    self._load_scene()\n    self._load_robots()\n    self._load_objects()\n    self._load_task()\n\n    og.sim.play()\n    self.reset()\n\n    # Load the obs / action spaces\n    self.load_observation_space()\n    self._load_action_space()\n\n    # Denote that the scene is loaded\n    self._loaded = True\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.load"},{"title":"<code>reload(configs, overwrite_old=True)</code>","text":"<p>Reload using another set of config file(s). This allows one to change the configuration and hot-reload the environment on the fly.</p> <p>Parameters:</p>    Name Type Description Default     <code>configs</code>  <code>str or list of str</code>  <p>config_file path(s). If multiple configs are specified, they will be merged sequentially in the order specified. This allows procedural generation of a \"full\" config from small sub-configs.</p>  required    <code>overwrite_old</code>  <code>bool</code>  <p>If True, will overwrite the internal self.config with @configs. Otherwise, will merge in the new config(s) into the pre-existing one. Setting this to False allows for minor modifications to be made without having to specify entire configs during each reload.</p>  <code>True</code>      Source code in <code>envs/env_base.py</code> <pre><code>def reload(self, configs, overwrite_old=True):\n    \"\"\"\n    Reload using another set of config file(s).\n    This allows one to change the configuration and hot-reload the environment on the fly.\n\n    Args:\n        configs (str or list of str): config_file path(s). If multiple configs are specified, they will\n            be merged sequentially in the order specified. This allows procedural generation of a \"full\" config from\n            small sub-configs.\n        overwrite_old (bool): If True, will overwrite the internal self.config with @configs. Otherwise, will\n            merge in the new config(s) into the pre-existing one. Setting this to False allows for minor\n            modifications to be made without having to specify entire configs during each reload.\n    \"\"\"\n    # Convert config file(s) into a single parsed dict\n    configs = [configs] if isinstance(configs, str) else configs\n\n    # Initial default config\n    new_config = self.default_config\n\n    # Merge in specified configs\n    for config in configs:\n        merge_nested_dicts(base_dict=new_config, extra_dict=parse_config(config), inplace=True)\n\n    # Either merge in or overwrite the old config\n    if overwrite_old:\n        self.config = new_config\n    else:\n        merge_nested_dicts(base_dict=self.config, extra_dict=new_config, inplace=True)\n\n    # Load this environment again\n    self.load()\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.reload"},{"title":"<code>reload_model(scene_model)</code>","text":"<p>Reload another scene model. This allows one to change the scene on the fly.</p> <p>Parameters:</p>    Name Type Description Default     <code>scene_model</code>  <code>str</code>  <p>new scene model to load (eg.: Rs_int)</p>  required      Source code in <code>envs/env_base.py</code> <pre><code>def reload_model(self, scene_model):\n    \"\"\"\n    Reload another scene model.\n    This allows one to change the scene on the fly.\n\n    Args:\n        scene_model (str): new scene model to load (eg.: Rs_int)\n    \"\"\"\n    self.scene_config[\"model\"] = scene_model\n    self.load()\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.reload_model"},{"title":"<code>reset()</code>","text":"<p>Reset episode.</p>  Source code in <code>envs/env_base.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Reset episode.\n    \"\"\"\n    # Stop and restart the simulation\n    og.sim.stop()\n    og.sim.play()\n\n    # Reset the task\n    self.task.reset(self)\n\n    # Reset internal variables\n    self._reset_variables()\n\n    # Run a single simulator step to make sure we can grab updated observations\n    og.sim.step()\n\n    # Grab and return observations\n    obs = self.get_obs()\n\n    if self.observation_space is not None and not self.observation_space.contains(obs):\n        # Print out all observations for all robots and task\n        for robot in self.robots:\n            for key, value in self.observation_space[robot.name].items():\n                logging.error((\"obs_space\", key, value.dtype, value.shape))\n                logging.error((\"obs\", key, obs[robot.name][key].dtype, obs[robot.name][key].shape))\n        for key, value in self.observation_space[\"task\"].items():\n            logging.error((\"obs_space\", key, value.dtype, value.shape))\n            logging.error((\"obs\", key, obs[\"task\"][key].dtype, obs[\"task\"][key].shape))\n        raise ValueError(\"Observation space does not match returned observations!\")\n\n    return obs\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.reset"},{"title":"<code>step(action)</code>","text":"<p>Apply robot's action and return the next state, reward, done and info, following OpenAI Gym's convention</p> <p>Parameters:</p>    Name Type Description Default     <code>action</code>  <code>gym.spaces.Dict or dict or np.array</code>  <p>robot actions. If a dict is specified, each entry should map robot name to corresponding action. If a np.array, it should be the flattened, concatenated set of actions</p>  required     <p>Returns:</p>    Type Description       <p>4-tuple: - OrderedDict: state, i.e. next observation - float: reward, i.e. reward at this current timestep - bool: done, i.e. whether this episode is terminated - OrderedDict: info, i.e. dictionary with any useful information</p>     Source code in <code>envs/env_base.py</code> <pre><code>def step(self, action):\n    \"\"\"\n    Apply robot's action and return the next state, reward, done and info,\n    following OpenAI Gym's convention\n\n    Args:\n        action (gym.spaces.Dict or dict or np.array): robot actions. If a dict is specified, each entry should\n            map robot name to corresponding action. If a np.array, it should be the flattened, concatenated set\n            of actions\n\n    Returns:\n        4-tuple:\n            - OrderedDict: state, i.e. next observation\n            - float: reward, i.e. reward at this current timestep\n            - bool: done, i.e. whether this episode is terminated\n            - OrderedDict: info, i.e. dictionary with any useful information\n    \"\"\"\n    # If the action is not a dictionary, convert into a dictionary\n    if not isinstance(action, dict) and not isinstance(action, gym.spaces.Dict):\n        action_dict = OrderedDict()\n        idx = 0\n        for robot in self.robots:\n            action_dim = robot.action_dim\n            action_dict[robot.name] = action[idx: idx + action_dim]\n            idx += action_dim\n    else:\n        # Our inputted action is the action dictionary\n        action_dict = action\n\n    # Iterate over all robots and apply actions\n    for robot in self.robots:\n        robot.apply_action(action_dict[robot.name])\n\n    # Run simulation step\n    og.sim.step()\n\n    # Grab observations\n    obs = self.get_obs()\n\n    # Grab reward, done, and info, and populate with internal info\n    reward, done, info = self.task.step(self, action)\n    self._populate_info(info)\n\n    if done and self._automatic_reset:\n        # Add lost observation to our information dict, and reset\n        info[\"last_observation\"] = obs\n        obs = self.reset()\n\n    # Increment step\n    self._current_step += 1\n\n    return obs, reward, done, info\n</code></pre>","location":"reference/envs/env_base.html#envs.env_base.Environment.step"},{"title":"examples","text":"","location":"reference/examples/index.html"},{"title":"blender_demo_transition_machine","text":"","location":"reference/examples/blender_demo_transition_machine.html"},{"title":"<code>CameraMover</code>","text":"Source code in <code>examples/blender_demo_transition_machine.py</code> <pre><code>class CameraMover:\n    def __init__(self, cam, delta=0.25):\n        self.cam = cam\n        self.delta = delta\n\n        self._appwindow = omni.appwindow.get_default_app_window()\n        self._input = carb.input.acquire_input_interface()\n        self._keyboard = self._appwindow.get_keyboard()\n        self._sub_keyboard = self._input.subscribe_to_keyboard_events(self._keyboard, self._sub_keyboard_event)\n\n    def print_cam_pose(self):\n        print(f\"cam pose: {self.cam.get_position_orientation()}\")\n\n    @property\n    def input_to_function(self):\n        return {\n            carb.input.KeyboardInput.SPACE: lambda: take_photo(use_rt=True),\n            carb.input.KeyboardInput.KEY_1: lambda: take_photo(use_rt=True),\n            carb.input.KeyboardInput.KEY_2: lambda: take_photo(use_rt=False),\n            carb.input.KeyboardInput.P: lambda: self.print_cam_pose(),\n        }\n\n    @property\n    def input_to_command(self):\n        return {\n            carb.input.KeyboardInput.D: np.array([self.delta, 0, 0]),\n            carb.input.KeyboardInput.A: np.array([-self.delta, 0, 0]),\n            carb.input.KeyboardInput.W: np.array([0, 0, -self.delta]),\n            carb.input.KeyboardInput.S: np.array([0, 0, self.delta]),\n            carb.input.KeyboardInput.T: np.array([0, self.delta, 0]),\n            carb.input.KeyboardInput.G: np.array([0, -self.delta, 0]),\n        }\n\n    def _sub_keyboard_event(self, event, *args, **kwargs):\n        \"\"\"Handle keyboard events\n        Args:\n            event (int): keyboard event type\n        \"\"\"\n        if event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\n\n            if event.type == carb.input.KeyboardEventType.KEY_PRESS and event.input in self.input_to_function:\n                self.input_to_function[event.input]()\n\n            else:\n                command = self.input_to_command.get(event.input, None)\n\n                if command is not None:\n                    # Convert to world frame to move the camera\n                    transform = T.quat2mat(self.cam.get_orientation())\n                    delta_pos_global = transform @ command\n                    self.cam.set_position(self.cam.get_position() + delta_pos_global)\n\n        return True\n</code></pre>","location":"reference/examples/blender_demo_transition_machine.html#examples.blender_demo_transition_machine.CameraMover"},{"title":"<code>euler2quat(euler, seq='xyz')</code>","text":"<p>Converts euler angles into quaternion form</p> <p>Parameters:</p>    Name Type Description Default     <code>euler</code>  <code>np.array</code>  <p>(r,p,y) angles</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) float quaternion angles</p>    <p>Raises:</p>    Type Description      <code>AssertionError</code>  <p>[Invalid input shape]</p>     Source code in <code>examples/blender_demo_transition_machine.py</code> <pre><code>def euler2quat(euler, seq=\"xyz\"):\n    \"\"\"\n    Converts euler angles into quaternion form\n\n    Args:\n        euler (np.array): (r,p,y) angles\n\n    Returns:\n        np.array: (x,y,z,w) float quaternion angles\n\n    Raises:\n        AssertionError: [Invalid input shape]\n    \"\"\"\n    return R.from_euler(seq, euler).as_quat()\n</code></pre>","location":"reference/examples/blender_demo_transition_machine.html#examples.blender_demo_transition_machine.euler2quat"},{"title":"environments","text":"","location":"reference/examples/environments/index.html"},{"title":"behavior_env_demo","text":"","location":"reference/examples/environments/behavior_env_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Generates a BEHAVIOR Task environment from a pre-defined configuration file.</p> <p>It steps the environment 100 times with random actions sampled from the action space, using the Gym interface, resetting it 10 times.</p>  Source code in <code>examples/environments/behavior_env_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Generates a BEHAVIOR Task environment from a pre-defined configuration file.\n\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Ask the user whether they want online object sampling or not\n    sampling_options = {\n        False: \"Use a pre-sampled cached BEHAVIOR activity scene\",\n        True: \"Sample the BEHAVIOR activity in an online fashion\",\n    }\n    should_sample = choose_from_options(options=sampling_options, name=\"online object sampling\", random_selection=random_selection)\n\n    # Load the pre-selected configuration and set the online_sampling flag\n    config_filename = os.path.join(og.example_config_path, \"fetch_behavior.yaml\")\n    cfg = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n    cfg[\"task\"][\"online_object_sampling\"] = should_sample\n\n    # If we're online sampling, make sure global contacts are enabled so we can accurately detect kinematic changes\n    if should_sample:\n        gm.ENABLE_GLOBAL_CONTACT_REPORTING = True\n\n    # Load the environment\n    env = og.Environment(configs=cfg)\n\n    # Allow user to move camera more easily\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Run a simple loop and reset periodically\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/environments/behavior_env_demo.html#examples.environments.behavior_env_demo.main"},{"title":"config_selector","text":"","location":"reference/examples/environments/config_selector.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select any available interactive scene and loads a turtlebot into it. It steps the environment 100 times with random actions sampled from the action space, using the Gym interface, resetting it 10 times.</p>  Source code in <code>examples/environments/config_selector.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select any available interactive scene and loads a turtlebot into it.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Grab all configs and choose one to load\n    og_config_path = og.example_config_path\n    available_configs = sorted(\n        [\n            f\n            for f in os.listdir(og_config_path)\n            if (not folder_is_hidden(f) and os.path.isfile(os.path.join(og_config_path, f)))\n        ]\n    )\n    config_id = choose_from_options(options=available_configs, name=\"config file\", random_selection=random_selection)\n    logging.info(\"Using config file \" + config_id)\n    config_filename = os.path.join(og.example_config_path, config_id)\n    config = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n\n    load_options = {\n        \"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n        \"Full\": \"Load all interactive objects in the scene\",\n    }\n    load_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\n    if load_mode == \"Quick\":\n        config[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n\n    # Load the environment\n    env = og.Environment(configs=config)\n\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            for robot_name in action.keys():\n                action[robot_name] = action[robot_name] * 0.05\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/environments/config_selector.html#examples.environments.config_selector.main"},{"title":"navigation_env_demo","text":"","location":"reference/examples/environments/navigation_env_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select a type of scene and loads a turtlebot into it, generating a Point-Goal navigation task within the environment.</p> <p>It steps the environment 100 times with random actions sampled from the action space, using the Gym interface, resetting it 10 times.</p>  Source code in <code>examples/environments/navigation_env_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select a type of scene and loads a turtlebot into it, generating a Point-Goal navigation\n    task within the environment.\n\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Infer which config to load based on the scene selected\n    scene_options = {\n        \"InteractiveTraversableScene\": \"Rs_int scene with fully interactive objects\",\n        \"StaticTraversableScene\": \"Adrian scene mesh with no interactive objects\",\n    }\n    scene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n    config_name = \"turtlebot_nav\" if scene_type == \"InteractiveTraversableScene\" else \"turtlebot_static_nav\"\n    config_filename = os.path.join(og.example_config_path, f\"{config_name}.yaml\")\n    config = yaml.load(open(config_filename, \"r\"), Loader=yaml.FullLoader)\n\n    # If the scene type is interactive, also check if we want to quick load or full load the scene\n    if scene_type == \"InteractiveTraversableScene\":\n        load_options = {\n            \"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n            \"Full\": \"Load all interactive objects in the scene\",\n        }\n        load_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\n        if load_mode == \"Quick\":\n            config[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n\n    # Load the environment\n    env = og.Environment(configs=config)\n\n    # Allow user to move camera more easily\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Run a simple loop and reset periodically\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/environments/navigation_env_demo.html#examples.environments.navigation_env_demo.main"},{"title":"learning","text":"","location":"reference/examples/learning/index.html"},{"title":"stable_baselines3_ppo_example","text":"<p>Example training code using stable-baselines3 PPO for one BEHAVIOR activity. Note that due to the sparsity of the reward, this training code will not converge and achieve task success. This only serves as a starting point that users can further build upon.</p>","location":"reference/examples/learning/stable_baselines3_ppo_example.html"},{"title":"object_states","text":"","location":"reference/examples/object_states/index.html"},{"title":"attachment_demo","text":"","location":"reference/examples/object_states/attachment_demo.html"},{"title":"blender_demo","text":"","location":"reference/examples/object_states/blender_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo to showcase the Blender transition rule in action.</p> <p>Creates a strawberry smoothie by first spawning milk, strawberries, and ice cubes, and then closes the lid and \"blends\" the items into a strawberry smoothie fluid</p>  Source code in <code>examples/object_states/blender_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo to showcase the Blender transition rule in action.\n\n    Creates a strawberry smoothie by first spawning milk, strawberries, and ice cubes,\n    and then closes the lid and \"blends\" the items into a strawberry smoothie fluid\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Make sure object states are enabled\n    assert gm.ENABLE_OBJECT_STATES, f\"Object states must be enabled in macros.py in order to use this demo!\"\n    assert gm.ENABLE_GLOBAL_CONTACT_REPORTING, f\"Global contact reporting must be enabled in macros.py in order to use this demo!\"\n    assert gm.ENABLE_TRANSITION_RULES, f\"Transition rules must be enabled in macros.py in order to use this demo!\"\n\n    # Create the scene config to load -- empty scene with table, knife, and apple\n    table_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"table\",\n        category=\"breakfast_table\",\n        model=\"19203\",\n        scale=0.9,\n        position=[0, 0, 0.532],\n    )\n\n    apple_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"apple\",\n        category=\"apple\",\n        model=\"00_0\",\n        scale=1.5,\n        position=[0.085, 0,  0.90],\n    )\n\n    knife_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"knife\",\n        category=\"table_knife\",\n        model=\"4\",\n        scale=2.5,\n        position=[0, 0, 10.0],\n    )\n\n    light0_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light0\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=4000.0,\n        position=[1.217, -0.848, 1.388],\n    )\n\n    light1_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light1\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=4000.0,\n        position=[-1.217, 0.848, 1.388],\n    )\n\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [table_cfg, apple_cfg, knife_cfg, light0_cfg, light1_cfg]\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Grab reference to apple and knife\n    apple = env.scene.object_registry(\"name\", \"apple\")\n    knife = env.scene.object_registry(\"name\", \"knife\")\n\n    # Update the simulator's viewer camera's pose so it points towards the table\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([ 0.544888, -0.412084,  1.11569 ]),\n        orientation=np.array([0.54757518, 0.27792802, 0.35721896, 0.70378409]),\n    )\n\n    # Let apple settle\n    for _ in range(50):\n        env.step(np.array([]))\n\n    knife.keep_still()\n    knife.set_position_orientation(\n        position=apple.get_position() + np.array([-0.15, 0.0, 0.2]),\n        orientation=T.euler2quat([-np.pi / 2, 0, 0]),\n    )\n\n    input(\"The knife will fall on the apple and slice it. Press [ENTER] to continue.\")\n\n    # Step simulation for a bit so that apple is sliced\n    for i in range(1000):\n        env.step(np.array([]))\n\n    input(\"Apple has been sliced! Press [ENTER] to terminate the demo.\")\n\n    # Always close environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/object_states/blender_demo.html#examples.object_states.blender_demo.main"},{"title":"cleaning_demo","text":"","location":"reference/examples/object_states/cleaning_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of a cleaning task Loads an interactive scene and sets all object surface to be dirty Loads also a cleaning tool that can be soaked in water and used to clean objects if moved manually</p>  Source code in <code>examples/object_states/cleaning_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of a cleaning task\n    Loads an interactive scene and sets all object surface to be dirty\n    Loads also a cleaning tool that can be soaked in water and used to clean objects if moved manually\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- Rs_int with only a few object categories loaded, as\n    # well as a custom block object that will be used as a cleaning tool\n    def check_water_saturation(obj):\n        return obj.states[object_states.Saturated].get_value(WaterSystem)\n\n    cfg = {\n        \"scene\": {\n            \"type\": \"InteractiveTraversableScene\",\n            \"scene_model\": \"Rs_int\",\n            \"load_object_categories\": [\"floors\", \"walls\", \"ceilings\", \"breakfast_table\", \"bottom_cabinet\", \"sink\", \"stove\", \"fridge\", \"window\"],\n        },\n        \"objects\": [\n            # A cleaning tool (cuboid) with the ability to be saturated and remove stain, dust, and water particles\n            {\n                \"type\": \"PrimitiveObject\",\n                \"name\": \"block\",\n                \"primitive_type\": \"Cube\",\n                \"scale\": [0.15, 0.1, 0.03],\n                \"rgba\": [0.5, 1.0, 1.0, 1.0],\n                \"abilities\": {\n                    \"saturable\": {},\n                    \"particleRemover\": {\n                        \"method\": ParticleModifyMethod.ADJACENCY,\n                        \"conditions\": {\n                            # For a specific particle system, this specifies what conditions are required in order for the\n                            # particle applier / remover to apply / remover particles associated with that system\n                            # The list should contain functions with signature condition() --&gt; bool,\n                            # where True means the condition is satisfied\n                            # In this case, we only allow our cleaning tool to remove stains and dust particles if\n                            # the object is saturated with water, i.e.: it's \"soaked\" with water particles\n                            StainSystem: [check_water_saturation],\n                            DustSystem: [check_water_saturation],\n                            WaterSystem: [],\n                        },\n                    },\n                },\n                \"position\": [-1.4, 3.0, 1.5],\n            },\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set everything that can go dirty and activate the water sources\n    dusty_objects = env.scene.object_registry(\"category\", \"breakfast_table\")\n    stained_objects = env.scene.object_registry(\"category\", \"bottom_cabinet\")\n    water_source_objects = env.scene.get_objects_with_state(object_states.WaterSource)\n\n    for obj in dusty_objects:\n        logging.info(f\"Setting object {obj.name} to be Dusty\")\n        obj.states[object_states.Covered].set_value(DustSystem, True)\n\n    for obj in stained_objects:\n        logging.info(f\"Setting object {obj.name} to be Stained\")\n        obj.states[object_states.Covered].set_value(StainSystem, True)\n\n    for obj in water_source_objects:\n        if object_states.ToggledOn in obj.states:\n            logging.info(f\"Setting water source object {obj} to be ToggledOn\")\n            obj.states[object_states.ToggledOn].set_value(True)\n\n    # Set the camera to be in a good position\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.825556,  2.42499 ,  1.04104 ]),\n        orientation=np.array([0.56919735, 0.09896035, 0.13981109, 0.80416049]),\n    )\n\n    max_steps = -1 if not short_exec else 1000\n    step = 0\n    try:\n        for i in range(200):\n            env.step(np.array([]))\n        while step != max_steps:\n            env.step(np.array([]))      # Empty action since no robots in the environment\n            step += 1\n    finally:\n        # Always close environment at the end\n        env.close()\n</code></pre>","location":"reference/examples/object_states/cleaning_demo.html#examples.object_states.cleaning_demo.main"},{"title":"cleaning_demo_simple","text":"","location":"reference/examples/object_states/cleaning_demo_simple.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of a cleaning task that resets after everything has been cleaned Loads an empty scene with a sink, a dusty table and a dirty and stained bowl, and a cleaning tool If everything is cleaned, or after N steps, the scene resets to the initial state</p>  Source code in <code>examples/object_states/cleaning_demo_simple.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of a cleaning task that resets after everything has been cleaned\n    Loads an empty scene with a sink, a dusty table and a dirty and stained bowl, and a cleaning tool\n    If everything is cleaned, or after N steps, the scene resets to the initial state\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        }\n    }\n\n    # Define objects to load into the environment\n    sink_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"sink\",\n        category=\"sink\",\n        model=\"sink_1\",\n        scale=[0.8, 0.8, 0.8],\n        abilities={\"toggleable\": {}, \"waterSource\": {}, \"waterSink\": {}},\n        position=[-0.7, 0, 0.53],\n    )\n\n    def check_water_saturation(obj):\n        return obj.states[object_states.Saturated].get_value(WaterSystem)\n\n    brush_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"brush\",\n        category=\"scrub_brush\",\n        model=\"scrub_brush_000\",\n        avg_obj_dims={\"size\": [0.1, 0.1, 0.1], \"density\": 67.0},\n        fit_avg_dim_volume=True,\n        position=[1.0, 0, 0.4],\n        abilities={\n            \"saturable\": {},\n            \"particleRemover\": {\n                \"method\": ParticleModifyMethod.ADJACENCY,\n                \"conditions\": {\n                    # For a specific particle system, this specifies what conditions are required in order for the\n                    # particle applier / remover to apply / remover particles associated with that system\n                    # The list should contain functions with signature condition() --&gt; bool,\n                    # where True means the condition is satisfied\n                    # In this case, we only allow our cleaning tool to remove stains and dust particles if\n                    # the object is saturated with water, i.e.: it's \"soaked\" with water particles\n                    StainSystem: [check_water_saturation],\n                    DustSystem: [check_water_saturation],\n                    WaterSystem: [],\n                },\n            },\n        },\n    )\n\n    # Desk that's dusty\n    desk_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"desk\",\n        category=\"breakfast_table\",\n        model=\"19203\",\n        scale=[0.8, 0.8, 0.8],\n        position=[1.0, 0, 0.48],\n    )\n\n    # Bowl with stains\n    bowl_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"bowl\",\n        category=\"bowl\",\n        model=\"68_0\",\n        scale=np.array([0.8, 0.8, 0.8]),\n        position=[-1.0, 0, 0.48],\n    )\n\n    cfg[\"objects\"] = [sink_cfg, brush_cfg, desk_cfg, bowl_cfg]\n\n    # Create the environment!\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set camera to ideal angle for viewing objects\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.782289, -0.633009,  1.4475  ]),\n        orientation=np.array([ 0.48871723, -0.24618907, -0.37654978,  0.74750028]),\n    )\n\n    # Take a few steps to let the objects settle, and then sanity check the initial state\n    for _ in range(10):\n        env.step(np.array([]))              # Empty action since no robots are in the scene\n\n    sink = env.scene.object_registry(\"name\", \"sink\")\n    brush = env.scene.object_registry(\"name\", \"brush\")\n    desk = env.scene.object_registry(\"name\", \"desk\")\n    bowl = env.scene.object_registry(\"name\", \"bowl\")\n\n    assert sink.states[object_states.ToggledOn].set_value(True)\n    assert desk.states[object_states.Covered].set_value(DustSystem, True)\n    assert bowl.states[object_states.OnTop].set_value(desk, True, use_ray_casting_method=True)\n    assert brush.states[object_states.OnTop].set_value(desk, True, use_ray_casting_method=True)\n    assert bowl.states[object_states.Covered].set_value(StainSystem, True)\n\n    # Take a step, and save the state\n    env.step(np.array([]))\n    initial_state = og.sim.dump_state()\n\n    # Main simulation loop.\n    max_steps = 1000\n    max_iterations = -1 if not short_exec else 1\n    iteration = 0\n    try:\n        while iteration != max_iterations:\n            # Keep stepping until table or bowl are clean, or we reach 1000 steps\n            steps = 0\n            while (\n                desk.states[object_states.Covered].get_value(DustSystem)\n                and bowl.states[object_states.Covered].get_value(StainSystem)\n                and steps != max_steps\n            ):\n                steps += 1\n                env.step(np.array([]))\n                logging.info(f\"Step {steps}\")\n\n            if not desk.states[object_states.Covered].get_value(DustSystem):\n                logging.info(\"Reset because Table cleaned\")\n            elif not bowl.states[object_states.Covered].get_value(StainSystem):\n                logging.info(\"Reset because Bowl cleaned\")\n            else:\n                logging.info(\"Reset because max steps\")\n\n            # Reset to the initial state\n            og.sim.load_state(initial_state)\n\n            iteration += 1\n\n    finally:\n        # Always shut down environment at the end\n        env.close()\n</code></pre>","location":"reference/examples/object_states/cleaning_demo_simple.html#examples.object_states.cleaning_demo_simple.main"},{"title":"folded_state_demo","text":"","location":"reference/examples/object_states/folded_state_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of cloth objects that can potentially be folded.</p>  Source code in <code>examples/object_states/folded_state_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of cloth objects that can potentially be folded.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene + custom cloth object\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"carpet\",\n                \"category\": \"carpet\",\n                \"model\": \"carpet_0\",\n                \"prim_type\": PrimType.CLOTH,\n                \"abilities\": {\"foldable\": {}},\n                \"position\": [0, 0, 0.5],\n            },\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"dishtowel\",\n                \"category\": \"dishtowel\",\n                \"model\": \"Tag_Dishtowel_Basket_Weave_Red\",\n                \"prim_type\": PrimType.CLOTH,\n                \"scale\": 5.0,\n                \"abilities\": {\"foldable\": {}},\n                \"position\": [1, 1, 0.5],\n            },\n            {\n                \"type\": \"DatasetObject\",\n                \"name\": \"shirt\",\n                \"category\": \"t-shirt\",\n                \"model\": \"t-shirt_000\",\n                \"prim_type\": PrimType.CLOTH,\n                \"scale\": 0.05,\n                \"abilities\": {\"foldable\": {}},\n                \"position\": [-1, 1, 0.5],\n                \"orientation\": [0.7071, 0., 0.7071, 0.],\n            },\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n\n    # Grab object references\n    carpet = env.scene.object_registry(\"name\", \"carpet\")\n    dishtowel = env.scene.object_registry(\"name\", \"dishtowel\")\n    shirt = env.scene.object_registry(\"name\", \"shirt\")\n\n    max_steps = 100 if short_exec else -1\n    steps = 0\n\n    # Criterion #1: the area of the convex hull of the projection of points onto the x-y plane should be reduced\n    # Criterion #2: the diagonal of the convex hull of the projection of points onto the x-y plane should be reduced\n    # Criterion #3: the face normals of the cloth should mostly point along the z-axis\n    while steps != max_steps:\n        og.sim.step()\n\n        flag_area_reduction, flag_diagonal_reduction = carpet.states[Folded].check_projection_area_and_diagonal()\n        flag_smoothness = carpet.states[Folded].check_smoothness()\n        folded = flag_area_reduction and flag_diagonal_reduction and flag_smoothness\n        info = 'carpet: [folded] %d [A] %d [D] %d [S] %d' % (folded, flag_area_reduction, flag_diagonal_reduction, flag_smoothness)\n\n        flag_area_reduction, flag_diagonal_reduction = dishtowel.states[Folded].check_projection_area_and_diagonal()\n        flag_smoothness = dishtowel.states[Folded].check_smoothness()\n        folded = flag_area_reduction and flag_diagonal_reduction and flag_smoothness\n        info += \" || dishtowel: [folded] %d [A] %d [D] %d [S] %d\" % (folded, flag_area_reduction, flag_diagonal_reduction, flag_smoothness)\n\n        flag_area_reduction, flag_diagonal_reduction = shirt.states[Folded].check_projection_area_and_diagonal()\n        flag_smoothness = shirt.states[Folded].check_smoothness()\n        folded = flag_area_reduction and flag_diagonal_reduction and flag_smoothness\n        info += \" || tshirt: [folded] %d [A] %d [D] %d [S] %d\" % (folded, flag_area_reduction, flag_diagonal_reduction, flag_smoothness)\n\n        print(info)\n        steps += 1\n\n    # Shut down env at the end\n    env.close()\n</code></pre>","location":"reference/examples/object_states/folded_state_demo.html#examples.object_states.folded_state_demo.main"},{"title":"heat_source_or_sink_demo","text":"","location":"reference/examples/object_states/heat_source_or_sink_demo.html"},{"title":"heated_state_demo","text":"","location":"reference/examples/object_states/heated_state_demo.html"},{"title":"object_state_texture_demo","text":"","location":"reference/examples/object_states/object_state_texture_demo.html"},{"title":"particle_applier_remover_demo","text":"","location":"reference/examples/object_states/particle_applier_remover_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of ParticleApplier and ParticleRemover object states, which enable objects to either apply arbitrary particles and remove arbitrary particles from the simulator, respectively.</p> <p>Loads an empty scene with a table, and starts clean to allow particles to be applied or pre-covers the table with particles to be removed. The ParticleApplier / ParticleRemover state is applied to an imported cloth object and allowed to interact with the table, applying / removing particles from the table.</p>  Source code in <code>examples/object_states/particle_applier_remover_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of ParticleApplier and ParticleRemover object states, which enable objects to either apply arbitrary\n    particles and remove arbitrary particles from the simulator, respectively.\n\n    Loads an empty scene with a table, and starts clean to allow particles to be applied or pre-covers the table\n    with particles to be removed. The ParticleApplier / ParticleRemover state is applied to an imported cloth object\n    and allowed to interact with the table, applying / removing particles from the table.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose what configuration to load\n    modifier_type = choose_from_options(\n        options={\n            \"particleApplier\": \"Demo object's ability to apply particles in the simulator\",\n            \"particleRemover\": \"Demo object's ability to remove particles from the simulator\",\n        },\n        name=\"particle modifier type\",\n        random_selection=random_selection,\n    )\n\n    modification_metalink = {\n        \"particleApplier\": \"particleapplication_link\",\n        \"particleRemover\": \"particleremover_link\",\n    }\n\n    particle_mapping = {system.name: system for system in [StainSystem, WaterSystem]}\n    particle_type = choose_from_options(\n        options={name: f\"{name} particles will be applied or removed from the simulator\" for name in particle_mapping},\n        name=\"particle type\",\n        random_selection=random_selection,\n    )\n    particle_system = particle_mapping[particle_type]\n\n    modification_method = {\n        \"Adjacency\": ParticleModifyMethod.ADJACENCY,\n        \"Projection\": ParticleModifyMethod.PROJECTION,\n    }\n\n    projection_mesh_params = {\n        \"Adjacency\": None,\n        \"Projection\": {\n            # Either Cone or Cylinder; shape of the projection where particles can be applied / removed\n            \"type\": \"Cone\",\n            # Size of the cone\n            \"extents\": np.array([0.375, 0.375, 0.75]),\n        },\n    }\n\n    method_type = choose_from_options(\n        options={\n            \"Adjacency\": \"Close proximity to the object will be used to determine whether particles can be applied / removed\",\n            \"Projection\": \"A Cone or Cylinder shape protruding from the object will be used to determine whether particles can be applied / removed\",\n        },\n        name=\"modifier method type\",\n        random_selection=random_selection,\n    )\n\n    # Create the ability kwargs to pass to the object state\n    abilities = {\n        modifier_type: {\n            \"method\": modification_method[method_type],\n            \"conditions\": {\n                # For a specific particle system, this specifies what conditions are required in order for the\n                # particle applier / remover to apply / remover particles associated with that system\n                # The list should contain functions with signature condition() --&gt; bool,\n                # where True means the condition is satisified\n                particle_system: [],\n            },\n            \"projection_mesh_params\": projection_mesh_params[method_type],\n        }\n    }\n\n    # Define objects to load: a light, table, and cloth\n    light_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, -2.0, 2.0],\n    )\n\n    table_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"table\",\n        category=\"breakfast_table\",\n        model=\"265851637a59eb2f882f822c83877cbc\",\n        scale=[4.0, 4.0, 4.0],\n        position=[0, 0, 0.7],\n    )\n\n    # Create the scene config to load -- empty scene with a light and table\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [light_cfg, table_cfg],\n    }\n\n    # Sanity check inputs: Remover + Adjacency + Fluid will not work because we are using a visual_only\n    # object, so contacts will not be triggered with this object\n\n    # Load the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Grab references to table\n    table = env.scene.object_registry(\"name\", \"table\")\n\n    # Set the viewer camera appropriately\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-1.11136405, -1.12709412,  1.99587299]),\n        orientation=np.array([ 0.44662832, -0.17829795, -0.32506992,  0.81428652]),\n    )\n\n    # Let objects settle first\n    for _ in range(10):\n        env.step(np.array([]))\n\n    # If we're using a projection volume, we manually add in the required metalink required in order to use the volume\n    modifier = DatasetObject(\n        prim_path=\"/World/modifier\",\n        name=\"modifier\",\n        category=\"dishtowel\",\n        model=\"Tag_Dishtowel_Basket_Weave_Red\",\n        scale=np.ones(3) * 2.0,\n        visual_only=method_type == \"Projection\" or particle_system == StainSystem,  # Fluid + adjacency requires the object to have collision geoms active\n        abilities=abilities,\n    )\n    modifier_root_link_path = f\"{modifier.prim_path}/base_link\"\n    modifier._prim = modifier._load(og.sim)\n    if method_type == \"Projection\":\n        metalink_path = f\"{modifier.prim_path}/{modification_metalink[modifier_type]}\"\n        og.sim.stage.DefinePrim(metalink_path, \"Xform\")\n        joint_prim = create_joint(\n            prim_path=f\"{modifier_root_link_path}/{modification_metalink[modifier_type]}_joint\",\n            body0=modifier_root_link_path,\n            body1=metalink_path,\n            joint_type=\"FixedJoint\",\n            enabled=True,\n        )\n        local_area_quat = np.array([0, 0.707, 0, 0.707])    # Needs to rotated so the metalink points downwards from cloth\n        joint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*(local_area_quat[[3, 0, 1, 2]])))\n    modifier._post_load()\n    modifier._loaded = True\n    og.sim.import_object(modifier)\n    modifier.set_position(np.array([0, 0, 5.0]))\n\n    # Take a step to make sure all objects are properly initialized\n    for _ in range(25):\n        env.step(np.array([]))\n\n    # If we're removing particles, set the table's covered state to be True\n    if modifier_type == \"particleRemover\":\n        table.states[Covered].set_value(particle_system, True)\n\n        # Take a few steps to let particles settle\n        for _ in range(25):\n            env.step(np.array([]))\n\n    # Enable camera teleoperation for convenience\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Set the modifier object to be in position to modify particles\n    if method_type == \"Projection\":\n        # Higher z to showcase projection volume at work\n        z = 1.85\n    elif particle_system == StainSystem:\n        # Lower z needed to allow for adjacency bounding box to overlap properly\n        z = 1.175\n    else:\n        # Higher z needed for actual physical interaction to accomodate non-negligible particle radius\n        z = 1.22\n    modifier.keep_still()\n    modifier.set_position_orientation(\n        position=np.array([0, 0.3, z]),\n        orientation=np.array([0, 0, 0, 1.0]),\n    )\n\n    # Move object in square around table\n    deltas = [\n        [150, np.array([-0.01, 0, 0])],\n        [60, np.array([0, -0.01, 0])],\n        [150, np.array([0.01, 0, 0])],\n        [60, np.array([0, 0.01, 0])],\n    ]\n    for t, delta in deltas:\n        for i in range(t):\n            modifier.set_position(modifier.get_position() + delta)\n            # env.step(np.array([]))\n            og.sim.step()\n\n    # Always shut down environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/object_states/particle_applier_remover_demo.html#examples.object_states.particle_applier_remover_demo.main"},{"title":"sample_kinematics_demo","text":"","location":"reference/examples/object_states/sample_kinematics_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo to use the raycasting-based sampler to load objects onTop and/or inside another Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet Then loads a shelf and cracker boxes inside of it</p>  Source code in <code>examples/object_states/sample_kinematics_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo to use the raycasting-based sampler to load objects onTop and/or inside another\n    Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet\n    Then loads a shelf and cracker boxes inside of it\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        }\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n    env.step([])\n\n    # Sample microwave and boxes\n    sample_boxes_on_shelf(env)\n    sample_microwave_plates_apples(env)\n\n    max_steps = 100 if short_exec else -1\n    step = 0\n    while step != max_steps:\n        env.step(np.array([]))\n        step += 1\n\n    # Always close environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/object_states/sample_kinematics_demo.html#examples.object_states.sample_kinematics_demo.main"},{"title":"slicing_demo","text":"","location":"reference/examples/object_states/slicing_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo to use the raycasting-based sampler to load objects onTop and/or inside another Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet Then loads a shelf and cracker boxes inside of it</p>  Source code in <code>examples/object_states/slicing_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo to use the raycasting-based sampler to load objects onTop and/or inside another\n    Loads a cabinet, a microwave open on top of it, and two plates with apples on top, one inside and one on top of the cabinet\n    Then loads a shelf and cracker boxes inside of it\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene with table, knife, and apple\n    table_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"table\",\n        category=\"breakfast_table\",\n        model=\"19203\",\n        scale=0.9,\n        position=[0, 0, 0.532],\n    )\n\n    apple_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"apple\",\n        category=\"apple\",\n        model=\"00_0\",\n        scale=1.5,\n        position=[0.085, 0,  0.90],\n    )\n\n    knife_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"knife\",\n        category=\"table_knife\",\n        model=\"4\",\n        scale=2.5,\n        position=[0, 0, 10.0],\n    )\n\n    light0_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light0\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=4000.0,\n        position=[1.217, -0.848, 1.388],\n    )\n\n    light1_cfg = OrderedDict(\n        type=\"LightObject\",\n        name=\"light1\",\n        light_type=\"Sphere\",\n        radius=0.01,\n        intensity=4000.0,\n        position=[-1.217, 0.848, 1.388],\n    )\n\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [table_cfg, apple_cfg, knife_cfg, light0_cfg, light1_cfg]\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Grab reference to apple and knife\n    apple = env.scene.object_registry(\"name\", \"apple\")\n    knife = env.scene.object_registry(\"name\", \"knife\")\n\n    # Update the simulator's viewer camera's pose so it points towards the table\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([ 0.544888, -0.412084,  1.11569 ]),\n        orientation=np.array([0.54757518, 0.27792802, 0.35721896, 0.70378409]),\n    )\n\n    # Let apple settle\n    for _ in range(50):\n        env.step(np.array([]))\n\n    knife.keep_still()\n    knife.set_position_orientation(\n        position=apple.get_position() + np.array([-0.15, 0.0, 0.2]),\n        orientation=T.euler2quat([-np.pi / 2, 0, 0]),\n    )\n\n    input(\"The knife will fall on the apple and slice it. Press [ENTER] to continue.\")\n\n    # Step simulation for a bit so that apple is sliced\n    for i in range(1000):\n        env.step(np.array([]))\n\n    input(\"Apple has been sliced! Press [ENTER] to terminate the demo.\")\n\n    # Always close environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/object_states/slicing_demo.html#examples.object_states.slicing_demo.main"},{"title":"temperature_demo","text":"","location":"reference/examples/object_states/temperature_demo.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Demo of temperature change Loads a stove, a microwave and an oven, all toggled on, and five frozen apples The user can move the apples to see them change from frozen, to normal temperature, to cooked and burnt This demo also shows how to load objects ToggledOn and how to set the initial temperature of an object</p>  Source code in <code>examples/object_states/temperature_demo.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Demo of temperature change\n    Loads a stove, a microwave and an oven, all toggled on, and five frozen apples\n    The user can move the apples to see them change from frozen, to normal temperature, to cooked and burnt\n    This demo also shows how to load objects ToggledOn and how to set the initial temperature of an object\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Define specific objects we want to load in with the scene directly\n    obj_configs = []\n\n    # Light\n    obj_configs.append(OrderedDict(\n        type=\"LightObject\",\n        light_type=\"Sphere\",\n        name=\"light\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, -2.0, 1.0],\n    ))\n\n    # Stove\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"stove\",\n        category=\"stove\",\n        model=\"101943\",\n        position=[0, 0, 0.65],\n    ))\n\n    # Microwave\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"microwave\",\n        category=\"microwave\",\n        model=\"7128\",\n        scale=0.25,\n        position=[2.5, 0, 0.094],\n    ))\n\n    # Oven\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"oven\",\n        category=\"oven\",\n        model=\"7120\",\n        position=[-1.25, 0, 0.80],\n    ))\n\n    # Tray\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"tray\",\n        category=\"tray\",\n        model=\"tray_000\",\n        scale=0.15,\n        position=[0, 0, 1.24],\n    ))\n\n    # Fridge\n    obj_configs.append(OrderedDict(\n        type=\"DatasetObject\",\n        name=\"fridge\",\n        category=\"fridge\",\n        model=\"12252\",\n        abilities={\n            \"coldSource\": {\n                \"temperature\": -100.0,\n                \"requires_inside\": True,\n            }\n        },\n        position=[1.25, 0, 0.90],\n    ))\n\n    # 5 Apples\n    for i in range(5):\n        obj_configs.append(OrderedDict(\n            type=\"DatasetObject\",\n            name=f\"apple{i}\",\n            category=\"apple\",\n            model=\"00_0\",\n            position=[0, i * 0.05, 1.65],\n        ))\n\n    # Create the scene config to load -- empty scene with desired objects\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": obj_configs,\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n\n    # Get reference to relevant objects\n    stove = env.scene.object_registry(\"name\", \"stove\")\n    microwave = env.scene.object_registry(\"name\", \"microwave\")\n    oven = env.scene.object_registry(\"name\", \"oven\")\n    tray = env.scene.object_registry(\"name\", \"tray\")\n    fridge = env.scene.object_registry(\"name\", \"fridge\")\n    apples = list(env.scene.object_registry(\"category\", \"apple\"))\n\n    # Set camera to appropriate viewing pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([ 0.46938863, -3.97887141,  1.64106008]),\n        orientation=np.array([0.63311689, 0.00127259, 0.00155577, 0.77405359]),\n    )\n\n    # Let objects settle\n    for _ in range(25):\n        env.step(np.array([]))\n\n    # Turn on all scene objects\n    stove.states[object_states.ToggledOn].set_value(True)\n    microwave.states[object_states.ToggledOn].set_value(True)\n    oven.states[object_states.ToggledOn].set_value(True)\n\n    # Set initial temperature of the apples to -50 degrees Celsius, and move the apples to different objects\n    for apple in apples:\n        apple.states[object_states.Temperature].set_value(-50)\n    apples[0].states[object_states.Inside].set_value(oven, True, use_ray_casting_method=True)\n    apples[1].set_position(stove.links[\"heat_source_link\"].get_position() + np.array([0, 0, 0.1]))\n    apples[2].states[object_states.OnTop].set_value(tray, True, use_ray_casting_method=True)\n    apples[3].states[object_states.Inside].set_value(fridge, True, use_ray_casting_method=True)\n    apples[4].states[object_states.Inside].set_value(microwave, True, use_ray_casting_method=True)\n\n    steps = 0\n    max_steps = -1 if not short_exec else 1000\n\n    # Main recording loop\n    locations = [f'{loc:&gt;20}' for loc in [\"Inside oven\", \"On stove\", \"On tray\", \"Inside fridge\", \"Inside microwave\"]]\n    print()\n    print(f\"{'Apple location:':&lt;20}\", *locations)\n    while steps != max_steps:\n        env.step(np.array([]))\n        temps = [f\"{apple.states[object_states.Temperature].get_value():&gt;20.2f}\" for apple in apples]\n        print(f\"{'Apple temperature:':&lt;20}\", *temps, end=\"\\r\")\n        steps += 1\n\n    # Always close env at the end\n    env.close()\n</code></pre>","location":"reference/examples/object_states/temperature_demo.html#examples.object_states.temperature_demo.main"},{"title":"objects","text":"","location":"reference/examples/objects/index.html"},{"title":"draw_bounding_box","text":"","location":"reference/examples/objects/draw_bounding_box.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Shows how to obtain the bounding box of an articulated object. Draws the bounding box around the loaded object, a cabinet, and writes the visualized image to disk at the current directory named 'bbox_2d_[loose / tight]_img.png'.</p> <p>NOTE: In the GUI, bounding boxes can be natively viewed by clicking on the sensor ((*)) icon at the top, and then selecting the appropriate bounding box modalities, and clicking \"Show\". See:</p> <p>https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator/visualization.html#the-visualizer</p>  Source code in <code>examples/objects/draw_bounding_box.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Shows how to obtain the bounding box of an articulated object.\n    Draws the bounding box around the loaded object, a cabinet, and writes the visualized image to disk at the\n    current directory named 'bbox_2d_[loose / tight]_img.png'.\n\n    NOTE: In the GUI, bounding boxes can be natively viewed by clicking on the sensor ((*)) icon at the top,\n    and then selecting the appropriate bounding box modalities, and clicking \"Show\". See:\n\n    https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator/visualization.html#the-visualizer\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Specify objects to load\n    banana_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"banana\",\n        category=\"banana\",\n        model=\"09_0\",\n        scale=[3.0, 5.0, 2.0],\n        position=[-0.906661, -0.545106,  0.136824],\n        orientation=[0, 0, 0.76040583, -0.6494482 ],\n    )\n\n    door_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"door\",\n        category=\"door\",\n        model=\"8930\",\n        position=[-2.0, 0, 0.70000001],\n        orientation=[0, 0, -0.38268343,  0.92387953],\n    )\n\n    # Create the scene config to load -- empty scene with a few objects\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [banana_cfg, door_cfg],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set camera to appropriate viewing pose\n    cam = og.sim.viewer_camera\n    cam.set_position_orientation(\n        position=np.array([-4.62785 , -0.418575,  0.933943]),\n        orientation=np.array([ 0.52196595, -0.4231939 , -0.46640436,  0.5752612 ]),\n    )\n\n    # Add bounding boxes to camera sensor\n    bbox_modalities = [\"bbox_3d\", \"bbox_2d_loose\", \"bbox_2d_tight\"]\n    for bbox_modality in bbox_modalities:\n        cam.add_modality(bbox_modality)\n\n    # Take a few steps to let objects settle\n    for i in range(100):\n        env.step(np.array([]))\n\n    # Grab observations from viewer camera and write them to disk\n    obs = cam.get_obs()\n\n    for bbox_modality in bbox_modalities:\n        # Print out each of the modalities\n        print(f\"Observation modality {bbox_modality}:\")\n        print(obs[bbox_modality])\n\n        # Also write the 2d loose bounding box to disk\n        if \"3d\" not in bbox_modality:\n            colorized_img = colorize_bboxes(bboxes_2d_data=obs[bbox_modality], bboxes_2d_rgb=obs[\"rgb\"], num_channels=4)\n            plt.imsave(f\"{bbox_modality}_img.png\", colorized_img)\n\n    # Always close environment down at end\n    env.close()\n</code></pre>","location":"reference/examples/objects/draw_bounding_box.html#examples.objects.draw_bounding_box.main"},{"title":"highlight_objects","text":"<p>Generate example top-down segmentation map via renderer</p>","location":"reference/examples/objects/highlight_objects.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Highlights visually all object instances of some given category and then removes the highlighting It also demonstrates how to apply an action on all instances of objects of a given category ONLY WORKS WITH OPTIMIZED RENDERING (not on Mac)</p>  Source code in <code>examples/objects/highlight_objects.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Highlights visually all object instances of some given category and then removes the highlighting\n    It also demonstrates how to apply an action on all instances of objects of a given category\n    ONLY WORKS WITH OPTIMIZED RENDERING (not on Mac)\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"InteractiveTraversableScene\",\n            \"scene_model\": \"Rs_int\",\n        }\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg)\n\n    # Grab all window objects\n    windows = og.sim.scene.object_registry(\"category\", \"window\")\n\n    # Step environment while toggling window highlighting\n    i = 0\n    highlighted = False\n    max_steps = -1 if not short_exec else 1000\n    while i != max_steps:\n        env.step(np.array([]))\n        if i % 50 == 0:\n            highlighted = not highlighted\n            logging.info(f\"Toggling window highlight to: {highlighted}\")\n            for window in windows:\n                # Note that this property is R/W!\n                window.highlighted = highlighted\n        i += 1\n\n    # Always close the environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/objects/highlight_objects.html#examples.objects.highlight_objects.main"},{"title":"load_object_selector","text":"","location":"reference/examples/objects/load_object_selector.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>This demo shows how to load any scaled objects from the iG object model dataset The user selects an object model to load The objects can be loaded into an empty scene, an interactive scene (iG) or a static scene (Gibson) The example also shows how to use the Environment API or directly the Simulator API, loading objects and robots and executing actions</p>  Source code in <code>examples/objects/load_object_selector.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    This demo shows how to load any scaled objects from the iG object model dataset\n    The user selects an object model to load\n    The objects can be loaded into an empty scene, an interactive scene (iG) or a static scene (Gibson)\n    The example also shows how to use the Environment API or directly the Simulator API, loading objects and robots\n    and executing actions\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n    scene_options = [\"Scene\", \"InteractiveTraversableScene\", \"StaticTraversableScene\"]\n    scene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n\n    # -- Choose the object to load --\n\n    # Select a category to load\n    available_obj_categories = get_all_object_categories()\n    obj_category = choose_from_options(options=available_obj_categories, name=\"object category\", random_selection=random_selection)\n\n    # Select a model to load\n    available_obj_models = get_object_models_of_category(obj_category)\n    obj_model = choose_from_options(options=available_obj_models, name=\"object model\", random_selection=random_selection)\n\n    # Load the specs of the object categories, e.g., common scaling factor\n    avg_category_spec = get_og_avg_category_specs()\n\n    # Create and load this object into the simulator\n    obj_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"obj\",\n        category=obj_category,\n        model=obj_model,\n        bounding_box=avg_category_spec.get(obj_category),\n        fit_avg_dim_volume=True,\n        position=[0.5, -0.5, 1.01],\n    )\n\n    cfg = {\n        \"scene\": {\n            \"type\": scene_type,\n        },\n        \"objects\": [obj_cfg],\n    }\n    if scene_type == \"InteractiveTraversableScene\":\n        cfg[\"scene\"][\"scene_model\"] = \"Rs_int\"\n    elif scene_type == \"StaticTraversableScene\":\n        cfg[\"scene\"][\"scene_model\"] = \"Adrian\"\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1 / 60., physics_timestep=1 / 60.)\n\n    # Step through the environment\n    max_steps = 100 if short_exec else 10000\n    for i in range(max_steps):\n        env.step(np.array([]))\n\n    # Always close the environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/objects/load_object_selector.html#examples.objects.load_object_selector.main"},{"title":"visualize_object","text":"","location":"reference/examples/objects/visualize_object.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Visualizes object as specified by its USD path, @usd_path. If None if specified, will instead result in an object selection from OmniGibson's object dataset</p>  Source code in <code>examples/objects/visualize_object.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Visualizes object as specified by its USD path, @usd_path. If None if specified, will instead\n    result in an object selection from OmniGibson's object dataset\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Assuming that if random_selection=True, headless=True, short_exec=True, we are calling it from tests and we\n    # do not want to parse args (it would fail because the calling function is pytest \"testfile.py\")\n    usd_path = None\n    if not (random_selection and headless and short_exec):\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            \"--usd_path\",\n            default=None,\n            help=\"USD Model to load\",\n        )\n        args = parser.parse_args()\n        usd_path = args.usd_path\n\n    # Define objects to load\n    light0_cfg = OrderedDict(\n        type=\"LightObject\",\n        light_type=\"Sphere\",\n        name=\"sphere_light0\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, -2.0, 2.0],\n    )\n\n    light1_cfg = OrderedDict(\n        type=\"LightObject\",\n        light_type=\"Sphere\",\n        name=\"sphere_light1\",\n        radius=0.01,\n        intensity=1e5,\n        position=[-2.0, 2.0, 2.0],\n    )\n\n    # Make sure we have a valid usd path\n    if usd_path is None:\n        # Select a category to load\n        available_obj_categories = get_all_object_categories()\n        obj_category = choose_from_options(options=available_obj_categories, name=\"object category\",\n                                           random_selection=random_selection)\n\n        # Select a model to load\n        available_obj_models = get_object_models_of_category(obj_category)\n        obj_model = choose_from_options(options=available_obj_models, name=\"object model\",\n                                        random_selection=random_selection)\n\n        kwargs = {\n            \"type\": \"DatasetObject\",\n            \"category\": obj_category,\n            \"model\": obj_model,\n        }\n    else:\n        kwargs = {\n            \"type\": \"USDObject\",\n            \"usd_path\": usd_path,\n        }\n\n    # Import the desired object\n    obj_cfg = OrderedDict(\n        **kwargs,\n        name=\"obj\",\n        usd_path=usd_path,\n        visual_only=True,\n        position=[0, 0, 10.0],\n    )\n\n    # Create the scene config to load -- empty scene\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [light0_cfg, light1_cfg, obj_cfg],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg)\n\n    # Set camera to appropriate viewing pose\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-0.00913503, -1.95750906,  1.36407314]),\n        orientation=np.array([0.6350064 , 0.        , 0.        , 0.77250687]),\n    )\n\n    # Grab the object references\n    obj = env.scene.object_registry(\"name\", \"obj\")\n\n    # Standardize the scale of the object so it fits in a [1,1,1] box -- note that we have to stop the simulator\n    # in order to set the scale\n    extents = obj.aabb_extent\n    og.sim.stop()\n    obj.scale = (np.ones(3) / extents).min()\n    og.sim.play()\n    env.step(np.array([]))\n\n    # Move the object so that its center is at [0, 0, 1]\n    center_offset = obj.aabb_center - obj.get_position() + np.array([0, 0, 1.0])\n    obj.set_position(center_offset)\n\n    # Allow the user to easily move the camera around\n    og.sim.enable_viewer_camera_teleoperation()\n\n    # Rotate the object in place\n    steps_per_rotate = 360\n    steps_per_joint = steps_per_rotate / 10\n    max_steps = 100 if short_exec else 10000\n    for i in range(max_steps):\n        z_angle = (2 * np.pi * (i % steps_per_rotate) / steps_per_rotate)\n        quat = T.euler2quat(np.array([0, 0, z_angle]))\n        pos = T.quat2mat(quat) @ center_offset\n        if obj.n_dof &gt; 0:\n            frac = (i % steps_per_joint) / steps_per_joint\n            j_frac = -1.0 + 2.0 * frac if (i // steps_per_joint) % 2 == 0 else 1.0 - 2.0 * frac\n            obj.set_joint_positions(positions=j_frac * np.ones(obj.n_dof), normalized=True, target=False)\n            obj.keep_still()\n        obj.set_position_orientation(position=pos, orientation=quat)\n        env.step(np.array([]))\n</code></pre>","location":"reference/examples/objects/visualize_object.html#examples.objects.visualize_object.main"},{"title":"renderer_settings","text":"","location":"reference/examples/renderer_settings/index.html"},{"title":"renderer_settings_example","text":"","location":"reference/examples/renderer_settings/renderer_settings_example.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Shows how to use RendererSettings class</p>  Source code in <code>examples/renderer_settings/renderer_settings_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Shows how to use RendererSettings class\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Specify objects to load\n    banana_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"banana\",\n        category=\"banana\",\n        model=\"09_0\",\n        scale=[3.0, 5.0, 2.0],\n        position=[-0.906661, -0.545106,  0.136824],\n        orientation=[0, 0, 0.76040583, -0.6494482 ],\n    )\n\n    door_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"door\",\n        category=\"door\",\n        model=\"8930\",\n        position=[-2.0, 0, 0.70000001],\n        orientation=[0, 0, -0.38268343,  0.92387953],\n    )\n\n    # Create the scene config to load -- empty scene with a few objects\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        },\n        \"objects\": [banana_cfg, door_cfg],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Set camera to appropriate viewing pose\n    cam = og.sim.viewer_camera\n    cam.set_position_orientation(\n        position=np.array([-4.62785 , -0.418575,  0.933943]),\n        orientation=np.array([ 0.52196595, -0.4231939 , -0.46640436,  0.5752612 ]),\n    )\n\n    def steps(n):\n        for _ in range(n):\n            env.step(np.array([]))\n\n    # Take a few steps to let objects settle\n    steps(25)\n\n    # Create renderer settings object.\n    renderer_setting = RendererSettings()\n\n    # RendererSettings is a singleton.\n    renderer_setting2 = RendererSettings()\n    assert renderer_setting == renderer_setting2\n\n    # Set current renderer.\n    input(\"Setting renderer to Real-Time. Press [ENTER] to continue.\")\n    renderer_setting.set_current_renderer(\"Real-Time\")\n    assert renderer_setting.get_current_renderer() == \"Real-Time\"\n    steps(5)\n\n    input(\"Setting renderer to Interactive (Path Tracing). Press [ENTER] to continue.\")\n    renderer_setting.set_current_renderer(\"Interactive (Path Tracing)\")\n    assert renderer_setting.get_current_renderer() == \"Interactive (Path Tracing)\"\n    steps(5)\n\n    # Get all available settings.\n    print(renderer_setting.settings.keys())\n\n    input(\"Showcasing how to use RendererSetting APIs. Please see example script for more information. \"\n          \"Press [ENTER] to continue.\")\n\n    # Set setting (2 lines below are equivalent).\n    renderer_setting.set_setting(path=\"/app/renderer/skipMaterialLoading\", value=True)\n    renderer_setting.common_settings.materials_settings.skip_material_loading.set(True)\n\n    # Get setting (3 lines below are equivalent).\n    assert renderer_setting.get_setting_from_path(path=\"/app/renderer/skipMaterialLoading\") == True\n    assert renderer_setting.common_settings.materials_settings.skip_material_loading.value == True\n    assert renderer_setting.common_settings.materials_settings.skip_material_loading.get() == True\n\n    # Reset setting (2 lines below are equivalent).\n    renderer_setting.reset_setting(path=\"/app/renderer/skipMaterialLoading\")\n    renderer_setting.common_settings.materials_settings.skip_material_loading.reset()\n    assert renderer_setting.get_setting_from_path(path=\"/app/renderer/skipMaterialLoading\") == False\n\n    # Set setting to an unallowed value using top-level method.\n    # Examples below will use the \"top-level\" setting method.\n    try:\n        renderer_setting.set_setting(path=\"/app/renderer/skipMaterialLoading\", value=\"foo\")\n    except AssertionError as e:\n        print(e)  # All good. We got an AssertionError.\n\n    # Set setting to a value out-of-range.\n    try:\n        renderer_setting.set_setting(path=\"/rtx/fog/fogColorIntensity\", value=0.0)\n    except AssertionError as e:\n        print(e)  # All good. We got an AssertionError.\n\n    # Set unallowed setting.\n    try:\n        renderer_setting.set_setting(path=\"foo\", value=\"bar\")\n    except NotImplementedError as e:\n        print(e)  # All good. We got a NotImplementedError.\n\n    # Set setting but the setting group is not enabled.\n    # Setting is successful but there will be a warning message printed.\n    renderer_setting.set_setting(path=\"/rtx/fog/fogColorIntensity\", value=1.0)\n\n    # Shutdown sim\n    input(\"Completed demo. Press [ENTER] to shutdown simulation.\")\n    og.shutdown()\n</code></pre>","location":"reference/examples/renderer_settings/renderer_settings_example.html#examples.renderer_settings.renderer_settings_example.main"},{"title":"robots","text":"","location":"reference/examples/robots/index.html"},{"title":"all_robots_visualizer","text":"","location":"reference/examples/robots/all_robots_visualizer.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Robot demo Loads all robots in an empty scene, generate random actions</p>  Source code in <code>examples/robots/all_robots_visualizer.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Robot demo\n    Loads all robots in an empty scene, generate random actions\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n    # Create empty scene with no robots in it initially\n    cfg = {\n        \"scene\": {\n            \"type\": \"Scene\",\n        }\n    }\n\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Iterate over all robots and demo their motion\n    for robot_name, robot_cls in REGISTERED_ROBOTS.items():\n        # Create and import robot\n        robot = robot_cls(\n            prim_path=f\"/World/{robot_name}\",\n            name=robot_name,\n            obs_modalities=[],              # We're just moving robots around so don't load any observation modalities\n        )\n        og.sim.import_object(robot)\n\n        # At least one step is always needed while sim is playing for any imported object to be fully initialized\n        og.sim.play()\n        og.sim.step()\n\n        # Reset robot and make sure it's not moving\n        robot.reset()\n        robot.keep_still()\n\n        # Log information\n        logging.info(f\"Loaded {robot_name}\")\n        logging.info(f\"Moving {robot_name}\")\n\n        if not headless:\n            # Set viewer in front facing robot\n            og.sim.viewer_camera.set_position_orientation(\n                position=np.array([ 2.69918369, -3.63686664,  4.57894564]),\n                orientation=np.array([0.39592411, 0.1348514 , 0.29286304, 0.85982   ]),\n            )\n\n        og.sim.enable_viewer_camera_teleoperation()\n\n        # Hold still briefly so viewer can see robot\n        for _ in range(100):\n            og.sim.step()\n\n        # Then apply random actions for a bit\n        for _ in range(30):\n            action = np.random.uniform(-1, 1, robot.action_dim)\n            for _ in range(10):\n                env.step(action)\n\n        # Re-import the scene\n        og.sim.stop()\n        og.sim.import_scene(Scene())\n\n    # Always shut down the environment cleanly at the end\n    env.close()\n</code></pre>","location":"reference/examples/robots/all_robots_visualizer.html#examples.robots.all_robots_visualizer.main"},{"title":"grasping_mode_example","text":"<p>Example script demo'ing robot manipulation control with grasping.</p>","location":"reference/examples/robots/grasping_mode_example.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Robot grasping mode demo with selection Queries the user to select a type of grasping mode and GUI</p>  Source code in <code>examples/robots/grasping_mode_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Robot grasping mode demo with selection\n    Queries the user to select a type of grasping mode and GUI\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose type of grasping\n    grasping_mode = choose_from_options(options=GRASPING_MODES, name=\"grasping mode\", random_selection=random_selection)\n\n    # Create environment configuration to use\n    scene_cfg = OrderedDict(type=\"Scene\")\n    robot0_cfg = OrderedDict(\n        type=\"Fetch\",\n        obs_modalities=[\"rgb\"],     # we're just doing a grasping demo so we don't need all observation modalities\n        action_type=\"continuous\",\n        action_normalize=True,\n        grasping_mode=grasping_mode,\n    )\n\n    # Define objects to load\n    table_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"table\",\n        category=\"breakfast_table\",\n        model=\"1b4e6f9dd22a8c628ef9d976af675b86\",\n        bounding_box=[0.5, 0.5, 0.8],\n        fit_avg_dim_volume=False,\n        fixed_base=True,\n        position=[0.7, -0.1, 0.6],\n        orientation=[0, 0, 0.707, 0.707],\n    )\n\n    chair_cfg = OrderedDict(\n        type=\"DatasetObject\",\n        name=\"chair\",\n        category=\"straight_chair\",\n        model=\"2a8d87523e23a01d5f40874aec1ee3a6\",\n        bounding_box=None,\n        fit_avg_dim_volume=True,\n        fixed_base=False,\n        position=[0.45, 0.65, 0.425],\n        orientation=[0, 0, -0.9990215, -0.0442276],\n    )\n\n    box_cfg = OrderedDict(\n        type=\"PrimitiveObject\",\n        name=\"box\",\n        primitive_type=\"Cube\",\n        rgba=[1.0, 0, 0, 1.0],\n        size=0.05,\n        position=[0.53, -0.1, 0.97],\n    )\n\n    # Compile config\n    cfg = OrderedDict(scene=scene_cfg, robots=[robot0_cfg], objects=[table_cfg, chair_cfg, box_cfg])\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Reset the robot\n    robot = env.robots[0]\n    robot.set_position([0, 0, 0])\n    robot.reset()\n    robot.keep_still()\n\n    # Update the simulator's viewer camera's pose so it points towards the robot\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([-2.39951,  2.26469,  2.66227]),\n        orientation=np.array([-0.23898481,  0.48475231,  0.75464013, -0.37204802]),\n    )\n\n    # Create teleop controller\n    action_generator = KeyboardRobotController(robot=robot)\n\n    # Print out relevant keyboard info if using keyboard teleop\n    action_generator.print_keyboard_teleop_info()\n\n    # Other helpful user info\n    print(\"Running demo with grasping mode {}.\".format(grasping_mode))\n    print(\"Press ESC to quit\")\n\n    # Loop control until user quits\n    max_steps = -1 if not short_exec else 100\n    step = 0\n    while step != max_steps:\n        action = action_generator.get_random_action() if random_selection else action_generator.get_teleop_action()\n        for _ in range(10):\n            env.step(action)\n            step += 1\n\n    # Always shut down the environment cleanly at the end\n    env.close()\n</code></pre>","location":"reference/examples/robots/grasping_mode_example.html#examples.robots.grasping_mode_example.main"},{"title":"robot_control_example","text":"<p>Example script demo'ing robot control.</p> <p>Options for random actions, as well as selection of robot action space</p>","location":"reference/examples/robots/robot_control_example.html"},{"title":"<code>choose_controllers(robot, random_selection=False)</code>","text":"<p>For a given robot, iterates over all components of the robot, and returns the requested controller type for each component.</p> <p>:param robot: BaseRobot, robot class from which to infer relevant valid controller options :param random_selection: bool, if the selection is random (for automatic demo execution). Default False</p> <p>:return OrderedDict: Mapping from individual robot component (e.g.: base, arm, etc.) to selected controller names</p>  Source code in <code>examples/robots/robot_control_example.py</code> <pre><code>def choose_controllers(robot, random_selection=False):\n    \"\"\"\n    For a given robot, iterates over all components of the robot, and returns the requested controller type for each\n    component.\n\n    :param robot: BaseRobot, robot class from which to infer relevant valid controller options\n    :param random_selection: bool, if the selection is random (for automatic demo execution). Default False\n\n    :return OrderedDict: Mapping from individual robot component (e.g.: base, arm, etc.) to selected controller names\n    \"\"\"\n    # Create new dict to store responses from user\n    controller_choices = OrderedDict()\n\n    # Grab the default controller config so we have the registry of all possible controller options\n    default_config = robot._default_controller_config\n\n    # Iterate over all components in robot\n    for component, controller_options in default_config.items():\n        # Select controller\n        options = list(sorted(controller_options.keys()))\n        choice = choose_from_options(\n            options=options, name=\"{} controller\".format(component), random_selection=random_selection\n        )\n\n        # Add to user responses\n        controller_choices[component] = choice\n\n    return controller_choices\n</code></pre>","location":"reference/examples/robots/robot_control_example.html#examples.robots.robot_control_example.choose_controllers"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Robot control demo with selection Queries the user to select a robot, the controllers, a scene and a type of input (random actions or teleop)</p>  Source code in <code>examples/robots/robot_control_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Robot control demo with selection\n    Queries the user to select a robot, the controllers, a scene and a type of input (random actions or teleop)\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose scene to load\n    scene_model = choose_from_options(options=SCENES, name=\"scene\", random_selection=random_selection)\n\n    # Choose robot to create\n    robot_name = choose_from_options(\n        options=list(sorted(REGISTERED_ROBOTS.keys())), name=\"robot\", random_selection=random_selection\n    )\n\n    # Create the config for generating the environment we want\n    scene_cfg = OrderedDict()\n    if scene_model == \"empty\":\n        scene_cfg[\"type\"] = \"Scene\"\n    else:\n        scene_cfg[\"type\"] = \"InteractiveTraversableScene\"\n        scene_cfg[\"scene_model\"] = scene_model\n\n    # Add the robot we want to load\n    robot0_cfg = OrderedDict()\n    robot0_cfg[\"type\"] = robot_name\n    robot0_cfg[\"obs_modalities\"] = [\"rgb\", \"depth\", \"seg_instance\", \"normal\", \"scan\", \"occupancy_grid\"]\n    robot0_cfg[\"action_type\"] = \"continuous\"\n    robot0_cfg[\"action_normalize\"] = True\n\n    # Compile config\n    cfg = OrderedDict(scene=scene_cfg, robots=[robot0_cfg])\n\n    # Create the environment\n    env = og.Environment(configs=cfg, action_timestep=1/60., physics_timestep=1/60.)\n\n    # Choose robot controller to use\n    robot = env.robots[0]\n    controller_choices = choose_controllers(robot=robot, random_selection=random_selection)\n\n    # Choose control mode\n    if random_selection:\n        control_mode = \"random\"\n    else:\n        control_mode = choose_from_options(options=CONTROL_MODES, name=\"control mode\")\n\n    # Update the control mode of the robot\n    controller_config = {component: {\"name\": name} for component, name in controller_choices.items()}\n    robot.reload_controllers(controller_config=controller_config)\n\n    # Update the simulator's viewer camera's pose so it points towards the robot\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([1.46949, -3.97358, 2.21529]),\n        orientation=np.array([0.56829048, 0.09569975, 0.13571846, 0.80589577]),\n    )\n\n    # Reset environment\n    env.reset()\n\n    # Create teleop controller\n    action_generator = KeyboardRobotController(robot=robot)\n\n    # Print out relevant keyboard info if using keyboard teleop\n    if control_mode == \"teleop\":\n        action_generator.print_keyboard_teleop_info()\n\n    # Other helpful user info\n    print(\"Running demo.\")\n    print(\"Press ESC to quit\")\n\n    # Loop control until user quits\n    max_steps = -1 if not short_exec else 100\n    step = 0\n    while step != max_steps:\n        action = action_generator.get_random_action() if control_mode == \"random\" else action_generator.get_teleop_action()\n        for _ in range(10):\n            env.step(action=action)\n            step += 1\n\n    # Always shut down the environment cleanly at the end\n    env.close()\n</code></pre>","location":"reference/examples/robots/robot_control_example.html#examples.robots.robot_control_example.main"},{"title":"advanced","text":"","location":"reference/examples/robots/advanced/index.html"},{"title":"ik_example","text":"","location":"reference/examples/robots/advanced/ik_example.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Minimal example of usage of inverse kinematics solver</p> <p>This example showcases how to construct your own IK functionality using omniverse's native lula library without explicitly utilizing all of OmniGibson's class abstractions, and also showcases how to manipulate the simulator at a lower-level than the main Environment entry point.</p>  Source code in <code>examples/robots/advanced/ik_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Minimal example of usage of inverse kinematics solver\n\n    This example showcases how to construct your own IK functionality using omniverse's native lula library\n    without explicitly utilizing all of OmniGibson's class abstractions, and also showcases how to manipulate\n    the simulator at a lower-level than the main Environment entry point.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Assuming that if random_selection=True, headless=True, short_exec=True, we are calling it from tests and we\n    # do not want to parse args (it would fail because the calling function is pytest \"testfile.py\")\n    if not (random_selection and headless and short_exec):\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            \"--programmatic\",\n            \"-p\",\n            dest=\"programmatic_pos\",\n            action=\"store_true\",\n            help=\"if the IK solvers should be used with the GUI or programmatically\",\n        )\n        args = parser.parse_args()\n        programmatic_pos = args.programmatic_pos\n    else:\n        programmatic_pos = True\n\n    # Import scene and robot (Fetch)\n    scene = Scene()\n    og.sim.import_scene(scene)\n\n    # Update the viewer camera's pose so that it points towards the robot\n    og.sim.viewer_camera.set_position_orientation(\n        position=np.array([4.32248, -5.74338, 6.85436]),\n        orientation=np.array([0.39592, 0.13485, 0.29286, 0.85982]),\n    )\n\n    # Create Fetch robot\n    # Note that since we only care about IK functionality, we fix the base (this also makes the robot more stable)\n    # (any object can also have its fixed_base attribute set to True!)\n    # Note that since we're going to be setting joint position targets, we also need to make sure the robot's arm joints\n    # (which includes the trunk) are being controlled using joint positions\n    robot = Fetch(\n        prim_path=\"/World/robot\",\n        name=\"robot\",\n        fixed_base=True,\n        controller_config={\n            \"arm_0\": {\n                \"name\": \"JointController\",\n                \"motor_type\": \"position\",\n            }\n        }\n    )\n    og.sim.import_object(robot)\n\n    # Set robot base at the origin\n    robot.set_position_orientation(np.array([0, 0, 0]), np.array([0, 0, 0, 1]))\n    # At least one simulation step while the simulator is playing must occur for the robot (or in general, any object)\n    # to be fully initialized after it is imported into the simulator\n    og.sim.play()\n    og.sim.step()\n    # Make sure none of the joints are moving\n    robot.keep_still()\n\n    # Create the IK solver -- note that we are controlling both the trunk and the arm since both are part of the\n    # controllable kinematic chain for the end-effector!\n    control_idx = np.concatenate([robot.trunk_control_idx, robot.arm_control_idx[robot.default_arm]])\n    ik_solver = IKSolver(\n        robot_description_path=robot.robot_arm_descriptor_yamls[robot.default_arm],\n        robot_urdf_path=robot.urdf_path,\n        default_joint_pos=robot.get_joint_positions()[control_idx],\n        eef_name=robot.eef_link_names[robot.default_arm],\n    )\n\n    # Define a helper function for executing specific end-effector commands using the ik solver\n    def execute_ik(pos, quat=None, max_iter=100):\n        logging.info(\"Querying joint configuration to current marker position\")\n        # Grab the joint positions in order to reach the desired pose target\n        joint_pos = ik_solver.solve(\n            target_pos=pos,\n            target_quat=quat,\n            max_iterations=max_iter,\n        )\n        if joint_pos is not None:\n            logging.info(\"Solution found. Setting new arm configuration.\")\n            robot.set_joint_positions(joint_pos, indices=control_idx, target=True)\n        else:\n            logging.info(\"EE position not reachable.\")\n        og.sim.step()\n\n    if programmatic_pos or headless:\n        # Sanity check IK using pre-defined hardcoded positions\n        query_positions = [[1, 0, 0.8], [1, 1, 1], [0.5, 0.5, 0], [0.5, 0.5, 0.5]]\n        for query_pos in query_positions:\n            execute_ik(query_pos)\n            time.sleep(2)\n    else:\n        # Create a visual marker to be moved by the user, representing desired end-effector position\n        marker = PrimitiveObject(\n            prim_path=f\"/World/marker\",\n            name=\"marker\",\n            primitive_type=\"Sphere\",\n            radius=0.03,\n            visual_only=True,\n            rgba=[1.0, 0, 0, 1.0],\n        )\n        og.sim.import_object(marker)\n\n        # Get initial EE position and set marker to that location\n        command = robot.get_eef_position()\n        marker.set_position(command)\n        og.sim.step()\n\n        # Setup callbacks for grabbing keyboard inputs from omni\n        exit_now = False\n\n        def keyboard_event_handler(event, *args, **kwargs):\n            nonlocal command, exit_now\n            # Check if we've received a key press or repeat\n            if event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                    or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\n                if event.input == carb.input.KeyboardInput.ENTER:\n                    # Execute the command\n                    execute_ik(pos=command)\n                elif event.input == carb.input.KeyboardInput.ESCAPE:\n                    # Quit\n                    logging.info(\"Quit.\")\n                    exit_now = True\n                else:\n                    # We see if we received a valid delta command, and if so, we update our command and visualized\n                    # marker position\n                    delta_cmd = input_to_xyz_delta_command(inp=event.input)\n                    if delta_cmd is not None:\n                        command = command + delta_cmd\n                        marker.set_position(command)\n                        og.sim.step()\n\n            # Callback must return True if valid\n            return True\n\n        # Hook up the callback function with omni's user interface\n        appwindow = omni.appwindow.get_default_app_window()\n        input_interface = carb.input.acquire_input_interface()\n        keyboard = appwindow.get_keyboard()\n        sub_keyboard = input_interface.subscribe_to_keyboard_events(keyboard, keyboard_event_handler)\n\n        # Print out helpful information to the user\n        print_message()\n\n        # Loop until the user requests an exit\n        while not exit_now:\n            og.sim.step()\n\n    # Always shut the simulation down cleanly at the end\n    og.app.close()\n</code></pre>","location":"reference/examples/robots/advanced/ik_example.html#examples.robots.advanced.ik_example.main"},{"title":"scenes","text":"","location":"reference/examples/scenes/index.html"},{"title":"scene_selector","text":"","location":"reference/examples/scenes/scene_selector.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select any available non-interactive scene and loads a turtlebot into it. It steps the environment 100 times with random actions sampled from the action space, using the Gym interface, resetting it 10 times.</p>  Source code in <code>examples/scenes/scene_selector.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select any available non-interactive scene and loads a turtlebot into it.\n    It steps the environment 100 times with random actions sampled from the action space,\n    using the Gym interface, resetting it 10 times.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    # Choose the scene type to load\n    scene_options = {\n        \"InteractiveTraversableScene\": \"Procedurally generated scene with fully interactive objects\",\n        \"StaticTraversableScene\": \"Monolithic scene mesh with no interactive objects\",\n    }\n    scene_type = choose_from_options(options=scene_options, name=\"scene type\", random_selection=random_selection)\n\n    # Choose the scene model to load\n    scenes = get_available_og_scenes() if scene_type == \"InteractiveTraversableScene\" else get_available_g_scenes()\n    scene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\n    print(f\"scene model: {scene_model}\")\n\n    cfg = {\n        \"scene\": {\n            \"type\": scene_type,\n            \"scene_model\": scene_model,\n        },\n        \"robots\": [\n            {\n                \"type\": \"Turtlebot\",\n                \"obs_modalities\": [\"scan\", \"rgb\", \"depth\"],\n                \"action_type\": \"continuous\",\n                \"action_normalize\": True,\n            }\n        ],\n    }\n\n    # If the scene type is interactive, also check if we want to quick load or full load the scene\n    if scene_type == \"InteractiveTraversableScene\":\n        load_options = {\n            \"Quick\": \"Only load the building assets (i.e.: the floors, walls, ceilings)\",\n            \"Full\": \"Load all interactive objects in the scene\",\n        }\n        load_mode = choose_from_options(options=load_options, name=\"load mode\", random_selection=random_selection)\n        if load_mode == \"Quick\":\n            cfg[\"scene\"][\"load_object_categories\"] = [\"floors\", \"walls\", \"ceilings\"]\n\n    # Load the environment\n    env = og.Environment(configs=cfg)\n\n    # Allow user to move camera more easily\n    if not headless:\n        og.sim.enable_viewer_camera_teleoperation()\n\n    # Run a simple loop and reset periodically\n    max_iterations = 10 if not short_exec else 1\n    for j in range(max_iterations):\n        logging.info(\"Resetting environment\")\n        env.reset()\n        for i in range(100):\n            action = env.action_space.sample()\n            state, reward, done, info = env.step(action)\n            if done:\n                logging.info(\"Episode finished after {} timesteps\".format(i + 1))\n                break\n\n    # Always close the environment at the end\n    env.close()\n</code></pre>","location":"reference/examples/scenes/scene_selector.html#examples.scenes.scene_selector.main"},{"title":"traversability_map_example","text":"","location":"reference/examples/scenes/traversability_map_example.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Traversable map demo Loads the floor plan and obstacles for the requested scene, and overlays them in a visual figure such that the highlighted area reflects the traversable (free-space) area</p>  Source code in <code>examples/scenes/traversability_map_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Traversable map demo\n    Loads the floor plan and obstacles for the requested scene, and overlays them in a visual figure such that the\n    highlighted area reflects the traversable (free-space) area\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    scenes = get_available_og_scenes()\n    scene_model = choose_from_options(options=scenes, name=\"scene model\", random_selection=random_selection)\n    print(f\"Generating traversability map for scene {scene_model}\")\n\n    trav_map_size = 200\n    trav_map_erosion = 2\n\n    trav_map = Image.open(os.path.join(get_og_scene_path(scene_model), \"layout\", \"floor_trav_0.png\"))\n    trav_map = np.array(trav_map.resize((trav_map_size, trav_map_size)))\n    trav_map = cv2.erode(trav_map, np.ones((trav_map_erosion, trav_map_erosion)))\n\n    if not headless:\n        plt.figure(figsize=(12, 12))\n        plt.imshow(trav_map)\n        plt.title(f\"Traversable area of {scene_model} scene\")\n\n    if not headless:\n        plt.show()\n</code></pre>","location":"reference/examples/scenes/traversability_map_example.html#examples.scenes.traversability_map_example.main"},{"title":"simulator","text":"","location":"reference/examples/simulator/index.html"},{"title":"sim_save_load_example","text":"","location":"reference/examples/simulator/sim_save_load_example.html"},{"title":"<code>main(random_selection=False, headless=False, short_exec=False)</code>","text":"<p>Prompts the user to select whether they are saving or loading an environment, and interactively shows how an environment can be saved or restored.</p>  Source code in <code>examples/simulator/sim_save_load_example.py</code> <pre><code>def main(random_selection=False, headless=False, short_exec=False):\n    \"\"\"\n    Prompts the user to select whether they are saving or loading an environment, and interactively\n    shows how an environment can be saved or restored.\n    \"\"\"\n    logging.info(\"*\" * 80 + \"\\nDescription:\" + main.__doc__ + \"*\" * 80)\n\n    cfg = {\n        \"scene\": {\n            \"type\": \"InteractiveTraversableScene\",\n            \"scene_model\": \"Rs_int\",\n            \"load_object_categories\": [\"floors\", \"walls\", \"bed\", \"bottom_cabinet\", \"chair\"],\n        },\n        \"robots\": [\n            {\n                \"type\": \"Turtlebot\",\n                \"obs_modalities\": [\"rgb\", \"depth\"],\n            },\n        ],\n    }\n\n    # Create the environment\n    env = og.Environment(configs=cfg)\n\n    # Set the camera to a good angle\n    def set_camera_pose():\n        og.sim.viewer_camera.set_position_orientation(\n            position=np.array([-0.229375, -3.40576 ,  7.26143 ]),\n            orientation=np.array([ 0.27619733, -0.00230233, -0.00801152,  0.9610648 ]),\n        )\n    set_camera_pose()\n\n    # Give user instructions, and then loop until completed\n    completed = short_exec\n    if not short_exec and not random_selection:\n        # Notify user to manipulate environment until ready, then press Z to exit\n        print()\n        print(\"Modify the scene by SHIFT + left clicking objects and dragging them. Once finished, press Z.\")\n        # Register callback so user knows to press space once they're done manipulating the scene\n        def complete_loop():\n            nonlocal completed\n            completed = True\n        KeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\n    while not completed:\n        env.step(np.random.uniform(-1, 1, env.robots[0].action_dim))\n\n    print(\"Completed scene modification, saving scene...\")\n    save_path = os.path.join(TEST_OUT_PATH, \"saved_stage.json\")\n    og.sim.save(json_path=save_path)\n\n    print(\"Re-loading scene...\")\n    og.sim.restore(json_path=save_path)\n\n    # Take a sim step and play\n    og.sim.step()\n    og.sim.play()\n    set_camera_pose()\n\n    # Loop until user terminates\n    completed = short_exec\n    if not short_exec and not random_selection:\n        # Notify user to manipulate environment until ready, then press Z to exit\n        print()\n        print(\"View reloaded scene. Once finished, press Z.\")\n        # Register callback so user knows to press space once they're done manipulating the scene\n        KeyboardEventHandler.add_keyboard_callback(carb.input.KeyboardInput.Z, complete_loop)\n    while not completed:\n        env.step(np.zeros(env.robots[0].action_dim))\n\n    # Shutdown omnigibson at the end\n    og.shutdown()\n</code></pre>","location":"reference/examples/simulator/sim_save_load_example.html#examples.simulator.sim_save_load_example.main"},{"title":"maps","text":"","location":"reference/maps/index.html"},{"title":"map_base","text":"","location":"reference/maps/map_base.html"},{"title":"<code>BaseMap</code>","text":"<p>Base map class. Contains basic interface for converting from map to world frame, and vise-versa</p>  Source code in <code>maps/map_base.py</code> <pre><code>class BaseMap:\n    \"\"\"\n    Base map class.\n    Contains basic interface for converting from map to world frame, and vise-versa\n    \"\"\"\n\n    def __init__(\n            self,\n            map_resolution=0.1,\n    ):\n        \"\"\"\n        Args:\n            map_resolution (float): map resolution\n        \"\"\"\n        # Set internal values\n        self.map_resolution = map_resolution\n        self.map_size = None\n\n    def load_map(self, *args, **kwargs):\n        \"\"\"\n        Load's this map internally\n        \"\"\"\n        # Run internal method and store map size\n        self.map_size = self._load_map(*args, **kwargs)\n\n    def _load_map(self, *args, **kwargs):\n        \"\"\"\n        Arbitrary function to load this map. Should be implemented by subclass\n\n        Returns:\n            int: Size of the loaded map\n        \"\"\"\n        raise NotImplementedError()\n\n    def map_to_world(self, xy):\n        \"\"\"\n        Transforms a 2D point in map reference frame into world (simulator) reference frame\n\n        Args:\n            xy (2-array or (N, 2)-array): 2D location(s) in map reference frame (in image pixel space)\n\n        Returns:\n            2-array or (N, 2)-array: 2D location(s) in world reference frame (in metric space)\n        \"\"\"\n        axis = 0 if len(xy.shape) == 1 else 1\n        return np.flip((xy - self.map_size / 2.0) * self.map_resolution, axis=axis)\n\n    def world_to_map(self, xy):\n        \"\"\"\n        Transforms a 2D point in world (simulator) reference frame into map reference frame\n\n            xy: 2D location in world reference frame (metric)\n        :return: 2D location in map reference frame (image)\n        \"\"\"\n        return np.flip((np.array(xy) / self.map_resolution + self.map_size / 2.0)).astype(np.int)\n</code></pre>","location":"reference/maps/map_base.html#maps.map_base.BaseMap"},{"title":"<code>__init__(map_resolution=0.1)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>map_resolution</code>  <code>float</code>  <p>map resolution</p>  <code>0.1</code>      Source code in <code>maps/map_base.py</code> <pre><code>def __init__(\n        self,\n        map_resolution=0.1,\n):\n    \"\"\"\n    Args:\n        map_resolution (float): map resolution\n    \"\"\"\n    # Set internal values\n    self.map_resolution = map_resolution\n    self.map_size = None\n</code></pre>","location":"reference/maps/map_base.html#maps.map_base.BaseMap.__init__"},{"title":"<code>load_map(*args, **kwargs)</code>","text":"<p>Load's this map internally</p>  Source code in <code>maps/map_base.py</code> <pre><code>def load_map(self, *args, **kwargs):\n    \"\"\"\n    Load's this map internally\n    \"\"\"\n    # Run internal method and store map size\n    self.map_size = self._load_map(*args, **kwargs)\n</code></pre>","location":"reference/maps/map_base.html#maps.map_base.BaseMap.load_map"},{"title":"<code>map_to_world(xy)</code>","text":"<p>Transforms a 2D point in map reference frame into world (simulator) reference frame</p> <p>Parameters:</p>    Name Type Description Default     <code>xy</code>  <code>2-array or (N, 2)-array</code>  <p>2D location(s) in map reference frame (in image pixel space)</p>  required     <p>Returns:</p>    Type Description       <p>2-array or (N, 2)-array: 2D location(s) in world reference frame (in metric space)</p>     Source code in <code>maps/map_base.py</code> <pre><code>def map_to_world(self, xy):\n    \"\"\"\n    Transforms a 2D point in map reference frame into world (simulator) reference frame\n\n    Args:\n        xy (2-array or (N, 2)-array): 2D location(s) in map reference frame (in image pixel space)\n\n    Returns:\n        2-array or (N, 2)-array: 2D location(s) in world reference frame (in metric space)\n    \"\"\"\n    axis = 0 if len(xy.shape) == 1 else 1\n    return np.flip((xy - self.map_size / 2.0) * self.map_resolution, axis=axis)\n</code></pre>","location":"reference/maps/map_base.html#maps.map_base.BaseMap.map_to_world"},{"title":"<code>world_to_map(xy)</code>","text":"<p>Transforms a 2D point in world (simulator) reference frame into map reference frame</p> <pre><code>xy: 2D location in world reference frame (metric)\n</code></pre> <p>:return: 2D location in map reference frame (image)</p>  Source code in <code>maps/map_base.py</code> <pre><code>def world_to_map(self, xy):\n    \"\"\"\n    Transforms a 2D point in world (simulator) reference frame into map reference frame\n\n        xy: 2D location in world reference frame (metric)\n    :return: 2D location in map reference frame (image)\n    \"\"\"\n    return np.flip((np.array(xy) / self.map_resolution + self.map_size / 2.0)).astype(np.int)\n</code></pre>","location":"reference/maps/map_base.html#maps.map_base.BaseMap.world_to_map"},{"title":"segmentation_map","text":"","location":"reference/maps/segmentation_map.html"},{"title":"<code>SegmentationMap</code>","text":"<p>         Bases: <code>BaseMap</code></p> <p>Segmentation map for computing connectivity within the scene</p>  Source code in <code>maps/segmentation_map.py</code> <pre><code>class SegmentationMap(BaseMap):\n    \"\"\"\n    Segmentation map for computing connectivity within the scene\n    \"\"\"\n\n    def __init__(\n        self,\n        scene_dir,\n        map_resolution=0.1,\n        floor_heights=(0.0,),\n    ):\n        \"\"\"\n        Args:\n            scene_dir (str): path to the scene directory from which segmentation info will be extracted\n            map_resolution (float): map resolution\n            floor_heights (list of float): heights of the floors for this segmentation map\n        \"\"\"\n        # Store internal values\n        self.scene_dir = scene_dir\n        self.map_default_resolution = 0.01\n        self.floor_heights = floor_heights\n\n        # Other values that will be loaded at runtime\n        self.room_sem_name_to_sem_id = None\n        self.room_sem_id_to_sem_name = None\n        self.room_ins_name_to_ins_id = None\n        self.room_ins_id_to_ins_name = None\n        self.room_sem_name_to_ins_name = None\n        self.room_ins_map = None\n        self.room_sem_map = None\n\n        # Run super call\n        super().__init__(map_resolution=map_resolution)\n\n        # Load the map\n        self.load_map()\n\n    def _load_map(self):\n        layout_dir = os.path.join(self.scene_dir, \"layout\")\n        room_seg_imgs = os.path.join(layout_dir, \"floor_insseg_0.png\")\n        img_ins = Image.open(room_seg_imgs)\n        room_seg_imgs = os.path.join(layout_dir, \"floor_semseg_0.png\")\n        img_sem = Image.open(room_seg_imgs)\n        height, width = img_ins.size\n        assert height == width, \"room seg map is not a square\"\n        assert img_ins.size == img_sem.size, \"semantic and instance seg maps have different sizes\"\n        map_size = int(height * self.map_default_resolution / self.map_resolution)\n        img_ins = np.array(img_ins.resize((map_size, map_size), Image.NEAREST))\n        img_sem = np.array(img_sem.resize((map_size, map_size), Image.NEAREST))\n\n        room_categories = os.path.join(og.og_dataset_path, \"metadata\", \"room_categories.txt\")\n        with open(room_categories, \"r\") as fp:\n            room_cats = [line.rstrip() for line in fp.readlines()]\n\n        sem_id_to_ins_id = {}\n        unique_ins_ids = np.unique(img_ins)\n        unique_ins_ids = np.delete(unique_ins_ids, 0)\n        for ins_id in unique_ins_ids:\n            # find one pixel for each ins id\n            x, y = np.where(img_ins == ins_id)\n            # retrieve the correspounding sem id\n            sem_id = img_sem[x[0], y[0]]\n            if sem_id not in sem_id_to_ins_id:\n                sem_id_to_ins_id[sem_id] = []\n            sem_id_to_ins_id[sem_id].append(ins_id)\n\n        room_sem_name_to_sem_id = {}\n        room_ins_name_to_ins_id = {}\n        room_sem_name_to_ins_name = {}\n        for sem_id, ins_ids in sem_id_to_ins_id.items():\n            sem_name = room_cats[sem_id - 1]\n            room_sem_name_to_sem_id[sem_name] = sem_id\n            for i, ins_id in enumerate(ins_ids):\n                # valid class start from 1\n                ins_name = \"{}_{}\".format(sem_name, i)\n                room_ins_name_to_ins_id[ins_name] = ins_id\n                if sem_name not in room_sem_name_to_ins_name:\n                    room_sem_name_to_ins_name[sem_name] = []\n                room_sem_name_to_ins_name[sem_name].append(ins_name)\n\n        self.room_sem_name_to_sem_id = room_sem_name_to_sem_id\n        self.room_sem_id_to_sem_name = {value: key for key, value in room_sem_name_to_sem_id.items()}\n        self.room_ins_name_to_ins_id = room_ins_name_to_ins_id\n        self.room_ins_id_to_ins_name = {value: key for key, value in room_ins_name_to_ins_id.items()}\n        self.room_sem_name_to_ins_name = room_sem_name_to_ins_name\n        self.room_ins_map = img_ins\n        self.room_sem_map = img_sem\n\n        return map_size\n\n    def get_random_point_by_room_type(self, room_type):\n        \"\"\"\n        Sample a random point on the given a specific room type @room_type.\n\n        Args:\n            room_type (str): Room type to sample random point (e.g.: \"bathroom\")\n\n        Returns:\n            2-tuple:\n                - int: floor number. This is always 0\n                - 3-array: (x,y,z) randomly sampled point in a room of type @room_type\n        \"\"\"\n        if room_type not in self.room_sem_name_to_sem_id:\n            logging.warning(\"room_type [{}] does not exist.\".format(room_type))\n            return None, None\n\n        sem_id = self.room_sem_name_to_sem_id[room_type]\n        valid_idx = np.array(np.where(self.room_sem_map == sem_id))\n        random_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\n\n        x, y = self.map_to_world(random_point_map)\n        # assume only 1 floor\n        floor = 0\n        z = self.floor_heights[floor]\n        return floor, np.array([x, y, z])\n\n    def get_random_point_by_room_instance(self, room_instance):\n        \"\"\"\n        Sample a random point on the given a specific room instance @room_instance.\n\n        Args:\n            room_instance (str): Room instance to sample random point (e.g.: \"bathroom_1\")\n\n        Returns:\n            2-tuple:\n                - int: floor number. This is always 0\n                - 3-array: (x,y,z) randomly sampled point in room @room_instance\n        \"\"\"\n        if room_instance not in self.room_ins_name_to_ins_id:\n            logging.warning(\"room_instance [{}] does not exist.\".format(room_instance))\n            return None, None\n\n        ins_id = self.room_ins_name_to_ins_id[room_instance]\n        valid_idx = np.array(np.where(self.room_ins_map == ins_id))\n        random_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\n\n        x, y = self.map_to_world(random_point_map)\n        # assume only 1 floor\n        floor = 0\n        z = self.floor_heights[floor]\n        return floor, np.array([x, y, z])\n\n    def get_room_type_by_point(self, xy):\n        \"\"\"\n        Return the room type given a point\n\n        Args:\n            xy (2-array): 2D location in world reference frame (in metric space)\n\n        Returns:\n            None or str: room type that this point is in or None, if this point is not on the room segmentation map\n        \"\"\"\n        x, y = self.world_to_map(xy)\n        if x &lt; 0 or x &gt;= self.room_sem_map.shape[0] or y &lt; 0 or y &gt;= self.room_sem_map.shape[1]:\n            return None\n        sem_id = self.room_sem_map[x, y]\n        # room boundary\n        if sem_id == 0:\n            return None\n        else:\n            return self.room_sem_id_to_sem_name[sem_id]\n\n    def get_room_instance_by_point(self, xy):\n        \"\"\"\n        Return the room type given a point\n\n        Args:\n            xy (2-array): 2D location in world reference frame (in metric space)\n\n        Returns:\n            None or str: room instance that this point is in or None, if this point is not on the room segmentation map\n        \"\"\"\n        x, y = self.world_to_map(xy)\n        if x &lt; 0 or x &gt;= self.room_ins_map.shape[0] or y &lt; 0 or y &gt;= self.room_ins_map.shape[1]:\n            return None\n        ins_id = self.room_ins_map[x, y]\n        # room boundary\n        if ins_id == 0:\n            return None\n        else:\n            return self.room_ins_id_to_ins_name[ins_id]\n</code></pre>","location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap"},{"title":"<code>__init__(scene_dir, map_resolution=0.1, floor_heights=(0.0))</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>scene_dir</code>  <code>str</code>  <p>path to the scene directory from which segmentation info will be extracted</p>  required    <code>map_resolution</code>  <code>float</code>  <p>map resolution</p>  <code>0.1</code>    <code>floor_heights</code>  <code>list of float</code>  <p>heights of the floors for this segmentation map</p>  <code>(0.0)</code>      Source code in <code>maps/segmentation_map.py</code> <pre><code>def __init__(\n    self,\n    scene_dir,\n    map_resolution=0.1,\n    floor_heights=(0.0,),\n):\n    \"\"\"\n    Args:\n        scene_dir (str): path to the scene directory from which segmentation info will be extracted\n        map_resolution (float): map resolution\n        floor_heights (list of float): heights of the floors for this segmentation map\n    \"\"\"\n    # Store internal values\n    self.scene_dir = scene_dir\n    self.map_default_resolution = 0.01\n    self.floor_heights = floor_heights\n\n    # Other values that will be loaded at runtime\n    self.room_sem_name_to_sem_id = None\n    self.room_sem_id_to_sem_name = None\n    self.room_ins_name_to_ins_id = None\n    self.room_ins_id_to_ins_name = None\n    self.room_sem_name_to_ins_name = None\n    self.room_ins_map = None\n    self.room_sem_map = None\n\n    # Run super call\n    super().__init__(map_resolution=map_resolution)\n\n    # Load the map\n    self.load_map()\n</code></pre>","location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.__init__"},{"title":"<code>get_random_point_by_room_instance(room_instance)</code>","text":"<p>Sample a random point on the given a specific room instance @room_instance.</p> <p>Parameters:</p>    Name Type Description Default     <code>room_instance</code>  <code>str</code>  <p>Room instance to sample random point (e.g.: \"bathroom_1\")</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - int: floor number. This is always 0 - 3-array: (x,y,z) randomly sampled point in room @room_instance</p>     Source code in <code>maps/segmentation_map.py</code> <pre><code>def get_random_point_by_room_instance(self, room_instance):\n    \"\"\"\n    Sample a random point on the given a specific room instance @room_instance.\n\n    Args:\n        room_instance (str): Room instance to sample random point (e.g.: \"bathroom_1\")\n\n    Returns:\n        2-tuple:\n            - int: floor number. This is always 0\n            - 3-array: (x,y,z) randomly sampled point in room @room_instance\n    \"\"\"\n    if room_instance not in self.room_ins_name_to_ins_id:\n        logging.warning(\"room_instance [{}] does not exist.\".format(room_instance))\n        return None, None\n\n    ins_id = self.room_ins_name_to_ins_id[room_instance]\n    valid_idx = np.array(np.where(self.room_ins_map == ins_id))\n    random_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\n\n    x, y = self.map_to_world(random_point_map)\n    # assume only 1 floor\n    floor = 0\n    z = self.floor_heights[floor]\n    return floor, np.array([x, y, z])\n</code></pre>","location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_random_point_by_room_instance"},{"title":"<code>get_random_point_by_room_type(room_type)</code>","text":"<p>Sample a random point on the given a specific room type @room_type.</p> <p>Parameters:</p>    Name Type Description Default     <code>room_type</code>  <code>str</code>  <p>Room type to sample random point (e.g.: \"bathroom\")</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - int: floor number. This is always 0 - 3-array: (x,y,z) randomly sampled point in a room of type @room_type</p>     Source code in <code>maps/segmentation_map.py</code> <pre><code>def get_random_point_by_room_type(self, room_type):\n    \"\"\"\n    Sample a random point on the given a specific room type @room_type.\n\n    Args:\n        room_type (str): Room type to sample random point (e.g.: \"bathroom\")\n\n    Returns:\n        2-tuple:\n            - int: floor number. This is always 0\n            - 3-array: (x,y,z) randomly sampled point in a room of type @room_type\n    \"\"\"\n    if room_type not in self.room_sem_name_to_sem_id:\n        logging.warning(\"room_type [{}] does not exist.\".format(room_type))\n        return None, None\n\n    sem_id = self.room_sem_name_to_sem_id[room_type]\n    valid_idx = np.array(np.where(self.room_sem_map == sem_id))\n    random_point_map = valid_idx[:, np.random.randint(valid_idx.shape[1])]\n\n    x, y = self.map_to_world(random_point_map)\n    # assume only 1 floor\n    floor = 0\n    z = self.floor_heights[floor]\n    return floor, np.array([x, y, z])\n</code></pre>","location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_random_point_by_room_type"},{"title":"<code>get_room_instance_by_point(xy)</code>","text":"<p>Return the room type given a point</p> <p>Parameters:</p>    Name Type Description Default     <code>xy</code>  <code>2-array</code>  <p>2D location in world reference frame (in metric space)</p>  required     <p>Returns:</p>    Type Description       <p>None or str: room instance that this point is in or None, if this point is not on the room segmentation map</p>     Source code in <code>maps/segmentation_map.py</code> <pre><code>def get_room_instance_by_point(self, xy):\n    \"\"\"\n    Return the room type given a point\n\n    Args:\n        xy (2-array): 2D location in world reference frame (in metric space)\n\n    Returns:\n        None or str: room instance that this point is in or None, if this point is not on the room segmentation map\n    \"\"\"\n    x, y = self.world_to_map(xy)\n    if x &lt; 0 or x &gt;= self.room_ins_map.shape[0] or y &lt; 0 or y &gt;= self.room_ins_map.shape[1]:\n        return None\n    ins_id = self.room_ins_map[x, y]\n    # room boundary\n    if ins_id == 0:\n        return None\n    else:\n        return self.room_ins_id_to_ins_name[ins_id]\n</code></pre>","location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_room_instance_by_point"},{"title":"<code>get_room_type_by_point(xy)</code>","text":"<p>Return the room type given a point</p> <p>Parameters:</p>    Name Type Description Default     <code>xy</code>  <code>2-array</code>  <p>2D location in world reference frame (in metric space)</p>  required     <p>Returns:</p>    Type Description       <p>None or str: room type that this point is in or None, if this point is not on the room segmentation map</p>     Source code in <code>maps/segmentation_map.py</code> <pre><code>def get_room_type_by_point(self, xy):\n    \"\"\"\n    Return the room type given a point\n\n    Args:\n        xy (2-array): 2D location in world reference frame (in metric space)\n\n    Returns:\n        None or str: room type that this point is in or None, if this point is not on the room segmentation map\n    \"\"\"\n    x, y = self.world_to_map(xy)\n    if x &lt; 0 or x &gt;= self.room_sem_map.shape[0] or y &lt; 0 or y &gt;= self.room_sem_map.shape[1]:\n        return None\n    sem_id = self.room_sem_map[x, y]\n    # room boundary\n    if sem_id == 0:\n        return None\n    else:\n        return self.room_sem_id_to_sem_name[sem_id]\n</code></pre>","location":"reference/maps/segmentation_map.html#maps.segmentation_map.SegmentationMap.get_room_type_by_point"},{"title":"traversable_map","text":"","location":"reference/maps/traversable_map.html"},{"title":"<code>TraversableMap</code>","text":"<p>         Bases: <code>BaseMap</code></p> <p>Traversable scene class. Contains the functionalities for navigation such as shortest path computation</p>  Source code in <code>maps/traversable_map.py</code> <pre><code>class TraversableMap(BaseMap):\n    \"\"\"\n    Traversable scene class.\n    Contains the functionalities for navigation such as shortest path computation\n    \"\"\"\n\n    def __init__(\n        self,\n        map_resolution=0.1,\n        trav_map_erosion=2,\n        trav_map_with_objects=True,\n        build_graph=True,\n        num_waypoints=10,\n        waypoint_resolution=0.2,\n    ):\n        \"\"\"\n        Args:\n            map_resolution (float): map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n        \"\"\"\n        # Set internal values\n        self.map_default_resolution = 0.01  # each pixel represents 0.01m\n        self.trav_map_erosion = trav_map_erosion\n        self.trav_map_with_objects = trav_map_with_objects\n        self.build_graph = build_graph\n        self.num_waypoints = num_waypoints\n        self.waypoint_interval = int(waypoint_resolution / map_resolution)\n\n        # Values loaded at runtime\n        self.trav_map_original_size = None\n        self.trav_map_size = None\n        self.mesh_body_id = None\n        self.floor_heights = None\n        self.floor_map = None\n        self.floor_graph = None\n\n        # Run super method\n        super().__init__(map_resolution=map_resolution)\n\n    def _load_map(self, maps_path, floor_heights=(0.0,)):\n        \"\"\"\n        Loads the traversability maps for all floors\n\n        Args:\n            maps_path (str): Path to the folder containing the traversability maps\n            floor_heights (n-array): Height(s) of the floors for this map\n\n        Returns:\n            int: Size of the loaded map\n        \"\"\"\n        if not os.path.exists(maps_path):\n            logging.warning(\"trav map does not exist: {}\".format(maps_path))\n            return\n\n        self.floor_heights = floor_heights\n        self.floor_map = []\n        map_size = None\n        for floor in range(len(self.floor_heights)):\n            if self.trav_map_with_objects:\n                # TODO: Shouldn't this be generated dynamically?\n                trav_map = np.array(Image.open(os.path.join(maps_path, \"floor_trav_{}.png\".format(floor))))\n            else:\n                trav_map = np.array(Image.open(os.path.join(maps_path, \"floor_trav_no_obj_{}.png\".format(floor))))\n\n            # If we do not initialize the original size of the traversability map, we obtain it from the image\n            # Then, we compute the final map size as the factor of scaling (default_resolution/resolution) times the\n            # original map size\n            if self.trav_map_original_size is None:\n                height, width = trav_map.shape\n                assert height == width, \"trav map is not a square\"\n                self.trav_map_original_size = height\n                map_size = int(\n                    self.trav_map_original_size * self.map_default_resolution / self.map_resolution\n                )\n\n            # We resize the traversability map to the new size computed before\n            trav_map = cv2.resize(trav_map, (map_size, map_size))\n\n            # We then erode the image. This is needed because the code that computes shortest path uses the global map\n            # and a point robot\n            if self.trav_map_erosion != 0:\n                trav_map = cv2.erode(trav_map, np.ones((self.trav_map_erosion, self.trav_map_erosion)))\n\n            # We make the pixels of the image to be either 0 or 255\n            trav_map[trav_map &lt; 255] = 0\n\n            # We search for the largest connected areas\n            if self.build_graph:\n                # Directly set map siz\n                self.floor_graph = self.build_trav_graph(map_size, maps_path, floor, trav_map)\n\n            self.floor_map.append(trav_map)\n\n        return map_size\n\n    # TODO: refactor into C++ for speedup\n    @staticmethod\n    def build_trav_graph(map_size, maps_path, floor, trav_map):\n        \"\"\"\n        Build traversibility graph and only take the largest connected component\n\n        Args:\n            map_size (int): Size of the map being generated\n            maps_path (str): Path to the folder containing the traversability maps\n            floor (int): floor number\n            trav_map ((H, W)-array): traversability map in image form\n        \"\"\"\n        floor_graph = []\n        graph_file = os.path.join(\n            maps_path, \"floor_trav_{}_py{}{}.p\".format(floor, sys.version_info.major, sys.version_info.minor)\n        )\n        if os.path.isfile(graph_file):\n            logging.info(\"Loading traversable graph\")\n            with open(graph_file, \"rb\") as pfile:\n                g = pickle.load(pfile)\n        else:\n            logging.info(\"Building traversable graph\")\n            g = nx.Graph()\n            for i in range(map_size):\n                for j in range(map_size):\n                    if trav_map[i, j] == 0:\n                        continue\n                    g.add_node((i, j))\n                    # 8-connected graph\n                    neighbors = [(i - 1, j - 1), (i, j - 1), (i + 1, j - 1), (i - 1, j)]\n                    for n in neighbors:\n                        if (\n                            0 &lt;= n[0] &lt; map_size\n                            and 0 &lt;= n[1] &lt; map_size\n                            and trav_map[n[0], n[1]] &gt; 0\n                        ):\n                            g.add_edge(n, (i, j), weight=T.l2_distance(n, (i, j)))\n\n            # only take the largest connected component\n            largest_cc = max(nx.connected_components(g), key=len)\n            g = g.subgraph(largest_cc).copy()\n            with open(graph_file, \"wb\") as pfile:\n                pickle.dump(g, pfile)\n\n        floor_graph.append(g)\n\n        # update trav_map accordingly\n        # This overwrites the traversability map loaded before\n        # It sets everything to zero, then only sets to one the points where we have graph nodes\n        # Dangerous! if the traversability graph is not computed from the loaded map but from a file, it could overwrite\n        # it silently.\n        trav_map[:, :] = 0\n        for node in g.nodes:\n            trav_map[node[0], node[1]] = 255\n\n        return floor_graph\n\n    @property\n    def n_floors(self):\n        \"\"\"\n        Returns:\n            int: Number of floors belonging to this map's associated scene\n        \"\"\"\n        return len(self.floor_heights)\n\n    def get_random_point(self, floor=None):\n        \"\"\"\n        Sample a random point on the given floor number. If not given, sample a random floor number.\n\n        Args:\n            floor (None or int): floor number. None means the floor is randomly sampled\n\n        Returns:\n            2-tuple:\n                - int: floor number. This is the sampled floor number if @floor is None\n                - 3-array: (x,y,z) randomly sampled point\n        \"\"\"\n        if floor is None:\n            floor = np.random.randint(0, self.n_floors)\n        trav = self.floor_map[floor]\n        trav_space = np.where(trav == 255)\n        idx = np.random.randint(0, high=trav_space[0].shape[0])\n        xy_map = np.array([trav_space[0][idx], trav_space[1][idx]])\n        x, y = self.map_to_world(xy_map)\n        z = self.floor_heights[floor]\n        return floor, np.array([x, y, z])\n\n    def has_node(self, floor, world_xy):\n        \"\"\"\n        Return whether the traversability graph contains a point\n\n            floor: floor number\n            world_xy: 2D location in world reference frame (metric)\n        \"\"\"\n        map_xy = tuple(self.world_to_map(world_xy))\n        g = self.floor_graph[floor]\n        return g.has_node(map_xy)\n\n    def get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n        \"\"\"\n        Get the shortest path from one point to another point.\n        If any of the given point is not in the graph, add it to the graph and\n        create an edge between it to its closest node.\n\n        Args:\n            floor (int): floor number\n            source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n            target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n            entire_path (bool): whether to return the entire path\n\n        Returns:\n            2-tuple:\n                - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n                - float: geodesic distance of the path\n        \"\"\"\n        assert self.build_graph, \"cannot get shortest path without building the graph\"\n        source_map = tuple(self.world_to_map(source_world))\n        target_map = tuple(self.world_to_map(target_world))\n\n        g = self.floor_graph[floor]\n\n        if not g.has_node(target_map):\n            nodes = np.array(g.nodes)\n            closest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - target_map, axis=1))])\n            g.add_edge(closest_node, target_map, weight=T.l2_distance(closest_node, target_map))\n\n        if not g.has_node(source_map):\n            nodes = np.array(g.nodes)\n            closest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - source_map, axis=1))])\n            g.add_edge(closest_node, source_map, weight=T.l2_distance(closest_node, source_map))\n\n        path_map = np.array(nx.astar_path(g, source_map, target_map, heuristic=T.l2_distance))\n\n        path_world = self.map_to_world(path_map)\n        geodesic_distance = np.sum(np.linalg.norm(path_world[1:] - path_world[:-1], axis=1))\n        path_world = path_world[:: self.waypoint_interval]\n\n        if not entire_path:\n            path_world = path_world[: self.num_waypoints]\n            num_remaining_waypoints = self.num_waypoints - path_world.shape[0]\n            if num_remaining_waypoints &gt; 0:\n                remaining_waypoints = np.tile(target_world, (num_remaining_waypoints, 1))\n                path_world = np.concatenate((path_world, remaining_waypoints), axis=0)\n\n        return path_world, geodesic_distance\n</code></pre>","location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap"},{"title":"<code>n_floors</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of floors belonging to this map's associated scene</p>","location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.n_floors"},{"title":"<code>__init__(map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>map_resolution</code>  <code>float</code>  <p>map resolution</p>  <code>0.1</code>    <code>trav_map_erosion</code>  <code>float</code>  <p>erosion radius of traversability areas, should be robot footprint radius</p>  <code>2</code>    <code>trav_map_with_objects</code>  <code>bool</code>  <p>whether to use objects or not when constructing graph</p>  <code>True</code>    <code>build_graph</code>  <code>bool</code>  <p>build connectivity graph</p>  <code>True</code>    <code>num_waypoints</code>  <code>int</code>  <p>number of way points returned</p>  <code>10</code>    <code>waypoint_resolution</code>  <code>float</code>  <p>resolution of adjacent way points</p>  <code>0.2</code>      Source code in <code>maps/traversable_map.py</code> <pre><code>def __init__(\n    self,\n    map_resolution=0.1,\n    trav_map_erosion=2,\n    trav_map_with_objects=True,\n    build_graph=True,\n    num_waypoints=10,\n    waypoint_resolution=0.2,\n):\n    \"\"\"\n    Args:\n        map_resolution (float): map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n    \"\"\"\n    # Set internal values\n    self.map_default_resolution = 0.01  # each pixel represents 0.01m\n    self.trav_map_erosion = trav_map_erosion\n    self.trav_map_with_objects = trav_map_with_objects\n    self.build_graph = build_graph\n    self.num_waypoints = num_waypoints\n    self.waypoint_interval = int(waypoint_resolution / map_resolution)\n\n    # Values loaded at runtime\n    self.trav_map_original_size = None\n    self.trav_map_size = None\n    self.mesh_body_id = None\n    self.floor_heights = None\n    self.floor_map = None\n    self.floor_graph = None\n\n    # Run super method\n    super().__init__(map_resolution=map_resolution)\n</code></pre>","location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.__init__"},{"title":"<code>build_trav_graph(map_size, maps_path, floor, trav_map)</code>  <code>staticmethod</code>","text":"<p>Build traversibility graph and only take the largest connected component</p> <p>Parameters:</p>    Name Type Description Default     <code>map_size</code>  <code>int</code>  <p>Size of the map being generated</p>  required    <code>maps_path</code>  <code>str</code>  <p>Path to the folder containing the traversability maps</p>  required    <code>floor</code>  <code>int</code>  <p>floor number</p>  required    <code>trav_map</code>  <code>H, W)-array</code>  <p>traversability map in image form</p>  required      Source code in <code>maps/traversable_map.py</code> <pre><code>@staticmethod\ndef build_trav_graph(map_size, maps_path, floor, trav_map):\n    \"\"\"\n    Build traversibility graph and only take the largest connected component\n\n    Args:\n        map_size (int): Size of the map being generated\n        maps_path (str): Path to the folder containing the traversability maps\n        floor (int): floor number\n        trav_map ((H, W)-array): traversability map in image form\n    \"\"\"\n    floor_graph = []\n    graph_file = os.path.join(\n        maps_path, \"floor_trav_{}_py{}{}.p\".format(floor, sys.version_info.major, sys.version_info.minor)\n    )\n    if os.path.isfile(graph_file):\n        logging.info(\"Loading traversable graph\")\n        with open(graph_file, \"rb\") as pfile:\n            g = pickle.load(pfile)\n    else:\n        logging.info(\"Building traversable graph\")\n        g = nx.Graph()\n        for i in range(map_size):\n            for j in range(map_size):\n                if trav_map[i, j] == 0:\n                    continue\n                g.add_node((i, j))\n                # 8-connected graph\n                neighbors = [(i - 1, j - 1), (i, j - 1), (i + 1, j - 1), (i - 1, j)]\n                for n in neighbors:\n                    if (\n                        0 &lt;= n[0] &lt; map_size\n                        and 0 &lt;= n[1] &lt; map_size\n                        and trav_map[n[0], n[1]] &gt; 0\n                    ):\n                        g.add_edge(n, (i, j), weight=T.l2_distance(n, (i, j)))\n\n        # only take the largest connected component\n        largest_cc = max(nx.connected_components(g), key=len)\n        g = g.subgraph(largest_cc).copy()\n        with open(graph_file, \"wb\") as pfile:\n            pickle.dump(g, pfile)\n\n    floor_graph.append(g)\n\n    # update trav_map accordingly\n    # This overwrites the traversability map loaded before\n    # It sets everything to zero, then only sets to one the points where we have graph nodes\n    # Dangerous! if the traversability graph is not computed from the loaded map but from a file, it could overwrite\n    # it silently.\n    trav_map[:, :] = 0\n    for node in g.nodes:\n        trav_map[node[0], node[1]] = 255\n\n    return floor_graph\n</code></pre>","location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.build_trav_graph"},{"title":"<code>get_random_point(floor=None)</code>","text":"<p>Sample a random point on the given floor number. If not given, sample a random floor number.</p> <p>Parameters:</p>    Name Type Description Default     <code>floor</code>  <code>None or int</code>  <p>floor number. None means the floor is randomly sampled</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - int: floor number. This is the sampled floor number if @floor is None - 3-array: (x,y,z) randomly sampled point</p>     Source code in <code>maps/traversable_map.py</code> <pre><code>def get_random_point(self, floor=None):\n    \"\"\"\n    Sample a random point on the given floor number. If not given, sample a random floor number.\n\n    Args:\n        floor (None or int): floor number. None means the floor is randomly sampled\n\n    Returns:\n        2-tuple:\n            - int: floor number. This is the sampled floor number if @floor is None\n            - 3-array: (x,y,z) randomly sampled point\n    \"\"\"\n    if floor is None:\n        floor = np.random.randint(0, self.n_floors)\n    trav = self.floor_map[floor]\n    trav_space = np.where(trav == 255)\n    idx = np.random.randint(0, high=trav_space[0].shape[0])\n    xy_map = np.array([trav_space[0][idx], trav_space[1][idx]])\n    x, y = self.map_to_world(xy_map)\n    z = self.floor_heights[floor]\n    return floor, np.array([x, y, z])\n</code></pre>","location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.get_random_point"},{"title":"<code>get_shortest_path(floor, source_world, target_world, entire_path=False)</code>","text":"<p>Get the shortest path from one point to another point. If any of the given point is not in the graph, add it to the graph and create an edge between it to its closest node.</p> <p>Parameters:</p>    Name Type Description Default     <code>floor</code>  <code>int</code>  <p>floor number</p>  required    <code>source_world</code>  <code>2-array</code>  <p>(x,y) 2D source location in world reference frame (metric)</p>  required    <code>target_world</code>  <code>2-array</code>  <p>(x,y) 2D target location in world reference frame (metric)</p>  required    <code>entire_path</code>  <code>bool</code>  <p>whether to return the entire path</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - (N, 2) array: array of path waypoints, where N is the number of generated waypoints - float: geodesic distance of the path</p>     Source code in <code>maps/traversable_map.py</code> <pre><code>def get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n    \"\"\"\n    Get the shortest path from one point to another point.\n    If any of the given point is not in the graph, add it to the graph and\n    create an edge between it to its closest node.\n\n    Args:\n        floor (int): floor number\n        source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n        target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n        entire_path (bool): whether to return the entire path\n\n    Returns:\n        2-tuple:\n            - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n            - float: geodesic distance of the path\n    \"\"\"\n    assert self.build_graph, \"cannot get shortest path without building the graph\"\n    source_map = tuple(self.world_to_map(source_world))\n    target_map = tuple(self.world_to_map(target_world))\n\n    g = self.floor_graph[floor]\n\n    if not g.has_node(target_map):\n        nodes = np.array(g.nodes)\n        closest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - target_map, axis=1))])\n        g.add_edge(closest_node, target_map, weight=T.l2_distance(closest_node, target_map))\n\n    if not g.has_node(source_map):\n        nodes = np.array(g.nodes)\n        closest_node = tuple(nodes[np.argmin(np.linalg.norm(nodes - source_map, axis=1))])\n        g.add_edge(closest_node, source_map, weight=T.l2_distance(closest_node, source_map))\n\n    path_map = np.array(nx.astar_path(g, source_map, target_map, heuristic=T.l2_distance))\n\n    path_world = self.map_to_world(path_map)\n    geodesic_distance = np.sum(np.linalg.norm(path_world[1:] - path_world[:-1], axis=1))\n    path_world = path_world[:: self.waypoint_interval]\n\n    if not entire_path:\n        path_world = path_world[: self.num_waypoints]\n        num_remaining_waypoints = self.num_waypoints - path_world.shape[0]\n        if num_remaining_waypoints &gt; 0:\n            remaining_waypoints = np.tile(target_world, (num_remaining_waypoints, 1))\n            path_world = np.concatenate((path_world, remaining_waypoints), axis=0)\n\n    return path_world, geodesic_distance\n</code></pre>","location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.get_shortest_path"},{"title":"<code>has_node(floor, world_xy)</code>","text":"<p>Return whether the traversability graph contains a point</p> <pre><code>floor: floor number\nworld_xy: 2D location in world reference frame (metric)\n</code></pre>  Source code in <code>maps/traversable_map.py</code> <pre><code>def has_node(self, floor, world_xy):\n    \"\"\"\n    Return whether the traversability graph contains a point\n\n        floor: floor number\n        world_xy: 2D location in world reference frame (metric)\n    \"\"\"\n    map_xy = tuple(self.world_to_map(world_xy))\n    g = self.floor_graph[floor]\n    return g.has_node(map_xy)\n</code></pre>","location":"reference/maps/traversable_map.html#maps.traversable_map.TraversableMap.has_node"},{"title":"object_states","text":"","location":"reference/object_states/index.html"},{"title":"aabb","text":"","location":"reference/object_states/aabb.html"},{"title":"adjacency","text":"","location":"reference/object_states/adjacency.html"},{"title":"<code>HorizontalAdjacency</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code></p> <p>State representing the object's horizontal adjacencies in a preset number of directions.</p> <p>The HorizontalAdjacency state returns adjacency lists for equally spaced coordinate planes. Each plane consists of 2 orthogonal axes, and adjacencies are checked for both the positive and negative directions of each axis.</p> <p>The value of the state is List[List[AxisAdjacencyList]], where the list dimensions are m.HORIZONTAL_AXIS_COUNT and 2. The first index is used to choose between the different planes, the second index to choose between the orthogonal axes of that plane. Given a plane/axis combo, the item in the list is a AxisAdjacencyList containing adjacencies in both directions of the axis.</p> <p>If the idea of orthogonal bases is not relevant (and your use case simply requires checking adjacencies in each direction), the flatten_planes() function can be used on the state value to reduce the output to List[AxisAdjacencyList], a list of adjacency lists for all 2 * m.HORIZONTAL_AXIS_COUNT directions.</p>  Source code in <code>object_states/adjacency.py</code> <pre><code>class HorizontalAdjacency(AbsoluteObjectState):\n    \"\"\"\n    State representing the object's horizontal adjacencies in a preset number of directions.\n\n    The HorizontalAdjacency state returns adjacency lists for equally spaced coordinate planes.\n    Each plane consists of 2 orthogonal axes, and adjacencies are checked for both the positive\n    and negative directions of each axis.\n\n    The value of the state is List[List[AxisAdjacencyList]], where the list dimensions are\n    m.HORIZONTAL_AXIS_COUNT and 2. The first index is used to choose between the different planes,\n    the second index to choose between the orthogonal axes of that plane. Given a plane/axis combo,\n    the item in the list is a AxisAdjacencyList containing adjacencies in both directions of the\n    axis.\n\n    If the idea of orthogonal bases is not relevant (and your use case simply requires checking\n    adjacencies in each direction), the flatten_planes() function can be used on the state value\n    to reduce the output to List[AxisAdjacencyList], a list of adjacency lists for all\n    2 * m.HORIZONTAL_AXIS_COUNT directions.\n    \"\"\"\n\n    def _get_value(self):\n        coordinate_planes = get_equidistant_coordinate_planes(m.HORIZONTAL_AXIS_COUNT)\n\n        # Flatten the axis dimension and input into compute_adjacencies.\n        bodies_by_axis = compute_adjacencies(self.obj, coordinate_planes.reshape(-1, 3), m.MAX_DISTANCE_HORIZONTAL)\n\n        # Now reshape the bodies_by_axis to group by coordinate planes.\n        bodies_by_plane = list(zip(bodies_by_axis[::2], bodies_by_axis[1::2]))\n\n        # Return the adjacencies.\n        return bodies_by_plane\n\n    def _set_value(self, new_value):\n        raise NotImplementedError(\"HorizontalAdjacency state currently does not support setting.\")\n\n    @staticmethod\n    def get_dependencies():\n        return AbsoluteObjectState.get_dependencies() + [AABB]\n</code></pre>","location":"reference/object_states/adjacency.html#object_states.adjacency.HorizontalAdjacency"},{"title":"<code>VerticalAdjacency</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code></p> <p>State representing the object's vertical adjacencies. Value is a AxisAdjacencyList object.</p>  Source code in <code>object_states/adjacency.py</code> <pre><code>class VerticalAdjacency(AbsoluteObjectState):\n    \"\"\"\n    State representing the object's vertical adjacencies.\n    Value is a AxisAdjacencyList object.\n    \"\"\"\n\n    def _get_value(self):\n        # Call the adjacency computation with th Z axis.\n        bodies_by_axis = compute_adjacencies(self.obj, np.array([[0, 0, 1]]), m.MAX_DISTANCE_VERTICAL)\n\n        # Return the adjacencies from the only axis we passed in.\n        return bodies_by_axis[0]\n\n    def _set_value(self, new_value):\n        raise NotImplementedError(\"VerticalAdjacency state currently does not support setting.\")\n\n    @staticmethod\n    def get_dependencies():\n        return AbsoluteObjectState.get_dependencies() + [AABB]\n</code></pre>","location":"reference/object_states/adjacency.html#object_states.adjacency.VerticalAdjacency"},{"title":"<code>compute_adjacencies(obj, axes, max_distance)</code>","text":"<p>Given an object and a list of axes, find the adjacent objects in the axes' positive and negative directions.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>StatefulObject</code>  <p>The object to check adjacencies of.</p>  required    <code>axes</code>  <code>2D-array</code>  <p>(n_axes, 3) array defining the axes to check in. Note that each axis will be checked in both its positive and negative direction.</p>  required     <p>Returns:</p>    Type Description       <p>list of AxisAdjacencyList: List of length len(axes) containing the adjacencies.</p>     Source code in <code>object_states/adjacency.py</code> <pre><code>def compute_adjacencies(obj, axes, max_distance):\n    \"\"\"\n    Given an object and a list of axes, find the adjacent objects in the axes'\n    positive and negative directions.\n\n    Args:\n        obj (StatefulObject): The object to check adjacencies of.\n        axes (2D-array): (n_axes, 3) array defining the axes to check in.\n            Note that each axis will be checked in both its positive and negative direction.\n\n    Returns:\n        list of AxisAdjacencyList: List of length len(axes) containing the adjacencies.\n    \"\"\"\n    # Get vectors for each of the axes' directions.\n    # The ordering is axes1+, axis1-, axis2+, axis2- etc.\n    directions = np.empty((len(axes) * 2, 3))\n    directions[0::2] = axes\n    directions[1::2] = -axes\n\n    # Prepare this object's info for ray casting.\n    # Use AABB center instead of position because we cannot get valid position\n    # for fixed objects if fixed links are merged.\n    aabb_lower, aabb_higher = obj.states[AABB].get_value()\n    object_position = (aabb_lower + aabb_higher) / 2.0\n    prim_paths = obj.link_prim_paths\n\n    # Prepare the rays to cast.\n    ray_starts = np.tile(object_position, (len(directions), 1))\n    ray_endpoints = ray_starts + (directions * max_distance)\n\n    # Cast time.\n    ray_results = raytest_batch(\n        ray_starts,\n        ray_endpoints,\n        only_closest=False,\n        ignore_bodies=prim_paths,\n        ignore_collisions=prim_paths\n    )\n\n    # Add the results to the appropriate lists\n    # For now, we keep our result in the dimensionality of (direction, hit_object_order).\n    # We convert the hit link into unique objects encountered\n    objs_by_direction = []\n    for results in ray_results:\n        unique_objs = set()\n        for result in results:\n            # Check if the inferred hit object is not None, we add it to our set\n            obj_prim_path = \"/\".join(result[\"rigidBody\"].split(\"/\")[:-1])\n            obj = og.sim.scene.object_registry(\"prim_path\", obj_prim_path, None)\n            if obj is not None:\n                unique_objs.add(obj)\n        objs_by_direction.append(unique_objs)\n\n    # Reshape so that these have the following indices:\n    # (axis_idx, direction-one-or-zero, hit_idx)\n    objs_by_axis = [\n        AxisAdjacencyList(positive_neighbors, negative_neighbors)\n        for positive_neighbors, negative_neighbors in zip(objs_by_direction[::2], objs_by_direction[1::2])\n    ]\n    return objs_by_axis\n</code></pre>","location":"reference/object_states/adjacency.html#object_states.adjacency.compute_adjacencies"},{"title":"<code>get_equidistant_coordinate_planes(n_planes)</code>","text":"<p>Given a number, sample that many equally spaced coordinate planes.</p> <p>The samples will cover all 360 degrees (although rotational symmetry is assumed, e.g. if you take into account the axis index and the positive/negative directions, only 1/4 of the possible coordinate (1 quadrant, np.pi / 2.0) planes will be sampled: the ones where the first axis' positive direction is in the first quadrant).</p> <p>Parameters:</p>    Name Type Description Default     <code>n_planes</code>  <code>int</code>  <p>number of planes to sample</p>  required     <p>Returns:</p>    Type Description       <p>3D-array: (n_planes, 2, 3) array where the first dimension is the sampled plane index, the second dimension is the axis index (0/1), and the third dimension is the 3-D world-coordinate vector corresponding to the axis.</p>     Source code in <code>object_states/adjacency.py</code> <pre><code>def get_equidistant_coordinate_planes(n_planes):\n    \"\"\"Given a number, sample that many equally spaced coordinate planes.\n\n    The samples will cover all 360 degrees (although rotational symmetry\n    is assumed, e.g. if you take into account the axis index and the\n    positive/negative directions, only 1/4 of the possible coordinate (1 quadrant, np.pi / 2.0)\n    planes will be sampled: the ones where the first axis' positive direction\n    is in the first quadrant).\n\n    Args:\n        n_planes (int): number of planes to sample\n\n    Returns:\n        3D-array: (n_planes, 2, 3) array where the first dimension\n            is the sampled plane index, the second dimension is the axis index\n            (0/1), and the third dimension is the 3-D world-coordinate vector\n            corresponding to the axis.\n    \"\"\"\n    # Compute the positive directions of the 1st axis of each plane.\n    first_axis_angles = np.linspace(0, np.pi / 2, n_planes)\n    first_axes = np.stack(\n        [np.cos(first_axis_angles), np.sin(first_axis_angles), np.zeros_like(first_axis_angles)], axis=1\n    )\n\n    # Compute the positive directions of the 2nd axes. These axes are\n    # orthogonal to both their corresponding first axes and to the Z axis.\n    second_axes = np.cross([0, 0, 1], first_axes)\n\n    # Return the axes in the shape (n_planes, 2, 3)\n    return np.stack([first_axes[:, None, :], second_axes[:, None, :]], axis=1)\n</code></pre>","location":"reference/object_states/adjacency.html#object_states.adjacency.get_equidistant_coordinate_planes"},{"title":"attachment","text":"","location":"reference/object_states/attachment.html"},{"title":"<code>Attached</code>","text":"<p>         Bases: <code>RelativeObjectState</code>, <code>BooleanState</code>, <code>ContactSubscribedStateMixin</code></p> <p>Handles attachment between two rigid objects, by creating a fixed joint between self (child) and other (parent) At any given moment, an object can only be attached to at most one other object.</p>  There are three types of attachment <p>STICKY: unidirectional, attach if in contact. SYMMETRIC: bidirectional, attach if in contact AND the other object has SYMMETRIC type     with the same attachment_category (e.g. \"magnet\"). MALE/FEMALE: bidirectional, attach if in contact AND the other object has the opposite end (male / female)     with the same attachment_category (e.g. \"usb\")</p>  <p>Subclasses ContactSubscribedStateMixin on_contact_found function attempts to attach two objects when a CONTACT_FOUND event happens</p>  Source code in <code>object_states/attachment.py</code> <pre><code>class Attached(RelativeObjectState, BooleanState, ContactSubscribedStateMixin):\n    \"\"\"\n        Handles attachment between two rigid objects, by creating a fixed joint between self (child) and other (parent)\n        At any given moment, an object can only be attached to at most one other object.\n        There are three types of attachment:\n            STICKY: unidirectional, attach if in contact.\n            SYMMETRIC: bidirectional, attach if in contact AND the other object has SYMMETRIC type\n                with the same attachment_category (e.g. \"magnet\").\n            MALE/FEMALE: bidirectional, attach if in contact AND the other object has the opposite end (male / female)\n                with the same attachment_category (e.g. \"usb\")\n\n        Subclasses ContactSubscribedStateMixin\n        on_contact_found function attempts to attach two objects when a CONTACT_FOUND event happens\n    \"\"\"\n\n    @staticmethod\n    def get_dependencies():\n        return RelativeObjectState.get_dependencies() + [ContactBodies]\n\n    def __init__(self, obj, attachment_type=AttachmentType.STICKY, attachment_category=None):\n        super(Attached, self).__init__(obj)\n        self.attachment_type = attachment_type\n        self.attachment_category = attachment_category\n\n        self.attached_obj = None\n\n    # Attempts to attach two objects when a CONTACT_FOUND event happens\n    def on_contact(self, other, contact_header, contact_data):\n        if contact_header.type == ContactEventType.CONTACT_FOUND:\n            self.set_value(other, True)\n\n    def _set_value(self, other, new_value):\n        # Attempt to attach\n        if new_value:\n            if self.attached_obj == other:\n                # Already attached to this object. Do nothing.\n                return True\n            elif self.attached_obj is None:\n                # If the attachment type and category match, and they are in contact, they should attach\n                if self._can_attach(other) and check_collision(self.obj, other):\n                    self._attach(other)\n\n                    # Non-sticky attachment is bidirectional\n                    if self.attachment_type != AttachmentType.STICKY:\n                        other.states[Attached].attached_obj = self.obj\n\n                    return True\n                else:\n                    logging.warning(f\"Trying to attach object {self.obj.name} to object {other.name}, \"\n                                    f\"but they have attachment type/category mismatch or they are not in contact.\")\n                    return False\n            else:\n                logging.warning(f\"Trying to attach object {self.obj.name} to object {other.name}, \"\n                                f\"but it is already attached to object {self.attached_obj.name}. Try detaching first.\")\n                return False\n\n        # Attempt to detach\n        else:\n            if self.attached_obj == other:\n                self._detach()\n\n                # Non-sticky attachment is bidirectional\n                if self.attachment_type != AttachmentType.STICKY:\n                    other.states[Attached].attached_obj = None\n\n                # Wake up objects so that passive forces like gravity can be applied.\n                self.obj.wake()\n                other.wake()\n\n            return True\n\n    def _get_value(self, other):\n        return other == self.attached_obj\n\n    def _can_attach(self, other):\n        \"\"\"\n        Returns:\n            bool: True if self is sticky or self and other have matching attachment type and category\n        \"\"\"\n        if self.attachment_type == AttachmentType.STICKY:\n            return True\n        else:\n            if Attached not in other.states or other.states[Attached].attachment_category != self.attachment_category:\n                return False\n            elif self.attachment_type == AttachmentType.SYMMETRIC:\n                return other.states[Attached].attachment_type == AttachmentType.SYMMETRIC\n            elif self.attachment_type == AttachmentType.MALE:\n                return other.states[Attached].attachment_type == AttachmentType.FEMALE\n            else:\n                return other.states[Attached].attachment_type == AttachmentType.MALE\n\n    def _attach(self, other):\n        \"\"\"\n        Creates a fixed joint between self.obj and other (where other is the parent and self.obj is the child)\n        \"\"\"\n        self.attached_obj = other\n\n        attached_joint_path = f\"{other.prim_path}/attachment_joint\"\n        attached_joint = create_joint(\n            prim_path=attached_joint_path,\n            joint_type=\"FixedJoint\",\n            body0=f\"{other.prim_path}/base_link\",\n            body1=f\"{self.obj.prim_path}/base_link\",\n        )\n\n        # Set the local pose of the attachment joint.\n        parent_pos, parent_quat = other.get_position_orientation()\n        child_pos, child_quat = self.obj.get_position_orientation()\n\n        # The child frame aligns with the joint frame.\n        # Compute the transformation of the child frame in the parent frame\n        rel_pos, rel_quat = T.relative_pose_transform(child_pos, child_quat, parent_pos, parent_quat)\n        # The child frame position in the parent frame needs to be divided by the parent's scale\n        rel_pos /= other.scale\n        rel_quat = rel_quat[[3, 0, 1, 2]]\n\n        attached_joint.GetAttribute(\"physics:localPos0\").Set(Gf.Vec3f(*rel_pos))\n        attached_joint.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*rel_quat))\n        attached_joint.GetAttribute(\"physics:localPos1\").Set(Gf.Vec3f(0.0, 0.0, 0.0))\n        attached_joint.GetAttribute(\"physics:localRot1\").Set(Gf.Quatf(1.0, 0.0, 0.0, 0.0))\n\n    def _detach(self):\n        \"\"\"\n        Removes the attachment joint\n        \"\"\"\n        attached_joint_path = f\"{self.attached_obj.prim_path}/attachment_joint\"\n        self._simulator.stage.RemovePrim(attached_joint_path)\n        self.attached_obj = None\n\n    @property\n    def settable(self):\n        return True\n\n    @property\n    def state_size(self):\n        return 1\n\n    def _dump_state(self):\n        return OrderedDict(attached_obj_uuid=-1 if self.attached_obj is None else self.attached_obj.uuid)\n\n    def _load_state(self, state):\n        uuid = state[\"attached_obj_uuid\"]\n        attached_obj = None if uuid == -1 else og.sim.scene.object_registry(\"uuid\", uuid)\n\n        if self.attached_obj != attached_obj:\n            # If it's currently attached to something, detach.\n            if self.attached_obj is not None:\n                self._detach()\n\n            # If the loaded state requires new attachment, attach.\n            if attached_obj is not None:\n                self._attach(attached_obj)\n\n    def _serialize(self, state):\n        return np.array([state[\"attached_obj_uuid\"]], dtype=float)\n\n    def _deserialize(self, state):\n        return OrderedDict(attached_obj_uuid=int(state[0])), 1\n</code></pre>","location":"reference/object_states/attachment.html#object_states.attachment.Attached"},{"title":"burnt","text":"","location":"reference/object_states/burnt.html"},{"title":"contact_bodies","text":"","location":"reference/object_states/contact_bodies.html"},{"title":"contact_subscribed_state_mixin","text":"","location":"reference/object_states/contact_subscribed_state_mixin.html"},{"title":"<code>ContactSubscribedStateMixin</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Handles contact events (including CONTACT_FOUND, CONTACT_PERSIST, and CONTACT_LOST). The subclass should implement its own on_contact method</p>  Source code in <code>object_states/contact_subscribed_state_mixin.py</code> <pre><code>class ContactSubscribedStateMixin(ABC):\n    \"\"\"\n    Handles contact events (including CONTACT_FOUND, CONTACT_PERSIST, and CONTACT_LOST).\n    The subclass should implement its own on_contact method\n    \"\"\"\n    @abstractmethod\n    def on_contact(self, other, contact_header, contact_data):\n        raise NotImplementedError(\"Subclasses of ContactSubscribedStateMixin should implement the on_contact method.\")\n</code></pre>","location":"reference/object_states/contact_subscribed_state_mixin.html#object_states.contact_subscribed_state_mixin.ContactSubscribedStateMixin"},{"title":"cooked","text":"","location":"reference/object_states/cooked.html"},{"title":"covered","text":"","location":"reference/object_states/covered.html"},{"title":"<code>Covered</code>","text":"<p>         Bases: <code>RelativeObjectState</code>, <code>BooleanState</code></p>  Source code in <code>object_states/covered.py</code> <pre><code>class Covered(RelativeObjectState, BooleanState):\n    def __init__(self, obj):\n        # Run super first\n        super().__init__(obj)\n\n        # Set internal values\n        self._visual_particle_groups = None\n        self._n_initial_visual_particles = None\n\n    @staticmethod\n    def get_dependencies():\n        # AABB needed for sampling visual particles on an object\n        return RelativeObjectState.get_dependencies() + [AABB]\n\n    def _initialize(self):\n        # Create the visual particle groups\n        self._visual_particle_groups = OrderedDict((get_element_name_from_system(system), system.create_attachment_group(obj=self.obj))\n                                                   for system in get_visual_particle_systems().values())\n\n        # Default initial particles is 0\n        self._n_initial_visual_particles = OrderedDict((get_element_name_from_system(system), 0)\n                                                       for system in get_visual_particle_systems().values())\n\n    def _get_value(self, system):\n        # Value is false by default\n        value = False\n        # First, we check what type of system\n        # Currently, we support VisualParticleSystems and FluidSystems\n        if issubclass(system, VisualParticleSystem):\n            # We check whether the current number of particles assigned to the group is greater than the threshold\n            name = get_element_name_from_system(system)\n            value = system.num_group_particles(group=self._visual_particle_groups[name]) \\\n                   &gt; m.VISUAL_PARTICLE_THRESHOLD * self._n_initial_visual_particles[name]\n        elif issubclass(system, FluidSystem):\n            # We only check if we have particle instancers currently\n            if len(system.particle_instancers) &gt; 0:\n                # We've already cached particle contacts, so we merely search through them to see if any particles are\n                # touching the object and are visible (the non-visible ones are considered already \"removed\")\n                n_near_particles = 0\n                for instancer, particle_idxs in system.state_cache[\"obj_particle_contacts\"][self.obj].items():\n                    particle_idxs = np.array(list(particle_idxs))\n                    n_near_particles += np.sum(instancer.particle_visibilities[particle_idxs])\n                # Heuristic: If the number of near particles is above the threshold, we consdier this covered\n                value = n_near_particles &gt;= m.FLUID_THRESHOLD\n        else:\n            raise ValueError(f\"Invalid system {system} received for getting Covered state!\"\n                             f\"Currently, only VisualParticleSystems and FluidSystems are supported.\")\n\n        return value\n\n    def _set_value(self, system, new_value):\n        # Default success value is True\n        success = True\n        # First, we check what type of system\n        # Currently, we support VisualParticleSystems and FluidSystems\n        if issubclass(system, VisualParticleSystem):\n            # Check current state and only do something if we're changing state\n            if self.get_value(system) != new_value:\n                name = get_element_name_from_system(system)\n                group = self._visual_particle_groups[name]\n                if new_value:\n                    # Generate particles\n                    success = system.generate_group_particles_on_object(group=group)\n                    # If we succeeded with generating particles (new_value = True), store additional info\n                    if success:\n                        # Store how many particles there are now -- this is the \"maximum\" number possible\n                        self._n_initial_visual_particles[name] = system.num_group_particles(group=group)\n                else:\n                    # We remove all of this group's particles\n                    system.remove_all_group_particles(group=group)\n\n        elif issubclass(system, FluidSystem):\n            # Check current state and only do something if we're changing state\n            if self.get_value(system) != new_value:\n                if new_value:\n                    # Sample particles on top of the object\n                    system.generate_particle_instancer_on_object(obj=self.obj, max_samples=m.MAX_FLUID_PARTICLES)\n                else:\n                    # We hide all particles within range to be garbage collected by fluid system\n                    for inst, particle_idxs in system.state_cache[\"obj_particle_contacts\"][self.obj].items():\n                        indices = np.array(list(particle_idxs))\n                        current_visibilities = inst.particle_visibilities\n                        current_visibilities[indices] = 0\n                        inst.particle_visibilities = current_visibilities\n\n        else:\n            raise ValueError(f\"Invalid system {system} received for setting Covered state!\"\n                             f\"Currently, only VisualParticleSystems and FluidSystems are supported.\")\n\n        return success\n\n    @property\n    def state_size(self):\n        # We have a single value for every visual particle system\n        return len(get_visual_particle_systems())\n\n    @classproperty\n    def supported_systems(self):\n        \"\"\"\n        Returns:\n            list: All systems used in this state, ordered deterministically\n        \"\"\"\n        return list(get_visual_particle_systems().values()) + list(get_fluid_systems().values())\n\n    def _dump_state(self):\n        # For fluid systems, we don't need to dump state, because the fluid systems themselves handle all state dumping\n        # related to fluids\n        # For every visual particle system, add the initial number of particles\n        state = OrderedDict()\n        for system in get_visual_particle_systems().values():\n            name = get_element_name_from_system(system)\n            state[f\"{name}_initial_visual_particles\"] = self._n_initial_visual_particles[name]\n\n        return state\n\n    def _load_state(self, state):\n        # For fluid systems, we don't need to load state, because the fluid systems themselves handle all state loading\n        # related to fluids\n        # For every visual particle system, set the initial number of particles\n        for system in get_visual_particle_systems().values():\n            name = get_element_name_from_system(system)\n            self._n_initial_visual_particles[name] = state[f\"{name}_initial_visual_particles\"]\n\n    def _serialize(self, state):\n        return np.array([val for val in state.values()], dtype=float)\n\n    def _deserialize(self, state):\n        state_dict = OrderedDict()\n        for i, system in enumerate(get_visual_particle_systems().values()):\n            name = get_element_name_from_system(system)\n            state_dict[f\"{name}_initial_visual_particles\"] = int(state[i])\n\n        return state_dict, len(state_dict)\n</code></pre>","location":"reference/object_states/covered.html#object_states.covered.Covered"},{"title":"<code>supported_systems()</code>","text":"<p>Returns:</p>    Name Type Description     <code>list</code>   <p>All systems used in this state, ordered deterministically</p>     Source code in <code>object_states/covered.py</code> <pre><code>@classproperty\ndef supported_systems(self):\n    \"\"\"\n    Returns:\n        list: All systems used in this state, ordered deterministically\n    \"\"\"\n    return list(get_visual_particle_systems().values()) + list(get_fluid_systems().values())\n</code></pre>","location":"reference/object_states/covered.html#object_states.covered.Covered.supported_systems"},{"title":"factory","text":"","location":"reference/object_states/factory.html"},{"title":"<code>get_object_state_instance(state_class, obj, params=None)</code>","text":"<p>Create an BaseObjectState child class instance for a given object &amp; state.</p> <p>The parameters passed in as a dictionary through params are passed as kwargs to the object state class constructor.</p> <p>Parameters:</p>    Name Type Description Default     <code>state_class</code>  <code>BaseObjectState</code>  <p>The state name from the state name dictionary.</p>  required    <code>obj</code>  <code>StatefulObject</code>  <p>The object for which the state is being constructed.</p>  required    <code>params</code>  <code>dict</code>  <p>Dictionary of {param: value} corresponding to the state's params.</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>BaseObjectState</code>   <p>The constructed state object</p>     Source code in <code>object_states/factory.py</code> <pre><code>def get_object_state_instance(state_class, obj, params=None):\n    \"\"\"\n    Create an BaseObjectState child class instance for a given object &amp; state.\n\n    The parameters passed in as a dictionary through params are passed as\n    kwargs to the object state class constructor.\n\n    Args:\n        state_class (BaseObjectState): The state name from the state name dictionary.\n        obj (StatefulObject): The object for which the state is being constructed.\n        params (dict): Dictionary of {param: value} corresponding to the state's params.\n\n    Returns:\n        BaseObjectState: The constructed state object\n    \"\"\"\n    if not issubclass(state_class, BaseObjectState):\n        assert False, \"unknown state class: {}\".format(state_class)\n\n    if params is None:\n        params = {}\n\n    return state_class(obj, **params)\n</code></pre>","location":"reference/object_states/factory.html#object_states.factory.get_object_state_instance"},{"title":"<code>get_state_dependency_graph()</code>","text":"<p>Returns:</p>    Type Description       <p>nx.DiGraph: State dependency graph of supported object states</p>     Source code in <code>object_states/factory.py</code> <pre><code>def get_state_dependency_graph():\n    \"\"\"\n    Returns:\n        nx.DiGraph: State dependency graph of supported object states\n    \"\"\"\n    dependencies = {state: state.get_dependencies() + state.get_optional_dependencies() for state in get_all_states()}\n    return nx.DiGraph(dependencies)\n</code></pre>","location":"reference/object_states/factory.html#object_states.factory.get_state_dependency_graph"},{"title":"<code>get_states_by_dependency_order()</code>","text":"<p>Returns:</p>    Name Type Description     <code>list</code>   <p>all states in topological order of dependency</p>     Source code in <code>object_states/factory.py</code> <pre><code>def get_states_by_dependency_order():\n    \"\"\"\n    Returns:\n        list: all states in topological order of dependency\n    \"\"\"\n    return list(reversed(list(nx.algorithms.topological_sort(get_state_dependency_graph()))))\n</code></pre>","location":"reference/object_states/factory.html#object_states.factory.get_states_by_dependency_order"},{"title":"filled","text":"","location":"reference/object_states/filled.html"},{"title":"fluid_sink","text":"","location":"reference/object_states/fluid_sink.html"},{"title":"<code>FluidSink</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>LinkBasedStateMixin</code></p>  Source code in <code>object_states/fluid_sink.py</code> <pre><code>class FluidSink(AbsoluteObjectState, LinkBasedStateMixin):\n    def __init__(self, obj, max_distance=m.MAX_SINK_DISTANCE):\n        super().__init__(obj)\n\n        # Store internal values\n        self.max_sink_distance = m.MAX_SINK_DISTANCE\n\n    @property\n    def fluid_system(self):\n        \"\"\"\n        Returns:\n            FluidSystem: Fluid system to use to generate / handle fluid particles\n        \"\"\"\n        raise NotImplementedError\n\n    @staticmethod\n    def get_state_link_name():\n        # Should be implemented by subclass\n        raise NotImplementedError\n\n    def _initialize(self):\n        super()._initialize()\n        self.initialize_link_mixin()\n\n    def _update(self):\n        fluid_sink_position = self.get_link_position()\n        if fluid_sink_position is None:\n            # Terminate early, this is a \"dead\" fluid sink\n            return\n\n        # We iterate over all active fluid groups in this sink's corresponding fluid system,\n        # and check to see if the group matches both the (a) distance and (b) fraction criteria in\n        # order to \"sink\" (delete) it\n        names_to_remove = []\n        for name, inst in self.fluid_system.particle_instancers.items():\n            # Grab particle positions, shape (N, 3)\n            particle_pos = inst.particle_positions\n            # Get distances and check fraction simultaneously\n            frac_in_sink = (np.linalg.norm(particle_pos - fluid_sink_position.reshape(1, 3), axis=-1) &lt; self.max_sink_distance).mean()\n            if frac_in_sink &gt;= m.MIN_GROUP_FRACTION:\n                names_to_remove.append(name)\n\n        # Delete all recorded groups\n        for name in names_to_remove:\n            self.fluid_system.remove_particle_instancer(name)\n\n    def _set_value(self, new_value):\n        raise ValueError(\"set_value not supported for FluidSink.\")\n\n    def _get_value(self):\n        pass\n\n    @staticmethod\n    def get_optional_dependencies():\n        return []\n\n    @staticmethod\n    def get_dependencies():\n        return []\n</code></pre>","location":"reference/object_states/fluid_sink.html#object_states.fluid_sink.FluidSink"},{"title":"<code>fluid_system</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>FluidSystem</code>   <p>Fluid system to use to generate / handle fluid particles</p>","location":"reference/object_states/fluid_sink.html#object_states.fluid_sink.FluidSink.fluid_system"},{"title":"fluid_source","text":"","location":"reference/object_states/fluid_source.html"},{"title":"<code>FluidSource</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>LinkBasedStateMixin</code></p>  Source code in <code>object_states/fluid_source.py</code> <pre><code>class FluidSource(AbsoluteObjectState, LinkBasedStateMixin):\n    def __init__(self, obj):\n        super().__init__(obj)\n\n        # Initialize variables that will be filled in at runtime\n        self.fluid_groups = None\n        self._step_counter = None\n\n    @property\n    def fluid_system(self):\n        \"\"\"\n        Returns:\n            FluidSystem: Fluid system to use to generate / handle fluid particles\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def n_particles_per_group(self):\n        \"\"\"\n        Returns:\n            int: How many fluid particles to generate per fluid group\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def n_steps_per_group(self):\n        \"\"\"\n        Returns:\n            int: How many update() steps to occur between fluid group generations\n        \"\"\"\n        raise NotImplementedError\n\n    @staticmethod\n    def get_state_link_name():\n        # Should be implemented by subclass\n        raise NotImplementedError\n\n    def _initialize(self):\n        super()._initialize()\n        self.initialize_link_mixin()\n        fluid_source_position = self.get_link_position()\n        if fluid_source_position is None:\n            return\n\n        # Further initialize internal variables\n        self.fluid_groups = OrderedDict()\n        self._step_counter = 0\n\n    def _update(self):\n        fluid_source_position = self.get_link_position()\n        if fluid_source_position is None or not self._simulator.is_playing():\n            # Terminate early, this is a \"dead\" fluid source or we're not stepping physics\n            return\n\n        # Synchronize our tracked fluid groups with the fluid system -- some might have been deleted from a fluid sink\n        self.fluid_groups = OrderedDict([(name, inst) for name, inst in self.fluid_groups.items()\n                                         if name in self.fluid_system.particle_instancers])\n\n        # Possibly increment our fluid generation counter if we're either (a) not using any toggle state (i.e.:\n        # fluid source is always on), or (b) toggledon is True\n        self._step_counter += int(self.obj.states[ToggledOn].get_value()) if ToggledOn in self.obj.states else 1\n\n        # If our counter reaches our threshold, we generate a new fluid group\n        if self._step_counter == self.n_steps_per_group:\n            # Create positions to generate particles at\n            positions = np.ones((self.n_particles_per_group, 3)) * fluid_source_position.reshape(1, 3)\n            # Modify the z direction procedurally, to simulated a \"falling\" stream of fluid\n            particle_dist = self.fluid_system.particle_contact_offset * 2\n            positions[:, -1] -= np.arange(0, particle_dist * self.n_particles_per_group, particle_dist)\n            # Generate a new group, and store it internally\n            particle_instancer = self.fluid_system.generate_particle_instancer(\n                n_particles=self.n_particles_per_group,\n                positions=positions,\n            )\n            self.fluid_groups[particle_instancer.name] = particle_instancer\n\n            # Reset the counter\n            self._step_counter = 0\n\n    def _set_value(self, new_value):\n        raise ValueError(\"set_value not supported for FluidSource.\")\n\n    def _get_value(self):\n        pass\n\n    @staticmethod\n    def get_optional_dependencies():\n        return [ToggledOn]\n\n    @staticmethod\n    def get_dependencies():\n        return []\n</code></pre>","location":"reference/object_states/fluid_source.html#object_states.fluid_source.FluidSource"},{"title":"<code>fluid_system</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>FluidSystem</code>   <p>Fluid system to use to generate / handle fluid particles</p>","location":"reference/object_states/fluid_source.html#object_states.fluid_source.FluidSource.fluid_system"},{"title":"<code>n_particles_per_group</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>How many fluid particles to generate per fluid group</p>","location":"reference/object_states/fluid_source.html#object_states.fluid_source.FluidSource.n_particles_per_group"},{"title":"<code>n_steps_per_group</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>How many update() steps to occur between fluid group generations</p>","location":"reference/object_states/fluid_source.html#object_states.fluid_source.FluidSource.n_steps_per_group"},{"title":"folded","text":"","location":"reference/object_states/folded.html"},{"title":"<code>Folded</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>BooleanState</code></p>  Source code in <code>object_states/folded.py</code> <pre><code>class Folded(AbsoluteObjectState, BooleanState):\n\n    def calculate_projection_area_and_diagonal(self, dims):\n        \"\"\"\n        Calculate the projection area and the diagonal length when projecting to the plane defined by the input dims\n        E.g. if dims is [0, 1], the points will be projected onto the x-y plane.\n\n        Args:\n            dims (2-array): Global axes to project area onto. Options are {0, 1, 2}.\n                E.g. if dims is [0, 1], project onto the x-y plane.\n\n        Returns:\n            area (float): \n        \"\"\"\n        cloth = self.obj.links[\"base_link\"]\n        points = cloth.particle_positions[:, dims]\n\n        hull = ConvexHull(points)\n\n        diagonal = distance_matrix(points[hull.vertices], points[hull.vertices]).max()\n\n        if m.DEBUG_VISUALIZATION:\n            import matplotlib.pyplot as plt\n            ax = plt.gca()\n            ax.set_aspect('equal')\n\n            plt.plot(points[:, dims[0]], points[:, dims[1]], 'o')\n            for simplex in hull.simplices:\n                plt.plot(points[simplex, dims[0]], points[simplex, dims[1]], 'k-')\n            plt.plot(points[hull.vertices, dims[0]], points[hull.vertices, dims[1]], 'r--', lw=2)\n            plt.plot(points[hull.vertices[0], dims[0]], points[hull.vertices[0], dims[1]], 'ro')\n            plt.show()\n\n        return hull.area, diagonal\n\n    def calculate_projection_area_and_diagonal_unfolded(self):\n        \"\"\"\n        Calculate the maximum projection area and the diagonal length along different axes in the unfolded state.\n        Should be called in the initialize function. Assume the object's default pose is unfolded.\n        \"\"\"\n        # use the largest projection area as the unfolded area\n        area_unfolded = 0.0\n        diagonal_unfolded = 0.0\n        dims_list = [[0, 1], [0, 2], [1, 2]]  # x-y plane, x-z plane, y-z plane\n\n        for dims in dims_list:\n            area, diagonal = self.calculate_projection_area_and_diagonal(dims=dims)\n            if area &gt; area_unfolded:\n                area_unfolded = area\n                diagonal_unfolded = diagonal\n\n        return area_unfolded, diagonal_unfolded\n\n    def check_projection_area_and_diagonal(self):\n        \"\"\"\n        Check whether the current projection area and diagonal length satisfy the thresholds\n        \"\"\"\n        area, diagonal = self.calculate_projection_area_and_diagonal([0, 1])\n\n        # Check area reduction ratio\n        flag_area_reduction = (area / self.area_unfolded) &lt; m.AREA_REDUCTION_THRESHOLD\n\n        # Check the diagonal reduction ratio\n        flag_diagonal_reduction = (diagonal / self.diagonal_unfolded) &lt; m.DIAGONAL_REDUCTION_THRESHOLD\n\n        return flag_area_reduction, flag_diagonal_reduction\n\n    def check_smoothness(self):\n        \"\"\"\n        Check the smoothness of the cloth; the face normals of the cloth need to be close to the z-axis.\n        \"\"\"\n        cloth = self.obj.links[\"base_link\"]\n        face_vertex_counts = np.array(cloth.get_attribute(\"faceVertexCounts\"))\n        assert (face_vertex_counts == 3).all(), \"cloth prim is expected to only contain triangle faces\"\n        face_vertex_indices = np.array(cloth.get_attribute(\"faceVertexIndices\"))\n        points = cloth.particle_positions[face_vertex_indices]\n        # Shape [F, 3, 3] where F is the number of faces\n        points = points.reshape((face_vertex_indices.shape[0] // 3, 3, 3))\n\n        # Shape [F, 3]\n        v1 = points[:, 2, :] - points[:, 0, :]\n        v2 = points[:, 1, :] - points[:, 0, :]\n        normals = np.cross(v1, v2)\n        normals_norm = np.linalg.norm(normals, axis=1)\n\n        valid_normals = normals[normals_norm.nonzero()] / np.expand_dims(normals_norm[normals_norm.nonzero()], axis=1)\n        assert valid_normals.shape[0] &gt; 0\n\n        # projection onto the z-axis\n        proj = np.abs(np.dot(valid_normals, np.array([0.0, 0.0, 1.0])))\n        percentage = np.mean(proj &gt; np.cos(m.NORMAL_Z_ANGLE_DIFF))\n        return percentage &gt; m.NORMAL_Z_PERCENTAGE\n\n    def _initialize(self):\n        self.area_unfolded, self.diagonal_unfolded = self.calculate_projection_area_and_diagonal_unfolded()\n\n    def _get_value(self):\n        # Check the smoothness of the cloth\n        flag_smoothness = self.check_smoothness()\n\n        # Early stopping\n        if not flag_smoothness:\n            return False\n\n        # Calculate the area and the diagonal of the current state\n        flag_area_reduction, flag_diagonal_reduction = self.check_projection_area_and_diagonal()\n\n        return flag_diagonal_reduction and flag_smoothness\n\n    def _set_value(self, new_value):\n        \"\"\"\n        Set the folded state. Currently, it's not supported yet.\n        \"\"\"\n        raise NotImplementedError(\"_set_value of the Folded state has not been implemented\")\n</code></pre>","location":"reference/object_states/folded.html#object_states.folded.Folded"},{"title":"<code>calculate_projection_area_and_diagonal(dims)</code>","text":"<p>Calculate the projection area and the diagonal length when projecting to the plane defined by the input dims E.g. if dims is [0, 1], the points will be projected onto the x-y plane.</p> <p>Parameters:</p>    Name Type Description Default     <code>dims</code>  <code>2-array</code>  <p>Global axes to project area onto. Options are {0, 1, 2}. E.g. if dims is [0, 1], project onto the x-y plane.</p>  required     <p>Returns:</p>    Name Type Description     <code>area</code>  <code>float</code>       Source code in <code>object_states/folded.py</code> <pre><code>def calculate_projection_area_and_diagonal(self, dims):\n    \"\"\"\n    Calculate the projection area and the diagonal length when projecting to the plane defined by the input dims\n    E.g. if dims is [0, 1], the points will be projected onto the x-y plane.\n\n    Args:\n        dims (2-array): Global axes to project area onto. Options are {0, 1, 2}.\n            E.g. if dims is [0, 1], project onto the x-y plane.\n\n    Returns:\n        area (float): \n    \"\"\"\n    cloth = self.obj.links[\"base_link\"]\n    points = cloth.particle_positions[:, dims]\n\n    hull = ConvexHull(points)\n\n    diagonal = distance_matrix(points[hull.vertices], points[hull.vertices]).max()\n\n    if m.DEBUG_VISUALIZATION:\n        import matplotlib.pyplot as plt\n        ax = plt.gca()\n        ax.set_aspect('equal')\n\n        plt.plot(points[:, dims[0]], points[:, dims[1]], 'o')\n        for simplex in hull.simplices:\n            plt.plot(points[simplex, dims[0]], points[simplex, dims[1]], 'k-')\n        plt.plot(points[hull.vertices, dims[0]], points[hull.vertices, dims[1]], 'r--', lw=2)\n        plt.plot(points[hull.vertices[0], dims[0]], points[hull.vertices[0], dims[1]], 'ro')\n        plt.show()\n\n    return hull.area, diagonal\n</code></pre>","location":"reference/object_states/folded.html#object_states.folded.Folded.calculate_projection_area_and_diagonal"},{"title":"<code>calculate_projection_area_and_diagonal_unfolded()</code>","text":"<p>Calculate the maximum projection area and the diagonal length along different axes in the unfolded state. Should be called in the initialize function. Assume the object's default pose is unfolded.</p>  Source code in <code>object_states/folded.py</code> <pre><code>def calculate_projection_area_and_diagonal_unfolded(self):\n    \"\"\"\n    Calculate the maximum projection area and the diagonal length along different axes in the unfolded state.\n    Should be called in the initialize function. Assume the object's default pose is unfolded.\n    \"\"\"\n    # use the largest projection area as the unfolded area\n    area_unfolded = 0.0\n    diagonal_unfolded = 0.0\n    dims_list = [[0, 1], [0, 2], [1, 2]]  # x-y plane, x-z plane, y-z plane\n\n    for dims in dims_list:\n        area, diagonal = self.calculate_projection_area_and_diagonal(dims=dims)\n        if area &gt; area_unfolded:\n            area_unfolded = area\n            diagonal_unfolded = diagonal\n\n    return area_unfolded, diagonal_unfolded\n</code></pre>","location":"reference/object_states/folded.html#object_states.folded.Folded.calculate_projection_area_and_diagonal_unfolded"},{"title":"<code>check_projection_area_and_diagonal()</code>","text":"<p>Check whether the current projection area and diagonal length satisfy the thresholds</p>  Source code in <code>object_states/folded.py</code> <pre><code>def check_projection_area_and_diagonal(self):\n    \"\"\"\n    Check whether the current projection area and diagonal length satisfy the thresholds\n    \"\"\"\n    area, diagonal = self.calculate_projection_area_and_diagonal([0, 1])\n\n    # Check area reduction ratio\n    flag_area_reduction = (area / self.area_unfolded) &lt; m.AREA_REDUCTION_THRESHOLD\n\n    # Check the diagonal reduction ratio\n    flag_diagonal_reduction = (diagonal / self.diagonal_unfolded) &lt; m.DIAGONAL_REDUCTION_THRESHOLD\n\n    return flag_area_reduction, flag_diagonal_reduction\n</code></pre>","location":"reference/object_states/folded.html#object_states.folded.Folded.check_projection_area_and_diagonal"},{"title":"<code>check_smoothness()</code>","text":"<p>Check the smoothness of the cloth; the face normals of the cloth need to be close to the z-axis.</p>  Source code in <code>object_states/folded.py</code> <pre><code>def check_smoothness(self):\n    \"\"\"\n    Check the smoothness of the cloth; the face normals of the cloth need to be close to the z-axis.\n    \"\"\"\n    cloth = self.obj.links[\"base_link\"]\n    face_vertex_counts = np.array(cloth.get_attribute(\"faceVertexCounts\"))\n    assert (face_vertex_counts == 3).all(), \"cloth prim is expected to only contain triangle faces\"\n    face_vertex_indices = np.array(cloth.get_attribute(\"faceVertexIndices\"))\n    points = cloth.particle_positions[face_vertex_indices]\n    # Shape [F, 3, 3] where F is the number of faces\n    points = points.reshape((face_vertex_indices.shape[0] // 3, 3, 3))\n\n    # Shape [F, 3]\n    v1 = points[:, 2, :] - points[:, 0, :]\n    v2 = points[:, 1, :] - points[:, 0, :]\n    normals = np.cross(v1, v2)\n    normals_norm = np.linalg.norm(normals, axis=1)\n\n    valid_normals = normals[normals_norm.nonzero()] / np.expand_dims(normals_norm[normals_norm.nonzero()], axis=1)\n    assert valid_normals.shape[0] &gt; 0\n\n    # projection onto the z-axis\n    proj = np.abs(np.dot(valid_normals, np.array([0.0, 0.0, 1.0])))\n    percentage = np.mean(proj &gt; np.cos(m.NORMAL_Z_ANGLE_DIFF))\n    return percentage &gt; m.NORMAL_Z_PERCENTAGE\n</code></pre>","location":"reference/object_states/folded.html#object_states.folded.Folded.check_smoothness"},{"title":"frozen","text":"","location":"reference/object_states/frozen.html"},{"title":"heat_source_or_sink","text":"","location":"reference/object_states/heat_source_or_sink.html"},{"title":"<code>HeatSourceOrSink</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>LinkBasedStateMixin</code></p> <p>This state indicates the heat source or heat sink state of the object.</p> <p>Currently, if the object is not an active heat source/sink, this returns (False, None). Otherwise, it returns True and the position of the heat source element, or (True, None) if the heat source has no heating element / only checks for Inside. E.g. on a stove object, True and the coordinates of the heating element will be returned. on a microwave object, True and None will be returned.</p>  Source code in <code>object_states/heat_source_or_sink.py</code> <pre><code>class HeatSourceOrSink(AbsoluteObjectState, LinkBasedStateMixin):\n    \"\"\"\n    This state indicates the heat source or heat sink state of the object.\n\n    Currently, if the object is not an active heat source/sink, this returns (False, None).\n    Otherwise, it returns True and the position of the heat source element, or (True, None) if the heat source has no\n    heating element / only checks for Inside.\n    E.g. on a stove object, True and the coordinates of the heating element will be returned.\n    on a microwave object, True and None will be returned.\n    \"\"\"\n\n    def __init__(\n        self,\n        obj,\n        temperature=m.DEFAULT_TEMPERATURE,\n        heating_rate=m.DEFAULT_HEATING_RATE,\n        distance_threshold=m.DEFAULT_DISTANCE_THRESHOLD,\n        requires_toggled_on=False,\n        requires_closed=False,\n        requires_inside=False,\n    ):\n        \"\"\"\n        Args:\n            obj (StatefulObject): The object with the heat source ability.\n            temperature (float): The temperature of the heat source.\n            heating_rate (float): Fraction in [0, 1] of the temperature difference with the\n                heat source temperature should be received every step, per second.\n            distance_threshold (float): The distance threshold which an object needs\n                to be closer than in order to receive heat from this heat source.\n            requires_toggled_on (bool): Whether the heat source object needs to be\n                toggled on to emit heat. Requires toggleable ability if set to True.\n            requires_closed (bool): Whether the heat source object needs to be\n                closed (e.g. in terms of the joints) to emit heat. Requires openable\n                ability if set to True.\n            requires_inside (bool): Whether an object needs to be `inside` the\n                heat source to receive heat. See the Inside state for details. This\n                will mean that the \"heating element\" link for the object will be\n                ignored.\n        \"\"\"\n        super(HeatSourceOrSink, self).__init__(obj)\n        self.temperature = temperature\n        self.heating_rate = heating_rate\n        self.distance_threshold = distance_threshold\n\n        # If the heat source needs to be toggled on, we assert the presence\n        # of that ability.\n        if requires_toggled_on:\n            assert ToggledOn in self.obj.states\n        self.requires_toggled_on = requires_toggled_on\n\n        # If the heat source needs to be closed, we assert the presence\n        # of that ability.\n        if requires_closed:\n            assert Open in self.obj.states\n        self.requires_closed = requires_closed\n\n        # If the heat source needs to contain an object inside to heat it,\n        # we record that for use in the heat transfer process.\n        self.requires_inside = requires_inside\n\n        self.marker = None\n        self.status = None\n        self.position = None\n\n    @staticmethod\n    def get_dependencies():\n        return AbsoluteObjectState.get_dependencies() + [AABB, Inside]\n\n    @staticmethod\n    def get_optional_dependencies():\n        return AbsoluteObjectState.get_optional_dependencies() + [ToggledOn, Open]\n\n    @staticmethod\n    def get_state_link_name():\n        return m.HEATING_ELEMENT_LINK_NAME\n\n    def _compute_state_and_position(self):\n        # Find the link first. Note that the link is only required\n        # if the object is not in self.requires_inside mode.\n        heating_element_position = self.get_link_position()\n        if not self.requires_inside and heating_element_position is None:\n            return False, None\n\n        # Check the toggle state.\n        if self.requires_toggled_on and not self.obj.states[ToggledOn].get_value():\n            return False, None\n\n        # Check the open state.\n        if self.requires_closed and self.obj.states[Open].get_value():\n            return False, None\n\n        # Return True and the heating element position (or None if not required).\n        return True, (heating_element_position if not self.requires_inside else None)\n\n    def _initialize(self):\n        # Run super first\n        super()._initialize()\n        self.initialize_link_mixin()\n\n    def _update(self):\n        self.status, self.position = self._compute_state_and_position()\n\n    def _get_value(self):\n        return self.status, self.position\n\n    def _set_value(self, new_value):\n        raise NotImplementedError(\"Setting heat source capability is not supported.\")\n</code></pre>","location":"reference/object_states/heat_source_or_sink.html#object_states.heat_source_or_sink.HeatSourceOrSink"},{"title":"<code>__init__(obj, temperature=m.DEFAULT_TEMPERATURE, heating_rate=m.DEFAULT_HEATING_RATE, distance_threshold=m.DEFAULT_DISTANCE_THRESHOLD, requires_toggled_on=False, requires_closed=False, requires_inside=False)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>StatefulObject</code>  <p>The object with the heat source ability.</p>  required    <code>temperature</code>  <code>float</code>  <p>The temperature of the heat source.</p>  <code>m.DEFAULT_TEMPERATURE</code>    <code>heating_rate</code>  <code>float</code>  <p>Fraction in [0, 1] of the temperature difference with the heat source temperature should be received every step, per second.</p>  <code>m.DEFAULT_HEATING_RATE</code>    <code>distance_threshold</code>  <code>float</code>  <p>The distance threshold which an object needs to be closer than in order to receive heat from this heat source.</p>  <code>m.DEFAULT_DISTANCE_THRESHOLD</code>    <code>requires_toggled_on</code>  <code>bool</code>  <p>Whether the heat source object needs to be toggled on to emit heat. Requires toggleable ability if set to True.</p>  <code>False</code>    <code>requires_closed</code>  <code>bool</code>  <p>Whether the heat source object needs to be closed (e.g. in terms of the joints) to emit heat. Requires openable ability if set to True.</p>  <code>False</code>    <code>requires_inside</code>  <code>bool</code>  <p>Whether an object needs to be <code>inside</code> the heat source to receive heat. See the Inside state for details. This will mean that the \"heating element\" link for the object will be ignored.</p>  <code>False</code>      Source code in <code>object_states/heat_source_or_sink.py</code> <pre><code>def __init__(\n    self,\n    obj,\n    temperature=m.DEFAULT_TEMPERATURE,\n    heating_rate=m.DEFAULT_HEATING_RATE,\n    distance_threshold=m.DEFAULT_DISTANCE_THRESHOLD,\n    requires_toggled_on=False,\n    requires_closed=False,\n    requires_inside=False,\n):\n    \"\"\"\n    Args:\n        obj (StatefulObject): The object with the heat source ability.\n        temperature (float): The temperature of the heat source.\n        heating_rate (float): Fraction in [0, 1] of the temperature difference with the\n            heat source temperature should be received every step, per second.\n        distance_threshold (float): The distance threshold which an object needs\n            to be closer than in order to receive heat from this heat source.\n        requires_toggled_on (bool): Whether the heat source object needs to be\n            toggled on to emit heat. Requires toggleable ability if set to True.\n        requires_closed (bool): Whether the heat source object needs to be\n            closed (e.g. in terms of the joints) to emit heat. Requires openable\n            ability if set to True.\n        requires_inside (bool): Whether an object needs to be `inside` the\n            heat source to receive heat. See the Inside state for details. This\n            will mean that the \"heating element\" link for the object will be\n            ignored.\n    \"\"\"\n    super(HeatSourceOrSink, self).__init__(obj)\n    self.temperature = temperature\n    self.heating_rate = heating_rate\n    self.distance_threshold = distance_threshold\n\n    # If the heat source needs to be toggled on, we assert the presence\n    # of that ability.\n    if requires_toggled_on:\n        assert ToggledOn in self.obj.states\n    self.requires_toggled_on = requires_toggled_on\n\n    # If the heat source needs to be closed, we assert the presence\n    # of that ability.\n    if requires_closed:\n        assert Open in self.obj.states\n    self.requires_closed = requires_closed\n\n    # If the heat source needs to contain an object inside to heat it,\n    # we record that for use in the heat transfer process.\n    self.requires_inside = requires_inside\n\n    self.marker = None\n    self.status = None\n    self.position = None\n</code></pre>","location":"reference/object_states/heat_source_or_sink.html#object_states.heat_source_or_sink.HeatSourceOrSink.__init__"},{"title":"heated","text":"","location":"reference/object_states/heated.html"},{"title":"inside","text":"","location":"reference/object_states/inside.html"},{"title":"kinematics","text":"","location":"reference/object_states/kinematics.html"},{"title":"<code>KinematicsMixin</code>","text":"<p>         Bases: <code>BaseObjectState</code></p> <p>This class is a subclass of BaseObjectState that adds dependencies on the default kinematics states.</p>  Source code in <code>object_states/kinematics.py</code> <pre><code>class KinematicsMixin(BaseObjectState):\n    \"\"\"\n    This class is a subclass of BaseObjectState that adds dependencies\n    on the default kinematics states.\n    \"\"\"\n\n    @staticmethod\n    def get_dependencies():\n        return BaseObjectState.get_dependencies() + [Pose, AABB, ContactBodies]\n\n    def cache_info(self, get_value_args):\n        # Import here to avoid circular imports\n        from omnigibson.objects.stateful_object import StatefulObject\n\n        # Run super first\n        info = super().cache_info(get_value_args=get_value_args)\n\n        # Store this object as well as any other objects from @get_value_args\n        info[self.obj] = self.obj.states[Pose].get_value()\n        for arg in get_value_args:\n            if isinstance(arg, StatefulObject):\n                info[arg] = arg.states[Pose].get_value()\n\n        return info\n\n    def _cache_is_valid(self, get_value_args):\n        # Cache is valid if and only if all of our cached objects have not changed\n        t = self._cache[get_value_args][\"t\"]\n        for obj, pose in self._cache[get_value_args][\"info\"].items():\n            if obj.states[Pose].has_changed(get_value_args=(), value=pose, info={}, t=t):\n                return False\n        return True\n</code></pre>","location":"reference/object_states/kinematics.html#object_states.kinematics.KinematicsMixin"},{"title":"link_based_state_mixin","text":"","location":"reference/object_states/link_based_state_mixin.html"},{"title":"max_temperature","text":"","location":"reference/object_states/max_temperature.html"},{"title":"<code>MaxTemperature</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code></p> <p>This state remembers the highest temperature reached by an object.</p>  Source code in <code>object_states/max_temperature.py</code> <pre><code>class MaxTemperature(AbsoluteObjectState):\n    \"\"\"\n    This state remembers the highest temperature reached by an object.\n    \"\"\"\n\n    @staticmethod\n    def get_dependencies():\n        return AbsoluteObjectState.get_dependencies() + [Temperature]\n\n    def __init__(self, obj):\n        super(MaxTemperature, self).__init__(obj)\n\n        self.value = float(\"-inf\")\n\n    def _get_value(self):\n        return self.value\n\n    def _set_value(self, new_value):\n        self.value = new_value\n        return True\n\n    def _update(self):\n        self.value = max(self.obj.states[Temperature].get_value(), self.value)\n\n    @property\n    def state_size(self):\n        return 1\n\n    def _dump_state(self):\n        return OrderedDict(temperature=self.value)\n\n    def _load_state(self, state):\n        self.value = state[\"temperature\"]\n\n    def _serialize(self, state):\n        return np.array([state[\"temperature\"]], dtype=float)\n\n    def _deserialize(self, state):\n        return OrderedDict(temperature=state[0]), 1\n</code></pre>","location":"reference/object_states/max_temperature.html#object_states.max_temperature.MaxTemperature"},{"title":"next_to","text":"","location":"reference/object_states/next_to.html"},{"title":"object_state_base","text":"","location":"reference/object_states/object_state_base.html"},{"title":"<code>AbsoluteObjectState</code>","text":"<p>         Bases: <code>BaseObjectState</code></p> <p>This class is used to track object states that are absolute, e.g. do not require a second object to compute the value.</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>class AbsoluteObjectState(BaseObjectState):\n    \"\"\"\n    This class is used to track object states that are absolute, e.g. do not require a second object to compute\n    the value.\n    \"\"\"\n\n    @abstractmethod\n    def _get_value(self):\n        raise NotImplementedError()\n\n    @abstractmethod\n    def _set_value(self, new_value):\n        raise NotImplementedError()\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"AbsoluteObjectState\")\n        return classes\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.AbsoluteObjectState"},{"title":"<code>BaseObjectState</code>","text":"<p>         Bases: <code>Serializable</code>, <code>Registerable</code>, <code>Recreatable</code>, <code>ABC</code></p> <p>Base ObjectState class. Do NOT inherit from this class directly - use either AbsoluteObjectState or RelativeObjectState.</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>class BaseObjectState(Serializable, Registerable, Recreatable, ABC):\n    \"\"\"\n    Base ObjectState class. Do NOT inherit from this class directly - use either AbsoluteObjectState or\n    RelativeObjectState.\n    \"\"\"\n\n    @staticmethod\n    def get_dependencies():\n        \"\"\"\n        Get the dependency states for this state, e.g. states that need to be explicitly enabled on the current object\n        before the current state is usable. States listed here will be enabled for all objects that have this current\n        state, and all dependency states will be processed on *all* objects prior to this state being processed on\n        *any* object.\n\n        Returns:\n            list of str: List of strings corresponding to state keys.\n        \"\"\"\n        return []\n\n    @staticmethod\n    def get_optional_dependencies():\n        \"\"\"\n        Get states that should be processed prior to this state if they are already enabled. These states will not be\n        enabled because of this state's dependency on them, but if they are already enabled for another reason (e.g.\n        because of an ability or another state's dependency etc.), they will be processed on *all* objects prior to this\n        state being processed on *any* object.\n\n        Returns:\n            list of str: List of strings corresponding to state keys.\n        \"\"\"\n        return []\n\n    def __init__(self, obj):\n        super().__init__()\n        self.obj = obj\n        self._initialized = False\n        self._cache = None\n        self._changed = None\n        self._simulator = None\n\n    @property\n    def stateful(self):\n        \"\"\"\n        Returns:\n            bool: True if this object has a state that can be directly dumped / loaded via dump_state() and\n                load_state(), otherwise, returns False. Note that any sub object states that are NOT stateful do\n                not need to implement any of _dump_state(), _load_state(), _serialize(), or _deserialize()!\n        \"\"\"\n        # Default is whether state size &gt; 0\n        return self.state_size &gt; 0\n\n    @property\n    def state_size(self):\n        return 0\n\n    def reset(self):\n        \"\"\"\n        Resets this object state. By default, it clears all internal caching data\n        \"\"\"\n        self._cache = OrderedDict()\n        self._changed = OrderedDict()\n\n    @property\n    def cache(self):\n        \"\"\"\n        Returns:\n            OrdereDict: Dictionary mapping specific argument combinations from @self.get_value() to cached values and\n                information stored for that specific combination\n        \"\"\"\n        return self._cache\n\n    def _update(self):\n        \"\"\"\n        This function will be called once for every simulator step.\n        \"\"\"\n        pass\n\n    def _initialize(self):\n        \"\"\"\n        This function will be called once; should be used for any object state-related objects have been loaded.\n        \"\"\"\n        pass\n\n    def initialize(self, simulator):\n        \"\"\"\n        Initialize this object state\n        \"\"\"\n        assert not self._initialized, \"State is already initialized.\"\n\n        # Store simulator reference and create cache\n        self._simulator = simulator\n        self.reset()\n\n        self._initialize()\n        self._initialized = True\n\n    def update(self):\n        \"\"\"\n        Updates the object state, possibly clearing internal cached information\n        \"\"\"\n        assert self._initialized, \"Cannot update uninitialized state.\"\n        # Clear all the changed values\n        self._changed = OrderedDict()\n        return self._update()\n\n    def clear_cache(self):\n        \"\"\"\n        Clears the internal cache\n        \"\"\"\n        # Clear all entries\n        self._cache = OrderedDict()\n\n    def update_cache(self, get_value_args):\n        \"\"\"\n        Updates the internal cached value based on the evaluation of @self._get_value(*get_value_args)\n\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value / @self._get_value\n        \"\"\"\n        t = og.sim.current_time_step_index\n        # Compute value and update cache\n        val = self._get_value(*get_value_args)\n        self._cache[get_value_args] = OrderedDict(value=val, info=self.cache_info(get_value_args=get_value_args), t=t)\n\n    def cache_info(self, get_value_args):\n        \"\"\"\n        Helper function to cache relevant information at the current timestep.\n        Stores it under @self._cache[&lt;KEY&gt;][\"info\"]\n\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value whose caching information should be computed\n\n        Returns:\n            OrderedDict: Any caching information to include at the current timestep when this state's value is computed\n        \"\"\"\n        # Default is an empty dictionary\n        return OrderedDict()\n\n    def cache_is_valid(self, get_value_args):\n        \"\"\"\n        Helper function to check whether the current cached value is valid or not at the current timestep.\n        Default is False unless we're at the current timestep.\n\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value whose cached values should be validated\n\n        Returns:\n            bool: True if the cache is valid, else False\n        \"\"\"\n        # If t == the current timestep, then our cache is obviously valid otherwise we assume it isn't\n        return True if self._cache[get_value_args][\"t\"] == og.sim.current_time_step_index else \\\n            self._cache_is_valid(get_value_args=get_value_args)\n\n    def _cache_is_valid(self, get_value_args):\n        \"\"\"\n        Helper function to check whether the current cached value is valid or not at the current timestep.\n        Default is False. Subclasses should implement special logic otherwise.\n\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value whose cached values should be validated\n\n        Returns:\n            bool: True if the cache is valid, else False\n        \"\"\"\n        return False\n\n    def has_changed(self, get_value_args, value, info, t):\n        \"\"\"\n        A helper function to query whether this object state has changed between an arbitrary previous timestep @t with\n        corresponding cached value @value and cache information @info\n        the current timestep.\n\n        Note that this may require some non-trivial compute, so we leverage @t, in addition to @get_value_args,\n        as a unique key into an internal dictionary, such that specific @t will result in a computation conducted\n        exactly once.\n        This is done for performance reasons; so that multiple states relying on the same state dependency can all\n        query whether that state has changed between the same timesteps with only a single computation.\n\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value\n            value (any): Cached value computed at timestep @t for this object state\n            info (OrderedDict): Information calculated at timestep @t when computing this state's value\n            t (int): Initial timestep to compare against. This should be an index of the steps taken,\n                i.e. a value queried from og.sim.current_time_step_index at some point in time. It is assumed @value\n                and @info were computed at this timestep\n\n        Returns:\n            bool: Whether this object state has changed between @t and the current timestep index for the specific\n                @get_value_args\n        \"\"\"\n        # Compile t, args, and kwargs deterministically\n        history_key = (t, *get_value_args)\n        # If t == the current timestep, then we obviously haven't changed so our value is False\n        if t == og.sim.current_time_step_index:\n            val = False\n        # Otherwise, check if it already exists in our has changed dictionary; we return that value if so\n        elif history_key in self._changed:\n            val = self._changed[history_key]\n        # Otherwise, we calculate the value and store it in our changed dictionary\n        else:\n            val = self._has_changed(get_value_args=get_value_args, value=value, info=info)\n            self._changed[history_key] = val\n\n        return val\n\n    def _has_changed(self, get_value_args, value, info):\n        \"\"\"\n        Checks whether the previous value evaluated at time @t has changed with the current timestep.\n        By default, it returns True.\n\n        Any custom checks should be overridden by subclass.\n\n        Args:\n            get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n                @self.get_value\n            value (any): Cached value computed at timestep @t for this object state\n            info (OrderedDict): Information calculated at timestep @t when computing this state's value\n\n        Returns:\n            bool: Whether the value has changed between @value and @info and the coresponding value and info computed\n                at the current timestep\n        \"\"\"\n        return True\n\n    def get_value(self, *args, **kwargs):\n        \"\"\"\n        Get this state's value\n\n        Returns:\n            any: Object state value given input @args and @kwargs\n        \"\"\"\n        assert self._initialized\n\n        # Compile args and kwargs deterministically\n        key = (*args, *tuple(kwargs.values()))\n        # We need to see if we need to update our cache -- we do so if and only if one of the following conditions are met:\n        # (a) key is NOT in the cache\n        # (b) Our cache is not valid\n        if key not in self._cache or not self.cache_is_valid(get_value_args=key):\n            # Update the cache\n            self.update_cache(get_value_args=key)\n\n        # Value is the cached value\n        val = self._cache[key][\"value\"]\n\n        return val\n\n    def _get_value(self, *args, **kwargs):\n        raise NotImplementedError\n\n    def set_value(self, *args, **kwargs):\n        \"\"\"\n        Set this state's value\n\n        Returns:\n            bool: True if setting the value was successful, otherwise False\n        \"\"\"\n        assert self._initialized\n        # Clear cache because the state may be changed\n        self.clear_cache()\n        # Set the value\n        val = self._set_value(*args, **kwargs)\n        return val\n\n    def _set_value(self, *args, **kwargs):\n        raise NotImplementedError\n\n    def remove(self):\n        \"\"\"\n        Any cleanup functionality to deploy when @self.obj is removed from the simulator\n        \"\"\"\n        pass\n\n    def dump_state(self, serialized=False):\n        assert self._initialized\n        assert self.stateful\n        return super().dump_state(serialized=serialized)\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseObjectState\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_OBJECT_STATES\n        return REGISTERED_OBJECT_STATES\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState"},{"title":"<code>cache</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrdereDict</code>   <p>Dictionary mapping specific argument combinations from @self.get_value() to cached values and information stored for that specific combination</p>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.cache"},{"title":"<code>stateful</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if this object has a state that can be directly dumped / loaded via dump_state() and load_state(), otherwise, returns False. Note that any sub object states that are NOT stateful do not need to implement any of _dump_state(), _load_state(), _serialize(), or _deserialize()!</p>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.stateful"},{"title":"<code>cache_info(get_value_args)</code>","text":"<p>Helper function to cache relevant information at the current timestep. Stores it under @self._cache <p>Parameters:</p>    Name Type Description Default     <code>get_value_args</code>  <code>tuple</code>  <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value whose caching information should be computed</p>  required     <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Any caching information to include at the current timestep when this state's value is computed</p>     Source code in <code>object_states/object_state_base.py</code> <pre><code>def cache_info(self, get_value_args):\n    \"\"\"\n    Helper function to cache relevant information at the current timestep.\n    Stores it under @self._cache[&lt;KEY&gt;][\"info\"]\n\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value whose caching information should be computed\n\n    Returns:\n        OrderedDict: Any caching information to include at the current timestep when this state's value is computed\n    \"\"\"\n    # Default is an empty dictionary\n    return OrderedDict()\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.cache_info"},{"title":"<code>cache_is_valid(get_value_args)</code>","text":"<p>Helper function to check whether the current cached value is valid or not at the current timestep. Default is False unless we're at the current timestep.</p> <p>Parameters:</p>    Name Type Description Default     <code>get_value_args</code>  <code>tuple</code>  <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value whose cached values should be validated</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if the cache is valid, else False</p>     Source code in <code>object_states/object_state_base.py</code> <pre><code>def cache_is_valid(self, get_value_args):\n    \"\"\"\n    Helper function to check whether the current cached value is valid or not at the current timestep.\n    Default is False unless we're at the current timestep.\n\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value whose cached values should be validated\n\n    Returns:\n        bool: True if the cache is valid, else False\n    \"\"\"\n    # If t == the current timestep, then our cache is obviously valid otherwise we assume it isn't\n    return True if self._cache[get_value_args][\"t\"] == og.sim.current_time_step_index else \\\n        self._cache_is_valid(get_value_args=get_value_args)\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.cache_is_valid"},{"title":"<code>clear_cache()</code>","text":"<p>Clears the internal cache</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>def clear_cache(self):\n    \"\"\"\n    Clears the internal cache\n    \"\"\"\n    # Clear all entries\n    self._cache = OrderedDict()\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.clear_cache"},{"title":"<code>get_dependencies()</code>  <code>staticmethod</code>","text":"<p>Get the dependency states for this state, e.g. states that need to be explicitly enabled on the current object before the current state is usable. States listed here will be enabled for all objects that have this current state, and all dependency states will be processed on all objects prior to this state being processed on any object.</p> <p>Returns:</p>    Type Description       <p>list of str: List of strings corresponding to state keys.</p>     Source code in <code>object_states/object_state_base.py</code> <pre><code>@staticmethod\ndef get_dependencies():\n    \"\"\"\n    Get the dependency states for this state, e.g. states that need to be explicitly enabled on the current object\n    before the current state is usable. States listed here will be enabled for all objects that have this current\n    state, and all dependency states will be processed on *all* objects prior to this state being processed on\n    *any* object.\n\n    Returns:\n        list of str: List of strings corresponding to state keys.\n    \"\"\"\n    return []\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.get_dependencies"},{"title":"<code>get_optional_dependencies()</code>  <code>staticmethod</code>","text":"<p>Get states that should be processed prior to this state if they are already enabled. These states will not be enabled because of this state's dependency on them, but if they are already enabled for another reason (e.g. because of an ability or another state's dependency etc.), they will be processed on all objects prior to this state being processed on any object.</p> <p>Returns:</p>    Type Description       <p>list of str: List of strings corresponding to state keys.</p>     Source code in <code>object_states/object_state_base.py</code> <pre><code>@staticmethod\ndef get_optional_dependencies():\n    \"\"\"\n    Get states that should be processed prior to this state if they are already enabled. These states will not be\n    enabled because of this state's dependency on them, but if they are already enabled for another reason (e.g.\n    because of an ability or another state's dependency etc.), they will be processed on *all* objects prior to this\n    state being processed on *any* object.\n\n    Returns:\n        list of str: List of strings corresponding to state keys.\n    \"\"\"\n    return []\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.get_optional_dependencies"},{"title":"<code>get_value(*args, **kwargs)</code>","text":"<p>Get this state's value</p> <p>Returns:</p>    Name Type Description     <code>any</code>   <p>Object state value given input @args and @kwargs</p>     Source code in <code>object_states/object_state_base.py</code> <pre><code>def get_value(self, *args, **kwargs):\n    \"\"\"\n    Get this state's value\n\n    Returns:\n        any: Object state value given input @args and @kwargs\n    \"\"\"\n    assert self._initialized\n\n    # Compile args and kwargs deterministically\n    key = (*args, *tuple(kwargs.values()))\n    # We need to see if we need to update our cache -- we do so if and only if one of the following conditions are met:\n    # (a) key is NOT in the cache\n    # (b) Our cache is not valid\n    if key not in self._cache or not self.cache_is_valid(get_value_args=key):\n        # Update the cache\n        self.update_cache(get_value_args=key)\n\n    # Value is the cached value\n    val = self._cache[key][\"value\"]\n\n    return val\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.get_value"},{"title":"<code>has_changed(get_value_args, value, info, t)</code>","text":"<p>A helper function to query whether this object state has changed between an arbitrary previous timestep @t with corresponding cached value @value and cache information @info the current timestep.</p> <p>Note that this may require some non-trivial compute, so we leverage @t, in addition to @get_value_args, as a unique key into an internal dictionary, such that specific @t will result in a computation conducted exactly once. This is done for performance reasons; so that multiple states relying on the same state dependency can all query whether that state has changed between the same timesteps with only a single computation.</p> <p>Parameters:</p>    Name Type Description Default     <code>get_value_args</code>  <code>tuple</code>  <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value</p>  required    <code>value</code>  <code>any</code>  <p>Cached value computed at timestep @t for this object state</p>  required    <code>info</code>  <code>OrderedDict</code>  <p>Information calculated at timestep @t when computing this state's value</p>  required    <code>t</code>  <code>int</code>  <p>Initial timestep to compare against. This should be an index of the steps taken, i.e. a value queried from og.sim.current_time_step_index at some point in time. It is assumed @value and @info were computed at this timestep</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this object state has changed between @t and the current timestep index for the specific @get_value_args</p>     Source code in <code>object_states/object_state_base.py</code> <pre><code>def has_changed(self, get_value_args, value, info, t):\n    \"\"\"\n    A helper function to query whether this object state has changed between an arbitrary previous timestep @t with\n    corresponding cached value @value and cache information @info\n    the current timestep.\n\n    Note that this may require some non-trivial compute, so we leverage @t, in addition to @get_value_args,\n    as a unique key into an internal dictionary, such that specific @t will result in a computation conducted\n    exactly once.\n    This is done for performance reasons; so that multiple states relying on the same state dependency can all\n    query whether that state has changed between the same timesteps with only a single computation.\n\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value\n        value (any): Cached value computed at timestep @t for this object state\n        info (OrderedDict): Information calculated at timestep @t when computing this state's value\n        t (int): Initial timestep to compare against. This should be an index of the steps taken,\n            i.e. a value queried from og.sim.current_time_step_index at some point in time. It is assumed @value\n            and @info were computed at this timestep\n\n    Returns:\n        bool: Whether this object state has changed between @t and the current timestep index for the specific\n            @get_value_args\n    \"\"\"\n    # Compile t, args, and kwargs deterministically\n    history_key = (t, *get_value_args)\n    # If t == the current timestep, then we obviously haven't changed so our value is False\n    if t == og.sim.current_time_step_index:\n        val = False\n    # Otherwise, check if it already exists in our has changed dictionary; we return that value if so\n    elif history_key in self._changed:\n        val = self._changed[history_key]\n    # Otherwise, we calculate the value and store it in our changed dictionary\n    else:\n        val = self._has_changed(get_value_args=get_value_args, value=value, info=info)\n        self._changed[history_key] = val\n\n    return val\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.has_changed"},{"title":"<code>initialize(simulator)</code>","text":"<p>Initialize this object state</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>def initialize(self, simulator):\n    \"\"\"\n    Initialize this object state\n    \"\"\"\n    assert not self._initialized, \"State is already initialized.\"\n\n    # Store simulator reference and create cache\n    self._simulator = simulator\n    self.reset()\n\n    self._initialize()\n    self._initialized = True\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.initialize"},{"title":"<code>remove()</code>","text":"<p>Any cleanup functionality to deploy when @self.obj is removed from the simulator</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>def remove(self):\n    \"\"\"\n    Any cleanup functionality to deploy when @self.obj is removed from the simulator\n    \"\"\"\n    pass\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.remove"},{"title":"<code>reset()</code>","text":"<p>Resets this object state. By default, it clears all internal caching data</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Resets this object state. By default, it clears all internal caching data\n    \"\"\"\n    self._cache = OrderedDict()\n    self._changed = OrderedDict()\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.reset"},{"title":"<code>set_value(*args, **kwargs)</code>","text":"<p>Set this state's value</p> <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if setting the value was successful, otherwise False</p>     Source code in <code>object_states/object_state_base.py</code> <pre><code>def set_value(self, *args, **kwargs):\n    \"\"\"\n    Set this state's value\n\n    Returns:\n        bool: True if setting the value was successful, otherwise False\n    \"\"\"\n    assert self._initialized\n    # Clear cache because the state may be changed\n    self.clear_cache()\n    # Set the value\n    val = self._set_value(*args, **kwargs)\n    return val\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.set_value"},{"title":"<code>update()</code>","text":"<p>Updates the object state, possibly clearing internal cached information</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>def update(self):\n    \"\"\"\n    Updates the object state, possibly clearing internal cached information\n    \"\"\"\n    assert self._initialized, \"Cannot update uninitialized state.\"\n    # Clear all the changed values\n    self._changed = OrderedDict()\n    return self._update()\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.update"},{"title":"<code>update_cache(get_value_args)</code>","text":"<p>Updates the internal cached value based on the evaluation of @self._get_value(*get_value_args)</p> <p>Parameters:</p>    Name Type Description Default     <code>get_value_args</code>  <code>tuple</code>  <p>Specific argument combinations (usually tuple of objects) passed into @self.get_value / @self._get_value</p>  required      Source code in <code>object_states/object_state_base.py</code> <pre><code>def update_cache(self, get_value_args):\n    \"\"\"\n    Updates the internal cached value based on the evaluation of @self._get_value(*get_value_args)\n\n    Args:\n        get_value_args (tuple): Specific argument combinations (usually tuple of objects) passed into\n            @self.get_value / @self._get_value\n    \"\"\"\n    t = og.sim.current_time_step_index\n    # Compute value and update cache\n    val = self._get_value(*get_value_args)\n    self._cache[get_value_args] = OrderedDict(value=val, info=self.cache_info(get_value_args=get_value_args), t=t)\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BaseObjectState.update_cache"},{"title":"<code>BooleanState</code>","text":"<p>This class is a mixin used to indicate that a state has a boolean value.</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>class BooleanState:\n    \"\"\"\n    This class is a mixin used to indicate that a state has a boolean value.\n    \"\"\"\n\n    pass\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.BooleanState"},{"title":"<code>RelativeObjectState</code>","text":"<p>         Bases: <code>BaseObjectState</code></p> <p>This class is used to track object states that are relative, e.g. require two objects to compute a value. Note that subclasses will typically compute values on-the-fly.</p>  Source code in <code>object_states/object_state_base.py</code> <pre><code>class RelativeObjectState(BaseObjectState):\n    \"\"\"\n    This class is used to track object states that are relative, e.g. require two objects to compute a value.\n    Note that subclasses will typically compute values on-the-fly.\n    \"\"\"\n\n    @abstractmethod\n    def _get_value(self, other):\n        raise NotImplementedError()\n\n    @abstractmethod\n    def _set_value(self, other, new_value):\n        raise NotImplementedError()\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"RelativeObjectState\")\n        return classes\n</code></pre>","location":"reference/object_states/object_state_base.html#object_states.object_state_base.RelativeObjectState"},{"title":"on_top","text":"","location":"reference/object_states/on_top.html"},{"title":"open","text":"","location":"reference/object_states/open.html"},{"title":"<code>Open</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>BooleanState</code></p>  Source code in <code>object_states/open.py</code> <pre><code>class Open(AbsoluteObjectState, BooleanState):\n    def _get_value(self):\n        both_sides, relevant_joints, joint_directions = _get_relevant_joints(self.obj)\n        if not relevant_joints:\n            return False\n\n        # The \"sides\" variable is used to check open/closed state for objects whose joints can switch\n        # positions. These objects are annotated with the both_sides annotation and the idea is that switching\n        # the directions of *all* of the joints results in a similarly valid checkable state. As a result, to check\n        # each \"side\", we multiply *all* of the joint directions with the coefficient belonging to that side, which\n        # may be 1 or -1.\n        sides = [1, -1] if both_sides else [1]\n\n        sides_openness = []\n        for side in sides:\n            # Compute a boolean openness state for each joint by comparing positions to thresholds.\n            joint_thresholds = (\n                _compute_joint_threshold(joint, joint_direction * side)\n                for joint, joint_direction in zip(relevant_joints, joint_directions)\n            )\n            joint_positions = [joint.get_state()[0] for joint in relevant_joints]\n            joint_openness = (\n                _is_in_range(position, threshold, open_end)\n                for position, (threshold, open_end, closed_end) in zip(joint_positions, joint_thresholds)\n            )\n\n            # Looking from this side, the object is open if any of its joints is open.\n            sides_openness.append(any(joint_openness))\n\n        # The object is open only if it's open from all of its sides.\n        return all(sides_openness)\n\n    def _set_value(self, new_value, fully=False):\n        \"\"\"\n        Set the openness state, either to a random joint position satisfying the new value, or fully open/closed.\n\n        @param new_value: bool value for the openness state of the object.\n        @param fully: whether the object should be fully opened/closed (e.g. all relevant joints to 0/1).\n        @return: bool indicating setter success. Failure may happen due to unannotated objects.\n        \"\"\"\n        both_sides, relevant_joints, joint_directions = _get_relevant_joints(self.obj)\n        if not relevant_joints:\n            return False\n\n        # The \"sides\" variable is used to check open/closed state for objects whose joints can switch\n        # positions. These objects are annotated with the both_sides annotation and the idea is that switching\n        # the directions of *all* of the joints results in a similarly valid checkable state. We want our object to be\n        # open from *both* of the two sides, and I was too lazy to implement the logic for this without rejection\n        # sampling, so that's what we do.\n        # TODO: Implement a sampling method that's guaranteed to be correct, ditch the rejection method.\n        sides = [1, -1] if both_sides else [1]\n\n        for _ in range(m.OPEN_SAMPLING_ATTEMPTS):\n            side = random.choice(sides)\n\n            # All joints are relevant if we are closing, but if we are opening let's sample a subset.\n            if new_value and not fully:\n                num_to_open = random.randint(1, len(relevant_joints))\n                relevant_joints = random.sample(relevant_joints, num_to_open)\n\n            # Go through the relevant joints &amp; set random positions.\n            for joint, joint_direction in zip(relevant_joints, joint_directions):\n                threshold, open_end, closed_end = _compute_joint_threshold(joint, joint_direction * side)\n\n                # Get the range\n                if new_value:\n                    joint_range = (threshold, open_end)\n                else:\n                    joint_range = (threshold, closed_end)\n\n                if fully:\n                    joint_pos = joint_range[1]\n                else:\n                    # Convert the range to the format numpy accepts.\n                    low = min(joint_range)\n                    high = max(joint_range)\n\n                    # Sample a position.\n                    joint_pos = random.uniform(low, high)\n\n                # Save sampled position.\n                joint.set_pos(joint_pos)\n\n            # If we succeeded, return now.\n            if self._get_value() == new_value:\n                return True\n\n        # We exhausted our attempts and could not find a working sample.\n        return False\n</code></pre>","location":"reference/object_states/open.html#object_states.open.Open"},{"title":"particle_modifier","text":"","location":"reference/object_states/particle_modifier.html"},{"title":"<code>ParticleApplier</code>","text":"<p>         Bases: <code>ParticleModifier</code></p> <p>ParticleModifier where the modification results in potentially adding particles into the simulation.</p>  Source code in <code>object_states/particle_modifier.py</code> <pre><code>class ParticleApplier(ParticleModifier):\n    \"\"\"\n    ParticleModifier where the modification results in potentially adding particles into the simulation.\n    \"\"\"\n    def __init__(self, obj, method, conditions, projection_mesh_params=None):\n        # Store internal value\n        self._sample_particle_locations = None\n\n        # Run super\n        super().__init__(obj=obj, method=method, conditions=conditions, projection_mesh_params=projection_mesh_params)\n\n    def _initialize(self):\n        # First, sanity check to make sure only one system is being applied, since unlike a ParticleRemover, which\n        # can potentially remove multiple types of particles, a ParticleApplier should only apply one type of particle\n        assert len(self.conditions) == 1, f\"A ParticleApplier can only have a single ParticleSystem associated \" \\\n                                          f\"with it! Got: {[system.name for system in self.conditions.keys()]}\"\n\n        # Run super\n        super()._initialize()\n\n        # Store which method to use for sampling particle locations\n        if self.method == ParticleModifyMethod.PROJECTION:\n            self._sample_particle_locations = self._sample_particle_locations_from_projection_volume\n        elif self.method == ParticleModifyMethod.ADJACENCY:\n            self._sample_particle_locations = self._sample_particle_locations_from_adjacency_area\n        else:\n            raise ValueError(f\"Unsupported ParticleModifyMethod: {self.method}!\")\n\n    def _modify_particles(self, system):\n        # If at the limit, don't modify anything\n        if self.check_at_limit(system=system):\n            return\n\n        # Sample potential locations to apply particles, and then apply them\n        start_points, end_points = self._sample_particle_locations(system=system)\n        n_samples = len(start_points)\n\n        # Sample the rays to see where particle can be generated\n        hits = [result for result in sample_cuboid_on_object(\n            obj=None,\n            start_points=start_points.reshape(n_samples, 1, 3),\n            end_points=end_points.reshape(n_samples, 1, 3),\n            cuboid_dimensions=system.sample_scales(\n                group=system.get_group_name(obj=self.obj), n=len(start_points)) * system.particle_object.aabb_extent.reshape(1, 3)\n            if issubclass(system, VisualParticleSystem) else np.zeros(3),\n            ignore_objs=[self.obj],\n            hit_proportion=0.0,             # We want all hits\n            undo_cuboid_bottom_padding=issubclass(system, VisualParticleSystem),      # micro particles have zero cuboid dimensions so we need to maintain padding\n            cuboid_bottom_padding=system.particle_radius if issubclass(system, FluidSystem) else\n            macros.utils.sampling_utils.DEFAULT_CUBOID_BOTTOM_PADDING,\n        ) if result[0] is not None]\n\n        self._apply_particles_at_raycast_hits(system=system, hits=hits)\n\n    def _apply_particles_at_raycast_hits(self, system, hits):\n        \"\"\"\n        Helper function to apply particles from system @system given raycast hits @hits,\n        which are the filtered results from omnigibson.utils.sampling_utils.raytest_batch that include only\n        the results with a valid hit\n\n        Args:\n            system (ParticleSystem): System to apply particles from\n            hits (list of dict): Valid hit results from a batched raycast representing locations for sampling particles\n        \"\"\"\n        # Check how many particles we can sample\n        print(f\"n hits: {len(hits)}\")\n        # Check the system\n        if issubclass(system, VisualParticleSystem):\n            # Sample potential application points\n            z_up = np.zeros(3)\n            z_up[-1] = 1.0\n            n_particles = min(len(hits), m.VISUAL_PARTICLES_APPLICATION_LIMIT - self.modified_particle_count[system])\n            # Generate particle info -- maps group name to particle info for that group,\n            # i.e.: positions, orientations, and link_prim_paths\n            particles_info = defaultdict(lambda: defaultdict(lambda: []))\n            for hit in hits[:n_particles]:\n                # Infer which object was hit\n                hit_obj = og.sim.scene.object_registry(\"prim_path\", \"/\".join(hit[3].split(\"/\")[:-1]), None)\n                print(f\"hit obj: {hit_obj}\")\n                if hit_obj is not None:\n                    # Create an attachment group if necessary\n                    group = system.get_group_name(obj=hit_obj)\n                    if group not in system.groups:\n                        system.create_attachment_group(obj=hit_obj)\n                    # Add to info\n                    particles_info[group][\"positions\"].append(hit[0])\n                    particles_info[group][\"orientations\"].append(hit[2])\n                    particles_info[group][\"link_prim_paths\"].append(hit[3])\n            # Generate all the particles for each group\n            for group, particle_info in particles_info.items():\n                # Generate particles for this group\n                system.generate_group_particles(\n                    group=group,\n                    positions=np.array(particle_info[\"positions\"]),\n                    orientations=np.array(particle_info[\"orientations\"]),\n                    link_prim_paths=particle_info[\"link_prim_paths\"],\n                )\n                # Update our particle count\n                self.modified_particle_count[system] += len(particle_info[\"link_prim_paths\"])\n\n        elif issubclass(system, FluidSystem):\n            # Compile the particle poses to generate and sample the particles\n            n_particles = min(len(hits), m.FLUID_PARTICLES_APPLICATION_LIMIT - self.modified_particle_count[system])\n            # Generate particle instancer\n            if n_particles &gt; 0:\n                system.generate_particle_instancer(\n                    n_particles=n_particles,\n                    positions=np.array([hit[0] for hit in hits[:n_particles]]),\n                )\n                # Update our particle count\n                self.modified_particle_count[system] += n_particles\n\n        else:\n            # Invalid system queried\n            self.unsupported_system_error(system=system)\n\n    def _sample_particle_locations_from_projection_volume(self, system):\n        \"\"\"\n        Helper function for generating potential particle locations from projection volume\n\n        Args:\n            system (ParticleSystem): System to sample potential particle positions for\n\n        Returns:\n            2-tuple:\n                - (n, 3) array: Ray start points to sample\n                - (n, 3) array: Ray end points to sample\n        \"\"\"\n        # Randomly sample end points from the base of the cone / cylinder\n        n_samples = self._get_max_particles_limit_per_step(system=system)\n        r, h = self._projection_mesh_params[\"extents\"][0] / 2, self._projection_mesh_params[\"extents\"][2]\n        sampled_r_theta = np.random.rand(n_samples, 2)\n        sampled_r_theta = sampled_r_theta * np.array([r, np.pi * 2]).reshape(1, 2)\n        # Get start, end points in local link frame\n        end_points = np.stack([\n            h * np.ones(n_samples),\n            sampled_r_theta[:, 0] * np.cos(sampled_r_theta[:, 1]),\n            sampled_r_theta[:, 0] * np.sin(sampled_r_theta[:, 1]),\n        ], axis=1)\n        if self._projection_mesh_params[\"type\"] == \"Cone\":\n            # All start points are the cone tip, which is the local link origin\n            start_points = np.zeros((n_samples, 3))\n        elif self._projection_mesh_params[\"type\"] == \"Cylinder\":\n            # All start points are the parallel point for their corresponding end point\n            # i.e.: (x, y, 0)\n            start_points = end_points + np.array([-h, 0, 0]).reshape(1, 3)\n        else:\n            raise ValueError(f\"Unsupported projection mesh type: {self._projection_mesh_params['type']}!\")\n\n        # Convert sampled normalized radius and angle into 3D points\n        # We convert r, theta --&gt; 3D point in local link frame --&gt; 3D point in global world frame\n        # We also combine start and end points for efficiency when doing the transform, then split them up again\n        points = np.concatenate([start_points, end_points], axis=0)\n        pos, quat = self.link.get_position_orientation()\n        points = get_particle_positions_from_frame(\n            pos=pos,\n            quat=quat,\n            scale=np.ones(3),\n            particle_positions=points,\n        )\n\n        return points[:n_samples, :], points[n_samples:, :]\n\n    def _sample_particle_locations_from_adjacency_area(self, system):\n        \"\"\"\n        Helper function for generating potential particle locations from adjacency area\n\n        Args:\n            system (ParticleSystem): System to sample potential particle positions for\n\n        Returns:\n            2-tuple:\n                - (n, 3) array: Ray start points to sample\n                - (n, 3) array: Ray end points to sample\n        \"\"\"\n        # Randomly sample end points from within the object's AABB\n        n_samples = self._get_max_particles_limit_per_step(system=system)\n        lower, upper = self.obj.states[AABB].get_value() if self.link is None else self.link.aabb\n        lower = lower.reshape(1, 3) - m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\n        upper = upper.reshape(1, 3) + m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\n        lower_upper = np.concatenate([lower, upper], axis=0)\n\n        # Sample in all directions, shooting from the center of the link / object frame\n        pos = self.obj.get_position() if self.link is None else self.link.get_position()\n        start_points = np.ones((n_samples, 3)) * pos.reshape(1, 3)\n        end_points = np.random.uniform(low=lower, high=upper, size=(n_samples, 3))\n        sides, axes = np.random.randint(2, size=(n_samples,)), np.random.randint(3, size=(n_samples,))\n        end_points[np.arange(n_samples), axes] = lower_upper[sides, axes]\n\n        return start_points, end_points\n\n    def _get_max_particles_limit_per_step(self, system):\n        \"\"\"\n        Helper function for grabbing the maximum particle limit per step\n\n        Args:\n            system (ParticleSystem): System for which to get max particle limit per step\n\n        Returns:\n            int: Maximum particles to apply per step for the given system @system\n        \"\"\"\n        # Check the system\n        if issubclass(system, VisualParticleSystem):\n            val = m.MAX_VISUAL_PARTICLES_APPLIED_PER_STEP\n        elif issubclass(system, FluidSystem):\n            val = m.MAX_FLUID_PARTICLES_APPLIED_PER_STEP\n        else:\n            # Invalid system queried\n            self.unsupported_system_error(system=system)\n        return val\n\n    @staticmethod\n    def get_state_link_name():\n        return m.APPLICATION_LINK_NAME\n\n    @property\n    def n_steps_per_modification(self):\n        return m.N_STEPS_PER_APPLICATION\n\n    @property\n    def visual_particle_modification_limit(self):\n        return m.VISUAL_PARTICLES_APPLICATION_LIMIT\n\n    @property\n    def fluid_particle_modification_limit(self):\n        return m.FLUID_PARTICLES_APPLICATION_LIMIT\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleApplier"},{"title":"<code>ParticleModifier</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code>, <code>LinkBasedStateMixin</code></p> <p>Object state representing an object that has the ability to modify visual and / or fluid particles within the active simulation.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>StatefulObject</code>  <p>Object to which this state will be applied</p>  required    <code>method</code>  <code>ParticleModifyMethod</code>  <p>Method to modify particles. Current options supported are ADJACENCY (i.e.: \"touching\" particles) or PROJECTION (i.e.: \"spraying\" particles)</p>  required    <code>conditions</code>  <code>dict</code>  <p>Dictionary mapping ParticleSystem to None or corresponding condition / list of conditions (where None represents no conditions) necessary in order for this particle modifier to be able to modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature is as follows:</p> <pre><code>def condition(obj) --&gt; bool\n</code></pre> <p>Where @obj is the specific object that this ParticleModifier state belongs to. For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within this particle modifier area, then we potentially modify those particles</p>  required    <code>projection_mesh_params</code>  <code>None or dict</code>  <p>If specified and @method is ParticleModifyMethod.PROJECTION, manually overrides any metadata found from @obj.metadata to infer what projection volume to generate for this particle modifier. Expected entries are as follows:</p> <pre><code>\"type\": (str), one of {\"Cylinder\", \"Cone\"}\n\"extents\": (3-array), the (x,y,z) extents of the generated volume\n</code></pre> <p>If None, information found from @obj.metadata will be used instead.</p>  <code>None</code>      Source code in <code>object_states/particle_modifier.py</code> <pre><code>class ParticleModifier(AbsoluteObjectState, LinkBasedStateMixin):\n    \"\"\"\n    Object state representing an object that has the ability to modify visual and / or fluid particles within the active\n    simulation.\n\n    Args:\n        obj (StatefulObject): Object to which this state will be applied\n        method (ParticleModifyMethod): Method to modify particles. Current options supported are ADJACENCY (i.e.:\n            \"touching\" particles) or PROJECTION (i.e.: \"spraying\" particles)\n        conditions (dict): Dictionary mapping ParticleSystem to None or corresponding condition / list of conditions\n            (where None represents no conditions) necessary in order for this particle modifier to be able to\n            modify particles belonging to @ParticleSystem. Each condition should be a function, whose signature\n            is as follows:\n\n                def condition(obj) --&gt; bool\n\n            Where @obj is the specific object that this ParticleModifier state belongs to.\n            For a given ParticleSystem, if all of its conditions evaluate to True and particles are detected within\n            this particle modifier area, then we potentially modify those particles\n        projection_mesh_params (None or dict): If specified and @method is ParticleModifyMethod.PROJECTION,\n            manually overrides any metadata found from @obj.metadata to infer what projection volume to generate\n            for this particle modifier. Expected entries are as follows:\n\n                \"type\": (str), one of {\"Cylinder\", \"Cone\"}\n                \"extents\": (3-array), the (x,y,z) extents of the generated volume\n\n            If None, information found from @obj.metadata will be used instead.\n    \"\"\"\n    def __init__(self, obj, method, conditions, projection_mesh_params=None):\n\n        # Store internal variables\n        self.method = method\n        self.conditions = conditions\n        self.projection_mesh = None\n        self.projection_system = None\n        self.projection_emitter = None\n        self._check_in_mesh = None\n        self._check_overlap = None\n        self._link_prim_paths = None\n        self._current_step = None\n        self._projection_mesh_params = projection_mesh_params\n\n        # Map of system to number of modified particles for this object corresponding to the specific system\n        self.modified_particle_count = OrderedDict([(system, 0) for system in self.supported_systems])\n\n        # Standardize the conditions (make sure every system has at least one condition, which to make sure\n        # the particle modifier isn't already limited with the specific number of particles)\n        for system, conds in conditions.items():\n            # Make sure the system is supported\n            assert_valid_key(key=system, valid_keys=self.supported_systems, name=\"particle system\")\n            # Make sure conds isn't empty and is a list\n            conds = [] if conds is None else list(conds)\n            # Add the condition to avoid limits\n            conds.append(self._generate_limit_condition(system=system))\n            conditions[system] = conds\n\n        # Run super method\n        super().__init__(obj)\n\n    @staticmethod\n    def get_state_link_name():\n        raise NotImplementedError()\n\n    def _initialize(self):\n        # Run link initialization\n        self.initialize_link_mixin()\n\n        # Initialize internal variables\n        self._current_step = 0\n\n        # Grab link prim paths and potentially update projection mesh params\n        self._link_prim_paths = set(self.obj.link_prim_paths)\n\n        # Define callback used during overlap method\n        # We want to ignore any hits that are with this object itself\n        valid_hit = False\n        def overlap_callback(hit):\n            nonlocal valid_hit\n            valid_hit = hit.rigid_body not in self._link_prim_paths\n            # Continue traversal only if we don't have a valid hit yet\n            return not valid_hit\n\n        # Possibly create a projection volume if we're using the projection method\n        if self.method == ParticleModifyMethod.PROJECTION:\n            # Make sure link is defined\n            assert self.link is not None, f\"Cannot use particle projection method without a metalink specified!\"\n            # Make sure projection mesh params are specified\n            # Import here to avoid circular imports\n            from omnigibson.objects.dataset_object import DatasetObject\n            if self._projection_mesh_params is None and isinstance(self.obj, DatasetObject):\n                # We try to grab metadata for this object\n                self._projection_mesh_params = self.obj.metadata.get(\"meta_links\", dict()).get(m.LINK_NAME, None)\n            # Sanity check to make sure projection mesh params is not None\n            assert self._projection_mesh_params is not None, \\\n                f\"Projection mesh params must be specified for {self.obj.name}'s {self.__class__.__name__} state \" \\\n                f\"when method=ParticleModifyMethod.PROJECTION!\"\n\n            mesh_prim_path = f\"{self.link.prim_path}/projection_mesh\"\n            # Create a primitive shape if it doesn't already exist\n            radius, height = self._projection_mesh_params[\"extents\"][0] / 2.0, self._projection_mesh_params[\"extents\"][2]\n            if not get_prim_at_path(mesh_prim_path):\n                mesh = UsdGeom.__dict__[self._projection_mesh_params[\"type\"]].Define(og.sim.stage, mesh_prim_path).GetPrim()\n                # Set the height and radius (scaled by half since the native objects have extents [2, 2, 2]\n                # TODO: Generalize to objects other than cylinder and radius\n                mesh.GetAttribute(\"height\").Set(height / 2.0)\n                mesh.GetAttribute(\"radius\").Set(radius / 2.0)\n\n            # Create the visual geom instance referencing the generated mesh prim, and then hide it\n            self.projection_mesh = VisualGeomPrim(prim_path=mesh_prim_path, name=f\"{self.obj.name}_projection_mesh\")\n            self.projection_mesh.initialize()\n            self.projection_mesh.visible = False\n\n            # Make sure the object updates its meshes\n            self.link.update_meshes()\n\n            # Make sure the mesh is translated so that its tip lies at the metalink origin, and rotated so the vector\n            # from tip to tail faces the positive x axis\n            self.projection_mesh.set_local_pose(\n                translation=np.array([self._projection_mesh_params[\"extents\"][2] / (2 * self.link.scale[2]), 0, 0]),\n                orientation=T.euler2quat([0, -np.pi / 2, 0]),\n            )\n\n            # Generate the projection visualization\n            system = list(self.conditions.keys())[0]    # Only one system should be included for a ParticleApplier!\n            particle_radius = m.VISUAL_PARTICLE_PROJECTION_PARTICLE_RADIUS if issubclass(system, VisualParticleSystem) else system.particle_radius\n            particle_material = system.particle_object.material if issubclass(system, VisualParticleSystem) else system.material\n\n            # Create the projection visualization if it doesn't already exist, otherwise we reference it directly\n            projection_name = f\"{self.obj.name}_projection_visualization\"\n            projection_path = f\"/OmniGraph/{projection_name}\"\n            if is_prim_path_valid(projection_path):\n                self.projection_system = get_prim_at_path(projection_path)\n                self.projection_emitter = get_prim_at_path(f\"{projection_path}/emitter\")\n            else:\n                self.projection_system, self.projection_emitter = create_projection_visualization(\n                    prim_path=f\"{self.link.prim_path}/projection_visualization\",\n                    shape=self._projection_mesh_params[\"type\"],\n                    projection_name=projection_name,\n                    projection_radius=radius,\n                    projection_height=height,\n                    particle_radius=particle_radius,\n                    material=particle_material,\n                )\n\n            # Generate the function for checking whether points are within the projection mesh\n            self._check_in_mesh, _ = generate_points_in_volume_checker_function(\n                obj=self.obj,\n                volume_link=self.link,\n                mesh_name_prefixes=\"projection\",\n            )\n\n            # Store the projection mesh's IDs\n            projection_mesh_ids = PhysicsSchemaTools.encodeSdfPath(self.projection_mesh.prim_path)\n\n            # We also generate the function for checking overlaps at runtime\n            def check_overlap():\n                nonlocal valid_hit\n                valid_hit = False\n                psqi().overlap_shape(*projection_mesh_ids, reportFn=overlap_callback)\n                return valid_hit\n\n        elif self.method == ParticleModifyMethod.ADJACENCY:\n            # Define the function for checking whether points are within the adjacency mesh\n            def check_in_adjacency_mesh(particle_positions):\n                # Define the AABB bounds\n                lower, upper = self.obj.states[AABB].get_value() if self.link is None else self.link.aabb\n                # Add the margin\n                lower -= m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\n                upper += m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN\n                return ((lower &lt; particle_positions) &amp; (particle_positions &lt; upper)).all(axis=-1)\n            self._check_in_mesh = check_in_adjacency_mesh\n\n            # Define the function for checking overlaps at runtime\n            def check_overlap():\n                nonlocal valid_hit\n                valid_hit = False\n                aabb = self.obj.states[AABB].get_value() if self.link is None else self.link.aabb\n                psqi().overlap_box(\n                    halfExtent=(aabb[1] - aabb[0]) / 2.0 + m.PARTICLE_MODIFIER_ADJACENCY_AREA_MARGIN,\n                    pos=(aabb[1] + aabb[0]) / 2.0,\n                    rot=np.array([0, 0, 0, 1.0]),\n                    reportFn=overlap_callback,\n                )\n                return valid_hit\n\n        else:\n            raise ValueError(f\"Unsupported ParticleModifyMethod: {self.method}!\")\n\n        # Store check overlap function\n        self._check_overlap = check_overlap\n\n    @abstractmethod\n    def _modify_particles(self, system):\n        \"\"\"\n        Helper function to modify any particles belonging to @system.\n\n        NOTE: This should handle both cases for @self.method:\n\n            ParticleModifyMethod.ADJACENCY: modify any particles that are overlapping within the relaxed AABB\n                defining adjacency to this object's modification link.\n            ParticleModifyMethod.PROJECTION: modify any particles that are overlapping within the projection mesh.\n\n        Must be implemented by subclass.\n\n        Args:\n            system (ParticleSystem): Particle system whose corresponding particles will be checked for modification\n        \"\"\"\n        raise NotImplementedError()\n\n    def _generate_limit_condition(self, system):\n        \"\"\"\n        Generates a limit function condition for specific system @system\n\n        Args:\n             system (ParticleSystem): Particle system for which to generate a limit checker function\n\n        Returns:\n            function: Limit checker function, with signature condition(obj) --&gt; bool, where @obj is the specific object\n                that this ParticleModifier state belongs to\n        \"\"\"\n        if issubclass(system, VisualParticleSystem):\n            def condition(obj):\n                return self.modified_particle_count[system] &lt; self.visual_particle_modification_limit\n        elif issubclass(system, FluidSystem):\n            def condition(obj):\n                return self.modified_particle_count[system] &lt; self.fluid_particle_modification_limit\n        else:\n            self.unsupported_system_error(system=system)\n\n        return condition\n\n    def _update(self):\n        # Check if there's any overlap and if we're at the correct step\n        if self._current_step == 0 and self._check_overlap():\n            # Iterate over all owned systems for this particle modifier\n            for system, conditions in self.conditions.items():\n                # Check if all conditions are met\n                if issubclass(system, FluidSystem):\n                    print(f\"{system.name} limited: {self.check_at_limit(system=system)}\")\n                if np.all([condition(self.obj) for condition in conditions]):\n                    # Sanity check for oversaturation\n                    self.check_at_limit(system=system, verify_not_over_limit=True)\n                    # Potentially modify particles within the volume\n                    self._modify_particles(system=system)\n\n        # Update the current step\n        self._current_step = (self._current_step + 1) % self.n_steps_per_modification\n\n    def _set_value(self, new_value):\n        raise ValueError(f\"Cannot set valueless state {self.__class__.__name__}.\")\n\n    def _get_value(self):\n        pass\n\n    def remove(self):\n        # We need to remove the generated particle system if we've created one\n        if self.method == ParticleModifyMethod.PROJECTION:\n            delete_prim(self.projection_system.GetPrimPath().pathString)\n\n    @staticmethod\n    def get_dependencies():\n        return AbsoluteObjectState.get_dependencies() + [AABB]\n\n    @staticmethod\n    def get_optional_dependencies():\n        return AbsoluteObjectState.get_optional_dependencies() + [Covered, ToggledOn, ContactBodies]\n\n    def check_at_limit(self, system, verify_not_over_limit=False):\n        \"\"\"\n        Checks whether this object is fully limited with particles modified from particle system @system. Also,\n        potentially sanity checks whether the object is over the limit, if @verify_not_over_limit is True\n\n        Args:\n            system (ParticleSystem): System to check for particle limitations within this object\n            verify_not_over_limit (bool): Whether to sanity check whether this object is over the limit with particles\n                from @system\n\n        Returns:\n            bool: True if the object has reached its limit with objects from @system, otherwise False\n        \"\"\"\n        if issubclass(system, VisualParticleSystem):\n            limit = self.visual_particle_modification_limit\n        elif issubclass(system, FluidSystem):\n            limit = self.fluid_particle_modification_limit\n        else:\n            self.unsupported_system_error(system=system)\n\n        # If requested, run sanity check to make sure we're not over the limit with this system's particles\n        if verify_not_over_limit:\n            assert self.modified_particle_count[system] &lt;= limit, \\\n                f\"{self.__class__.__name__} should not be over the limit! \" \\\n                f\"Max: {limit}, got: {self.modified_particle_count[system]}\"\n\n        return self.modified_particle_count[system] == limit\n\n    def set_at_limit(self, system, value):\n        \"\"\"\n        Sets whether this particle modifier is at its limit for system @system\n\n        Args:\n            system (ParticleSystem): System to set corresponding absorbed particle count limit level for\n            value (bool): Whether to set the particle limit level to be at its limit or not\n        \"\"\"\n        n_particles = 0\n        if value:\n            if issubclass(system, VisualParticleSystem):\n                n_particles = self.visual_particle_modification_limit\n            elif issubclass(system, FluidSystem):\n                n_particles = self.fluid_particle_modification_limit\n            else:\n                self.unsupported_system_error(system=system)\n        self.modified_particle_count[system] = n_particles\n\n    @classmethod\n    def unsupported_system_error(cls, system):\n        \"\"\"\n        Raises a ValueError given unsupported system @system\n\n        Args:\n            system (ParticleSystem): Any unsupported system (any system that does not exist in @self.supported_systems)\n        \"\"\"\n        raise ValueError(f\"Invalid system for {cls.__name__}! Supported systems: \"\n                         f\"{[sys.name for sys in cls.supported_systems]}, got: {system.name}\")\n\n    @classproperty\n    def supported_systems(self):\n        \"\"\"\n        Returns:\n            list: All systems used in this state, ordered deterministically\n        \"\"\"\n        return list(get_visual_particle_systems().values()) + list(get_fluid_systems().values())\n\n    @property\n    def n_steps_per_modification(self):\n        \"\"\"\n        Returns:\n            int: How many steps to take in between potentially modifying particles within the simulation\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def visual_particle_modification_limit(self):\n        \"\"\"\n        Returns:\n            int: Maximum number of visual particles from a specific system that can be modified by this object\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def fluid_particle_modification_limit(self):\n        \"\"\"\n        Returns:\n            int: Maximum number of fluid particles from a specific system that can be modified by this object\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def state_size(self):\n        # One entry per system plus the current_step\n        return len(self.modified_particle_count) + 1\n\n    def _dump_state(self):\n        state = OrderedDict()\n        for system, val in self.modified_particle_count.items():\n            state[get_element_name_from_system(system)] = val\n        # Add current step\n        state[\"current_step\"] = self._current_step\n        return state\n\n    def _load_state(self, state):\n        for system in self.supported_systems:\n            self.modified_particle_count[system] = state[get_element_name_from_system(system)]\n        # Set current step\n        self._current_step = state[\"current_step\"]\n\n    def _serialize(self, state):\n        return np.array(list(state.values()), dtype=float)\n\n    def _deserialize(self, state):\n        state_dict = OrderedDict()\n        for i, system in enumerate(self.modified_particle_count.keys()):\n            state_dict[get_element_name_from_system(system)] = int(state[i])\n        state_dict[\"current_step\"] = int(state[len(self.modified_particle_count)])\n\n        return state_dict, len(self.modified_particle_count) + 1\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier"},{"title":"<code>fluid_particle_modification_limit</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Maximum number of fluid particles from a specific system that can be modified by this object</p>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.fluid_particle_modification_limit"},{"title":"<code>n_steps_per_modification</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>How many steps to take in between potentially modifying particles within the simulation</p>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.n_steps_per_modification"},{"title":"<code>visual_particle_modification_limit</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Maximum number of visual particles from a specific system that can be modified by this object</p>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.visual_particle_modification_limit"},{"title":"<code>check_at_limit(system, verify_not_over_limit=False)</code>","text":"<p>Checks whether this object is fully limited with particles modified from particle system @system. Also, potentially sanity checks whether the object is over the limit, if @verify_not_over_limit is True</p> <p>Parameters:</p>    Name Type Description Default     <code>system</code>  <code>ParticleSystem</code>  <p>System to check for particle limitations within this object</p>  required    <code>verify_not_over_limit</code>  <code>bool</code>  <p>Whether to sanity check whether this object is over the limit with particles from @system</p>  <code>False</code>     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if the object has reached its limit with objects from @system, otherwise False</p>     Source code in <code>object_states/particle_modifier.py</code> <pre><code>def check_at_limit(self, system, verify_not_over_limit=False):\n    \"\"\"\n    Checks whether this object is fully limited with particles modified from particle system @system. Also,\n    potentially sanity checks whether the object is over the limit, if @verify_not_over_limit is True\n\n    Args:\n        system (ParticleSystem): System to check for particle limitations within this object\n        verify_not_over_limit (bool): Whether to sanity check whether this object is over the limit with particles\n            from @system\n\n    Returns:\n        bool: True if the object has reached its limit with objects from @system, otherwise False\n    \"\"\"\n    if issubclass(system, VisualParticleSystem):\n        limit = self.visual_particle_modification_limit\n    elif issubclass(system, FluidSystem):\n        limit = self.fluid_particle_modification_limit\n    else:\n        self.unsupported_system_error(system=system)\n\n    # If requested, run sanity check to make sure we're not over the limit with this system's particles\n    if verify_not_over_limit:\n        assert self.modified_particle_count[system] &lt;= limit, \\\n            f\"{self.__class__.__name__} should not be over the limit! \" \\\n            f\"Max: {limit}, got: {self.modified_particle_count[system]}\"\n\n    return self.modified_particle_count[system] == limit\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.check_at_limit"},{"title":"<code>set_at_limit(system, value)</code>","text":"<p>Sets whether this particle modifier is at its limit for system @system</p> <p>Parameters:</p>    Name Type Description Default     <code>system</code>  <code>ParticleSystem</code>  <p>System to set corresponding absorbed particle count limit level for</p>  required    <code>value</code>  <code>bool</code>  <p>Whether to set the particle limit level to be at its limit or not</p>  required      Source code in <code>object_states/particle_modifier.py</code> <pre><code>def set_at_limit(self, system, value):\n    \"\"\"\n    Sets whether this particle modifier is at its limit for system @system\n\n    Args:\n        system (ParticleSystem): System to set corresponding absorbed particle count limit level for\n        value (bool): Whether to set the particle limit level to be at its limit or not\n    \"\"\"\n    n_particles = 0\n    if value:\n        if issubclass(system, VisualParticleSystem):\n            n_particles = self.visual_particle_modification_limit\n        elif issubclass(system, FluidSystem):\n            n_particles = self.fluid_particle_modification_limit\n        else:\n            self.unsupported_system_error(system=system)\n    self.modified_particle_count[system] = n_particles\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.set_at_limit"},{"title":"<code>supported_systems()</code>","text":"<p>Returns:</p>    Name Type Description     <code>list</code>   <p>All systems used in this state, ordered deterministically</p>     Source code in <code>object_states/particle_modifier.py</code> <pre><code>@classproperty\ndef supported_systems(self):\n    \"\"\"\n    Returns:\n        list: All systems used in this state, ordered deterministically\n    \"\"\"\n    return list(get_visual_particle_systems().values()) + list(get_fluid_systems().values())\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.supported_systems"},{"title":"<code>unsupported_system_error(system)</code>  <code>classmethod</code>","text":"<p>Raises a ValueError given unsupported system @system</p> <p>Parameters:</p>    Name Type Description Default     <code>system</code>  <code>ParticleSystem</code>  <p>Any unsupported system (any system that does not exist in @self.supported_systems)</p>  required      Source code in <code>object_states/particle_modifier.py</code> <pre><code>@classmethod\ndef unsupported_system_error(cls, system):\n    \"\"\"\n    Raises a ValueError given unsupported system @system\n\n    Args:\n        system (ParticleSystem): Any unsupported system (any system that does not exist in @self.supported_systems)\n    \"\"\"\n    raise ValueError(f\"Invalid system for {cls.__name__}! Supported systems: \"\n                     f\"{[sys.name for sys in cls.supported_systems]}, got: {system.name}\")\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleModifier.unsupported_system_error"},{"title":"<code>ParticleRemover</code>","text":"<p>         Bases: <code>ParticleModifier</code></p> <p>ParticleModifier where the modification results in potentially removing particles from the simulation.</p>  Source code in <code>object_states/particle_modifier.py</code> <pre><code>class ParticleRemover(ParticleModifier):\n    \"\"\"\n    ParticleModifier where the modification results in potentially removing particles from the simulation.\n    \"\"\"\n\n    def _modify_particles(self, system):\n        # If at the limit, don't modify anything\n        if self.check_at_limit(system=system):\n            return\n        # Check the system\n        if issubclass(system, VisualParticleSystem):\n            # Only modify particles if there are any that exist\n            if system.n_particles &gt; 0:\n                # Iterate over all particles and remove any that are within the relaxed AABB of the remover volume\n                particle_names = list(system.particles.keys())\n                particle_positions = np.array([particle.get_position() for particle in system.particles.values()])\n                inbound_idxs = self._check_in_mesh(particle_positions).nonzero()[0]\n                max_particle_absorbed = self.visual_particle_modification_limit - self.modified_particle_count[system]\n                for idx in inbound_idxs[:max_particle_absorbed]:\n                    system.remove_particle(particle_names[idx])\n                self.modified_particle_count[system] += min(len(inbound_idxs), max_particle_absorbed)\n\n        elif issubclass(system, FluidSystem):\n            instancer_to_particle_idxs = {}\n            # If we're a cloth and using adjacency, we have to use check_in_mesh with the relaxed AABB since we\n            # can't detect collisions via scene query interface. Alternatively, if we're using the projection method,\n            # we also need to use check_in_mesh to check for overlap with the projection mesh\n            # We'll check for if the fluid particles are within this relaxed AABB\n            if self.obj.prim_type == PrimType.CLOTH or self.method == ParticleModifyMethod.PROJECTION:\n                for inst in system.particle_instancers.values():\n                    inbound_idxs = (self._check_in_mesh(inst.particle_positions) &amp; inst.particle_visibilities &gt; 0).nonzero()[0]\n                    instancer_to_particle_idxs[inst] = inbound_idxs\n            # Otherwise, we can simply use the contact cached information for each particle\n            else:\n                instancer_to_particle_idxs = system.state_cache[\"obj_particle_contacts\"][self.obj] if \\\n                    self.link is None else system.state_cache[\"link_particle_contacts\"][self.link]\n\n            # Iterate over all particles and hide any that are detected to be removed\n            for inst, particle_idxs in instancer_to_particle_idxs.items():\n                # If at the limit, stop absorbing\n                if self.check_at_limit(system=system):\n                    break\n                max_particle_absorbed = self.fluid_particle_modification_limit - self.modified_particle_count[\n                    system]\n                particles_to_absorb = min(len(particle_idxs), max_particle_absorbed)\n                particle_idxs_to_absorb = list(particle_idxs)[:particles_to_absorb]\n\n                # Hide particles that have been absorbed\n                visibilities = inst.particle_visibilities\n                visibilities[particle_idxs_to_absorb] = 0\n                inst.particle_visibilities = visibilities\n\n                # Keep track of the particles that have been absorbed\n                self.modified_particle_count[system] += particles_to_absorb\n\n        else:\n            # Invalid system queried\n            self.unsupported_system_error(system=system)\n\n    @staticmethod\n    def get_state_link_name():\n        return m.REMOVAL_LINK_NAME\n\n    @property\n    def n_steps_per_modification(self):\n        return m.N_STEPS_PER_REMOVAL\n\n    @property\n    def visual_particle_modification_limit(self):\n        return m.VISUAL_PARTICLES_REMOVAL_LIMIT\n\n    @property\n    def fluid_particle_modification_limit(self):\n        return m.FLUID_PARTICLES_REMOVAL_LIMIT\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.ParticleRemover"},{"title":"<code>create_projection_visualization(prim_path, shape, projection_name, projection_radius, projection_height, particle_radius, material=None)</code>","text":"<p>Helper function to generate a projection visualization using Omniverse's particle visualization system</p> <p>NOTE: Due to limitations with omniverse's generation scheme, the generated projection must have its origin at the origin of its parent frame, with its cone / cylinder facing in the local x-axis direction. The parent frame should also be aligned to its own parent frame to one of its own parent frame's axes - ie: any orientation such that its axes are exactly parallel / orthogonal to its parent axes.</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Stage location for where to generate the projection visualization</p>  required    <code>shape</code>  <code>str</code>  <p>Shape of the projection to generate. Valid options are: {Sphere, Cone}</p>  required    <code>projection_name</code>  <code>str</code>  <p>Name associated with this projection visualization. Should be unique!</p>  required    <code>projection_radius</code>  <code>float</code>  <p>Radius of the generated projection visualization overall volume</p>  required    <code>projection_height</code>  <code>float</code>  <p>Height of the generated projection visualization overall volume</p>  required    <code>particle_radius</code>  <code>float</code>  <p>Radius of the particles composing the projection visualization</p>  required    <code>material</code>  <code>None or MaterialPrim</code>  <p>If specified, specifies the material to associate with the generated particles within the projection visualization</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - UsdPrim: Generated ParticleSystem (ComputeGraph) prim generated - UsdPrim: Generated Emitter (ComputeGraph) prim generated</p>     Source code in <code>object_states/particle_modifier.py</code> <pre><code>def create_projection_visualization(\n        prim_path,\n        shape,\n        projection_name,\n        projection_radius,\n        projection_height,\n        particle_radius,\n        material=None,\n):\n    \"\"\"\n    Helper function to generate a projection visualization using Omniverse's particle visualization system\n\n    NOTE: Due to limitations with omniverse's generation scheme, the generated projection must have its origin at\n    the origin of its parent frame, with its cone / cylinder facing in the local x-axis direction. The parent frame\n    should also be aligned to its own parent frame to one of its own parent frame's axes - ie: any orientation such\n    that its axes are exactly parallel / orthogonal to its parent axes.\n\n    Args:\n        prim_path (str): Stage location for where to generate the projection visualization\n        shape (str): Shape of the projection to generate. Valid options are: {Sphere, Cone}\n        projection_name (str): Name associated with this projection visualization. Should be unique!\n        projection_radius (float): Radius of the generated projection visualization overall volume\n        projection_height (float): Height of the generated projection visualization overall volume\n        particle_radius (float): Radius of the particles composing the projection visualization\n        material (None or MaterialPrim): If specified, specifies the material to associate with the generated\n            particles within the projection visualization\n\n    Returns:\n        2-tuple:\n            - UsdPrim: Generated ParticleSystem (ComputeGraph) prim generated\n            - UsdPrim: Generated Emitter (ComputeGraph) prim generated\n    \"\"\"\n    # Create the desired shape which will be used as the source input prim into the generated projection visualization\n    source = UsdGeom.Sphere.Define(og.sim.stage, Sdf.Path(prim_path))\n    # Modify the radius according to the desired @shape (and also infer the desired spread values)\n    if shape == \"Cylinder\":\n        source_radius = projection_radius\n        spread = np.zeros(3)\n    elif shape == \"Cone\":\n        # Default to close to singular point otherwise\n        source_radius = m.PROJECTION_VISUALIZATION_CONE_TIP_RADIUS\n        spread_ratio = projection_radius * 2.0 / projection_height\n        spread = np.ones(3) * spread_ratio * m.PROJECTION_VISUALIZATION_ORIENTATION_BIAS\n    else:\n        raise ValueError(f\"Invalid shape specified for projection visualization! Valid options are: [Sphere, Cylinder], got: {shape}\")\n    # Set the radius\n    # Note that we divide the expected value in half since the native Sphere geom has native extents [2, 2, 2]\n    source.GetRadiusAttr().Set(source_radius / 2.0)\n    # Also make the prim invisible\n    UsdGeom.Imageable(source.GetPrim()).MakeInvisible()\n    # Generate the ComputeGraph nodes to render the projection\n    core = Core(lambda val: None, particle_system_name=projection_name)\n    system_path, _, emitter_path, instancer_path, sprite_path, mat_path, output_path = core.create_particle_system(display=\"point_instancer\", paths=[prim_path])\n    # Override the prototype with our own sphere with optional material\n    prototype_path = \"/\".join(sprite_path.split(\"/\")[:-1]) + \"/prototype\"\n    create_primitive_mesh(prototype_path, primitive_type=\"Sphere\")\n    prototype = VisualGeomPrim(prim_path=prototype_path, name=f\"{projection_name}_prototype\")\n    prototype.initialize()\n    # Set the scale (native scaling --&gt; radius 0.5) and possibly update the material\n    prototype.scale = particle_radius * 2.0\n    if material is not None:\n        prototype.material = material\n    # Override the prototype used by the instancer\n    instancer_prim = get_prim_at_path(instancer_path)\n    instancer_prim.GetProperty(\"inputs:prototypes\").SetTargets([prototype_path])\n\n    # Destroy the old mat path since we don't use the sprites\n    delete_prim(mat_path)\n\n    # Modify the settings of the emitter to match the desired shape from inputs\n    emitter_prim = get_prim_at_path(emitter_path)\n    emitter_prim.GetProperty(\"inputs:rate\").Set(m.PROJECTION_VISUALIZATION_RATE)\n    emitter_prim.GetProperty(\"inputs:lifespan\").Set(projection_height / m.PROJECTION_VISUALIZATION_SPEED)\n    emitter_prim.GetProperty(\"inputs:speed\").Set(m.PROJECTION_VISUALIZATION_SPEED)\n    emitter_prim.GetProperty(\"inputs:alongAxis\").Set(m.PROJECTION_VISUALIZATION_ORIENTATION_BIAS)\n    emitter_prim.GetProperty(\"inputs:scale\").Set(Gf.Vec3f(1.0, 1.0, 1.0))\n    emitter_prim.GetProperty(\"inputs:directionRandom\").Set(Gf.Vec3f(*spread))\n\n    # Move the output path so it moves with the particle system prim\n    og.sim.render()\n    output_name = output_path.split(\"/\")[-1]\n    move_prim(output_path, f\"{system_path}/{output_name}\")\n\n    # Return the particle system prim which \"owns\" everything\n    return get_prim_at_path(system_path), emitter_prim\n</code></pre>","location":"reference/object_states/particle_modifier.html#object_states.particle_modifier.create_projection_visualization"},{"title":"pose","text":"","location":"reference/object_states/pose.html"},{"title":"robot_related_states","text":"","location":"reference/object_states/robot_related_states.html"},{"title":"room_states","text":"","location":"reference/object_states/room_states.html"},{"title":"<code>InsideRoomTypes</code>","text":"<p>         Bases: <code>AbsoluteObjectState</code></p> <p>The value of this state is the list of rooms that the object currently is in.</p>  Source code in <code>object_states/room_states.py</code> <pre><code>class InsideRoomTypes(AbsoluteObjectState):\n    \"\"\"\n    The value of this state is the list of rooms that the object currently is in.\n    \"\"\"\n\n    def _get_value(self):\n        if hasattr(self.obj, \"fixed_base\") and self.obj.fixed_base:\n            # For fixed objects, we can use the in_rooms attribute.\n            if hasattr(self.obj, \"in_rooms\") and self.obj.in_rooms:\n                return self.obj.in_rooms\n\n        # Otherwise we need to calculate using room segmentation function. Check that it exists.\n        if not hasattr(self._simulator.scene, \"get_room_type_by_point\"):\n            return [\"undefined\"]\n\n        pose = self.obj.get_position()\n        return [self._simulator.scene.get_room_type_by_point(np.array(pose[:2]))]\n\n    def _set_value(self, new_value):\n        raise NotImplementedError(\"Room state currently does not support setting.\")\n</code></pre>","location":"reference/object_states/room_states.html#object_states.room_states.InsideRoomTypes"},{"title":"saturated","text":"","location":"reference/object_states/saturated.html"},{"title":"sliced","text":"","location":"reference/object_states/sliced.html"},{"title":"slicer","text":"","location":"reference/object_states/slicer.html"},{"title":"temperature","text":"","location":"reference/object_states/temperature.html"},{"title":"toggle","text":"","location":"reference/object_states/toggle.html"},{"title":"touching","text":"","location":"reference/object_states/touching.html"},{"title":"under","text":"","location":"reference/object_states/under.html"},{"title":"water_sink","text":"","location":"reference/object_states/water_sink.html"},{"title":"water_source","text":"","location":"reference/object_states/water_source.html"},{"title":"objects","text":"","location":"reference/objects/index.html"},{"title":"controllable_object","text":"","location":"reference/objects/controllable_object.html"},{"title":"<code>ControllableObject</code>","text":"<p>         Bases: <code>BaseObject</code></p> <p>Simple class that extends object functionality for controlling joints -- this assumes that at least some joints are motorized (i.e.: non-zero low-level simulator joint motor gains) and intended to be controlled, e.g.: a conveyor belt or a robot agent</p>  Source code in <code>objects/controllable_object.py</code> <pre><code>class ControllableObject(BaseObject):\n    \"\"\"\n    Simple class that extends object functionality for controlling joints -- this assumes that at least some joints\n    are motorized (i.e.: non-zero low-level simulator joint motor gains) and intended to be controlled,\n    e.g.: a conveyor belt or a robot agent\n    \"\"\"\n    def __init__(\n        self,\n        prim_path,\n        name=None,\n        category=\"object\",\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        prim_type=PrimType.RIGID,\n        load_config=None,\n        control_freq=None,\n        controller_config=None,\n        action_type=\"continuous\",\n        action_normalize=True,\n        reset_joint_pos=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Store inputs\n        self._control_freq = control_freq\n        self._controller_config = controller_config\n        self._reset_joint_pos = reset_joint_pos if reset_joint_pos is None else np.array(reset_joint_pos)\n\n        # Make sure action type is valid, and also save\n        assert_valid_key(key=action_type, valid_keys={\"discrete\", \"continuous\"}, name=\"action type\")\n        self._action_type = action_type\n        self._action_normalize = action_normalize\n\n        # Store internal placeholders that will be filled in later\n        self._dof_to_joints = None          # OrderedDict that will map DOF indices to JointPrims\n        self._last_action = None\n        self._controllers = None\n        self.dof_names_ordered = None\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            category=category,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            prim_type=prim_type,\n            load_config=load_config,\n            **kwargs,\n        )\n\n    def _initialize(self):\n        # Run super first\n        super()._initialize()\n        # Fill in the DOF to joint mapping\n        self._dof_to_joints = OrderedDict()\n        idx = 0\n        for joint in self._joints.values():\n            for _ in range(joint.n_dof):\n                self._dof_to_joints[idx] = joint\n                idx += 1\n\n        # Update the reset joint pos\n        if self._reset_joint_pos is None:\n            self._reset_joint_pos = self.default_joint_pos\n\n        # Load controllers\n        self._load_controllers()\n\n        # Setup action space\n        self._action_space = self._create_discrete_action_space() if self._action_type == \"discrete\" \\\n            else self._create_continuous_action_space()\n\n        # Reset the object and keep all joints still after loading\n        self.reset()\n        self.keep_still()\n\n    def load(self, simulator=None):\n        # Run super first\n        prim = super().load(simulator=simulator)\n\n        # Set the control frequency if one was not provided.\n        expected_control_freq = 1.0 / simulator.get_rendering_dt()\n        if self._control_freq is None:\n            logging.info(\n                \"Control frequency is None - being set to default of 1 / render_timestep: %.4f\", expected_control_freq\n            )\n            self._control_freq = expected_control_freq\n        else:\n            assert np.isclose(\n                expected_control_freq, self._control_freq\n            ), \"Stored control frequency does not match environment's render timestep.\"\n\n        return prim\n\n    def _load_controllers(self):\n        \"\"\"\n        Loads controller(s) to map inputted actions into executable (pos, vel, and / or effort) signals on this object.\n        Stores created controllers as dictionary mapping controller names to specific controller\n        instances used by this object.\n        \"\"\"\n        # Generate the controller config\n        self._controller_config = self._generate_controller_config(custom_config=self._controller_config)\n\n        # Store dof idx mapping to dof name\n        self.dof_names_ordered = list(self._joints.keys())\n\n        # Initialize controllers to create\n        self._controllers = OrderedDict()\n        # Loop over all controllers, in the order corresponding to @action dim\n        for name in self.controller_order:\n            assert_valid_key(key=name, valid_keys=self._controller_config, name=\"controller name\")\n            cfg = self._controller_config[name]\n            # If we're using normalized action space, override the inputs for all controllers\n            if self._action_normalize:\n                cfg[\"command_input_limits\"] = \"default\"  # default is normalized (-1, 1)\n            # Create the controller\n            self._controllers[name] = create_controller(**cfg)\n\n        self._update_controller_mode()\n\n    def _update_controller_mode(self):\n        \"\"\"\n        Helper function to force the joints to use the internal specified control mode and gains\n        \"\"\"\n        # Update the control modes of each joint based on the outputted control from the controllers\n        for name in self._controllers:\n            for dof in self._controllers[name].dof_idx:\n                control_type = self._controllers[name].control_type\n                self._joints[self.dof_names_ordered[dof]].set_control_type(\n                    control_type=control_type,\n                    kp=self.default_kp if control_type == ControlType.POSITION else None,\n                    kd=self.default_kd if control_type == ControlType.VELOCITY else None,\n                )\n\n    def _generate_controller_config(self, custom_config=None):\n        \"\"\"\n        Generates a fully-populated controller config, overriding any default values with the corresponding values\n        specified in @custom_config\n\n        Args:\n            custom_config (None or Dict[str, ...]): nested dictionary mapping controller name(s) to specific custom\n                controller configurations for this object. This will override any default values specified by this class\n\n        Returns:\n            dict: Fully-populated nested dictionary mapping controller name(s) to specific controller configurations for\n                this object\n        \"\"\"\n        controller_config = {} if custom_config is None else deepcopy(custom_config)\n\n        # Update the configs\n        for group in self.controller_order:\n            group_controller_name = (\n                controller_config[group][\"name\"]\n                if group in controller_config and \"name\" in controller_config[group]\n                else self._default_controllers[group]\n            )\n            controller_config[group] = merge_nested_dicts(\n                base_dict=self._default_controller_config[group][group_controller_name],\n                extra_dict=controller_config.get(group, {}),\n            )\n\n        return controller_config\n\n    def reload_controllers(self, controller_config=None):\n        \"\"\"\n        Reloads controllers based on the specified new @controller_config\n\n        Args:\n            controller_config (None or Dict[str, ...]): nested dictionary mapping controller name(s) to specific\n                controller configurations for this object. This will override any default values specified by this class.\n        \"\"\"\n        self._controller_config = {} if controller_config is None else controller_config\n\n        # (Re-)load controllers\n        self._load_controllers()\n\n        # (Re-)create the action space\n        self._action_space = self._create_discrete_action_space() if self._action_type == \"discrete\" \\\n            else self._create_continuous_action_space()\n\n    def reset(self):\n        # Make sure simulation is playing, otherwise, we cannot reset because DC requires active running\n        # simulation in order to set joints\n        assert self._simulator.is_playing(), \"Simulator must be playing in order to reset controllable object's joints!\"\n\n        # Run super first\n        super().reset()\n\n        # Additionally set the joint states based on the reset values\n        self.set_joint_positions(positions=self._reset_joint_pos, target=False)\n        self.set_joint_velocities(velocities=np.zeros(self.n_dof), target=False)\n\n        # Update the control modes of each joint based on the outputted control from the controllers\n        # Omni resets them after every reset\n        self._update_controller_mode()\n\n        # Reset all controllers\n        for controller in self._controllers.values():\n            controller.reset()\n\n    @abstractmethod\n    def _create_discrete_action_space(self):\n        \"\"\"\n        Create a discrete action space for this object. Should be implemented by the subclass (if a subclass does not\n        support this type of action space, it should raise an error).\n\n        Returns:\n            gym.space: Object-specific discrete action space\n        \"\"\"\n        raise NotImplementedError\n\n    def _create_continuous_action_space(self):\n        \"\"\"\n        Create a continuous action space for this object. By default, this loops over all controllers and\n        appends their respective input command limits to set the action space.\n        Any custom behavior should be implemented by the subclass (e.g.: if a subclass does not\n        support this type of action space, it should raise an error).\n\n        Returns:\n            gym.space.Box: Object-specific continuous action space\n        \"\"\"\n        # Action space is ordered according to the order in _default_controller_config control\n        low, high = [], []\n        for controller in self._controllers.values():\n            limits = controller.command_input_limits\n            low.append(np.array([-np.inf] * controller.command_dim) if limits is None else limits[0])\n            high.append(np.array([np.inf] * controller.command_dim) if limits is None else limits[1])\n\n        return gym.spaces.Box(\n            shape=(self.action_dim,), low=np.concatenate(low), high=np.concatenate(high), dtype=np.float32\n        )\n\n    def apply_action(self, action):\n        \"\"\"\n\n        Converts inputted actions into low-level control signals and deploys them on the object\n\n        Args:\n            n_array: n-DOF length array of actions to convert and deploy on the object\n        \"\"\"\n        # Store last action as the current action being applied\n        self._last_action = action\n\n        # If we're using discrete action space, we grab the specific action and use that to convert to control\n        if self._action_type == \"discrete\":\n            action = np.array(self.discrete_action_list[action])\n\n        # Check if the input action's length matches the action dimension\n        assert len(action) == self.action_dim, \"Action must be dimension {}, got dim {} instead.\".format(\n            self.action_dim, len(action)\n        )\n\n        # Run convert actions to controls\n        control, control_type = self._actions_to_control(action=action)\n\n        # Deploy control signals\n        self.deploy_control(control=control, control_type=control_type, indices=None, normalized=False)\n\n    def _actions_to_control(self, action):\n        \"\"\"\n        Converts inputted @action into low level control signals to deploy directly on the object.\n        This returns two arrays: the converted low level control signals and an array corresponding\n        to the specific ControlType for each signal.\n\n        Args:\n            action (n-array): n-DOF length array of actions to convert and deploy on the object\n\n        Returns:\n            2-tuple:\n                - n-array: raw control signals to send to the object's joints\n                - list: control types for each joint\n        \"\"\"\n        # First, loop over all controllers, and calculate the computed control\n        control = OrderedDict()\n        idx = 0\n\n        # Compose control_dict\n        control_dict = self.get_control_dict()\n\n        for name, controller in self._controllers.items():\n            # Set command, then take a controller step\n            controller.update_command(command=action[idx : idx + controller.command_dim])\n            control[name] = {\n                \"value\": controller.step(control_dict=control_dict),\n                \"type\": controller.control_type,\n            }\n            # Update idx\n            idx += controller.command_dim\n\n        # Compose controls\n        u_vec = np.zeros(self.n_dof)\n        # By default, the control type is effort and the control value is 0 (np.zeros) - 0 effort means no control.\n        u_type_vec = np.array([ControlType.EFFORT] * self.n_dof)\n        for group, ctrl in control.items():\n            idx = self._controllers[group].dof_idx\n            u_vec[idx] = ctrl[\"value\"]\n            u_type_vec[idx] = ctrl[\"type\"]\n\n        # Return control\n        return u_vec, u_type_vec\n\n    def deploy_control(self, control, control_type, indices=None, normalized=False):\n        \"\"\"\n        Deploys control signals @control with corresponding @control_type on this entity.\n\n        Note: This is DIFFERENT than self.set_joint_positions/velocities/efforts, because in this case we are only\n            setting target values (i.e.: we subject this entity to physical dynamics in order to reach the desired\n            @control setpoints), compared to set_joint_XXXX which manually sets the actual state of the joints.\n\n            This function is intended to be used with motorized entities, e.g.: robot agents or machines (e.g.: a\n            conveyor belt) to simulation physical control of these entities.\n\n            In contrast, use set_joint_XXXX for simulation-specific logic, such as simulator resetting or \"magic\"\n            action implementations.\n\n        Args:\n            control (k- or n-array): control signals to deploy. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @control must\n                be the same length as @indices!\n            control_type (k- or n-array): control types for each DOF. Each entry should be one of ControlType.\n                 This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific\n                 indices are being set. In this case, the length of @control must be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF controls to deploy.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool or array of bool): Whether the inputted joint controls should be interpreted as normalized\n                values. A single bool can be specified for the entire @control, or an array can be specified for\n                individual values. Default is False, corresponding to all @control assumed to be not normalized\n        \"\"\"\n        # Run sanity check\n        if indices is None:\n            assert len(control) == len(control_type) == self.n_dof, (\n                \"Control signals, control types, and number of DOF should all be the same!\"\n                \"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), self.n_dof)\n            )\n            # Set indices manually so that we're standardized\n            indices = np.arange(self.n_dof)\n        else:\n            assert len(control) == len(control_type) == len(indices), (\n                \"Control signals, control types, and indices should all be the same!\"\n                \"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), len(indices))\n            )\n\n        # Standardize normalized input\n        n_indices = len(indices)\n        normalized = normalized if isinstance(normalized, Iterable) else [normalized] * n_indices\n\n        # Loop through controls and deploy\n        # We have to use delicate logic to account for the edge cases where a single joint may contain &gt; 1 DOF\n        # (e.g.: spherical joint)\n        cur_indices_idx = 0\n        while cur_indices_idx != n_indices:\n            # Grab the current DOF index we're controlling and find the corresponding joint\n            joint = self._dof_to_joints[indices[cur_indices_idx]]\n            cur_ctrl_idx = indices[cur_indices_idx]\n            joint_dof = joint.n_dof\n            if joint_dof &gt; 1:\n                # Run additional sanity checks since the joint has more than one DOF to make sure our controls,\n                # control types, and indices all match as expected\n\n                # Make sure the indices are mapped correctly\n                assert indices[cur_indices_idx + joint_dof] == cur_ctrl_idx + joint_dof, \\\n                    \"Got mismatched control indices for a single joint!\"\n                # Check to make sure all joints, control_types, and normalized as all the same over n-DOF for the joint\n                for group_name, group in zip(\n                        (\"joints\", \"control_types\", \"normalized\"),\n                        (self._dof_to_joints, control_type, normalized),\n                ):\n                    assert len({group[indices[cur_indices_idx + i]] for i in range(joint_dof)}) == 1, \\\n                        f\"Not all {group_name} were the same when trying to deploy control for a single joint!\"\n                # Assuming this all passes, we grab the control subvector, type, and normalized value accordingly\n                ctrl = control[cur_ctrl_idx: cur_ctrl_idx + joint_dof]\n            else:\n                # Grab specific control. No need to do checks since this is a single value\n                ctrl = control[cur_ctrl_idx]\n\n            # Deploy control based on type\n            ctrl_type, norm = control_type[cur_ctrl_idx], normalized[cur_ctrl_idx]       # In multi-DOF joint case all values were already checked to be the same\n            if ctrl_type == ControlType.EFFORT:\n                joint.set_effort(ctrl, normalized=norm)\n            elif ctrl_type == ControlType.VELOCITY:\n                joint.set_vel(ctrl, normalized=norm, target=True)\n            elif ctrl_type == ControlType.POSITION:\n                joint.set_pos(ctrl, normalized=norm, target=True)\n            else:\n                raise ValueError(\"Invalid control type specified: {}\".format(ctrl_type))\n\n            # Finally, increment the current index based on how many DOFs were just controlled\n            cur_indices_idx += joint_dof\n\n    def get_control_dict(self):\n        \"\"\"\n        Grabs all relevant information that should be passed to each controller during each controller step.\n\n        Returns:\n            dict: Keyword-mapped control values for this object, mapping names to n-arrays.\n                By default, returns the following:\n\n                - joint_position: (n_dof,) joint positions\n                - joint_velocity: (n_dof,) joint velocities\n                - joint_effort: (n_dof,) joint efforts\n                - root_pos: (3,) (x,y,z) global cartesian position of the object's root link\n                - root_quat: (4,) (x,y,z,w) global cartesian orientation of ths object's root link\n        \"\"\"\n        pos, ori = self.get_position_orientation()\n        return OrderedDict(\n            joint_position=self.get_joint_positions(normalized=False),\n            joint_velocity=self.get_joint_velocities(normalized=False),\n            joint_effort=self.get_joint_efforts(normalized=False),\n            root_pos=pos,\n            root_quat=ori,\n        )\n\n    def dump_action(self):\n        \"\"\"\n        Dump the last action applied to this object. For use in demo collection.\n        \"\"\"\n        return self._last_action\n\n    @property\n    def state_size(self):\n        # Grab size from super and add in controller state sizes\n        size = super().state_size\n\n        return size + sum([c.state_size for c in self._controllers.values()])\n\n    def _dump_state(self):\n        # Grab super state\n        state = super()._dump_state()\n\n        # Add in controller states\n        controller_states = OrderedDict()\n        for controller_name, controller in self._controllers.items():\n            controller_states[controller_name] = controller.dump_state()\n\n        state[\"controllers\"] = controller_states\n\n        return state\n\n    def _load_state(self, state):\n        # Run super first\n        super()._load_state(state=state)\n\n        # Load controller states\n        controller_states = state[\"controllers\"]\n        for controller_name, controller in self._controllers.items():\n            controller.load_state(state=controller_states[controller_name])\n\n    def _serialize(self, state):\n        # Run super first\n        state_flat = super()._serialize(state=state)\n\n        # Serialize the controller states sequentially\n        controller_states_flat = np.concatenate([\n            c.serialize(state=state[\"controllers\"][c_name]) for c_name, c in self._controllers.items()\n        ])\n\n        # Concatenate and return\n        return np.concatenate([state_flat, controller_states_flat]).astype(float)\n\n    def _deserialize(self, state):\n        # Run super first\n        state_dict, idx = super()._deserialize(state=state)\n\n        # Deserialize the controller states sequentially\n        controller_states = OrderedDict()\n        for c_name, c in self._controllers.items():\n            state_size = c.state_size\n            controller_states[c_name] = c.deserialize(state=state[idx: idx + state_size])\n            idx += state_size\n        state_dict[\"controllers\"] = controller_states\n\n        return state_dict, idx\n\n    @property\n    def action_dim(self):\n        \"\"\"\n        Returns:\n            int: Dimension of action space for this object. By default,\n                is the sum over all controller action dimensions\n        \"\"\"\n        return sum([controller.command_dim for controller in self._controllers.values()])\n\n    @property\n    def action_space(self):\n        \"\"\"\n        Action space for this object.\n\n        Returns:\n            gym.space: Action space, either discrete (Discrete) or continuous (Box)\n        \"\"\"\n        return deepcopy(self._action_space)\n\n    @property\n    def discrete_action_list(self):\n        \"\"\"\n        Discrete choices for actions for this object. Only needs to be implemented if the object supports discrete\n        actions.\n\n        Returns:\n            OrderedDict: Mapping from single action identifier (e.g.: a string, or a number) to array of continuous\n                actions to deploy via this object's controllers.\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def controllers(self):\n        \"\"\"\n        Returns:\n            OrderedDict: Controllers owned by this object, mapping controller name to controller object\n        \"\"\"\n        return self._controllers\n\n    @property\n    @abstractmethod\n    def controller_order(self):\n        \"\"\"\n        Returns:\n            list: Ordering of the actions, corresponding to the controllers. e.g., [\"base\", \"arm\", \"gripper\"],\n                to denote that the action vector should be interpreted as first the base action, then arm command, then\n                gripper command\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def controller_action_idx(self):\n        \"\"\"\n        Returns:\n            dict: Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding\n                indices (list) in the action vector\n        \"\"\"\n        dic = {}\n        idx = 0\n        for controller in self.controller_order:\n            cmd_dim = self._controllers[controller].command_dim\n            dic[controller] = np.arange(idx, idx + cmd_dim)\n            idx += cmd_dim\n\n        return dic\n\n    @property\n    def controller_joint_idx(self):\n        \"\"\"\n        Returns:\n            dict: Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding\n                indices (list) of the joint state vector controlled by each controller\n        \"\"\"\n        dic = {}\n        for controller in self.controller_order:\n            dic[controller] = self._controllers[controller].dof_idx\n\n        return dic\n\n    @property\n    def control_limits(self):\n        \"\"\"\n        Returns:\n            dict: Keyword-mapped limits for this object. Dict contains:\n                position: (min, max) joint limits, where min and max are N-DOF arrays\n                velocity: (min, max) joint velocity limits, where min and max are N-DOF arrays\n                effort: (min, max) joint effort limits, where min and max are N-DOF arrays\n                has_limit: (n_dof,) array where each element is True if that corresponding joint has a position limit\n                    (otherwise, joint is assumed to be limitless)\n        \"\"\"\n        return {\n            \"position\": (self.joint_lower_limits, self.joint_upper_limits),\n            \"velocity\": (-self.max_joint_velocities, self.max_joint_velocities),\n            \"effort\": (-self.max_joint_efforts, self.max_joint_efforts),\n            \"has_limit\": self.joint_has_limits,\n        }\n\n    @property\n    def default_kp(self):\n        \"\"\"\n        Returns:\n            float: Default kp gain to apply to any DOF when switching control modes (e.g.: switching from a\n                velocity control mode to a position control mode)\n        \"\"\"\n        return 1e7\n\n    @property\n    def default_kd(self):\n        \"\"\"\n        Returns:\n            float: Default kd gain to apply to any DOF when switching control modes (e.g.: switching from a\n                position control mode to a velocity control mode)\n        \"\"\"\n        return 1e5\n\n    @property\n    @abstractmethod\n    def default_joint_pos(self):\n        \"\"\"\n        Returns:\n            n-array: Default joint positions for this robot\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def _default_controller_config(self):\n        \"\"\"\n        Returns:\n            dict: default nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. Note that the order specifies the sequence of actions to be received\n                from the environment.\n\n                Expected structure is as follows:\n                    group1:\n                        controller_name1:\n                            controller_name1_params\n                            ...\n                        controller_name2:\n                            ...\n                    group2:\n                        ...\n\n                The @group keys specify the control type for various aspects of the object,\n                e.g.: \"head\", \"arm\", \"base\", etc. @controller_name keys specify the supported controllers for\n                that group. A default specification MUST be specified for each controller_name.\n                e.g.: IKController, DifferentialDriveController, JointController, etc.\n        \"\"\"\n        return {}\n\n    @property\n    @abstractmethod\n    def _default_controllers(self):\n        \"\"\"\n        Returns:\n            dict: Maps object group (e.g. base, arm, etc.) to default controller class name to use\n            (e.g. IKController, JointController, etc.)\n        \"\"\"\n        return {}\n</code></pre>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject"},{"title":"<code>action_dim</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Dimension of action space for this object. By default, is the sum over all controller action dimensions</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.action_dim"},{"title":"<code>action_space</code>  <code>property</code>","text":"<p>Action space for this object.</p> <p>Returns:</p>    Type Description       <p>gym.space: Action space, either discrete (Discrete) or continuous (Box)</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.action_space"},{"title":"<code>control_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Keyword-mapped limits for this object. Dict contains: position: (min, max) joint limits, where min and max are N-DOF arrays velocity: (min, max) joint velocity limits, where min and max are N-DOF arrays effort: (min, max) joint effort limits, where min and max are N-DOF arrays has_limit: (n_dof,) array where each element is True if that corresponding joint has a position limit     (otherwise, joint is assumed to be limitless)</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.control_limits"},{"title":"<code>controller_action_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding indices (list) in the action vector</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controller_action_idx"},{"title":"<code>controller_joint_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Mapping from controller names (e.g.: head, base, arm, etc.) to corresponding indices (list) of the joint state vector controlled by each controller</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controller_joint_idx"},{"title":"<code>controller_order</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>list</code>   <p>Ordering of the actions, corresponding to the controllers. e.g., [\"base\", \"arm\", \"gripper\"], to denote that the action vector should be interpreted as first the base action, then arm command, then gripper command</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controller_order"},{"title":"<code>controllers</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Controllers owned by this object, mapping controller name to controller object</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.controllers"},{"title":"<code>default_joint_pos</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Default joint positions for this robot</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.default_joint_pos"},{"title":"<code>default_kd</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Default kd gain to apply to any DOF when switching control modes (e.g.: switching from a position control mode to a velocity control mode)</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.default_kd"},{"title":"<code>default_kp</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Default kp gain to apply to any DOF when switching control modes (e.g.: switching from a velocity control mode to a position control mode)</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.default_kp"},{"title":"<code>discrete_action_list</code>  <code>property</code>","text":"<p>Discrete choices for actions for this object. Only needs to be implemented if the object supports discrete actions.</p> <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Mapping from single action identifier (e.g.: a string, or a number) to array of continuous actions to deploy via this object's controllers.</p>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.discrete_action_list"},{"title":"<code>__init__(prim_path, name=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  <code>'object'</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  <code>PrimType.RIGID</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>control_freq</code>  <code>float</code>  <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p>  <code>None</code>    <code>controller_config</code>  <code>None or dict</code>  <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p>  <code>None</code>    <code>action_type</code>  <code>str</code>  <p>one of {discrete, continuous} - what type of action space to use</p>  <code>'continuous'</code>    <code>action_normalize</code>  <code>bool</code>  <p>whether to normalize inputted actions. This will override any default values specified by this class.</p>  <code>True</code>    <code>reset_joint_pos</code>  <code>None or n-array</code>  <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p>  <code>None</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>objects/controllable_object.py</code> <pre><code>def __init__(\n    self,\n    prim_path,\n    name=None,\n    category=\"object\",\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    prim_type=PrimType.RIGID,\n    load_config=None,\n    control_freq=None,\n    controller_config=None,\n    action_type=\"continuous\",\n    action_normalize=True,\n    reset_joint_pos=None,\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Store inputs\n    self._control_freq = control_freq\n    self._controller_config = controller_config\n    self._reset_joint_pos = reset_joint_pos if reset_joint_pos is None else np.array(reset_joint_pos)\n\n    # Make sure action type is valid, and also save\n    assert_valid_key(key=action_type, valid_keys={\"discrete\", \"continuous\"}, name=\"action type\")\n    self._action_type = action_type\n    self._action_normalize = action_normalize\n\n    # Store internal placeholders that will be filled in later\n    self._dof_to_joints = None          # OrderedDict that will map DOF indices to JointPrims\n    self._last_action = None\n    self._controllers = None\n    self.dof_names_ordered = None\n\n    # Run super init\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        category=category,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        prim_type=prim_type,\n        load_config=load_config,\n        **kwargs,\n    )\n</code></pre>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.__init__"},{"title":"<code>apply_action(action)</code>","text":"<p>Converts inputted actions into low-level control signals and deploys them on the object</p> <p>Parameters:</p>    Name Type Description Default     <code>n_array</code>   <p>n-DOF length array of actions to convert and deploy on the object</p>  required      Source code in <code>objects/controllable_object.py</code> <pre><code>def apply_action(self, action):\n    \"\"\"\n\n    Converts inputted actions into low-level control signals and deploys them on the object\n\n    Args:\n        n_array: n-DOF length array of actions to convert and deploy on the object\n    \"\"\"\n    # Store last action as the current action being applied\n    self._last_action = action\n\n    # If we're using discrete action space, we grab the specific action and use that to convert to control\n    if self._action_type == \"discrete\":\n        action = np.array(self.discrete_action_list[action])\n\n    # Check if the input action's length matches the action dimension\n    assert len(action) == self.action_dim, \"Action must be dimension {}, got dim {} instead.\".format(\n        self.action_dim, len(action)\n    )\n\n    # Run convert actions to controls\n    control, control_type = self._actions_to_control(action=action)\n\n    # Deploy control signals\n    self.deploy_control(control=control, control_type=control_type, indices=None, normalized=False)\n</code></pre>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.apply_action"},{"title":"<code>deploy_control(control, control_type, indices=None, normalized=False)</code>","text":"<p>Deploys control signals @control with corresponding @control_type on this entity.</p>  This is DIFFERENT than self.set_joint_positions/velocities/efforts, because in this case we are only <p>setting target values (i.e.: we subject this entity to physical dynamics in order to reach the desired @control setpoints), compared to set_joint_XXXX which manually sets the actual state of the joints.</p> <p>This function is intended to be used with motorized entities, e.g.: robot agents or machines (e.g.: a conveyor belt) to simulation physical control of these entities.</p> <p>In contrast, use set_joint_XXXX for simulation-specific logic, such as simulator resetting or \"magic\" action implementations.</p>  <p>Parameters:</p>    Name Type Description Default     <code>control</code>  <code>k- or n-array</code>  <p>control signals to deploy. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @control must be the same length as @indices!</p>  required    <code>control_type</code>  <code>k- or n-array</code>  <p>control types for each DOF. Each entry should be one of ControlType.  This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific  indices are being set. In this case, the length of @control must be the same length as @indices!</p>  required    <code>indices</code>  <code>None or k-array</code>  <p>If specified, should be k (k &lt; n) length array of specific DOF controls to deploy. Default is None, which assumes that all joints are being set.</p>  <code>None</code>    <code>normalized</code>  <code>bool or array of bool</code>  <p>Whether the inputted joint controls should be interpreted as normalized values. A single bool can be specified for the entire @control, or an array can be specified for individual values. Default is False, corresponding to all @control assumed to be not normalized</p>  <code>False</code>      Source code in <code>objects/controllable_object.py</code> <pre><code>def deploy_control(self, control, control_type, indices=None, normalized=False):\n    \"\"\"\n    Deploys control signals @control with corresponding @control_type on this entity.\n\n    Note: This is DIFFERENT than self.set_joint_positions/velocities/efforts, because in this case we are only\n        setting target values (i.e.: we subject this entity to physical dynamics in order to reach the desired\n        @control setpoints), compared to set_joint_XXXX which manually sets the actual state of the joints.\n\n        This function is intended to be used with motorized entities, e.g.: robot agents or machines (e.g.: a\n        conveyor belt) to simulation physical control of these entities.\n\n        In contrast, use set_joint_XXXX for simulation-specific logic, such as simulator resetting or \"magic\"\n        action implementations.\n\n    Args:\n        control (k- or n-array): control signals to deploy. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @control must\n            be the same length as @indices!\n        control_type (k- or n-array): control types for each DOF. Each entry should be one of ControlType.\n             This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific\n             indices are being set. In this case, the length of @control must be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF controls to deploy.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool or array of bool): Whether the inputted joint controls should be interpreted as normalized\n            values. A single bool can be specified for the entire @control, or an array can be specified for\n            individual values. Default is False, corresponding to all @control assumed to be not normalized\n    \"\"\"\n    # Run sanity check\n    if indices is None:\n        assert len(control) == len(control_type) == self.n_dof, (\n            \"Control signals, control types, and number of DOF should all be the same!\"\n            \"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), self.n_dof)\n        )\n        # Set indices manually so that we're standardized\n        indices = np.arange(self.n_dof)\n    else:\n        assert len(control) == len(control_type) == len(indices), (\n            \"Control signals, control types, and indices should all be the same!\"\n            \"Got {}, {}, and {} respectively.\".format(len(control), len(control_type), len(indices))\n        )\n\n    # Standardize normalized input\n    n_indices = len(indices)\n    normalized = normalized if isinstance(normalized, Iterable) else [normalized] * n_indices\n\n    # Loop through controls and deploy\n    # We have to use delicate logic to account for the edge cases where a single joint may contain &gt; 1 DOF\n    # (e.g.: spherical joint)\n    cur_indices_idx = 0\n    while cur_indices_idx != n_indices:\n        # Grab the current DOF index we're controlling and find the corresponding joint\n        joint = self._dof_to_joints[indices[cur_indices_idx]]\n        cur_ctrl_idx = indices[cur_indices_idx]\n        joint_dof = joint.n_dof\n        if joint_dof &gt; 1:\n            # Run additional sanity checks since the joint has more than one DOF to make sure our controls,\n            # control types, and indices all match as expected\n\n            # Make sure the indices are mapped correctly\n            assert indices[cur_indices_idx + joint_dof] == cur_ctrl_idx + joint_dof, \\\n                \"Got mismatched control indices for a single joint!\"\n            # Check to make sure all joints, control_types, and normalized as all the same over n-DOF for the joint\n            for group_name, group in zip(\n                    (\"joints\", \"control_types\", \"normalized\"),\n                    (self._dof_to_joints, control_type, normalized),\n            ):\n                assert len({group[indices[cur_indices_idx + i]] for i in range(joint_dof)}) == 1, \\\n                    f\"Not all {group_name} were the same when trying to deploy control for a single joint!\"\n            # Assuming this all passes, we grab the control subvector, type, and normalized value accordingly\n            ctrl = control[cur_ctrl_idx: cur_ctrl_idx + joint_dof]\n        else:\n            # Grab specific control. No need to do checks since this is a single value\n            ctrl = control[cur_ctrl_idx]\n\n        # Deploy control based on type\n        ctrl_type, norm = control_type[cur_ctrl_idx], normalized[cur_ctrl_idx]       # In multi-DOF joint case all values were already checked to be the same\n        if ctrl_type == ControlType.EFFORT:\n            joint.set_effort(ctrl, normalized=norm)\n        elif ctrl_type == ControlType.VELOCITY:\n            joint.set_vel(ctrl, normalized=norm, target=True)\n        elif ctrl_type == ControlType.POSITION:\n            joint.set_pos(ctrl, normalized=norm, target=True)\n        else:\n            raise ValueError(\"Invalid control type specified: {}\".format(ctrl_type))\n\n        # Finally, increment the current index based on how many DOFs were just controlled\n        cur_indices_idx += joint_dof\n</code></pre>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.deploy_control"},{"title":"<code>dump_action()</code>","text":"<p>Dump the last action applied to this object. For use in demo collection.</p>  Source code in <code>objects/controllable_object.py</code> <pre><code>def dump_action(self):\n    \"\"\"\n    Dump the last action applied to this object. For use in demo collection.\n    \"\"\"\n    return self._last_action\n</code></pre>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.dump_action"},{"title":"<code>get_control_dict()</code>","text":"<p>Grabs all relevant information that should be passed to each controller during each controller step.</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Keyword-mapped control values for this object, mapping names to n-arrays. By default, returns the following:</p> <ul> <li>joint_position: (n_dof,) joint positions</li> <li>joint_velocity: (n_dof,) joint velocities</li> <li>joint_effort: (n_dof,) joint efforts</li> <li>root_pos: (3,) (x,y,z) global cartesian position of the object's root link</li> <li>root_quat: (4,) (x,y,z,w) global cartesian orientation of ths object's root link</li> </ul>     Source code in <code>objects/controllable_object.py</code> <pre><code>def get_control_dict(self):\n    \"\"\"\n    Grabs all relevant information that should be passed to each controller during each controller step.\n\n    Returns:\n        dict: Keyword-mapped control values for this object, mapping names to n-arrays.\n            By default, returns the following:\n\n            - joint_position: (n_dof,) joint positions\n            - joint_velocity: (n_dof,) joint velocities\n            - joint_effort: (n_dof,) joint efforts\n            - root_pos: (3,) (x,y,z) global cartesian position of the object's root link\n            - root_quat: (4,) (x,y,z,w) global cartesian orientation of ths object's root link\n    \"\"\"\n    pos, ori = self.get_position_orientation()\n    return OrderedDict(\n        joint_position=self.get_joint_positions(normalized=False),\n        joint_velocity=self.get_joint_velocities(normalized=False),\n        joint_effort=self.get_joint_efforts(normalized=False),\n        root_pos=pos,\n        root_quat=ori,\n    )\n</code></pre>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.get_control_dict"},{"title":"<code>reload_controllers(controller_config=None)</code>","text":"<p>Reloads controllers based on the specified new @controller_config</p> <p>Parameters:</p>    Name Type Description Default     <code>controller_config</code>  <code>None or Dict[str, ...]</code>  <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p>  <code>None</code>      Source code in <code>objects/controllable_object.py</code> <pre><code>def reload_controllers(self, controller_config=None):\n    \"\"\"\n    Reloads controllers based on the specified new @controller_config\n\n    Args:\n        controller_config (None or Dict[str, ...]): nested dictionary mapping controller name(s) to specific\n            controller configurations for this object. This will override any default values specified by this class.\n    \"\"\"\n    self._controller_config = {} if controller_config is None else controller_config\n\n    # (Re-)load controllers\n    self._load_controllers()\n\n    # (Re-)create the action space\n    self._action_space = self._create_discrete_action_space() if self._action_type == \"discrete\" \\\n        else self._create_continuous_action_space()\n</code></pre>","location":"reference/objects/controllable_object.html#objects.controllable_object.ControllableObject.reload_controllers"},{"title":"dataset_object","text":"","location":"reference/objects/dataset_object.html"},{"title":"<code>DatasetObject</code>","text":"<p>         Bases: <code>USDObject</code></p> <p>DatasetObjects are instantiated from a USD file. It is an object that is assumed to come from an iG-supported dataset. These objects should contain additional metadata, including aggregate statistics across the object's category, e.g., avg dims, bounding boxes, masses, etc.</p>  Source code in <code>objects/dataset_object.py</code> <pre><code>class DatasetObject(USDObject):\n    \"\"\"\n    DatasetObjects are instantiated from a USD file. It is an object that is assumed to come from an iG-supported\n    dataset. These objects should contain additional metadata, including aggregate statistics across the\n    object's category, e.g., avg dims, bounding boxes, masses, etc.\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        usd_path=None,\n        name=None,\n        category=\"object\",\n        model=None,\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        prim_type=PrimType.RIGID,\n        load_config=None,\n        abilities=None,\n        include_default_states=True,\n        bounding_box=None,\n        fit_avg_dim_volume=False,\n        in_rooms=None,\n        bddl_object_scope=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            usd_path (None or str): If specified, global path to the USD file to load. Note that this will override\n                @category + @model!\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            model (None or str): if @usd_path is not specified, then this must be specified in conjunction with\n                @category to infer the usd filepath to load for this object, which evaluates to the following:\n\n                    {og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\n\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            bounding_box (None or 3-array): If specified, will scale this object such that it fits in the desired\n                (x,y,z) object-aligned bounding box. Note that EITHER @bounding_box or @scale may be specified\n                -- not both!\n            fit_avg_dim_volume (bool): whether to fit the object to have the same volume as the average dimension\n                while keeping the aspect ratio. Note that if this is set, it will override both @scale and @bounding_box\n            in_rooms (None or list): If specified, sets the rooms that this object should belong to\n            bddl_object_scope (None or str): If specified, should set the BDDL object scope name, e.g. chip.n.04_2\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Store variables\n        self._in_rooms = in_rooms\n        self._bddl_object_scope = bddl_object_scope\n\n        # Info that will be filled in at runtime\n        self.supporting_surfaces = None             # Dictionary mapping link names to surfaces represented by links\n\n        # Make sure only one of bounding_box and scale are specified\n        if bounding_box is not None and scale is not None:\n            raise Exception(\"You cannot define both scale and bounding box size for an DatasetObject\")\n\n        # Add info to load config\n        load_config = dict() if load_config is None else load_config\n        load_config[\"bounding_box\"] = bounding_box\n        load_config[\"fit_avg_dim_volume\"] = fit_avg_dim_volume\n\n        # Infer the correct usd path to use\n        if usd_path is None:\n            assert model is not None, f\"Either usd_path or model and category must be specified in order to create a\" \\\n                                      f\"DatasetObject!\"\n            usd_path = f\"{og.og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\"\n\n        # Post-process the usd path if we're generating a cloth object\n        if prim_type == PrimType.CLOTH:\n            assert usd_path.endswith(\".usd\"), f\"usd_path [{usd_path}] is invalid.\"\n            usd_path = usd_path[:-4] + \"_cloth.usd\"\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            usd_path=usd_path,\n            name=name,\n            category=category,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            prim_type=prim_type,\n            include_default_states=include_default_states,\n            load_config=load_config,\n            abilities=abilities,\n            **kwargs,\n        )\n\n    def load_supporting_surfaces(self):\n        # Initialize dict of supporting surface info\n        self.supporting_surfaces = {}\n\n        # See if we have any height info -- if not, we can immediately return\n        heights_info = self.heights_per_link\n        if heights_info is None:\n            return\n\n        # TODO: Integrate images directly into usd file?\n        # We loop over all the predicates and corresponding supported links in our heights info\n        usd_dir = os.path.dirname(self._usd_path)\n        for predicate, links in heights_info.items():\n            height_maps = {}\n            for link_name, heights in links.items():\n                height_maps[link_name] = []\n                for i, z_value in enumerate(heights):\n                    # Get boolean birds-eye view xy-mask image for this surface\n                    img_fname = os.path.join(usd_dir, \"../misc\", \"height_maps_per_link\", predicate, link_name, f\"{i}.png\")\n                    xy_map = cv2.imread(img_fname, 0)\n                    # Add this map to the supporting surfaces for this link and predicate combination\n                    height_maps[link_name].append((z_value, xy_map))\n            # Add this heights map to the overall supporting surfaces\n            self.supporting_surfaces[predicate] = height_maps\n\n    def sample_orientation(self):\n        \"\"\"\n        Samples an orientation in quaternion (x,y,z,w) form\n\n        Returns:\n            4-array: (x,y,z,w) sampled quaternion orientation for this object, based on self.orientations\n        \"\"\"\n        if self.orientations is None:\n            raise ValueError(\"No orientation probabilities set\")\n        if len(self.orientations) == 0:\n            # Set default value\n            chosen_orientation = np.array([0, 0, 0, 1.0])\n        else:\n            probabilities = [o[\"prob\"] for o in self.orientations.values()]\n            probabilities = np.array(probabilities) / np.sum(probabilities)\n            chosen_orientation = np.array(np.random.choice(list(self.orientations.values()), p=probabilities)[\"rotation\"])\n\n        # Randomize yaw from -pi to pi\n        rot_num = np.random.uniform(-1, 1)\n        rot_matrix = np.array(\n            [\n                [math.cos(math.pi * rot_num), -math.sin(math.pi * rot_num), 0.0],\n                [math.sin(math.pi * rot_num), math.cos(math.pi * rot_num), 0.0],\n                [0.0, 0.0, 1.0],\n            ]\n        )\n        rotated_quat = T.mat2quat(rot_matrix @ T.quat2mat(chosen_orientation))\n        return rotated_quat\n\n    def _initialize(self):\n        # Run super method first\n        super()._initialize()\n\n        # Set the joint frictions based on category\n        friction = SPECIAL_JOINT_FRICTIONS.get(self.category, DEFAULT_JOINT_FRICTION)\n        for joint in self._joints.values():\n            if joint.joint_type != JointType.JOINT_FIXED:\n                joint.friction = friction\n\n    def _load(self, simulator=None):\n        if gm.USE_ENCRYPTED_ASSETS:\n            # Create a temporary file to store the decrytped asset, load it, and then delete it.\n            with tempfile.NamedTemporaryFile(suffix=\".usd\") as fp:\n                original_usd_path = self._usd_path\n                encrypted_filename = original_usd_path.replace(\".usd\", \".encrypted.usd\")\n                decrypt_file(encrypted_filename, decrypted_file=fp)\n                self._usd_path = fp.name\n                prim = super()._load(simulator=simulator)\n                self._usd_path = original_usd_path\n                return prim\n        else:\n            return super()._load(simulator=simulator)\n\n    def _post_load(self):\n        # We run this post loading first before any others because we're modifying the load config that will be used\n        # downstream\n        # Set the scale of this prim according to its bounding box\n        if self._load_config[\"fit_avg_dim_volume\"]:\n            # By default, we assume scale does not change if no avg obj specs are given, otherwise, scale accordingly\n            scale = np.ones(3)\n            if self.avg_obj_dims is not None:\n                # Find the average volume, and scale accordingly relative to the native volume based on the bbox\n                volume_ratio = np.product(self.avg_obj_dims[\"size\"]) / np.product(self.native_bbox)\n                size_ratio = np.cbrt(volume_ratio)\n                scale *= size_ratio\n        # Otherwise, if manual bounding box is specified, scale based on ratio between that and the native bbox\n        elif self._load_config[\"bounding_box\"] is not None:\n            scale = self._load_config[\"bounding_box\"] / self.native_bbox\n        else:\n            scale = np.ones(3) if self._load_config[\"scale\"] is None else self._load_config[\"scale\"]\n\n        # Set this scale in the load config -- it will automatically scale the object during self.initialize()\n        self._load_config[\"scale\"] = scale\n\n        # Load any supporting surfaces belonging to this object\n        self.load_supporting_surfaces()\n\n        # Run super last\n        super()._post_load()\n\n        if gm.USE_ENCRYPTED_ASSETS:\n            # The loaded USD is from an already-deleted temporary file, so the asset paths for texture maps are wrong.\n            # We explicitly provide the root_path to update all the asset paths: the asset paths are relative to the\n            # original USD folder, i.e. &lt;category&gt;/&lt;model&gt;/usd.\n            root_path = os.path.dirname(self._usd_path)\n            for material in self.materials:\n                material.shader_update_asset_paths_with_root_path(root_path)\n\n        # Assign realistic density and mass based on average object category spec\n        if self.avg_obj_dims is not None:\n            # Assume each link has the same density\n            v_ratio = (np.product(self.native_bbox) * np.product(self.scale)) / np.product(self.avg_obj_dims[\"size\"])\n            mass = self.avg_obj_dims[\"mass\"] * v_ratio\n            if self._prim_type == PrimType.RIGID:\n                density = mass / self.volume\n                for link in self._links.values():\n                    if bool(link.prim.GetAttribute(\"ig:is_metalink\").Get()):\n                        # This is a metalink; we set a negligible value\n                        link.mass = 1e-6\n                        link.density = 0.0\n                    else:\n                        # Otherwise overwrite the original, inaccurate mass value\n                        link.mass = 0.0\n                        link.density = density\n\n            elif self._prim_type == PrimType.CLOTH:\n                # Cloth cannot set density. Internally omni evenly distributes the mass to each particle\n                mass = self.avg_obj_dims[\"mass\"] * v_ratio\n                self._links[\"base_link\"].mass = mass\n\n        # Lastly, after post loading (which includes loading / registering the links internally)\n        # check for any metalinks. If there are any, we disable gravity and collisions for them\n        for link in self._links.values():\n            is_metalink = link.prim.GetAttribute(\"ig:is_metalink\").Get() or False\n            if is_metalink:\n                # Make sure this link is only visual (i.e.: no collisions or gravity enabled)\n                link.visual_only = True\n\n    def _update_texture_change(self, object_state):\n        \"\"\"\n        Update the texture based on the given object_state. E.g. if object_state is Frozen, update the diffuse color\n        to match the frozen state. If object_state is None, update the diffuse color to the default value. It attempts\n        to load the cached texture map named DIFFUSE/albedo_[STATE_NAME].png. If the cached texture map does not exist,\n        it modifies the current albedo map by adding and scaling the values. See @self._update_albedo_value for details.\n\n        Args:\n            object_state (BooleanState or None): the object state that the diffuse color should match to\n        \"\"\"\n        # TODO: uncomment these once our dataset has the object state-conditioned texture maps\n        # DEFAULT_ALBEDO_MAP_SUFFIX = frozenset({\"DIFFUSE\", \"COMBINED\", \"albedo\"})\n        # state_name = object_state.__class__.__name__ if object_state is not None else None\n        for material in self.materials:\n            # texture_path = material.diffuse_texture\n            # assert texture_path is not None, f\"DatasetObject [{self.prim_path}] has invalid diffuse texture map.\"\n            #\n            # # Get updated texture file path for state.\n            # texture_path_split = texture_path.split(\"/\")\n            # filedir, filename = \"/\".join(texture_path_split[:-1]), texture_path_split[-1]\n            # assert filename[-4:] == \".png\", f\"Texture file {filename} does not end with .png\"\n            #\n            # filename_split = filename[:-4].split(\"_\")\n            # # Check all three file names for backward compatibility.\n            # if len(filename_split) &gt; 0 and filename_split[-1] not in DEFAULT_ALBEDO_MAP_SUFFIX:\n            #     filename_split.pop()\n            # target_texture_path = f\"{filedir}/{'_'.join(filename_split)}\"\n            # target_texture_path += f\"_{state_name}.png\" if state_name is not None else \".png\"\n            #\n            # if os.path.exists(target_texture_path):\n            #     # Since we are loading a pre-cached texture map, we need to reset the albedo value to the default\n            #     self._update_albedo_value(None, material)\n            #     if material.diffuse_texture != target_texture_path:\n            #         material.diffuse_texture = target_texture_path\n            # else:\n            #     print(f\"Warning: DatasetObject [{self.prim_path}] does not have texture map: \"\n            #           f\"[{target_texture_path}]. Falling back to directly updating albedo value.\")\n            self._update_albedo_value(object_state, material)\n\n    def set_bbox_center_position_orientation(self, position=None, orientation=None):\n        \"\"\"\n        Sets the center of the object's bounding box with respect to the world's frame.\n\n        Args:\n            position (None or 3-array): The desired global (x,y,z) position. None means it will not be changed\n            orientation (None or 4-array): The desired global (x,y,z,w) quaternion orientation.\n                None means it will not be changed\n        \"\"\"\n        if orientation is None:\n            orientation = self.get_orientation()\n        if position is not None:\n            rotated_offset = T.pose_transform([0, 0, 0], orientation,\n                                              self.scaled_bbox_center_in_base_frame, [0, 0, 0, 1])[0]\n            position = position + rotated_offset\n        self.set_position_orientation(position, orientation)\n\n    @property\n    def in_rooms(self):\n        \"\"\"\n        Returns:\n            None or list of str: If specified, room(s) that this object should belong to\n        \"\"\"\n        return self._in_rooms\n\n    @in_rooms.setter\n    def in_rooms(self, rooms):\n        \"\"\"\n        Sets which room(s) this object should belong to. If no rooms, then should set to None\n\n        Args:\n            rooms (None or list of str): If specified, the room(s) this object should belong to\n        \"\"\"\n        # Store the value to the internal variable and also update the init kwargs accordingly\n        self._init_info[\"args\"][\"in_rooms\"] = rooms\n        self._in_rooms = rooms\n\n    @property\n    def bddl_object_scope(self):\n        \"\"\"\n        Returns:\n            None or str: If specified, BDDL object scope name (e.g. chip.n.04_2) to assign to this object\n        \"\"\"\n        return self._bddl_object_scope\n\n    @bddl_object_scope.setter\n    def bddl_object_scope(self, name):\n        \"\"\"\n        Sets which BDDL object scope name for this object. If no name, then should set to None\n\n        Args:\n            name (None or str): If specified, BDDL object scope name (e.g. chip.n.04_2) to assign to this object\n        \"\"\"\n        # Store the value to the internal variable and also update the init kwargs accordingly\n        self._init_info[\"args\"][\"bddl_object_scope\"] = name\n        self._bddl_object_scope = name\n\n    @property\n    def native_bbox(self):\n        \"\"\"\n        Get this object's native bounding box\n\n        Returns:\n            3-array: (x,y,z) bounding box\n        \"\"\"\n        assert \"ig:nativeBB\" in self.property_names, \\\n            f\"This dataset object '{self.name}' is expected to have native_bbox specified, but found none!\"\n        return np.array(self.get_attribute(attr=\"ig:nativeBB\"))\n\n    @property\n    def base_link_offset(self):\n        \"\"\"\n        Get this object's native base link offset\n\n        Returns:\n            3-array: (x,y,z) base link offset if it exists\n        \"\"\"\n        return np.array(self.get_attribute(attr=\"ig:offsetBaseLink\"))\n\n    @property\n    def metadata(self):\n        \"\"\"\n        Gets this object's metadata, if it exists\n\n        Returns:\n            None or dict: Nested dictionary of object's metadata if it exists, else None\n        \"\"\"\n        return self.get_custom_data().get(\"metadata\", None)\n\n    @property\n    def heights_per_link(self):\n        \"\"\"\n        Gets this object's heights per link information, if it exists\n\n        Returns:\n            None or dict: Nested dictionary of object's height per link information if it exists, else None\n        \"\"\"\n        return self.get_custom_data().get(\"heights_per_link\", None)\n\n    @property\n    def orientations(self):\n        \"\"\"\n        Returns:\n            None or dict: Possible orientation information for this object, if it exists. Otherwise, returns None\n        \"\"\"\n        metadata = self.metadata\n        return None if metadata is None else metadata.get(\"orientations\", None)\n\n    @property\n    def scaled_bbox_center_in_base_frame(self):\n        \"\"\"\n        where the base_link origin is wrt. the bounding box center. This allows us to place the model correctly\n        since the joint transformations given in the scene USD are wrt. the bounding box center.\n        We need to scale this offset as well.\n\n        Returns:\n            3-array: (x,y,z) location of bounding box, with respet to the base link's coordinate frame\n        \"\"\"\n        return -self.scale * self.base_link_offset\n\n    @property\n    def native_link_bboxes(self):\n        \"\"\"\n        Returns:\n             dict: Keyword-mapped native bounding boxes for each link of this object\n        \"\"\"\n        return None if self.metadata is None else self.metadata.get(\"link_bounding_boxes\", None)\n\n    @property\n    def scales_in_link_frame(self):\n        \"\"\"\n        Returns:\n        dict: Keyword-mapped relative scales for each link of this object\n        \"\"\"\n        scales = {self.root_link.body_name: self.scale}\n\n        # We iterate through all links in this object, and check for any joint prims that exist\n        # We traverse manually this way instead of accessing the self._joints dictionary, because\n        # the dictionary only includes articulated joints and not fixed joints!\n        for link in self._links.values():\n            for prim in link.prim.GetChildren():\n                if \"joint\" in prim.GetTypeName().lower():\n                    # Grab relevant joint information\n                    parent_name = prim.GetProperty(\"physics:body0\").GetTargets()[0].pathString.split(\"/\")[-1]\n                    child_name = prim.GetProperty(\"physics:body1\").GetTargets()[0].pathString.split(\"/\")[-1]\n                    if parent_name in scales and child_name not in scales:\n                        scale_in_parent_lf = scales[parent_name]\n                        # The location of the joint frame is scaled using the scale in the parent frame\n                        quat0 = gf_quat_to_np_array(prim.GetAttribute(\"physics:localRot0\").Get())[[1, 2, 3, 0]]\n                        quat1 = gf_quat_to_np_array(prim.GetAttribute(\"physics:localRot1\").Get())[[1, 2, 3, 0]]\n                        # Invert the child link relationship, and multiply the two rotations together to get the final rotation\n                        local_ori = T.quat_multiply(quaternion1=T.quat_inverse(quat1), quaternion0=quat0)\n                        jnt_frame_rot = T.quat2mat(local_ori)\n                        scale_in_child_lf = np.absolute(jnt_frame_rot.T @ np.array(scale_in_parent_lf))\n                        scales[child_name] = scale_in_child_lf\n\n        return scales\n\n    def get_base_aligned_bbox(self, link_name=None, visual=False, xy_aligned=False, fallback_to_aabb=False, link_bbox_type=\"axis_aligned\"):\n        \"\"\"\n        Get a bounding box for this object that's axis-aligned in the object's base frame.\n\n        Args:\n            link_name (None or str): If specified, only get the bbox for the given link\n            visual (bool): Whether to aggregate the bounding boxes from the visual meshes. Otherwise, will use\n                collision meshes\n            xy_aligned (bool): Whether to align the bounding box to the global XY-plane\n            fallback_to_aabb (bool): If set and a link's info is not found, the (global-frame) AABB will be\n                dynamically computed directly from omniverse\n            link_bbox_type (str): Which type of link bbox to use, \"axis_aligned\" means the bounding box is axis-aligned\n                to the link frame, \"oriented\" means the bounding box has the minimum volume\n\n        Returns:\n            4-tuple:\n                - 3-array: (x,y,z) bbox center position in world frame\n                - 3-array: (x,y,z,w) bbox quaternion orientation in world frame\n                - 3-array: (x,y,z) bbox extent in world frame\n                - 3-array: (x,y,z) bbox center in desired frame\n        \"\"\"\n        bbox_type = \"visual\" if visual else \"collision\"\n\n        # Get the base position transform.\n        pos, orn = self.get_position_orientation()\n        base_frame_to_world = T.pose2mat((pos, orn))\n\n        # Compute the world-to-base frame transform.\n        world_to_base_frame = trimesh.transformations.inverse_matrix(base_frame_to_world)\n\n        # Grab the corners of all the different links' bounding boxes. We will later fit a bounding box to\n        # this set of points to get our final, base-frame bounding box.\n        points = []\n\n        links = {link_name: self._links[link_name]} if link_name is not None else self._links\n        for link_name, link in links.items():\n            # If the link has no visual or collision meshes, we skip over it (based on the @visual flag)\n            meshes = link.visual_meshes if visual else link.collision_meshes\n            if len(meshes) == 0:\n                continue\n\n            # If the link has a bounding box annotation.\n            if self.native_link_bboxes is not None and link_name in self.native_link_bboxes:\n                # If a visual bounding box does not exist in the dictionary, try switching to collision.\n                # We expect that every link has its collision bb annotated (or set to None if none exists).\n                if bbox_type == \"visual\" and \"visual\" not in self.native_link_bboxes[link_name]:\n                    logging.debug(\n                        \"Falling back to collision bbox for object %s link %s since no visual bbox exists.\",\n                        self.name,\n                        link_name,\n                    )\n                    bbox_type = \"collision\"\n\n                # Check if the annotation is still missing.\n                if bbox_type not in self.native_link_bboxes[link_name]:\n                    raise ValueError(\n                        \"Could not find %s bounding box for object %s link %s\" % (bbox_type, self.name, link_name)\n                    )\n\n                # Check if a mesh exists for this link. If None, the link is meshless, so we continue to the next link.\n                # TODO: Because of encoding, may need to be UsdTokens.none, not None\n                if self.native_link_bboxes[link_name][bbox_type] is None:\n                    continue\n\n                # Get the extent and transform.\n                bb_data = self.native_link_bboxes[link_name][bbox_type][link_bbox_type]\n                extent_in_bbox_frame = np.array(bb_data[\"extent\"])\n                bbox_to_link_origin = np.array(bb_data[\"transform\"])\n\n                # # Get the link's pose in the base frame.\n                link_frame_to_world = T.pose2mat(link.get_position_orientation())\n                link_frame_to_base_frame = world_to_base_frame @ link_frame_to_world\n\n                # Scale the bounding box in link origin frame. Here we create a transform that first puts the bounding\n                # box's vertices into the link frame, and then scales them to match the scale applied to this object.\n                # Note that once scaled, the vertices of the bounding box do not necessarily form a cuboid anymore but\n                # instead a parallelepiped. This is not a problem because we later fit a bounding box to the points,\n                # this time in the object's base link frame.\n                scale_in_link_frame = np.diag(np.concatenate([self.scales_in_link_frame[link_name], [1]]))\n                bbox_to_scaled_link_origin = np.dot(scale_in_link_frame, bbox_to_link_origin)\n\n                # Compute the bounding box vertices in the base frame.\n                # bbox_to_link_com = np.dot(link_origin_to_link_com, bbox_to_scaled_link_origin)\n                bbox_center_in_base_frame = np.dot(link_frame_to_base_frame, bbox_to_scaled_link_origin)\n                vertices_in_base_frame = np.array(list(itertools.product((1, -1), repeat=3))) * (extent_in_bbox_frame / 2)\n\n                # Add the points to our collection of points.\n                points.extend(trimesh.transformations.transform_points(vertices_in_base_frame, bbox_center_in_base_frame))\n            elif fallback_to_aabb:\n                # If no BB annotation is available, get the AABB for this link.\n                aabb_center, aabb_extent = BoundingBoxAPI.compute_center_extent(prim_path=link.prim_path)\n                aabb_vertices_in_world = aabb_center + np.array(list(itertools.product((1, -1), repeat=3))) * (\n                        aabb_extent / 2\n                )\n                aabb_vertices_in_base_frame = trimesh.transformations.transform_points(\n                    aabb_vertices_in_world, world_to_base_frame\n                )\n                points.extend(aabb_vertices_in_base_frame)\n            else:\n                raise ValueError(\n                    \"Bounding box annotation missing for link: %s. Use fallback_to_aabb=True if you're okay with using \"\n                    \"AABB as fallback.\" % link_name\n                )\n\n        if xy_aligned:\n            # If the user requested an XY-plane aligned bbox, convert everything to that frame.\n            # The desired frame is same as the base_com frame with its X/Y rotations removed.\n            translate = trimesh.transformations.translation_from_matrix(base_frame_to_world)\n\n            # To find the rotation that this transform does around the Z axis, we rotate the [1, 0, 0] vector by it\n            # and then take the arctangent of its projection onto the XY plane.\n            rotated_X_axis = base_frame_to_world[:3, 0]\n            rotation_around_Z_axis = np.arctan2(rotated_X_axis[1], rotated_X_axis[0])\n            xy_aligned_base_com_to_world = trimesh.transformations.compose_matrix(\n                translate=translate, angles=[0, 0, rotation_around_Z_axis]\n            )\n\n            # We want to move our points to this frame as well.\n            world_to_xy_aligned_base_com = trimesh.transformations.inverse_matrix(xy_aligned_base_com_to_world)\n            base_com_to_xy_aligned_base_com = np.dot(world_to_xy_aligned_base_com, base_frame_to_world)\n            points = trimesh.transformations.transform_points(points, base_com_to_xy_aligned_base_com)\n\n            # Finally update our desired frame.\n            desired_frame_to_world = xy_aligned_base_com_to_world\n        else:\n            # Default desired frame is base CoM frame.\n            desired_frame_to_world = base_frame_to_world\n\n        # TODO: Implement logic to allow tight bounding boxes that don't necessarily have to match the base frame.\n        # All points are now in the desired frame: either the base CoM or the xy-plane-aligned base CoM.\n        # Now fit a bounding box to all the points by taking the minimum/maximum in the desired frame.\n        aabb_min_in_desired_frame = np.amin(points, axis=0)\n        aabb_max_in_desired_frame = np.amax(points, axis=0)\n        bbox_center_in_desired_frame = (aabb_min_in_desired_frame + aabb_max_in_desired_frame) / 2\n        bbox_extent_in_desired_frame = aabb_max_in_desired_frame - aabb_min_in_desired_frame\n\n        # Transform the center to the world frame.\n        bbox_center_in_world = trimesh.transformations.transform_points(\n            [bbox_center_in_desired_frame], desired_frame_to_world\n        )[0]\n        bbox_orn_in_world = Rotation.from_matrix(desired_frame_to_world[:3, :3]).as_quat()\n\n        return bbox_center_in_world, bbox_orn_in_world, bbox_extent_in_desired_frame, bbox_center_in_desired_frame\n\n    @property\n    def avg_obj_dims(self):\n        \"\"\"\n        Get the average object dimensions for this object, based on its category\n\n        Returns:\n            None or dict: Average object information based on its category\n        \"\"\"\n        return AVERAGE_CATEGORY_SPECS.get(self.category, None)\n\n    def _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n        # Add additional kwargs (fit_avg_dim_volume and bounding_box are already captured in load_config)\n        return self.__class__(\n            prim_path=prim_path,\n            usd_path=self._usd_path,\n            name=name,\n            category=self.category,\n            class_id=self.class_id,\n            scale=self.scale,\n            visible=self.visible,\n            fixed_base=self.fixed_base,\n            visual_only=self._visual_only,\n            prim_type=self._prim_type,\n            load_config=load_config,\n            abilities=self._abilities,\n            in_rooms=self.in_rooms,\n            bddl_object_scope=self.bddl_object_scope,\n        )\n</code></pre>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject"},{"title":"<code>avg_obj_dims</code>  <code>property</code>","text":"<p>Get the average object dimensions for this object, based on its category</p> <p>Returns:</p>    Type Description       <p>None or dict: Average object information based on its category</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.avg_obj_dims"},{"title":"<code>base_link_offset</code>  <code>property</code>","text":"<p>Get this object's native base link offset</p> <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) base link offset if it exists</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.base_link_offset"},{"title":"<code>bddl_object_scope</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: If specified, BDDL object scope name (e.g. chip.n.04_2) to assign to this object</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.bddl_object_scope"},{"title":"<code>heights_per_link</code>  <code>property</code>","text":"<p>Gets this object's heights per link information, if it exists</p> <p>Returns:</p>    Type Description       <p>None or dict: Nested dictionary of object's height per link information if it exists, else None</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.heights_per_link"},{"title":"<code>in_rooms</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or list of str: If specified, room(s) that this object should belong to</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.in_rooms"},{"title":"<code>metadata</code>  <code>property</code>","text":"<p>Gets this object's metadata, if it exists</p> <p>Returns:</p>    Type Description       <p>None or dict: Nested dictionary of object's metadata if it exists, else None</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.metadata"},{"title":"<code>native_bbox</code>  <code>property</code>","text":"<p>Get this object's native bounding box</p> <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) bounding box</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.native_bbox"},{"title":"<code>native_link_bboxes</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Keyword-mapped native bounding boxes for each link of this object</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.native_link_bboxes"},{"title":"<code>orientations</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or dict: Possible orientation information for this object, if it exists. Otherwise, returns None</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.orientations"},{"title":"<code>scaled_bbox_center_in_base_frame</code>  <code>property</code>","text":"<p>where the base_link origin is wrt. the bounding box center. This allows us to place the model correctly since the joint transformations given in the scene USD are wrt. the bounding box center. We need to scale this offset as well.</p> <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) location of bounding box, with respet to the base link's coordinate frame</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.scaled_bbox_center_in_base_frame"},{"title":"<code>scales_in_link_frame</code>  <code>property</code>","text":"<p>dict: Keyword-mapped relative scales for each link of this object</p>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.scales_in_link_frame"},{"title":"<code>__init__(prim_path, usd_path=None, name=None, category='object', model=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, bounding_box=None, fit_avg_dim_volume=False, in_rooms=None, bddl_object_scope=None, **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>usd_path</code>  <code>None or str</code>  <p>If specified, global path to the USD file to load. Note that this will override @category + @model!</p>  <code>None</code>    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  <code>'object'</code>    <code>model</code>  <code>None or str</code>  <p>if @usd_path is not specified, then this must be specified in conjunction with @category to infer the usd filepath to load for this object, which evaluates to the following:</p> <pre><code>{og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\n</code></pre>  <code>None</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  <code>PrimType.RIGID</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>include_default_states</code>  <code>bool</code>  <p>whether to include the default object states from @get_default_states</p>  <code>True</code>    <code>bounding_box</code>  <code>None or 3-array</code>  <p>If specified, will scale this object such that it fits in the desired (x,y,z) object-aligned bounding box. Note that EITHER @bounding_box or @scale may be specified -- not both!</p>  <code>None</code>    <code>fit_avg_dim_volume</code>  <code>bool</code>  <p>whether to fit the object to have the same volume as the average dimension while keeping the aspect ratio. Note that if this is set, it will override both @scale and @bounding_box</p>  <code>False</code>    <code>in_rooms</code>  <code>None or list</code>  <p>If specified, sets the rooms that this object should belong to</p>  <code>None</code>    <code>bddl_object_scope</code>  <code>None or str</code>  <p>If specified, should set the BDDL object scope name, e.g. chip.n.04_2</p>  <code>None</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>objects/dataset_object.py</code> <pre><code>def __init__(\n    self,\n    prim_path,\n    usd_path=None,\n    name=None,\n    category=\"object\",\n    model=None,\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    prim_type=PrimType.RIGID,\n    load_config=None,\n    abilities=None,\n    include_default_states=True,\n    bounding_box=None,\n    fit_avg_dim_volume=False,\n    in_rooms=None,\n    bddl_object_scope=None,\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        usd_path (None or str): If specified, global path to the USD file to load. Note that this will override\n            @category + @model!\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        model (None or str): if @usd_path is not specified, then this must be specified in conjunction with\n            @category to infer the usd filepath to load for this object, which evaluates to the following:\n\n                {og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\n\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        bounding_box (None or 3-array): If specified, will scale this object such that it fits in the desired\n            (x,y,z) object-aligned bounding box. Note that EITHER @bounding_box or @scale may be specified\n            -- not both!\n        fit_avg_dim_volume (bool): whether to fit the object to have the same volume as the average dimension\n            while keeping the aspect ratio. Note that if this is set, it will override both @scale and @bounding_box\n        in_rooms (None or list): If specified, sets the rooms that this object should belong to\n        bddl_object_scope (None or str): If specified, should set the BDDL object scope name, e.g. chip.n.04_2\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Store variables\n    self._in_rooms = in_rooms\n    self._bddl_object_scope = bddl_object_scope\n\n    # Info that will be filled in at runtime\n    self.supporting_surfaces = None             # Dictionary mapping link names to surfaces represented by links\n\n    # Make sure only one of bounding_box and scale are specified\n    if bounding_box is not None and scale is not None:\n        raise Exception(\"You cannot define both scale and bounding box size for an DatasetObject\")\n\n    # Add info to load config\n    load_config = dict() if load_config is None else load_config\n    load_config[\"bounding_box\"] = bounding_box\n    load_config[\"fit_avg_dim_volume\"] = fit_avg_dim_volume\n\n    # Infer the correct usd path to use\n    if usd_path is None:\n        assert model is not None, f\"Either usd_path or model and category must be specified in order to create a\" \\\n                                  f\"DatasetObject!\"\n        usd_path = f\"{og.og_dataset_path}/objects/{category}/{model}/usd/{model}.usd\"\n\n    # Post-process the usd path if we're generating a cloth object\n    if prim_type == PrimType.CLOTH:\n        assert usd_path.endswith(\".usd\"), f\"usd_path [{usd_path}] is invalid.\"\n        usd_path = usd_path[:-4] + \"_cloth.usd\"\n\n    # Run super init\n    super().__init__(\n        prim_path=prim_path,\n        usd_path=usd_path,\n        name=name,\n        category=category,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        prim_type=prim_type,\n        include_default_states=include_default_states,\n        load_config=load_config,\n        abilities=abilities,\n        **kwargs,\n    )\n</code></pre>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.__init__"},{"title":"<code>get_base_aligned_bbox(link_name=None, visual=False, xy_aligned=False, fallback_to_aabb=False, link_bbox_type='axis_aligned')</code>","text":"<p>Get a bounding box for this object that's axis-aligned in the object's base frame.</p> <p>Parameters:</p>    Name Type Description Default     <code>link_name</code>  <code>None or str</code>  <p>If specified, only get the bbox for the given link</p>  <code>None</code>    <code>visual</code>  <code>bool</code>  <p>Whether to aggregate the bounding boxes from the visual meshes. Otherwise, will use collision meshes</p>  <code>False</code>    <code>xy_aligned</code>  <code>bool</code>  <p>Whether to align the bounding box to the global XY-plane</p>  <code>False</code>    <code>fallback_to_aabb</code>  <code>bool</code>  <p>If set and a link's info is not found, the (global-frame) AABB will be dynamically computed directly from omniverse</p>  <code>False</code>    <code>link_bbox_type</code>  <code>str</code>  <p>Which type of link bbox to use, \"axis_aligned\" means the bounding box is axis-aligned to the link frame, \"oriented\" means the bounding box has the minimum volume</p>  <code>'axis_aligned'</code>     <p>Returns:</p>    Type Description       <p>4-tuple: - 3-array: (x,y,z) bbox center position in world frame - 3-array: (x,y,z,w) bbox quaternion orientation in world frame - 3-array: (x,y,z) bbox extent in world frame - 3-array: (x,y,z) bbox center in desired frame</p>     Source code in <code>objects/dataset_object.py</code> <pre><code>def get_base_aligned_bbox(self, link_name=None, visual=False, xy_aligned=False, fallback_to_aabb=False, link_bbox_type=\"axis_aligned\"):\n    \"\"\"\n    Get a bounding box for this object that's axis-aligned in the object's base frame.\n\n    Args:\n        link_name (None or str): If specified, only get the bbox for the given link\n        visual (bool): Whether to aggregate the bounding boxes from the visual meshes. Otherwise, will use\n            collision meshes\n        xy_aligned (bool): Whether to align the bounding box to the global XY-plane\n        fallback_to_aabb (bool): If set and a link's info is not found, the (global-frame) AABB will be\n            dynamically computed directly from omniverse\n        link_bbox_type (str): Which type of link bbox to use, \"axis_aligned\" means the bounding box is axis-aligned\n            to the link frame, \"oriented\" means the bounding box has the minimum volume\n\n    Returns:\n        4-tuple:\n            - 3-array: (x,y,z) bbox center position in world frame\n            - 3-array: (x,y,z,w) bbox quaternion orientation in world frame\n            - 3-array: (x,y,z) bbox extent in world frame\n            - 3-array: (x,y,z) bbox center in desired frame\n    \"\"\"\n    bbox_type = \"visual\" if visual else \"collision\"\n\n    # Get the base position transform.\n    pos, orn = self.get_position_orientation()\n    base_frame_to_world = T.pose2mat((pos, orn))\n\n    # Compute the world-to-base frame transform.\n    world_to_base_frame = trimesh.transformations.inverse_matrix(base_frame_to_world)\n\n    # Grab the corners of all the different links' bounding boxes. We will later fit a bounding box to\n    # this set of points to get our final, base-frame bounding box.\n    points = []\n\n    links = {link_name: self._links[link_name]} if link_name is not None else self._links\n    for link_name, link in links.items():\n        # If the link has no visual or collision meshes, we skip over it (based on the @visual flag)\n        meshes = link.visual_meshes if visual else link.collision_meshes\n        if len(meshes) == 0:\n            continue\n\n        # If the link has a bounding box annotation.\n        if self.native_link_bboxes is not None and link_name in self.native_link_bboxes:\n            # If a visual bounding box does not exist in the dictionary, try switching to collision.\n            # We expect that every link has its collision bb annotated (or set to None if none exists).\n            if bbox_type == \"visual\" and \"visual\" not in self.native_link_bboxes[link_name]:\n                logging.debug(\n                    \"Falling back to collision bbox for object %s link %s since no visual bbox exists.\",\n                    self.name,\n                    link_name,\n                )\n                bbox_type = \"collision\"\n\n            # Check if the annotation is still missing.\n            if bbox_type not in self.native_link_bboxes[link_name]:\n                raise ValueError(\n                    \"Could not find %s bounding box for object %s link %s\" % (bbox_type, self.name, link_name)\n                )\n\n            # Check if a mesh exists for this link. If None, the link is meshless, so we continue to the next link.\n            # TODO: Because of encoding, may need to be UsdTokens.none, not None\n            if self.native_link_bboxes[link_name][bbox_type] is None:\n                continue\n\n            # Get the extent and transform.\n            bb_data = self.native_link_bboxes[link_name][bbox_type][link_bbox_type]\n            extent_in_bbox_frame = np.array(bb_data[\"extent\"])\n            bbox_to_link_origin = np.array(bb_data[\"transform\"])\n\n            # # Get the link's pose in the base frame.\n            link_frame_to_world = T.pose2mat(link.get_position_orientation())\n            link_frame_to_base_frame = world_to_base_frame @ link_frame_to_world\n\n            # Scale the bounding box in link origin frame. Here we create a transform that first puts the bounding\n            # box's vertices into the link frame, and then scales them to match the scale applied to this object.\n            # Note that once scaled, the vertices of the bounding box do not necessarily form a cuboid anymore but\n            # instead a parallelepiped. This is not a problem because we later fit a bounding box to the points,\n            # this time in the object's base link frame.\n            scale_in_link_frame = np.diag(np.concatenate([self.scales_in_link_frame[link_name], [1]]))\n            bbox_to_scaled_link_origin = np.dot(scale_in_link_frame, bbox_to_link_origin)\n\n            # Compute the bounding box vertices in the base frame.\n            # bbox_to_link_com = np.dot(link_origin_to_link_com, bbox_to_scaled_link_origin)\n            bbox_center_in_base_frame = np.dot(link_frame_to_base_frame, bbox_to_scaled_link_origin)\n            vertices_in_base_frame = np.array(list(itertools.product((1, -1), repeat=3))) * (extent_in_bbox_frame / 2)\n\n            # Add the points to our collection of points.\n            points.extend(trimesh.transformations.transform_points(vertices_in_base_frame, bbox_center_in_base_frame))\n        elif fallback_to_aabb:\n            # If no BB annotation is available, get the AABB for this link.\n            aabb_center, aabb_extent = BoundingBoxAPI.compute_center_extent(prim_path=link.prim_path)\n            aabb_vertices_in_world = aabb_center + np.array(list(itertools.product((1, -1), repeat=3))) * (\n                    aabb_extent / 2\n            )\n            aabb_vertices_in_base_frame = trimesh.transformations.transform_points(\n                aabb_vertices_in_world, world_to_base_frame\n            )\n            points.extend(aabb_vertices_in_base_frame)\n        else:\n            raise ValueError(\n                \"Bounding box annotation missing for link: %s. Use fallback_to_aabb=True if you're okay with using \"\n                \"AABB as fallback.\" % link_name\n            )\n\n    if xy_aligned:\n        # If the user requested an XY-plane aligned bbox, convert everything to that frame.\n        # The desired frame is same as the base_com frame with its X/Y rotations removed.\n        translate = trimesh.transformations.translation_from_matrix(base_frame_to_world)\n\n        # To find the rotation that this transform does around the Z axis, we rotate the [1, 0, 0] vector by it\n        # and then take the arctangent of its projection onto the XY plane.\n        rotated_X_axis = base_frame_to_world[:3, 0]\n        rotation_around_Z_axis = np.arctan2(rotated_X_axis[1], rotated_X_axis[0])\n        xy_aligned_base_com_to_world = trimesh.transformations.compose_matrix(\n            translate=translate, angles=[0, 0, rotation_around_Z_axis]\n        )\n\n        # We want to move our points to this frame as well.\n        world_to_xy_aligned_base_com = trimesh.transformations.inverse_matrix(xy_aligned_base_com_to_world)\n        base_com_to_xy_aligned_base_com = np.dot(world_to_xy_aligned_base_com, base_frame_to_world)\n        points = trimesh.transformations.transform_points(points, base_com_to_xy_aligned_base_com)\n\n        # Finally update our desired frame.\n        desired_frame_to_world = xy_aligned_base_com_to_world\n    else:\n        # Default desired frame is base CoM frame.\n        desired_frame_to_world = base_frame_to_world\n\n    # TODO: Implement logic to allow tight bounding boxes that don't necessarily have to match the base frame.\n    # All points are now in the desired frame: either the base CoM or the xy-plane-aligned base CoM.\n    # Now fit a bounding box to all the points by taking the minimum/maximum in the desired frame.\n    aabb_min_in_desired_frame = np.amin(points, axis=0)\n    aabb_max_in_desired_frame = np.amax(points, axis=0)\n    bbox_center_in_desired_frame = (aabb_min_in_desired_frame + aabb_max_in_desired_frame) / 2\n    bbox_extent_in_desired_frame = aabb_max_in_desired_frame - aabb_min_in_desired_frame\n\n    # Transform the center to the world frame.\n    bbox_center_in_world = trimesh.transformations.transform_points(\n        [bbox_center_in_desired_frame], desired_frame_to_world\n    )[0]\n    bbox_orn_in_world = Rotation.from_matrix(desired_frame_to_world[:3, :3]).as_quat()\n\n    return bbox_center_in_world, bbox_orn_in_world, bbox_extent_in_desired_frame, bbox_center_in_desired_frame\n</code></pre>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.get_base_aligned_bbox"},{"title":"<code>sample_orientation()</code>","text":"<p>Samples an orientation in quaternion (x,y,z,w) form</p> <p>Returns:</p>    Type Description       <p>4-array: (x,y,z,w) sampled quaternion orientation for this object, based on self.orientations</p>     Source code in <code>objects/dataset_object.py</code> <pre><code>def sample_orientation(self):\n    \"\"\"\n    Samples an orientation in quaternion (x,y,z,w) form\n\n    Returns:\n        4-array: (x,y,z,w) sampled quaternion orientation for this object, based on self.orientations\n    \"\"\"\n    if self.orientations is None:\n        raise ValueError(\"No orientation probabilities set\")\n    if len(self.orientations) == 0:\n        # Set default value\n        chosen_orientation = np.array([0, 0, 0, 1.0])\n    else:\n        probabilities = [o[\"prob\"] for o in self.orientations.values()]\n        probabilities = np.array(probabilities) / np.sum(probabilities)\n        chosen_orientation = np.array(np.random.choice(list(self.orientations.values()), p=probabilities)[\"rotation\"])\n\n    # Randomize yaw from -pi to pi\n    rot_num = np.random.uniform(-1, 1)\n    rot_matrix = np.array(\n        [\n            [math.cos(math.pi * rot_num), -math.sin(math.pi * rot_num), 0.0],\n            [math.sin(math.pi * rot_num), math.cos(math.pi * rot_num), 0.0],\n            [0.0, 0.0, 1.0],\n        ]\n    )\n    rotated_quat = T.mat2quat(rot_matrix @ T.quat2mat(chosen_orientation))\n    return rotated_quat\n</code></pre>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.sample_orientation"},{"title":"<code>set_bbox_center_position_orientation(position=None, orientation=None)</code>","text":"<p>Sets the center of the object's bounding box with respect to the world's frame.</p> <p>Parameters:</p>    Name Type Description Default     <code>position</code>  <code>None or 3-array</code>  <p>The desired global (x,y,z) position. None means it will not be changed</p>  <code>None</code>    <code>orientation</code>  <code>None or 4-array</code>  <p>The desired global (x,y,z,w) quaternion orientation. None means it will not be changed</p>  <code>None</code>      Source code in <code>objects/dataset_object.py</code> <pre><code>def set_bbox_center_position_orientation(self, position=None, orientation=None):\n    \"\"\"\n    Sets the center of the object's bounding box with respect to the world's frame.\n\n    Args:\n        position (None or 3-array): The desired global (x,y,z) position. None means it will not be changed\n        orientation (None or 4-array): The desired global (x,y,z,w) quaternion orientation.\n            None means it will not be changed\n    \"\"\"\n    if orientation is None:\n        orientation = self.get_orientation()\n    if position is not None:\n        rotated_offset = T.pose_transform([0, 0, 0], orientation,\n                                          self.scaled_bbox_center_in_base_frame, [0, 0, 0, 1])[0]\n        position = position + rotated_offset\n    self.set_position_orientation(position, orientation)\n</code></pre>","location":"reference/objects/dataset_object.html#objects.dataset_object.DatasetObject.set_bbox_center_position_orientation"},{"title":"light_object","text":"","location":"reference/objects/light_object.html"},{"title":"<code>LightObject</code>","text":"<p>         Bases: <code>StatefulObject</code></p> <p>LightObjects are objects that generate light in the simulation</p>  Source code in <code>objects/light_object.py</code> <pre><code>class LightObject(StatefulObject):\n    \"\"\"\n    LightObjects are objects that generate light in the simulation\n    \"\"\"\n    LIGHT_TYPES = {\n        \"Cylinder\",\n        \"Disk\",\n        \"Distant\",\n        \"Dome\",\n        \"Geometry\",\n        \"Rect\",\n        \"Sphere\",\n    }\n\n    def __init__(\n        self,\n        prim_path,\n        light_type,\n        name=None,\n        category=\"light\",\n        class_id=None,\n        uuid=None,\n        scale=None,\n        load_config=None,\n        abilities=None,\n        include_default_states=True,\n        radius=1.0,\n        intensity=50000.0,\n        **kwargs,\n    ):\n\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            light_type (str): Type of light to create. Valid options are LIGHT_TYPES\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            radius (float): Radius for this light.\n            intensity (float): Intensity for this light.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Compose load config and add rgba values\n        load_config = dict() if load_config is None else load_config\n        load_config[\"scale\"] = scale\n        load_config[\"intensity\"] = intensity\n        load_config[\"radius\"] = radius if light_type in {\"Cylinder\", \"Disk\", \"Sphere\"} else None\n\n        # Make sure primitive type is valid\n        assert_valid_key(key=light_type, valid_keys=self.LIGHT_TYPES, name=\"light_type\")\n        self.light_type = light_type\n\n        # Other attributes to be filled in at runtime\n        self._light_link = None\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            category=category,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=True,\n            fixed_base=False,\n            visual_only=True,\n            self_collisions=False,\n            prim_type=PrimType.RIGID,\n            include_default_states=include_default_states,\n            load_config=load_config,\n            abilities=abilities,\n            **kwargs,\n        )\n\n    def _load(self, simulator=None):\n        logging.info(f\"Loading the following light: {self.light_type}\")\n\n        # Define a light prim at the current stage, or the simulator's stage if specified\n        stage = get_current_stage()\n\n        # Define XForm and base link for this light\n        prim = stage.DefinePrim(self._prim_path, \"Xform\")\n        base_link = stage.DefinePrim(f\"{self._prim_path}/base_link\", \"Xform\")\n\n        # Define the actual light link\n        light_prim = UsdLux.__dict__[f\"{self.light_type}Light\"].Define(stage, f\"{self._prim_path}/base_link/light\").GetPrim()\n\n        return prim\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # Grab reference to light link\n        self._light_link = XFormPrim(prim_path=f\"{self._prim_path}/base_link/light\", name=f\"{self.name}:light_link\")\n\n        # Apply Shaping API and set default cone angle attribute\n        shaping_api = UsdLux.ShapingAPI.Apply(self._light_link.prim).GetShapingConeAngleAttr().Set(180.0)\n\n        # Optionally set the intensity\n        if self._load_config.get(\"intensity\", None) is not None:\n            self.intensity = self._load_config[\"intensity\"]\n\n        # Optionally set the radius\n        if self._load_config.get(\"radius\", None) is not None:\n            self.radius = self._load_config[\"radius\"]\n\n    def _initialize(self):\n        # Run super\n        super()._initialize()\n\n        # Initialize light link\n        self._light_link.initialize()\n\n    @property\n    def light_link(self):\n        \"\"\"\n        Returns:\n            XFormPrim: Link corresponding to the light prim itself\n        \"\"\"\n        return self._light_link\n\n    @property\n    def radius(self):\n        \"\"\"\n        Gets this light's radius\n\n        Returns:\n            float: radius for this light\n        \"\"\"\n        return self._light_link.get_attribute(\"radius\")\n\n    @radius.setter\n    def radius(self, radius):\n        \"\"\"\n        Sets this light's radius\n\n        Args:\n            radius (float): radius to set\n        \"\"\"\n        self._light_link.set_attribute(\"radius\", radius)\n\n    @property\n    def intensity(self):\n        \"\"\"\n        Gets this joint's intensity\n\n        Returns:\n            float: intensity for this light\n        \"\"\"\n        return self._light_link.get_attribute(\"intensity\")\n\n    @intensity.setter\n    def intensity(self, intensity):\n        \"\"\"\n        Sets this joint's intensity\n\n        Args:\n            intensity (float): intensity to set\n        \"\"\"\n        self._light_link.set_attribute(\"intensity\", intensity)\n\n    def _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n        # Add additional kwargs (fit_avg_dim_volume and bounding_box are already captured in load_config)\n        return self.__class__(\n            prim_path=prim_path,\n            light_type=self.light_type,\n            name=name,\n            intensity=self.intensity,\n            load_config=load_config,\n        )\n</code></pre>","location":"reference/objects/light_object.html#objects.light_object.LightObject"},{"title":"<code>intensity</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's intensity</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>intensity for this light</p>","location":"reference/objects/light_object.html#objects.light_object.LightObject.intensity"},{"title":"<code>light_link</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>XFormPrim</code>   <p>Link corresponding to the light prim itself</p>","location":"reference/objects/light_object.html#objects.light_object.LightObject.light_link"},{"title":"<code>radius</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this light's radius</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>radius for this light</p>","location":"reference/objects/light_object.html#objects.light_object.LightObject.radius"},{"title":"<code>__init__(prim_path, light_type, name=None, category='light', class_id=None, uuid=None, scale=None, load_config=None, abilities=None, include_default_states=True, radius=1.0, intensity=50000.0, **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>light_type</code>  <code>str</code>  <p>Type of light to create. Valid options are LIGHT_TYPES</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  <code>'light'</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  required    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  required    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  required    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  required    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>include_default_states</code>  <code>bool</code>  <p>whether to include the default object states from @get_default_states</p>  <code>True</code>    <code>radius</code>  <code>float</code>  <p>Radius for this light.</p>  <code>1.0</code>    <code>intensity</code>  <code>float</code>  <p>Intensity for this light.</p>  <code>50000.0</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>objects/light_object.py</code> <pre><code>def __init__(\n    self,\n    prim_path,\n    light_type,\n    name=None,\n    category=\"light\",\n    class_id=None,\n    uuid=None,\n    scale=None,\n    load_config=None,\n    abilities=None,\n    include_default_states=True,\n    radius=1.0,\n    intensity=50000.0,\n    **kwargs,\n):\n\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        light_type (str): Type of light to create. Valid options are LIGHT_TYPES\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        radius (float): Radius for this light.\n        intensity (float): Intensity for this light.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Compose load config and add rgba values\n    load_config = dict() if load_config is None else load_config\n    load_config[\"scale\"] = scale\n    load_config[\"intensity\"] = intensity\n    load_config[\"radius\"] = radius if light_type in {\"Cylinder\", \"Disk\", \"Sphere\"} else None\n\n    # Make sure primitive type is valid\n    assert_valid_key(key=light_type, valid_keys=self.LIGHT_TYPES, name=\"light_type\")\n    self.light_type = light_type\n\n    # Other attributes to be filled in at runtime\n    self._light_link = None\n\n    # Run super method\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        category=category,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=True,\n        fixed_base=False,\n        visual_only=True,\n        self_collisions=False,\n        prim_type=PrimType.RIGID,\n        include_default_states=include_default_states,\n        load_config=load_config,\n        abilities=abilities,\n        **kwargs,\n    )\n</code></pre>","location":"reference/objects/light_object.html#objects.light_object.LightObject.__init__"},{"title":"object_base","text":"","location":"reference/objects/object_base.html"},{"title":"<code>BaseObject</code>","text":"<p>         Bases: <code>EntityPrim</code>, <code>Registerable</code></p> <p>This is the interface that all OmniGibson objects must implement.</p>  Source code in <code>objects/object_base.py</code> <pre><code>class BaseObject(EntityPrim, Registerable, metaclass=ABCMeta):\n    \"\"\"This is the interface that all OmniGibson objects must implement.\"\"\"\n\n    def __init__(\n            self,\n            prim_path,\n            name=None,\n            category=\"object\",\n            class_id=None,\n            uuid=None,\n            scale=None,\n            visible=True,\n            fixed_base=False,\n            visual_only=False,\n            self_collisions=False,\n            prim_type=PrimType.RIGID,\n            load_config=None,\n            **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n                Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n                that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n        \"\"\"\n        # Generate a name if necessary. Note that the generation order &amp; set of these names is not deterministic.\n        if name is None:\n            address = \"%08X\" % id(self)\n            name = \"{}_{}\".format(category, address)\n\n        # Store values\n        self.uuid = int(str(id(self))[-8:]) if uuid is None else uuid\n        assert len(str(self.uuid)) &lt;= 8, f\"UUID for this object must be at max 8-digits, got: {self.uuid}\"\n        self.category = category\n        self.fixed_base = fixed_base\n\n        logging.info(f\"Category: {self.category}\")\n\n        # This sets the collision group of the object. In omnigibson, objects are only permitted to be part of a single\n        # collision group, e.g. collisions are only enabled within a single group\n        self.collision_group = SPECIAL_COLLISION_GROUPS.get(self.category, DEFAULT_COLLISION_GROUP)\n\n        # Infer class ID if not specified\n        if class_id is None:\n            class_id = CLASS_NAME_TO_CLASS_ID.get(category, SemanticClass.USER_ADDED_OBJS)\n        self.class_id = class_id\n\n        # Values to be created at runtime\n        self._simulator = None\n        self._highlight_cached_values = None\n        self._highlighted = None\n\n        # Create load config from inputs\n        load_config = dict() if load_config is None else load_config\n        load_config[\"scale\"] = scale\n        load_config[\"visible\"] = visible\n        load_config[\"visual_only\"] = visual_only\n        load_config[\"self_collisions\"] = self_collisions\n        load_config[\"prim_type\"] = prim_type\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n        # TODO: Super hacky, think of a better way to preserve this info\n        # Update init info for this\n        self._init_info[\"args\"][\"name\"] = self.name\n        self._init_info[\"args\"][\"uuid\"] = self.uuid\n\n    def load(self, simulator=None):\n        # Run sanity check, any of these objects REQUIRE a simulator to be specified\n        assert simulator is not None, \"Simulator must be specified for loading any object subclassed from BaseObject!\"\n\n        # Save simulator reference\n        self._simulator = simulator\n\n        # Run super method ONLY if we're not loaded yet\n        return super().load(simulator=simulator) if not self.loaded else self._prim\n\n    def _post_load(self):\n        # Run super first\n        super()._post_load()\n\n        # Set visibility\n        if \"visible\" in self._load_config and self._load_config[\"visible\"] is not None:\n            self.visible = self._load_config[\"visible\"]\n\n        # Add fixed joint if we're fixing the base\n        if self.fixed_base:\n            # Create fixed joint, and set Body0 to be this object's root prim\n            create_joint(\n                prim_path=f\"{self._prim_path}/rootJoint\",\n                joint_type=\"FixedJoint\",\n                body1=f\"{self._prim_path}/{self._root_link_name}\",\n            )\n            # Also set the articulation root to be the object head if it doesn't already exist\n            if not self._prim.HasAPI(UsdPhysics.ArticulationRootAPI):\n                UsdPhysics.ArticulationRootAPI.Apply(self.prim)\n                PhysxSchema.PhysxArticulationAPI.Apply(self.prim)\n        else:\n            if self._prim.HasAPI(UsdPhysics.ArticulationRootAPI):\n                # If we only have a link, remove the articulation root API\n                if self.n_links == 1:\n                    self._prim.RemoveAPI(UsdPhysics.ArticulationRootAPI)\n                    self._prim.RemoveAPI(PhysxSchema.PhysxArticulationAPI)\n                else:\n                    # We need to fix (change) the articulation root\n                    # We have to do something very hacky because omniverse is buggy\n                    # Articulation roots mess up the joint order if it's on a non-fixed base robot, e.g. a\n                    # mobile manipulator. So if we have to move it to the actual root link of the robot instead.\n                    # See https://forums.developer.nvidia.com/t/inconsistent-values-from-isaacsims-dc-get-joint-parent-child-body/201452/2\n                    # for more info\n                    self._prim.RemoveAPI(UsdPhysics.ArticulationRootAPI)\n                    self._prim.RemoveAPI(PhysxSchema.PhysxArticulationAPI)\n                    UsdPhysics.ArticulationRootAPI.Apply(self.root_prim)\n                    PhysxSchema.PhysxArticulationAPI.Apply(self.root_prim)\n\n        # Set self collisions if we have articulation API to set\n        if self._prim.HasAPI(UsdPhysics.ArticulationRootAPI) or self.root_prim.HasAPI(UsdPhysics.ArticulationRootAPI):\n            self.self_collisions = self._load_config[\"self_collisions\"]\n\n        # TODO: Do we need to explicitly add all links? or is adding articulation root itself sufficient?\n        # Set the collision group\n        CollisionAPI.add_to_collision_group(\n            col_group=self.collision_group,\n            prim_path=self.prim_path,\n            create_if_not_exist=True,\n        )\n\n        # Update semantics\n        add_update_semantics(\n            prim=self._prim,\n            semantic_label=self.category,\n            type_label=\"class\",\n        )\n\n        # Force populate inputs and outputs of the shaders of all materials\n        for material in self.materials:\n            material.shader_force_populate()\n\n        # Iterate over all links and grab their relevant material info for highlighting (i.e.: emissivity info)\n        self._highlighted = False\n        self._highlight_cached_values = OrderedDict()\n\n        for material in self.materials:\n            self._highlight_cached_values[material] = {\n                \"enable_emission\": material.enable_emission,\n                \"emissive_color\": material.emissive_color,\n                \"emissive_intensity\": material.emissive_intensity,\n            }\n\n    def reset(self):\n        \"\"\"\n        Runs any necessary resetting functionality for this object. Default is pass-through\n        \"\"\"\n        pass\n\n    @property\n    def articulation_root_path(self):\n        # We override this because omniverse is buggy ):\n        # For non-fixed base objects (e.g.: mobile manipulators), using the default articulation root breaks the\n        # kinematic chain for some reason. So, the current workaround is to set the articulation root to be the\n        # actual base link of the robot instead.\n        # See https://forums.developer.nvidia.com/t/inconsistent-values-from-isaacsims-dc-get-joint-parent-child-body/201452/2\n        # for more info\n        return f\"{self._prim_path}/{self.root_link_name}\" if \\\n            (not self.fixed_base) and (self.n_links &gt; 1) else super().articulation_root_path\n\n    @property\n    def mass(self):\n        \"\"\"\n        Returns:\n             float: Cumulative mass of this potentially articulated object.\n        \"\"\"\n        mass = 0.0\n        for link in self._links.values():\n            mass += link.mass\n\n        return mass\n\n    @mass.setter\n    def mass(self, mass):\n        raise NotImplementedError(\"Cannot set mass directly for an object!\")\n\n    @property\n    def volume(self):\n        \"\"\"\n        Returns:\n             float: Cumulative volume of this potentially articulated object.\n        \"\"\"\n        volume = 0.0\n        for link in self._links.values():\n            volume += link.volume\n\n        return volume\n\n    @volume.setter\n    def volume(self, volume):\n        raise NotImplementedError(\"Cannot set volume directly for an object!\")\n\n    @property\n    def link_prim_paths(self):\n        return [link.prim_path for link in self._links.values()]\n\n    @property\n    def highlighted(self):\n        \"\"\"\n        Returns:\n            bool: Whether the object is highlighted or not\n        \"\"\"\n        return self._highlighted\n\n    @highlighted.setter\n    def highlighted(self, enabled):\n        \"\"\"\n        Iterates over all owned links, and modifies their materials with emissive colors so that the object is\n        highlighted (magenta by default)\n\n        Args:\n            enabled (bool): whether the object should be highlighted or not\n        \"\"\"\n        # Return early if the set value matches the internal value\n        if enabled == self._highlighted:\n            return\n\n        for material in self.materials:\n            if enabled:\n                # Store values before swapping\n                self._highlight_cached_values[material] = {\n                    \"enable_emission\": material.enable_emission,\n                    \"emissive_color\": material.emissive_color,\n                    \"emissive_intensity\": material.emissive_intensity,\n                }\n            material.enable_emission = True if enabled else self._highlight_cached_values[material][\"enable_emission\"]\n            material.emissive_color = m.HIGHLIGHT_RGB if enabled else self._highlight_cached_values[material][\"emissive_color\"]\n            material.emissive_intensity = m.HIGHLIGHT_INTENSITY if enabled else self._highlight_cached_values[material][\"emissive_intensity\"]\n\n        # Update internal value\n        self._highlighted = enabled\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseObject\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global robot registry\n        global REGISTERED_OBJECTS\n        return REGISTERED_OBJECTS\n</code></pre>","location":"reference/objects/object_base.html#objects.object_base.BaseObject"},{"title":"<code>highlighted</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether the object is highlighted or not</p>","location":"reference/objects/object_base.html#objects.object_base.BaseObject.highlighted"},{"title":"<code>mass</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Cumulative mass of this potentially articulated object.</p>","location":"reference/objects/object_base.html#objects.object_base.BaseObject.mass"},{"title":"<code>volume</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Cumulative volume of this potentially articulated object.</p>","location":"reference/objects/object_base.html#objects.object_base.BaseObject.volume"},{"title":"<code>__init__(prim_path, name=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  <code>'object'</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  <code>PrimType.RIGID</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject). Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).</p>  <code>{}</code>      Source code in <code>objects/object_base.py</code> <pre><code>def __init__(\n        self,\n        prim_path,\n        name=None,\n        category=\"object\",\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        prim_type=PrimType.RIGID,\n        load_config=None,\n        **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n            Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n            that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n    \"\"\"\n    # Generate a name if necessary. Note that the generation order &amp; set of these names is not deterministic.\n    if name is None:\n        address = \"%08X\" % id(self)\n        name = \"{}_{}\".format(category, address)\n\n    # Store values\n    self.uuid = int(str(id(self))[-8:]) if uuid is None else uuid\n    assert len(str(self.uuid)) &lt;= 8, f\"UUID for this object must be at max 8-digits, got: {self.uuid}\"\n    self.category = category\n    self.fixed_base = fixed_base\n\n    logging.info(f\"Category: {self.category}\")\n\n    # This sets the collision group of the object. In omnigibson, objects are only permitted to be part of a single\n    # collision group, e.g. collisions are only enabled within a single group\n    self.collision_group = SPECIAL_COLLISION_GROUPS.get(self.category, DEFAULT_COLLISION_GROUP)\n\n    # Infer class ID if not specified\n    if class_id is None:\n        class_id = CLASS_NAME_TO_CLASS_ID.get(category, SemanticClass.USER_ADDED_OBJS)\n    self.class_id = class_id\n\n    # Values to be created at runtime\n    self._simulator = None\n    self._highlight_cached_values = None\n    self._highlighted = None\n\n    # Create load config from inputs\n    load_config = dict() if load_config is None else load_config\n    load_config[\"scale\"] = scale\n    load_config[\"visible\"] = visible\n    load_config[\"visual_only\"] = visual_only\n    load_config[\"self_collisions\"] = self_collisions\n    load_config[\"prim_type\"] = prim_type\n\n    # Run super init\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        load_config=load_config,\n    )\n\n    # TODO: Super hacky, think of a better way to preserve this info\n    # Update init info for this\n    self._init_info[\"args\"][\"name\"] = self.name\n    self._init_info[\"args\"][\"uuid\"] = self.uuid\n</code></pre>","location":"reference/objects/object_base.html#objects.object_base.BaseObject.__init__"},{"title":"<code>reset()</code>","text":"<p>Runs any necessary resetting functionality for this object. Default is pass-through</p>  Source code in <code>objects/object_base.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Runs any necessary resetting functionality for this object. Default is pass-through\n    \"\"\"\n    pass\n</code></pre>","location":"reference/objects/object_base.html#objects.object_base.BaseObject.reset"},{"title":"primitive_object","text":"","location":"reference/objects/primitive_object.html"},{"title":"<code>PrimitiveObject</code>","text":"<p>         Bases: <code>StatefulObject</code></p> <p>PrimitiveObjects are objects defined by a single geom, e.g: sphere, mesh, cube, etc.</p>  Source code in <code>objects/primitive_object.py</code> <pre><code>class PrimitiveObject(StatefulObject):\n    \"\"\"\n    PrimitiveObjects are objects defined by a single geom, e.g: sphere, mesh, cube, etc.\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        primitive_type,\n        name=None,\n        category=\"object\",\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        prim_type=PrimType.RIGID,\n        load_config=None,\n        abilities=None,\n        include_default_states=True,\n        rgba=(0.5, 0.5, 0.5, 1.0),\n        radius=None,\n        height=None,\n        size=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            primitive_type (str): type of primitive object to create. Should be one of:\n                {\"Cone\", \"Cube\", \"Cylinder\", \"Disk\", \"Plane\", \"Sphere\", \"Torus\"}\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.rgba (4-array): (R, G, B, A) values to set for this object\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            radius (None or float): If specified, sets the radius for this object. This value is scaled by @scale\n                Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n            height (None or float): If specified, sets the height for this object. This value is scaled by @scale\n                Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\"}\n            size (None or float): If specified, sets the size for this object. This value is scaled by @scale\n                Note: Should only be specified if the @primitive_type is one of {\"Cube\", \"Torus\"}\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Compose load config and add rgba values\n        load_config = dict() if load_config is None else load_config\n        load_config[\"color\"] = np.array(rgba[:3])\n        load_config[\"opacity\"] = rgba[3]\n        load_config[\"radius\"] = radius\n        load_config[\"height\"] = height\n        load_config[\"size\"] = size\n\n        # Initialize other internal variables\n        self._vis_geom = None\n        self._col_geom = None\n        self._extents = np.ones(3)            # (x,y,z extents)\n\n        # Make sure primitive type is valid\n        assert_valid_key(key=primitive_type, valid_keys=PRIMITIVE_MESH_TYPES, name=\"primitive mesh type\")\n        self._primitive_type = primitive_type\n\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            category=category,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            prim_type=prim_type,\n            include_default_states=include_default_states,\n            load_config=load_config,\n            abilities=abilities,\n            **kwargs,\n        )\n\n    def _load(self, simulator=None):\n        logging.info(f\"Loading the following primitive: {self._primitive_type}\")\n\n        # Define an Xform at the specified path\n        stage = simulator.stage\n        prim = stage.DefinePrim(self._prim_path, \"Xform\")\n\n        if self._prim_type == PrimType.RIGID:\n            # Define a nested mesh corresponding to the root link for this prim\n            base_link = stage.DefinePrim(f\"{self._prim_path}/base_link\", \"Xform\")\n            self._vis_geom = create_primitive_mesh(prim_path=f\"{self._prim_path}/base_link/visual\", primitive_type=self._primitive_type)\n            self._col_geom = create_primitive_mesh(prim_path=f\"{self._prim_path}/base_link/collision\", primitive_type=self._primitive_type)\n\n            # Add collision API to collision geom\n            UsdPhysics.CollisionAPI.Apply(self._col_geom.GetPrim())\n            UsdPhysics.MeshCollisionAPI.Apply(self._col_geom.GetPrim())\n            PhysxSchema.PhysxCollisionAPI.Apply(self._col_geom.GetPrim())\n\n        elif self._prim_type == PrimType.CLOTH:\n            # For Cloth, the base link itself is a cloth mesh\n            # TODO (eric): configure u_patches and v_patches\n            self._vis_geom = create_primitive_mesh(\n                prim_path=f\"{self._prim_path}/base_link\",\n                primitive_type=self._primitive_type,\n                u_patches=None,\n                v_patches=None,\n            )\n            self._col_geom = None\n\n        # Create a material for this object for the base link\n        stage.DefinePrim(f\"{self._prim_path}/Looks\", \"Scope\")\n        mat_path = f\"{self._prim_path}/Looks/default\"\n        mat = create_pbr_material(prim_path=mat_path)\n        bind_material(prim_path=self._vis_geom.GetPrim().GetPrimPath().pathString, material_path=mat_path)\n\n        return prim\n\n    def _post_load(self):\n        # Run super first\n        super()._post_load()\n\n        if self._prim_type == PrimType.RIGID:\n            visual_geom_prim = list(self.links[\"base_link\"].visual_meshes.values())[0]\n        elif self._prim_type == PrimType.CLOTH:\n            visual_geom_prim = self.links[\"base_link\"]\n        else:\n            raise ValueError(\"Prim type must either be PrimType.RIGID or PrimType.CLOTH for loading a primitive object\")\n\n        visual_geom_prim.color = self._load_config[\"color\"]\n        visual_geom_prim.opacity = self._load_config[\"opacity\"]\n\n        # Update collision approximation\n        self.root_link.collision_meshes[\"collision\"].set_collision_approximation(\"convexHull\")\n\n        # Possibly set scalings (only if the scale value is not set)\n        if self._load_config[\"scale\"] is not None:\n            logging.warning(\"Custom scale specified for primitive object, so ignoring radius, height, and size arguments!\")\n        else:\n            if self._load_config[\"radius\"] is not None:\n                self.radius = self._load_config[\"radius\"]\n            if self._load_config[\"height\"] is not None:\n                self.height = self._load_config[\"height\"]\n            if self._load_config[\"size\"] is not None:\n                self.size = self._load_config[\"size\"]\n\n    @property\n    def radius(self):\n        \"\"\"\n        Gets this object's radius, if it exists.\n\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n\n        Returns:\n            float: radius for this object\n        \"\"\"\n        assert_valid_key(key=self._primitive_type, valid_keys=VALID_RADIUS_OBJECTS, name=\"primitive object with radius\")\n        return self._extents[0] / 2.0\n\n    @radius.setter\n    def radius(self, radius):\n        \"\"\"\n        Sets this object's radius\n\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n\n        Args:\n            radius (float): radius to set\n        \"\"\"\n        assert_valid_key(key=self._primitive_type, valid_keys=VALID_RADIUS_OBJECTS, name=\"primitive object with radius\")\n        original_extent = self._extents\n        attr_pairs = []\n        for geom in self._vis_geom, self._col_geom:\n            if geom is not None:\n                for attr in (geom.GetPointsAttr(), geom.GetNormalsAttr()):\n                    vals = np.array(attr.Get()).astype(np.float64)\n                    attr_pairs.append([attr, vals])\n\n        # Calculate how much to scale extents by and then modify the points / normals accordingly\n        scaling_factor = 2.0 * radius / original_extent[0]\n        for attr, vals in attr_pairs:\n            # If this is a sphere, modify all 3 axes\n            if self._primitive_type == \"Sphere\":\n                vals = vals * scaling_factor\n            # Otherwise, just modify the first two dimensions\n            else:\n                vals[:, :2] = vals[:, :2] * scaling_factor\n            # Set the value\n            attr.Set(Vt.Vec3fArray([Gf.Vec3f(*v) for v in vals]))\n\n        # Update the extents variable\n        self._extents = np.ones(3) * radius * 2.0 if self._primitive_type == \"Sphere\" else \\\n            np.array([radius * 2.0, radius * 2.0, self._extents[2]])\n\n    @property\n    def height(self):\n        \"\"\"\n        Gets this object's height, if it exists.\n\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\"}\n\n        Returns:\n            float: height for this object\n        \"\"\"\n        assert_valid_key(key=self._primitive_type, valid_keys=VALID_HEIGHT_OBJECTS, name=\"primitive object with height\")\n        return self._extents[2]\n\n    @height.setter\n    def height(self, height):\n        \"\"\"\n        Sets this object's height\n\n        Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\"}\n\n        Args:\n            height (float): height to set\n        \"\"\"\n        assert_valid_key(key=self._primitive_type, valid_keys=VALID_HEIGHT_OBJECTS, name=\"primitive object with height\")\n        original_extent = self._extents\n\n        # Calculate the correct scaling factor and scale the points and normals appropriately\n        scaling_factor = height / original_extent[2]\n        for geom in self._vis_geom, self._col_geom:\n            if geom is not None:\n                for attr in (geom.GetPointsAttr(), geom.GetNormalsAttr()):\n                    vals = np.array(attr.Get()).astype(np.float64)\n                    # Scale the z axis by the scaling factor\n                    vals[:, 2] = vals[:, 2] * scaling_factor\n                    attr.Set(Vt.Vec3fArray([Gf.Vec3f(*v) for v in vals]))\n\n        # Update the extents variable\n        self._extents[2] = height\n\n    @property\n    def size(self):\n        \"\"\"\n        Gets this object's size, if it exists.\n\n        Note: Can only be called if the primitive type is one of {\"Cube\", \"Torus\"}\n\n        Returns:\n            float: size for this object\n        \"\"\"\n        assert_valid_key(key=self._primitive_type, valid_keys=VALID_SIZE_OBJECTS, name=\"primitive object with size\")\n        return self._extents[0]\n\n    @size.setter\n    def size(self, size):\n        \"\"\"\n        Sets this object's size\n\n        Note: Can only be called if the primitive type is one of {\"Cube\", \"Torus\"}\n\n        Args:\n            size (float): size to set\n        \"\"\"\n        assert_valid_key(key=self._primitive_type, valid_keys=VALID_SIZE_OBJECTS, name=\"primitive object with size\")\n\n        original_extent = self._extents\n\n        # Calculate the correct scaling factor and scale the points and normals appropriately\n        scaling_factor = size / original_extent[0]\n        for geom in self._vis_geom, self._col_geom:\n            if geom is not None:\n                for attr in (geom.GetPointsAttr(), geom.GetNormalsAttr()):\n                    # Scale all three axes by the scaling factor\n                    vals = np.array(attr.Get()).astype(np.float64) * scaling_factor\n                    attr.Set(Vt.Vec3fArray([Gf.Vec3f(*v) for v in vals]))\n\n        # Update the extents variable\n        self._extents = np.ones(3) * size\n\n    def _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n        # Add additional kwargs (fit_avg_dim_volume and bounding_box are already captured in load_config)\n        return self.__class__(\n            prim_path=prim_path,\n            primitive_type=self._primitive_type,\n            name=name,\n            category=self.category,\n            class_id=self.class_id,\n            scale=self.scale,\n            visible=self.visible,\n            fixed_base=self.fixed_base,\n            prim_type=self._prim_type,\n            load_config=load_config,\n            abilities=self._abilities,\n            visual_only=self._visual_only,\n        )\n\n    def _dump_state(self):\n        state = super()._dump_state()\n        # state[\"extents\"] = self._extents\n        state[\"radius\"] = self.radius if self._primitive_type in VALID_RADIUS_OBJECTS else -1\n        state[\"height\"] = self.height if self._primitive_type in VALID_HEIGHT_OBJECTS else -1\n        state[\"size\"] = self.size if self._primitive_type in VALID_SIZE_OBJECTS else -1\n        return state\n\n    def _load_state(self, state):\n        super()._load_state(state=state)\n        # self._extents = np.array(state[\"extents\"])\n        if self._primitive_type in VALID_RADIUS_OBJECTS:\n            self.radius = state[\"radius\"]\n        if self._primitive_type in VALID_HEIGHT_OBJECTS:\n            self.height = state[\"height\"]\n        if self._primitive_type in VALID_SIZE_OBJECTS:\n            self.size = state[\"size\"]\n\n    def _deserialize(self, state):\n        state_dict, idx = super()._deserialize(state=state)\n        # state_dict[\"extents\"] = state[idx: idx + 3]\n        state_dict[\"radius\"] = state[idx]\n        state_dict[\"height\"] = state[idx + 1]\n        state_dict[\"size\"] = state[idx + 2]\n        return state_dict, idx + 3\n\n    def _serialize(self, state):\n        # Run super first\n        state_flat = super()._serialize(state=state)\n\n        return np.concatenate([\n            state_flat,\n            np.array([state[\"radius\"], state[\"height\"], state[\"size\"]]),\n        ]).astype(float)\n</code></pre>","location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject"},{"title":"<code>height</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this object's height, if it exists.</p> <p>Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\"}</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>height for this object</p>","location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.height"},{"title":"<code>radius</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this object's radius, if it exists.</p> <p>Note: Can only be called if the primitive type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>radius for this object</p>","location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.radius"},{"title":"<code>size</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this object's size, if it exists.</p> <p>Note: Can only be called if the primitive type is one of {\"Cube\", \"Torus\"}</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>size for this object</p>","location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.size"},{"title":"<code>__init__(prim_path, primitive_type, name=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, rgba=(0.5, 0.5, 0.5, 1.0), radius=None, height=None, size=None, **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>primitive_type</code>  <code>str</code>  <p>type of primitive object to create. Should be one of:</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  <code>'object'</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  <code>PrimType.RIGID</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.rgba (4-array): (R, G, B, A) values to set for this object</p>  <code>None</code>    <code>include_default_states</code>  <code>bool</code>  <p>whether to include the default object states from @get_default_states</p>  <code>True</code>    <code>radius</code>  <code>None or float</code>  <p>If specified, sets the radius for this object. This value is scaled by @scale Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}</p>  <code>None</code>    <code>height</code>  <code>None or float</code>  <p>If specified, sets the height for this object. This value is scaled by @scale Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\"}</p>  <code>None</code>    <code>size</code>  <code>None or float</code>  <p>If specified, sets the size for this object. This value is scaled by @scale Note: Should only be specified if the @primitive_type is one of {\"Cube\", \"Torus\"}</p>  <code>None</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>objects/primitive_object.py</code> <pre><code>def __init__(\n    self,\n    prim_path,\n    primitive_type,\n    name=None,\n    category=\"object\",\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    prim_type=PrimType.RIGID,\n    load_config=None,\n    abilities=None,\n    include_default_states=True,\n    rgba=(0.5, 0.5, 0.5, 1.0),\n    radius=None,\n    height=None,\n    size=None,\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        primitive_type (str): type of primitive object to create. Should be one of:\n            {\"Cone\", \"Cube\", \"Cylinder\", \"Disk\", \"Plane\", \"Sphere\", \"Torus\"}\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.rgba (4-array): (R, G, B, A) values to set for this object\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        radius (None or float): If specified, sets the radius for this object. This value is scaled by @scale\n            Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\", \"Disk\", \"Sphere\"}\n        height (None or float): If specified, sets the height for this object. This value is scaled by @scale\n            Note: Should only be specified if the @primitive_type is one of {\"Cone\", \"Cylinder\"}\n        size (None or float): If specified, sets the size for this object. This value is scaled by @scale\n            Note: Should only be specified if the @primitive_type is one of {\"Cube\", \"Torus\"}\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Compose load config and add rgba values\n    load_config = dict() if load_config is None else load_config\n    load_config[\"color\"] = np.array(rgba[:3])\n    load_config[\"opacity\"] = rgba[3]\n    load_config[\"radius\"] = radius\n    load_config[\"height\"] = height\n    load_config[\"size\"] = size\n\n    # Initialize other internal variables\n    self._vis_geom = None\n    self._col_geom = None\n    self._extents = np.ones(3)            # (x,y,z extents)\n\n    # Make sure primitive type is valid\n    assert_valid_key(key=primitive_type, valid_keys=PRIMITIVE_MESH_TYPES, name=\"primitive mesh type\")\n    self._primitive_type = primitive_type\n\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        category=category,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        prim_type=prim_type,\n        include_default_states=include_default_states,\n        load_config=load_config,\n        abilities=abilities,\n        **kwargs,\n    )\n</code></pre>","location":"reference/objects/primitive_object.html#objects.primitive_object.PrimitiveObject.__init__"},{"title":"stateful_object","text":"","location":"reference/objects/stateful_object.html"},{"title":"<code>StatefulObject</code>","text":"<p>         Bases: <code>BaseObject</code></p> <p>Objects that support object states.</p>  Source code in <code>objects/stateful_object.py</code> <pre><code>class StatefulObject(BaseObject):\n    \"\"\"Objects that support object states.\"\"\"\n\n    def __init__(\n            self,\n            prim_path,\n            name=None,\n            category=\"object\",\n            class_id=None,\n            uuid=None,\n            scale=None,\n            visible=True,\n            fixed_base=False,\n            visual_only=False,\n            self_collisions=False,\n            prim_type=PrimType.RIGID,\n            load_config=None,\n            abilities=None,\n            include_default_states=True,\n            **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Values that will be filled later\n        self._states = None\n        self._emitters = OrderedDict()\n        self._current_texture_state = None\n\n        # Load abilities from taxonomy if needed &amp; possible\n        if abilities is None:\n            abilities = {}\n            if OBJECT_TAXONOMY is not None:\n                # TODO! Update!!\n                taxonomy_class = OBJECT_TAXONOMY.get_class_name_from_igibson_category(category)\n                if taxonomy_class is not None:\n                    abilities = OBJECT_TAXONOMY.get_abilities(taxonomy_class)\n        assert isinstance(abilities, dict), \"Object abilities must be in dictionary form.\"\n\n        self._abilities = abilities\n        self.prepare_object_states(abilities=abilities, include_default_states=include_default_states)\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            category=category,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            prim_type=prim_type,\n            load_config=load_config,\n            **kwargs,\n        )\n\n    def _initialize(self):\n        # Run super first\n        super()._initialize()\n\n        # Initialize all states\n        for state in self._states.values():\n            state.initialize(self._simulator)\n\n    def add_state(self, state):\n        \"\"\"\n        Adds state @state with name @name to self.states.\n\n        Args:\n            state (ObjectStateBase): Object state instance to add to this object\n        \"\"\"\n        assert self._states is not None, \"Cannot add state since states have not been initialized yet!\"\n        assert state.__class__ not in self._states, f\"State {state.__class__.__name__} \" \\\n                                                    f\"has already been added to this object!\"\n        self._states[state.__class__] = state\n\n    @property\n    def states(self):\n        \"\"\"\n        Get the current states of this object.\n\n        Returns:\n            OrderedDict: Keyword-mapped states for this object\n        \"\"\"\n        return self._states\n\n    def prepare_object_states(self, abilities=None, include_default_states=True):\n        \"\"\"\n        Prepare the state dictionary for an object by generating the appropriate\n        object state instances.\n\n        This uses the abilities of the object and the state dependency graph to\n        find &amp; instantiate all relevant states.\n\n        Args:\n            abilities (None or dict): If specified, dict in the form of {ability: {param: value}} containing\n                object abilities and parameters.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n        \"\"\"\n        if abilities is None:\n            abilities = {}\n\n        state_types_and_params = [(state, {}) for state in get_default_states()] if include_default_states else []\n\n        # Map the ability params to the states immediately imported by the abilities\n        for ability, params in abilities.items():\n            state_types_and_params.extend((state_name, params) for state_name in get_states_for_ability(ability))\n\n        # Add the dependencies into the list, too.\n        for state_type, _ in state_types_and_params:\n            # Add each state's dependencies, too. Note that only required dependencies are added.\n            for dependency in state_type.get_dependencies():\n                if all(other_state != dependency for other_state, _ in state_types_and_params):\n                    state_types_and_params.append((dependency, {}))\n\n        # Now generate the states in topological order.\n        self._states = OrderedDict()\n        for state_type, params in reversed(state_types_and_params):\n            self._states[state_type] = get_object_state_instance(state_type, self, params)\n\n    def _post_load(self):\n        super()._post_load()\n\n        if len(set(self.states) &amp; set(get_steam_states())) &gt; 0:\n            self._create_emitter_apis(EmitterType.STEAM)\n\n        if len(set(self.states) &amp; set(get_fire_states())) &gt; 0 and self.states[HeatSourceOrSink].get_state_link_name() in self._links:\n            self._create_emitter_apis(EmitterType.FIRE)\n\n    def _create_emitter_apis(self, emitter_type):\n        \"\"\"\n        Create necessary prims and apis for steam effects.\n\n        Args:\n            emitter_type (EmitterType): Emitter to create\n        \"\"\"\n        # Make sure that flow setting is enabled.\n        renderer_setting = RendererSettings()\n        renderer_setting.common_settings.flow_settings.enable()\n\n        # Specify emitter config.\n        emitter_config = {}\n        link_name = self.root_link_name\n        if emitter_type == EmitterType.FIRE:\n            link_name = self.states[HeatSourceOrSink].get_state_link_name()\n            emitter_config[\"name\"] = \"flowEmitterSphere\"\n            emitter_config[\"type\"] = \"FlowEmitterSphere\"\n            emitter_config[\"position\"] = (0.0, 0.0, 0.0)\n            emitter_config[\"fuel\"] = 0.6\n            emitter_config[\"coupleRateFuel\"] = 1.2\n            emitter_config[\"buoyancyPerTemp\"] = 0.04\n            emitter_config[\"burnPerTemp\"] = 4\n            emitter_config[\"gravity\"] = (0, 0, -60.0)\n            emitter_config[\"constantMask\"] = 5.0\n            emitter_config[\"attenuation\"] = 0.5\n        elif emitter_type == EmitterType.STEAM:\n            bbox_extent_local = self.native_bbox if hasattr(self, \"native_bbox\") else self.aabb_extent / self.scale\n            emitter_config[\"name\"] = \"flowEmitterBox\"\n            emitter_config[\"type\"] = \"FlowEmitterBox\"\n            emitter_config[\"position\"] = (0.0, 0.0, bbox_extent_local[2] * m.STEAM_EMITTER_HEIGHT_RATIO)\n            emitter_config[\"fuel\"] = 1.0\n            emitter_config[\"coupleRateFuel\"] = 0.5\n            emitter_config[\"buoyancyPerTemp\"] = 0.05\n            emitter_config[\"burnPerTemp\"] = 0.5\n            emitter_config[\"gravity\"] = (0, 0, -50.0)\n            emitter_config[\"constantMask\"] = 10.0\n            emitter_config[\"attenuation\"] = 1.5\n        else:\n            raise ValueError(\"Currently, only EmitterTypes FIRE and STEAM are supported!\")\n\n        # Define prim paths.\n        # The flow system is created under the root link so that it automatically updates its pose as the object moves\n        flowEmitter_prim_path = f\"{self._prim_path}/{link_name}/{emitter_config['name']}\"\n        flowSimulate_prim_path = f\"{self._prim_path}/{link_name}/flowSimulate\"\n        flowOffscreen_prim_path = f\"{self._prim_path}/{link_name}/flowOffscreen\"\n        flowRender_prim_path = f\"{self._prim_path}/{link_name}/flowRender\"\n\n        # Define prims.\n        stage = self._simulator.stage\n        emitter = stage.DefinePrim(flowEmitter_prim_path, emitter_config[\"type\"])\n        simulate = stage.DefinePrim(flowSimulate_prim_path, \"FlowSimulate\")\n        offscreen = stage.DefinePrim(flowOffscreen_prim_path, \"FlowOffscreen\")\n        renderer = stage.DefinePrim(flowRender_prim_path, \"FlowRender\")\n        advection = stage.DefinePrim(flowSimulate_prim_path + \"/advection\", \"FlowAdvectionCombustionParams\")\n        smoke = stage.DefinePrim(flowSimulate_prim_path + \"/advection/smoke\", \"FlowAdvectionCombustionParams\")\n        vorticity = stage.DefinePrim(flowSimulate_prim_path + \"/vorticity\", \"FlowVorticityParams\")\n        rayMarch = stage.DefinePrim(flowRender_prim_path + \"/rayMarch\", \"FlowRayMarchParams\")\n        colormap = stage.DefinePrim(flowOffscreen_prim_path + \"/colormap\", \"FlowRayMarchColormapParams\")\n\n        self._emitters[emitter_type] = emitter\n\n        # Update emitter general settings.\n        emitter.CreateAttribute(\"enabled\", VT.Bool, False).Set(False)\n        emitter.CreateAttribute(\"position\", VT.Float3, False).Set(emitter_config[\"position\"])\n        emitter.CreateAttribute(\"fuel\", VT.Float, False).Set(emitter_config[\"fuel\"])\n        emitter.CreateAttribute(\"coupleRateFuel\", VT.Float, False).Set(emitter_config[\"coupleRateFuel\"])\n        emitter.CreateAttribute(\"coupleRateVelocity\", VT.Float, False).Set(2.0)\n        emitter.CreateAttribute(\"velocity\", VT.Float3, False).Set((0, 0, 0))\n        advection.CreateAttribute(\"buoyancyPerTemp\", VT.Float, False).Set(emitter_config[\"buoyancyPerTemp\"])\n        advection.CreateAttribute(\"burnPerTemp\", VT.Float, False).Set(emitter_config[\"burnPerTemp\"])\n        advection.CreateAttribute(\"gravity\", VT.Float3, False).Set(emitter_config[\"gravity\"])\n        vorticity.CreateAttribute(\"constantMask\", VT.Float, False).Set(emitter_config[\"constantMask\"])\n        rayMarch.CreateAttribute(\"attenuation\", VT.Float, False).Set(emitter_config[\"attenuation\"])\n\n        # Update emitter unique settings.\n        if emitter_type == EmitterType.FIRE:\n            # TODO: get radius of heat_source_link from metadata.\n            radius = 0.05\n            emitter.CreateAttribute(\"radius\", VT.Float, False).Set(radius)\n            simulate.CreateAttribute(\"densityCellSize\", VT.Float, False).Set(radius*0.2)\n            smoke.CreateAttribute(\"fade\", Sdf.ValueTypeNames.Float, False).Set(2.0)\n            # Set fire colormap.\n            rgbaPoints = []\n            rgbaPoints.append(Gf.Vec4f(0.0154, 0.0177, 0.0154, 0.004902))\n            rgbaPoints.append(Gf.Vec4f(0.03575, 0.03575, 0.03575, 0.504902))\n            rgbaPoints.append(Gf.Vec4f(0.03575, 0.03575, 0.03575, 0.504902))\n            rgbaPoints.append(Gf.Vec4f(1, 0.1594, 0.0134, 0.8))\n            rgbaPoints.append(Gf.Vec4f(13.53, 2.99, 0.12599, 0.8))\n            rgbaPoints.append(Gf.Vec4f(78, 39, 6.1, 0.7))\n            colormap.CreateAttribute(\"rgbaPoints\", Sdf.ValueTypeNames.Float4Array, False).Set(rgbaPoints)\n        elif emitter_type == EmitterType.STEAM:\n            emitter.CreateAttribute(\"halfSize\", VT.Float3, False).Set(\n                tuple(bbox_extent_local * np.array(m.STEAM_EMITTER_SIZE_RATIO) / 2.0))\n            simulate.CreateAttribute(\"densityCellSize\", VT.Float, False).Set(bbox_extent_local[2] * m.STEAM_EMITTER_DENSITY_CELL_RATIO)\n\n    def set_emitter_enabled(self, emitter_type, value):\n        \"\"\"\n        Enable/disable the emitter prim for fire/steam effect.\n\n        Args:\n            emitter_type (EmitterType): Emitter to set\n            value (bool): Value to set\n        \"\"\"\n        if emitter_type not in self._emitters:\n            return\n        if value != self._emitters[emitter_type].GetAttribute(\"enabled\").Get():\n            self._emitters[emitter_type].GetAttribute(\"enabled\").Set(value)\n\n    def get_textures(self):\n        \"\"\"\n        Gets prim's texture files.\n\n        Returns:\n            list of str: List of texture file paths\n        \"\"\"\n        return [material.diffuse_texture for material in self.materials if material.diffuse_texture is not None]\n\n    def update_visuals(self):\n        \"\"\"\n        Update the prim's visuals (texture change, steam/fire effects, etc).\n        Should be called after all the states are updated.\n        \"\"\"\n        texture_change_states = []\n        emitter_enabled = defaultdict(bool)\n        for state_type, state in self.states.items():\n            if state_type in get_texture_change_states():\n                if state_type == Saturated:\n                    for fluid_system in get_fluid_systems.values():\n                        if state.get_value(fluid_system):\n                            texture_change_states.append(state)\n                            # Only need to do this once, since soaked handles all fluid systems\n                            break\n                elif state.get_value():\n                    texture_change_states.append(state)\n            if state_type in get_steam_states():\n                emitter_enabled[EmitterType.STEAM] |= state.get_value()\n            if state_type in get_fire_states():\n                # Currently, the only state that uses fire is HeatSourceOrSink, whose get_value()\n                # returns (heat_source_state, heat_source_position).\n                emitter_enabled[EmitterType.FIRE] |= state.get_value()[0]\n\n            for emitter_type in emitter_enabled:\n                self.set_emitter_enabled(emitter_type, emitter_enabled[emitter_type])\n\n        texture_change_states.sort(key=lambda s: get_texture_change_priority()[s.__class__])\n        object_state = texture_change_states[-1] if len(texture_change_states) &gt; 0 else None\n\n        # Only update our texture change if it's a different object state than the one we already have\n        if object_state != self._current_texture_state:\n            self._update_texture_change(object_state)\n            self._current_texture_state = object_state\n\n    def _update_texture_change(self, object_state):\n        \"\"\"\n        Update the texture based on the given object_state. E.g. if object_state is Frozen, update the diffuse color\n        to match the frozen state. If object_state is None, update the diffuse color to the default value. It modifies\n        the current albedo map by adding and scaling the values. See @self._update_albedo_value for details.\n\n        Args:\n            object_state (BooleanState or None): the object state that the diffuse color should match to\n        \"\"\"\n        for material in self.materials:\n            self._update_albedo_value(object_state, material)\n\n    @staticmethod\n    def _update_albedo_value(object_state, material):\n        \"\"\"\n        Update the albedo value based on the given object_state. The final albedo value is\n        albedo_value = diffuse_tint * (albedo_value + albedo_add)\n\n        Args:\n            object_state (BooleanState or None): the object state that the diffuse color should match to\n            material (MaterialPrim): the material to use to update the albedo value\n        \"\"\"\n        if object_state is None:\n            # This restore the albedo map to its original value\n            albedo_add = 0.0\n            diffuse_tint = (1.0, 1.0, 1.0)\n        else:\n            # Query the object state for the parameters\n            albedo_add, diffuse_tint = object_state.get_texture_change_params()\n\n        if material.albedo_add != albedo_add:\n            material.albedo_add = albedo_add\n\n        if not np.allclose(material.diffuse_tint, diffuse_tint):\n            material.diffuse_tint = diffuse_tint\n\n    def remove(self, simulator=None):\n        \"\"\"\n        Removes this prim from omniverse stage\n\n        Args:\n            simulator (None or SimulationContext): If specified, should be simulator into which this prim will be\n                removed. Otherwise, it will be removed from the default stage\n        \"\"\"\n        # Iterate over all states and run their remove call\n        for state_instance in self._states.values():\n            state_instance.remove()\n\n        # Run super\n        super().remove(simulator=simulator)\n\n    def _dump_state(self):\n        # Grab state from super class\n        state = super()._dump_state()\n\n        # Also add non-kinematic states\n        non_kin_states = OrderedDict()\n        for state_type, state_instance in self._states.items():\n            if state_instance.stateful:\n                non_kin_states[get_state_name(state_type)] = state_instance.dump_state(serialized=False)\n\n        state[\"non_kin\"] = non_kin_states\n\n        return state\n\n    def _load_state(self, state):\n        # Call super method first\n        super()._load_state(state=state)\n\n        # Load all states that are stateful\n        for state_type, state_instance in self._states.items():\n            state_name = get_state_name(state_type)\n            if state_instance.stateful:\n                if state_name in state[\"non_kin\"]:\n                    state_instance.load_state(state=state[\"non_kin\"][state_name], serialized=False)\n                else:\n                    logging.warning(\"Missing object state [{}] in the state dump\".format(state_name))\n\n    def _serialize(self, state):\n        # Call super method first\n        state_flat = super()._serialize(state=state)\n\n        # Iterate over all states and serialize them individually\n        non_kin_state_flat = np.concatenate([\n            self._states[REGISTERED_OBJECT_STATES[state_name]].serialize(state_dict)\n            for state_name, state_dict in state[\"non_kin\"].items()\n        ]) if len(state[\"non_kin\"]) &gt; 0 else np.array([])\n\n        # Combine these two arrays\n        return np.concatenate([state_flat, non_kin_state_flat]).astype(float)\n\n    def _deserialize(self, state):\n        # Call super method first\n        state_dic, idx = super()._deserialize(state=state)\n\n        # Iterate over all states and deserialize their states if they're stateful\n        non_kin_state_dic = OrderedDict()\n        for state_type, state_instance in self._states.items():\n            state_name = get_state_name(state_type)\n            if state_instance.stateful:\n                non_kin_state_dic[state_name] = state_instance.deserialize(state[idx:idx+state_instance.state_size])\n                idx += state_instance.state_size\n        state_dic[\"non_kin\"] = non_kin_state_dic\n\n        return state_dic, idx\n\n    def clear_cached_states(self):\n        \"\"\"\n        Clears the internal cache from all owned states\n        \"\"\"\n        # Check self._states just in case states have not been initialized yet.\n        if not self._states:\n            return\n        for _, obj_state in self._states.items():\n            obj_state.clear_cache()\n        BoundingBoxAPI.clear()\n\n    def reset_states(self):\n        \"\"\"\n        Resets all object states' internal values\n        \"\"\"\n        # Check self._states just in case states have not been initialized yet.\n        if not self._states:\n            return\n        for _, obj_state in self._states.items():\n            obj_state.reset()\n\n    def reset(self):\n        # Call super first\n        super().reset()\n\n        # Reset all states\n        self.reset_states()\n\n    def set_position_orientation(self, position=None, orientation=None):\n        super().set_position_orientation(position=position, orientation=orientation)\n        self.clear_cached_states()\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"StatefulObject\")\n        return classes\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject"},{"title":"<code>states</code>  <code>property</code>","text":"<p>Get the current states of this object.</p> <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Keyword-mapped states for this object</p>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.states"},{"title":"<code>__init__(prim_path, name=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  <code>'object'</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  <code>PrimType.RIGID</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>include_default_states</code>  <code>bool</code>  <p>whether to include the default object states from @get_default_states</p>  <code>True</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>objects/stateful_object.py</code> <pre><code>def __init__(\n        self,\n        prim_path,\n        name=None,\n        category=\"object\",\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        prim_type=PrimType.RIGID,\n        load_config=None,\n        abilities=None,\n        include_default_states=True,\n        **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Values that will be filled later\n    self._states = None\n    self._emitters = OrderedDict()\n    self._current_texture_state = None\n\n    # Load abilities from taxonomy if needed &amp; possible\n    if abilities is None:\n        abilities = {}\n        if OBJECT_TAXONOMY is not None:\n            # TODO! Update!!\n            taxonomy_class = OBJECT_TAXONOMY.get_class_name_from_igibson_category(category)\n            if taxonomy_class is not None:\n                abilities = OBJECT_TAXONOMY.get_abilities(taxonomy_class)\n    assert isinstance(abilities, dict), \"Object abilities must be in dictionary form.\"\n\n    self._abilities = abilities\n    self.prepare_object_states(abilities=abilities, include_default_states=include_default_states)\n\n    # Run super init\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        category=category,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        prim_type=prim_type,\n        load_config=load_config,\n        **kwargs,\n    )\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.__init__"},{"title":"<code>add_state(state)</code>","text":"<p>Adds state @state with name @name to self.states.</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>ObjectStateBase</code>  <p>Object state instance to add to this object</p>  required      Source code in <code>objects/stateful_object.py</code> <pre><code>def add_state(self, state):\n    \"\"\"\n    Adds state @state with name @name to self.states.\n\n    Args:\n        state (ObjectStateBase): Object state instance to add to this object\n    \"\"\"\n    assert self._states is not None, \"Cannot add state since states have not been initialized yet!\"\n    assert state.__class__ not in self._states, f\"State {state.__class__.__name__} \" \\\n                                                f\"has already been added to this object!\"\n    self._states[state.__class__] = state\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.add_state"},{"title":"<code>clear_cached_states()</code>","text":"<p>Clears the internal cache from all owned states</p>  Source code in <code>objects/stateful_object.py</code> <pre><code>def clear_cached_states(self):\n    \"\"\"\n    Clears the internal cache from all owned states\n    \"\"\"\n    # Check self._states just in case states have not been initialized yet.\n    if not self._states:\n        return\n    for _, obj_state in self._states.items():\n        obj_state.clear_cache()\n    BoundingBoxAPI.clear()\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.clear_cached_states"},{"title":"<code>get_textures()</code>","text":"<p>Gets prim's texture files.</p> <p>Returns:</p>    Type Description       <p>list of str: List of texture file paths</p>     Source code in <code>objects/stateful_object.py</code> <pre><code>def get_textures(self):\n    \"\"\"\n    Gets prim's texture files.\n\n    Returns:\n        list of str: List of texture file paths\n    \"\"\"\n    return [material.diffuse_texture for material in self.materials if material.diffuse_texture is not None]\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.get_textures"},{"title":"<code>prepare_object_states(abilities=None, include_default_states=True)</code>","text":"<p>Prepare the state dictionary for an object by generating the appropriate object state instances.</p> <p>This uses the abilities of the object and the state dependency graph to find &amp; instantiate all relevant states.</p> <p>Parameters:</p>    Name Type Description Default     <code>abilities</code>  <code>None or dict</code>  <p>If specified, dict in the form of {ability: {param: value}} containing object abilities and parameters.</p>  <code>None</code>    <code>include_default_states</code>  <code>bool</code>  <p>whether to include the default object states from @get_default_states</p>  <code>True</code>      Source code in <code>objects/stateful_object.py</code> <pre><code>def prepare_object_states(self, abilities=None, include_default_states=True):\n    \"\"\"\n    Prepare the state dictionary for an object by generating the appropriate\n    object state instances.\n\n    This uses the abilities of the object and the state dependency graph to\n    find &amp; instantiate all relevant states.\n\n    Args:\n        abilities (None or dict): If specified, dict in the form of {ability: {param: value}} containing\n            object abilities and parameters.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n    \"\"\"\n    if abilities is None:\n        abilities = {}\n\n    state_types_and_params = [(state, {}) for state in get_default_states()] if include_default_states else []\n\n    # Map the ability params to the states immediately imported by the abilities\n    for ability, params in abilities.items():\n        state_types_and_params.extend((state_name, params) for state_name in get_states_for_ability(ability))\n\n    # Add the dependencies into the list, too.\n    for state_type, _ in state_types_and_params:\n        # Add each state's dependencies, too. Note that only required dependencies are added.\n        for dependency in state_type.get_dependencies():\n            if all(other_state != dependency for other_state, _ in state_types_and_params):\n                state_types_and_params.append((dependency, {}))\n\n    # Now generate the states in topological order.\n    self._states = OrderedDict()\n    for state_type, params in reversed(state_types_and_params):\n        self._states[state_type] = get_object_state_instance(state_type, self, params)\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.prepare_object_states"},{"title":"<code>remove(simulator=None)</code>","text":"<p>Removes this prim from omniverse stage</p> <p>Parameters:</p>    Name Type Description Default     <code>simulator</code>  <code>None or SimulationContext</code>  <p>If specified, should be simulator into which this prim will be removed. Otherwise, it will be removed from the default stage</p>  <code>None</code>      Source code in <code>objects/stateful_object.py</code> <pre><code>def remove(self, simulator=None):\n    \"\"\"\n    Removes this prim from omniverse stage\n\n    Args:\n        simulator (None or SimulationContext): If specified, should be simulator into which this prim will be\n            removed. Otherwise, it will be removed from the default stage\n    \"\"\"\n    # Iterate over all states and run their remove call\n    for state_instance in self._states.values():\n        state_instance.remove()\n\n    # Run super\n    super().remove(simulator=simulator)\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.remove"},{"title":"<code>reset_states()</code>","text":"<p>Resets all object states' internal values</p>  Source code in <code>objects/stateful_object.py</code> <pre><code>def reset_states(self):\n    \"\"\"\n    Resets all object states' internal values\n    \"\"\"\n    # Check self._states just in case states have not been initialized yet.\n    if not self._states:\n        return\n    for _, obj_state in self._states.items():\n        obj_state.reset()\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.reset_states"},{"title":"<code>set_emitter_enabled(emitter_type, value)</code>","text":"<p>Enable/disable the emitter prim for fire/steam effect.</p> <p>Parameters:</p>    Name Type Description Default     <code>emitter_type</code>  <code>EmitterType</code>  <p>Emitter to set</p>  required    <code>value</code>  <code>bool</code>  <p>Value to set</p>  required      Source code in <code>objects/stateful_object.py</code> <pre><code>def set_emitter_enabled(self, emitter_type, value):\n    \"\"\"\n    Enable/disable the emitter prim for fire/steam effect.\n\n    Args:\n        emitter_type (EmitterType): Emitter to set\n        value (bool): Value to set\n    \"\"\"\n    if emitter_type not in self._emitters:\n        return\n    if value != self._emitters[emitter_type].GetAttribute(\"enabled\").Get():\n        self._emitters[emitter_type].GetAttribute(\"enabled\").Set(value)\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.set_emitter_enabled"},{"title":"<code>update_visuals()</code>","text":"<p>Update the prim's visuals (texture change, steam/fire effects, etc). Should be called after all the states are updated.</p>  Source code in <code>objects/stateful_object.py</code> <pre><code>def update_visuals(self):\n    \"\"\"\n    Update the prim's visuals (texture change, steam/fire effects, etc).\n    Should be called after all the states are updated.\n    \"\"\"\n    texture_change_states = []\n    emitter_enabled = defaultdict(bool)\n    for state_type, state in self.states.items():\n        if state_type in get_texture_change_states():\n            if state_type == Saturated:\n                for fluid_system in get_fluid_systems.values():\n                    if state.get_value(fluid_system):\n                        texture_change_states.append(state)\n                        # Only need to do this once, since soaked handles all fluid systems\n                        break\n            elif state.get_value():\n                texture_change_states.append(state)\n        if state_type in get_steam_states():\n            emitter_enabled[EmitterType.STEAM] |= state.get_value()\n        if state_type in get_fire_states():\n            # Currently, the only state that uses fire is HeatSourceOrSink, whose get_value()\n            # returns (heat_source_state, heat_source_position).\n            emitter_enabled[EmitterType.FIRE] |= state.get_value()[0]\n\n        for emitter_type in emitter_enabled:\n            self.set_emitter_enabled(emitter_type, emitter_enabled[emitter_type])\n\n    texture_change_states.sort(key=lambda s: get_texture_change_priority()[s.__class__])\n    object_state = texture_change_states[-1] if len(texture_change_states) &gt; 0 else None\n\n    # Only update our texture change if it's a different object state than the one we already have\n    if object_state != self._current_texture_state:\n        self._update_texture_change(object_state)\n        self._current_texture_state = object_state\n</code></pre>","location":"reference/objects/stateful_object.html#objects.stateful_object.StatefulObject.update_visuals"},{"title":"usd_object","text":"","location":"reference/objects/usd_object.html"},{"title":"<code>USDObject</code>","text":"<p>         Bases: <code>StatefulObject</code></p> <p>USDObjects are instantiated from a USD file. They can be composed of one or more links and joints. They may or may not be passive.</p>  Source code in <code>objects/usd_object.py</code> <pre><code>class USDObject(StatefulObject):\n    \"\"\"\n    USDObjects are instantiated from a USD file. They can be composed of one\n    or more links and joints. They may or may not be passive.\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        usd_path,\n        name=None,\n        category=\"object\",\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        prim_type=PrimType.RIGID,\n        load_config=None,\n        abilities=None,\n        include_default_states=True,\n        **kwargs,\n    ):\n        \"\"\"\n\n        Args:\n            prim_path (str): global path in the stage to this object\n            usd_path (str): global path to the USD file to load\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            include_default_states (bool): whether to include the default object states from @get_default_states\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n                Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n                that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n        \"\"\"\n        self._usd_path = usd_path\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            category=category,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            prim_type=prim_type,\n            include_default_states=include_default_states,\n            load_config=load_config,\n            abilities=abilities,\n            **kwargs,\n        )\n\n    def _load(self, simulator=None):\n        \"\"\"\n        Load the object into pybullet and set it to the correct pose\n        \"\"\"\n        logging.info(f\"Loading the following USD: {self._usd_path}\")\n        return add_asset_to_stage(asset_path=self._usd_path, prim_path=self._prim_path)\n\n    def _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n        # Add additional kwargs\n        return self.__class__(\n            prim_path=prim_path,\n            usd_path=self._usd_path,\n            name=name,\n            category=self.category,\n            class_id=self.class_id,\n            scale=self.scale,\n            visible=self.visible,\n            fixed_base=self.fixed_base,\n            visual_only=self._visual_only,\n            prim_type=self._prim_type,\n            load_config=load_config,\n            abilities=self._abilities,\n        )\n\n    @property\n    def usd_path(self):\n        \"\"\"\n        :return str: absolute path to this model's USD file. By default, this is the loaded usd path\n        passed in as an argument\n        \"\"\"\n        return self._usd_path\n</code></pre>","location":"reference/objects/usd_object.html#objects.usd_object.USDObject"},{"title":"<code>usd_path</code>  <code>property</code>","text":"<p>:return str: absolute path to this model's USD file. By default, this is the loaded usd path passed in as an argument</p>","location":"reference/objects/usd_object.html#objects.usd_object.USDObject.usd_path"},{"title":"<code>__init__(prim_path, usd_path, name=None, category='object', class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, prim_type=PrimType.RIGID, load_config=None, abilities=None, include_default_states=True, **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>usd_path</code>  <code>str</code>  <p>global path to the USD file to load</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  <code>'object'</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  <code>PrimType.RIGID</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>include_default_states</code>  <code>bool</code>  <p>whether to include the default object states from @get_default_states</p>  <code>True</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject). Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).</p>  <code>{}</code>      Source code in <code>objects/usd_object.py</code> <pre><code>def __init__(\n    self,\n    prim_path,\n    usd_path,\n    name=None,\n    category=\"object\",\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    prim_type=PrimType.RIGID,\n    load_config=None,\n    abilities=None,\n    include_default_states=True,\n    **kwargs,\n):\n    \"\"\"\n\n    Args:\n        prim_path (str): global path in the stage to this object\n        usd_path (str): global path to the USD file to load\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        include_default_states (bool): whether to include the default object states from @get_default_states\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n            Note that this base object does NOT pass kwargs down into the Prim-type super() classes, and we assume\n            that kwargs are only shared between all SUBclasses (children), not SUPERclasses (parents).\n    \"\"\"\n    self._usd_path = usd_path\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        category=category,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        prim_type=prim_type,\n        include_default_states=include_default_states,\n        load_config=load_config,\n        abilities=abilities,\n        **kwargs,\n    )\n</code></pre>","location":"reference/objects/usd_object.html#objects.usd_object.USDObject.__init__"},{"title":"prims","text":"","location":"reference/prims/index.html"},{"title":"cloth_prim","text":"","location":"reference/prims/cloth_prim.html"},{"title":"<code>ClothPrim</code>","text":"<p>         Bases: <code>GeomPrim</code></p> <p>Provides high level functions to deal with a cloth prim and its attributes/ properties. If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created.</p>  if the prim does not already have a cloth api applied to it before it is loaded, <p>it will apply it.</p>  <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be specified:</p> <p>scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds     to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling. mass (None or float): If specified, mass of this body in kg</p>  <code>None</code>      Source code in <code>prims/cloth_prim.py</code> <pre><code>class ClothPrim(GeomPrim):\n    \"\"\"\n    Provides high level functions to deal with a cloth prim and its attributes/ properties.\n    If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created.\n\n    Notes: if the prim does not already have a cloth api applied to it before it is loaded,\n        it will apply it.\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be\n            specified:\n\n            scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds\n                to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.\n            mass (None or float): If specified, mass of this body in kg\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        self._mass_api = UsdPhysics.MassAPI(self._prim) if self._prim.HasAPI(UsdPhysics.MassAPI) else \\\n            UsdPhysics.MassAPI.Apply(self._prim)\n\n        # Possibly set the mass / density\n        if \"mass\" in self._load_config and self._load_config[\"mass\"] is not None:\n            self.mass = self._load_config[\"mass\"]\n\n        particleUtils.add_physx_particle_cloth(\n            stage=get_current_stage(),\n            path=self._prim.GetPath(),\n            dynamic_mesh_path=None,\n            particle_system_path=f\"/World/ClothSystem\",\n            spring_stretch_stiffness=m.CLOTH_STRETCH_STIFFNESS,\n            spring_bend_stiffness=m.CLOTH_BEND_STIFFNESS,\n            spring_shear_stiffness=m.CLOTH_SHEAR_STIFFNESS,\n            spring_damping=m.CLOTH_DAMPING,\n            self_collision=True,\n            self_collision_filter=True,\n        )\n\n    def _initialize(self):\n        super()._initialize()\n        # TODO (eric): hacky way to get cloth rendering to work (otherwise, there exist some rendering artifacts).\n        self._prim.CreateAttribute(\"primvars:isVolume\", VT.Bool, False).Set(True)\n        self._prim.GetAttribute(\"primvars:isVolume\").Set(False)\n\n    @property\n    def particle_positions(self):\n        \"\"\"\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z)\n                cartesian coordinates relative to the world frame\n        \"\"\"\n        r = T.quat2mat(self.get_orientation())\n        t = self.get_position()\n        s = self.scale\n\n        p_local = np.array(self.get_attribute(attr=\"points\"))\n        p_world = (r @ (p_local * s).T).T + t\n\n        return p_world\n\n    @particle_positions.setter\n    def particle_positions(self, pos):\n        \"\"\"\n        Set the particle positions for this instancer\n\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired positions are expressed in (x,y,z)\n                cartesian coordinates relative to the world frame\n        \"\"\"\n        assert pos.shape[0] == self.particle_positions.shape[0], \\\n            f\"Got mismatch in particle setting size: {pos.shape[0]}, vs. number of particles {self.particle_positions.shape[0]}!\"\n\n        r = T.quat2mat(self.get_orientation())\n        t = self.get_position()\n        s = self.scale\n\n        p_local = (r.T @ (pos - t).T).T / s\n        self.set_attribute(attr=\"points\", val=array_to_vtarray(arr=p_local, element_type=Gf.Vec3f))\n\n    def update_handles(self):\n        # no handles to update\n        pass\n\n    @property\n    def volume(self):\n        raise NotImplementedError(\"Cannot get volume for ClothPrim\")\n\n    @volume.setter\n    def volume(self, volume):\n        raise NotImplementedError(\"Cannot set volume for ClothPrim\")\n\n    @property\n    def mass(self):\n        \"\"\"\n        Returns:\n            float: mass of the rigid body in kg.\n        \"\"\"\n        # We have to read the mass directly in the cloth prim\n        return self._mass_api.GetMassAttr().Get()\n\n    @mass.setter\n    def mass(self, mass):\n        \"\"\"\n        Args:\n            mass (float): mass of the rigid body in kg.\n        \"\"\"\n        # We have to set the mass directly in the cloth prim\n        self._mass_api.GetMassAttr().Set(mass)\n\n    @property\n    def density(self):\n        raise NotImplementedError(\"Cannot get density for ClothPrim\")\n\n    @density.setter\n    def density(self, density):\n        raise NotImplementedError(\"Cannot set density for ClothPrim\")\n\n    def set_linear_velocity(self, velocity):\n        # TODO (eric): Just a pass through for now.\n        return\n\n    def set_angular_velocity(self, velocity):\n        # TODO (eric): Just a pass through for now.\n        return\n\n    def wake(self):\n        # TODO (eric): Just a pass through for now.\n        return\n</code></pre>","location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim"},{"title":"<code>mass</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>mass of the rigid body in kg.</p>","location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.mass"},{"title":"<code>particle_positions</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z) cartesian coordinates relative to the world frame</p>","location":"reference/prims/cloth_prim.html#prims.cloth_prim.ClothPrim.particle_positions"},{"title":"entity_prim","text":"","location":"reference/prims/entity_prim.html"},{"title":"<code>EntityPrim</code>","text":"<p>         Bases: <code>XFormPrim</code></p> <p>Provides high level functions to deal with an articulation prim and its attributes/ properties. Note that this type of prim cannot be created from scratch, and assumes there is already a pre-existing prim tree that should be converted into an articulation!</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that by default, this assumes an articulation already exists (i.e.: load() will raise NotImplementedError)! Subclasses must implement _load() for this prim to be able to be dynamically loaded after this class is created.</p> <p>visual_only (None or bool): If specified, whether this prim should include collisions or not.         Default is True.</p>  <code>None</code>      Source code in <code>prims/entity_prim.py</code> <pre><code>class EntityPrim(XFormPrim):\n    \"\"\"\n    Provides high level functions to deal with an articulation prim and its attributes/ properties. Note that this\n    type of prim cannot be created from scratch, and assumes there is already a pre-existing prim tree that should\n    be converted into an articulation!\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that by default, this assumes an articulation already exists (i.e.:\n            load() will raise NotImplementedError)! Subclasses must implement _load() for this prim to be able to be\n            dynamically loaded after this class is created.\n\n            visual_only (None or bool): If specified, whether this prim should include collisions or not.\n                    Default is True.\n        \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n        # Other values that will be filled in at runtime\n        self._dc = None                         # Dynamics control interface\n        self._handle = None                     # Handle to this articulation\n        self._root_handle = None                # Handle to the root rigid body of this articulation\n        self._root_link_name = None             # Name of the root link\n        self._dofs_infos = None\n        self._n_dof = None                      # dof with dynamic control\n        self._links = None\n        self._joints = None\n        self._visual_only = None\n\n        # This needs to be initialized to be used for _load() of PrimitiveObject\n        self._prim_type = load_config[\"prim_type\"] if \"prim_type\" in load_config else PrimType.RIGID\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _initialize(self):\n        # Run super method\n        super()._initialize()\n\n        # Initialize all the links\n        # This must happen BEFORE the handle is generated for this prim, because things changing in the RigidPrims may\n        # cause the handle to change!\n        for link in self._links.values():\n            link.initialize()\n\n        # Get dynamic control info\n        self._dc = _dynamic_control.acquire_dynamic_control_interface()\n\n        # Update joint information\n        self.update_joints()\n\n    def _load(self, simulator=None):\n        # By default, this prim cannot be instantiated from scratch!\n        raise NotImplementedError(\"By default, an entity prim cannot be created from scratch.\")\n\n    def _post_load(self):\n        # Setup links info FIRST before running any other post loading behavior\n        self.update_links()\n\n        # Set visual only flag\n        # This automatically handles setting collisions / gravity appropriately per-link\n        self.visual_only = self._load_config[\"visual_only\"] if \\\n            \"visual_only\" in self._load_config and self._load_config[\"visual_only\"] is not None else False\n\n        if self._prim_type == PrimType.CLOTH:\n            assert not self._visual_only, \"Cloth cannot be visual-only.\"\n            assert len(self._links) == 1, f\"Cloth entity prim can only have one link; got: {len(self._links)}\"\n            if gm.AG_CLOTH:\n                self.create_attachment_point_link()\n\n        # Disable any requested collision pairs\n        for a_name, b_name in self.disabled_collision_pairs:\n            link_a, link_b = self._links[a_name], self._links[b_name]\n            link_a.add_filtered_collision_pair(prim=link_b)\n\n        # Run super\n        super()._post_load()\n\n    def update_links(self):\n        \"\"\"\n        Helper function to refresh owned joints. Useful for synchronizing internal data if\n        additional bodies are added manually\n        \"\"\"\n        # Make sure to clean up all pre-existing names for all links\n        if self._links is not None:\n            for link in self._links.values():\n                link.remove_names()\n\n        # We iterate over all children of this object's prim,\n        # and grab any that are presumed to be rigid bodies (i.e.: other Xforms)\n        self._links = OrderedDict()\n        joint_children = set()\n        for prim in self._prim.GetChildren():\n            link = None\n            link_name = prim.GetName()\n            if self._prim_type == PrimType.RIGID and prim.GetPrimTypeInfo().GetTypeName() == \"Xform\":\n                # For rigid body object, process prims that are Xforms (e.g. rigid links)\n                link = RigidPrim(\n                    prim_path=prim.GetPrimPath().__str__(),\n                    name=f\"{self._name}:{link_name}\",\n                )\n                # Also iterate through all children to infer joints and determine the children of those joints\n                # We will use this info to infer which link is the base link!\n                for child_prim in prim.GetChildren():\n                    if \"joint\" in child_prim.GetPrimTypeInfo().GetTypeName().lower():\n                        # Store the child target of this joint\n                        relationships = {r.GetName(): r for r in child_prim.GetRelationships()}\n                        # Only record if this is NOT a fixed link tying us to the world (i.e.: no target for body0)\n                        if len(relationships[\"physics:body0\"].GetTargets()) &gt; 0:\n                            joint_children.add(relationships[\"physics:body1\"].GetTargets()[0].pathString.split(\"/\")[-1])\n\n            if self._prim_type == PrimType.CLOTH and prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\n                # For cloth object, process prims that belong to any of the GEOM_TYPES (e.g. Cube, Mesh, etc)\n                link = ClothPrim(\n                    prim_path=prim.GetPrimPath().__str__(),\n                    name=f\"{self._name}:{link_name}\",\n                )\n\n            if link is not None:\n                self._links[link_name] = link\n\n        # Infer the correct root link name -- this corresponds to whatever link does not have any joint existing\n        # in the children joints\n        valid_root_links = list(set(self._links.keys()) - joint_children)\n\n        # TODO: Uncomment safety check here after we figure out how to handle legacy multi-bodied assets like bed with pillow\n        # assert len(valid_root_links) == 1, f\"Only a single root link should have been found for this entity prim, \" \\\n        #                                    f\"but found multiple instead: {valid_root_links}\"\n        self._root_link_name = valid_root_links[0] if len(valid_root_links) == 1 else \"base_link\"\n\n    def update_joints(self):\n        \"\"\"\n        Helper function to refresh owned joints. Useful for synchronizing internal data if\n        additional bodies are added manually\n        \"\"\"\n        # Make sure to clean up all pre-existing names for all joints\n        if self._joints is not None:\n            for joint in self._joints.values():\n                joint.remove_names()\n\n        # Initialize joints dictionary\n        self._joints = OrderedDict()\n        self.update_handles()\n\n        # Handle case separately based on whether the handle is valid (i.e.: whether we are actually articulated or not)\n        if self._handle != _dynamic_control.INVALID_HANDLE:\n            root_prim = get_prim_at_path(self._dc.get_rigid_body_path(self._root_handle))\n            n_dof = self._dc.get_articulation_dof_count(self._handle)\n\n            # Additionally grab DOF info if we have non-fixed joints\n            if n_dof &gt; 0:\n                self._dofs_infos = OrderedDict()\n                # Grab DOF info\n                for index in range(n_dof):\n                    dof_handle = self._dc.get_articulation_dof(self._handle, index)\n                    dof_name = self._dc.get_dof_name(dof_handle)\n                    # add dof to list\n                    prim_path = self._dc.get_dof_path(dof_handle)\n                    self._dofs_infos[dof_name] = DOFInfo(prim_path=prim_path, handle=dof_handle, prim=self.prim,\n                                                         index=index)\n\n                for i in range(self._dc.get_articulation_joint_count(self._handle)):\n                    joint_handle = self._dc.get_articulation_joint(self._handle, i)\n                    joint_name = self._dc.get_joint_name(joint_handle)\n                    joint_path = self._dc.get_joint_path(joint_handle)\n                    joint_prim = get_prim_at_path(joint_path)\n                    # Only add the joint if it's not fixed (i.e.: it has DOFs &gt; 0)\n                    if self._dc.get_joint_dof_count(joint_handle) &gt; 0:\n                        joint = JointPrim(\n                            prim_path=joint_path,\n                            name=f\"{self._name}:joint_{joint_name}\",\n                            articulation=self._handle,\n                        )\n                        joint.initialize()\n                        self._joints[joint_name] = joint\n        else:\n            # TODO: May need to extend to clusters of rigid bodies, that aren't exactly joined\n            # We assume this object contains a single rigid body\n            body_path = f\"{self._prim_path}/{self.root_link_name}\"\n            root_prim = get_prim_at_path(body_path)\n            n_dof = 0\n\n        # Make sure root prim stored is the same as the one found during initialization\n        assert self.root_prim == root_prim, \\\n            f\"Mismatch in root prims! Original was {self.root_prim.GetPrimPath()}, \" \\\n            f\"initialized is {root_prim.GetPrimPath()}!\"\n\n        # Store values internally\n        self._n_dof = n_dof\n\n    @property\n    def prim_type(self):\n        \"\"\"\n        Returns:\n            str: Type of this entity prim, one of omnigibson.utils.constants.PrimType\n        \"\"\"\n        return self._prim_type\n\n    @property\n    def articulated(self):\n        \"\"\"\n        Returns:\n             bool: Whether this prim is articulated or not\n        \"\"\"\n        # An invalid handle implies that there is no articulation available for this object\n        return self._handle != _dynamic_control.INVALID_HANDLE and self.n_joints &gt; 0\n\n    @property\n    def articulation_root_path(self):\n        \"\"\"\n        Returns:\n            str: Absolute USD path to the expected prim that represents the articulation root, if it exists. By default,\n                this corresponds to self.prim_path\n        \"\"\"\n        return self._prim_path\n\n    def assert_articulated(self):\n        \"\"\"\n        Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended\n        behavior (e.g.: trying to grab this joint's state if it's not articulated)\n        \"\"\"\n        assert self.articulated, \"Tried to call method not intended for non-articulated entity prim!\"\n\n    @property\n    def root_link_name(self):\n        \"\"\"\n        Returns:\n            str: Name of this entity's root link\n        \"\"\"\n        return self._root_link_name\n\n    @property\n    def root_link(self):\n        \"\"\"\n        Returns:\n            RigidPrim: Root link of this object prim\n        \"\"\"\n        return self._links[self.root_link_name]\n\n    @property\n    def root_prim(self):\n        \"\"\"\n        Returns:\n            UsdPrim: Root prim object associated with the root link of this object prim\n        \"\"\"\n        # The root prim belongs to the link with name root_link_name\n        return self._links[self.root_link_name].prim\n\n    @property\n    def handle(self):\n        \"\"\"\n        Returns:\n            int: ID (articulation) handle assigned to this prim from dynamic_control interface. Note that\n                if this prim is not an articulation, it is assigned _dynamic_control.INVALID_HANDLE\n        \"\"\"\n        return self._handle\n\n    @property\n    def root_handle(self):\n        \"\"\"\n        Handle used by Isaac Sim's dynamic control module to reference the root body in this object.\n        Note: while self.handle may be 0 (i.e.: invalid articulation, i.e.: object with no joints), root_handle should\n            always be non-zero (i.e.: valid) if this object is initialized!\n\n        Returns:\n            int: ID handle assigned to this prim's root prim from dynamic_control interface\n        \"\"\"\n        return self._root_handle\n\n    @property\n    def n_dof(self):\n        \"\"\"\n        Returns:\n            int: number of DoFs of the object\n        \"\"\"\n        return self._n_dof\n\n    @property\n    def n_joints(self):\n        \"\"\"\n        Returns:\n            int: Number of joints owned by this articulation\n        \"\"\"\n        return len(list(self._joints.keys()))\n\n    @property\n    def n_links(self):\n        \"\"\"\n        Returns:\n            int: Number of links owned by this articulation\n        \"\"\"\n        return len(list(self._links.keys()))\n\n    @property\n    def joints(self):\n        \"\"\"\n        Returns:\n            OrderedDict: Dictionary mapping joint names (str) to joint prims (JointPrim) owned by this articulation\n        \"\"\"\n        return self._joints\n\n    @property\n    def links(self):\n        \"\"\"\n        Returns:\n            OrderedDict: Dictionary mapping link names (str) to link prims (RigidPrim) owned by this articulation\n        \"\"\"\n        return self._links\n\n    @property\n    def materials(self):\n        \"\"\"\n        Loop through each link and their visual meshes to gather all the materials that belong to this object\n\n        Returns:\n            materials: a list of MaterialPrim that belongs to this object\n        \"\"\"\n        materials = set()\n        material_paths = set()\n        for link in self._links.values():\n            xforms = [link] + list(link.visual_meshes.values()) if self.prim_type == PrimType.RIGID else [link]\n            for xform in xforms:\n                if xform.has_material():\n                    mat_path = xform.material.prim_path\n                    if mat_path not in material_paths:\n                        materials.add(xform.material)\n        return materials\n\n    @property\n    def dof_properties(self):\n        \"\"\"\n        Returns:\n            n-array: Array of DOF properties assigned to this articulation's DoFs.\n        \"\"\"\n        return self._dc.get_articulation_dof_properties(self._handle)\n\n    @property\n    def visual_only(self):\n        \"\"\"\n        Returns:\n            bool: Whether this link is a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\n        return self._visual_only\n\n    @visual_only.setter\n    def visual_only(self, val):\n        \"\"\"\n        Sets the visaul only state of this link\n\n        Args:\n            val (bool): Whether this link should be a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\n        # Iterate over all owned links and set their respective visual-only properties accordingly\n        for link in self._links.values():\n            link.visual_only = val\n\n        # Also set the internal value\n        self._visual_only = val\n\n    def contact_list(self):\n        \"\"\"\n        Get list of all current contacts with this object prim\n\n        Returns:\n            list of CsRawData: raw contact info for this rigid body\n        \"\"\"\n        contacts = []\n        for link in self._links.values():\n            contacts += link.contact_list()\n        return contacts\n\n    def in_contact_links(self):\n        \"\"\"\n        Get set of unique rigid body prim paths that this object prim is in contact with\n\n        Returns:\n            set: Unique rigid body prim paths that this body is in contact with\n        \"\"\"\n        contact_list = self.contact_list()\n        link_paths = {link.prim_path for link in self._links.values()}\n        body0_contacts = {c.body0 for c in contact_list if c.body0 not in link_paths}\n        body1_contacts = {c.body1 for c in contact_list if c.body1 not in link_paths}\n        return body0_contacts.union(body1_contacts)\n\n    def in_contact(self, prims=None):\n        \"\"\"\n        Returns whether this entity is in contact with any prim(s) @prims. If no @prims is specified,\n        then this will check for any contact.\n\n        NOTE: If checking for self-collisions, set prims=self\n\n        Args:\n            prims (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) to check for collision.\n            If None, will check against all objects currently in the scene.\n\n        Returns:\n            bool: Whether this object is in contact with the specified prim(s)\n        \"\"\"\n        return check_collision(prims=self, prims_check=prims, step_physics=False)\n\n    def enable_gravity(self) -&gt; None:\n        \"\"\"\n        Enables gravity for this entity\n        \"\"\"\n        for link in self._links.values():\n            link.enable_gravity()\n\n    def disable_gravity(self) -&gt; None:\n        \"\"\"\n        Disables gravity for this entity\n        \"\"\"\n        for link in self._links.values():\n            link.disable_gravity()\n\n    def set_joint_positions(self, positions, indices=None, normalized=False, target=False):\n        \"\"\"\n        Set the joint positions (both actual value and target values) in simulation. Note: only works if the simulator\n        is actively running!\n\n        Args:\n            positions (np.ndarray): positions to set. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @positions must\n                be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF positions to set.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool): Whether the inputted joint positions should be interpreted as normalized values. Default\n                is False\n            target (bool): Whether the positions being set are target values or manual values to immediately set.\n                Default is False, corresponding to an instantaneous setting of the positions\n        \"\"\"\n        # Run sanity checks -- make sure our handle is initialized and that we are articulated\n        assert self._handle is not None, \"handles are not initialized yet!\"\n        self.assert_articulated()\n\n        # Possibly de-normalize the inputs\n        if normalized:\n            positions = self._denormalize_positions(positions=positions, indices=indices)\n\n        # Grab current DOF states\n        dof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)\n\n        # Possibly set specific values in the array if indies are specified\n        if indices is None:\n            assert len(positions) == self._n_dof, \\\n                \"set_joint_positions called without specifying indices, but the desired positions do not match n_dof.\"\n            new_positions = positions\n        else:\n            new_positions = dof_states[\"pos\"]\n            new_positions[indices] = positions\n\n        # Set the DOF states\n        dof_states[\"pos\"] = new_positions\n        if not target:\n            self._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_POS)\n\n        # Also set the target\n        self._dc.set_articulation_dof_position_targets(self._handle, new_positions.astype(np.float32))\n\n    def set_joint_velocities(self, velocities, indices=None, normalized=False, target=False):\n        \"\"\"\n        Set the joint velocities (both actual value and target values) in simulation. Note: only works if the simulator\n        is actively running!\n\n        Args:\n            velocities (np.ndarray): velocities to set. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @velocities must\n                be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF velocities to set.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool): Whether the inputted joint velocities should be interpreted as normalized values. Default\n                is False\n            target (bool): Whether the velocities being set are target values or manual values to immediately set.\n                Default is False, corresponding to an instantaneous setting of the velocities\n        \"\"\"\n        # Run sanity checks -- make sure our handle is initialized and that we are articulated\n        assert self._handle is not None, \"handles are not initialized yet!\"\n        self.assert_articulated()\n\n        # Possibly de-normalize the inputs\n        if normalized:\n            velocities = self._denormalize_velocities(velocities=velocities, indices=indices)\n\n        # Grab current DOF states\n        dof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)\n\n        # Possibly set specific values in the array if indies are specified\n        if indices is None:\n            new_velocities = velocities\n        else:\n            new_velocities = dof_states[\"vel\"]\n            new_velocities[indices] = velocities\n\n        # Set the DOF states\n        dof_states[\"vel\"] = new_velocities\n        if not target:\n            self._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_VEL)\n\n        # Also set the target\n        self._dc.set_articulation_dof_velocity_targets(self._handle, new_velocities.astype(np.float32))\n\n    def set_joint_efforts(self, efforts, indices=None, normalized=False):\n        \"\"\"\n        Set the joint efforts (both actual value and target values) in simulation. Note: only works if the simulator\n        is actively running!\n\n        Args:\n            efforts (np.ndarray): efforts to set. This should be n-DOF length if all joints are being set,\n                or k-length (k &lt; n) if specific indices are being set. In this case, the length of @efforts must\n                be the same length as @indices!\n            indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF efforts to set.\n                Default is None, which assumes that all joints are being set.\n            normalized (bool): Whether the inputted joint efforts should be interpreted as normalized values. Default\n                is False\n        \"\"\"\n        # Run sanity checks -- make sure our handle is initialized and that we are articulated\n        assert self._handle is not None, \"handles are not initialized yet!\"\n        self.assert_articulated()\n\n        # Possibly de-normalize the inputs\n        if normalized:\n            efforts = self._denormalize_efforts(efforts=efforts, indices=indices)\n\n        # Grab current DOF states\n        dof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)\n\n        # Possibly set specific values in the array if indies are specified\n        if indices is None:\n            new_efforts = efforts\n        else:\n            new_efforts = dof_states[\"effort\"]\n            new_efforts[indices] = efforts\n\n        # Set the DOF states\n        dof_states[\"effort\"] = new_efforts\n        self._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_EFFORT)\n\n    def _normalize_positions(self, positions, indices=None):\n        \"\"\"\n        Normalizes raw joint positions @positions\n\n        Args:\n            positions (n- or k-array): n-DOF raw positions to normalize, or k (k &lt; n) specific positions to normalize.\n                In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                positions to normalize. Default is None, which assumes the positions correspond to all DOF being\n                normalized.\n\n        Returns:\n            n- or k-array: normalized positions in range [-1, 1] for the specified DOFs\n        \"\"\"\n        low, high = self.joint_lower_limits, self.joint_upper_limits\n        mean = (low + high) / 2.0\n        magnitude = (high - low) / 2.0\n        return (positions - mean) / magnitude if indices is None else (positions - mean[indices]) / magnitude[indices]\n\n    def _denormalize_positions(self, positions, indices=None):\n        \"\"\"\n        De-normalizes joint positions @positions\n\n        Args:\n            positions (n- or k-array): n-DOF normalized positions or k (k &lt; n) specific positions in range [-1, 1]\n                to de-normalize. In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                positions to de-normalize. Default is None, which assumes the positions correspond to all DOF being\n                de-normalized.\n\n        Returns:\n            n- or k-array: de-normalized positions for the specified DOFs\n        \"\"\"\n        low, high = self.joint_lower_limits, self.joint_upper_limits\n        mean = (low + high) / 2.0\n        magnitude = (high - low) / 2.0\n        return positions * magnitude + mean if indices is None else positions * magnitude[indices] + mean[indices]\n\n    def _normalize_velocities(self, velocities, indices=None):\n        \"\"\"\n        Normalizes raw joint velocities @velocities\n\n        Args:\n            velocities (n- or k-array): n-DOF raw velocities to normalize, or k (k &lt; n) specific velocities to normalize.\n                In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                velocities to normalize. Default is None, which assumes the velocities correspond to all DOF being\n                normalized.\n\n        Returns:\n            n- or k-array: normalized velocities in range [-1, 1] for the specified DOFs\n        \"\"\"\n        return velocities / self.max_joint_velocities if indices is None else \\\n            velocities / self.max_joint_velocities[indices]\n\n    def _denormalize_velocities(self, velocities, indices=None):\n        \"\"\"\n        De-normalizes joint velocities @velocities\n\n        Args:\n            velocities (n- or k-array): n-DOF normalized velocities or k (k &lt; n) specific velocities in range [-1, 1]\n                to de-normalize. In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                velocities to de-normalize. Default is None, which assumes the velocities correspond to all DOF being\n                de-normalized.\n\n        Returns:\n            n- or k-array: de-normalized velocities for the specified DOFs\n        \"\"\"\n        return velocities * self.max_joint_velocities if indices is None else \\\n            velocities * self.max_joint_velocities[indices]\n\n    def _normalize_efforts(self, efforts, indices=None):\n        \"\"\"\n        Normalizes raw joint efforts @efforts\n\n        Args:\n            efforts (n- or k-array): n-DOF raw efforts to normalize, or k (k &lt; n) specific efforts to normalize.\n                In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                efforts to normalize. Default is None, which assumes the efforts correspond to all DOF being\n                normalized.\n\n        Returns:\n            n- or k-array: normalized efforts in range [-1, 1] for the specified DOFs\n        \"\"\"\n        return efforts / self.max_joint_efforts if indices is None else efforts / self.max_joint_efforts[indices]\n\n    def _denormalize_efforts(self, efforts, indices=None):\n        \"\"\"\n        De-normalizes joint efforts @efforts\n\n        Args:\n            efforts (n- or k-array): n-DOF normalized efforts or k (k &lt; n) specific efforts in range [-1, 1]\n                to de-normalize. In the latter case, @indices should be specified\n            indices (None or k-array): If specified, should be k (k &lt; n) DOF indices corresponding to the specific\n                efforts to de-normalize. Default is None, which assumes the efforts correspond to all DOF being\n                de-normalized.\n\n        Returns:\n            n- or k-array: de-normalized efforts for the specified DOFs\n        \"\"\"\n        return efforts * self.max_joint_efforts if indices is None else efforts * self.max_joint_efforts[indices]\n\n    def update_handles(self):\n        \"\"\"\n        Updates all internal handles for this prim, in case they change since initialization\n        \"\"\"\n        self._handle = self._dc.get_articulation(self.articulation_root_path)\n        self._root_handle = self._dc.get_articulation_root_body(self._handle) if \\\n            self._handle != _dynamic_control.INVALID_HANDLE else self._dc.get_rigid_body(f\"{self._prim_path}/{self.root_link_name}\")\n\n        # Update all links and joints as well\n        for link in self._links.values():\n            if not link.initialized:\n                link.initialize()\n            link.update_handles()\n\n        for joint in self._joints.values():\n            if not joint.initialized:\n                joint.initialize()\n            joint.update_handles()\n\n    def get_joint_positions(self, normalized=False):\n        \"\"\"\n        Grabs this entity's joint positions\n\n        Args:\n            normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n\n        Returns:\n            n-array: n-DOF length array of positions\n        \"\"\"\n        # Run sanity checks -- make sure our handle is initialized and that we are articulated\n        assert self._handle is not None, \"handles are not initialized yet!\"\n        self.assert_articulated()\n\n        joint_positions = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)[\"pos\"]\n\n        # Possibly normalize values when returning\n        return self._normalize_positions(positions=joint_positions) if normalized else joint_positions\n\n    def get_joint_velocities(self, normalized=False):\n        \"\"\"\n        Grabs this entity's joint velocities\n\n        Args:\n            normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n\n        Returns:\n            n-array: n-DOF length array of velocities\n        \"\"\"\n        # Run sanity checks -- make sure our handle is initialized and that we are articulated\n        assert self._handle is not None, \"handles are not initialized yet!\"\n        self.assert_articulated()\n\n        joint_velocities = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)[\"vel\"]\n\n        # Possibly normalize values when returning\n        return self._normalize_velocities(velocities=joint_velocities) if normalized else joint_velocities\n\n    def get_joint_efforts(self, normalized=False):\n        \"\"\"\n        Grabs this entity's joint efforts\n\n        Args:\n            normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n\n        Returns:\n            n-array: n-DOF length array of efforts\n        \"\"\"\n        # Run sanity checks -- make sure our handle is initialized and that we are articulated\n        assert self._handle is not None, \"handles are not initialized yet!\"\n        self.assert_articulated()\n\n        joint_efforts = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)[\"effort\"]\n\n        # Possibly normalize values when returning\n        return self._normalize_efforts(efforts=joint_efforts) if normalized else joint_efforts\n\n    def set_linear_velocity(self, velocity: np.ndarray):\n        \"\"\"\n        Sets the linear velocity of the root prim in stage.\n\n        Args:\n            velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\n        self.root_link.set_linear_velocity(velocity)\n\n    def get_linear_velocity(self):\n        \"\"\"\n        Gets the linear velocity of the root prim in stage.\n\n        Returns:\n            velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\n        return self.root_link.get_linear_velocity()\n\n    def set_angular_velocity(self, velocity):\n        \"\"\"\n        Sets the angular velocity of the root prim in stage.\n\n        Args:\n            velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\n        self.root_link.set_angular_velocity(velocity)\n\n    def get_angular_velocity(self):\n        \"\"\"Gets the angular velocity of the root prim in stage.\n\n        Returns:\n            velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n        \"\"\"\n        return self.root_link.get_angular_velocity()\n\n    def set_position_orientation(self, position=None, orientation=None):\n        current_position, current_orientation = self.get_position_orientation()\n        if position is None:\n            position = current_position\n        if orientation is None:\n            orientation = current_orientation\n\n        if self._prim_type == PrimType.CLOTH:\n            # Can only set position\n            if self._dc is not None and self._dc.is_simulating():\n                # Assume there is only one base link (the cloth)\n                self.root_link.set_position_orientation(position, orientation)\n            else:\n                super().set_position_orientation(position, orientation)\n        else:\n            if self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\n                pose = _dynamic_control.Transform(position, orientation)\n                self._dc.set_rigid_body_pose(self._root_handle, pose)\n            else:\n                super().set_position_orientation(position=position, orientation=orientation)\n\n    def get_position_orientation(self):\n        if self._prim_type == PrimType.CLOTH:\n            if self._dc is not None and self._dc.is_simulating():\n                return self.root_link.get_position_orientation()\n            else:\n                return super().get_position_orientation()\n        else:\n            if self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\n                pose = self._dc.get_rigid_body_pose(self._root_handle)\n                return np.asarray(pose.p), np.asarray(pose.r)\n            else:\n                return super().get_position_orientation()\n\n    def _set_local_pose_when_simulating(self, translation=None, orientation=None):\n        \"\"\"\n        Sets prim's pose with respect to the local frame (the prim's parent frame) when simulation is running.\n\n        Args:\n            translation (None or 3-array): if specified, (x,y,z) translation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n            orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n        \"\"\"\n        current_translation, current_orientation = self.get_local_pose()\n        if translation is None:\n            translation = current_translation\n        if orientation is None:\n            orientation = current_orientation\n        orientation = orientation[[3, 0, 1, 2]]\n        local_transform = tf_matrix_from_pose(translation=translation, orientation=orientation)\n        parent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\n            Usd.TimeCode.Default()\n        )\n        my_world_transform = np.matmul(parent_world_tf, local_transform)\n        transform = Gf.Transform()\n        transform.SetMatrix(Gf.Matrix4d(np.transpose(my_world_transform)))\n        calculated_position = transform.GetTranslation()\n        calculated_orientation = transform.GetRotation().GetQuat()\n        self.set_position_orientation(\n            position=np.array(calculated_position),\n            orientation=gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]],\n        )\n\n    def set_local_pose(self, translation=None, orientation=None):\n        if self._prim_type == PrimType.CLOTH:\n            if self._dc is not None and self._dc.is_simulating():\n                self._set_local_pose_when_simulating(translation=translation, orientation=orientation)\n            else:\n                super().set_local_pose(translation=translation, orientation=orientation)\n        else:\n            if self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\n                self._set_local_pose_when_simulating(translation=translation, orientation=orientation)\n            else:\n                super().set_local_pose(translation=translation, orientation=orientation)\n\n    def _get_local_pose_when_simulating(self):\n        \"\"\"\n        Gets prim's pose with respect to the prim's local frame (it's parent frame) when simulation is running\n\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) position in the local frame\n                - 4-array: (x,y,z,w) quaternion orientation in the local frame\n        \"\"\"\n        parent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\n            Usd.TimeCode.Default()\n        )\n        world_position, world_orientation = self.get_position_orientation()\n        my_world_transform = tf_matrix_from_pose(translation=world_position,\n                                                 orientation=world_orientation[[3, 0, 1, 2]])\n        local_transform = np.matmul(np.linalg.inv(np.transpose(parent_world_tf)), my_world_transform)\n        transform = Gf.Transform()\n        transform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\n        calculated_translation = transform.GetTranslation()\n        calculated_orientation = transform.GetRotation().GetQuat()\n        return np.array(calculated_translation), gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]]\n\n    def get_local_pose(self):\n        if self._prim_type == PrimType.CLOTH:\n            if self._dc is not None and self._dc.is_simulating():\n                return self._get_local_pose_when_simulating()\n            else:\n                return super().get_local_pose()\n        else:\n            if self._root_handle is not None and self._root_handle != _dynamic_control.INVALID_HANDLE and \\\n                    self._dc is not None and self._dc.is_simulating():\n                return self._get_local_pose_when_simulating()\n            else:\n                return super().get_local_pose()\n\n    # TODO: Is the omni joint damping (used for driving motors) same as dissipative joint damping (what we had in pb)?\n    @property\n    def joint_damping(self):\n        \"\"\"\n        Returns:\n            n-array: joint damping values for this prim\n        \"\"\"\n        return np.concatenate([joint.damping for joint in self._joints.values()])\n\n    @property\n    def joint_lower_limits(self):\n        \"\"\"\n        Returns:\n            n-array: minimum values for this robot's joints. If joint does not have a range, returns -1000\n                for that joint\n        \"\"\"\n        return np.array([joint.lower_limit for joint in self._joints.values()])\n\n    @property\n    def joint_upper_limits(self):\n        \"\"\"\n        Returns:\n            n-array: maximum values for this robot's joints. If joint does not have a range, returns 1000\n                for that joint\n        \"\"\"\n        return np.array([joint.upper_limit for joint in self._joints.values()])\n\n    @property\n    def joint_range(self):\n        \"\"\"\n        Returns:\n            n-array: joint range values for this robot's joints\n        \"\"\"\n        return self.joint_upper_limits - self.joint_lower_limits\n\n    @property\n    def max_joint_velocities(self):\n        \"\"\"\n        Returns:\n            n-array: maximum velocities for this robot's joints\n        \"\"\"\n        return np.array([joint.max_velocity for joint in self._joints.values()])\n\n    @property\n    def max_joint_efforts(self):\n        \"\"\"\n        Returns:\n            n-array: maximum efforts for this robot's joints\n        \"\"\"\n        return np.array([joint.max_force for joint in self._joints.values()])\n\n    @property\n    def joint_position_limits(self):\n        \"\"\"\n        Returns:\n            2-tuple:\n                - n-array: min joint position limits, where each is an n-DOF length array\n                - n-array: max joint position limits, where each is an n-DOF length array\n        \"\"\"\n        return self.joint_lower_limits, self.joint_upper_limits\n\n    @property\n    def joint_velocity_limits(self):\n        \"\"\"\n        Returns:\n            2-tuple:\n                - n-array: min joint velocity limits, where each is an n-DOF length array\n                - n-array: max joint velocity limits, where each is an n-DOF length array\n        \"\"\"\n        return -self.max_joint_velocities, self.max_joint_velocities\n\n    @property\n    def joint_effort_limits(self):\n        \"\"\"\n        Returns:\n            2-tuple:\n                - n-array: min joint effort limits, where each is an n-DOF length array\n                - n-array: max joint effort limits, where each is an n-DOF length array\n        \"\"\"\n        return -self.max_joint_efforts, self.max_joint_efforts\n\n    @property\n    def joint_at_limits(self):\n        \"\"\"\n        Returns:\n            n-array: n-DOF length array specifying whether joint is at its limit,\n                with 1.0 --&gt; at limit, otherwise 0.0\n        \"\"\"\n        return 1.0 * (np.abs(self.get_joint_positions(normalized=True)) &gt; 0.99)\n\n    @property\n    def joint_has_limits(self):\n        \"\"\"\n        Returns:\n            n-array: n-DOF length array specifying whether joint has a limit or not\n        \"\"\"\n        return np.array([j.has_limit for j in self._joints.values()])\n\n    @property\n    def disabled_collision_pairs(self):\n        \"\"\"\n        Returns:\n            list of (str, str): List of rigid body collision pairs to disable within this object prim.\n                Default is an empty list (no pairs)\n        \"\"\"\n        return []\n\n    @property\n    def scale(self):\n        # Since all rigid bodies owned by this object prim have the same scale, we simply grab it from the root prim\n        return self.root_link.scale\n\n    @scale.setter\n    def scale(self, scale):\n        # We iterate over all rigid bodies owned by this object prim and set their individual scales\n        # We do this because omniverse cannot scale orientation of an articulated prim, so we get mesh mismatches as\n        # they rotate in the world\n        for link in self._links.values():\n            link.scale = scale\n\n    @property\n    def solver_position_iteration_count(self):\n        \"\"\"\n        Returns:\n            int: How many position iterations to take per physics step by the physx solver\n        \"\"\"\n        return get_prim_property(self.articulation_root_path, \"physxArticulation:solverPositionIterationCount\")\n\n    @solver_position_iteration_count.setter\n    def solver_position_iteration_count(self, count):\n        \"\"\"\n        Sets how many position iterations to take per physics step by the physx solver\n\n        Args:\n            count (int): How many position iterations to take per physics step by the physx solver\n        \"\"\"\n        set_prim_property(self.articulation_root_path, \"physxArticulation:solverPositionIterationCount\", count)\n        return\n\n    @property\n    def solver_velocity_iteration_count(self):\n        \"\"\"\n        Returns:\n            int: How many velocity iterations to take per physics step by the physx solver\n        \"\"\"\n        return get_prim_property(self.articulation_root_path, \"physxArticulation:solverVelocityIterationCount\")\n\n    @solver_velocity_iteration_count.setter\n    def solver_velocity_iteration_count(self, count):\n        \"\"\"\n        Sets how many velocity iterations to take per physics step by the physx solver\n\n        Args:\n            count (int): How many velocity iterations to take per physics step by the physx solver\n        \"\"\"\n        set_prim_property(self.articulation_root_path, \"physxArticulation:solverVelocityIterationCount\", count)\n        return\n\n    @property\n    def stabilization_threshold(self):\n        \"\"\"\n        Returns:\n            float: threshold for stabilizing this articulation\n        \"\"\"\n        return get_prim_property(self.articulation_root_path, \"physxArticulation:stabilizationThreshold\")\n\n    @stabilization_threshold.setter\n    def stabilization_threshold(self, threshold):\n        \"\"\"\n        Sets threshold for stabilizing this articulation\n\n        Args:\n            threshold (float): Stabilization threshold\n        \"\"\"\n        set_prim_property(self.articulation_root_path, \"physxArticulation:stabilizationThreshold\", threshold)\n        return\n\n    @property\n    def self_collisions(self):\n        \"\"\"\n        Returns:\n            bool: Whether self-collisions are enabled for this prim or not\n        \"\"\"\n        return get_prim_property(self.articulation_root_path, \"physxArticulation:enabledSelfCollisions\")\n\n    @self_collisions.setter\n    def self_collisions(self, flag):\n        \"\"\"\n        Sets whether self-collisions are enabled for this prim or not\n\n        Args:\n            flag (bool): Whether self collisions are enabled for this prim or not\n        \"\"\"\n        set_prim_property(self.articulation_root_path, \"physxArticulation:enabledSelfCollisions\", flag)\n        return\n\n    @property\n    def sleep_threshold(self):\n        \"\"\"\n        Returns:\n            float: threshold for sleeping this articulation\n        \"\"\"\n        return get_prim_property(self.articulation_root_path, \"physxArticulation:sleepThreshold\")\n\n    @sleep_threshold.setter\n    def sleep_threshold(self, threshold):\n        \"\"\"\n        Sets threshold for sleeping this articulation\n\n        Args:\n            threshold (float): Sleeping threshold\n        \"\"\"\n        set_prim_property(self.articulation_root_path, \"physxArticulation:sleepThreshold\", threshold)\n        return\n\n    def wake(self):\n        \"\"\"\n        Enable physics for this articulation\n        \"\"\"\n        if self.articulated:\n            self._dc.wake_up_articulation(self._handle)\n        else:\n            for link in self._links.values():\n                link.wake()\n\n    def sleep(self):\n        \"\"\"\n        Disable physics for this articulation\n        \"\"\"\n        if self.articulated:\n            self._dc.sleep_articulation(self._handle)\n        else:\n            for link in self._links.values():\n                link.sleep()\n\n    def keep_still(self):\n        \"\"\"\n        Zero out all velocities for this prim\n        \"\"\"\n        self.set_linear_velocity(velocity=np.zeros(3))\n        self.set_angular_velocity(velocity=np.zeros(3))\n        for joint in self._joints.values():\n            joint.keep_still()\n\n    def create_attachment_point_link(self):\n        \"\"\"\n        Create a collision-free, invisible attachment point link for the cloth object, and create an attachment between\n        the ClothPrim and this attachment point link (RigidPrim).\n\n        One use case for this is that we can create a fixed joint between this link and the world to enable AG fo cloth.\n        During simulation, this joint will move and match the robot gripper frame, which will then drive the cloth.\n        \"\"\"\n\n        assert self._prim_type == PrimType.CLOTH, \"create_attachment_point_link should only be called for Cloth\"\n        link_name = \"attachment_point\"\n        stage = get_current_stage()\n        link_prim = stage.DefinePrim(f\"{self._prim_path}/{link_name}\", \"Xform\")\n        vis_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/visuals\").GetPrim()\n        col_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/collisions\").GetPrim()\n\n        # Set the radius to be 0.03m. In theory, we want this radius to be as small as possible. Otherwise, the cloth\n        # dynamics will be unrealistic. However, in practice, if the radius is too small, the attachment becomes very\n        # unstable. Empirically 0.03m works reasonably well.\n        vis_prim.GetAttribute(\"radius\").Set(0.03)\n        col_prim.GetAttribute(\"radius\").Set(0.03)\n\n        # Need to sync the extents\n        extent = vis_prim.GetAttribute(\"extent\").Get()\n        extent[0] = Gf.Vec3f(-0.03, -0.03, -0.03)\n        extent[1] = Gf.Vec3f(0.03, 0.03, 0.03)\n        vis_prim.GetAttribute(\"extent\").Set(extent)\n        col_prim.GetAttribute(\"extent\").Set(extent)\n\n        # Add collision API to collision geom\n        UsdPhysics.CollisionAPI.Apply(col_prim)\n        UsdPhysics.MeshCollisionAPI.Apply(col_prim)\n        PhysxSchema.PhysxCollisionAPI.Apply(col_prim)\n\n        # Create a attachment point link\n        link = RigidPrim(\n            prim_path=link_prim.GetPrimPath().__str__(),\n            name=f\"{self._name}:{link_name}\",\n        )\n        link.disable_collisions()\n        # TODO (eric): Should we disable gravity for this link?\n        # link.disable_gravity()\n        link.visible = False\n        # Set a very small mass\n        link.mass = 1e-6\n\n        self._links[link_name] = link\n\n        # Create an attachment between the root link (ClothPrim) and the newly created attachment point link (RigidPrim)\n        attachment_path = self.root_link.prim.GetPath().AppendElementString(\"attachment\")\n        omni.kit.commands.execute(\"CreatePhysicsAttachment\", target_attachment_path=attachment_path,\n                                  actor0_path=self.root_link.prim.GetPath(), actor1_path=link.prim.GetPath())\n\n    def _dump_state(self):\n        # We don't call super, instead, this state is simply the root link state and all joint states\n        state = OrderedDict(root_link=self.root_link._dump_state())\n        joint_state = OrderedDict()\n        for prim_name, prim in self._joints.items():\n            joint_state[prim_name] = prim._dump_state()\n        state[\"joints\"] = joint_state\n\n        return state\n\n    def _load_state(self, state):\n        # Load base link state and joint states\n        self.root_link._load_state(state=state[\"root_link\"])\n        for joint_name, joint_state in state[\"joints\"].items():\n            self._joints[joint_name]._load_state(state=joint_state)\n\n    def _serialize(self, state):\n        # We serialize by first flattening the root link state and then iterating over all joints and\n        # adding them to the a flattened array\n        state_flat = [self.root_link.serialize(state=state[\"root_link\"])]\n        if self.n_joints &gt; 0:\n            state_flat.append(\n                np.concatenate(\n                    [prim.serialize(state=state[\"joints\"][prim_name]) for prim_name, prim in self._joints.items()]\n                )\n            )\n\n        return np.concatenate(state_flat).astype(float)\n\n    def _deserialize(self, state):\n        # We deserialize by first de-flattening the root link state and then iterating over all joints and\n        # sequentially grabbing from the flattened state array, incrementing along the way\n        idx = self.root_link.state_size\n        state_dict = OrderedDict(root_link=self.root_link.deserialize(state=state[:idx]))\n        joint_state_dict = OrderedDict()\n        for prim_name, prim in self._joints.items():\n            joint_state_dict[prim_name] = prim.deserialize(state=state[idx:idx+prim.state_size])\n            idx += prim.state_size\n        state_dict[\"joints\"] = joint_state_dict\n\n        return state_dict, idx\n\n    def _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n        # Subclass must implement this method for duplication functionality\n        raise NotImplementedError(\"Subclass must implement _create_prim_with_same_kwargs() to enable duplication \"\n                                  \"functionality for EntityPrim!\")\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim"},{"title":"<code>articulated</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this prim is articulated or not</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.articulated"},{"title":"<code>articulation_root_path</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Absolute USD path to the expected prim that represents the articulation root, if it exists. By default, this corresponds to self.prim_path</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.articulation_root_path"},{"title":"<code>disabled_collision_pairs</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>list of (str, str): List of rigid body collision pairs to disable within this object prim. Default is an empty list (no pairs)</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.disabled_collision_pairs"},{"title":"<code>dof_properties</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Array of DOF properties assigned to this articulation's DoFs.</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.dof_properties"},{"title":"<code>handle</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>ID (articulation) handle assigned to this prim from dynamic_control interface. Note that if this prim is not an articulation, it is assigned _dynamic_control.INVALID_HANDLE</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.handle"},{"title":"<code>joint_at_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: n-DOF length array specifying whether joint is at its limit, with 1.0 --&gt; at limit, otherwise 0.0</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_at_limits"},{"title":"<code>joint_damping</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: joint damping values for this prim</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_damping"},{"title":"<code>joint_effort_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-tuple: - n-array: min joint effort limits, where each is an n-DOF length array - n-array: max joint effort limits, where each is an n-DOF length array</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_effort_limits"},{"title":"<code>joint_has_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: n-DOF length array specifying whether joint has a limit or not</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_has_limits"},{"title":"<code>joint_lower_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: minimum values for this robot's joints. If joint does not have a range, returns -1000 for that joint</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_lower_limits"},{"title":"<code>joint_position_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-tuple: - n-array: min joint position limits, where each is an n-DOF length array - n-array: max joint position limits, where each is an n-DOF length array</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_position_limits"},{"title":"<code>joint_range</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: joint range values for this robot's joints</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_range"},{"title":"<code>joint_upper_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: maximum values for this robot's joints. If joint does not have a range, returns 1000 for that joint</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_upper_limits"},{"title":"<code>joint_velocity_limits</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-tuple: - n-array: min joint velocity limits, where each is an n-DOF length array - n-array: max joint velocity limits, where each is an n-DOF length array</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joint_velocity_limits"},{"title":"<code>joints</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Dictionary mapping joint names (str) to joint prims (JointPrim) owned by this articulation</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.joints"},{"title":"<code>links</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Dictionary mapping link names (str) to link prims (RigidPrim) owned by this articulation</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.links"},{"title":"<code>materials</code>  <code>property</code>","text":"<p>Loop through each link and their visual meshes to gather all the materials that belong to this object</p> <p>Returns:</p>    Name Type Description     <code>materials</code>   <p>a list of MaterialPrim that belongs to this object</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.materials"},{"title":"<code>max_joint_efforts</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: maximum efforts for this robot's joints</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.max_joint_efforts"},{"title":"<code>max_joint_velocities</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: maximum velocities for this robot's joints</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.max_joint_velocities"},{"title":"<code>n_dof</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>number of DoFs of the object</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.n_dof"},{"title":"<code>n_joints</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of joints owned by this articulation</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.n_joints"},{"title":"<code>n_links</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of links owned by this articulation</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.n_links"},{"title":"<code>prim_type</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Type of this entity prim, one of omnigibson.utils.constants.PrimType</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.prim_type"},{"title":"<code>root_handle</code>  <code>property</code>","text":"<p>Handle used by Isaac Sim's dynamic control module to reference the root body in this object.</p>  while self.handle may be 0 (i.e.: invalid articulation, i.e.: object with no joints), root_handle should <p>always be non-zero (i.e.: valid) if this object is initialized!</p>  <p>Returns:</p>    Name Type Description     <code>int</code>   <p>ID handle assigned to this prim's root prim from dynamic_control interface</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_handle"},{"title":"<code>root_link</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>RigidPrim</code>   <p>Root link of this object prim</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_link"},{"title":"<code>root_link_name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this entity's root link</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_link_name"},{"title":"<code>root_prim</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>UsdPrim</code>   <p>Root prim object associated with the root link of this object prim</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.root_prim"},{"title":"<code>self_collisions</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether self-collisions are enabled for this prim or not</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.self_collisions"},{"title":"<code>sleep_threshold</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>threshold for sleeping this articulation</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.sleep_threshold"},{"title":"<code>solver_position_iteration_count</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>How many position iterations to take per physics step by the physx solver</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.solver_position_iteration_count"},{"title":"<code>solver_velocity_iteration_count</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>How many velocity iterations to take per physics step by the physx solver</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.solver_velocity_iteration_count"},{"title":"<code>stabilization_threshold</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>threshold for stabilizing this articulation</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.stabilization_threshold"},{"title":"<code>visual_only</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this link is a visual-only link (i.e.: no gravity or collisions applied)</p>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.visual_only"},{"title":"<code>assert_articulated()</code>","text":"<p>Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended behavior (e.g.: trying to grab this joint's state if it's not articulated)</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def assert_articulated(self):\n    \"\"\"\n    Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended\n    behavior (e.g.: trying to grab this joint's state if it's not articulated)\n    \"\"\"\n    assert self.articulated, \"Tried to call method not intended for non-articulated entity prim!\"\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.assert_articulated"},{"title":"<code>contact_list()</code>","text":"<p>Get list of all current contacts with this object prim</p> <p>Returns:</p>    Type Description       <p>list of CsRawData: raw contact info for this rigid body</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def contact_list(self):\n    \"\"\"\n    Get list of all current contacts with this object prim\n\n    Returns:\n        list of CsRawData: raw contact info for this rigid body\n    \"\"\"\n    contacts = []\n    for link in self._links.values():\n        contacts += link.contact_list()\n    return contacts\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.contact_list"},{"title":"<code>create_attachment_point_link()</code>","text":"<p>Create a collision-free, invisible attachment point link for the cloth object, and create an attachment between the ClothPrim and this attachment point link (RigidPrim).</p> <p>One use case for this is that we can create a fixed joint between this link and the world to enable AG fo cloth. During simulation, this joint will move and match the robot gripper frame, which will then drive the cloth.</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def create_attachment_point_link(self):\n    \"\"\"\n    Create a collision-free, invisible attachment point link for the cloth object, and create an attachment between\n    the ClothPrim and this attachment point link (RigidPrim).\n\n    One use case for this is that we can create a fixed joint between this link and the world to enable AG fo cloth.\n    During simulation, this joint will move and match the robot gripper frame, which will then drive the cloth.\n    \"\"\"\n\n    assert self._prim_type == PrimType.CLOTH, \"create_attachment_point_link should only be called for Cloth\"\n    link_name = \"attachment_point\"\n    stage = get_current_stage()\n    link_prim = stage.DefinePrim(f\"{self._prim_path}/{link_name}\", \"Xform\")\n    vis_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/visuals\").GetPrim()\n    col_prim = UsdGeom.Sphere.Define(stage, f\"{self._prim_path}/{link_name}/collisions\").GetPrim()\n\n    # Set the radius to be 0.03m. In theory, we want this radius to be as small as possible. Otherwise, the cloth\n    # dynamics will be unrealistic. However, in practice, if the radius is too small, the attachment becomes very\n    # unstable. Empirically 0.03m works reasonably well.\n    vis_prim.GetAttribute(\"radius\").Set(0.03)\n    col_prim.GetAttribute(\"radius\").Set(0.03)\n\n    # Need to sync the extents\n    extent = vis_prim.GetAttribute(\"extent\").Get()\n    extent[0] = Gf.Vec3f(-0.03, -0.03, -0.03)\n    extent[1] = Gf.Vec3f(0.03, 0.03, 0.03)\n    vis_prim.GetAttribute(\"extent\").Set(extent)\n    col_prim.GetAttribute(\"extent\").Set(extent)\n\n    # Add collision API to collision geom\n    UsdPhysics.CollisionAPI.Apply(col_prim)\n    UsdPhysics.MeshCollisionAPI.Apply(col_prim)\n    PhysxSchema.PhysxCollisionAPI.Apply(col_prim)\n\n    # Create a attachment point link\n    link = RigidPrim(\n        prim_path=link_prim.GetPrimPath().__str__(),\n        name=f\"{self._name}:{link_name}\",\n    )\n    link.disable_collisions()\n    # TODO (eric): Should we disable gravity for this link?\n    # link.disable_gravity()\n    link.visible = False\n    # Set a very small mass\n    link.mass = 1e-6\n\n    self._links[link_name] = link\n\n    # Create an attachment between the root link (ClothPrim) and the newly created attachment point link (RigidPrim)\n    attachment_path = self.root_link.prim.GetPath().AppendElementString(\"attachment\")\n    omni.kit.commands.execute(\"CreatePhysicsAttachment\", target_attachment_path=attachment_path,\n                              actor0_path=self.root_link.prim.GetPath(), actor1_path=link.prim.GetPath())\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.create_attachment_point_link"},{"title":"<code>disable_gravity()</code>","text":"<p>Disables gravity for this entity</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def disable_gravity(self) -&gt; None:\n    \"\"\"\n    Disables gravity for this entity\n    \"\"\"\n    for link in self._links.values():\n        link.disable_gravity()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.disable_gravity"},{"title":"<code>enable_gravity()</code>","text":"<p>Enables gravity for this entity</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def enable_gravity(self) -&gt; None:\n    \"\"\"\n    Enables gravity for this entity\n    \"\"\"\n    for link in self._links.values():\n        link.enable_gravity()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.enable_gravity"},{"title":"<code>get_angular_velocity()</code>","text":"<p>Gets the angular velocity of the root prim in stage.</p> <p>Returns:</p>    Name Type Description     <code>velocity</code>  <code>np.ndarray</code>  <p>angular velocity to set the rigid prim to, in the world frame. Shape (3,).</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def get_angular_velocity(self):\n    \"\"\"Gets the angular velocity of the root prim in stage.\n\n    Returns:\n        velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\n    return self.root_link.get_angular_velocity()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_angular_velocity"},{"title":"<code>get_joint_efforts(normalized=False)</code>","text":"<p>Grabs this entity's joint efforts</p> <p>Parameters:</p>    Name Type Description Default     <code>normalized</code>  <code>bool</code>  <p>Whether returned values should be normalized to range [-1, 1] based on limits or not.</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>n-array: n-DOF length array of efforts</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def get_joint_efforts(self, normalized=False):\n    \"\"\"\n    Grabs this entity's joint efforts\n\n    Args:\n        normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n\n    Returns:\n        n-array: n-DOF length array of efforts\n    \"\"\"\n    # Run sanity checks -- make sure our handle is initialized and that we are articulated\n    assert self._handle is not None, \"handles are not initialized yet!\"\n    self.assert_articulated()\n\n    joint_efforts = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)[\"effort\"]\n\n    # Possibly normalize values when returning\n    return self._normalize_efforts(efforts=joint_efforts) if normalized else joint_efforts\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_joint_efforts"},{"title":"<code>get_joint_positions(normalized=False)</code>","text":"<p>Grabs this entity's joint positions</p> <p>Parameters:</p>    Name Type Description Default     <code>normalized</code>  <code>bool</code>  <p>Whether returned values should be normalized to range [-1, 1] based on limits or not.</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>n-array: n-DOF length array of positions</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def get_joint_positions(self, normalized=False):\n    \"\"\"\n    Grabs this entity's joint positions\n\n    Args:\n        normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n\n    Returns:\n        n-array: n-DOF length array of positions\n    \"\"\"\n    # Run sanity checks -- make sure our handle is initialized and that we are articulated\n    assert self._handle is not None, \"handles are not initialized yet!\"\n    self.assert_articulated()\n\n    joint_positions = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)[\"pos\"]\n\n    # Possibly normalize values when returning\n    return self._normalize_positions(positions=joint_positions) if normalized else joint_positions\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_joint_positions"},{"title":"<code>get_joint_velocities(normalized=False)</code>","text":"<p>Grabs this entity's joint velocities</p> <p>Parameters:</p>    Name Type Description Default     <code>normalized</code>  <code>bool</code>  <p>Whether returned values should be normalized to range [-1, 1] based on limits or not.</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>n-array: n-DOF length array of velocities</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def get_joint_velocities(self, normalized=False):\n    \"\"\"\n    Grabs this entity's joint velocities\n\n    Args:\n        normalized (bool): Whether returned values should be normalized to range [-1, 1] based on limits or not.\n\n    Returns:\n        n-array: n-DOF length array of velocities\n    \"\"\"\n    # Run sanity checks -- make sure our handle is initialized and that we are articulated\n    assert self._handle is not None, \"handles are not initialized yet!\"\n    self.assert_articulated()\n\n    joint_velocities = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)[\"vel\"]\n\n    # Possibly normalize values when returning\n    return self._normalize_velocities(velocities=joint_velocities) if normalized else joint_velocities\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_joint_velocities"},{"title":"<code>get_linear_velocity()</code>","text":"<p>Gets the linear velocity of the root prim in stage.</p> <p>Returns:</p>    Name Type Description     <code>velocity</code>  <code>np.ndarray</code>  <p>linear velocity to set the rigid prim to, in the world frame. Shape (3,).</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def get_linear_velocity(self):\n    \"\"\"\n    Gets the linear velocity of the root prim in stage.\n\n    Returns:\n        velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\n    return self.root_link.get_linear_velocity()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.get_linear_velocity"},{"title":"<code>in_contact(prims=None)</code>","text":"<p>Returns whether this entity is in contact with any prim(s) @prims. If no @prims is specified, then this will check for any contact.</p> <p>NOTE: If checking for self-collisions, set prims=self</p> <p>Parameters:</p>    Name Type Description Default     <code>prims</code>  <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>Prim(s) to check for collision.</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this object is in contact with the specified prim(s)</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def in_contact(self, prims=None):\n    \"\"\"\n    Returns whether this entity is in contact with any prim(s) @prims. If no @prims is specified,\n    then this will check for any contact.\n\n    NOTE: If checking for self-collisions, set prims=self\n\n    Args:\n        prims (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) to check for collision.\n        If None, will check against all objects currently in the scene.\n\n    Returns:\n        bool: Whether this object is in contact with the specified prim(s)\n    \"\"\"\n    return check_collision(prims=self, prims_check=prims, step_physics=False)\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.in_contact"},{"title":"<code>in_contact_links()</code>","text":"<p>Get set of unique rigid body prim paths that this object prim is in contact with</p> <p>Returns:</p>    Name Type Description     <code>set</code>   <p>Unique rigid body prim paths that this body is in contact with</p>     Source code in <code>prims/entity_prim.py</code> <pre><code>def in_contact_links(self):\n    \"\"\"\n    Get set of unique rigid body prim paths that this object prim is in contact with\n\n    Returns:\n        set: Unique rigid body prim paths that this body is in contact with\n    \"\"\"\n    contact_list = self.contact_list()\n    link_paths = {link.prim_path for link in self._links.values()}\n    body0_contacts = {c.body0 for c in contact_list if c.body0 not in link_paths}\n    body1_contacts = {c.body1 for c in contact_list if c.body1 not in link_paths}\n    return body0_contacts.union(body1_contacts)\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.in_contact_links"},{"title":"<code>keep_still()</code>","text":"<p>Zero out all velocities for this prim</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def keep_still(self):\n    \"\"\"\n    Zero out all velocities for this prim\n    \"\"\"\n    self.set_linear_velocity(velocity=np.zeros(3))\n    self.set_angular_velocity(velocity=np.zeros(3))\n    for joint in self._joints.values():\n        joint.keep_still()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.keep_still"},{"title":"<code>set_angular_velocity(velocity)</code>","text":"<p>Sets the angular velocity of the root prim in stage.</p> <p>Parameters:</p>    Name Type Description Default     <code>velocity</code>  <code>np.ndarray</code>  <p>angular velocity to set the rigid prim to, in the world frame. Shape (3,).</p>  required      Source code in <code>prims/entity_prim.py</code> <pre><code>def set_angular_velocity(self, velocity):\n    \"\"\"\n    Sets the angular velocity of the root prim in stage.\n\n    Args:\n        velocity (np.ndarray): angular velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\n    self.root_link.set_angular_velocity(velocity)\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_angular_velocity"},{"title":"<code>set_joint_efforts(efforts, indices=None, normalized=False)</code>","text":"<p>Set the joint efforts (both actual value and target values) in simulation. Note: only works if the simulator is actively running!</p> <p>Parameters:</p>    Name Type Description Default     <code>efforts</code>  <code>np.ndarray</code>  <p>efforts to set. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @efforts must be the same length as @indices!</p>  required    <code>indices</code>  <code>None or k-array</code>  <p>If specified, should be k (k &lt; n) length array of specific DOF efforts to set. Default is None, which assumes that all joints are being set.</p>  <code>None</code>    <code>normalized</code>  <code>bool</code>  <p>Whether the inputted joint efforts should be interpreted as normalized values. Default is False</p>  <code>False</code>      Source code in <code>prims/entity_prim.py</code> <pre><code>def set_joint_efforts(self, efforts, indices=None, normalized=False):\n    \"\"\"\n    Set the joint efforts (both actual value and target values) in simulation. Note: only works if the simulator\n    is actively running!\n\n    Args:\n        efforts (np.ndarray): efforts to set. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @efforts must\n            be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF efforts to set.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool): Whether the inputted joint efforts should be interpreted as normalized values. Default\n            is False\n    \"\"\"\n    # Run sanity checks -- make sure our handle is initialized and that we are articulated\n    assert self._handle is not None, \"handles are not initialized yet!\"\n    self.assert_articulated()\n\n    # Possibly de-normalize the inputs\n    if normalized:\n        efforts = self._denormalize_efforts(efforts=efforts, indices=indices)\n\n    # Grab current DOF states\n    dof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_EFFORT)\n\n    # Possibly set specific values in the array if indies are specified\n    if indices is None:\n        new_efforts = efforts\n    else:\n        new_efforts = dof_states[\"effort\"]\n        new_efforts[indices] = efforts\n\n    # Set the DOF states\n    dof_states[\"effort\"] = new_efforts\n    self._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_EFFORT)\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_joint_efforts"},{"title":"<code>set_joint_positions(positions, indices=None, normalized=False, target=False)</code>","text":"<p>Set the joint positions (both actual value and target values) in simulation. Note: only works if the simulator is actively running!</p> <p>Parameters:</p>    Name Type Description Default     <code>positions</code>  <code>np.ndarray</code>  <p>positions to set. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @positions must be the same length as @indices!</p>  required    <code>indices</code>  <code>None or k-array</code>  <p>If specified, should be k (k &lt; n) length array of specific DOF positions to set. Default is None, which assumes that all joints are being set.</p>  <code>None</code>    <code>normalized</code>  <code>bool</code>  <p>Whether the inputted joint positions should be interpreted as normalized values. Default is False</p>  <code>False</code>    <code>target</code>  <code>bool</code>  <p>Whether the positions being set are target values or manual values to immediately set. Default is False, corresponding to an instantaneous setting of the positions</p>  <code>False</code>      Source code in <code>prims/entity_prim.py</code> <pre><code>def set_joint_positions(self, positions, indices=None, normalized=False, target=False):\n    \"\"\"\n    Set the joint positions (both actual value and target values) in simulation. Note: only works if the simulator\n    is actively running!\n\n    Args:\n        positions (np.ndarray): positions to set. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @positions must\n            be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF positions to set.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool): Whether the inputted joint positions should be interpreted as normalized values. Default\n            is False\n        target (bool): Whether the positions being set are target values or manual values to immediately set.\n            Default is False, corresponding to an instantaneous setting of the positions\n    \"\"\"\n    # Run sanity checks -- make sure our handle is initialized and that we are articulated\n    assert self._handle is not None, \"handles are not initialized yet!\"\n    self.assert_articulated()\n\n    # Possibly de-normalize the inputs\n    if normalized:\n        positions = self._denormalize_positions(positions=positions, indices=indices)\n\n    # Grab current DOF states\n    dof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_POS)\n\n    # Possibly set specific values in the array if indies are specified\n    if indices is None:\n        assert len(positions) == self._n_dof, \\\n            \"set_joint_positions called without specifying indices, but the desired positions do not match n_dof.\"\n        new_positions = positions\n    else:\n        new_positions = dof_states[\"pos\"]\n        new_positions[indices] = positions\n\n    # Set the DOF states\n    dof_states[\"pos\"] = new_positions\n    if not target:\n        self._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_POS)\n\n    # Also set the target\n    self._dc.set_articulation_dof_position_targets(self._handle, new_positions.astype(np.float32))\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_joint_positions"},{"title":"<code>set_joint_velocities(velocities, indices=None, normalized=False, target=False)</code>","text":"<p>Set the joint velocities (both actual value and target values) in simulation. Note: only works if the simulator is actively running!</p> <p>Parameters:</p>    Name Type Description Default     <code>velocities</code>  <code>np.ndarray</code>  <p>velocities to set. This should be n-DOF length if all joints are being set, or k-length (k &lt; n) if specific indices are being set. In this case, the length of @velocities must be the same length as @indices!</p>  required    <code>indices</code>  <code>None or k-array</code>  <p>If specified, should be k (k &lt; n) length array of specific DOF velocities to set. Default is None, which assumes that all joints are being set.</p>  <code>None</code>    <code>normalized</code>  <code>bool</code>  <p>Whether the inputted joint velocities should be interpreted as normalized values. Default is False</p>  <code>False</code>    <code>target</code>  <code>bool</code>  <p>Whether the velocities being set are target values or manual values to immediately set. Default is False, corresponding to an instantaneous setting of the velocities</p>  <code>False</code>      Source code in <code>prims/entity_prim.py</code> <pre><code>def set_joint_velocities(self, velocities, indices=None, normalized=False, target=False):\n    \"\"\"\n    Set the joint velocities (both actual value and target values) in simulation. Note: only works if the simulator\n    is actively running!\n\n    Args:\n        velocities (np.ndarray): velocities to set. This should be n-DOF length if all joints are being set,\n            or k-length (k &lt; n) if specific indices are being set. In this case, the length of @velocities must\n            be the same length as @indices!\n        indices (None or k-array): If specified, should be k (k &lt; n) length array of specific DOF velocities to set.\n            Default is None, which assumes that all joints are being set.\n        normalized (bool): Whether the inputted joint velocities should be interpreted as normalized values. Default\n            is False\n        target (bool): Whether the velocities being set are target values or manual values to immediately set.\n            Default is False, corresponding to an instantaneous setting of the velocities\n    \"\"\"\n    # Run sanity checks -- make sure our handle is initialized and that we are articulated\n    assert self._handle is not None, \"handles are not initialized yet!\"\n    self.assert_articulated()\n\n    # Possibly de-normalize the inputs\n    if normalized:\n        velocities = self._denormalize_velocities(velocities=velocities, indices=indices)\n\n    # Grab current DOF states\n    dof_states = self._dc.get_articulation_dof_states(self._handle, _dynamic_control.STATE_VEL)\n\n    # Possibly set specific values in the array if indies are specified\n    if indices is None:\n        new_velocities = velocities\n    else:\n        new_velocities = dof_states[\"vel\"]\n        new_velocities[indices] = velocities\n\n    # Set the DOF states\n    dof_states[\"vel\"] = new_velocities\n    if not target:\n        self._dc.set_articulation_dof_states(self._handle, dof_states, _dynamic_control.STATE_VEL)\n\n    # Also set the target\n    self._dc.set_articulation_dof_velocity_targets(self._handle, new_velocities.astype(np.float32))\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_joint_velocities"},{"title":"<code>set_linear_velocity(velocity)</code>","text":"<p>Sets the linear velocity of the root prim in stage.</p> <p>Parameters:</p>    Name Type Description Default     <code>velocity</code>  <code>np.ndarray</code>  <p>linear velocity to set the rigid prim to, in the world frame. Shape (3,).</p>  required      Source code in <code>prims/entity_prim.py</code> <pre><code>def set_linear_velocity(self, velocity: np.ndarray):\n    \"\"\"\n    Sets the linear velocity of the root prim in stage.\n\n    Args:\n        velocity (np.ndarray): linear velocity to set the rigid prim to, in the world frame. Shape (3,).\n    \"\"\"\n    self.root_link.set_linear_velocity(velocity)\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.set_linear_velocity"},{"title":"<code>sleep()</code>","text":"<p>Disable physics for this articulation</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def sleep(self):\n    \"\"\"\n    Disable physics for this articulation\n    \"\"\"\n    if self.articulated:\n        self._dc.sleep_articulation(self._handle)\n    else:\n        for link in self._links.values():\n            link.sleep()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.sleep"},{"title":"<code>update_handles()</code>","text":"<p>Updates all internal handles for this prim, in case they change since initialization</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def update_handles(self):\n    \"\"\"\n    Updates all internal handles for this prim, in case they change since initialization\n    \"\"\"\n    self._handle = self._dc.get_articulation(self.articulation_root_path)\n    self._root_handle = self._dc.get_articulation_root_body(self._handle) if \\\n        self._handle != _dynamic_control.INVALID_HANDLE else self._dc.get_rigid_body(f\"{self._prim_path}/{self.root_link_name}\")\n\n    # Update all links and joints as well\n    for link in self._links.values():\n        if not link.initialized:\n            link.initialize()\n        link.update_handles()\n\n    for joint in self._joints.values():\n        if not joint.initialized:\n            joint.initialize()\n        joint.update_handles()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.update_handles"},{"title":"<code>update_joints()</code>","text":"<p>Helper function to refresh owned joints. Useful for synchronizing internal data if additional bodies are added manually</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def update_joints(self):\n    \"\"\"\n    Helper function to refresh owned joints. Useful for synchronizing internal data if\n    additional bodies are added manually\n    \"\"\"\n    # Make sure to clean up all pre-existing names for all joints\n    if self._joints is not None:\n        for joint in self._joints.values():\n            joint.remove_names()\n\n    # Initialize joints dictionary\n    self._joints = OrderedDict()\n    self.update_handles()\n\n    # Handle case separately based on whether the handle is valid (i.e.: whether we are actually articulated or not)\n    if self._handle != _dynamic_control.INVALID_HANDLE:\n        root_prim = get_prim_at_path(self._dc.get_rigid_body_path(self._root_handle))\n        n_dof = self._dc.get_articulation_dof_count(self._handle)\n\n        # Additionally grab DOF info if we have non-fixed joints\n        if n_dof &gt; 0:\n            self._dofs_infos = OrderedDict()\n            # Grab DOF info\n            for index in range(n_dof):\n                dof_handle = self._dc.get_articulation_dof(self._handle, index)\n                dof_name = self._dc.get_dof_name(dof_handle)\n                # add dof to list\n                prim_path = self._dc.get_dof_path(dof_handle)\n                self._dofs_infos[dof_name] = DOFInfo(prim_path=prim_path, handle=dof_handle, prim=self.prim,\n                                                     index=index)\n\n            for i in range(self._dc.get_articulation_joint_count(self._handle)):\n                joint_handle = self._dc.get_articulation_joint(self._handle, i)\n                joint_name = self._dc.get_joint_name(joint_handle)\n                joint_path = self._dc.get_joint_path(joint_handle)\n                joint_prim = get_prim_at_path(joint_path)\n                # Only add the joint if it's not fixed (i.e.: it has DOFs &gt; 0)\n                if self._dc.get_joint_dof_count(joint_handle) &gt; 0:\n                    joint = JointPrim(\n                        prim_path=joint_path,\n                        name=f\"{self._name}:joint_{joint_name}\",\n                        articulation=self._handle,\n                    )\n                    joint.initialize()\n                    self._joints[joint_name] = joint\n    else:\n        # TODO: May need to extend to clusters of rigid bodies, that aren't exactly joined\n        # We assume this object contains a single rigid body\n        body_path = f\"{self._prim_path}/{self.root_link_name}\"\n        root_prim = get_prim_at_path(body_path)\n        n_dof = 0\n\n    # Make sure root prim stored is the same as the one found during initialization\n    assert self.root_prim == root_prim, \\\n        f\"Mismatch in root prims! Original was {self.root_prim.GetPrimPath()}, \" \\\n        f\"initialized is {root_prim.GetPrimPath()}!\"\n\n    # Store values internally\n    self._n_dof = n_dof\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.update_joints"},{"title":"<code>update_links()</code>","text":"<p>Helper function to refresh owned joints. Useful for synchronizing internal data if additional bodies are added manually</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def update_links(self):\n    \"\"\"\n    Helper function to refresh owned joints. Useful for synchronizing internal data if\n    additional bodies are added manually\n    \"\"\"\n    # Make sure to clean up all pre-existing names for all links\n    if self._links is not None:\n        for link in self._links.values():\n            link.remove_names()\n\n    # We iterate over all children of this object's prim,\n    # and grab any that are presumed to be rigid bodies (i.e.: other Xforms)\n    self._links = OrderedDict()\n    joint_children = set()\n    for prim in self._prim.GetChildren():\n        link = None\n        link_name = prim.GetName()\n        if self._prim_type == PrimType.RIGID and prim.GetPrimTypeInfo().GetTypeName() == \"Xform\":\n            # For rigid body object, process prims that are Xforms (e.g. rigid links)\n            link = RigidPrim(\n                prim_path=prim.GetPrimPath().__str__(),\n                name=f\"{self._name}:{link_name}\",\n            )\n            # Also iterate through all children to infer joints and determine the children of those joints\n            # We will use this info to infer which link is the base link!\n            for child_prim in prim.GetChildren():\n                if \"joint\" in child_prim.GetPrimTypeInfo().GetTypeName().lower():\n                    # Store the child target of this joint\n                    relationships = {r.GetName(): r for r in child_prim.GetRelationships()}\n                    # Only record if this is NOT a fixed link tying us to the world (i.e.: no target for body0)\n                    if len(relationships[\"physics:body0\"].GetTargets()) &gt; 0:\n                        joint_children.add(relationships[\"physics:body1\"].GetTargets()[0].pathString.split(\"/\")[-1])\n\n        if self._prim_type == PrimType.CLOTH and prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\n            # For cloth object, process prims that belong to any of the GEOM_TYPES (e.g. Cube, Mesh, etc)\n            link = ClothPrim(\n                prim_path=prim.GetPrimPath().__str__(),\n                name=f\"{self._name}:{link_name}\",\n            )\n\n        if link is not None:\n            self._links[link_name] = link\n\n    # Infer the correct root link name -- this corresponds to whatever link does not have any joint existing\n    # in the children joints\n    valid_root_links = list(set(self._links.keys()) - joint_children)\n\n    # TODO: Uncomment safety check here after we figure out how to handle legacy multi-bodied assets like bed with pillow\n    # assert len(valid_root_links) == 1, f\"Only a single root link should have been found for this entity prim, \" \\\n    #                                    f\"but found multiple instead: {valid_root_links}\"\n    self._root_link_name = valid_root_links[0] if len(valid_root_links) == 1 else \"base_link\"\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.update_links"},{"title":"<code>wake()</code>","text":"<p>Enable physics for this articulation</p>  Source code in <code>prims/entity_prim.py</code> <pre><code>def wake(self):\n    \"\"\"\n    Enable physics for this articulation\n    \"\"\"\n    if self.articulated:\n        self._dc.wake_up_articulation(self._handle)\n    else:\n        for link in self._links.values():\n            link.wake()\n</code></pre>","location":"reference/prims/entity_prim.html#prims.entity_prim.EntityPrim.wake"},{"title":"geom_prim","text":"","location":"reference/prims/geom_prim.html"},{"title":"<code>CollisionGeomPrim</code>","text":"<p>         Bases: <code>GeomPrim</code></p>  Source code in <code>prims/geom_prim.py</code> <pre><code>class CollisionGeomPrim(GeomPrim):\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n        # Store values created at runtime\n        self._collision_api = None\n        self._mesh_collision_api = None\n        self._physx_collision_api = None\n        self._applied_physics_material = None\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # By default, CollisionGeomPrim does not show up in the rendering.\n        self.purpose = \"guide\"\n\n        # Create API references\n        self._collision_api = UsdPhysics.CollisionAPI(self._prim) if \\\n            self._prim.HasAPI(UsdPhysics.CollisionAPI) else UsdPhysics.CollisionAPI.Apply(self._prim)\n        self._physx_collision_api = PhysxSchema.PhysxCollisionAPI(self._prim) if \\\n            self._prim.HasAPI(PhysxSchema.PhysxCollisionAPI) else PhysxSchema.PhysxCollisionAPI.Apply(self._prim)\n\n        # Optionally add mesh collision API if this is a mesh\n        if self._prim.GetPrimTypeInfo().GetTypeName() == \"Mesh\":\n            self._mesh_collision_api = UsdPhysics.MeshCollisionAPI(self._prim) if \\\n                self._prim.HasAPI(UsdPhysics.MeshCollisionAPI) else UsdPhysics.MeshCollisionAPI.Apply(self._prim)\n\n    @property\n    def collision_enabled(self):\n        \"\"\"\n        Returns:\n            bool: Whether collisions are enabled for this collision mesh\n        \"\"\"\n        return self.get_attribute(\"physics:collisionEnabled\")\n\n    @collision_enabled.setter\n    def collision_enabled(self, enabled):\n        \"\"\"\n        Sets whether collisions are enabled for this mesh\n\n        Args:\n            enabled (bool): Whether collisions should be enabled for this mesh\n        \"\"\"\n        # Currently, trying to toggle while simulator is playing while using GPU dynamics results in a crash, so we\n        # assert that the sim is stopped here\n        if self._initialized and gm.USE_GPU_DYNAMICS:\n            assert og.sim.is_stopped(), \"Cannot toggle collisions while using GPU dynamics unless simulator is stopped!\"\n        self.set_attribute(\"physics:collisionEnabled\", enabled)\n\n    # TODO: Maybe this should all be added to RigidPrim instead?\n    def set_contact_offset(self, offset):\n        \"\"\"\n        Args:\n            offset (float): Contact offset of a collision shape. Allowed range [maximum(0, rest_offset), 0].\n                            Default value is -inf, means default is picked by simulation based on the shape extent.\n        \"\"\"\n        self._physx_collision_api.GetContactOffsetAttr().Set(offset)\n        return\n\n    def get_contact_offset(self):\n        \"\"\"\n        Returns:\n            float: contact offset of the collision shape.\n        \"\"\"\n        return self._physx_collision_api.GetContactOffsetAttr().Get()\n\n    def set_rest_offset(self, offset):\n        \"\"\"\n        Args:\n            offset (float): Rest offset of a collision shape. Allowed range [-max_float, contact_offset.\n                            Default value is -inf, means default is picked by simulatiion. For rigid bodies its zero.\n        \"\"\"\n        self._physx_collision_api.GetRestOffsetAttr().Set(offset)\n        return\n\n    def get_rest_offset(self):\n        \"\"\"\n        Returns:\n            float: rest offset of the collision shape.\n        \"\"\"\n        return self._physx_collision_api.GetRestOffsetAttr().Get()\n\n    def set_torsional_patch_radius(self, radius):\n        \"\"\"\n        Args:\n            radius (float): radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\n        self._physx_collision_api.GetTorsionalPatchRadiusAttr().Set(radius)\n        return\n\n    def get_torsional_patch_radius(self):\n        \"\"\"\n        Returns:\n            float: radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\n        return self._physx_collision_api.GetTorsionalPatchRadiusAttr().Get()\n\n    def set_min_torsional_patch_radius(self, radius):\n        \"\"\"\n        Args:\n            radius (float): minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\n        self._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Set(radius)\n        return\n\n    def get_min_torsional_patch_radius(self):\n        \"\"\"\n        Returns:\n            float: minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n        \"\"\"\n        return self._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Get()\n\n    def set_collision_approximation(self, approximation_type):\n        \"\"\"\n        Args:\n            approximation_type (str): approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"\n        \"\"\"\n        assert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\n        self._mesh_collision_api.GetApproximationAttr().Set(approximation_type)\n        return\n\n    def get_collision_approximation(self):\n        \"\"\"\n        Returns:\n            str: approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"\n        \"\"\"\n        assert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\n        return self._mesh_collision_api.GetApproximationAttr().Get()\n\n    def apply_physics_material(self, physics_material, weaker_than_descendants=False):\n        \"\"\"\n        Used to apply physics material to the held prim and optionally its descendants.\n\n        Args:\n            physics_material (PhysicsMaterial): physics material to be applied to the held prim. This where you want to\n                                                define friction, restitution..etc. Note: if a physics material is not\n                                                defined, the defaults will be used from PhysX.\n            weaker_than_descendants (bool, optional): True if the material shouldn't override the descendants\n                                                      materials, otherwise False. Defaults to False.\n        \"\"\"\n        if self._binding_api is None:\n            if self._prim.HasAPI(UsdShade.MaterialBindingAPI):\n                self._binding_api = UsdShade.MaterialBindingAPI(self.prim)\n            else:\n                self._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\n        if weaker_than_descendants:\n            self._binding_api.Bind(\n                physics_material.material,\n                bindingStrength=UsdShade.Tokens.weakerThanDescendants,\n                materialPurpose=\"physics\",\n            )\n        else:\n            self._binding_api.Bind(\n                physics_material.material,\n                bindingStrength=UsdShade.Tokens.strongerThanDescendants,\n                materialPurpose=\"physics\",\n            )\n        self._applied_physics_material = physics_material\n        return\n\n    def get_applied_physics_material(self):\n        \"\"\"\n        Returns the current applied physics material in case it was applied using apply_physics_material or not.\n\n        Returns:\n            PhysicsMaterial: the current applied physics material.\n        \"\"\"\n        if self._binding_api is None:\n            if self._prim.HasAPI(UsdShade.MaterialBindingAPI):\n                self._binding_api = UsdShade.MaterialBindingAPI(self.prim)\n            else:\n                self._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\n        if self._applied_physics_material is not None:\n            return self._applied_physics_material\n        else:\n            physics_binding = self._binding_api.GetDirectBinding(materialPurpose=\"physics\")\n            path = physics_binding.GetMaterialPath()\n            if path == \"\":\n                return None\n            else:\n                self._applied_physics_material = PhysicsMaterial(prim_path=path)\n                return self._applied_physics_material\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim"},{"title":"<code>collision_enabled</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether collisions are enabled for this collision mesh</p>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.collision_enabled"},{"title":"<code>apply_physics_material(physics_material, weaker_than_descendants=False)</code>","text":"<p>Used to apply physics material to the held prim and optionally its descendants.</p> <p>Parameters:</p>    Name Type Description Default     <code>physics_material</code>  <code>PhysicsMaterial</code>  <p>physics material to be applied to the held prim. This where you want to                                 define friction, restitution..etc. Note: if a physics material is not                                 defined, the defaults will be used from PhysX.</p>  required    <code>weaker_than_descendants</code>  <code>bool</code>  <p>True if the material shouldn't override the descendants                                       materials, otherwise False. Defaults to False.</p>  <code>False</code>      Source code in <code>prims/geom_prim.py</code> <pre><code>def apply_physics_material(self, physics_material, weaker_than_descendants=False):\n    \"\"\"\n    Used to apply physics material to the held prim and optionally its descendants.\n\n    Args:\n        physics_material (PhysicsMaterial): physics material to be applied to the held prim. This where you want to\n                                            define friction, restitution..etc. Note: if a physics material is not\n                                            defined, the defaults will be used from PhysX.\n        weaker_than_descendants (bool, optional): True if the material shouldn't override the descendants\n                                                  materials, otherwise False. Defaults to False.\n    \"\"\"\n    if self._binding_api is None:\n        if self._prim.HasAPI(UsdShade.MaterialBindingAPI):\n            self._binding_api = UsdShade.MaterialBindingAPI(self.prim)\n        else:\n            self._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\n    if weaker_than_descendants:\n        self._binding_api.Bind(\n            physics_material.material,\n            bindingStrength=UsdShade.Tokens.weakerThanDescendants,\n            materialPurpose=\"physics\",\n        )\n    else:\n        self._binding_api.Bind(\n            physics_material.material,\n            bindingStrength=UsdShade.Tokens.strongerThanDescendants,\n            materialPurpose=\"physics\",\n        )\n    self._applied_physics_material = physics_material\n    return\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.apply_physics_material"},{"title":"<code>get_applied_physics_material()</code>","text":"<p>Returns the current applied physics material in case it was applied using apply_physics_material or not.</p> <p>Returns:</p>    Name Type Description     <code>PhysicsMaterial</code>   <p>the current applied physics material.</p>     Source code in <code>prims/geom_prim.py</code> <pre><code>def get_applied_physics_material(self):\n    \"\"\"\n    Returns the current applied physics material in case it was applied using apply_physics_material or not.\n\n    Returns:\n        PhysicsMaterial: the current applied physics material.\n    \"\"\"\n    if self._binding_api is None:\n        if self._prim.HasAPI(UsdShade.MaterialBindingAPI):\n            self._binding_api = UsdShade.MaterialBindingAPI(self.prim)\n        else:\n            self._binding_api = UsdShade.MaterialBindingAPI.Apply(self.prim)\n    if self._applied_physics_material is not None:\n        return self._applied_physics_material\n    else:\n        physics_binding = self._binding_api.GetDirectBinding(materialPurpose=\"physics\")\n        path = physics_binding.GetMaterialPath()\n        if path == \"\":\n            return None\n        else:\n            self._applied_physics_material = PhysicsMaterial(prim_path=path)\n            return self._applied_physics_material\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_applied_physics_material"},{"title":"<code>get_collision_approximation()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"</p>     Source code in <code>prims/geom_prim.py</code> <pre><code>def get_collision_approximation(self):\n    \"\"\"\n    Returns:\n        str: approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"\n    \"\"\"\n    assert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\n    return self._mesh_collision_api.GetApproximationAttr().Get()\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_collision_approximation"},{"title":"<code>get_contact_offset()</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>contact offset of the collision shape.</p>     Source code in <code>prims/geom_prim.py</code> <pre><code>def get_contact_offset(self):\n    \"\"\"\n    Returns:\n        float: contact offset of the collision shape.\n    \"\"\"\n    return self._physx_collision_api.GetContactOffsetAttr().Get()\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_contact_offset"},{"title":"<code>get_min_torsional_patch_radius()</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p>     Source code in <code>prims/geom_prim.py</code> <pre><code>def get_min_torsional_patch_radius(self):\n    \"\"\"\n    Returns:\n        float: minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\n    return self._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Get()\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_min_torsional_patch_radius"},{"title":"<code>get_rest_offset()</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>rest offset of the collision shape.</p>     Source code in <code>prims/geom_prim.py</code> <pre><code>def get_rest_offset(self):\n    \"\"\"\n    Returns:\n        float: rest offset of the collision shape.\n    \"\"\"\n    return self._physx_collision_api.GetRestOffsetAttr().Get()\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_rest_offset"},{"title":"<code>get_torsional_patch_radius()</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p>     Source code in <code>prims/geom_prim.py</code> <pre><code>def get_torsional_patch_radius(self):\n    \"\"\"\n    Returns:\n        float: radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\n    return self._physx_collision_api.GetTorsionalPatchRadiusAttr().Get()\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.get_torsional_patch_radius"},{"title":"<code>set_collision_approximation(approximation_type)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>approximation_type</code>  <code>str</code>  <p>approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"</p>  required      Source code in <code>prims/geom_prim.py</code> <pre><code>def set_collision_approximation(self, approximation_type):\n    \"\"\"\n    Args:\n        approximation_type (str): approximation used for collision, could be \"none\", \"convexHull\" or \"convexDecomposition\"\n    \"\"\"\n    assert self._mesh_collision_api is not None, \"collision_approximation only applicable for meshes!\"\n    self._mesh_collision_api.GetApproximationAttr().Set(approximation_type)\n    return\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_collision_approximation"},{"title":"<code>set_contact_offset(offset)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>offset</code>  <code>float</code>  <p>Contact offset of a collision shape. Allowed range [maximum(0, rest_offset), 0].             Default value is -inf, means default is picked by simulation based on the shape extent.</p>  required      Source code in <code>prims/geom_prim.py</code> <pre><code>def set_contact_offset(self, offset):\n    \"\"\"\n    Args:\n        offset (float): Contact offset of a collision shape. Allowed range [maximum(0, rest_offset), 0].\n                        Default value is -inf, means default is picked by simulation based on the shape extent.\n    \"\"\"\n    self._physx_collision_api.GetContactOffsetAttr().Set(offset)\n    return\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_contact_offset"},{"title":"<code>set_min_torsional_patch_radius(radius)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>radius</code>  <code>float</code>  <p>minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p>  required      Source code in <code>prims/geom_prim.py</code> <pre><code>def set_min_torsional_patch_radius(self, radius):\n    \"\"\"\n    Args:\n        radius (float): minimum radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\n    self._physx_collision_api.GetMinTorsionalPatchRadiusAttr().Set(radius)\n    return\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_min_torsional_patch_radius"},{"title":"<code>set_rest_offset(offset)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>offset</code>  <code>float</code>  <p>Rest offset of a collision shape. Allowed range [-max_float, contact_offset.             Default value is -inf, means default is picked by simulatiion. For rigid bodies its zero.</p>  required      Source code in <code>prims/geom_prim.py</code> <pre><code>def set_rest_offset(self, offset):\n    \"\"\"\n    Args:\n        offset (float): Rest offset of a collision shape. Allowed range [-max_float, contact_offset.\n                        Default value is -inf, means default is picked by simulatiion. For rigid bodies its zero.\n    \"\"\"\n    self._physx_collision_api.GetRestOffsetAttr().Set(offset)\n    return\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_rest_offset"},{"title":"<code>set_torsional_patch_radius(radius)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>radius</code>  <code>float</code>  <p>radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].</p>  required      Source code in <code>prims/geom_prim.py</code> <pre><code>def set_torsional_patch_radius(self, radius):\n    \"\"\"\n    Args:\n        radius (float): radius of the contact patch used to apply torsional friction. Allowed range [0, max_float].\n    \"\"\"\n    self._physx_collision_api.GetTorsionalPatchRadiusAttr().Set(radius)\n    return\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.CollisionGeomPrim.set_torsional_patch_radius"},{"title":"<code>GeomPrim</code>","text":"<p>         Bases: <code>XFormPrim</code></p> <p>Provides high level functions to deal with a geom prim and its attributes / properties. If there is an geom prim present at the path, it will use it. By default, a geom prim cannot be directly created from scratch.at</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. For this mesh prim, the below values can be specified:</p>  <code>None</code>      Source code in <code>prims/geom_prim.py</code> <pre><code>class GeomPrim(XFormPrim):\n    \"\"\"\n    Provides high level functions to deal with a geom prim and its attributes / properties.\n    If there is an geom prim present at the path, it will use it. By default, a geom prim cannot be directly\n    created from scratch.at\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. For this mesh prim, the below values can be specified:\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _load(self, simulator=None):\n        # This should not be called, because this prim cannot be instantiated from scratch!\n        raise NotImplementedError(\"By default, a geom prim cannot be created from scratch.\")\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # By default, GeomPrim shows up in the rendering.\n        self.purpose = \"default\"\n\n    def _dump_state(self):\n        # No state to dump\n        return OrderedDict()\n\n    def _load_state(self, state):\n        # No state to load\n        pass\n\n    def _serialize(self, state):\n        # No state to serialize\n        return np.array([])\n\n    def _deserialize(self, state):\n        # No state to deserialize\n        return OrderedDict()\n\n    def duplicate(self, simulator, prim_path):\n        # Cannot directly duplicate a mesh prim\n        raise NotImplementedError(\"Cannot directly duplicate a geom prim!\")\n\n    @property\n    def purpose(self):\n        \"\"\"\n        Returns:\n            str: the purpose used for this geom, one of {\"default\", \"render\", \"proxy\", \"guide\"}\n        \"\"\"\n        return self.get_attribute(\"purpose\")\n\n    @purpose.setter\n    def purpose(self, purpose):\n        \"\"\"\n        Sets the purpose of this geom\n\n        Args:\n            purpose (str): the purpose used for this geom, one of {\"default\", \"render\", \"proxy\", \"guide\"}\n        \"\"\"\n        self.set_attribute(\"purpose\", purpose)\n\n    @property\n    def color(self):\n        \"\"\"\n        Returns:\n            None or 3-array: If set, the default RGB color used for this visual geom\n        \"\"\"\n        if self.has_material():\n            return self.material.diffuse_color_constant\n        else:\n            color = self.get_attribute(\"primvars:displayColor\")\n            return None if color is None else np.array(color)[0]\n\n    @color.setter\n    def color(self, rgb):\n        \"\"\"\n        Sets the RGB color of this visual mesh\n\n        Args:\n            3-array: The default RGB color used for this visual geom\n        \"\"\"\n        if self.has_material():\n            self.material.diffuse_color_constant = rgb\n        else:\n            self.set_attribute(\"primvars:displayColor\", np.array(rgb))\n\n    @property\n    def opacity(self):\n        \"\"\"\n        Returns:\n            None or float: If set, the default opacity used for this visual geom\n        \"\"\"\n        if self.has_material():\n            return self.material.opacity_constant\n        else:\n            opacity = self.get_attribute(\"primvars:displayOpacity\")\n            return None if opacity is None else np.array(opacity)[0]\n\n    @opacity.setter\n    def opacity(self, opacity):\n        \"\"\"\n        Sets the opacity of this visual mesh\n\n        Args:\n            opacity: The default opacity used for this visual geom\n        \"\"\"\n        if self.has_material():\n            self.material.opacity_constant = opacity\n        else:\n            self.set_attribute(\"primvars:displayOpacity\", np.array([opacity]))\n</code></pre>","location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim"},{"title":"<code>color</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or 3-array: If set, the default RGB color used for this visual geom</p>","location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim.color"},{"title":"<code>opacity</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or float: If set, the default opacity used for this visual geom</p>","location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim.opacity"},{"title":"<code>purpose</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>the purpose used for this geom, one of {\"default\", \"render\", \"proxy\", \"guide\"}</p>","location":"reference/prims/geom_prim.html#prims.geom_prim.GeomPrim.purpose"},{"title":"joint_prim","text":"","location":"reference/prims/joint_prim.html"},{"title":"<code>JointPrim</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Provides high level functions to deal with a joint prim and its attributes/ properties. If there is an joint prim present at the path, it will use it. Otherwise, a new joint prim at the specified prim path will be created when self.load(...) is called.</p>  the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init, <p>unless it is a non-root articulation link.</p>  <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. For this joint prim, the below values can be specified:</p> <p>joint_type (str): If specified, should be the joint type to create. Valid options are:     {\"Joint\", \"FixedJoint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"}     (equivalently, one of JointType) body0 (None or str): If specified, should be the absolute prim path to the parent body that this joint     is connected to. None can also be valid, which corresponds to cases where only a single body may be     specified (e.g.: fixed joints) body1 (None or str): If specified, should be the absolute prim path to the child body that this joint     is connected to. None can also be valid, which corresponds to cases where only a single body may be     specified (e.g.: fixed joints)</p>  <code>None</code>    <code>articulation</code>  <code>None or int</code>  <p>if specified, should be handle to pre-existing articulation. This will enable additional features for this joint prim, e.g.: polling / setting this joint's state. Note that in this case, the joint must already exist prior to this class instance. Default is None, which corresponds to a non-articulated joint.</p>  <code>None</code>      Source code in <code>prims/joint_prim.py</code> <pre><code>class JointPrim(BasePrim):\n    \"\"\"\n    Provides high level functions to deal with a joint prim and its attributes/ properties.\n    If there is an joint prim present at the path, it will use it. Otherwise, a new joint prim at\n    the specified prim path will be created when self.load(...) is called.\n\n    Note: the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init,\n            unless it is a non-root articulation link.\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. For this joint prim, the below values can be specified:\n\n            joint_type (str): If specified, should be the joint type to create. Valid options are:\n                {\"Joint\", \"FixedJoint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"}\n                (equivalently, one of JointType)\n            body0 (None or str): If specified, should be the absolute prim path to the parent body that this joint\n                is connected to. None can also be valid, which corresponds to cases where only a single body may be\n                specified (e.g.: fixed joints)\n            body1 (None or str): If specified, should be the absolute prim path to the child body that this joint\n                is connected to. None can also be valid, which corresponds to cases where only a single body may be\n                specified (e.g.: fixed joints)\n\n        articulation (None or int): if specified, should be handle to pre-existing articulation. This will enable\n            additional features for this joint prim, e.g.: polling / setting this joint's state. Note that in this\n            case, the joint must already exist prior to this class instance. Default is None,\n            which corresponds to a non-articulated joint.\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n        articulation=None,\n    ):\n        # Grab dynamic control reference and set properties\n        self._art = articulation\n\n        # Other values that will be filled in at runtime\n        self._joint_type = None\n        self._control_type = None\n        self._dof_properties = None\n\n        # The following values will only be valid if this joint is part of an articulation\n        self._dc = None\n        self._handle = None\n        self._n_dof = None\n        self._joint_name = None\n        self._dof_handles = None\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _load(self, simulator=None):\n        # Make sure this joint isn't articulated\n        assert not self.articulated, \"Joint cannot be created, since this is an articulated joint! We are assuming\" \\\n                                     \"the joint already exists in the stage.\"\n\n        # Define a joint prim at the current stage\n        stage = get_current_stage()\n        prim = create_joint(\n            prim_path=self._prim_path,\n            joint_type=self._load_config.get(\"joint_type\", JointType.JOINT),\n            stage=stage,\n        )\n\n        return prim\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # Possibly set the bodies\n        if \"body0\" in self._load_config and self._load_config[\"body0\"] is not None:\n            self.body0 = self._load_config[\"body0\"]\n        if \"body1\" in self._load_config and self._load_config[\"body1\"] is not None:\n            self.body1 = self._load_config[\"body1\"]\n\n    def _initialize(self):\n        # Always run super first\n        super()._initialize()\n\n        # Get joint info\n        self._joint_type = JointType.get_type(self._prim.GetTypeName().split(\"Physics\")[-1])\n\n        # Initialize dynamic control references if this joint is articulated\n        if self.articulated:\n            self._dc = _dynamic_control.acquire_dynamic_control_interface()\n            # TODO: A bit hacky way to get the joint handle, ideally we'd simply do dc.get_joint(), but this doesn't seem to work as expected?\n            for i in range(self._dc.get_articulation_joint_count(self._art)):\n                joint_handle = self._dc.get_articulation_joint(self._art, i)\n                joint_path = self._dc.get_joint_path(joint_handle)\n                if joint_path == self._prim_path:\n                    self._handle = joint_handle\n                    break\n            assert self._handle is not None, f\"Did not find valid articulated joint with path: {self._prim_path}\"\n\n            # Grab DOF info / handles\n            self._joint_name = self._dc.get_joint_name(self._handle)\n            self._n_dof = self._dc.get_joint_dof_count(self._handle)\n            self._dof_handles = []\n            self._dof_properties = []\n            control_types = []\n            for i in range(self._n_dof):\n                dof_handle = self._dc.get_joint_dof(self._handle, i)\n                dof_props = self._dc.get_dof_properties(dof_handle)\n                self._dof_handles.append(dof_handle)\n                self._dof_properties.append(dof_props)\n                # Infer control type based on whether kp and kd are 0 or not\n                kp, kd = dof_props.stiffness, dof_props.damping\n                if kp == 0.0:\n                    control_type = ControlType.EFFORT if kd == 0.0 else ControlType.VELOCITY\n                else:\n                    control_type = ControlType.POSITION\n                control_types.append(control_type)\n\n            # Make sure all the control types are the same -- if not, we had something go wrong!\n            assert len(set(control_types)) == 1, f\"Got multiple control types for this single joint: {control_types}\"\n            self._control_type = control_types[0]\n\n    def update_handles(self):\n        \"\"\"\n        Updates all internal handles for this prim, in case they change since initialization\n        \"\"\"\n        # TODO: A bit hacky way to get the joint handle, ideally we'd simply do dc.get_joint(), but this doesn't seem to work as expected?\n        self._handle = None\n        for i in range(self._dc.get_articulation_joint_count(self._art)):\n            joint_handle = self._dc.get_articulation_joint(self._art, i)\n            joint_path = self._dc.get_joint_path(joint_handle)\n            if joint_path == self._prim_path:\n                self._handle = joint_handle\n                break\n\n    def set_control_type(self, control_type, kp=None, kd=None):\n        \"\"\"\n        Sets the control type for this joint.\n\n        Args:\n            control_type (ControlType): What type of control to use for this joint.\n                Valid options are: {ControlType.POSITION, ControlType.VELOCITY, ControlType.EFFORT}\n            kp (None or float): If specified, sets the kp gain value for this joint. Should only be set if\n                setting ControlType.POSITION\n            kd (None or float): If specified, sets the kd gain value for this joint. Should only be set if\n                setting ControlType.VELOCITY\n        \"\"\"\n        # Sanity check inputs\n        assert_valid_key(key=control_type, valid_keys=ControlType.VALID_TYPES, name=\"control type\")\n        if control_type == ControlType.POSITION:\n            assert kp is not None, \"kp gain must be specified for setting POSITION control!\"\n            assert kd is None, \"kd gain must not be specified for setting POSITION control!\"\n            kd = 0.0\n        elif control_type == ControlType.VELOCITY:\n            assert kp is None, \"kp gain must not be specified for setting VELOCITY control!\"\n            assert kd is not None, \"kd gain must be specified for setting VELOCITY control!\"\n            kp = 0.0\n        else:   # Efforts\n            assert kp is None, \"kp gain must not be specified for setting EFFORT control!\"\n            assert kd is None, \"kd gain must not be specified for setting EFFORT control!\"\n            kp, kd = 0.0, 0.0\n\n        # Set values\n        if self._dc:\n            for dof_handle, dof_property in zip(self._dof_handles, self._dof_properties):\n                dof_property.stiffness = kp\n                dof_property.damping = kd\n                self._dc.set_dof_properties(dof_handle, dof_property)\n\n        # Update control type\n        self._control_type = control_type\n\n    @property\n    def body0(self):\n        \"\"\"\n        Gets this joint's body0 relationship.\n\n        Returns:\n            None or str: Absolute prim path to the body prim to set as this joint's parent link, or None if there is\n                no body0 specified.\n        \"\"\"\n        targets = self._prim.GetRelationship(\"physics:body0\").GetTargets()\n        return targets[0].__str__() if len(targets) &gt; 0 else None\n\n    @body0.setter\n    def body0(self, body0):\n        \"\"\"\n        Sets this joint's body0 relationship.\n\n        Args:\n            body0 (str): Absolute prim path to the body prim to set as this joint's parent link.\n        \"\"\"\n        # Make sure prim path is valid\n        assert is_prim_path_valid(body0), f\"Invalid body0 path specified: {body0}\"\n        self._prim.GetRelationship(\"physics:body0\").SetTargets([Sdf.Path(body0)])\n\n    @property\n    def body1(self):\n        \"\"\"\n        Gets this joint's body1 relationship.\n\n        Returns:\n            None or str: Absolute prim path to the body prim to set as this joint's child link, or None if there is\n                no body1 specified.\n        \"\"\"\n        targets = self._prim.GetRelationship(\"physics:body1\").GetTargets()\n        return targets[0].__str__()\n\n    @body1.setter\n    def body1(self, body1):\n        \"\"\"\n        Sets this joint's body1 relationship.\n\n        Args:\n            body1 (str): Absolute prim path to the body prim to set as this joint's child link.\n        \"\"\"\n        # Make sure prim path is valid\n        assert is_prim_path_valid(body1), f\"Invalid body1 path specified: {body1}\"\n        self._prim.GetRelationship(\"physics:body1\").SetTargets([Sdf.Path(body1)])\n\n    @property\n    def parent_name(self):\n        \"\"\"\n        Gets this joint's parent body name, if it exists\n\n        Returns:\n            str: Joint's parent body name\n        \"\"\"\n        return self._dc.get_rigid_body_name(self._dc.get_joint_parent_body(self._handle))\n\n    @property\n    def child_name(self):\n        \"\"\"\n        Gets this joint's child body name, if it exists\n\n        Returns:\n            str: Joint's child body name\n        \"\"\"\n        return self._dc.get_rigid_body_name(self._dc.get_joint_child_body(self._handle))\n\n    @property\n    def local_orientation(self):\n        \"\"\"\n        Returns:\n            4-array: (x,y,z,w) local quaternion orientation of this joint, relative to the parent link\n        \"\"\"\n        # Grab local rotation to parent and child links\n        quat0 = gf_quat_to_np_array(self.get_attribute(\"physics:localRot0\"))[[1, 2, 3, 0]]\n        quat1 = gf_quat_to_np_array(self.get_attribute(\"physics:localRot1\"))[[1, 2, 3, 0]]\n\n        # Invert the child link relationship, and multiply the two rotations together to get the final rotation\n        return T.quat_multiply(quaternion1=T.quat_inverse(quat1), quaternion0=quat0)\n\n    @property\n    def joint_name(self):\n        \"\"\"\n        Returns:\n            str: Name of this joint\n        \"\"\"\n        return self._joint_name\n\n    @property\n    def joint_type(self):\n        \"\"\"\n        Gets this joint's type (ignoring the \"Physics\" prefix)\n\n        Returns:\n            str: Joint's type. Should be one of:\n                {\"FixedJoint\", \"Joint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"}\n                    (equivalently, one of JointType)\n        \"\"\"\n        return self._joint_type\n\n    @property\n    def control_type(self):\n        \"\"\"\n        Gets the control types for this joint\n\n        Returns:\n            ControlType: control type for this joint\n        \"\"\"\n        return self._control_type\n\n    @property\n    def dof_properties(self):\n        \"\"\"\n        Returns:\n            list of DOFProperties: Per-DOF properties for this joint.\n                See https://docs.omniverse.nvidia.com/py/isaacsim/source/extensions/omni.isaac.dynamic_control/docs/index.html#omni.isaac.dynamic_control._dynamic_control.DofProperties\n                for more information.\n        \"\"\"\n        return self._dof_properties\n\n    @property\n    def max_velocity(self):\n        \"\"\"\n        Gets this joint's maximum velocity\n\n        Returns:\n            float: maximum velocity for this joint\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        # We either return the raw value or a default value if there is no max specified\n        raw_vel = self._dof_properties[0].max_velocity\n        default_max_vel = m.DEFAULT_MAX_REVOLUTE_VEL if self.joint_type == \"RevoluteJoint\" else m.DEFAULT_MAX_PRISMATIC_VEL\n        return default_max_vel if raw_vel is None or np.abs(raw_vel) &gt; m.INF_VEL_THRESHOLD else raw_vel\n\n    @max_velocity.setter\n    def max_velocity(self, vel):\n        \"\"\"\n        Sets this joint's maximum velocity\n\n        Args:\n            vel (float): Velocity to set\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        self._dof_properties[0].max_velocity = vel\n        self._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n\n    @property\n    def max_force(self):\n        \"\"\"\n        Gets this joint's maximum force\n\n        Returns:\n            float: maximum force for this joint\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        # We either return the raw value or a default value if there is no max specified\n        raw_force = self._dof_properties[0].max_effort\n        return m.DEFAULT_MAX_EFFORT if raw_force is None or np.abs(raw_force) &gt; m.INF_EFFORT_THRESHOLD else raw_force\n\n    @max_force.setter\n    def max_force(self, force):\n        \"\"\"\n        Sets this joint's maximum force\n\n        Args:\n            force (float): Force to set\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        self._dof_properties[0].max_effort = force\n        self._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n\n    @property\n    def stiffness(self):\n        \"\"\"\n        Gets this joint's stiffness\n\n        Returns:\n            float: stiffness for this joint\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        return self._dof_properties[0].stiffness\n\n    @stiffness.setter\n    def stiffness(self, stiffness):\n        \"\"\"\n        Sets this joint's stiffness\n\n        Args:\n            stiffness (float): stiffness to set\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        self._dof_properties[0].stiffness = stiffness\n        self._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n\n    @property\n    def damping(self):\n        \"\"\"\n        Gets this joint's damping\n\n        Returns:\n            float: damping for this joint\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        return self._dof_properties[0].damping\n\n    @damping.setter\n    def damping(self, damping):\n        \"\"\"\n        Sets this joint's damping\n\n        Args:\n            damping (float): damping to set\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        self._dof_properties[0].damping = damping\n        self._dc.set_dof_properties(self._dof_handles[0], self._dof_properties[0])\n\n    @property\n    def friction(self):\n        \"\"\"\n        Gets this joint's friction\n\n        Returns:\n            float: friction for this joint\n        \"\"\"\n        return self.get_attribute(\"physxJoint:jointFriction\")\n\n    @friction.setter\n    def friction(self, friction):\n        \"\"\"\n        Sets this joint's friction\n\n        Args:\n            friction (float): friction to set\n        \"\"\"\n        self.set_attribute(\"physxJoint:jointFriction\", friction)\n\n    @property\n    def lower_limit(self):\n        \"\"\"\n        Gets this joint's lower_limit\n\n        Returns:\n            float: lower_limit for this joint\n        \"\"\"\n        # TODO: Add logic for non Prismatic / Revolute joints (D6, spherical)\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        # We either return the raw value or a default value if there is no max specified\n        raw_pos_lower, raw_pos_upper = self._dof_properties[0].lower, self._dof_properties[0].upper\n        return -m.DEFAULT_MAX_POS \\\n            if raw_pos_lower is None or raw_pos_lower == raw_pos_upper or np.abs(raw_pos_lower) &gt; m.INF_POS_THRESHOLD \\\n            else raw_pos_lower\n\n    @lower_limit.setter\n    def lower_limit(self, lower_limit):\n        \"\"\"\n        Sets this joint's lower_limit\n\n        Args:\n            lower_limit (float): lower_limit to set\n        \"\"\"\n        # Can't use DC because it's read only property\n        lower_limit = T.rad2deg(lower_limit) if self.is_revolute else lower_limit\n        self.set_attribute(\"physics:lowerLimit\", lower_limit)\n\n    @property\n    def upper_limit(self):\n        \"\"\"\n        Gets this joint's upper_limit\n\n        Returns:\n            float: upper_limit for this joint\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        # We either return the raw value or a default value if there is no max specified\n        raw_pos_lower, raw_pos_upper = self._dof_properties[0].lower, self._dof_properties[0].upper\n        return m.DEFAULT_MAX_POS \\\n            if raw_pos_upper is None or raw_pos_lower == raw_pos_upper or np.abs(raw_pos_upper) &gt; m.INF_POS_THRESHOLD \\\n            else raw_pos_upper\n\n    @upper_limit.setter\n    def upper_limit(self, upper_limit):\n        \"\"\"\n        Sets this joint's upper_limit\n\n        Args:\n            upper_limit (float): upper_limit to set\n        \"\"\"\n        # Can't use DC because it's read only property\n        upper_limit = T.rad2deg(upper_limit) if self.is_revolute else upper_limit\n        self.set_attribute(\"physics:upperLimit\", upper_limit)\n\n    @property\n    def has_limit(self):\n        \"\"\"\n        Returns:\n            bool: True if this joint has a limit, else False\n        \"\"\"\n        # Only support revolute and prismatic joints for now\n        assert self.is_single_dof, \"Joint properties only supported for a single DOF currently!\"\n        # We either return the raw value or a default value if there is no max specified\n        return self._dof_properties[0].has_limits\n\n    @property\n    def n_dof(self):\n        \"\"\"\n        Returns:\n            int: Number of degrees of freedom this joint has\n        \"\"\"\n        return self._n_dof\n\n    @property\n    def articulated(self):\n        \"\"\"\n        Returns:\n             bool: Whether this joint is articulated or not\n        \"\"\"\n        return self._art is not None\n\n    @property\n    def is_revolute(self):\n        \"\"\"\n        Returns:\n            bool: Whether this joint is revolute or  not\n        \"\"\"\n        return self._joint_type == \"RevoluteJoint\"\n\n    @property\n    def is_single_dof(self):\n        \"\"\"\n        Returns:\n            bool: Whether this joint has a single DOF or not\n        \"\"\"\n        return self._joint_type in {\"RevoluteJoint\", \"PrismaticJoint\"}\n\n    def assert_articulated(self):\n        \"\"\"\n        Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended\n        behavior (e.g.: trying to grab this joint's state if it's not articulated)\n        \"\"\"\n        assert self.articulated, \"Tried to call method not intended for non-articulated joint!\"\n\n    def get_state(self, normalized=False):\n        \"\"\"\n        (pos, vel, effort) state of this joint\n\n        Args:\n            normalized (bool): If True, will return normalized state of this joint, where pos, vel, and effort values\n                are in range [-1, 1].\n\n        Returns:\n            3-tuple:\n                - n-array: position of this joint, where n = number of DOF for this joint\n                - n-array: velocity of this joint, where n = number of DOF for this joint\n                - n-array: effort of this joint, where n = number of DOF for this joint\n        \"\"\"\n        # Make sure we only call this if we're an articulated joint\n        self.assert_articulated()\n\n        # Grab raw states\n        pos, vel, effort = np.zeros(self.n_dof), np.zeros(self.n_dof), np.zeros(self.n_dof)\n        for i, dof_handle in enumerate(self._dof_handles):\n            dof_state = self._dc.get_dof_state(dof_handle, _dynamic_control.STATE_ALL)\n            pos[i] = dof_state.pos\n            vel[i] = dof_state.vel\n            effort[i] = dof_state.effort\n\n        # Potentially normalize if requested\n        if normalized:\n            pos, vel, effort = self._normalize_pos(pos), self._normalize_vel(vel), self._normalize_effort(effort)\n\n        return pos, vel, effort\n\n    def get_target(self, normalized=False):\n        \"\"\"\n        (pos, vel) target of this joint\n\n        Args:\n            normalized (bool): If True, will return normalized target of this joint\n\n        Returns:\n            2-tuple:\n                - n-array: target position of this joint, where n = number of DOF for this joint\n                - n-array: target velocity of this joint, where n = number of DOF for this joint\n        \"\"\"\n        # Make sure we only call this if we're an articulated joint\n        self.assert_articulated()\n\n        # Grab raw states\n        pos, vel = np.zeros(self.n_dof), np.zeros(self.n_dof)\n        for i, dof_handle in enumerate(self._dof_handles):\n            pos[i] = self._dc.get_dof_position_target(dof_handle)\n            vel[i] = self._dc.get_dof_velocity_target(dof_handle)\n\n        # Potentially normalize if requested\n        if normalized:\n            pos, vel = self._normalize_pos(pos), self._normalize_vel(vel)\n\n        return pos, vel\n\n    def _normalize_pos(self, pos):\n        \"\"\"\n        Normalizes raw joint positions @pos\n\n        Args:\n            pos (n-array): n-DOF raw positions to normalize\n\n        Returns:\n            n-array: n-DOF normalized positions in range [-1, 1]\n        \"\"\"\n        low, high = self.lower_limit, self.upper_limit\n        mean = (low + high) / 2.0\n        magnitude = (high - low) / 2.0\n        pos = (pos - mean) / magnitude\n\n        return pos\n\n    def _denormalize_pos(self, pos):\n        \"\"\"\n        De-normalizes joint positions @pos\n\n        Args:\n            pos (n-array): n-DOF normalized positions in range [-1, 1]\n\n        Returns:\n            n-array: n-DOF de-normalized positions\n        \"\"\"\n        low, high = self.lower_limit, self.upper_limit\n        mean = (low + high) / 2.0\n        magnitude = (high - low) / 2.0\n        pos = pos * magnitude + mean\n\n        return pos\n\n    def _normalize_vel(self, vel):\n        \"\"\"\n        Normalizes raw joint velocities @vel\n\n        Args:\n            vel (n-array): n-DOF raw velocities to normalize\n\n        Returns:\n            n-array: n-DOF normalized velocities in range [-1, 1]\n        \"\"\"\n        return vel / self.max_velocity\n\n    def _denormalize_vel(self, vel):\n        \"\"\"\n        De-normalizes joint velocities @vel\n\n        Args:\n            vel (n-array): n-DOF normalized velocities in range [-1, 1]\n\n        Returns:\n            n-array: n-DOF de-normalized velocities\n        \"\"\"\n        return vel * self.max_velocity\n\n    def _normalize_effort(self, effort):\n        \"\"\"\n        Normalizes raw joint effort @effort\n\n        Args:\n            effort (n-array): n-DOF raw effort to normalize\n\n        Returns:\n            n-array: n-DOF normalized effort in range [-1, 1]\n        \"\"\"\n        return effort / self.max_force\n\n    def _denormalize_effort(self, effort):\n        \"\"\"\n        De-normalizes joint effort @effort\n\n        Args:\n            effort (n-array): n-DOF normalized effort in range [-1, 1]\n\n        Returns:\n            n-array: n-DOF de-normalized effort\n        \"\"\"\n        return effort * self.max_force\n\n    def set_pos(self, pos, normalized=False, target=False):\n        \"\"\"\n        Set the position of this joint in metric space\n\n        Args:\n            pos (float or n-array of float): Set the position(s) for this joint. Can be a single float or 1-array of\n                float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n            normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n                de-normalized first before being executed). Default is False\n            target (bool): Whether the position being set is a target value or manual value to immediately set. Default\n                is False, corresponding to an instantaneous setting of the position\n        \"\"\"\n        # Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\n        self.assert_articulated()\n        if target:\n            assert self._control_type == ControlType.POSITION, \\\n                \"Trying to set joint position target, but control type is not position!\"\n\n        # Standardize input\n        pos = np.array([pos]) if self._n_dof == 1 and not isinstance(pos, Iterable) else np.array(pos)\n\n        # Potentially de-normalize if the input is normalized\n        if normalized:\n            pos = self._denormalize_pos(pos)\n\n        # Set the DOF(s) in this joint\n        for dof_handle, p in zip(self._dof_handles, pos):\n            if not target:\n                self._dc.set_dof_position(dof_handle, p)\n            # We set the position in either case\n            self._dc.set_dof_position_target(dof_handle, p)\n\n    def set_vel(self, vel, normalized=False, target=False):\n        \"\"\"\n        Set the velocity of this joint in metric space\n\n        Args:\n            vel (float or n-array of float): Set the velocity(s) for this joint. Can be a single float or 1-array of\n                float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n            normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n                de-normalized first before being executed). Default is False\n            target (bool): Whether the velocity being set is a target value or manual value to immediately set. Default\n                is False, corresponding to an instantaneous setting of the velocity\n        \"\"\"\n        # Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\n        self.assert_articulated()\n        if target:\n            assert self._control_type == ControlType.VELOCITY, \\\n                f\"Trying to set joint velocity target for joint {self.name}, but control type is not velocity!\"\n\n        # Standardize input\n        vel = np.array([vel]) if self._n_dof == 1 and not isinstance(vel, Iterable) else np.array(vel)\n\n        # Potentially de-normalize if the input is normalized\n        if normalized:\n            vel = self._denormalize_vel(vel)\n\n        # Set the DOF(s) in this joint\n        for dof_handle, v in zip(self._dof_handles, vel):\n            if not target:\n                self._dc.set_dof_velocity(dof_handle, v)\n            # We set the target in either case\n            self._dc.set_dof_velocity_target(dof_handle, v)\n\n    def set_effort(self, effort, normalized=False):\n        \"\"\"\n        Set the effort of this joint in metric space\n\n        Args:\n            effort (float or n-array of float): Set the effort(s) for this joint. Can be a single float or 1-array of\n                float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n            normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n                de-normalized first before being executed). Default is False\n        \"\"\"\n        # Sanity checks -- make sure that we're articulated (no control type check like position and velocity\n        # because we can't set effort targets)\n        self.assert_articulated()\n\n        # Standardize input\n        effort = np.array([effort]) if self._n_dof == 1 and not isinstance(effort, Iterable) else np.array(effort)\n\n        # Potentially de-normalize if the input is normalized\n        if normalized:\n            effort = self._denormalize_effort(effort)\n\n        # Set the DOF(s) in this joint\n        for dof_handle, e in zip(self._dof_handles, effort):\n            self._dc.set_dof_effort(dof_handle, e)\n\n    def keep_still(self):\n        \"\"\"\n        Zero out all velocities for this prim\n        \"\"\"\n        self.set_vel(np.zeros(self.n_dof))\n\n    def _dump_state(self):\n        pos, vel, effort = self.get_state() if self.articulated else (np.array([]), np.array([]), np.array([]))\n        target_pos, target_vel = self.get_target() if self.articulated else (np.array([]), np.array([]))\n        return OrderedDict(\n            pos=pos,\n            vel=vel,\n            effort=effort,\n            target_pos=target_pos,\n            target_vel=target_vel,\n        )\n\n    def _load_state(self, state):\n        if self.articulated:\n            self.set_pos(state[\"pos\"], target=False)\n            self.set_vel(state[\"vel\"], target=False)\n            self.set_effort(state[\"effort\"])\n            if self._control_type == ControlType.POSITION:\n                self.set_pos(state[\"target_pos\"], target=True)\n            elif self._control_type == ControlType.VELOCITY:\n                self.set_vel(state[\"target_vel\"], target=True)\n\n    def _serialize(self, state):\n        # We serialize by iterating over the keys and adding them to a list that's concatenated at the end\n        # This is a deterministic mapping because we assume the state is an OrderedDict\n        return np.concatenate(list(state.values())).astype(float)\n\n    def _deserialize(self, state):\n        # We deserialize deterministically by knowing the order of values -- pos, vel, effort\n        return OrderedDict(\n            pos=state[0:self.n_dof],\n            vel=state[self.n_dof:2*self.n_dof],\n            effort=state[2*self.n_dof:3*self.n_dof],\n            target_pos=state[3*self.n_dof:4*self.n_dof],\n            target_vel=state[4*self.n_dof:5*self.n_dof],\n        ), 5*self.n_dof\n\n    def duplicate(self, simulator, prim_path):\n        # Cannot directly duplicate a joint prim\n        raise NotImplementedError(\"Cannot directly duplicate a joint prim!\")\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim"},{"title":"<code>articulated</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this joint is articulated or not</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.articulated"},{"title":"<code>body0</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's body0 relationship.</p> <p>Returns:</p>    Type Description       <p>None or str: Absolute prim path to the body prim to set as this joint's parent link, or None if there is no body0 specified.</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.body0"},{"title":"<code>body1</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's body1 relationship.</p> <p>Returns:</p>    Type Description       <p>None or str: Absolute prim path to the body prim to set as this joint's child link, or None if there is no body1 specified.</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.body1"},{"title":"<code>child_name</code>  <code>property</code>","text":"<p>Gets this joint's child body name, if it exists</p> <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Joint's child body name</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.child_name"},{"title":"<code>control_type</code>  <code>property</code>","text":"<p>Gets the control types for this joint</p> <p>Returns:</p>    Name Type Description     <code>ControlType</code>   <p>control type for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.control_type"},{"title":"<code>damping</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's damping</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>damping for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.damping"},{"title":"<code>dof_properties</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>list of DOFProperties: Per-DOF properties for this joint. See https://docs.omniverse.nvidia.com/py/isaacsim/source/extensions/omni.isaac.dynamic_control/docs/index.html#omni.isaac.dynamic_control._dynamic_control.DofProperties for more information.</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.dof_properties"},{"title":"<code>friction</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's friction</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>friction for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.friction"},{"title":"<code>has_limit</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if this joint has a limit, else False</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.has_limit"},{"title":"<code>is_revolute</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this joint is revolute or  not</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.is_revolute"},{"title":"<code>is_single_dof</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this joint has a single DOF or not</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.is_single_dof"},{"title":"<code>joint_name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.joint_name"},{"title":"<code>joint_type</code>  <code>property</code>","text":"<p>Gets this joint's type (ignoring the \"Physics\" prefix)</p> <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Joint's type. Should be one of: {\"FixedJoint\", \"Joint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"}     (equivalently, one of JointType)</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.joint_type"},{"title":"<code>local_orientation</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>4-array: (x,y,z,w) local quaternion orientation of this joint, relative to the parent link</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.local_orientation"},{"title":"<code>lower_limit</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's lower_limit</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>lower_limit for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.lower_limit"},{"title":"<code>max_force</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's maximum force</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>maximum force for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.max_force"},{"title":"<code>max_velocity</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's maximum velocity</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>maximum velocity for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.max_velocity"},{"title":"<code>n_dof</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of degrees of freedom this joint has</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.n_dof"},{"title":"<code>parent_name</code>  <code>property</code>","text":"<p>Gets this joint's parent body name, if it exists</p> <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Joint's parent body name</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.parent_name"},{"title":"<code>stiffness</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's stiffness</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>stiffness for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.stiffness"},{"title":"<code>upper_limit</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this joint's upper_limit</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>upper_limit for this joint</p>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.upper_limit"},{"title":"<code>assert_articulated()</code>","text":"<p>Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended behavior (e.g.: trying to grab this joint's state if it's not articulated)</p>  Source code in <code>prims/joint_prim.py</code> <pre><code>def assert_articulated(self):\n    \"\"\"\n    Sanity check to make sure this joint is articulated. Used as a gatekeeping function to prevent non-intended\n    behavior (e.g.: trying to grab this joint's state if it's not articulated)\n    \"\"\"\n    assert self.articulated, \"Tried to call method not intended for non-articulated joint!\"\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.assert_articulated"},{"title":"<code>get_state(normalized=False)</code>","text":"<p>(pos, vel, effort) state of this joint</p> <p>Parameters:</p>    Name Type Description Default     <code>normalized</code>  <code>bool</code>  <p>If True, will return normalized state of this joint, where pos, vel, and effort values are in range [-1, 1].</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>3-tuple: - n-array: position of this joint, where n = number of DOF for this joint - n-array: velocity of this joint, where n = number of DOF for this joint - n-array: effort of this joint, where n = number of DOF for this joint</p>     Source code in <code>prims/joint_prim.py</code> <pre><code>def get_state(self, normalized=False):\n    \"\"\"\n    (pos, vel, effort) state of this joint\n\n    Args:\n        normalized (bool): If True, will return normalized state of this joint, where pos, vel, and effort values\n            are in range [-1, 1].\n\n    Returns:\n        3-tuple:\n            - n-array: position of this joint, where n = number of DOF for this joint\n            - n-array: velocity of this joint, where n = number of DOF for this joint\n            - n-array: effort of this joint, where n = number of DOF for this joint\n    \"\"\"\n    # Make sure we only call this if we're an articulated joint\n    self.assert_articulated()\n\n    # Grab raw states\n    pos, vel, effort = np.zeros(self.n_dof), np.zeros(self.n_dof), np.zeros(self.n_dof)\n    for i, dof_handle in enumerate(self._dof_handles):\n        dof_state = self._dc.get_dof_state(dof_handle, _dynamic_control.STATE_ALL)\n        pos[i] = dof_state.pos\n        vel[i] = dof_state.vel\n        effort[i] = dof_state.effort\n\n    # Potentially normalize if requested\n    if normalized:\n        pos, vel, effort = self._normalize_pos(pos), self._normalize_vel(vel), self._normalize_effort(effort)\n\n    return pos, vel, effort\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.get_state"},{"title":"<code>get_target(normalized=False)</code>","text":"<p>(pos, vel) target of this joint</p> <p>Parameters:</p>    Name Type Description Default     <code>normalized</code>  <code>bool</code>  <p>If True, will return normalized target of this joint</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - n-array: target position of this joint, where n = number of DOF for this joint - n-array: target velocity of this joint, where n = number of DOF for this joint</p>     Source code in <code>prims/joint_prim.py</code> <pre><code>def get_target(self, normalized=False):\n    \"\"\"\n    (pos, vel) target of this joint\n\n    Args:\n        normalized (bool): If True, will return normalized target of this joint\n\n    Returns:\n        2-tuple:\n            - n-array: target position of this joint, where n = number of DOF for this joint\n            - n-array: target velocity of this joint, where n = number of DOF for this joint\n    \"\"\"\n    # Make sure we only call this if we're an articulated joint\n    self.assert_articulated()\n\n    # Grab raw states\n    pos, vel = np.zeros(self.n_dof), np.zeros(self.n_dof)\n    for i, dof_handle in enumerate(self._dof_handles):\n        pos[i] = self._dc.get_dof_position_target(dof_handle)\n        vel[i] = self._dc.get_dof_velocity_target(dof_handle)\n\n    # Potentially normalize if requested\n    if normalized:\n        pos, vel = self._normalize_pos(pos), self._normalize_vel(vel)\n\n    return pos, vel\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.get_target"},{"title":"<code>keep_still()</code>","text":"<p>Zero out all velocities for this prim</p>  Source code in <code>prims/joint_prim.py</code> <pre><code>def keep_still(self):\n    \"\"\"\n    Zero out all velocities for this prim\n    \"\"\"\n    self.set_vel(np.zeros(self.n_dof))\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.keep_still"},{"title":"<code>set_control_type(control_type, kp=None, kd=None)</code>","text":"<p>Sets the control type for this joint.</p> <p>Parameters:</p>    Name Type Description Default     <code>control_type</code>  <code>ControlType</code>  <p>What type of control to use for this joint. Valid options are: {ControlType.POSITION, ControlType.VELOCITY, ControlType.EFFORT}</p>  required    <code>kp</code>  <code>None or float</code>  <p>If specified, sets the kp gain value for this joint. Should only be set if setting ControlType.POSITION</p>  <code>None</code>    <code>kd</code>  <code>None or float</code>  <p>If specified, sets the kd gain value for this joint. Should only be set if setting ControlType.VELOCITY</p>  <code>None</code>      Source code in <code>prims/joint_prim.py</code> <pre><code>def set_control_type(self, control_type, kp=None, kd=None):\n    \"\"\"\n    Sets the control type for this joint.\n\n    Args:\n        control_type (ControlType): What type of control to use for this joint.\n            Valid options are: {ControlType.POSITION, ControlType.VELOCITY, ControlType.EFFORT}\n        kp (None or float): If specified, sets the kp gain value for this joint. Should only be set if\n            setting ControlType.POSITION\n        kd (None or float): If specified, sets the kd gain value for this joint. Should only be set if\n            setting ControlType.VELOCITY\n    \"\"\"\n    # Sanity check inputs\n    assert_valid_key(key=control_type, valid_keys=ControlType.VALID_TYPES, name=\"control type\")\n    if control_type == ControlType.POSITION:\n        assert kp is not None, \"kp gain must be specified for setting POSITION control!\"\n        assert kd is None, \"kd gain must not be specified for setting POSITION control!\"\n        kd = 0.0\n    elif control_type == ControlType.VELOCITY:\n        assert kp is None, \"kp gain must not be specified for setting VELOCITY control!\"\n        assert kd is not None, \"kd gain must be specified for setting VELOCITY control!\"\n        kp = 0.0\n    else:   # Efforts\n        assert kp is None, \"kp gain must not be specified for setting EFFORT control!\"\n        assert kd is None, \"kd gain must not be specified for setting EFFORT control!\"\n        kp, kd = 0.0, 0.0\n\n    # Set values\n    if self._dc:\n        for dof_handle, dof_property in zip(self._dof_handles, self._dof_properties):\n            dof_property.stiffness = kp\n            dof_property.damping = kd\n            self._dc.set_dof_properties(dof_handle, dof_property)\n\n    # Update control type\n    self._control_type = control_type\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_control_type"},{"title":"<code>set_effort(effort, normalized=False)</code>","text":"<p>Set the effort of this joint in metric space</p> <p>Parameters:</p>    Name Type Description Default     <code>effort</code>  <code>float or n-array of float</code>  <p>Set the effort(s) for this joint. Can be a single float or 1-array of float if the joint only has a single DOF, otherwise it should be an n-array of floats.</p>  required    <code>normalized</code>  <code>bool</code>  <p>Whether the input is normalized to [-1, 1] (in this case, the values will be de-normalized first before being executed). Default is False</p>  <code>False</code>      Source code in <code>prims/joint_prim.py</code> <pre><code>def set_effort(self, effort, normalized=False):\n    \"\"\"\n    Set the effort of this joint in metric space\n\n    Args:\n        effort (float or n-array of float): Set the effort(s) for this joint. Can be a single float or 1-array of\n            float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n        normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n            de-normalized first before being executed). Default is False\n    \"\"\"\n    # Sanity checks -- make sure that we're articulated (no control type check like position and velocity\n    # because we can't set effort targets)\n    self.assert_articulated()\n\n    # Standardize input\n    effort = np.array([effort]) if self._n_dof == 1 and not isinstance(effort, Iterable) else np.array(effort)\n\n    # Potentially de-normalize if the input is normalized\n    if normalized:\n        effort = self._denormalize_effort(effort)\n\n    # Set the DOF(s) in this joint\n    for dof_handle, e in zip(self._dof_handles, effort):\n        self._dc.set_dof_effort(dof_handle, e)\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_effort"},{"title":"<code>set_pos(pos, normalized=False, target=False)</code>","text":"<p>Set the position of this joint in metric space</p> <p>Parameters:</p>    Name Type Description Default     <code>pos</code>  <code>float or n-array of float</code>  <p>Set the position(s) for this joint. Can be a single float or 1-array of float if the joint only has a single DOF, otherwise it should be an n-array of floats.</p>  required    <code>normalized</code>  <code>bool</code>  <p>Whether the input is normalized to [-1, 1] (in this case, the values will be de-normalized first before being executed). Default is False</p>  <code>False</code>    <code>target</code>  <code>bool</code>  <p>Whether the position being set is a target value or manual value to immediately set. Default is False, corresponding to an instantaneous setting of the position</p>  <code>False</code>      Source code in <code>prims/joint_prim.py</code> <pre><code>def set_pos(self, pos, normalized=False, target=False):\n    \"\"\"\n    Set the position of this joint in metric space\n\n    Args:\n        pos (float or n-array of float): Set the position(s) for this joint. Can be a single float or 1-array of\n            float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n        normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n            de-normalized first before being executed). Default is False\n        target (bool): Whether the position being set is a target value or manual value to immediately set. Default\n            is False, corresponding to an instantaneous setting of the position\n    \"\"\"\n    # Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\n    self.assert_articulated()\n    if target:\n        assert self._control_type == ControlType.POSITION, \\\n            \"Trying to set joint position target, but control type is not position!\"\n\n    # Standardize input\n    pos = np.array([pos]) if self._n_dof == 1 and not isinstance(pos, Iterable) else np.array(pos)\n\n    # Potentially de-normalize if the input is normalized\n    if normalized:\n        pos = self._denormalize_pos(pos)\n\n    # Set the DOF(s) in this joint\n    for dof_handle, p in zip(self._dof_handles, pos):\n        if not target:\n            self._dc.set_dof_position(dof_handle, p)\n        # We set the position in either case\n        self._dc.set_dof_position_target(dof_handle, p)\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_pos"},{"title":"<code>set_vel(vel, normalized=False, target=False)</code>","text":"<p>Set the velocity of this joint in metric space</p> <p>Parameters:</p>    Name Type Description Default     <code>vel</code>  <code>float or n-array of float</code>  <p>Set the velocity(s) for this joint. Can be a single float or 1-array of float if the joint only has a single DOF, otherwise it should be an n-array of floats.</p>  required    <code>normalized</code>  <code>bool</code>  <p>Whether the input is normalized to [-1, 1] (in this case, the values will be de-normalized first before being executed). Default is False</p>  <code>False</code>    <code>target</code>  <code>bool</code>  <p>Whether the velocity being set is a target value or manual value to immediately set. Default is False, corresponding to an instantaneous setting of the velocity</p>  <code>False</code>      Source code in <code>prims/joint_prim.py</code> <pre><code>def set_vel(self, vel, normalized=False, target=False):\n    \"\"\"\n    Set the velocity of this joint in metric space\n\n    Args:\n        vel (float or n-array of float): Set the velocity(s) for this joint. Can be a single float or 1-array of\n            float if the joint only has a single DOF, otherwise it should be an n-array of floats.\n        normalized (bool): Whether the input is normalized to [-1, 1] (in this case, the values will be\n            de-normalized first before being executed). Default is False\n        target (bool): Whether the velocity being set is a target value or manual value to immediately set. Default\n            is False, corresponding to an instantaneous setting of the velocity\n    \"\"\"\n    # Sanity checks -- make sure we're the correct control type if we're setting a target and that we're articulated\n    self.assert_articulated()\n    if target:\n        assert self._control_type == ControlType.VELOCITY, \\\n            f\"Trying to set joint velocity target for joint {self.name}, but control type is not velocity!\"\n\n    # Standardize input\n    vel = np.array([vel]) if self._n_dof == 1 and not isinstance(vel, Iterable) else np.array(vel)\n\n    # Potentially de-normalize if the input is normalized\n    if normalized:\n        vel = self._denormalize_vel(vel)\n\n    # Set the DOF(s) in this joint\n    for dof_handle, v in zip(self._dof_handles, vel):\n        if not target:\n            self._dc.set_dof_velocity(dof_handle, v)\n        # We set the target in either case\n        self._dc.set_dof_velocity_target(dof_handle, v)\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.set_vel"},{"title":"<code>update_handles()</code>","text":"<p>Updates all internal handles for this prim, in case they change since initialization</p>  Source code in <code>prims/joint_prim.py</code> <pre><code>def update_handles(self):\n    \"\"\"\n    Updates all internal handles for this prim, in case they change since initialization\n    \"\"\"\n    # TODO: A bit hacky way to get the joint handle, ideally we'd simply do dc.get_joint(), but this doesn't seem to work as expected?\n    self._handle = None\n    for i in range(self._dc.get_articulation_joint_count(self._art)):\n        joint_handle = self._dc.get_articulation_joint(self._art, i)\n        joint_path = self._dc.get_joint_path(joint_handle)\n        if joint_path == self._prim_path:\n            self._handle = joint_handle\n            break\n</code></pre>","location":"reference/prims/joint_prim.html#prims.joint_prim.JointPrim.update_handles"},{"title":"material_prim","text":"","location":"reference/prims/material_prim.html"},{"title":"<code>MaterialPrim</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Provides high level functions to deal with a material prim and its attributes/ properties.</p> <p>If there is a material prim present at the path, it will use it. Otherwise, a new material prim at the specified prim path will be created.</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected for their class. For this material prim, the below values can be specified:</p> <p>mdl_name (None or str): If specified, should be the name of the mdl preset to load (including .mdl).     None results in default, \"OmniPBR.mdl\" mtl_name (None or str): If specified, should be the name of the mtl preset to load.     None results in default, \"OmniPBR\"</p>  <code>None</code>      Source code in <code>prims/material_prim.py</code> <pre><code>class MaterialPrim(BasePrim):\n    \"\"\"\n    Provides high level functions to deal with a material prim and its attributes/ properties.\n\n    If there is a material prim present at the path, it will use it. Otherwise, a new material prim at\n    the specified prim path will be created.\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected\n            for their class. For this material prim, the below values can be specified:\n\n            mdl_name (None or str): If specified, should be the name of the mdl preset to load (including .mdl).\n                None results in default, \"OmniPBR.mdl\"\n            mtl_name (None or str): If specified, should be the name of the mtl preset to load.\n                None results in default, \"OmniPBR\"\n    \"\"\"\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n        # Other values that will be filled in at runtime\n        self._shader = None\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _load(self, simulator=None):\n        # We create a new material at the specified path\n        mtl_created = []\n        omni.kit.commands.execute(\n            \"CreateAndBindMdlMaterialFromLibrary\",\n            mdl_name=\"OmniPBR.mdl\" if self._load_config.get(\"mdl_name\", None) is None else self._load_config[\"mdl_name\"],\n            mtl_name=\"OmniPBR\" if self._load_config.get(\"mtl_name\", None) is None else self._load_config[\"mtl_name\"],\n            mtl_created_list=mtl_created,\n        )\n        material_path = mtl_created[0]\n\n        # Move prim to desired location\n        omni.kit.commands.execute(\"MovePrim\", path_from=material_path, path_to=self._prim_path)\n\n        # Return generated material\n        return get_prim_at_path(self._prim_path)\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # Generate shader reference\n        self._shader = get_shader_from_material(self._prim)\n\n    def bind(self, target_prim_path):\n        \"\"\"\n        Bind this material to an arbitrary prim (usually a visual mesh prim)\n\n        Args:\n            target_prim_path (str): prim path of the Prim to bind to\n        \"\"\"\n        bind_material(prim_path=target_prim_path, material_path=self.prim_path)\n\n    async def _load_mdl_parameters(self):\n        \"\"\"\n        Loads MDL parameters internally so they can be accessed by our class instance\n        \"\"\"\n        og.sim.render()\n        await omni.usd.get_context().load_mdl_parameters_for_prim_async(self._shader)\n\n    def shader_force_populate(self):\n        \"\"\"\n        Force populate inputs and outputs of the shader\n        \"\"\"\n        assert self._shader is not None\n        asyncio.run(self._load_mdl_parameters())\n\n    def shader_update_asset_paths_with_root_path(self, root_path):\n        \"\"\"\n        Similar to @shader_update_asset_paths, except in this case, root_path is explicitly provided by the caller.\n\n        Args:\n            root_path (str): root to be pre-appended to the original asset paths\n        \"\"\"\n\n        for inp_name in self.shader_input_names_by_type(\"SdfAssetPath\"):\n            inp = self.get_input(inp_name)\n            # If the input doesn't have any path, skip\n            if inp is None:\n                continue\n\n            original_path = inp.path if inp.resolvedPath == \"\" else inp.resolvedPath\n            # If the input has an empty path, skip\n            if original_path == \"\":\n                continue\n\n            new_path = os.path.join(root_path, original_path)\n            self.set_input(inp_name, new_path)\n\n    def get_input(self, inp):\n        \"\"\"\n        Grabs the input with corresponding name @inp associated with this material and shader\n\n        Args:\n            inp (str): Name of the shader input whose value will be grabbed\n\n        Returns:\n            any: value of the requested @inp\n        \"\"\"\n        return self._shader.GetInput(inp).Get()\n\n    def set_input(self, inp, val):\n        \"\"\"\n        Sets the input with corresponding name @inp associated with this material and shader\n\n        Args:\n            inp (str): Name of the shader input whose value will be set\n            val (any): Value to set for the input. This should be the valid type for that attribute.\n        \"\"\"\n        # Make sure the input exists first, so we avoid segfaults with \"invalid null prim\"\n        assert inp in self.shader_input_names, \\\n            f\"Got invalid shader input to set! Current inputs are: {self.shader_input_names}. Got: {inp}\"\n        self._shader.GetInput(inp).Set(val)\n\n    @property\n    def shader(self):\n        \"\"\"\n        Returns:\n            Usd.Shade: Shader associated with this material\n        \"\"\"\n        return self._shader\n\n    @property\n    def shader_input_names(self):\n        \"\"\"\n        Returns:\n            set: All the shader input names associated with this material\n        \"\"\"\n        return {inp.GetBaseName() for inp in self._shader.GetInputs()}\n\n    def shader_input_names_by_type(self, input_type):\n        \"\"\"\n        Args:\n            input_type (str): input type\n\n        Returns:\n            set: All the shader input names associated with this material that match the given input type\n        \"\"\"\n        return {inp.GetBaseName() for inp in self._shader.GetInputs() if inp.GetTypeName().cppTypeName == input_type}\n\n    @property\n    def diffuse_color_constant(self):\n        \"\"\"\n        Returns:\n            3-array: this material's applied (R,G,B) color\n        \"\"\"\n        return np.array(self.get_input(inp=\"diffuse_color_constant\"))\n\n    @diffuse_color_constant.setter\n    def diffuse_color_constant(self, color):\n        \"\"\"\n        Args:\n             color (3-array): this material's applied (R,G,B) color\n        \"\"\"\n        self.set_input(inp=\"diffuse_color_constant\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n\n    @property\n    def diffuse_texture(self):\n        \"\"\"\n        Returns:\n            str: this material's applied diffuse_texture filepath\n        \"\"\"\n        return self.get_input(inp=\"diffuse_texture\").resolvedPath\n\n    @diffuse_texture.setter\n    def diffuse_texture(self, fpath):\n        \"\"\"\n        Args:\n            str: this material's applied diffuse_texture filepath\n        \"\"\"\n        self.set_input(inp=\"diffuse_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def albedo_desaturation(self):\n        \"\"\"\n        Returns:\n            float: this material's applied albedo_desaturation\n        \"\"\"\n        return self.get_input(inp=\"albedo_desaturation\")\n\n    @albedo_desaturation.setter\n    def albedo_desaturation(self, desaturation):\n        \"\"\"\n        Args:\n             desaturation (float): this material's applied albedo_desaturation\n        \"\"\"\n        self.set_input(inp=\"albedo_desaturation\", val=desaturation)\n\n    @property\n    def albedo_add(self):\n        \"\"\"\n        Returns:\n            float: this material's applied albedo_add\n        \"\"\"\n        return self.get_input(inp=\"albedo_add\")\n\n    @albedo_add.setter\n    def albedo_add(self, add):\n        \"\"\"\n        Args:\n             add (float): this material's applied albedo_add\n        \"\"\"\n        self.set_input(inp=\"albedo_add\", val=add)\n\n    @property\n    def albedo_brightness(self):\n        \"\"\"\n        Returns:\n            float: this material's applied albedo_brightness\n        \"\"\"\n        return self.get_input(inp=\"albedo_brightness\")\n\n    @albedo_brightness.setter\n    def albedo_brightness(self, brightness):\n        \"\"\"\n        Args:\n             brightness (float): this material's applied albedo_brightness\n        \"\"\"\n        self.set_input(inp=\"albedo_brightness\", val=brightness)\n\n    @property\n    def diffuse_tint(self):\n        \"\"\"\n        Returns:\n            3-array: this material's applied (R,G,B) diffuse_tint\n        \"\"\"\n        return np.array(self.get_input(inp=\"diffuse_tint\"))\n\n    @diffuse_tint.setter\n    def diffuse_tint(self, color):\n        \"\"\"\n        Args:\n             color (3-array): this material's applied (R,G,B) diffuse_tint\n        \"\"\"\n        self.set_input(inp=\"diffuse_tint\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n\n    @property\n    def reflection_roughness_constant(self):\n        \"\"\"\n        Returns:\n            float: this material's applied reflection_roughness_constant\n        \"\"\"\n        return self.get_input(inp=\"reflection_roughness_constant\")\n\n    @reflection_roughness_constant.setter\n    def reflection_roughness_constant(self, roughness):\n        \"\"\"\n        Args:\n             roughness (float): this material's applied reflection_roughness_constant\n        \"\"\"\n        self.set_input(inp=\"reflection_roughness_constant\", val=roughness)\n\n    @property\n    def reflection_roughness_texture_influence(self):\n        \"\"\"\n        Returns:\n            float: this material's applied reflection_roughness_texture_influence\n        \"\"\"\n        return self.get_input(inp=\"reflection_roughness_texture_influence\")\n\n    @reflection_roughness_texture_influence.setter\n    def reflection_roughness_texture_influence(self, prop):\n        \"\"\"\n        Args:\n             prop (float): this material's applied reflection_roughness_texture_influence proportion\n        \"\"\"\n        self.set_input(inp=\"reflection_roughness_texture_influence\", val=prop)\n\n    @property\n    def reflectionroughness_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied reflectionroughness_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"reflectionroughness_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @reflectionroughness_texture.setter\n    def reflectionroughness_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied reflectionroughness_texture fpath\n        \"\"\"\n        self.set_input(inp=\"reflectionroughness_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def metallic_constant(self):\n        \"\"\"\n        Returns:\n            float: this material's applied metallic_constant\n        \"\"\"\n        return self.get_input(inp=\"metallic_constant\")\n\n    @metallic_constant.setter\n    def metallic_constant(self, constant):\n        \"\"\"\n        Args:\n             constant (float): this material's applied metallic_constant\n        \"\"\"\n        self.set_input(inp=\"metallic_constant\", val=constant)\n\n    @property\n    def metallic_texture_influence(self):\n        \"\"\"\n        Returns:\n            float: this material's applied metallic_texture_influence\n        \"\"\"\n        return self.get_input(inp=\"metallic_texture_influence\")\n\n    @metallic_texture_influence.setter\n    def metallic_texture_influence(self, prop):\n        \"\"\"\n        Args:\n             prop (float): this material's applied metallic_texture_influence\n        \"\"\"\n        self.set_input(inp=\"metallic_texture_influence\", val=prop)\n\n    @property\n    def metallic_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied metallic_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"metallic_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @metallic_texture.setter\n    def metallic_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied metallic_texture fpath\n        \"\"\"\n        self.set_input(inp=\"metallic_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def specular_level(self):\n        \"\"\"\n        Returns:\n            float: this material's applied specular_level\n        \"\"\"\n        return self.get_input(inp=\"specular_level\")\n\n    @specular_level.setter\n    def specular_level(self, level):\n        \"\"\"\n        Args:\n             level (float): this material's applied specular_level\n        \"\"\"\n        self.set_input(inp=\"specular_level\", val=level)\n\n    @property\n    def enable_ORM_texture(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied enable_ORM_texture\n        \"\"\"\n        return self.get_input(inp=\"enable_ORM_texture\")\n\n    @enable_ORM_texture.setter\n    def enable_ORM_texture(self, enabled):\n        \"\"\"\n        Args:\n             enabled (bool): this material's applied enable_ORM_texture\n        \"\"\"\n        self.set_input(inp=\"enable_ORM_texture\", val=enabled)\n\n    @property\n    def ORM_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied ORM_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"ORM_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @ORM_texture.setter\n    def ORM_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied ORM_texture fpath\n        \"\"\"\n        self.set_input(inp=\"ORM_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def ao_to_diffuse(self):\n        \"\"\"\n        Returns:\n            float: this material's applied ao_to_diffuse\n        \"\"\"\n        return self.get_input(inp=\"ao_to_diffuse\")\n\n    @ao_to_diffuse.setter\n    def ao_to_diffuse(self, val):\n        \"\"\"\n        Args:\n             val (float): this material's applied ao_to_diffuse\n        \"\"\"\n        self.set_input(inp=\"ao_to_diffuse\", val=val)\n\n    @property\n    def ao_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied ao_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"ao_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @ao_texture.setter\n    def ao_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied ao_texture fpath\n        \"\"\"\n        self.set_input(inp=\"ao_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def enable_emission(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied enable_emission\n        \"\"\"\n        return self.get_input(inp=\"enable_emission\")\n\n    @enable_emission.setter\n    def enable_emission(self, enabled):\n        \"\"\"\n        Args:\n             enabled (bool): this material's applied enable_emission\n        \"\"\"\n        self.set_input(inp=\"enable_emission\", val=enabled)\n\n    @property\n    def emissive_color(self):\n        \"\"\"\n        Returns:\n            3-array: this material's applied (R,G,B) emissive_color\n        \"\"\"\n        return np.array(self.get_input(inp=\"emissive_color\"))\n\n    @emissive_color.setter\n    def emissive_color(self, color):\n        \"\"\"\n        Args:\n             color (3-array): this material's applied emissive_color\n        \"\"\"\n        self.set_input(inp=\"emissive_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n\n    @property\n    def emissive_color_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied emissive_color_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"emissive_color_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @emissive_color_texture.setter\n    def emissive_color_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied emissive_color_texture fpath\n        \"\"\"\n        self.set_input(inp=\"emissive_color_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def emissive_mask_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied emissive_mask_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"emissive_mask_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @emissive_mask_texture.setter\n    def emissive_mask_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied emissive_mask_texture fpath\n        \"\"\"\n        self.set_input(inp=\"emissive_mask_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def emissive_intensity(self):\n        \"\"\"\n        Returns:\n            float: this material's applied emissive_intensity\n        \"\"\"\n        return self.get_input(inp=\"emissive_intensity\")\n\n    @emissive_intensity.setter\n    def emissive_intensity(self, intensity):\n        \"\"\"\n        Args:\n             intensity (float): this material's applied emissive_intensity\n        \"\"\"\n        self.set_input(inp=\"emissive_intensity\", val=intensity)\n\n    @property\n    def enable_opacity(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied enable_opacity\n        \"\"\"\n        return self.get_input(inp=\"enable_opacity\")\n\n    @enable_opacity.setter\n    def enable_opacity(self, enabled):\n        \"\"\"\n        Args:\n             enabled (bool): this material's applied enable_opacity\n        \"\"\"\n        self.set_input(inp=\"enable_opacity\", val=enabled)\n\n    @property\n    def enable_opacity_texture(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied enable_opacity_texture\n        \"\"\"\n        return self.get_input(inp=\"enable_opacity_texture\")\n\n    @enable_opacity_texture.setter\n    def enable_opacity_texture(self, enabled):\n        \"\"\"\n        Args:\n             enabled (bool): this material's applied enable_opacity_texture\n        \"\"\"\n        self.set_input(inp=\"enable_opacity_texture\", val=enabled)\n\n    @property\n    def opacity_constant(self):\n        \"\"\"\n        Returns:\n            float: this material's applied opacity_constant\n        \"\"\"\n        return self.get_input(inp=\"opacity_constant\")\n\n    @opacity_constant.setter\n    def opacity_constant(self, constant):\n        \"\"\"\n        Args:\n             constant (float): this material's applied opacity_constant\n        \"\"\"\n        self.set_input(inp=\"opacity_constant\", val=constant)\n\n    @property\n    def opacity_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied opacity_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"opacity_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @opacity_texture.setter\n    def opacity_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied opacity_texture fpath\n        \"\"\"\n        self.set_input(inp=\"opacity_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def opacity_mode(self):\n        \"\"\"\n        Returns:\n            int: this material's applied opacity_mode\n        \"\"\"\n        return self.get_input(inp=\"opacity_mode\")\n\n    @opacity_mode.setter\n    def opacity_mode(self, mode):\n        \"\"\"\n        Args:\n             mode (int): this material's applied opacity_mode\n        \"\"\"\n        self.set_input(inp=\"opacity_mode\", val=mode)\n\n    @property\n    def opacity_threshold(self):\n        \"\"\"\n        Returns:\n            float: this material's applied opacity_threshold\n        \"\"\"\n        return self.get_input(inp=\"opacity_threshold\")\n\n    @opacity_threshold.setter\n    def opacity_threshold(self, threshold):\n        \"\"\"\n        Args:\n             threshold (float): this material's applied opacity_threshold\n        \"\"\"\n        self.set_input(inp=\"opacity_threshold\", val=threshold)\n\n    @property\n    def bump_factor(self):\n        \"\"\"\n        Returns:\n            float: this material's applied bump_factor\n        \"\"\"\n        return self.get_input(inp=\"bump_factor\")\n\n    @bump_factor.setter\n    def bump_factor(self, factor):\n        \"\"\"\n        Args:\n             factor (float): this material's applied bump_factor\n        \"\"\"\n        self.set_input(inp=\"bump_factor\", val=factor)\n\n    @property\n    def normalmap_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied normalmap_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"normalmap_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @normalmap_texture.setter\n    def normalmap_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied normalmap_texture fpath\n        \"\"\"\n        self.set_input(inp=\"normalmap_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def detail_bump_factor(self):\n        \"\"\"\n        Returns:\n            float: this material's applied detail_bump_factor\n        \"\"\"\n        return self.get_input(inp=\"detail_bump_factor\")\n\n    @detail_bump_factor.setter\n    def detail_bump_factor(self, factor):\n        \"\"\"\n        Args:\n             factor (float): this material's applied detail_bump_factor\n        \"\"\"\n        self.set_input(inp=\"detail_bump_factor\", val=factor)\n\n    @property\n    def detail_normalmap_texture(self):\n        \"\"\"\n        Returns:\n            None or str: this material's applied detail_normalmap_texture fpath if there is a texture applied, else\n                None\n        \"\"\"\n        inp = self.get_input(inp=\"detail_normalmap_texture\")\n        return None if inp is None else inp.resolvedPath\n\n    @detail_normalmap_texture.setter\n    def detail_normalmap_texture(self, fpath):\n        \"\"\"\n        Args:\n             fpath (str): this material's applied detail_normalmap_texture fpath\n        \"\"\"\n        self.set_input(inp=\"detail_normalmap_texture\", val=Sdf.AssetPath(fpath))\n\n    @property\n    def flip_tangent_u(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied flip_tangent_u\n        \"\"\"\n        return self.get_input(inp=\"flip_tangent_u\")\n\n    @flip_tangent_u.setter\n    def flip_tangent_u(self, flipped):\n        \"\"\"\n        Args:\n             flipped (bool): this material's applied flip_tangent_u\n        \"\"\"\n        self.set_input(inp=\"flip_tangent_u\", val=flipped)\n\n    @property\n    def flip_tangent_v(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied flip_tangent_v\n        \"\"\"\n        return self.get_input(inp=\"flip_tangent_v\")\n\n    @flip_tangent_v.setter\n    def flip_tangent_v(self, flipped):\n        \"\"\"\n        Args:\n             flipped (bool): this material's applied flip_tangent_v\n        \"\"\"\n        self.set_input(inp=\"flip_tangent_v\", val=flipped)\n\n    @property\n    def project_uvw(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied project_uvw\n        \"\"\"\n        return self.get_input(inp=\"project_uvw\")\n\n    @project_uvw.setter\n    def project_uvw(self, projected):\n        \"\"\"\n        Args:\n             projected (bool): this material's applied project_uvw\n        \"\"\"\n        self.set_input(inp=\"project_uvw\", val=projected)\n\n    @property\n    def world_or_object(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied world_or_object\n        \"\"\"\n        return self.get_input(inp=\"world_or_object\")\n\n    @world_or_object.setter\n    def world_or_object(self, val):\n        \"\"\"\n        Args:\n             val (bool): this material's applied world_or_object\n        \"\"\"\n        self.set_input(inp=\"world_or_object\", val=val)\n\n    @property\n    def uv_space_index(self):\n        \"\"\"\n        Returns:\n            int: this material's applied uv_space_index\n        \"\"\"\n        return self.get_input(inp=\"uv_space_index\")\n\n    @uv_space_index.setter\n    def uv_space_index(self, index):\n        \"\"\"\n        Args:\n             index (int): this material's applied uv_space_index\n        \"\"\"\n        self.set_input(inp=\"uv_space_index\", val=index)\n\n    @property\n    def texture_translate(self):\n        \"\"\"\n        Returns:\n            2-array: this material's applied texture_translate\n        \"\"\"\n        return np.array(self.get_input(inp=\"texture_translate\"))\n\n    @texture_translate.setter\n    def texture_translate(self, translate):\n        \"\"\"\n        Args:\n             translate (2-array): this material's applied (x,y) texture_translate\n        \"\"\"\n        self.set_input(inp=\"texture_translate\", val=Gf.Vec2f(*np.array(translate, dtype=float)))\n\n    @property\n    def texture_rotate(self):\n        \"\"\"\n        Returns:\n            float: this material's applied texture_rotate\n        \"\"\"\n        return self.get_input(inp=\"texture_rotate\")\n\n    @texture_rotate.setter\n    def texture_rotate(self, rotate):\n        \"\"\"\n        Args:\n             rotate (float): this material's applied texture_rotate\n        \"\"\"\n        self.set_input(inp=\"texture_rotate\", val=rotate)\n\n    @property\n    def texture_scale(self):\n        \"\"\"\n        Returns:\n            2-array: this material's applied texture_scale\n        \"\"\"\n        return np.array(self.get_input(inp=\"texture_scale\"))\n\n    @texture_scale.setter\n    def texture_scale(self, scale):\n        \"\"\"\n        Args:\n             scale (2-array): this material's applied (x,y) texture_scale\n        \"\"\"\n        self.set_input(inp=\"texture_scale\", val=Gf.Vec2f(*np.array(scale, dtype=float)))\n\n    @property\n    def detail_texture_translate(self):\n        \"\"\"\n        Returns:\n            2-array: this material's applied detail_texture_translate\n        \"\"\"\n        return np.array(self.get_input(inp=\"detail_texture_translate\"))\n\n    @detail_texture_translate.setter\n    def detail_texture_translate(self, translate):\n        \"\"\"\n        Args:\n             translate (2-array): this material's applied detail_texture_translate\n        \"\"\"\n        self.set_input(inp=\"detail_texture_translate\", val=Gf.Vec2f(*np.array(translate, dtype=float)))\n\n    @property\n    def detail_texture_rotate(self):\n        \"\"\"\n        Returns:\n            float: this material's applied detail_texture_rotate\n        \"\"\"\n        return self.get_input(inp=\"detail_texture_rotate\")\n\n    @detail_texture_rotate.setter\n    def detail_texture_rotate(self, rotate):\n        \"\"\"\n        Args:\n             rotate (float): this material's applied detail_texture_rotate\n        \"\"\"\n        self.set_input(inp=\"detail_texture_rotate\", val=rotate)\n\n    @property\n    def detail_texture_scale(self):\n        \"\"\"\n        Returns:\n            2-array: this material's applied detail_texture_scale\n        \"\"\"\n        return np.array(self.get_input(inp=\"detail_texture_scale\"))\n\n    @detail_texture_scale.setter\n    def detail_texture_scale(self, scale):\n        \"\"\"\n        Args:\n             scale (2-array): this material's applied detail_texture_scale\n        \"\"\"\n        self.set_input(inp=\"detail_texture_scale\", val=Gf.Vec2f(*np.array(scale, dtype=float)))\n\n    @property\n    def exclude_from_white_mode(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied excludeFromWhiteMode\n        \"\"\"\n        return self.get_input(inp=\"excludeFromWhiteMode\")\n\n    @exclude_from_white_mode.setter\n    def exclude_from_white_mode(self, exclude):\n        \"\"\"\n        Args:\n             exclude (bool): this material's applied excludeFromWhiteMode\n        \"\"\"\n        self.set_input(inp=\"excludeFromWhiteMode\", val=exclude)\n\n    @property\n    def diffuse_reflection_weight(self):\n        \"\"\"\n        Returns:\n            float: this material's applied diffuse_reflection_weight\n        \"\"\"\n        return self.get_input(inp=\"diffuse_reflection_weight\")\n\n    @diffuse_reflection_weight.setter\n    def diffuse_reflection_weight(self, weight):\n        \"\"\"\n        Args:\n             weight (float): this material's applied diffuse_reflection_weight\n        \"\"\"\n        self.set_input(inp=\"diffuse_reflection_weight\", val=weight)\n\n    @property\n    def enable_specular_transmission(self):\n        \"\"\"\n        Returns:\n            bool: this material's applied enable_specular_transmission\n        \"\"\"\n        return self.get_input(inp=\"enable_specular_transmission\")\n\n    @enable_specular_transmission.setter\n    def enable_specular_transmission(self, enabled):\n        \"\"\"\n        Args:\n             enabled (bool): this material's applied enable_specular_transmission\n        \"\"\"\n        self.set_input(inp=\"enable_specular_transmission\", val=enabled)\n\n    @property\n    def specular_transmission_weight(self):\n        \"\"\"\n        Returns:\n            float: this material's applied specular_transmission_weight\n        \"\"\"\n        return self.get_input(inp=\"specular_transmission_weight\")\n\n    @specular_transmission_weight.setter\n    def specular_transmission_weight(self, weight):\n        \"\"\"\n        Args:\n             weight (float): this material's applied specular_transmission_weight\n        \"\"\"\n        self.set_input(inp=\"specular_transmission_weight\", val=weight)\n\n    @property\n    def diffuse_reflection_color(self):\n        \"\"\"\n        Returns:\n            3-array: this material's diffuse_reflection_color in (R,G,B)\n        \"\"\"\n        return np.array(self.get_input(inp=\"diffuse_reflection_color\"))\n\n    @diffuse_reflection_color.setter\n    def diffuse_reflection_color(self, color):\n        \"\"\"\n        Args:\n             color (3-array): this material's diffuse_reflection_color in (R,G,B)\n        \"\"\"\n        self.set_input(inp=\"diffuse_reflection_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n\n    @property\n    def specular_reflection_color(self):\n        \"\"\"\n        Returns:\n            3-array: this material's specular_reflection_color in (R,G,B)\n        \"\"\"\n        return np.array(self.get_input(inp=\"specular_reflection_color\"))\n\n    @specular_reflection_color.setter\n    def specular_reflection_color(self, color):\n        \"\"\"\n        Args:\n             color (3-array): this material's specular_reflection_color in (R,G,B)\n        \"\"\"\n        self.set_input(inp=\"specular_reflection_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n\n    @property\n    def specular_transmission_color(self):\n        \"\"\"\n        Returns:\n            3-array: this material's specular_transmission_color in (R,G,B)\n        \"\"\"\n        return np.array(self.get_input(inp=\"specular_transmission_color\"))\n\n    @specular_transmission_color.setter\n    def specular_transmission_color(self, color):\n        \"\"\"\n        Args:\n             color (3-array): this material's specular_transmission_color in (R,G,B)\n        \"\"\"\n        self.set_input(inp=\"specular_transmission_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n\n    @property\n    def specular_transmission_scattering_color(self):\n        \"\"\"\n        Returns:\n            3-array: this material's specular_transmission_scattering_color in (R,G,B)\n        \"\"\"\n        return np.array(self.get_input(inp=\"specular_transmission_scattering_color\"))\n\n    @specular_transmission_scattering_color.setter\n    def specular_transmission_scattering_color(self, color):\n        \"\"\"\n        Args:\n             color (3-array): this material's specular_transmission_scattering_color in (R,G,B)\n        \"\"\"\n        self.set_input(inp=\"specular_transmission_scattering_color\", val=Gf.Vec3f(*np.array(color, dtype=float)))\n</code></pre>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim"},{"title":"<code>ORM_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied ORM_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.ORM_texture"},{"title":"<code>albedo_add</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied albedo_add</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.albedo_add"},{"title":"<code>albedo_brightness</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied albedo_brightness</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.albedo_brightness"},{"title":"<code>albedo_desaturation</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied albedo_desaturation</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.albedo_desaturation"},{"title":"<code>ao_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied ao_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.ao_texture"},{"title":"<code>ao_to_diffuse</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied ao_to_diffuse</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.ao_to_diffuse"},{"title":"<code>bump_factor</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied bump_factor</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.bump_factor"},{"title":"<code>detail_bump_factor</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied detail_bump_factor</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_bump_factor"},{"title":"<code>detail_normalmap_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied detail_normalmap_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_normalmap_texture"},{"title":"<code>detail_texture_rotate</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied detail_texture_rotate</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_texture_rotate"},{"title":"<code>detail_texture_scale</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-array: this material's applied detail_texture_scale</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_texture_scale"},{"title":"<code>detail_texture_translate</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-array: this material's applied detail_texture_translate</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.detail_texture_translate"},{"title":"<code>diffuse_color_constant</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: this material's applied (R,G,B) color</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_color_constant"},{"title":"<code>diffuse_reflection_color</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: this material's diffuse_reflection_color in (R,G,B)</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_reflection_color"},{"title":"<code>diffuse_reflection_weight</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied diffuse_reflection_weight</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_reflection_weight"},{"title":"<code>diffuse_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>this material's applied diffuse_texture filepath</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_texture"},{"title":"<code>diffuse_tint</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: this material's applied (R,G,B) diffuse_tint</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.diffuse_tint"},{"title":"<code>emissive_color</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: this material's applied (R,G,B) emissive_color</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_color"},{"title":"<code>emissive_color_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied emissive_color_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_color_texture"},{"title":"<code>emissive_intensity</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied emissive_intensity</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_intensity"},{"title":"<code>emissive_mask_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied emissive_mask_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.emissive_mask_texture"},{"title":"<code>enable_ORM_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied enable_ORM_texture</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_ORM_texture"},{"title":"<code>enable_emission</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied enable_emission</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_emission"},{"title":"<code>enable_opacity</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied enable_opacity</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_opacity"},{"title":"<code>enable_opacity_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied enable_opacity_texture</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_opacity_texture"},{"title":"<code>enable_specular_transmission</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied enable_specular_transmission</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.enable_specular_transmission"},{"title":"<code>exclude_from_white_mode</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied excludeFromWhiteMode</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.exclude_from_white_mode"},{"title":"<code>flip_tangent_u</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied flip_tangent_u</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.flip_tangent_u"},{"title":"<code>flip_tangent_v</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied flip_tangent_v</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.flip_tangent_v"},{"title":"<code>metallic_constant</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied metallic_constant</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.metallic_constant"},{"title":"<code>metallic_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied metallic_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.metallic_texture"},{"title":"<code>metallic_texture_influence</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied metallic_texture_influence</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.metallic_texture_influence"},{"title":"<code>normalmap_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied normalmap_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.normalmap_texture"},{"title":"<code>opacity_constant</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied opacity_constant</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_constant"},{"title":"<code>opacity_mode</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>this material's applied opacity_mode</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_mode"},{"title":"<code>opacity_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied opacity_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_texture"},{"title":"<code>opacity_threshold</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied opacity_threshold</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.opacity_threshold"},{"title":"<code>project_uvw</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied project_uvw</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.project_uvw"},{"title":"<code>reflection_roughness_constant</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied reflection_roughness_constant</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.reflection_roughness_constant"},{"title":"<code>reflection_roughness_texture_influence</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied reflection_roughness_texture_influence</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.reflection_roughness_texture_influence"},{"title":"<code>reflectionroughness_texture</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or str: this material's applied reflectionroughness_texture fpath if there is a texture applied, else None</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.reflectionroughness_texture"},{"title":"<code>shader</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>Usd.Shade: Shader associated with this material</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader"},{"title":"<code>shader_input_names</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>set</code>   <p>All the shader input names associated with this material</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_input_names"},{"title":"<code>specular_level</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied specular_level</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_level"},{"title":"<code>specular_reflection_color</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: this material's specular_reflection_color in (R,G,B)</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_reflection_color"},{"title":"<code>specular_transmission_color</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: this material's specular_transmission_color in (R,G,B)</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_transmission_color"},{"title":"<code>specular_transmission_scattering_color</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: this material's specular_transmission_scattering_color in (R,G,B)</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_transmission_scattering_color"},{"title":"<code>specular_transmission_weight</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied specular_transmission_weight</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.specular_transmission_weight"},{"title":"<code>texture_rotate</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>this material's applied texture_rotate</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.texture_rotate"},{"title":"<code>texture_scale</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-array: this material's applied texture_scale</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.texture_scale"},{"title":"<code>texture_translate</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-array: this material's applied texture_translate</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.texture_translate"},{"title":"<code>uv_space_index</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>this material's applied uv_space_index</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.uv_space_index"},{"title":"<code>world_or_object</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>this material's applied world_or_object</p>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.world_or_object"},{"title":"<code>bind(target_prim_path)</code>","text":"<p>Bind this material to an arbitrary prim (usually a visual mesh prim)</p> <p>Parameters:</p>    Name Type Description Default     <code>target_prim_path</code>  <code>str</code>  <p>prim path of the Prim to bind to</p>  required      Source code in <code>prims/material_prim.py</code> <pre><code>def bind(self, target_prim_path):\n    \"\"\"\n    Bind this material to an arbitrary prim (usually a visual mesh prim)\n\n    Args:\n        target_prim_path (str): prim path of the Prim to bind to\n    \"\"\"\n    bind_material(prim_path=target_prim_path, material_path=self.prim_path)\n</code></pre>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.bind"},{"title":"<code>get_input(inp)</code>","text":"<p>Grabs the input with corresponding name @inp associated with this material and shader</p> <p>Parameters:</p>    Name Type Description Default     <code>inp</code>  <code>str</code>  <p>Name of the shader input whose value will be grabbed</p>  required     <p>Returns:</p>    Name Type Description     <code>any</code>   <p>value of the requested @inp</p>     Source code in <code>prims/material_prim.py</code> <pre><code>def get_input(self, inp):\n    \"\"\"\n    Grabs the input with corresponding name @inp associated with this material and shader\n\n    Args:\n        inp (str): Name of the shader input whose value will be grabbed\n\n    Returns:\n        any: value of the requested @inp\n    \"\"\"\n    return self._shader.GetInput(inp).Get()\n</code></pre>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.get_input"},{"title":"<code>set_input(inp, val)</code>","text":"<p>Sets the input with corresponding name @inp associated with this material and shader</p> <p>Parameters:</p>    Name Type Description Default     <code>inp</code>  <code>str</code>  <p>Name of the shader input whose value will be set</p>  required    <code>val</code>  <code>any</code>  <p>Value to set for the input. This should be the valid type for that attribute.</p>  required      Source code in <code>prims/material_prim.py</code> <pre><code>def set_input(self, inp, val):\n    \"\"\"\n    Sets the input with corresponding name @inp associated with this material and shader\n\n    Args:\n        inp (str): Name of the shader input whose value will be set\n        val (any): Value to set for the input. This should be the valid type for that attribute.\n    \"\"\"\n    # Make sure the input exists first, so we avoid segfaults with \"invalid null prim\"\n    assert inp in self.shader_input_names, \\\n        f\"Got invalid shader input to set! Current inputs are: {self.shader_input_names}. Got: {inp}\"\n    self._shader.GetInput(inp).Set(val)\n</code></pre>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.set_input"},{"title":"<code>shader_force_populate()</code>","text":"<p>Force populate inputs and outputs of the shader</p>  Source code in <code>prims/material_prim.py</code> <pre><code>def shader_force_populate(self):\n    \"\"\"\n    Force populate inputs and outputs of the shader\n    \"\"\"\n    assert self._shader is not None\n    asyncio.run(self._load_mdl_parameters())\n</code></pre>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_force_populate"},{"title":"<code>shader_input_names_by_type(input_type)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>input_type</code>  <code>str</code>  <p>input type</p>  required     <p>Returns:</p>    Name Type Description     <code>set</code>   <p>All the shader input names associated with this material that match the given input type</p>     Source code in <code>prims/material_prim.py</code> <pre><code>def shader_input_names_by_type(self, input_type):\n    \"\"\"\n    Args:\n        input_type (str): input type\n\n    Returns:\n        set: All the shader input names associated with this material that match the given input type\n    \"\"\"\n    return {inp.GetBaseName() for inp in self._shader.GetInputs() if inp.GetTypeName().cppTypeName == input_type}\n</code></pre>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_input_names_by_type"},{"title":"<code>shader_update_asset_paths_with_root_path(root_path)</code>","text":"<p>Similar to @shader_update_asset_paths, except in this case, root_path is explicitly provided by the caller.</p> <p>Parameters:</p>    Name Type Description Default     <code>root_path</code>  <code>str</code>  <p>root to be pre-appended to the original asset paths</p>  required      Source code in <code>prims/material_prim.py</code> <pre><code>def shader_update_asset_paths_with_root_path(self, root_path):\n    \"\"\"\n    Similar to @shader_update_asset_paths, except in this case, root_path is explicitly provided by the caller.\n\n    Args:\n        root_path (str): root to be pre-appended to the original asset paths\n    \"\"\"\n\n    for inp_name in self.shader_input_names_by_type(\"SdfAssetPath\"):\n        inp = self.get_input(inp_name)\n        # If the input doesn't have any path, skip\n        if inp is None:\n            continue\n\n        original_path = inp.path if inp.resolvedPath == \"\" else inp.resolvedPath\n        # If the input has an empty path, skip\n        if original_path == \"\":\n            continue\n\n        new_path = os.path.join(root_path, original_path)\n        self.set_input(inp_name, new_path)\n</code></pre>","location":"reference/prims/material_prim.html#prims.material_prim.MaterialPrim.shader_update_asset_paths_with_root_path"},{"title":"prim_base","text":"","location":"reference/prims/prim_base.html"},{"title":"<code>BasePrim</code>","text":"<p>         Bases: <code>Serializable</code>, <code>UniquelyNamed</code>, <code>Recreatable</code>, <code>ABC</code></p> <p>Provides high level functions to deal with a basic prim and its attributes/ properties. If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created.</p>  the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init, <p>unless it is a non-root articulation link.</p>  <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected for their class.</p>  <code>None</code>      Source code in <code>prims/prim_base.py</code> <pre><code>class BasePrim(Serializable, UniquelyNamed, Recreatable, ABC):\n    \"\"\"\n    Provides high level functions to deal with a basic prim and its attributes/ properties.\n    If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created.\n\n    Note: the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init,\n        unless it is a non-root articulation link.\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. Subclasses should define the exact keys expected\n            for their class.\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n        self._prim_path = prim_path\n        self._name = name\n        self._load_config = {} if load_config is None else load_config\n\n        # Other values that will be filled in at runtime\n        self._applied_visual_material = None\n        self._loaded = False                                # Whether this prim exists in the stage or not\n        self._initialized = False                           # Whether this prim has its internal handles / info initialized or not (occurs AFTER and INDEPENDENTLY from loading!)\n        self._prim = None\n        self._state_size = None\n        self._n_duplicates = 0                              # Simple counter for keeping track of duplicates for unique name indexing\n\n        # Run some post-loading steps if this prim has already been loaded\n        if is_prim_path_valid(prim_path=self._prim_path):\n            logging.debug(f\"prim {name} already exists, skipping load\")\n            self._prim = get_prim_at_path(prim_path=self._prim_path)\n            self._loaded = True\n            # Run post load.\n            self._post_load()\n\n        # Run super init\n        super().__init__()\n\n    def _initialize(self):\n        \"\"\"\n        Initializes state of this object and sets up any references necessary post-loading. Should be implemented by\n        sub-class for extended utility\n        \"\"\"\n        pass\n\n    def initialize(self):\n        \"\"\"\n        Initializes state of this object and sets up any references necessary post-loading. Subclasses should\n        implement / extend the _initialize() method.\n        \"\"\"\n        assert not self._initialized, \\\n            f\"Prim {self.name} at prim_path {self._prim_path} can only be initialized once! (It is already initialized)\"\n        self._initialize()\n\n        # Cache state size\n        self._state_size = len(self.dump_state(serialized=True))\n\n        self._initialized = True\n\n    def load(self, simulator=None):\n        \"\"\"\n        Load this prim into omniverse, optionally integrating this prim with simulator context @simulator, and return\n        loaded prim reference.\n\n        Args:\n            simulator (None or SimulationContext): If specified, should be simulator into which this prim will be\n                loaded. Otherwise, it will be loaded into the default stage\n\n        Returns:\n            Usd.Prim: Prim object loaded into the simulator\n        \"\"\"\n        if self._loaded:\n            raise ValueError(\"Cannot load a single prim multiple times.\")\n\n        # Load prim\n        self._prim = self._load(simulator=simulator)\n        self._loaded = True\n\n        # Run any post-loading logic\n        self._post_load()\n\n        return self._prim\n\n    def _post_load(self):\n        \"\"\"\n        Any actions that should be taken (e.g.: modifying the object's properties such as scale, visibility, additional\n        joints, etc.) that should be taken after loading the raw object into omniverse but BEFORE we initialize the\n        object and grab its handles and internal references. By default, this is a no-op.\n        \"\"\"\n        pass\n\n    def remove(self, simulator=None):\n        \"\"\"\n        Removes this prim from omniverse stage\n\n        Args:\n            simulator (None or SimulationContext): If specified, should be simulator into which this prim will be\n                removed. Otherwise, it will be removed from the default stage\n        \"\"\"\n        if not self._loaded:\n            raise ValueError(\"Cannot remove a prim that was never loaded.\")\n\n        # Remove prim\n        delete_prim(self.prim_path)\n        if simulator:\n            # Also clear the name so we can reuse this later\n            self.remove_names(include_all_owned=True, skip_ids={id(simulator)})\n\n    @abstractmethod\n    def _load(self, simulator=None):\n        \"\"\"\n        Loads the raw prim into the simulator. Any post-processing should be done in @self._post_load()\n\n        Args:\n            simulator (Simulator): Active simulation context\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def loaded(self):\n        return self._loaded\n\n    @property\n    def initialized(self):\n        return self._initialized\n\n    @property\n    def state_size(self):\n        # This is the cached value\n        return self._state_size\n\n    @property\n    def prim_path(self):\n        \"\"\"\n        Returns:\n            str: prim path in the stage.\n        \"\"\"\n        return self._prim_path\n\n    @property\n    def name(self):\n        \"\"\"\n        Returns:\n            str: unique name assigned to this prim\n        \"\"\"\n        return self._name\n\n    @property\n    def prim(self):\n        \"\"\"\n        Returns:\n            Usd.Prim: USD Prim object that this object holds.\n        \"\"\"\n        return self._prim\n\n    @property\n    def property_names(self):\n        \"\"\"\n        Returns:\n            set of str: Set of property names that this prim has (e.g.: visibility, proxyPrim, etc.)\n        \"\"\"\n        return set(self._prim.GetPropertyNames())\n\n    @property\n    def visible(self):\n        \"\"\"\n        Returns:\n            bool: true if the prim is visible in stage. false otherwise.\n        \"\"\"\n        return UsdGeom.Imageable(self.prim).ComputeVisibility(Usd.TimeCode.Default()) != UsdGeom.Tokens.invisible\n\n    @visible.setter\n    def visible(self, visible):\n        \"\"\"\n        Sets the visibility of the prim in stage.\n\n        Args:\n            visible (bool): flag to set the visibility of the usd prim in stage.\n        \"\"\"\n        imageable = UsdGeom.Imageable(self.prim)\n        if visible:\n            imageable.MakeVisible()\n        else:\n            imageable.MakeInvisible()\n        return\n\n    def is_valid(self):\n        \"\"\"\n        Returns:\n            bool: True is the current prim path corresponds to a valid prim in stage. False otherwise.\n        \"\"\"\n        return is_prim_path_valid(self.prim_path)\n\n    def change_prim_path(self, new_prim_path):\n        \"\"\"\n        Moves prim from the old path to a new one.\n\n        Args:\n            new_prim_path (str): new path of the prim to be moved to.\n        \"\"\"\n        move_prim(path_from=self.prim_path, path_to=new_prim_path)\n        self._prim_path = new_prim_path\n        self._prim = get_prim_at_path(self._prim_path)\n        return\n\n    def get_attribute(self, attr):\n        \"\"\"\n        Get this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n\n        Returns:\n            any: value of the requested @attribute\n        \"\"\"\n        return self._prim.GetAttribute(attr).Get()\n\n    def set_attribute(self, attr, val):\n        \"\"\"\n        Set this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n\n        Args:\n            attr (str): Attribute to set\n            val (any): Value to set for the attribute. This should be the valid type for that attribute.\n        \"\"\"\n        self._prim.GetAttribute(attr).Set(val)\n\n    def get_property(self, prop):\n        \"\"\"\n        Sets property @prop with value @val\n\n        Args:\n            prop (str): Name of the property to get. See Raw USD Properties in the GUI for examples of property names\n\n        Returns:\n            any: Property value\n        \"\"\"\n        self._prim.GetProperty(prop).Get()\n\n    def set_property(self, prop, val):\n        \"\"\"\n        Sets property @prop with value @val\n\n        Args:\n            prop (str): Name of the property to set. See Raw USD Properties in the GUI for examples of property names\n            val (any): Value to set for the property. Should be valid for that property\n        \"\"\"\n        self._prim.GetProperty(prop).Set(val)\n\n    def get_custom_data(self):\n        \"\"\"\n        Get custom data associated with this prim\n\n        Returns:\n            dict: Dictionary of any custom information\n        \"\"\"\n        return self._prim.GetCustomData()\n\n    def _create_prim_with_same_kwargs(self, prim_path, name, load_config):\n        \"\"\"\n        Generates a new instance of this prim's class with specified @prim_path, @name, and @load_config, but otherwise\n        all other kwargs should be identical to this instance's values.\n\n        Args:\n            prim_path (str): Absolute path to the newly generated prim\n            name (str): Name for the newly created prim\n            load_config (dict): Keyword-mapped kwargs to use to set specific attributes for the created prim's instance\n\n        Returns:\n            BasePrim: Generated prim object (not loaded, and not initialized!)\n        \"\"\"\n        return self.__class__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def duplicate(self, simulator, prim_path):\n        \"\"\"\n        Duplicates this object, and generates a new instance at @prim_path.\n        Note that the created object is automatically loaded into the simulator, but is NOT initialized\n        until a sim step occurs!\n\n        Args:\n            simulator (Simulator): simulation instance to load this object\n            prim_path (str): Absolute path to the newly generated prim\n\n        Returns:\n            BasePrim: Generated prim object\n        \"\"\"\n        new_prim = self._create_prim_with_same_kwargs(\n            prim_path=prim_path,\n            name=f\"{self.name}_copy{self._n_duplicates}\",\n            load_config=self._load_config,\n        )\n        simulator.import_object(new_prim, register=False, auto_initialize=True)\n\n        # Increment duplicate count\n        self._n_duplicates += 1\n\n        # Set visibility\n        new_prim.visible = self.visible\n\n        return new_prim\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim"},{"title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>unique name assigned to this prim</p>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.name"},{"title":"<code>prim</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>Usd.Prim: USD Prim object that this object holds.</p>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.prim"},{"title":"<code>prim_path</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>prim path in the stage.</p>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.prim_path"},{"title":"<code>property_names</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>set of str: Set of property names that this prim has (e.g.: visibility, proxyPrim, etc.)</p>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.property_names"},{"title":"<code>visible</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>true if the prim is visible in stage. false otherwise.</p>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.visible"},{"title":"<code>change_prim_path(new_prim_path)</code>","text":"<p>Moves prim from the old path to a new one.</p> <p>Parameters:</p>    Name Type Description Default     <code>new_prim_path</code>  <code>str</code>  <p>new path of the prim to be moved to.</p>  required      Source code in <code>prims/prim_base.py</code> <pre><code>def change_prim_path(self, new_prim_path):\n    \"\"\"\n    Moves prim from the old path to a new one.\n\n    Args:\n        new_prim_path (str): new path of the prim to be moved to.\n    \"\"\"\n    move_prim(path_from=self.prim_path, path_to=new_prim_path)\n    self._prim_path = new_prim_path\n    self._prim = get_prim_at_path(self._prim_path)\n    return\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.change_prim_path"},{"title":"<code>duplicate(simulator, prim_path)</code>","text":"<p>Duplicates this object, and generates a new instance at @prim_path. Note that the created object is automatically loaded into the simulator, but is NOT initialized until a sim step occurs!</p> <p>Parameters:</p>    Name Type Description Default     <code>simulator</code>  <code>Simulator</code>  <p>simulation instance to load this object</p>  required    <code>prim_path</code>  <code>str</code>  <p>Absolute path to the newly generated prim</p>  required     <p>Returns:</p>    Name Type Description     <code>BasePrim</code>   <p>Generated prim object</p>     Source code in <code>prims/prim_base.py</code> <pre><code>def duplicate(self, simulator, prim_path):\n    \"\"\"\n    Duplicates this object, and generates a new instance at @prim_path.\n    Note that the created object is automatically loaded into the simulator, but is NOT initialized\n    until a sim step occurs!\n\n    Args:\n        simulator (Simulator): simulation instance to load this object\n        prim_path (str): Absolute path to the newly generated prim\n\n    Returns:\n        BasePrim: Generated prim object\n    \"\"\"\n    new_prim = self._create_prim_with_same_kwargs(\n        prim_path=prim_path,\n        name=f\"{self.name}_copy{self._n_duplicates}\",\n        load_config=self._load_config,\n    )\n    simulator.import_object(new_prim, register=False, auto_initialize=True)\n\n    # Increment duplicate count\n    self._n_duplicates += 1\n\n    # Set visibility\n    new_prim.visible = self.visible\n\n    return new_prim\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.duplicate"},{"title":"<code>get_attribute(attr)</code>","text":"<p>Get this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()</p> <p>Returns:</p>    Name Type Description     <code>any</code>   <p>value of the requested @attribute</p>     Source code in <code>prims/prim_base.py</code> <pre><code>def get_attribute(self, attr):\n    \"\"\"\n    Get this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n\n    Returns:\n        any: value of the requested @attribute\n    \"\"\"\n    return self._prim.GetAttribute(attr).Get()\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.get_attribute"},{"title":"<code>get_custom_data()</code>","text":"<p>Get custom data associated with this prim</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary of any custom information</p>     Source code in <code>prims/prim_base.py</code> <pre><code>def get_custom_data(self):\n    \"\"\"\n    Get custom data associated with this prim\n\n    Returns:\n        dict: Dictionary of any custom information\n    \"\"\"\n    return self._prim.GetCustomData()\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.get_custom_data"},{"title":"<code>get_property(prop)</code>","text":"<p>Sets property @prop with value @val</p> <p>Parameters:</p>    Name Type Description Default     <code>prop</code>  <code>str</code>  <p>Name of the property to get. See Raw USD Properties in the GUI for examples of property names</p>  required     <p>Returns:</p>    Name Type Description     <code>any</code>   <p>Property value</p>     Source code in <code>prims/prim_base.py</code> <pre><code>def get_property(self, prop):\n    \"\"\"\n    Sets property @prop with value @val\n\n    Args:\n        prop (str): Name of the property to get. See Raw USD Properties in the GUI for examples of property names\n\n    Returns:\n        any: Property value\n    \"\"\"\n    self._prim.GetProperty(prop).Get()\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.get_property"},{"title":"<code>initialize()</code>","text":"<p>Initializes state of this object and sets up any references necessary post-loading. Subclasses should implement / extend the _initialize() method.</p>  Source code in <code>prims/prim_base.py</code> <pre><code>def initialize(self):\n    \"\"\"\n    Initializes state of this object and sets up any references necessary post-loading. Subclasses should\n    implement / extend the _initialize() method.\n    \"\"\"\n    assert not self._initialized, \\\n        f\"Prim {self.name} at prim_path {self._prim_path} can only be initialized once! (It is already initialized)\"\n    self._initialize()\n\n    # Cache state size\n    self._state_size = len(self.dump_state(serialized=True))\n\n    self._initialized = True\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.initialize"},{"title":"<code>is_valid()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True is the current prim path corresponds to a valid prim in stage. False otherwise.</p>     Source code in <code>prims/prim_base.py</code> <pre><code>def is_valid(self):\n    \"\"\"\n    Returns:\n        bool: True is the current prim path corresponds to a valid prim in stage. False otherwise.\n    \"\"\"\n    return is_prim_path_valid(self.prim_path)\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.is_valid"},{"title":"<code>load(simulator=None)</code>","text":"<p>Load this prim into omniverse, optionally integrating this prim with simulator context @simulator, and return loaded prim reference.</p> <p>Parameters:</p>    Name Type Description Default     <code>simulator</code>  <code>None or SimulationContext</code>  <p>If specified, should be simulator into which this prim will be loaded. Otherwise, it will be loaded into the default stage</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>Usd.Prim: Prim object loaded into the simulator</p>     Source code in <code>prims/prim_base.py</code> <pre><code>def load(self, simulator=None):\n    \"\"\"\n    Load this prim into omniverse, optionally integrating this prim with simulator context @simulator, and return\n    loaded prim reference.\n\n    Args:\n        simulator (None or SimulationContext): If specified, should be simulator into which this prim will be\n            loaded. Otherwise, it will be loaded into the default stage\n\n    Returns:\n        Usd.Prim: Prim object loaded into the simulator\n    \"\"\"\n    if self._loaded:\n        raise ValueError(\"Cannot load a single prim multiple times.\")\n\n    # Load prim\n    self._prim = self._load(simulator=simulator)\n    self._loaded = True\n\n    # Run any post-loading logic\n    self._post_load()\n\n    return self._prim\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.load"},{"title":"<code>remove(simulator=None)</code>","text":"<p>Removes this prim from omniverse stage</p> <p>Parameters:</p>    Name Type Description Default     <code>simulator</code>  <code>None or SimulationContext</code>  <p>If specified, should be simulator into which this prim will be removed. Otherwise, it will be removed from the default stage</p>  <code>None</code>      Source code in <code>prims/prim_base.py</code> <pre><code>def remove(self, simulator=None):\n    \"\"\"\n    Removes this prim from omniverse stage\n\n    Args:\n        simulator (None or SimulationContext): If specified, should be simulator into which this prim will be\n            removed. Otherwise, it will be removed from the default stage\n    \"\"\"\n    if not self._loaded:\n        raise ValueError(\"Cannot remove a prim that was never loaded.\")\n\n    # Remove prim\n    delete_prim(self.prim_path)\n    if simulator:\n        # Also clear the name so we can reuse this later\n        self.remove_names(include_all_owned=True, skip_ids={id(simulator)})\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.remove"},{"title":"<code>set_attribute(attr, val)</code>","text":"<p>Set this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()</p> <p>Parameters:</p>    Name Type Description Default     <code>attr</code>  <code>str</code>  <p>Attribute to set</p>  required    <code>val</code>  <code>any</code>  <p>Value to set for the attribute. This should be the valid type for that attribute.</p>  required      Source code in <code>prims/prim_base.py</code> <pre><code>def set_attribute(self, attr, val):\n    \"\"\"\n    Set this prim's attribute. Should be a valid attribute under self._prim.GetAttributes()\n\n    Args:\n        attr (str): Attribute to set\n        val (any): Value to set for the attribute. This should be the valid type for that attribute.\n    \"\"\"\n    self._prim.GetAttribute(attr).Set(val)\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.set_attribute"},{"title":"<code>set_property(prop, val)</code>","text":"<p>Sets property @prop with value @val</p> <p>Parameters:</p>    Name Type Description Default     <code>prop</code>  <code>str</code>  <p>Name of the property to set. See Raw USD Properties in the GUI for examples of property names</p>  required    <code>val</code>  <code>any</code>  <p>Value to set for the property. Should be valid for that property</p>  required      Source code in <code>prims/prim_base.py</code> <pre><code>def set_property(self, prop, val):\n    \"\"\"\n    Sets property @prop with value @val\n\n    Args:\n        prop (str): Name of the property to set. See Raw USD Properties in the GUI for examples of property names\n        val (any): Value to set for the property. Should be valid for that property\n    \"\"\"\n    self._prim.GetProperty(prop).Set(val)\n</code></pre>","location":"reference/prims/prim_base.html#prims.prim_base.BasePrim.set_property"},{"title":"rigid_prim","text":"","location":"reference/prims/rigid_prim.html"},{"title":"<code>RigidPrim</code>","text":"<p>         Bases: <code>XFormPrim</code></p> <p>Provides high level functions to deal with a rigid body prim and its attributes/ properties. If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created.</p>  if the prim does not already have a rigid body api applied to it before it is loaded, <p>it will apply it.</p>  <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. Note that this is only needed if the prim does not already exist at @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be specified:</p> <p>scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds     to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling. mass (None or float): If specified, mass of this body in kg density (None or float): If specified, density of this body in kg / m^3 visual_only (None or bool): If specified, whether this prim should include collisions or not.     Default is True.</p>  <code>None</code>      Source code in <code>prims/rigid_prim.py</code> <pre><code>class RigidPrim(XFormPrim):\n    \"\"\"\n    Provides high level functions to deal with a rigid body prim and its attributes/ properties.\n    If there is an prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created.\n\n    Notes: if the prim does not already have a rigid body api applied to it before it is loaded,\n        it will apply it.\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. Note that this is only needed if the prim does not already exist at\n            @prim_path -- it will be ignored if it already exists. For this joint prim, the below values can be\n            specified:\n\n            scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds\n                to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.\n            mass (None or float): If specified, mass of this body in kg\n            density (None or float): If specified, density of this body in kg / m^3\n            visual_only (None or bool): If specified, whether this prim should include collisions or not.\n                Default is True.\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n        # Other values that will be filled in at runtime\n        self._dc = None                     # Dynamic control interface\n        self._cs = None                     # Contact sensor interface\n        self._handle = None\n        self._contact_handle = None\n        self._body_name = None\n        self._rigid_api = None\n        self._physx_rigid_api = None\n        self._physx_contact_report_api = None\n        self._mass_api = None\n\n        self._visual_only = None\n        self._collision_meshes = None\n        self._visual_meshes = None\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # Apply rigid body and mass APIs\n        self._rigid_api = UsdPhysics.RigidBodyAPI(self._prim) if self._prim.HasAPI(UsdPhysics.RigidBodyAPI) else \\\n            UsdPhysics.RigidBodyAPI.Apply(self._prim)\n        self._physx_rigid_api = PhysxSchema.PhysxRigidBodyAPI(self._prim) if \\\n            self._prim.HasAPI(PhysxSchema.PhysxRigidBodyAPI) else PhysxSchema.PhysxRigidBodyAPI.Apply(self._prim)\n        self._mass_api = UsdPhysics.MassAPI(self._prim) if self._prim.HasAPI(UsdPhysics.MassAPI) else \\\n            UsdPhysics.MassAPI.Apply(self._prim)\n\n        # Only create contact report api if we're not visual only\n        if (not self._visual_only) and gm.ENABLE_GLOBAL_CONTACT_REPORTING:\n            self._physx_rigid_api = PhysxSchema.PhysxContactReportAPI(self._prim) if \\\n                self._prim.HasAPI(PhysxSchema.PhysxContactReportAPI) else \\\n                PhysxSchema.PhysxContactReportAPI.Apply(self._prim)\n\n        # Possibly set the mass / density\n        if \"mass\" in self._load_config and self._load_config[\"mass\"] is not None:\n            self.mass = self._load_config[\"mass\"]\n        if \"density\" in self._load_config and self._load_config[\"density\"] is not None:\n            self.density = self._load_config[\"density\"]\n\n        # Store references to owned visual / collision meshes\n        # We iterate over all children of this object's prim,\n        # and grab any that are presumed to be meshes\n        self.update_meshes()\n\n        # Set the visual-only attribute\n        # This automatically handles setting collisions / gravity appropriately\n        self.visual_only = self._load_config[\"visual_only\"] if \\\n            \"visual_only\" in self._load_config and self._load_config[\"visual_only\"] is not None else False\n\n        # Create contact sensor\n        self._cs = _s.acquire_contact_sensor_interface()\n        # self._create_contact_sensor()\n\n    def _initialize(self):\n        # Run super method first\n        super()._initialize()\n\n        # Get dynamic control and contact sensing interfaces\n        self._dc = _dynamic_control.acquire_dynamic_control_interface()\n\n        # Initialize all owned meshes\n        for mesh_group in (self._collision_meshes, self._visual_meshes):\n            for mesh in mesh_group.values():\n                mesh.initialize()\n\n        # Add enabled attribute for the rigid body\n        self._rigid_api.CreateRigidBodyEnabledAttr(True)\n\n        # We grab contact info for the first time before setting our internal handle, because this changes the dc handle\n        if self.contact_reporting_enabled:\n            self._cs.get_rigid_body_raw_data(self._prim_path)\n\n        # Grab handle to this rigid body and get name\n        self.update_handles()\n        self._body_name = self._dc.get_rigid_body_name(self._handle)\n\n    def update_meshes(self):\n        \"\"\"\n        Helper function to refresh owned visual and collision meshes. Useful for synchronizing internal data if\n        additional bodies are added manually\n        \"\"\"\n        # Make sure to clean up all pre-existing names for all collision_meshes\n        if self._collision_meshes is not None:\n            for collision_mesh in self._collision_meshes.values():\n                collision_mesh.remove_names()\n\n        # Make sure to clean up all pre-existing names for all visual_meshes\n        if self._visual_meshes is not None:\n            for visual_mesh in self._visual_meshes.values():\n                visual_mesh.remove_names()\n\n        self._collision_meshes, self._visual_meshes = OrderedDict(), OrderedDict()\n        prims_to_check = []\n        coms, vols = [], []\n        for prim in self._prim.GetChildren():\n            prims_to_check.append(prim)\n            for child in prim.GetChildren():\n                prims_to_check.append(child)\n        for prim in prims_to_check:\n            if prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\n                mesh_name, mesh_path = prim.GetName(), prim.GetPrimPath().__str__()\n                mesh_prim = get_prim_at_path(prim_path=mesh_path)\n                mesh_kwargs = {\"prim_path\": mesh_path, \"name\": f\"{self._name}:{mesh_name}\"}\n                if mesh_prim.HasAPI(UsdPhysics.CollisionAPI):\n                    mesh = CollisionGeomPrim(**mesh_kwargs)\n                    # We also modify the collision mesh's contact and rest offsets, since omni's default values result\n                    # in lightweight objects sometimes not triggering contacts correctly\n                    mesh.set_contact_offset(m.DEFAULT_CONTACT_OFFSET)\n                    mesh.set_rest_offset(m.DEFAULT_REST_OFFSET)\n                    self._collision_meshes[mesh_name] = mesh\n                    # We construct a trimesh object from this mesh in order to infer its center-of-mass and volume\n                    # TODO: Cleaner way to aggregate this information? Right now we just skip if we encounter a primitive\n                    mesh_vertices = mesh_prim.GetAttribute(\"points\").Get()\n                    if mesh_vertices is not None and len(mesh_vertices) &gt;= 4:\n                        msh = mesh_prim_to_trimesh_mesh(mesh_prim)\n                        coms.append(msh.center_mass)\n                        vols.append(msh.volume)\n                else:\n                    self._visual_meshes[mesh_name] = VisualGeomPrim(**mesh_kwargs)\n\n        # If we have any collision meshes, we aggregate their center of mass and volume values to set the center of mass\n        # for this link\n        if len(coms) &gt; 0:\n            com = (np.array(coms) * np.array(vols).reshape(-1, 1)).sum(axis=0) / np.sum(vols)\n            self.set_attribute(\"physics:centerOfMass\", Gf.Vec3f(*com))\n\n    def enable_collisions(self):\n        \"\"\"\n        Enable collisions for this RigidPrim\n        \"\"\"\n        # Iterate through all owned collision meshes and toggle on their collisions\n        for col_mesh in self._collision_meshes.values():\n            col_mesh.collision_enabled = True\n\n    def disable_collisions(self):\n        \"\"\"\n        Disable collisions for this RigidPrim\n        \"\"\"\n        # Iterate through all owned collision meshes and toggle off their collisions\n        for col_mesh in self._collision_meshes.values():\n            col_mesh.collision_enabled = False\n\n    def update_handles(self):\n        \"\"\"\n        Updates all internal handles for this prim, in case they change since initialization\n        \"\"\"\n        self._handle = self._dc.get_rigid_body(self._prim_path)\n\n    def contact_list(self):\n        \"\"\"\n        Get list of all current contacts with this rigid body\n\n        Returns:\n            list of CsRawData: raw contact info for this rigid body\n        \"\"\"\n        # # Make sure we have the ability to grab contacts for this object\n        # assert self._physx_contact_report_api is not None, \\\n        #     \"Cannot grab contacts for this rigid prim without Physx's contact report API being added!\"\n        contacts = []\n        if self.contact_reporting_enabled:\n            raw_data = self._cs.get_rigid_body_raw_data(self._prim_path)\n            for c in raw_data:\n                # contact sensor handles and dynamic articulation handles are not comparable\n                # every prim has a cs to convert (cs) handle to prim path (decode_body_name)\n                # but not every prim (e.g. groundPlane) has a dc to convert prim path to (dc) handle (get_rigid_body)\n                # so simpler to convert both handles (int) to prim paths (str) for comparison\n                c = [*c] # CsRawData enforces body0 and body1 types to be ints, but we want strings\n                c[2] = self._cs.decode_body_name(c[2])\n                c[3] = self._cs.decode_body_name(c[3])\n                contacts.append(CsRawData(*c))\n        return contacts\n\n    def set_linear_velocity(self, velocity):\n        \"\"\"\n        Sets the linear velocity of the prim in stage.\n\n        Args:\n            velocity (np.ndarray): linear velocity to set the rigid prim to. Shape (3,).\n        \"\"\"\n        if self.dc_is_accessible:\n            self._dc.set_rigid_body_linear_velocity(self._handle, velocity)\n        else:\n            self._rigid_api.GetVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\n        return\n\n    def get_linear_velocity(self):\n        \"\"\"\n        Returns:\n            np.ndarray: current linear velocity of the the rigid prim. Shape (3,).\n        \"\"\"\n        if self.dc_is_accessible:\n            lin_vel = np.array(self._dc.get_rigid_body_linear_velocity(self._handle))\n        else:\n            lin_vel = self._rigid_api.GetVelocityAttr().Get()\n        return np.array(lin_vel)\n\n    def set_angular_velocity(self, velocity):\n        \"\"\"\n        Sets the angular velocity of the prim in stage.\n\n        Args:\n            velocity (np.ndarray): angular velocity to set the rigid prim to. Shape (3,).\n        \"\"\"\n        if self.dc_is_accessible:\n            self._dc.set_rigid_body_angular_velocity(self._handle, velocity)\n        else:\n            self._rigid_api.GetAngularVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\n        return\n\n    def get_angular_velocity(self):\n        \"\"\"\n        Returns:\n            np.ndarray: current angular velocity of the the rigid prim. Shape (3,).\n        \"\"\"\n        if self.dc_is_accessible:\n            return np.array(self._dc.get_rigid_body_angular_velocity(self._handle))\n        else:\n            return np.array(self._rigid_api.GetAngularVelocityAttr().Get())\n\n    def set_position_orientation(self, position=None, orientation=None):\n        if self.dc_is_accessible:\n            current_position, current_orientation = self.get_position_orientation()\n            if position is None:\n                position = current_position\n            if orientation is None:\n                orientation = current_orientation\n            pose = _dynamic_control.Transform(position, orientation)\n            self._dc.set_rigid_body_pose(self._handle, pose)\n        else:\n            # Call super method by default\n            super().set_position_orientation(position=position, orientation=orientation)\n\n    def get_position_orientation(self):\n        if self.dc_is_accessible:\n            pose = self._dc.get_rigid_body_pose(self._handle)\n            pos, ori = np.asarray(pose.p), np.asarray(pose.r)\n        else:\n            # Call super method by default\n            pos, ori = super().get_position_orientation()\n\n        return np.array(pos), np.array(ori)\n\n    def set_local_pose(self, translation=None, orientation=None):\n        if self.dc_is_accessible:\n            current_translation, current_orientation = self.get_local_pose()\n            translation = current_translation if translation is None else translation\n            orientation = current_orientation if orientation is None else orientation\n            orientation = orientation[[3, 0, 1, 2]]  # Flip from x,y,z,w to w,x,y,z\n            local_transform = tf_matrix_from_pose(translation=translation, orientation=orientation)\n            parent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\n                Usd.TimeCode.Default()\n            )\n            my_world_transform = np.matmul(parent_world_tf, local_transform)\n            transform = Gf.Transform()\n            transform.SetMatrix(Gf.Matrix4d(np.transpose(my_world_transform)))\n            calculated_position = transform.GetTranslation()\n            calculated_orientation = transform.GetRotation().GetQuat()\n            self.set_position_orientation(\n                position=np.array(calculated_position), orientation=gf_quat_to_np_array(calculated_orientation)\n            )\n        else:\n            # Call super method by default\n            super().set_local_pose(translation=translation, orientation=orientation)\n\n    def get_local_pose(self):\n        if self.dc_is_accessible:\n            parent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(\n                Usd.TimeCode.Default()\n            )\n            world_position, world_orientation = self.get_position_orientation()\n            world_orientation = world_orientation[[3, 0, 1, 2]]  # Flip from x,y,z,w to w,x,y,z\n            my_world_transform = tf_matrix_from_pose(translation=world_position, orientation=world_orientation)\n            local_transform = np.matmul(np.linalg.inv(np.transpose(parent_world_tf)), my_world_transform)\n            transform = Gf.Transform()\n            transform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\n            calculated_translation = transform.GetTranslation()\n            calculated_orientation = transform.GetRotation().GetQuat()\n            pos, ori = np.array(calculated_translation), gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]] # Flip from w,x,y,z to x,y,z,w to\n        else:\n            # Call super method by default\n            pos, ori = super().get_local_pose()\n\n        return np.array(pos), np.array(ori)\n\n    @property\n    def handle(self):\n        \"\"\"\n        Handle used by Isaac Sim's dynamic control module to reference this rigid prim\n\n        Returns:\n            int: ID handle assigned to this prim from dynamic_control interface\n        \"\"\"\n        return self._handle\n\n    @property\n    def body_name(self):\n        \"\"\"\n        Returns:\n            str: Name of this body\n        \"\"\"\n        return self._body_name\n\n    @property\n    def collision_meshes(self):\n        \"\"\"\n        Returns:\n            OrderedDict: Dictionary mapping collision mesh names (str) to mesh prims (CollisionMeshPrim) owned by\n                this rigid body\n        \"\"\"\n        return self._collision_meshes\n\n    @property\n    def visual_meshes(self):\n        \"\"\"\n        Returns:\n            OrderedDict: Dictionary mapping visual mesh names (str) to mesh prims (VisualMeshPrim) owned by\n                this rigid body\n        \"\"\"\n        return self._visual_meshes\n\n    @property\n    def visual_only(self):\n        \"\"\"\n        Returns:\n            bool: Whether this link is a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\n        return self._visual_only\n\n    @visual_only.setter\n    def visual_only(self, val):\n        \"\"\"\n        Sets the visaul only state of this link\n\n        Args:\n            val (bool): Whether this link should be a visual-only link (i.e.: no gravity or collisions applied)\n        \"\"\"\n        # Set gravity and collisions based on value\n        if val:\n            self.disable_collisions()\n            self.disable_gravity()\n        else:\n            self.enable_collisions()\n            self.enable_gravity()\n\n        # Also set the internal value\n        self._visual_only = val\n\n    @property\n    def volume(self):\n        \"\"\"\n        Note: Currently it doesn't support Capsule type yet\n\n        Returns:\n            float: total volume of all the collision meshes of the rigid body in m^3.\n        \"\"\"\n        # TODO (eric): revise this once omni exposes API to query volume of GeomPrims\n        volume = 0.0\n        for collision_mesh in self._collision_meshes.values():\n            mesh = collision_mesh.prim\n            mesh_type = mesh.GetPrimTypeInfo().GetTypeName()\n            assert mesh_type in GEOM_TYPES, f\"Invalid collision mesh type: {mesh_type}\"\n            if mesh_type == \"Mesh\":\n                # We construct a trimesh object from this mesh in order to infer its volume\n                trimesh_mesh = mesh_prim_to_trimesh_mesh(mesh)\n                mesh_volume = trimesh_mesh.volume if trimesh_mesh.is_volume else trimesh_mesh.convex_hull.volume\n            elif mesh_type == \"Sphere\":\n                mesh_volume = 4 / 3 * np.pi * (mesh.GetAttribute(\"radius\").Get() ** 3)\n            elif mesh_type == \"Cube\":\n                mesh_volume = mesh.GetAttribute(\"size\").Get() ** 3\n            elif mesh_type == \"Cone\":\n                mesh_volume = np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get() / 3\n            elif mesh_type == \"Cylinder\":\n                mesh_volume = np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get()\n            else:\n                raise ValueError(f\"Cannot compute volume for mesh of type: {mesh_type}\")\n\n            volume += mesh_volume * np.product(collision_mesh.get_world_scale())\n\n        return volume\n\n    @volume.setter\n    def volume(self, volume):\n        raise NotImplementedError(\"Cannot set volume directly for an link!\")\n\n    @property\n    def mass(self):\n        \"\"\"\n        Returns:\n            float: mass of the rigid body in kg.\n        \"\"\"\n        raw_usd_mass = self._mass_api.GetMassAttr().Get()\n        # If our raw_usd_mass isn't specified, we check dynamic control if possible (sim is playing),\n        # otherwise we fallback to analytical computation of volume * density\n        if raw_usd_mass != 0:\n            mass = raw_usd_mass\n        elif self.dc_is_accessible:\n            mass = self.rigid_body_properties.mass\n        else:\n            mass = self.volume * self.density\n\n        return mass\n\n    @mass.setter\n    def mass(self, mass):\n        \"\"\"\n        Args:\n            mass (float): mass of the rigid body in kg.\n        \"\"\"\n        self._mass_api.GetMassAttr().Set(mass)\n\n    @property\n    def density(self):\n        \"\"\"\n        Returns:\n            float: density of the rigid body in kg / m^3.\n        \"\"\"\n        raw_usd_mass = self._mass_api.GetMassAttr().Get()\n        # We first check if the raw usd mass is specified, since mass overrides density\n        # If it's specified, we infer density based on that value divided by volume\n        # Otherwise, we try to directly grab the raw usd density value, and if that value\n        # does not exist, we return 1000 since that is the canonical density assigned by omniverse\n        if raw_usd_mass != 0:\n            density = raw_usd_mass / self.volume\n        else:\n            density = self._mass_api.GetDensityAttr().Get()\n            if density == 0:\n                density = 1000.0\n\n        return density\n\n    @density.setter\n    def density(self, density):\n        \"\"\"\n        Args:\n            density (float): density of the rigid body in kg / m^3.\n        \"\"\"\n        self._mass_api.GetDensityAttr().Set(density)\n\n    @property\n    def ccd_enabled(self):\n        \"\"\"\n        Returns:\n            bool: whether CCD is enabled or not for this link\n        \"\"\"\n        return self.get_attribute(\"physxRigidBody:enableCCD\")\n\n    @ccd_enabled.setter\n    def ccd_enabled(self, enabled):\n        \"\"\"\n        Args:\n            enabled (bool): whether CCD should be enabled or not for this link\n        \"\"\"\n        self.set_attribute(\"physxRigidBody:enableCCD\", enabled)\n\n    @property\n    def contact_reporting_enabled(self):\n        \"\"\"\n        Returns:\n            bool: Whether contact reporting is enabled for this rigid prim or not\n        \"\"\"\n        return self._prim.HasAPI(PhysxSchema.PhysxContactReportAPI)\n\n    @property\n    def rigid_body_properties(self):\n        \"\"\"\n        Returns:\n            None or RigidBodyProperty: Properties for this rigid body, if accessible. If they do not exist or\n                dc cannot be queried, this will return None\n        \"\"\"\n        return self._dc.get_rigid_body_properties(self._handle) if self.dc_is_accessible else None\n\n    @property\n    def dc_is_accessible(self):\n        \"\"\"\n        Checks if dynamic control interface is accessible (checks whether we have a dc handle for this body\n        and if dc is simulating)\n\n        Returns:\n            bool: Whether dc interface can be used or not\n        \"\"\"\n        return self._handle is not None and self._dc.is_simulating()\n\n    def enable_gravity(self):\n        \"\"\"\n        Enables gravity for this rigid body\n        \"\"\"\n        self.set_attribute(\"physxRigidBody:disableGravity\", False)\n        # self._dc.set_rigid_body_disable_gravity(self._handle, False)\n\n    def disable_gravity(self):\n        \"\"\"\n        Disables gravity for this rigid body\n        \"\"\"\n        self.set_attribute(\"physxRigidBody:disableGravity\", True)\n        # self._dc.set_rigid_body_disable_gravity(self._handle, True)\n\n    def wake(self):\n        \"\"\"\n        Enable physics for this rigid body\n        \"\"\"\n        self._dc.wake_up_rigid_body(self._handle)\n\n    def sleep(self):\n        \"\"\"\n        Disable physics for this rigid body\n        \"\"\"\n        self._dc.sleep_rigid_body(self._handle)\n\n    def _dump_state(self):\n        # Grab pose from super class\n        state = super()._dump_state()\n        state[\"lin_vel\"] = self.get_linear_velocity()\n        state[\"ang_vel\"] = self.get_angular_velocity()\n\n        return state\n\n    def _load_state(self, state):\n        # Call super first\n        super()._load_state(state=state)\n\n        # Set velocities\n        self.set_linear_velocity(np.array(state[\"lin_vel\"]))\n        self.set_angular_velocity(np.array(state[\"ang_vel\"]))\n\n    def _deserialize(self, state):\n        # Call supermethod first\n        state_dic, idx = super()._deserialize(state=state)\n        # We deserialize deterministically by knowing the order of values -- lin_vel, ang_vel\n        state_dic[\"lin_vel\"] = state[idx: idx+3]\n        state_dic[\"ang_vel\"] = state[idx + 3: idx + 6]\n\n        return state_dic, idx + 6\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim"},{"title":"<code>body_name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this body</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.body_name"},{"title":"<code>ccd_enabled</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>whether CCD is enabled or not for this link</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.ccd_enabled"},{"title":"<code>collision_meshes</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Dictionary mapping collision mesh names (str) to mesh prims (CollisionMeshPrim) owned by this rigid body</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.collision_meshes"},{"title":"<code>contact_reporting_enabled</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether contact reporting is enabled for this rigid prim or not</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.contact_reporting_enabled"},{"title":"<code>dc_is_accessible</code>  <code>property</code>","text":"<p>Checks if dynamic control interface is accessible (checks whether we have a dc handle for this body and if dc is simulating)</p> <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether dc interface can be used or not</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.dc_is_accessible"},{"title":"<code>density</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>density of the rigid body in kg / m^3.</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.density"},{"title":"<code>handle</code>  <code>property</code>","text":"<p>Handle used by Isaac Sim's dynamic control module to reference this rigid prim</p> <p>Returns:</p>    Name Type Description     <code>int</code>   <p>ID handle assigned to this prim from dynamic_control interface</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.handle"},{"title":"<code>mass</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>mass of the rigid body in kg.</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.mass"},{"title":"<code>rigid_body_properties</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or RigidBodyProperty: Properties for this rigid body, if accessible. If they do not exist or dc cannot be queried, this will return None</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.rigid_body_properties"},{"title":"<code>visual_meshes</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Dictionary mapping visual mesh names (str) to mesh prims (VisualMeshPrim) owned by this rigid body</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.visual_meshes"},{"title":"<code>visual_only</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this link is a visual-only link (i.e.: no gravity or collisions applied)</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.visual_only"},{"title":"<code>volume</code>  <code>writable</code> <code>property</code>","text":"<p>Note: Currently it doesn't support Capsule type yet</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>total volume of all the collision meshes of the rigid body in m^3.</p>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.volume"},{"title":"<code>contact_list()</code>","text":"<p>Get list of all current contacts with this rigid body</p> <p>Returns:</p>    Type Description       <p>list of CsRawData: raw contact info for this rigid body</p>     Source code in <code>prims/rigid_prim.py</code> <pre><code>def contact_list(self):\n    \"\"\"\n    Get list of all current contacts with this rigid body\n\n    Returns:\n        list of CsRawData: raw contact info for this rigid body\n    \"\"\"\n    # # Make sure we have the ability to grab contacts for this object\n    # assert self._physx_contact_report_api is not None, \\\n    #     \"Cannot grab contacts for this rigid prim without Physx's contact report API being added!\"\n    contacts = []\n    if self.contact_reporting_enabled:\n        raw_data = self._cs.get_rigid_body_raw_data(self._prim_path)\n        for c in raw_data:\n            # contact sensor handles and dynamic articulation handles are not comparable\n            # every prim has a cs to convert (cs) handle to prim path (decode_body_name)\n            # but not every prim (e.g. groundPlane) has a dc to convert prim path to (dc) handle (get_rigid_body)\n            # so simpler to convert both handles (int) to prim paths (str) for comparison\n            c = [*c] # CsRawData enforces body0 and body1 types to be ints, but we want strings\n            c[2] = self._cs.decode_body_name(c[2])\n            c[3] = self._cs.decode_body_name(c[3])\n            contacts.append(CsRawData(*c))\n    return contacts\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.contact_list"},{"title":"<code>disable_collisions()</code>","text":"<p>Disable collisions for this RigidPrim</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def disable_collisions(self):\n    \"\"\"\n    Disable collisions for this RigidPrim\n    \"\"\"\n    # Iterate through all owned collision meshes and toggle off their collisions\n    for col_mesh in self._collision_meshes.values():\n        col_mesh.collision_enabled = False\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.disable_collisions"},{"title":"<code>disable_gravity()</code>","text":"<p>Disables gravity for this rigid body</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def disable_gravity(self):\n    \"\"\"\n    Disables gravity for this rigid body\n    \"\"\"\n    self.set_attribute(\"physxRigidBody:disableGravity\", True)\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.disable_gravity"},{"title":"<code>enable_collisions()</code>","text":"<p>Enable collisions for this RigidPrim</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def enable_collisions(self):\n    \"\"\"\n    Enable collisions for this RigidPrim\n    \"\"\"\n    # Iterate through all owned collision meshes and toggle on their collisions\n    for col_mesh in self._collision_meshes.values():\n        col_mesh.collision_enabled = True\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.enable_collisions"},{"title":"<code>enable_gravity()</code>","text":"<p>Enables gravity for this rigid body</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def enable_gravity(self):\n    \"\"\"\n    Enables gravity for this rigid body\n    \"\"\"\n    self.set_attribute(\"physxRigidBody:disableGravity\", False)\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.enable_gravity"},{"title":"<code>get_angular_velocity()</code>","text":"<p>Returns:</p>    Type Description       <p>np.ndarray: current angular velocity of the the rigid prim. Shape (3,).</p>     Source code in <code>prims/rigid_prim.py</code> <pre><code>def get_angular_velocity(self):\n    \"\"\"\n    Returns:\n        np.ndarray: current angular velocity of the the rigid prim. Shape (3,).\n    \"\"\"\n    if self.dc_is_accessible:\n        return np.array(self._dc.get_rigid_body_angular_velocity(self._handle))\n    else:\n        return np.array(self._rigid_api.GetAngularVelocityAttr().Get())\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.get_angular_velocity"},{"title":"<code>get_linear_velocity()</code>","text":"<p>Returns:</p>    Type Description       <p>np.ndarray: current linear velocity of the the rigid prim. Shape (3,).</p>     Source code in <code>prims/rigid_prim.py</code> <pre><code>def get_linear_velocity(self):\n    \"\"\"\n    Returns:\n        np.ndarray: current linear velocity of the the rigid prim. Shape (3,).\n    \"\"\"\n    if self.dc_is_accessible:\n        lin_vel = np.array(self._dc.get_rigid_body_linear_velocity(self._handle))\n    else:\n        lin_vel = self._rigid_api.GetVelocityAttr().Get()\n    return np.array(lin_vel)\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.get_linear_velocity"},{"title":"<code>set_angular_velocity(velocity)</code>","text":"<p>Sets the angular velocity of the prim in stage.</p> <p>Parameters:</p>    Name Type Description Default     <code>velocity</code>  <code>np.ndarray</code>  <p>angular velocity to set the rigid prim to. Shape (3,).</p>  required      Source code in <code>prims/rigid_prim.py</code> <pre><code>def set_angular_velocity(self, velocity):\n    \"\"\"\n    Sets the angular velocity of the prim in stage.\n\n    Args:\n        velocity (np.ndarray): angular velocity to set the rigid prim to. Shape (3,).\n    \"\"\"\n    if self.dc_is_accessible:\n        self._dc.set_rigid_body_angular_velocity(self._handle, velocity)\n    else:\n        self._rigid_api.GetAngularVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\n    return\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.set_angular_velocity"},{"title":"<code>set_linear_velocity(velocity)</code>","text":"<p>Sets the linear velocity of the prim in stage.</p> <p>Parameters:</p>    Name Type Description Default     <code>velocity</code>  <code>np.ndarray</code>  <p>linear velocity to set the rigid prim to. Shape (3,).</p>  required      Source code in <code>prims/rigid_prim.py</code> <pre><code>def set_linear_velocity(self, velocity):\n    \"\"\"\n    Sets the linear velocity of the prim in stage.\n\n    Args:\n        velocity (np.ndarray): linear velocity to set the rigid prim to. Shape (3,).\n    \"\"\"\n    if self.dc_is_accessible:\n        self._dc.set_rigid_body_linear_velocity(self._handle, velocity)\n    else:\n        self._rigid_api.GetVelocityAttr().Set(Gf.Vec3f(velocity.tolist()))\n    return\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.set_linear_velocity"},{"title":"<code>sleep()</code>","text":"<p>Disable physics for this rigid body</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def sleep(self):\n    \"\"\"\n    Disable physics for this rigid body\n    \"\"\"\n    self._dc.sleep_rigid_body(self._handle)\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.sleep"},{"title":"<code>update_handles()</code>","text":"<p>Updates all internal handles for this prim, in case they change since initialization</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def update_handles(self):\n    \"\"\"\n    Updates all internal handles for this prim, in case they change since initialization\n    \"\"\"\n    self._handle = self._dc.get_rigid_body(self._prim_path)\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.update_handles"},{"title":"<code>update_meshes()</code>","text":"<p>Helper function to refresh owned visual and collision meshes. Useful for synchronizing internal data if additional bodies are added manually</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def update_meshes(self):\n    \"\"\"\n    Helper function to refresh owned visual and collision meshes. Useful for synchronizing internal data if\n    additional bodies are added manually\n    \"\"\"\n    # Make sure to clean up all pre-existing names for all collision_meshes\n    if self._collision_meshes is not None:\n        for collision_mesh in self._collision_meshes.values():\n            collision_mesh.remove_names()\n\n    # Make sure to clean up all pre-existing names for all visual_meshes\n    if self._visual_meshes is not None:\n        for visual_mesh in self._visual_meshes.values():\n            visual_mesh.remove_names()\n\n    self._collision_meshes, self._visual_meshes = OrderedDict(), OrderedDict()\n    prims_to_check = []\n    coms, vols = [], []\n    for prim in self._prim.GetChildren():\n        prims_to_check.append(prim)\n        for child in prim.GetChildren():\n            prims_to_check.append(child)\n    for prim in prims_to_check:\n        if prim.GetPrimTypeInfo().GetTypeName() in GEOM_TYPES:\n            mesh_name, mesh_path = prim.GetName(), prim.GetPrimPath().__str__()\n            mesh_prim = get_prim_at_path(prim_path=mesh_path)\n            mesh_kwargs = {\"prim_path\": mesh_path, \"name\": f\"{self._name}:{mesh_name}\"}\n            if mesh_prim.HasAPI(UsdPhysics.CollisionAPI):\n                mesh = CollisionGeomPrim(**mesh_kwargs)\n                # We also modify the collision mesh's contact and rest offsets, since omni's default values result\n                # in lightweight objects sometimes not triggering contacts correctly\n                mesh.set_contact_offset(m.DEFAULT_CONTACT_OFFSET)\n                mesh.set_rest_offset(m.DEFAULT_REST_OFFSET)\n                self._collision_meshes[mesh_name] = mesh\n                # We construct a trimesh object from this mesh in order to infer its center-of-mass and volume\n                # TODO: Cleaner way to aggregate this information? Right now we just skip if we encounter a primitive\n                mesh_vertices = mesh_prim.GetAttribute(\"points\").Get()\n                if mesh_vertices is not None and len(mesh_vertices) &gt;= 4:\n                    msh = mesh_prim_to_trimesh_mesh(mesh_prim)\n                    coms.append(msh.center_mass)\n                    vols.append(msh.volume)\n            else:\n                self._visual_meshes[mesh_name] = VisualGeomPrim(**mesh_kwargs)\n\n    # If we have any collision meshes, we aggregate their center of mass and volume values to set the center of mass\n    # for this link\n    if len(coms) &gt; 0:\n        com = (np.array(coms) * np.array(vols).reshape(-1, 1)).sum(axis=0) / np.sum(vols)\n        self.set_attribute(\"physics:centerOfMass\", Gf.Vec3f(*com))\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.update_meshes"},{"title":"<code>wake()</code>","text":"<p>Enable physics for this rigid body</p>  Source code in <code>prims/rigid_prim.py</code> <pre><code>def wake(self):\n    \"\"\"\n    Enable physics for this rigid body\n    \"\"\"\n    self._dc.wake_up_rigid_body(self._handle)\n</code></pre>","location":"reference/prims/rigid_prim.html#prims.rigid_prim.RigidPrim.wake"},{"title":"xform_prim","text":"","location":"reference/prims/xform_prim.html"},{"title":"<code>XFormPrim</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Provides high level functions to deal with an Xform prim and its attributes/ properties. If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at the specified prim path will be created when self.load(...) is called.</p>  the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init, <p>unless it is a non-root articulation link.</p>  <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime. For this xform prim, the below values can be specified:</p> <p>scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds     to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>      Source code in <code>prims/xform_prim.py</code> <pre><code>class XFormPrim(BasePrim):\n    \"\"\"\n    Provides high level functions to deal with an Xform prim and its attributes/ properties.\n    If there is an Xform prim present at the path, it will use it. Otherwise, a new XForm prim at\n    the specified prim path will be created when self.load(...) is called.\n\n    Note: the prim will have \"xformOp:orient\", \"xformOp:translate\" and \"xformOp:scale\" only post init,\n        unless it is a non-root articulation link.\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime. For this xform prim, the below values can be specified:\n\n            scale (None or float or 3-array): If specified, sets the scale for this object. A single number corresponds\n                to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.\n    \"\"\"\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        load_config=None,\n    ):\n        # Other values that will be filled in at runtime\n        self._binding_api = None\n        self._material = None\n        self._collision_filter_api = None\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _load(self, simulator=None):\n        # Define an Xform prim at the current stage, or the simulator's stage if specified\n        stage = get_current_stage()\n        prim = stage.DefinePrim(self._prim_path, \"Xform\")\n\n        return prim\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # Make sure all xforms have pose and scaling info\n        self._set_xform_properties()\n\n        # Create collision filter API\n        self._collision_filter_api = UsdPhysics.FilteredPairsAPI(self._prim) if \\\n            self._prim.HasAPI(UsdPhysics.FilteredPairsAPI) else UsdPhysics.FilteredPairsAPI.Apply(self._prim)\n\n        # Create binding API\n        self._binding_api = UsdShade.MaterialBindingAPI(self.prim) if \\\n            self._prim.HasAPI(UsdShade.MaterialBindingAPI) else UsdShade.MaterialBindingAPI.Apply(self.prim)\n\n        # Grab the attached material if it exists\n        if self.has_material():\n            self._material = MaterialPrim(\n                prim_path=self._binding_api.GetDirectBinding().GetMaterialPath().pathString,\n                name=f\"{self.name}:material\",\n            )\n\n        # Optionally set the scale and visibility\n        if \"scale\" in self._load_config and self._load_config[\"scale\"] is not None:\n            self.scale = self._load_config[\"scale\"]\n\n    def _set_xform_properties(self):\n        current_position, current_orientation = self.get_position_orientation()\n        properties_to_remove = [\n            \"xformOp:rotateX\",\n            \"xformOp:rotateXZY\",\n            \"xformOp:rotateY\",\n            \"xformOp:rotateYXZ\",\n            \"xformOp:rotateYZX\",\n            \"xformOp:rotateZ\",\n            \"xformOp:rotateZYX\",\n            \"xformOp:rotateZXY\",\n            \"xformOp:rotateXYZ\",\n            \"xformOp:transform\",\n        ]\n        prop_names = self.prim.GetPropertyNames()\n        xformable = UsdGeom.Xformable(self.prim)\n        xformable.ClearXformOpOrder()\n        # TODO: wont be able to delete props for non root links on articulated objects\n        for prop_name in prop_names:\n            if prop_name in properties_to_remove:\n                self.prim.RemoveProperty(prop_name)\n        if \"xformOp:scale\" not in prop_names:\n            xform_op_scale = xformable.AddXformOp(UsdGeom.XformOp.TypeScale, UsdGeom.XformOp.PrecisionDouble, \"\")\n            xform_op_scale.Set(Gf.Vec3d([1.0, 1.0, 1.0]))\n        else:\n            xform_op_scale = UsdGeom.XformOp(self._prim.GetAttribute(\"xformOp:scale\"))\n\n        if \"xformOp:translate\" not in prop_names:\n            xform_op_translate = xformable.AddXformOp(\n                UsdGeom.XformOp.TypeTranslate, UsdGeom.XformOp.PrecisionDouble, \"\"\n            )\n        else:\n            xform_op_translate = UsdGeom.XformOp(self._prim.GetAttribute(\"xformOp:translate\"))\n\n        if \"xformOp:orient\" not in prop_names:\n            xform_op_rot = xformable.AddXformOp(UsdGeom.XformOp.TypeOrient, UsdGeom.XformOp.PrecisionDouble, \"\")\n        else:\n            xform_op_rot = UsdGeom.XformOp(self._prim.GetAttribute(\"xformOp:orient\"))\n        xformable.SetXformOpOrder([xform_op_translate, xform_op_rot, xform_op_scale])\n\n        self.set_position_orientation(position=current_position, orientation=current_orientation)\n        new_position, new_orientation = self.get_position_orientation()\n        r1 = R.from_quat(current_orientation).as_matrix()\n        r2 = R.from_quat(new_orientation).as_matrix()\n        # Make sure setting is done correctly\n        assert np.allclose(new_position, current_position, atol=1e-4) and np.allclose(r1, r2, atol=1e-4), \\\n            f\"{self.prim_path}: old_pos: {current_position}, new_pos: {new_position}, \" \\\n            f\"old_orn: {current_orientation}, new_orn: {new_orientation}\"\n\n    def has_material(self):\n        \"\"\"\n        Returns:\n            bool: True if there is a visual material bound to this prim. False otherwise\n        \"\"\"\n        material_path = self._binding_api.GetDirectBinding().GetMaterialPath().pathString\n        return False if material_path == \"\" else True\n\n    def set_position_orientation(self, position=None, orientation=None):\n        \"\"\"\n        Sets prim's pose with respect to the world frame\n\n        Args:\n            position (None or 3-array): if specified, (x,y,z) position in the world frame\n                Default is None, which means left unchanged.\n            orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the world frame.\n                Default is None, which means left unchanged.\n        \"\"\"\n        current_position, current_orientation = self.get_position_orientation()\n        position = current_position if position is None else np.array(position, dtype=float)\n        orientation = current_orientation if orientation is None else np.array(orientation, dtype=float)\n        orientation = orientation[[3, 0, 1, 2]]     # Flip from x,y,z,w to w,x,y,z\n\n        mat = Gf.Transform()\n        mat.SetRotation(Gf.Rotation(Gf.Quatd(*orientation)))\n        mat.SetTranslation(Gf.Vec3d(*position))\n\n        # mat.SetScale(Gf.Vec3d(*(self.get_world_scale() / self.scale)))\n        # TODO (eric): understand why this (mat.setScale) works - this works empirically but it's unclear why.\n        mat.SetScale(Gf.Vec3d(*(self.scale.astype(np.float64))))\n        my_world_transform = np.transpose(mat.GetMatrix())\n\n        parent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\n        parent_world_transform = np.transpose(parent_world_tf)\n\n        local_transform = np.matmul(np.linalg.inv(parent_world_transform), my_world_transform)\n        transform = Gf.Transform()\n        transform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\n        calculated_translation = transform.GetTranslation()\n        calculated_orientation = transform.GetRotation().GetQuat()\n        self.set_local_pose(\n            translation=np.array(calculated_translation), orientation=gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]]     # Flip from w,x,y,z to x,y,z,w\n        )\n\n    def get_position_orientation(self):\n        \"\"\"\n        Gets prim's pose with respect to the world's frame.\n\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) position in the world frame\n                - 4-array: (x,y,z,w) quaternion orientation in the world frame\n        \"\"\"\n        prim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\n        transform = Gf.Transform()\n        transform.SetMatrix(prim_tf)\n        position = transform.GetTranslation()\n        orientation = transform.GetRotation().GetQuat()\n        return np.array(position), gf_quat_to_np_array(orientation)[[1, 2, 3, 0]]\n\n    def set_position(self, position):\n        \"\"\"\n        Set this prim's position with respect to the world frame\n\n        Args:\n            position (3-array): (x,y,z) global cartesian position to set\n        \"\"\"\n        self.set_position_orientation(position=position)\n\n    def get_position(self):\n        \"\"\"\n        Get this prim's position with respect to the world frame\n\n        Returns:\n            3-array: (x,y,z) global cartesian position of this prim\n        \"\"\"\n        return self.get_position_orientation()[0]\n\n    def set_orientation(self, orientation):\n        \"\"\"\n        Set this prim's orientation with respect to the world frame\n\n        Args:\n            orientation (4-array): (x,y,z,w) global quaternion orientation to set\n        \"\"\"\n        self.set_position_orientation(orientation=orientation)\n\n    def get_orientation(self):\n        \"\"\"\n        Get this prim's orientation with respect to the world frame\n\n        Returns:\n            4-array: (x,y,z,w) global quaternion orientation of this prim\n        \"\"\"\n        return self.get_position_orientation()[1]\n\n    def get_rpy(self):\n        \"\"\"\n        Get this prim's orientation with respect to the world frame\n\n        Returns:\n            3-array: (roll, pitch, yaw) global euler orientation of this prim\n        \"\"\"\n        return mat2euler(quat2mat(self.get_orientation()))\n\n    def get_local_pose(self):\n        \"\"\"\n        Gets prim's pose with respect to the prim's local frame (it's parent frame)\n\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) position in the local frame\n                - 4-array: (x,y,z,w) quaternion orientation in the local frame\n        \"\"\"\n        xform_translate_op = self.get_attribute(\"xformOp:translate\")\n        xform_orient_op = self.get_attribute(\"xformOp:orient\")\n        return np.array(xform_translate_op), gf_quat_to_np_array(xform_orient_op)[[1, 2, 3, 0]]\n\n    def set_local_pose(self, translation=None, orientation=None):\n        \"\"\"\n        Sets prim's pose with respect to the local frame (the prim's parent frame).\n\n        Args:\n            translation (None or 3-array): if specified, (x,y,z) translation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n            orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the local frame of the prim\n                (with respect to its parent prim). Default is None, which means left unchanged.\n        \"\"\"\n        properties = self.prim.GetPropertyNames()\n        if translation is not None:\n            translation = Gf.Vec3d(*np.array(translation, dtype=float))\n            if \"xformOp:translate\" not in properties:\n                carb.log_error(\n                    \"Translate property needs to be set for {} before setting its position\".format(self.name)\n                )\n            self.set_attribute(\"xformOp:translate\", translation)\n        if orientation is not None:\n            orientation = np.array(orientation, dtype=float)[[3, 0, 1, 2]]\n            if \"xformOp:orient\" not in properties:\n                carb.log_error(\n                    \"Orient property needs to be set for {} before setting its orientation\".format(self.name)\n                )\n            xform_op = self._prim.GetAttribute(\"xformOp:orient\")\n            if xform_op.GetTypeName() == \"quatf\":\n                rotq = Gf.Quatf(*orientation)\n            else:\n                rotq = Gf.Quatd(*orientation)\n            xform_op.Set(rotq)\n        return\n\n    def get_world_scale(self):\n        \"\"\"\n        Gets prim's scale with respect to the world's frame.\n\n        Returns:\n            np.ndarray: scale applied to the prim's dimensions in the world frame. shape is (3, ).\n        \"\"\"\n        prim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\n        transform = Gf.Transform()\n        transform.SetMatrix(prim_tf)\n        return np.array(transform.GetScale())\n\n    @property\n    def scale(self):\n        \"\"\"\n        Gets prim's scale with respect to the local frame (the parent's frame).\n\n        Returns:\n            np.ndarray: scale applied to the prim's dimensions in the local frame. shape is (3, ).\n        \"\"\"\n        return np.array(self.get_attribute(\"xformOp:scale\"))\n\n    @scale.setter\n    def scale(self, scale):\n        \"\"\"\n        Sets prim's scale with respect to the local frame (the prim's parent frame).\n\n        Args:\n            scale (float or np.ndarray): scale to be applied to the prim's dimensions. shape is (3, ).\n                                          Defaults to None, which means left unchanged.\n        \"\"\"\n        scale = np.array(scale, dtype=float) if isinstance(scale, Iterable) else np.ones(3) * scale\n        scale = Gf.Vec3d(*scale)\n        properties = self.prim.GetPropertyNames()\n        if \"xformOp:scale\" not in properties:\n            carb.log_error(\"Scale property needs to be set for {} before setting its scale\".format(self.name))\n        self.set_attribute(\"xformOp:scale\", scale)\n\n    @property\n    def aabb(self):\n        \"\"\"\n        Get this xform's actual bounding box, axis-aligned in the world frame\n\n        Returns:\n            2-tuple:\n                - 3-array: (x,y,z) lower corner of the bounding box\n                - 3-array: (x,y,z) upper corner of the bounding box\n        \"\"\"\n        return BoundingBoxAPI.compute_aabb(self.prim_path)\n\n    @property\n    def aabb_extent(self):\n        \"\"\"\n        Get this xform's actual bounding box extent\n\n        Returns:\n            3-array: (x,y,z) bounding box\n        \"\"\"\n        min_corner, max_corner = self.aabb\n        return max_corner - min_corner\n\n    @property\n    def aabb_center(self):\n        \"\"\"\n        Get this xform's actual bounding box center\n\n        Returns:\n            3-array: (x,y,z) bounding box center\n        \"\"\"\n        min_corner, max_corner = self.aabb\n        return (max_corner + min_corner) / 2.0\n\n    @property\n    def material(self):\n        \"\"\"\n        Returns:\n            None or MaterialPrim: The bound material to this prim, if there is one\n        \"\"\"\n        return self._material\n\n    @material.setter\n    def material(self, material):\n        \"\"\"\n        Set the material @material for this prim. This will also bind the material to this prim\n\n        Args:\n            material (MaterialPrim): Material to bind to this prim\n        \"\"\"\n        self._binding_api.Bind(UsdShade.Material(material.prim), bindingStrength=UsdShade.Tokens.weakerThanDescendants)\n        self._material = material\n\n    def add_filtered_collision_pair(self, prim):\n        \"\"\"\n        Adds a collision filter pair with another prim\n\n        Args:\n            prim (XFormPrim): Another prim to filter collisions with\n        \"\"\"\n        # Add to both this prim's and the other prim's filtered pair\n        self._collision_filter_api.GetFilteredPairsRel().AddTarget(prim.prim_path)\n        prim._collision_filter_api.GetFilteredPairsRel().AddTarget(self._prim_path)\n\n    def remove_filtered_collision_pair(self, prim):\n        \"\"\"\n        Removes a collision filter pair with another prim\n\n        Args:\n            prim (XFormPrim): Another prim to remove filter collisions with\n        \"\"\"\n        # Add to both this prim's and the other prim's filtered pair\n        self._collision_filter_api.GetFilteredPairsRel().RemoveTarget(prim.prim_path)\n        prim._collision_filter_api.GetFilteredPairsRel().RemoveTarget(self._prim_path)\n\n    def _dump_state(self):\n        pos, ori = self.get_position_orientation()\n        return OrderedDict(pos=pos, ori=ori)\n\n    def _load_state(self, state):\n        self.set_position_orientation(np.array(state[\"pos\"]), np.array(state[\"ori\"]))\n\n    def _serialize(self, state):\n        # We serialize by iterating over the keys and adding them to a list that's concatenated at the end\n        # This is a deterministic mapping because we assume the state is an OrderedDict\n        return np.concatenate(list(state.values())).astype(float)\n\n    def _deserialize(self, state):\n        # We deserialize deterministically by knowing the order of values -- pos, ori\n        return OrderedDict(pos=state[0:3], ori=state[3:7]), 7\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim"},{"title":"<code>aabb</code>  <code>property</code>","text":"<p>Get this xform's actual bounding box, axis-aligned in the world frame</p> <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: (x,y,z) lower corner of the bounding box - 3-array: (x,y,z) upper corner of the bounding box</p>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.aabb"},{"title":"<code>aabb_center</code>  <code>property</code>","text":"<p>Get this xform's actual bounding box center</p> <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) bounding box center</p>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.aabb_center"},{"title":"<code>aabb_extent</code>  <code>property</code>","text":"<p>Get this xform's actual bounding box extent</p> <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) bounding box</p>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.aabb_extent"},{"title":"<code>material</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or MaterialPrim: The bound material to this prim, if there is one</p>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.material"},{"title":"<code>scale</code>  <code>writable</code> <code>property</code>","text":"<p>Gets prim's scale with respect to the local frame (the parent's frame).</p> <p>Returns:</p>    Type Description       <p>np.ndarray: scale applied to the prim's dimensions in the local frame. shape is (3, ).</p>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.scale"},{"title":"<code>add_filtered_collision_pair(prim)</code>","text":"<p>Adds a collision filter pair with another prim</p> <p>Parameters:</p>    Name Type Description Default     <code>prim</code>  <code>XFormPrim</code>  <p>Another prim to filter collisions with</p>  required      Source code in <code>prims/xform_prim.py</code> <pre><code>def add_filtered_collision_pair(self, prim):\n    \"\"\"\n    Adds a collision filter pair with another prim\n\n    Args:\n        prim (XFormPrim): Another prim to filter collisions with\n    \"\"\"\n    # Add to both this prim's and the other prim's filtered pair\n    self._collision_filter_api.GetFilteredPairsRel().AddTarget(prim.prim_path)\n    prim._collision_filter_api.GetFilteredPairsRel().AddTarget(self._prim_path)\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.add_filtered_collision_pair"},{"title":"<code>get_local_pose()</code>","text":"<p>Gets prim's pose with respect to the prim's local frame (it's parent frame)</p> <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: (x,y,z) position in the local frame - 4-array: (x,y,z,w) quaternion orientation in the local frame</p>     Source code in <code>prims/xform_prim.py</code> <pre><code>def get_local_pose(self):\n    \"\"\"\n    Gets prim's pose with respect to the prim's local frame (it's parent frame)\n\n    Returns:\n        2-tuple:\n            - 3-array: (x,y,z) position in the local frame\n            - 4-array: (x,y,z,w) quaternion orientation in the local frame\n    \"\"\"\n    xform_translate_op = self.get_attribute(\"xformOp:translate\")\n    xform_orient_op = self.get_attribute(\"xformOp:orient\")\n    return np.array(xform_translate_op), gf_quat_to_np_array(xform_orient_op)[[1, 2, 3, 0]]\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_local_pose"},{"title":"<code>get_orientation()</code>","text":"<p>Get this prim's orientation with respect to the world frame</p> <p>Returns:</p>    Type Description       <p>4-array: (x,y,z,w) global quaternion orientation of this prim</p>     Source code in <code>prims/xform_prim.py</code> <pre><code>def get_orientation(self):\n    \"\"\"\n    Get this prim's orientation with respect to the world frame\n\n    Returns:\n        4-array: (x,y,z,w) global quaternion orientation of this prim\n    \"\"\"\n    return self.get_position_orientation()[1]\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_orientation"},{"title":"<code>get_position()</code>","text":"<p>Get this prim's position with respect to the world frame</p> <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) global cartesian position of this prim</p>     Source code in <code>prims/xform_prim.py</code> <pre><code>def get_position(self):\n    \"\"\"\n    Get this prim's position with respect to the world frame\n\n    Returns:\n        3-array: (x,y,z) global cartesian position of this prim\n    \"\"\"\n    return self.get_position_orientation()[0]\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_position"},{"title":"<code>get_position_orientation()</code>","text":"<p>Gets prim's pose with respect to the world's frame.</p> <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: (x,y,z) position in the world frame - 4-array: (x,y,z,w) quaternion orientation in the world frame</p>     Source code in <code>prims/xform_prim.py</code> <pre><code>def get_position_orientation(self):\n    \"\"\"\n    Gets prim's pose with respect to the world's frame.\n\n    Returns:\n        2-tuple:\n            - 3-array: (x,y,z) position in the world frame\n            - 4-array: (x,y,z,w) quaternion orientation in the world frame\n    \"\"\"\n    prim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\n    transform = Gf.Transform()\n    transform.SetMatrix(prim_tf)\n    position = transform.GetTranslation()\n    orientation = transform.GetRotation().GetQuat()\n    return np.array(position), gf_quat_to_np_array(orientation)[[1, 2, 3, 0]]\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_position_orientation"},{"title":"<code>get_rpy()</code>","text":"<p>Get this prim's orientation with respect to the world frame</p> <p>Returns:</p>    Type Description       <p>3-array: (roll, pitch, yaw) global euler orientation of this prim</p>     Source code in <code>prims/xform_prim.py</code> <pre><code>def get_rpy(self):\n    \"\"\"\n    Get this prim's orientation with respect to the world frame\n\n    Returns:\n        3-array: (roll, pitch, yaw) global euler orientation of this prim\n    \"\"\"\n    return mat2euler(quat2mat(self.get_orientation()))\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_rpy"},{"title":"<code>get_world_scale()</code>","text":"<p>Gets prim's scale with respect to the world's frame.</p> <p>Returns:</p>    Type Description       <p>np.ndarray: scale applied to the prim's dimensions in the world frame. shape is (3, ).</p>     Source code in <code>prims/xform_prim.py</code> <pre><code>def get_world_scale(self):\n    \"\"\"\n    Gets prim's scale with respect to the world's frame.\n\n    Returns:\n        np.ndarray: scale applied to the prim's dimensions in the world frame. shape is (3, ).\n    \"\"\"\n    prim_tf = UsdGeom.Xformable(self._prim).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\n    transform = Gf.Transform()\n    transform.SetMatrix(prim_tf)\n    return np.array(transform.GetScale())\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.get_world_scale"},{"title":"<code>has_material()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if there is a visual material bound to this prim. False otherwise</p>     Source code in <code>prims/xform_prim.py</code> <pre><code>def has_material(self):\n    \"\"\"\n    Returns:\n        bool: True if there is a visual material bound to this prim. False otherwise\n    \"\"\"\n    material_path = self._binding_api.GetDirectBinding().GetMaterialPath().pathString\n    return False if material_path == \"\" else True\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.has_material"},{"title":"<code>remove_filtered_collision_pair(prim)</code>","text":"<p>Removes a collision filter pair with another prim</p> <p>Parameters:</p>    Name Type Description Default     <code>prim</code>  <code>XFormPrim</code>  <p>Another prim to remove filter collisions with</p>  required      Source code in <code>prims/xform_prim.py</code> <pre><code>def remove_filtered_collision_pair(self, prim):\n    \"\"\"\n    Removes a collision filter pair with another prim\n\n    Args:\n        prim (XFormPrim): Another prim to remove filter collisions with\n    \"\"\"\n    # Add to both this prim's and the other prim's filtered pair\n    self._collision_filter_api.GetFilteredPairsRel().RemoveTarget(prim.prim_path)\n    prim._collision_filter_api.GetFilteredPairsRel().RemoveTarget(self._prim_path)\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.remove_filtered_collision_pair"},{"title":"<code>set_local_pose(translation=None, orientation=None)</code>","text":"<p>Sets prim's pose with respect to the local frame (the prim's parent frame).</p> <p>Parameters:</p>    Name Type Description Default     <code>translation</code>  <code>None or 3-array</code>  <p>if specified, (x,y,z) translation in the local frame of the prim (with respect to its parent prim). Default is None, which means left unchanged.</p>  <code>None</code>    <code>orientation</code>  <code>None or 4-array</code>  <p>if specified, (x,y,z,w) quaternion orientation in the local frame of the prim (with respect to its parent prim). Default is None, which means left unchanged.</p>  <code>None</code>      Source code in <code>prims/xform_prim.py</code> <pre><code>def set_local_pose(self, translation=None, orientation=None):\n    \"\"\"\n    Sets prim's pose with respect to the local frame (the prim's parent frame).\n\n    Args:\n        translation (None or 3-array): if specified, (x,y,z) translation in the local frame of the prim\n            (with respect to its parent prim). Default is None, which means left unchanged.\n        orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the local frame of the prim\n            (with respect to its parent prim). Default is None, which means left unchanged.\n    \"\"\"\n    properties = self.prim.GetPropertyNames()\n    if translation is not None:\n        translation = Gf.Vec3d(*np.array(translation, dtype=float))\n        if \"xformOp:translate\" not in properties:\n            carb.log_error(\n                \"Translate property needs to be set for {} before setting its position\".format(self.name)\n            )\n        self.set_attribute(\"xformOp:translate\", translation)\n    if orientation is not None:\n        orientation = np.array(orientation, dtype=float)[[3, 0, 1, 2]]\n        if \"xformOp:orient\" not in properties:\n            carb.log_error(\n                \"Orient property needs to be set for {} before setting its orientation\".format(self.name)\n            )\n        xform_op = self._prim.GetAttribute(\"xformOp:orient\")\n        if xform_op.GetTypeName() == \"quatf\":\n            rotq = Gf.Quatf(*orientation)\n        else:\n            rotq = Gf.Quatd(*orientation)\n        xform_op.Set(rotq)\n    return\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_local_pose"},{"title":"<code>set_orientation(orientation)</code>","text":"<p>Set this prim's orientation with respect to the world frame</p> <p>Parameters:</p>    Name Type Description Default     <code>orientation</code>  <code>4-array</code>  <p>(x,y,z,w) global quaternion orientation to set</p>  required      Source code in <code>prims/xform_prim.py</code> <pre><code>def set_orientation(self, orientation):\n    \"\"\"\n    Set this prim's orientation with respect to the world frame\n\n    Args:\n        orientation (4-array): (x,y,z,w) global quaternion orientation to set\n    \"\"\"\n    self.set_position_orientation(orientation=orientation)\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_orientation"},{"title":"<code>set_position(position)</code>","text":"<p>Set this prim's position with respect to the world frame</p> <p>Parameters:</p>    Name Type Description Default     <code>position</code>  <code>3-array</code>  <p>(x,y,z) global cartesian position to set</p>  required      Source code in <code>prims/xform_prim.py</code> <pre><code>def set_position(self, position):\n    \"\"\"\n    Set this prim's position with respect to the world frame\n\n    Args:\n        position (3-array): (x,y,z) global cartesian position to set\n    \"\"\"\n    self.set_position_orientation(position=position)\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_position"},{"title":"<code>set_position_orientation(position=None, orientation=None)</code>","text":"<p>Sets prim's pose with respect to the world frame</p> <p>Parameters:</p>    Name Type Description Default     <code>position</code>  <code>None or 3-array</code>  <p>if specified, (x,y,z) position in the world frame Default is None, which means left unchanged.</p>  <code>None</code>    <code>orientation</code>  <code>None or 4-array</code>  <p>if specified, (x,y,z,w) quaternion orientation in the world frame. Default is None, which means left unchanged.</p>  <code>None</code>      Source code in <code>prims/xform_prim.py</code> <pre><code>def set_position_orientation(self, position=None, orientation=None):\n    \"\"\"\n    Sets prim's pose with respect to the world frame\n\n    Args:\n        position (None or 3-array): if specified, (x,y,z) position in the world frame\n            Default is None, which means left unchanged.\n        orientation (None or 4-array): if specified, (x,y,z,w) quaternion orientation in the world frame.\n            Default is None, which means left unchanged.\n    \"\"\"\n    current_position, current_orientation = self.get_position_orientation()\n    position = current_position if position is None else np.array(position, dtype=float)\n    orientation = current_orientation if orientation is None else np.array(orientation, dtype=float)\n    orientation = orientation[[3, 0, 1, 2]]     # Flip from x,y,z,w to w,x,y,z\n\n    mat = Gf.Transform()\n    mat.SetRotation(Gf.Rotation(Gf.Quatd(*orientation)))\n    mat.SetTranslation(Gf.Vec3d(*position))\n\n    # mat.SetScale(Gf.Vec3d(*(self.get_world_scale() / self.scale)))\n    # TODO (eric): understand why this (mat.setScale) works - this works empirically but it's unclear why.\n    mat.SetScale(Gf.Vec3d(*(self.scale.astype(np.float64))))\n    my_world_transform = np.transpose(mat.GetMatrix())\n\n    parent_world_tf = UsdGeom.Xformable(get_prim_parent(self._prim)).ComputeLocalToWorldTransform(Usd.TimeCode.Default())\n    parent_world_transform = np.transpose(parent_world_tf)\n\n    local_transform = np.matmul(np.linalg.inv(parent_world_transform), my_world_transform)\n    transform = Gf.Transform()\n    transform.SetMatrix(Gf.Matrix4d(np.transpose(local_transform)))\n    calculated_translation = transform.GetTranslation()\n    calculated_orientation = transform.GetRotation().GetQuat()\n    self.set_local_pose(\n        translation=np.array(calculated_translation), orientation=gf_quat_to_np_array(calculated_orientation)[[1, 2, 3, 0]]     # Flip from w,x,y,z to x,y,z,w\n    )\n</code></pre>","location":"reference/prims/xform_prim.html#prims.xform_prim.XFormPrim.set_position_orientation"},{"title":"renderer_settings","text":"","location":"reference/renderer_settings/index.html"},{"title":"common_settings","text":"","location":"reference/renderer_settings/common_settings.html"},{"title":"<code>CommonSettings</code>","text":"<p>         Bases: <code>SettingsBase</code></p> <p>Common setting group that handles a variety of sub-settings, including:     - Rendering     - Geometry     - Materials     - Lighting     - Simple Fog     - Flow     - Debug View</p>  Source code in <code>renderer_settings/common_settings.py</code> <pre><code>class CommonSettings(SettingsBase):\n    \"\"\"\n    Common setting group that handles a variety of sub-settings, including:\n        - Rendering\n        - Geometry\n        - Materials\n        - Lighting\n        - Simple Fog\n        - Flow\n        - Debug View\n    \"\"\"\n\n    def __init__(self):\n        self.render_settings = RenderSettings()\n        self.geometry_settings = GeometrySettings()\n        self.materials_settings = MaterialsSettings()\n        self.lighting_settings = LightingSettings()\n        self.simple_fog_setting = SimpleFogSettings()\n        self.flow_settings = FlowSettings()\n        self.debug_view_settings = DebugViewSettings()\n\n    @property\n    def settings(self):\n        settings = {}\n        settings.update(self.render_settings.settings)\n        settings.update(self.geometry_settings.settings)\n        settings.update(self.materials_settings.settings)\n        settings.update(self.lighting_settings.settings)\n        settings.update(self.simple_fog_setting.settings)\n        settings.update(self.flow_settings.settings)\n        settings.update(self.debug_view_settings.settings)\n        return settings\n</code></pre>","location":"reference/renderer_settings/common_settings.html#renderer_settings.common_settings.CommonSettings"},{"title":"path_tracing_settings","text":"","location":"reference/renderer_settings/path_tracing_settings.html"},{"title":"post_processing_settings","text":"","location":"reference/renderer_settings/post_processing_settings.html"},{"title":"<code>PostProcessingSettings</code>","text":"<p>         Bases: <code>SettingsBase</code></p> <p>Post-Processing setting group that handles a variety of sub-settings, including:     - Tone Mapping     - Auto Exposure     - Color Correction     - Color Grading     - XR Compositing     - Chromatic Aberration     - Depth Of Field Camera Overrides     - Motion Blur     - FTT Bloom     - TV Noise &amp; Film Grain     - Reshade</p>  Source code in <code>renderer_settings/post_processing_settings.py</code> <pre><code>class PostProcessingSettings(SettingsBase):\n    \"\"\"\n    Post-Processing setting group that handles a variety of sub-settings, including:\n        - Tone Mapping\n        - Auto Exposure\n        - Color Correction\n        - Color Grading\n        - XR Compositing\n        - Chromatic Aberration\n        - Depth Of Field Camera Overrides\n        - Motion Blur\n        - FTT Bloom\n        - TV Noise &amp; Film Grain\n        - Reshade\n    \"\"\"\n\n    def __init__(self):\n        self.tone_mapping_settings = ToneMappingSettings()\n        self.auto_exposure_settings = AutoExposureSettings()\n        self.color_correction_settings = ColorCorrectionSettings()\n        self.color_grading_settings = ColorGradingSettings()\n        self.xr_compositing_settings = XRCompositingSettings()\n        self.chromatic_aberration_settings = ChromaticAberrationSettings()\n        self.depth_of_field_settings = DepthOfFieldSettings()\n        self.motion_blur_settings = MotionBlurSettings()\n        self.ftt_bloom_settings = FTTBloomSettings()\n        self.tv_noise_grain_settings = TVNoiseGrainSettings()\n        self.reshade_settings = ReshadeSettings()\n\n    @property\n    def settings(self):\n        settings = {}\n        settings.update(self.tone_mapping_settings.settings)\n        settings.update(self.auto_exposure_settings.settings)\n        settings.update(self.color_correction_settings.settings)\n        settings.update(self.color_grading_settings.settings)\n        settings.update(self.xr_compositing_settings.settings)\n        settings.update(self.chromatic_aberration_settings.settings)\n        settings.update(self.depth_of_field_settings.settings)\n        settings.update(self.motion_blur_settings.settings)\n        settings.update(self.ftt_bloom_settings.settings)\n        settings.update(self.tv_noise_grain_settings.settings)\n        settings.update(self.reshade_settings.settings)\n        return settings\n</code></pre>","location":"reference/renderer_settings/post_processing_settings.html#renderer_settings.post_processing_settings.PostProcessingSettings"},{"title":"real_time_settings","text":"","location":"reference/renderer_settings/real_time_settings.html"},{"title":"<code>RealTimeSettings</code>","text":"<p>         Bases: <code>SettingsBase</code></p> <p>Real-Time setting group that handles a variety of sub-settings, including:     - Eco Mode     - Anti Aliasing     - Direct Lighting     - Reflections     - Translucency     - Global Volumetric Effects     - Caustics     - Indirect Diffuse Lighting     - RTMulti GPU (if multiple GPUs available)</p>  Source code in <code>renderer_settings/real_time_settings.py</code> <pre><code>class RealTimeSettings(SettingsBase):\n    \"\"\"\n    Real-Time setting group that handles a variety of sub-settings, including:\n        - Eco Mode\n        - Anti Aliasing\n        - Direct Lighting\n        - Reflections\n        - Translucency\n        - Global Volumetric Effects\n        - Caustics\n        - Indirect Diffuse Lighting\n        - RTMulti GPU (if multiple GPUs available)\n    \"\"\"\n\n    def __init__(self):\n        self.eco_mode_settings = EcoModeSettings()\n        self.anti_aliasing_settings = AntiAliasingSettings()\n        self.direct_lighting_settings = DirectLightingSettings()\n        self.reflections_settings = ReflectionsSettings()\n        self.translucency_settings = TranslucencySettings()\n        self.global_volumetric_effects_settings = GlobalVolumetricEffectsSettings()\n        self.caustics_settings = CausticsSettings()\n        self.indirect_diffuse_lighting_settings = IndirectDiffuseLightingSettings()\n        gpu_count = carb.settings.get_settings().get(\"/renderer/multiGpu/currentGpuCount\")\n        if gpu_count and gpu_count &gt; 1:\n            self.rt_multi_gpu_settings = RTMultiGPUSettings()\n\n    @property\n    def settings(self):\n        settings = {}\n        settings.update(self.eco_mode_settings.settings)\n        settings.update(self.anti_aliasing_settings.settings)\n        settings.update(self.direct_lighting_settings.settings)\n        settings.update(self.reflections_settings.settings)\n        settings.update(self.translucency_settings.settings)\n        settings.update(self.global_volumetric_effects_settings.settings)\n        settings.update(self.caustics_settings.settings)\n        settings.update(self.indirect_diffuse_lighting_settings.settings)\n        gpu_count = carb.settings.get_settings().get(\"/renderer/multiGpu/currentGpuCount\")\n        if gpu_count and gpu_count &gt; 1:\n            settings.update(self.rt_multi_gpu_settings.settings)\n        return settings\n</code></pre>","location":"reference/renderer_settings/real_time_settings.html#renderer_settings.real_time_settings.RealTimeSettings"},{"title":"renderer_settings","text":"","location":"reference/renderer_settings/renderer_settings.html"},{"title":"<code>RendererSettings</code>","text":"<p>Controller for all renderer settings.</p>  Source code in <code>renderer_settings/renderer_settings.py</code> <pre><code>@singleton\nclass RendererSettings:\n    \"\"\"\n    Controller for all renderer settings.\n    \"\"\"\n\n    def __init__(self):\n        self._carb_settings = carb.settings.get_settings()\n        self.common_settings = CommonSettings()\n        self.path_tracing_settings = PathTracingSettings()\n        self.post_processing_settings = PostProcessingSettings()\n        self.real_time_settings = RealTimeSettings()\n\n    def set_setting(self, path, value):\n        \"\"\"\n        Sets setting @path with value @value.\n\n        Args:\n            path (str): Path of the setting to set.\n            value (any): Value to set for for setting @path.\n        \"\"\"\n        if path not in self.settings:\n            raise NotImplementedError(f\"Setting {path} is not supported.\")\n        self.settings[path].set(value)\n\n    def reset_setting(self, path):\n        \"\"\"\n        Resets setting @path to default value.\n\n        Args:\n            path (str): Path of the setting to reset.\n        \"\"\"\n        if path not in self.settings:\n            raise NotImplementedError(f\"Setting {path} is not supported.\")\n        self.settings[path].reset()\n\n    def get_setting_from_path(self, path):\n        \"\"\"\n        Get the value of setting @path.\n\n        Args:\n            path (str): Path of the setting to get.\n\n        Returns:\n            any: Value of the requested setting @path.\n        \"\"\"\n        return self._carb_settings.get(path)\n\n    def get_current_renderer(self):\n        \"\"\"\n        Get the current renderer.\n\n        Args:\n            path (str): Path of the setting to get.\n\n        Returns:\n            str: the current renderer.\n        \"\"\"\n        return RendererSettingsFactory.get_current_renderer()\n\n    def set_current_renderer(self, renderer):\n        \"\"\"\n        Set the current renderer to @renderer.\n\n        Args:\n            renderer (str): The renderer to set as current (e.g. Real-Time, Path-Traced).\n        \"\"\"\n        assert (\n            renderer in RendererSettingsFactory.get_registered_renderers()\n        ), f\"renderer must be one of {RendererSettingsFactory.get_registered_renderers()}\"\n        print(f\"Set current renderer to {renderer}.\")\n        RendererSettingsFactory.set_current_renderer(renderer)\n\n    @property\n    def settings(self):\n        \"\"\"\n        Get all available settings.\n\n        Returns:\n            dict: A dictionary of all available settings.\n                Keys are setting paths and values are setting item objects. \n        \"\"\"\n        settings = {}\n        settings.update(self.common_settings.settings)\n        settings.update(self.path_tracing_settings.settings)\n        settings.update(self.post_processing_settings.settings)\n        settings.update(self.real_time_settings.settings)\n        return settings\n</code></pre>","location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings"},{"title":"<code>settings</code>  <code>property</code>","text":"<p>Get all available settings.</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>A dictionary of all available settings. Keys are setting paths and values are setting item objects.</p>","location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.settings"},{"title":"<code>get_current_renderer()</code>","text":"<p>Get the current renderer.</p> <p>Parameters:</p>    Name Type Description Default     <code>path</code>  <code>str</code>  <p>Path of the setting to get.</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>the current renderer.</p>     Source code in <code>renderer_settings/renderer_settings.py</code> <pre><code>def get_current_renderer(self):\n    \"\"\"\n    Get the current renderer.\n\n    Args:\n        path (str): Path of the setting to get.\n\n    Returns:\n        str: the current renderer.\n    \"\"\"\n    return RendererSettingsFactory.get_current_renderer()\n</code></pre>","location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.get_current_renderer"},{"title":"<code>get_setting_from_path(path)</code>","text":"<p>Get the value of setting @path.</p> <p>Parameters:</p>    Name Type Description Default     <code>path</code>  <code>str</code>  <p>Path of the setting to get.</p>  required     <p>Returns:</p>    Name Type Description     <code>any</code>   <p>Value of the requested setting @path.</p>     Source code in <code>renderer_settings/renderer_settings.py</code> <pre><code>def get_setting_from_path(self, path):\n    \"\"\"\n    Get the value of setting @path.\n\n    Args:\n        path (str): Path of the setting to get.\n\n    Returns:\n        any: Value of the requested setting @path.\n    \"\"\"\n    return self._carb_settings.get(path)\n</code></pre>","location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.get_setting_from_path"},{"title":"<code>reset_setting(path)</code>","text":"<p>Resets setting @path to default value.</p> <p>Parameters:</p>    Name Type Description Default     <code>path</code>  <code>str</code>  <p>Path of the setting to reset.</p>  required      Source code in <code>renderer_settings/renderer_settings.py</code> <pre><code>def reset_setting(self, path):\n    \"\"\"\n    Resets setting @path to default value.\n\n    Args:\n        path (str): Path of the setting to reset.\n    \"\"\"\n    if path not in self.settings:\n        raise NotImplementedError(f\"Setting {path} is not supported.\")\n    self.settings[path].reset()\n</code></pre>","location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.reset_setting"},{"title":"<code>set_current_renderer(renderer)</code>","text":"<p>Set the current renderer to @renderer.</p> <p>Parameters:</p>    Name Type Description Default     <code>renderer</code>  <code>str</code>  <p>The renderer to set as current (e.g. Real-Time, Path-Traced).</p>  required      Source code in <code>renderer_settings/renderer_settings.py</code> <pre><code>def set_current_renderer(self, renderer):\n    \"\"\"\n    Set the current renderer to @renderer.\n\n    Args:\n        renderer (str): The renderer to set as current (e.g. Real-Time, Path-Traced).\n    \"\"\"\n    assert (\n        renderer in RendererSettingsFactory.get_registered_renderers()\n    ), f\"renderer must be one of {RendererSettingsFactory.get_registered_renderers()}\"\n    print(f\"Set current renderer to {renderer}.\")\n    RendererSettingsFactory.set_current_renderer(renderer)\n</code></pre>","location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.set_current_renderer"},{"title":"<code>set_setting(path, value)</code>","text":"<p>Sets setting @path with value @value.</p> <p>Parameters:</p>    Name Type Description Default     <code>path</code>  <code>str</code>  <p>Path of the setting to set.</p>  required    <code>value</code>  <code>any</code>  <p>Value to set for for setting @path.</p>  required      Source code in <code>renderer_settings/renderer_settings.py</code> <pre><code>def set_setting(self, path, value):\n    \"\"\"\n    Sets setting @path with value @value.\n\n    Args:\n        path (str): Path of the setting to set.\n        value (any): Value to set for for setting @path.\n    \"\"\"\n    if path not in self.settings:\n        raise NotImplementedError(f\"Setting {path} is not supported.\")\n    self.settings[path].set(value)\n</code></pre>","location":"reference/renderer_settings/renderer_settings.html#renderer_settings.renderer_settings.RendererSettings.set_setting"},{"title":"settings_base","text":"","location":"reference/renderer_settings/settings_base.html"},{"title":"<code>SettingItem</code>","text":"<p>A wrapper of an individual setting item.</p> <p>Parameters:</p>    Name Type Description Default     <code>owner</code>   <p>class:<code>SubSettingsBase</code>): The SubSettingsBase object owning this setting.</p>  required    <code>setting_type</code>   <p>class:<code>SettingType</code>): Setting type (e.g. float, int).</p>  required    <code>name</code>  <code>str</code>  <p>Description of this setting.</p>  required    <code>path</code>  <code>str</code>  <p>Path of this setting.</p>  required    <code>range_from</code>  <code>float</code>  <p>The lower bound of the values for this setting. Defaults to -inf.</p>  <code>-float('inf')</code>    <code>range_to</code>  <code>float</code>  <p>The upper bound of the values for this settin. Defaults to inf.</p>  <code>float('inf')</code>    <code>range_list</code>  <code>list</code>  <p>Possible values for this setting. Defaults to None.</p>  <code>None</code>    <code>range_dict</code>  <code>dict</code>  <p>Possible values for this setting. Defaults to None.</p>  <code>None</code>      Source code in <code>renderer_settings/settings_base.py</code> <pre><code>class SettingItem:\n    \"\"\"\n    A wrapper of an individual setting item.\n\n    Args:\n        owner (:class:`SubSettingsBase`): The SubSettingsBase object owning this setting.\n        setting_type (:class:`SettingType`): Setting type (e.g. float, int).\n        name (str): Description of this setting.\n        path (str): Path of this setting.\n        range_from (float): The lower bound of the values for this setting. Defaults to -inf.\n        range_to (float): The upper bound of the values for this settin. Defaults to inf.\n        range_list (list): Possible values for this setting. Defaults to None.\n        range_dict (dict): Possible values for this setting. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        owner,\n        setting_type: SettingType,\n        name,\n        path,\n        range_from=-float(\"inf\"),\n        range_to=float(\"inf\"),\n        range_list=None,\n        range_dict=None,\n    ):\n        self._carb_settings = carb.settings.get_settings()\n        self.owner = owner\n        self.setting_type = setting_type\n        self.name = name\n        self.path = path\n        self.range_from = range_from\n        self.range_to = range_to\n        self.range_list = range_list\n        self.range_dict = range_dict\n        self.initial_value = self.value\n\n    @property\n    def value(self):\n        \"\"\"\n        Get the current setting value.\n\n        Returns:\n            any: The current setting value.\n        \"\"\"\n        return self._carb_settings.get(self.path)\n\n    def get(self):\n        \"\"\"\n        Get the current setting value.\n\n        Returns:\n            any: The current setting value.\n        \"\"\"\n        return self.value\n\n    def reset(self):\n        \"\"\"\n        Reset the current setting value to default.\n        \"\"\"\n        self.set(self.initial_value)\n\n    def set(self, value):\n        \"\"\"\n        Set the current setting to @value.\n\n        Args:\n            value (any): Value to set for the current setting value.\n        \"\"\"\n        print(f\"Set setting {self.path} ({self.name}) to {value}.\")  # carb.log_info\n        if not self.owner.is_enabled():\n            print(f\"Note: {self.owner.enabled_setting_path} is not enabled.\")\n\n        # Validate range list and range dict.\n        if self.range_list:\n            assert value in self.range_list, f\"Setting {self.path} must be chosen from {self.range_list}.\"\n        if self.range_dict:\n            assert isinstance(self.range_dict, dict)\n            assert (\n                value in self.range_dict.values()\n            ), f\"Setting {self.path} must be chosen from a value (not key) in {self.range_dict}.\"\n\n        if self.setting_type == SettingType.FLOAT:\n            assert isinstance(value, (int, float)), f\"Setting {self.path} must be of type float.\"\n            assert (\n                value &gt;= self.range_from and value &lt;= self.range_to\n            ), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\n            self._carb_settings.set_float(self.path, value)\n\n        elif self.setting_type == SettingType.INT:\n            assert isinstance(value, int), f\"Setting {self.path} must be of type int.\"\n            assert (\n                value &gt;= self.range_from and value &lt;= self.range_to\n            ), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\n            self._carb_settings.set_int(self.path, value)\n\n        elif self.setting_type == SettingType.COLOR3:\n            assert (\n                isinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n            ), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\n            for v in value:\n                assert (\n                    isinstance(v, (int, float)) and v &gt;= 0 and v &lt;= 1\n                ), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\n            self._carb_settings.set_float_array(self.path, value)\n\n        elif self.setting_type == SettingType.BOOL:\n            assert isinstance(value, bool), f\"Setting {self.path} must be of type bool.\"\n            self._carb_settings.set_bool(self.path, value)\n\n        elif self.setting_type == SettingType.STRING:\n            assert isinstance(value, str), f\"Setting {self.path} must be of type str.\"\n            self._carb_settings.set_string(self.path, value)\n\n        elif self.setting_type == SettingType.DOUBLE3:\n            assert (\n                isinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n            ), f\"Setting {self.path} must be a list of 3 floats.\"\n            for v in value:\n                assert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 3 floats.\"\n            self._carb_settings.set_float_array(self.path, value)\n\n        elif self.setting_type == SettingType.INT2:\n            assert (\n                isinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n            ), f\"Setting {self.path} must be a list of 2 ints.\"\n            for v in value:\n                assert isinstance(v, int), f\"Setting {self.path} must be a list of 2 ints.\"\n            self._carb_settings.set_int_array(self.path, value)\n\n        elif self.setting_type == SettingType.DOUBLE2:\n            assert (\n                isinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n            ), f\"Setting {self.path} must be a list of 2 floats.\"\n            for v in value:\n                assert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 2 floats.\"\n            self._carb_settings.set_float_array(self.path, value)\n\n        else:\n            raise TypeError(f\"Setting type {self.setting_type} is not supported.\")\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem"},{"title":"<code>value</code>  <code>property</code>","text":"<p>Get the current setting value.</p> <p>Returns:</p>    Name Type Description     <code>any</code>   <p>The current setting value.</p>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.value"},{"title":"<code>get()</code>","text":"<p>Get the current setting value.</p> <p>Returns:</p>    Name Type Description     <code>any</code>   <p>The current setting value.</p>     Source code in <code>renderer_settings/settings_base.py</code> <pre><code>def get(self):\n    \"\"\"\n    Get the current setting value.\n\n    Returns:\n        any: The current setting value.\n    \"\"\"\n    return self.value\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.get"},{"title":"<code>reset()</code>","text":"<p>Reset the current setting value to default.</p>  Source code in <code>renderer_settings/settings_base.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Reset the current setting value to default.\n    \"\"\"\n    self.set(self.initial_value)\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.reset"},{"title":"<code>set(value)</code>","text":"<p>Set the current setting to @value.</p> <p>Parameters:</p>    Name Type Description Default     <code>value</code>  <code>any</code>  <p>Value to set for the current setting value.</p>  required      Source code in <code>renderer_settings/settings_base.py</code> <pre><code>def set(self, value):\n    \"\"\"\n    Set the current setting to @value.\n\n    Args:\n        value (any): Value to set for the current setting value.\n    \"\"\"\n    print(f\"Set setting {self.path} ({self.name}) to {value}.\")  # carb.log_info\n    if not self.owner.is_enabled():\n        print(f\"Note: {self.owner.enabled_setting_path} is not enabled.\")\n\n    # Validate range list and range dict.\n    if self.range_list:\n        assert value in self.range_list, f\"Setting {self.path} must be chosen from {self.range_list}.\"\n    if self.range_dict:\n        assert isinstance(self.range_dict, dict)\n        assert (\n            value in self.range_dict.values()\n        ), f\"Setting {self.path} must be chosen from a value (not key) in {self.range_dict}.\"\n\n    if self.setting_type == SettingType.FLOAT:\n        assert isinstance(value, (int, float)), f\"Setting {self.path} must be of type float.\"\n        assert (\n            value &gt;= self.range_from and value &lt;= self.range_to\n        ), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\n        self._carb_settings.set_float(self.path, value)\n\n    elif self.setting_type == SettingType.INT:\n        assert isinstance(value, int), f\"Setting {self.path} must be of type int.\"\n        assert (\n            value &gt;= self.range_from and value &lt;= self.range_to\n        ), f\"Setting {self.path} must be within range ({self.range_from}, {self.range_to}).\"\n        self._carb_settings.set_int(self.path, value)\n\n    elif self.setting_type == SettingType.COLOR3:\n        assert (\n            isinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n        ), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\n        for v in value:\n            assert (\n                isinstance(v, (int, float)) and v &gt;= 0 and v &lt;= 1\n            ), f\"Setting {self.path} must be a list of 3 numbers within range [0,1].\"\n        self._carb_settings.set_float_array(self.path, value)\n\n    elif self.setting_type == SettingType.BOOL:\n        assert isinstance(value, bool), f\"Setting {self.path} must be of type bool.\"\n        self._carb_settings.set_bool(self.path, value)\n\n    elif self.setting_type == SettingType.STRING:\n        assert isinstance(value, str), f\"Setting {self.path} must be of type str.\"\n        self._carb_settings.set_string(self.path, value)\n\n    elif self.setting_type == SettingType.DOUBLE3:\n        assert (\n            isinstance(value, (list, tuple, np.ndarray)) and len(value) == 3\n        ), f\"Setting {self.path} must be a list of 3 floats.\"\n        for v in value:\n            assert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 3 floats.\"\n        self._carb_settings.set_float_array(self.path, value)\n\n    elif self.setting_type == SettingType.INT2:\n        assert (\n            isinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n        ), f\"Setting {self.path} must be a list of 2 ints.\"\n        for v in value:\n            assert isinstance(v, int), f\"Setting {self.path} must be a list of 2 ints.\"\n        self._carb_settings.set_int_array(self.path, value)\n\n    elif self.setting_type == SettingType.DOUBLE2:\n        assert (\n            isinstance(value, (list, tuple, np.ndarray)) and len(value) == 2\n        ), f\"Setting {self.path} must be a list of 2 floats.\"\n        for v in value:\n            assert isinstance(v, (int, float)), f\"Setting {self.path} must be a list of 2 floats.\"\n        self._carb_settings.set_float_array(self.path, value)\n\n    else:\n        raise TypeError(f\"Setting type {self.setting_type} is not supported.\")\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingItem.set"},{"title":"<code>SettingsBase</code>","text":"<p>Base class for all renderer settings classes.</p> <p>Settings classes include Common, Real-Time (Ray-Tracing), Path-Tracing and Post Processing.</p>  Source code in <code>renderer_settings/settings_base.py</code> <pre><code>class SettingsBase(metaclass=ABCMeta):\n    \"\"\"\n    Base class for all renderer settings classes.\n\n    Settings classes include Common, Real-Time (Ray-Tracing), Path-Tracing and Post Processing.\n    \"\"\"\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SettingsBase"},{"title":"<code>SubSettingsBase</code>","text":"<p>Base class for all renderer sub-settings classes.</p>  Source code in <code>renderer_settings/settings_base.py</code> <pre><code>class SubSettingsBase(metaclass=ABCMeta):\n    \"\"\"\n    Base class for all renderer sub-settings classes.\n    \"\"\"\n\n    def __init__(self):\n        self._carb_settings = carb.settings.get_settings()\n\n    @property\n    def enabled_setting_path(self):\n        \"\"\"\n        The path of \"enabled\" setting for this sub-settings class.\n\n        Subclass with \"enabled\" mode needs to overwrite this method. \n\n        Returns:\n            str or None: The path of \"enabled\" mode for this sub-setting class.\n                Defaults to None, which means this sub-setting group cannot be enabled/disabled.\n        \"\"\"\n        return None\n\n    def is_enabled(self):\n        \"\"\"\n        Get the enabled status for this sub-setting class.\n\n        Returns:\n            bool: Whether this sub-setting group is enabled.\n                Returns true if this sub-setting group has no \"enabled\" mode.\n        \"\"\"\n        if not self.enabled_setting_path:\n            return True\n        return self._carb_settings.get(self.enabled_setting_path)\n\n    def enable(self):\n        \"\"\"\n        Enable this sub-setting class.\n        \"\"\"\n        if not self.enabled_setting_path:\n            print(f\"{self.__class__.__name__} has no enabled mode.\")\n            return\n        self._carb_settings.set_bool(self.enabled_setting_path, True)\n\n    def disable(self):\n        \"\"\"\n        Disable this sub-setting class.\n        \"\"\"\n        if not self.enabled_setting_path:\n            print(f\"{self.__class__.__name__} has no enabled mode.\")\n            return\n        self._carb_settings.set_bool(self.enabled_setting_path, False)\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase"},{"title":"<code>enabled_setting_path</code>  <code>property</code>","text":"<p>The path of \"enabled\" setting for this sub-settings class.</p> <p>Subclass with \"enabled\" mode needs to overwrite this method. </p> <p>Returns:</p>    Type Description       <p>str or None: The path of \"enabled\" mode for this sub-setting class. Defaults to None, which means this sub-setting group cannot be enabled/disabled.</p>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.enabled_setting_path"},{"title":"<code>disable()</code>","text":"<p>Disable this sub-setting class.</p>  Source code in <code>renderer_settings/settings_base.py</code> <pre><code>def disable(self):\n    \"\"\"\n    Disable this sub-setting class.\n    \"\"\"\n    if not self.enabled_setting_path:\n        print(f\"{self.__class__.__name__} has no enabled mode.\")\n        return\n    self._carb_settings.set_bool(self.enabled_setting_path, False)\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.disable"},{"title":"<code>enable()</code>","text":"<p>Enable this sub-setting class.</p>  Source code in <code>renderer_settings/settings_base.py</code> <pre><code>def enable(self):\n    \"\"\"\n    Enable this sub-setting class.\n    \"\"\"\n    if not self.enabled_setting_path:\n        print(f\"{self.__class__.__name__} has no enabled mode.\")\n        return\n    self._carb_settings.set_bool(self.enabled_setting_path, True)\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.enable"},{"title":"<code>is_enabled()</code>","text":"<p>Get the enabled status for this sub-setting class.</p> <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this sub-setting group is enabled. Returns true if this sub-setting group has no \"enabled\" mode.</p>     Source code in <code>renderer_settings/settings_base.py</code> <pre><code>def is_enabled(self):\n    \"\"\"\n    Get the enabled status for this sub-setting class.\n\n    Returns:\n        bool: Whether this sub-setting group is enabled.\n            Returns true if this sub-setting group has no \"enabled\" mode.\n    \"\"\"\n    if not self.enabled_setting_path:\n        return True\n    return self._carb_settings.get(self.enabled_setting_path)\n</code></pre>","location":"reference/renderer_settings/settings_base.html#renderer_settings.settings_base.SubSettingsBase.is_enabled"},{"title":"reward_functions","text":"","location":"reference/reward_functions/index.html"},{"title":"collision_reward","text":"","location":"reference/reward_functions/collision_reward.html"},{"title":"<code>CollisionReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Collision reward Penalize robot collision. Typically collision_reward_weight is negative. Note that we ignore collisions with any floor objects.</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>robot identifier to evaluate collision penalty with. Default is 0, corresponding to the first robot added to the scene</p>  <code>0</code>    <code>ignore_self_collisions</code>  <code>bool</code>  <p>Whether to ignore robot self-collisions or not</p>  <code>True</code>    <code>r_collision</code>  <code>float</code>  <p>Penalty value (&gt;0) to penalize collisions</p>  <code>0.1</code>      Source code in <code>reward_functions/collision_reward.py</code> <pre><code>class CollisionReward(BaseRewardFunction):\n    \"\"\"\n    Collision reward\n    Penalize robot collision. Typically collision_reward_weight is negative. Note that we ignore collisions with any\n    floor objects.\n\n    Args:\n        robot_idn (int): robot identifier to evaluate collision penalty with. Default is 0, corresponding to the first\n            robot added to the scene\n        ignore_self_collisions (bool): Whether to ignore robot self-collisions or not\n        r_collision (float): Penalty value (&gt;0) to penalize collisions\n    \"\"\"\n\n    def __init__(self, robot_idn=0, ignore_self_collisions=True, r_collision=0.1):\n        # Store internal vars\n        assert r_collision &gt; 0, f\"r_collision must be positive, got: {r_collision}!\"\n        self._robot_idn = robot_idn\n        self._ignore_self_collisions = ignore_self_collisions\n        self._r_collision = r_collision\n\n        # Run super\n        super().__init__()\n\n    def _step(self, task, env, action):\n        # Penalty is Reward is -self._r_collision if there were any collisions in the last timestep\n        robot = env.robots[self._robot_idn]\n        # Ignore floors and potentially robot's own prims as well\n        floors = list(env.scene.object_registry(\"category\", \"floors\", []))\n        ignore_objs = floors if self._ignore_self_collisions is None else floors + [robot]\n        in_contact = len(env.robots[self._robot_idn].states[ContactBodies].get_value(ignore_objs=tuple(ignore_objs))) &gt; 0\n        reward = float(in_contact) * -self._r_collision\n        return reward, {}\n</code></pre>","location":"reference/reward_functions/collision_reward.html#reward_functions.collision_reward.CollisionReward"},{"title":"point_goal_reward","text":"","location":"reference/reward_functions/point_goal_reward.html"},{"title":"<code>PointGoalReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Point goal reward Success reward for reaching the goal with the robot's base</p> <p>Parameters:</p>    Name Type Description Default     <code>pointgoal</code>  <code>PointGoal</code>  <p>Termination condition for checking whether a point goal is reached</p>  required    <code>r_pointgoal</code>  <code>float</code>  <p>Reward for reaching the point goal</p>  <code>10.0</code>      Source code in <code>reward_functions/point_goal_reward.py</code> <pre><code>class PointGoalReward(BaseRewardFunction):\n    \"\"\"\n    Point goal reward\n    Success reward for reaching the goal with the robot's base\n\n    Args:\n        pointgoal (PointGoal): Termination condition for checking whether a point goal is reached\n        r_pointgoal (float): Reward for reaching the point goal\n    \"\"\"\n\n    def __init__(self, pointgoal, r_pointgoal=10.0):\n        # Store internal vars\n        self._pointgoal = pointgoal\n        self._r_pointgoal = r_pointgoal\n\n        # Run super\n        super().__init__()\n\n    def _step(self, task, env, action):\n        # Reward received the pointgoal success condition is met\n        reward = self._r_pointgoal if self._pointgoal.success else 0.0\n\n        return reward, {}\n</code></pre>","location":"reference/reward_functions/point_goal_reward.html#reward_functions.point_goal_reward.PointGoalReward"},{"title":"potential_reward","text":"","location":"reference/reward_functions/potential_reward.html"},{"title":"<code>PotentialReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Potential reward Assume task has get_potential implemented; Low potential is preferred (e.g. a common potential for goal-directed task is the distance to goal)</p> <p>Parameters:</p>    Name Type Description Default     <code>potential_fcn</code>  <code>method</code>  <p>function for calculating potential. Function signature should be:</p> <p>potential = potential_fcn(env)</p> <p>where @env is a Environment instance, and @potential is a float value representing the calculated potential</p>  required    <code>r_potential</code>  <code>float</code>  <p>Reward weighting to give proportional to the potential difference calculated in between env timesteps</p>  <code>1.0</code>      Source code in <code>reward_functions/potential_reward.py</code> <pre><code>class PotentialReward(BaseRewardFunction):\n    \"\"\"\n    Potential reward\n    Assume task has get_potential implemented; Low potential is preferred\n    (e.g. a common potential for goal-directed task is the distance to goal)\n\n    Args:\n        potential_fcn (method): function for calculating potential. Function signature should be:\n\n            potential = potential_fcn(env)\n\n            where @env is a Environment instance, and @potential is a float value representing the calculated potential\n\n        r_potential (float): Reward weighting to give proportional to the potential difference calculated\n            in between env timesteps\n    \"\"\"\n\n    def __init__(self, potential_fcn, r_potential=1.0):\n        # Store internal vars\n        self._potential_fcn = potential_fcn\n        self._r_potential = r_potential\n\n        # Store internal vars that will be filled in at runtime\n        self._potential = None\n\n        # Run super\n        super().__init__()\n\n    def reset(self, task, env):\n        \"\"\"\n        Compute the initial potential after episode reset\n\n        :param task: task instance\n        :param env: environment instance\n        \"\"\"\n        # Reset potential\n        self._potential = self._potential_fcn(env)\n\n    def _step(self, task, env, action):\n        # Reward is proportional to the potential difference between the current and previous timestep\n        new_potential = self._potential_fcn(env)\n        reward = (self._potential - new_potential) * self._r_potential\n\n        # Update internal potential\n        self._potential = new_potential\n\n        return reward, {}\n</code></pre>","location":"reference/reward_functions/potential_reward.html#reward_functions.potential_reward.PotentialReward"},{"title":"<code>reset(task, env)</code>","text":"<p>Compute the initial potential after episode reset</p> <p>:param task: task instance :param env: environment instance</p>  Source code in <code>reward_functions/potential_reward.py</code> <pre><code>def reset(self, task, env):\n    \"\"\"\n    Compute the initial potential after episode reset\n\n    :param task: task instance\n    :param env: environment instance\n    \"\"\"\n    # Reset potential\n    self._potential = self._potential_fcn(env)\n</code></pre>","location":"reference/reward_functions/potential_reward.html#reward_functions.potential_reward.PotentialReward.reset"},{"title":"reaching_goal_reward","text":"","location":"reference/reward_functions/reaching_goal_reward.html"},{"title":"<code>ReachingGoalReward</code>","text":"<p>         Bases: <code>BaseRewardFunction</code></p> <p>Reaching goal reward Success reward for reaching the goal with the robot's end-effector</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>robot identifier to evaluate point goal with. Default is 0, corresponding to the first robot added to the scene</p>  <code>0</code>    <code>r_reach</code>  <code>float</code>  <p>reward for succeeding to reach the goal</p>  <code>10.0</code>    <code>distance_tol</code>  <code>float</code>  <p>Distance (m) tolerance between goal position and @robot_idn's robot eef position that is accepted as a success</p>  <code>0.1</code>      Source code in <code>reward_functions/reaching_goal_reward.py</code> <pre><code>class ReachingGoalReward(BaseRewardFunction):\n    \"\"\"\n    Reaching goal reward\n    Success reward for reaching the goal with the robot's end-effector\n\n    Args:\n        robot_idn (int): robot identifier to evaluate point goal with. Default is 0, corresponding to the first\n            robot added to the scene\n        r_reach (float): reward for succeeding to reach the goal\n        distance_tol (float): Distance (m) tolerance between goal position and @robot_idn's robot eef position\n            that is accepted as a success\n    \"\"\"\n\n    def __init__(self, robot_idn=0, r_reach=10.0, distance_tol=0.1):\n        # Store internal vars\n        self._robot_idn = robot_idn\n        self._r_reach = r_reach\n        self._distance_tol = distance_tol\n\n        # Run super\n        super().__init__()\n\n    def _step(self, task, env, action):\n        # Sparse reward is received if distance between robot_idn robot's eef and goal is below the distance threshold\n        success = T.l2_distance(env.robots[self._robot_idn].get_end_effector_position(), task.goal_pos) &lt; \\\n            self._distance_tol\n        reward = self._r_reach if success else 0.0\n\n        return reward, {}\n</code></pre>","location":"reference/reward_functions/reaching_goal_reward.html#reward_functions.reaching_goal_reward.ReachingGoalReward"},{"title":"reward_function_base","text":"","location":"reference/reward_functions/reward_function_base.html"},{"title":"<code>BaseRewardFunction</code>","text":"<p>         Bases: <code>Registerable</code></p> <p>Base RewardFunction class Reward-specific reset and get_reward methods are implemented in subclasses</p>  Source code in <code>reward_functions/reward_function_base.py</code> <pre><code>class BaseRewardFunction(Registerable, metaclass=ABCMeta):\n    \"\"\"\n    Base RewardFunction class\n    Reward-specific reset and get_reward methods are implemented in subclasses\n    \"\"\"\n    def __init__(self):\n        # Store internal vars that will be filled in at runtime\n        self._reward = None\n        self._info = None\n\n    @abstractmethod\n    def _step(self, task, env, action):\n        \"\"\"\n        Step the reward function and compute the reward at the current timestep. Overwritten by subclasses.\n\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n        Returns:\n            2-tuple:\n                - bool: computed reward\n                - dict: any reward-related information for this specific reward\n        \"\"\"\n        raise NotImplementedError()\n\n    def step(self, task, env, action):\n        \"\"\"\n        Step the reward function and compute the reward at the current timestep.\n\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n        Returns:\n            2-tuple:\n                - bool: computed reward\n                - dict: any reward-related information for this specific reward\n        \"\"\"\n        # Step internally and store output\n        self._reward, self._info = self._step(task=task, env=env, action=action)\n\n        # Return reward and a copy of the info\n        return self._reward, deepcopy(self._info)\n\n    def reset(self, task, env):\n        \"\"\"\n        Reward function-specific reset\n\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n        \"\"\"\n        # Reset internal vars\n        self._reward = None\n        self._info = None\n\n    @property\n    def reward(self):\n        \"\"\"\n        Returns:\n            float: Current reward for this reward function\n        \"\"\"\n        assert self._reward is not None, \"At least one step() must occur before reward can be calculated!\"\n        return self._reward\n\n    @property\n    def info(self):\n        \"\"\"\n        Returns:\n            dict: Current info for this reward function\n        \"\"\"\n        assert self._info is not None, \"At least one step() must occur before info can be calculated!\"\n        return self._info\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseRewardFunction\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_REWARD_FUNCTIONS\n        return REGISTERED_REWARD_FUNCTIONS\n</code></pre>","location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction"},{"title":"<code>info</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Current info for this reward function</p>","location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.info"},{"title":"<code>reward</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Current reward for this reward function</p>","location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.reward"},{"title":"<code>reset(task, env)</code>","text":"<p>Reward function-specific reset</p> <p>Parameters:</p>    Name Type Description Default     <code>task</code>  <code>BaseTask</code>  <p>Task instance</p>  required    <code>env</code>  <code>Environment</code>  <p>Environment instance</p>  required      Source code in <code>reward_functions/reward_function_base.py</code> <pre><code>def reset(self, task, env):\n    \"\"\"\n    Reward function-specific reset\n\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n    \"\"\"\n    # Reset internal vars\n    self._reward = None\n    self._info = None\n</code></pre>","location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.reset"},{"title":"<code>step(task, env, action)</code>","text":"<p>Step the reward function and compute the reward at the current timestep.</p> <p>Parameters:</p>    Name Type Description Default     <code>task</code>  <code>BaseTask</code>  <p>Task instance</p>  required    <code>env</code>  <code>Environment</code>  <p>Environment instance</p>  required    <code>action</code>  <code>n-array</code>  <p>1D flattened array of actions executed by all agents in the environment</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - bool: computed reward - dict: any reward-related information for this specific reward</p>     Source code in <code>reward_functions/reward_function_base.py</code> <pre><code>def step(self, task, env, action):\n    \"\"\"\n    Step the reward function and compute the reward at the current timestep.\n\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n        action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n    Returns:\n        2-tuple:\n            - bool: computed reward\n            - dict: any reward-related information for this specific reward\n    \"\"\"\n    # Step internally and store output\n    self._reward, self._info = self._step(task=task, env=env, action=action)\n\n    # Return reward and a copy of the info\n    return self._reward, deepcopy(self._info)\n</code></pre>","location":"reference/reward_functions/reward_function_base.html#reward_functions.reward_function_base.BaseRewardFunction.step"},{"title":"robots","text":"","location":"reference/robots/index.html"},{"title":"active_camera_robot","text":"","location":"reference/robots/active_camera_robot.html"},{"title":"<code>ActiveCameraRobot</code>","text":"<p>         Bases: <code>BaseRobot</code></p> <p>Robot that is is equipped with an onboard camera that can be moved independently from the robot's other kinematic joints (e.g.: independent of base and arm for a mobile manipulator).</p>  controller_config should, at the minimum, contain: <p>camera: controller specifications for the controller to control this robot's camera.     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre>   Source code in <code>robots/active_camera_robot.py</code> <pre><code>class ActiveCameraRobot(BaseRobot):\n    \"\"\"\n    Robot that is is equipped with an onboard camera that can be moved independently from the robot's other kinematic\n    joints (e.g.: independent of base and arm for a mobile manipulator).\n\n    NOTE: controller_config should, at the minimum, contain:\n        camera: controller specifications for the controller to control this robot's camera.\n            Should include:\n\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n\n    \"\"\"\n\n    def _validate_configuration(self):\n        # Make sure a camera controller is specified\n        assert (\n            \"camera\" in self._controllers\n        ), \"Controller 'camera' must exist in controllers! Current controllers: {}\".format(\n            list(self._controllers.keys())\n        )\n\n        # run super\n        super()._validate_configuration()\n\n    def _get_proprioception_dict(self):\n        dic = super()._get_proprioception_dict()\n\n        # Add camera pos info\n        joint_positions = self.get_joint_positions(normalized=False)\n        joint_velocities = self.get_joint_velocities(normalized=False)\n        dic[\"camera_qpos\"] = joint_positions[self.camera_control_idx]\n        dic[\"camera_qpos_sin\"] = np.sin(joint_positions[self.camera_control_idx])\n        dic[\"camera_qpos_cos\"] = np.cos(joint_positions[self.camera_control_idx])\n        dic[\"camera_qvel\"] = joint_velocities[self.camera_control_idx]\n\n        return dic\n\n    @property\n    def default_proprio_obs(self):\n        obs_keys = super().default_proprio_obs\n        return obs_keys + [\"camera_qpos_sin\", \"camera_qpos_cos\"]\n\n    @property\n    def controller_order(self):\n        # By default, only camera is supported\n        return [\"camera\"]\n\n    @property\n    def _default_controllers(self):\n        # Always call super first\n        controllers = super()._default_controllers\n\n        # For best generalizability use, joint controller as default\n        controllers[\"camera\"] = \"JointController\"\n\n        return controllers\n\n    @property\n    def _default_camera_joint_controller_config(self):\n        \"\"\"\n        Returns:\n            dict: Default camera joint controller config to control this robot's camera\n        \"\"\"\n        return {\n            \"name\": \"JointController\",\n            \"control_freq\": self._control_freq,\n            \"motor_type\": \"velocity\",\n            \"control_limits\": self.control_limits,\n            \"dof_idx\": self.camera_control_idx,\n            \"command_output_limits\": \"default\",\n            \"use_delta_commands\": False,\n        }\n\n    @property\n    def _default_camera_null_joint_controller_config(self):\n        \"\"\"\n        Returns:\n            dict: Default null joint controller config to control this robot's camera i.e. dummy controller\n        \"\"\"\n        return {\n            \"name\": \"NullJointController\",\n            \"control_freq\": self._control_freq,\n            \"motor_type\": \"velocity\",\n            \"control_limits\": self.control_limits,\n            \"dof_idx\": self.camera_control_idx,\n        }\n\n    @property\n    def _default_controller_config(self):\n        # Always run super method first\n        cfg = super()._default_controller_config\n\n        # We additionally add in camera default\n        cfg[\"camera\"] = {\n            self._default_camera_joint_controller_config[\"name\"]: self._default_camera_joint_controller_config,\n            self._default_camera_null_joint_controller_config[\"name\"]: self._default_camera_null_joint_controller_config,\n        }\n\n        return cfg\n\n    @property\n    @abstractmethod\n    def camera_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to camera joints.\n        \"\"\"\n        raise NotImplementedError\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"ActiveCameraRobot\")\n        return classes\n</code></pre>","location":"reference/robots/active_camera_robot.html#robots.active_camera_robot.ActiveCameraRobot"},{"title":"<code>camera_control_idx</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to camera joints.</p>","location":"reference/robots/active_camera_robot.html#robots.active_camera_robot.ActiveCameraRobot.camera_control_idx"},{"title":"fetch","text":"","location":"reference/robots/fetch.html"},{"title":"<code>Fetch</code>","text":"<p>         Bases: <code>ManipulationRobot</code>, <code>TwoWheelRobot</code>, <code>ActiveCameraRobot</code></p> <p>Fetch Robot Reference: https://fetchrobotics.com/robotics-platforms/fetch-mobile-manipulator/</p>  Source code in <code>robots/fetch.py</code> <pre><code>class Fetch(ManipulationRobot, TwoWheelRobot, ActiveCameraRobot):\n    \"\"\"\n    Fetch Robot\n    Reference: https://fetchrobotics.com/robotics-platforms/fetch-mobile-manipulator/\n    \"\"\"\n\n    def __init__(\n        self,\n        # Shared kwargs in hierarchy\n        prim_path,\n        name=None,\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        load_config=None,\n\n        # Unique to USDObject hierarchy\n        abilities=None,\n\n        # Unique to ControllableObject hierarchy\n        control_freq=None,\n        controller_config=None,\n        action_type=\"continuous\",\n        action_normalize=True,\n        reset_joint_pos=None,\n\n        # Unique to BaseRobot\n        obs_modalities=\"all\",\n        proprio_obs=\"default\",\n\n        # Unique to ManipulationRobot\n        grasping_mode=\"physical\",\n\n        # Unique to Fetch\n        rigid_trunk=False,\n        default_trunk_offset=0.365,\n        default_arm_pose=\"vertical\",\n\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n                If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n                If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n                If \"sticky\", will magnetize any object touching the gripper's fingers.\n            rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n            default_trunk_offset (float): sets the default height of the robot's trunk\n            default_arm_pose (str): Default pose for the robot arm. Should be one of:\n                {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Store args\n        self.rigid_trunk = rigid_trunk\n        self.default_trunk_offset = default_trunk_offset\n        assert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\n        self.default_arm_pose = default_arm_pose\n\n        # Parse reset joint pos if specifying special string\n        if isinstance(reset_joint_pos, str):\n            assert (\n                reset_joint_pos in RESET_JOINT_OPTIONS\n            ), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\n            reset_joint_pos = (\n                self.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n            )\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            load_config=load_config,\n            abilities=abilities,\n            control_freq=control_freq,\n            controller_config=controller_config,\n            action_type=action_type,\n            action_normalize=action_normalize,\n            reset_joint_pos=reset_joint_pos,\n            obs_modalities=obs_modalities,\n            proprio_obs=proprio_obs,\n            grasping_mode=grasping_mode,\n            **kwargs,\n        )\n\n    @property\n    def model_name(self):\n        return \"Fetch\"\n\n    @property\n    def tucked_default_joint_pos(self):\n        return np.array(\n            [\n                0.0,\n                0.0,  # wheels\n                0.02,  # trunk\n                0.0,\n                1.1707963267948966,\n                0.0,  # head\n                1.4707963267948965,\n                -0.4,\n                1.6707963267948966,\n                0.0,\n                1.5707963267948966,\n                0.0,  # arm\n                0.05,\n                0.05,  # gripper\n            ]\n        )\n\n    @property\n    def untucked_default_joint_pos(self):\n        pos = np.zeros(self.n_joints)\n        pos[self.base_control_idx] = 0.0\n        pos[self.trunk_control_idx] = 0.02 + self.default_trunk_offset\n        pos[self.camera_control_idx] = np.array([0.0, 0.45])\n        pos[self.gripper_control_idx[self.default_arm]] = np.array([0.05, 0.05])  # open gripper\n\n        # Choose arm based on setting\n        if self.default_arm_pose == \"vertical\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [-0.94121, -0.64134, 1.55186, 1.65672, -0.93218, 1.53416, 2.14474]\n            )\n        elif self.default_arm_pose == \"diagonal15\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [-0.95587, -0.34778, 1.46388, 1.47821, -0.93813, 1.4587, 1.9939]\n            )\n        elif self.default_arm_pose == \"diagonal30\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [-1.06595, -0.22184, 1.53448, 1.46076, -0.84995, 1.36904, 1.90996]\n            )\n        elif self.default_arm_pose == \"diagonal45\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [-1.11479, -0.0685, 1.5696, 1.37304, -0.74273, 1.3983, 1.79618]\n            )\n        elif self.default_arm_pose == \"horizontal\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [-1.43016, 0.20965, 1.86816, 1.77576, -0.27289, 1.31715, 2.01226]\n            )\n        else:\n            raise ValueError(\"Unknown default arm pose: {}\".format(self.default_arm_pose))\n        return pos\n\n    @property\n    def discrete_action_list(self):\n        # Not supported for this robot\n        raise NotImplementedError()\n\n    def _create_discrete_action_space(self):\n        # Fetch does not support discrete actions\n        raise ValueError(\"Fetch does not support discrete actions!\")\n\n    def tuck(self):\n        \"\"\"\n        Immediately set this robot's configuration to be in tucked mode\n        \"\"\"\n        self.set_joint_positions(self.tucked_default_joint_pos)\n\n    def untuck(self):\n        \"\"\"\n        Immediately set this robot's configuration to be in untucked mode\n        \"\"\"\n        self.set_joint_positions(self.untucked_default_joint_pos)\n\n    def _initialize(self):\n        # Run super method first\n        super()._initialize()\n\n        # Set the joint friction for EEF to be higher\n        for arm in self.arm_names:\n            for joint in self.finger_joints[arm]:\n                if joint.joint_type != JointType.JOINT_FIXED:\n                    joint.friction = 500\n\n    def _actions_to_control(self, action):\n        # Run super method first\n        u_vec, u_type_vec = super()._actions_to_control(action=action)\n\n        # Override trunk value if we're keeping the trunk rigid\n        if self.rigid_trunk:\n            u_vec[self.trunk_control_idx] = self.untucked_default_joint_pos[self.trunk_control_idx]\n            u_type_vec[self.trunk_control_idx] = ControlType.POSITION\n\n        # Return control\n        return u_vec, u_type_vec\n\n    def _get_proprioception_dict(self):\n        dic = super()._get_proprioception_dict()\n\n        # Add trunk info\n        joint_positions = self.get_joint_positions(normalized=False)\n        joint_velocities = self.get_joint_velocities(normalized=False)\n        dic[\"trunk_qpos\"] = joint_positions[self.trunk_control_idx]\n        dic[\"trunk_qvel\"] = joint_velocities[self.trunk_control_idx]\n\n        return dic\n\n    @property\n    def default_proprio_obs(self):\n        obs_keys = super().default_proprio_obs\n        return obs_keys + [\"trunk_qpos\"]\n\n    @property\n    def controller_order(self):\n        # Ordered by general robot kinematics chain\n        return [\"base\", \"camera\", \"arm_{}\".format(self.default_arm), \"gripper_{}\".format(self.default_arm)]\n\n    @property\n    def _default_controllers(self):\n        # Always call super first\n        controllers = super()._default_controllers\n\n        # We use multi finger gripper, differential drive, and IK controllers as default\n        controllers[\"base\"] = \"DifferentialDriveController\"\n        controllers[\"camera\"] = \"JointController\"\n        controllers[\"arm_{}\".format(self.default_arm)] = \"InverseKinematicsController\"\n        controllers[\"gripper_{}\".format(self.default_arm)] = \"MultiFingerGripperController\"\n\n        return controllers\n\n    @property\n    def _default_controller_config(self):\n        # Grab defaults from super method first\n        cfg = super()._default_controller_config\n\n        # Need to override joint idx being controlled to include trunk in default arm controller configs\n        for arm_cfg in cfg[f\"arm_{self.default_arm}\"].values():\n            arm_cfg[\"dof_idx\"] = np.concatenate([self.trunk_control_idx, self.arm_control_idx[self.default_arm]])\n\n            # If using rigid trunk, we also clamp its limits\n            if self.rigid_trunk:\n                arm_cfg[\"control_limits\"][\"position\"][0][self.trunk_control_idx] = \\\n                    self.untucked_default_joint_pos[self.trunk_control_idx]\n                arm_cfg[\"control_limits\"][\"position\"][1][self.trunk_control_idx] = \\\n                    self.untucked_default_joint_pos[self.trunk_control_idx]\n\n        return cfg\n\n    @property\n    def default_joint_pos(self):\n        return self.untucked_default_joint_pos\n\n    @property\n    def wheel_radius(self):\n        return 0.0613\n\n    @property\n    def wheel_axle_length(self):\n        return 0.372\n\n    @property\n    def finger_lengths(self):\n        return {self.default_arm: 0.1}\n\n    @property\n    def assisted_grasp_start_points(self):\n        return {\n            self.default_arm: [\n                GraspingPoint(link_name=\"r_gripper_finger_link\", position=[0.04, -0.012, 0.014]),\n                GraspingPoint(link_name=\"r_gripper_finger_link\", position=[0.04, -0.012, -0.014]),\n                GraspingPoint(link_name=\"r_gripper_finger_link\", position=[-0.04, -0.012, 0.014]),\n                GraspingPoint(link_name=\"r_gripper_finger_link\", position=[-0.04, -0.012, -0.014]),\n            ]\n        }\n\n    @property\n    def assisted_grasp_end_points(self):\n        return {\n            self.default_arm: [\n                GraspingPoint(link_name=\"l_gripper_finger_link\", position=[0.04, 0.012, 0.014]),\n                GraspingPoint(link_name=\"l_gripper_finger_link\", position=[0.04, 0.012, -0.014]),\n                GraspingPoint(link_name=\"l_gripper_finger_link\", position=[-0.04, 0.012, 0.014]),\n                GraspingPoint(link_name=\"l_gripper_finger_link\", position=[-0.04, 0.012, -0.014]),\n            ]\n        }\n\n    @property\n    def base_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\n        return np.array([0, 1])\n\n    @property\n    def trunk_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to trunk joint.\n        \"\"\"\n        return np.array([2])\n\n    @property\n    def camera_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.\n        \"\"\"\n        return np.array([3, 5])\n\n    @property\n    def arm_control_idx(self):\n        return {self.default_arm: np.array([4, 6, 7, 8, 9, 10, 11])}\n\n    @property\n    def gripper_control_idx(self):\n        return {self.default_arm: np.array([12, 13])}\n\n    @property\n    def disabled_collision_pairs(self):\n        return [\n            [\"torso_lift_link\", \"shoulder_lift_link\"],\n            [\"torso_lift_link\", \"torso_fixed_link\"],\n        ]\n\n    @property\n    def arm_link_names(self):\n        return {self.default_arm: [\n            \"shoulder_pan_link\",\n            \"shoulder_lift_link\",\n            \"upperarm_roll_link\",\n            \"elbow_flex_link\",\n            \"forearm_roll_link\",\n            \"wrist_flex_link\",\n            \"wrist_roll_link\",\n        ]}\n\n    @property\n    def arm_joint_names(self):\n        return {self.default_arm: [\n            \"torso_lift_joint\",\n            \"shoulder_pan_joint\",\n            \"shoulder_lift_joint\",\n            \"upperarm_roll_joint\",\n            \"elbow_flex_joint\",\n            \"forearm_roll_joint\",\n            \"wrist_flex_joint\",\n            \"wrist_roll_joint\",\n        ]}\n\n    @property\n    def eef_link_names(self):\n        return {self.default_arm: \"gripper_link\"}\n\n    @property\n    def finger_link_names(self):\n        return {self.default_arm: [\"r_gripper_finger_link\", \"l_gripper_finger_link\"]}\n\n    @property\n    def finger_joint_names(self):\n        return {self.default_arm: [\"r_gripper_finger_joint\", \"l_gripper_finger_joint\"]}\n\n    @property\n    def usd_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/fetch/fetch/fetch.usd\")\n\n    @property\n    def robot_arm_descriptor_yamls(self):\n        return {self.default_arm: os.path.join(omnigibson.assets_path, \"models/fetch/fetch_descriptor.yaml\")}\n\n    @property\n    def urdf_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/fetch/fetch.urdf\")\n</code></pre>","location":"reference/robots/fetch.html#robots.fetch.Fetch"},{"title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>","location":"reference/robots/fetch.html#robots.fetch.Fetch.base_control_idx"},{"title":"<code>camera_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.</p>","location":"reference/robots/fetch.html#robots.fetch.Fetch.camera_control_idx"},{"title":"<code>trunk_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to trunk joint.</p>","location":"reference/robots/fetch.html#robots.fetch.Fetch.trunk_control_idx"},{"title":"<code>__init__(prim_path, name=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, load_config=None, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', grasping_mode='physical', rigid_trunk=False, default_trunk_offset=0.365, default_arm_pose='vertical', **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>control_freq</code>  <code>float</code>  <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p>  <code>None</code>    <code>controller_config</code>  <code>None or dict</code>  <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p>  <code>None</code>    <code>action_type</code>  <code>str</code>  <p>one of {discrete, continuous} - what type of action space to use</p>  <code>'continuous'</code>    <code>action_normalize</code>  <code>bool</code>  <p>whether to normalize inputted actions. This will override any default values specified by this class.</p>  <code>True</code>    <code>reset_joint_pos</code>  <code>None or n-array</code>  <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p>  <code>None</code>    <code>obs_modalities</code>  <code>str or list of str</code>  <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p>  <code>'all'</code>    <code>proprio_obs</code>  <code>str or list of str</code>  <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p>  <code>'default'</code>    <code>grasping_mode</code>  <code>str</code>  <p>One of {\"physical\", \"assisted\", \"sticky\"}. If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force). If \"assisted\", will magnetize any object touching and within the gripper's fingers. If \"sticky\", will magnetize any object touching the gripper's fingers.</p>  <code>'physical'</code>    <code>default_trunk_offset</code>  <code>float</code>  <p>sets the default height of the robot's trunk</p>  <code>0.365</code>    <code>default_arm_pose</code>  <code>str</code>  <p>Default pose for the robot arm. Should be one of:</p>  <code>'vertical'</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>robots/fetch.py</code> <pre><code>def __init__(\n    self,\n    # Shared kwargs in hierarchy\n    prim_path,\n    name=None,\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    load_config=None,\n\n    # Unique to USDObject hierarchy\n    abilities=None,\n\n    # Unique to ControllableObject hierarchy\n    control_freq=None,\n    controller_config=None,\n    action_type=\"continuous\",\n    action_normalize=True,\n    reset_joint_pos=None,\n\n    # Unique to BaseRobot\n    obs_modalities=\"all\",\n    proprio_obs=\"default\",\n\n    # Unique to ManipulationRobot\n    grasping_mode=\"physical\",\n\n    # Unique to Fetch\n    rigid_trunk=False,\n    default_trunk_offset=0.365,\n    default_arm_pose=\"vertical\",\n\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n            If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n            If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n            If \"sticky\", will magnetize any object touching the gripper's fingers.\n        rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n        default_trunk_offset (float): sets the default height of the robot's trunk\n        default_arm_pose (str): Default pose for the robot arm. Should be one of:\n            {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Store args\n    self.rigid_trunk = rigid_trunk\n    self.default_trunk_offset = default_trunk_offset\n    assert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\n    self.default_arm_pose = default_arm_pose\n\n    # Parse reset joint pos if specifying special string\n    if isinstance(reset_joint_pos, str):\n        assert (\n            reset_joint_pos in RESET_JOINT_OPTIONS\n        ), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\n        reset_joint_pos = (\n            self.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n        )\n\n    # Run super init\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        load_config=load_config,\n        abilities=abilities,\n        control_freq=control_freq,\n        controller_config=controller_config,\n        action_type=action_type,\n        action_normalize=action_normalize,\n        reset_joint_pos=reset_joint_pos,\n        obs_modalities=obs_modalities,\n        proprio_obs=proprio_obs,\n        grasping_mode=grasping_mode,\n        **kwargs,\n    )\n</code></pre>","location":"reference/robots/fetch.html#robots.fetch.Fetch.__init__"},{"title":"<code>tuck()</code>","text":"<p>Immediately set this robot's configuration to be in tucked mode</p>  Source code in <code>robots/fetch.py</code> <pre><code>def tuck(self):\n    \"\"\"\n    Immediately set this robot's configuration to be in tucked mode\n    \"\"\"\n    self.set_joint_positions(self.tucked_default_joint_pos)\n</code></pre>","location":"reference/robots/fetch.html#robots.fetch.Fetch.tuck"},{"title":"<code>untuck()</code>","text":"<p>Immediately set this robot's configuration to be in untucked mode</p>  Source code in <code>robots/fetch.py</code> <pre><code>def untuck(self):\n    \"\"\"\n    Immediately set this robot's configuration to be in untucked mode\n    \"\"\"\n    self.set_joint_positions(self.untucked_default_joint_pos)\n</code></pre>","location":"reference/robots/fetch.html#robots.fetch.Fetch.untuck"},{"title":"freight","text":"","location":"reference/robots/freight.html"},{"title":"<code>Freight</code>","text":"<p>         Bases: <code>TwoWheelRobot</code></p> <p>Freight Robot Reference: https://fetchrobotics.com/robotics-platforms/freight-base/ Uses joint velocity control</p>  Source code in <code>robots/freight.py</code> <pre><code>class Freight(TwoWheelRobot):\n    \"\"\"\n    Freight Robot\n    Reference: https://fetchrobotics.com/robotics-platforms/freight-base/\n    Uses joint velocity control\n    \"\"\"\n\n    @property\n    def model_name(self):\n        return \"Freight\"\n\n    @property\n    def wheel_radius(self):\n        return 0.0613\n\n    @property\n    def wheel_axle_length(self):\n        return 0.372\n\n    @property\n    def base_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\n        return np.array([0, 1])\n\n    @property\n    def default_joint_pos(self):\n        return np.zeros(self.n_joints)\n\n    @property\n    def usd_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/fetch/freight/freight.usd\")\n\n    @property\n    def urdf_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/fetch/freight.urdf\")\n</code></pre>","location":"reference/robots/freight.html#robots.freight.Freight"},{"title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>","location":"reference/robots/freight.html#robots.freight.Freight.base_control_idx"},{"title":"husky","text":"","location":"reference/robots/husky.html"},{"title":"<code>Husky</code>","text":"<p>         Bases: <code>LocomotionRobot</code></p> <p>Husky robot Reference: https://clearpathrobotics.com/, http://wiki.ros.org/Robots/Husky</p>  Source code in <code>robots/husky.py</code> <pre><code>class Husky(LocomotionRobot):\n    \"\"\"\n    Husky robot\n    Reference: https://clearpathrobotics.com/, http://wiki.ros.org/Robots/Husky\n    \"\"\"\n\n    def _create_discrete_action_space(self):\n        raise ValueError(\"Husky does not support discrete actions!\")\n\n    @property\n    def base_control_idx(self):\n        return np.array([0, 1, 2, 3])\n\n    @property\n    def default_joint_pos(self):\n        return np.zeros(self.n_joints)\n\n    @property\n    def usd_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/husky/husky/husky.usd\")\n\n    @property\n    def urdf_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/husky/husky.urdf\")\n</code></pre>","location":"reference/robots/husky.html#robots.husky.Husky"},{"title":"locobot","text":"","location":"reference/robots/locobot.html"},{"title":"<code>Locobot</code>","text":"<p>         Bases: <code>TwoWheelRobot</code></p> <p>Locobot robot Reference: https://www.trossenrobotics.com/locobot-pyrobot-ros-rover.aspx</p>  Source code in <code>robots/locobot.py</code> <pre><code>class Locobot(TwoWheelRobot):\n    \"\"\"\n    Locobot robot\n    Reference: https://www.trossenrobotics.com/locobot-pyrobot-ros-rover.aspx\n    \"\"\"\n\n    @property\n    def model_name(self):\n        return \"Locobot\"\n\n    @property\n    def wheel_radius(self):\n        return 0.038\n\n    @property\n    def wheel_axle_length(self):\n        return 0.230\n\n    @property\n    def base_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\n        return np.array([1, 0])\n\n    @property\n    def default_joint_pos(self):\n        return np.zeros(self.n_joints)\n\n    @property\n    def usd_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/locobot/locobot/locobot.usd\")\n\n    @property\n    def urdf_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/locobot/locobot.urdf\")\n</code></pre>","location":"reference/robots/locobot.html#robots.locobot.Locobot"},{"title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>","location":"reference/robots/locobot.html#robots.locobot.Locobot.base_control_idx"},{"title":"locomotion_robot","text":"","location":"reference/robots/locomotion_robot.html"},{"title":"<code>LocomotionRobot</code>","text":"<p>         Bases: <code>BaseRobot</code></p> <p>Robot that is is equipped with locomotive (navigational) capabilities. Provides common interface for a wide variety of robots.</p>  controller_config should, at the minimum, contain: <p>base: controller specifications for the controller to control this robot's base (locomotion).     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre>   Source code in <code>robots/locomotion_robot.py</code> <pre><code>class LocomotionRobot(BaseRobot):\n    \"\"\"\n    Robot that is is equipped with locomotive (navigational) capabilities.\n    Provides common interface for a wide variety of robots.\n\n    NOTE: controller_config should, at the minimum, contain:\n        base: controller specifications for the controller to control this robot's base (locomotion).\n            Should include:\n\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n\n    \"\"\"\n\n    def _validate_configuration(self):\n        # We make sure that our base controller exists and is a locomotion controller\n        assert (\n            \"base\" in self._controllers\n        ), \"Controller 'base' must exist in controllers! Current controllers: {}\".format(list(self._controllers.keys()))\n        assert isinstance(\n            self._controllers[\"base\"], LocomotionController\n        ), \"Base controller must be a LocomotionController!\"\n\n        # run super\n        super()._validate_configuration()\n\n    def _get_proprioception_dict(self):\n        dic = super()._get_proprioception_dict()\n\n        joint_positions = self.get_joint_positions(normalized=False)\n        joint_velocities = self.get_joint_velocities(normalized=False)\n\n        # Add base info\n        dic[\"base_qpos\"] = joint_positions[self.base_control_idx]\n        dic[\"base_qpos_sin\"] = np.sin(joint_positions[self.base_control_idx])\n        dic[\"base_qpos_cos\"] = np.cos(joint_positions[self.base_control_idx])\n        dic[\"base_qvel\"] = joint_velocities[self.base_control_idx]\n\n        return dic\n\n    @property\n    def default_proprio_obs(self):\n        obs_keys = super().default_proprio_obs\n        return obs_keys + [\"base_qpos_sin\", \"base_qpos_cos\", \"robot_lin_vel\", \"robot_ang_vel\"]\n\n    @property\n    def controller_order(self):\n        # By default, only base is supported\n        return [\"base\"]\n\n    @property\n    def _default_controllers(self):\n        # Always call super first\n        controllers = super()._default_controllers\n\n        # For best generalizability use, joint controller as default\n        controllers[\"base\"] = \"JointController\"\n\n        return controllers\n\n    @property\n    def _default_base_joint_controller_config(self):\n        \"\"\"\n        Returns:\n            dict: Default base joint controller config to control this robot's base. Uses velocity\n                control by default.\n        \"\"\"\n        return {\n            \"name\": \"JointController\",\n            \"control_freq\": self._control_freq,\n            \"motor_type\": \"velocity\",\n            \"control_limits\": self.control_limits,\n            \"dof_idx\": self.base_control_idx,\n            \"command_output_limits\": \"default\",\n            \"use_delta_commands\": False,\n        }\n\n    @property\n    def _default_base_null_joint_controller_config(self):\n        \"\"\"\n        Returns:\n            dict: Default null joint controller config to control this robot's base i.e. dummy controller\n        \"\"\"\n        return {\n            \"name\": \"NullJointController\",\n            \"control_freq\": self._control_freq,\n            \"motor_type\": \"velocity\",\n            \"control_limits\": self.control_limits,\n            \"dof_idx\": self.base_control_idx,\n        }\n\n    @property\n    def _default_controller_config(self):\n        # Always run super method first\n        cfg = super()._default_controller_config\n\n        # Add supported base controllers\n        cfg[\"base\"] = {\n            self._default_base_joint_controller_config[\"name\"]: self._default_base_joint_controller_config,\n            self._default_base_null_joint_controller_config[\"name\"]: self._default_base_null_joint_controller_config,\n        }\n\n        return cfg\n\n    def move_by(self, delta):\n        \"\"\"\n        Move robot base without physics simulation\n\n        Args:\n            delta (float):float], (x,y,z) cartesian delta base position\n        \"\"\"\n        new_pos = np.array(delta) + self.get_position()\n        self.set_position(position=new_pos)\n\n    def move_forward(self, delta=0.05):\n        \"\"\"\n        Move robot base forward without physics simulation\n\n        Args:\n            delta (float): delta base position forward\n        \"\"\"\n        self.move_by(quat2mat(self.get_orientation()).dot(np.array([delta, 0, 0])))\n\n    def move_backward(self, delta=0.05):\n        \"\"\"\n        Move robot base backward without physics simulation\n\n        Args:\n            delta (float): delta base position backward\n        \"\"\"\n        self.move_by(quat2mat(self.get_orientation()).dot(np.array([-delta, 0, 0])))\n\n    def move_left(self, delta=0.05):\n        \"\"\"\n        Move robot base left without physics simulation\n\n        Args:\n            delta (float): delta base position left\n        \"\"\"\n        self.move_by(quat2mat(self.get_orientation()).dot(np.array([0, -delta, 0])))\n\n    def move_right(self, delta=0.05):\n        \"\"\"\n        Move robot base right without physics simulation\n\n        Args:\n            delta (float): delta base position right\n        \"\"\"\n        self.move_by(quat2mat(self.get_orientation()).dot(np.array([0, delta, 0])))\n\n    def turn_left(self, delta=0.03):\n        \"\"\"\n        Rotate robot base left without physics simulation\n\n        Args:\n            delta (float): delta angle to rotate the base left\n        \"\"\"\n        quat = self.get_orientation()\n        quat = qmult((euler2quat(-delta, 0, 0)), quat)\n        self.set_orientation(quat)\n\n    def turn_right(self, delta=0.03):\n        \"\"\"\n        Rotate robot base right without physics simulation\n\n        Args:\n            delta (float): angle to rotate the base right\n        \"\"\"\n        quat = self.get_orientation()\n        quat = qmult((euler2quat(delta, 0, 0)), quat)\n        self.set_orientation(quat)\n\n    @property\n    @abstractmethod\n    def base_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to base joints.\n        \"\"\"\n        raise NotImplementedError\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"LocomotionRobot\")\n        return classes\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot"},{"title":"<code>base_control_idx</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to base joints.</p>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.base_control_idx"},{"title":"<code>move_backward(delta=0.05)</code>","text":"<p>Move robot base backward without physics simulation</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>delta base position backward</p>  <code>0.05</code>      Source code in <code>robots/locomotion_robot.py</code> <pre><code>def move_backward(self, delta=0.05):\n    \"\"\"\n    Move robot base backward without physics simulation\n\n    Args:\n        delta (float): delta base position backward\n    \"\"\"\n    self.move_by(quat2mat(self.get_orientation()).dot(np.array([-delta, 0, 0])))\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_backward"},{"title":"<code>move_by(delta)</code>","text":"<p>Move robot base without physics simulation</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>float], (x,y,z) cartesian delta base position</p>  required      Source code in <code>robots/locomotion_robot.py</code> <pre><code>def move_by(self, delta):\n    \"\"\"\n    Move robot base without physics simulation\n\n    Args:\n        delta (float):float], (x,y,z) cartesian delta base position\n    \"\"\"\n    new_pos = np.array(delta) + self.get_position()\n    self.set_position(position=new_pos)\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_by"},{"title":"<code>move_forward(delta=0.05)</code>","text":"<p>Move robot base forward without physics simulation</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>delta base position forward</p>  <code>0.05</code>      Source code in <code>robots/locomotion_robot.py</code> <pre><code>def move_forward(self, delta=0.05):\n    \"\"\"\n    Move robot base forward without physics simulation\n\n    Args:\n        delta (float): delta base position forward\n    \"\"\"\n    self.move_by(quat2mat(self.get_orientation()).dot(np.array([delta, 0, 0])))\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_forward"},{"title":"<code>move_left(delta=0.05)</code>","text":"<p>Move robot base left without physics simulation</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>delta base position left</p>  <code>0.05</code>      Source code in <code>robots/locomotion_robot.py</code> <pre><code>def move_left(self, delta=0.05):\n    \"\"\"\n    Move robot base left without physics simulation\n\n    Args:\n        delta (float): delta base position left\n    \"\"\"\n    self.move_by(quat2mat(self.get_orientation()).dot(np.array([0, -delta, 0])))\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_left"},{"title":"<code>move_right(delta=0.05)</code>","text":"<p>Move robot base right without physics simulation</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>delta base position right</p>  <code>0.05</code>      Source code in <code>robots/locomotion_robot.py</code> <pre><code>def move_right(self, delta=0.05):\n    \"\"\"\n    Move robot base right without physics simulation\n\n    Args:\n        delta (float): delta base position right\n    \"\"\"\n    self.move_by(quat2mat(self.get_orientation()).dot(np.array([0, delta, 0])))\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.move_right"},{"title":"<code>turn_left(delta=0.03)</code>","text":"<p>Rotate robot base left without physics simulation</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>delta angle to rotate the base left</p>  <code>0.03</code>      Source code in <code>robots/locomotion_robot.py</code> <pre><code>def turn_left(self, delta=0.03):\n    \"\"\"\n    Rotate robot base left without physics simulation\n\n    Args:\n        delta (float): delta angle to rotate the base left\n    \"\"\"\n    quat = self.get_orientation()\n    quat = qmult((euler2quat(-delta, 0, 0)), quat)\n    self.set_orientation(quat)\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.turn_left"},{"title":"<code>turn_right(delta=0.03)</code>","text":"<p>Rotate robot base right without physics simulation</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>angle to rotate the base right</p>  <code>0.03</code>      Source code in <code>robots/locomotion_robot.py</code> <pre><code>def turn_right(self, delta=0.03):\n    \"\"\"\n    Rotate robot base right without physics simulation\n\n    Args:\n        delta (float): angle to rotate the base right\n    \"\"\"\n    quat = self.get_orientation()\n    quat = qmult((euler2quat(delta, 0, 0)), quat)\n    self.set_orientation(quat)\n</code></pre>","location":"reference/robots/locomotion_robot.html#robots.locomotion_robot.LocomotionRobot.turn_right"},{"title":"manipulation_robot","text":"","location":"reference/robots/manipulation_robot.html"},{"title":"<code>ManipulationRobot</code>","text":"<p>         Bases: <code>BaseRobot</code></p> <p>Robot that is is equipped with grasping (manipulation) capabilities. Provides common interface for a wide variety of robots.</p>  controller_config should, at the minimum, contain: <p>arm: controller specifications for the controller to control this robot's arm (manipulation).     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre>   Source code in <code>robots/manipulation_robot.py</code> <pre><code>class ManipulationRobot(BaseRobot):\n    \"\"\"\n    Robot that is is equipped with grasping (manipulation) capabilities.\n    Provides common interface for a wide variety of robots.\n\n    NOTE: controller_config should, at the minimum, contain:\n        arm: controller specifications for the controller to control this robot's arm (manipulation).\n            Should include:\n\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n    \"\"\"\n\n    def __init__(\n        self,\n        # Shared kwargs in hierarchy\n        prim_path,\n        name=None,\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        load_config=None,\n\n        # Unique to USDObject hierarchy\n        abilities=None,\n\n        # Unique to ControllableObject hierarchy\n        control_freq=None,\n        controller_config=None,\n        action_type=\"continuous\",\n        action_normalize=True,\n        reset_joint_pos=None,\n\n        # Unique to BaseRobot\n        obs_modalities=\"all\",\n        proprio_obs=\"default\",\n\n        # Unique to ManipulationRobot\n        grasping_mode=\"physical\",\n\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n                If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n                If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n                If \"sticky\", will magnetize any object touching the gripper's fingers.\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Store relevant internal vars\n        assert_valid_key(key=grasping_mode, valid_keys=AG_MODES, name=\"grasping_mode\")\n        self._grasping_mode = grasping_mode\n\n        # Initialize other variables used for assistive grasping\n        self._ag_data = {arm: None for arm in self.arm_names}\n        self._ag_freeze_joint_pos = {\n            arm: {} for arm in self.arm_names\n        }  # Frozen positions for keeping fingers held still\n        self._ag_obj_in_hand = {arm: None for arm in self.arm_names}\n        self._ag_obj_constraints = {arm: None for arm in self.arm_names}\n        self._ag_obj_constraint_params = {arm: {} for arm in self.arm_names}\n        self._ag_freeze_gripper = {arm: None for arm in self.arm_names}\n        self._ag_release_counter = {arm: None for arm in self.arm_names}\n        self._ag_check_in_volume = {arm: None for arm in self.arm_names}\n        self._ag_calculate_volume = {arm: None for arm in self.arm_names}\n\n        # Call super() method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            load_config=load_config,\n            abilities=abilities,\n            control_freq=control_freq,\n            controller_config=controller_config,\n            action_type=action_type,\n            action_normalize=action_normalize,\n            reset_joint_pos=reset_joint_pos,\n            obs_modalities=obs_modalities,\n            proprio_obs=proprio_obs,\n            **kwargs,\n        )\n\n    def _validate_configuration(self):\n        # Iterate over all arms\n        for arm in self.arm_names:\n            # We make sure that our arm controller exists and is a manipulation controller\n            assert (\n                \"arm_{}\".format(arm) in self._controllers\n            ), \"Controller 'arm_{}' must exist in controllers! Current controllers: {}\".format(\n                arm, list(self._controllers.keys())\n            )\n            assert isinstance(\n                self._controllers[\"arm_{}\".format(arm)], ManipulationController\n            ), \"Arm {} controller must be a ManipulationController!\".format(arm)\n\n            # We make sure that our gripper controller exists and is a gripper controller\n            assert (\n                \"gripper_{}\".format(arm) in self._controllers\n            ), \"Controller 'gripper_{}' must exist in controllers! Current controllers: {}\".format(\n                arm, list(self._controllers.keys())\n            )\n            assert isinstance(\n                self._controllers[\"gripper_{}\".format(arm)], GripperController\n            ), \"Gripper {} controller must be a GripperController!\".format(arm)\n\n        # run super\n        super()._validate_configuration()\n\n    def _initialize(self):\n        super()._initialize()\n        if gm.AG_CLOTH:\n            for arm in self.arm_names:\n                self._ag_check_in_volume[arm], self._ag_calculate_volume[arm] = \\\n                    generate_points_in_volume_checker_function(obj=self, volume_link=self.eef_links[arm], mesh_name_prefixes=\"container\")\n\n    def is_grasping(self, arm=\"default\", candidate_obj=None):\n        \"\"\"\n        Returns True if the robot is grasping the target option @candidate_obj or any object if @candidate_obj is None.\n\n        Args:\n            arm (str): specific arm to check for grasping. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n            candidate_obj (EntityPrim or None): object to check if this robot is currently grasping. If None, then\n                will be a general (object-agnostic) check for grasping.\n                Note: if self.grasping_mode is \"physical\", then @candidate_obj will be ignored completely\n\n        Returns:\n            IsGraspingState: For the specific manipulator appendage, returns IsGraspingState.TRUE if it is grasping\n                (potentially @candidate_obj if specified), IsGraspingState.FALSE if it is not grasping,\n                and IsGraspingState.UNKNOWN if unknown.\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        if self.grasping_mode != \"physical\":\n            is_grasping_obj = (\n                self._ag_obj_in_hand[arm] is not None\n                if candidate_obj is None\n                else self._ag_obj_in_hand[arm] == candidate_obj\n            )\n            is_grasping = (\n                IsGraspingState.TRUE\n                if is_grasping_obj and self._ag_release_counter[arm] is None\n                else IsGraspingState.FALSE\n            )\n        else:\n            # Infer from the gripper controller the state\n            is_grasping = self._controllers[\"gripper_{}\".format(arm)].is_grasping()\n            # If candidate obj is not None, we also check to see if our fingers are in contact with the object\n            if is_grasping and candidate_obj is not None:\n                grasping_obj = False\n                obj_links = {link.prim_path for link in candidate_obj.links.values()}\n                finger_links = {link.prim_path for link in self.finger_links[arm]}\n                for c in self.contact_list():\n                    c_set = {c.body0, c.body1}\n                    # Valid grasping of object if one of the set is a finger link and the other is the grasped object\n                    if len(c_set - finger_links) == 1 and len(c_set - obj_links) == 1:\n                        grasping_obj = True\n                        break\n                # Update is_grasping\n                is_grasping = grasping_obj\n\n        return is_grasping\n\n    def _find_gripper_contacts(self, arm=\"default\", return_contact_positions=False):\n        \"\"\"\n        For arm @arm, calculate any body IDs and corresponding link IDs that are not part of the robot\n        itself that are in contact with any of this arm's gripper's fingers\n\n        Args:\n            arm (str): specific arm whose gripper will be checked for contact. Default is \"default\" which\n                corresponds to the first entry in self.arm_names\n            return_contact_positions (bool): if True, will additionally return the contact (x,y,z) position\n\n        Returns:\n            2-tuple:\n                - set: set of unique contact prim_paths that are not the robot self-collisions.\n                    If @return_contact_positions is True, then returns (prim_path, pos), where pos is the contact\n                    (x,y,z) position\n                    Note: if no objects that are not the robot itself are intersecting, the set will be empty.\n                - dict: dictionary mapping unique contact objects defined by the contact prim_path to\n                    set of unique robot link prim_paths that it is in contact with\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        robot_contact_links = dict()\n        contact_data = set()\n        # Find all objects in contact with all finger joints for this arm\n        con_results = [con for link in self.finger_links[arm] for con in link.contact_list()]\n\n        # Get robot contact links\n        link_paths = set(self.link_prim_paths)\n\n        for con_res in con_results:\n            # Only add this contact if it's not a robot self-collision\n            other_contact_set = {con_res.body0, con_res.body1} - link_paths\n            if len(other_contact_set) == 1:\n                link_contact, other_contact = (con_res.body0, con_res.body1) if \\\n                    list(other_contact_set)[0] == con_res.body1 else (con_res.body1, con_res.body0)\n                # Add to contact data\n                contact_data.add((other_contact, tuple(con_res.position)) if return_contact_positions else other_contact)\n                # Also add robot contact link info\n                if other_contact not in robot_contact_links:\n                    robot_contact_links[other_contact] = set()\n                robot_contact_links[other_contact].add(link_contact)\n\n        return contact_data, robot_contact_links\n\n    def set_position_orientation(self, position=None, orientation=None):\n        # Store the original EEF poses.\n        original_poses = {}\n        for arm in self.arm_names:\n            original_poses[arm] = (self.get_eef_position(arm), self.get_eef_orientation(arm))\n\n        # Run the super method\n        super().set_position_orientation(position=position, orientation=orientation)\n\n        # Now for each hand, if it was holding an AG object, teleport it.\n        for arm in self.arm_names:\n            if self._ag_obj_in_hand[arm] is not None:\n                original_eef_pose = T.pose2mat(original_poses[arm])\n                inv_original_eef_pose = T.pose_inv(pose_mat=original_eef_pose)\n                original_obj_pose = T.pose2mat(self._ag_obj_in_hand[arm].get_position_orientation())\n                new_eef_pose = T.pose2mat((self.get_eef_position(arm), self.get_eef_orientation(arm)))\n                # New object pose is transform:\n                # original --&gt; \"De\"transform the original EEF pose --&gt; \"Re\"transform the new EEF pose\n                new_obj_pose = new_eef_pose @ inv_original_eef_pose @ original_obj_pose\n                self._ag_obj_in_hand[arm].set_position_orientation(*T.mat2pose(hmat=new_obj_pose))\n\n    def apply_action(self, action):\n        # First run assisted grasping\n        if self.grasping_mode != \"physical\":\n            self._handle_assisted_grasping(action=action)\n\n        # Potentially freeze gripper joints\n        for arm in self.arm_names:\n            if self._ag_freeze_gripper[arm]:\n                self._freeze_gripper(arm)\n\n        # Run super method as normal\n        super().apply_action(action)\n\n    def deploy_control(self, control, control_type, indices=None, normalized=False):\n        # We intercept the gripper control and replace it with the current joint position if we're freezing our gripper\n        for arm in self.arm_names:\n            if self._ag_freeze_gripper[arm]:\n                control[self.gripper_control_idx[arm]] = self._ag_obj_constraint_params[arm][\"gripper_pos\"] if \\\n                    self.controllers[f\"gripper_{arm}\"].control_type == ControlType.POSITION else 0.0\n\n        super().deploy_control(control=control, control_type=control_type, indices=indices, normalized=normalized)\n\n    def _release_grasp(self, arm=\"default\"):\n        \"\"\"\n        Magic action to release this robot's grasp on an object\n\n        Args:\n            arm (str): specific arm whose grasp will be released.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n\n        # Remove joint and filtered collision restraints\n        self._simulator.stage.RemovePrim(self._ag_obj_constraint_params[arm][\"ag_joint_prim_path\"])\n        self._ag_data[arm] = None\n        self._ag_obj_constraints[arm] = None\n        self._ag_obj_constraint_params[arm] = {}\n        self._ag_freeze_gripper[arm] = False\n        self._ag_release_counter[arm] = 0\n\n    def release_grasp_immediately(self):\n        \"\"\"\n        Magic action to release this robot's grasp for all arms at once.\n        As opposed to @_release_grasp, this method would byupass the release window mechanism and immediately release.\n        \"\"\"\n        for arm in self.arm_names:\n            if self._ag_obj_in_hand[arm] is not None:\n                self._release_grasp(arm=arm)\n                # TODO: Verify not needed!\n                # for finger_link in self.finger_links[arm]:\n                #     finger_link.remove_filtered_collision_pair(prim=self._ag_obj_in_hand[arm])\n                self._ag_obj_in_hand[arm] = None\n                self._ag_release_counter[arm] = None\n\n    def get_control_dict(self):\n        # In addition to super method, add in EEF states\n        dic = super().get_control_dict()\n\n        for arm in self.arm_names:\n            dic[\"eef_{}_pos_relative\".format(arm)] = self.get_relative_eef_position(arm)\n            dic[\"eef_{}_quat_relative\".format(arm)] = self.get_relative_eef_orientation(arm)\n\n        return dic\n\n    def _get_proprioception_dict(self):\n        dic = super()._get_proprioception_dict()\n\n        # Loop over all arms to grab proprio info\n        joint_positions = self.get_joint_positions(normalized=False)\n        joint_velocities = self.get_joint_velocities(normalized=False)\n        for arm in self.arm_names:\n            # Add arm info\n            dic[\"arm_{}_qpos\".format(arm)] = joint_positions[self.arm_control_idx[arm]]\n            dic[\"arm_{}_qpos_sin\".format(arm)] = np.sin(joint_positions[self.arm_control_idx[arm]])\n            dic[\"arm_{}_qpos_cos\".format(arm)] = np.cos(joint_positions[self.arm_control_idx[arm]])\n            dic[\"arm_{}_qvel\".format(arm)] = joint_velocities[self.arm_control_idx[arm]]\n\n            # Add eef and grasping info\n            dic[\"eef_{}_pos_global\".format(arm)] = self.get_eef_position(arm)\n            dic[\"eef_{}_quat_global\".format(arm)] = self.get_eef_orientation(arm)\n            dic[\"eef_{}_pos\".format(arm)] = self.get_relative_eef_position(arm)\n            dic[\"eef_{}_quat\".format(arm)] = self.get_relative_eef_orientation(arm)\n            dic[\"grasp_{}\".format(arm)] = np.array([self.is_grasping(arm)])\n            dic[\"gripper_{}_qpos\".format(arm)] = joint_positions[self.gripper_control_idx[arm]]\n            dic[\"gripper_{}_qvel\".format(arm)] = joint_velocities[self.gripper_control_idx[arm]]\n\n        return dic\n\n    @property\n    def default_proprio_obs(self):\n        obs_keys = super().default_proprio_obs\n        for arm in self.arm_names:\n            obs_keys += [\n                \"arm_{}_qpos_sin\".format(arm),\n                \"arm_{}_qpos_cos\".format(arm),\n                \"eef_{}_pos\".format(arm),\n                \"eef_{}_quat\".format(arm),\n                \"gripper_{}_qpos\".format(arm),\n                \"grasp_{}\".format(arm),\n            ]\n        return obs_keys\n\n    @property\n    def grasping_mode(self):\n        \"\"\"\n        Grasping mode of this robot. Is one of AG_MODES\n\n        Returns:\n            str: Grasping mode for this robot\n        \"\"\"\n        return self._grasping_mode\n\n    @property\n    def controller_order(self):\n        # Assumes we have arm(s) and corresponding gripper(s)\n        controllers = []\n        for arm in self.arm_names:\n            controllers += [\"arm_{}\".format(arm), \"gripper_{}\".format(arm)]\n\n        return controllers\n\n    @property\n    def _default_controllers(self):\n        # Always call super first\n        controllers = super()._default_controllers\n\n        # For best generalizability use, joint controller as default\n        for arm in self.arm_names:\n            controllers[\"arm_{}\".format(arm)] = \"JointController\"\n            controllers[\"gripper_{}\".format(arm)] = \"JointController\"\n\n        return controllers\n\n    @property\n    def n_arms(self):\n        \"\"\"\n        Returns:\n            int: Number of arms this robot has. Returns 1 by default\n        \"\"\"\n        return 1\n\n    @property\n    def arm_names(self):\n        \"\"\"\n        Returns:\n            list of str: List of arm names for this robot. Should correspond to the keys used to index into\n                arm- and gripper-related dictionaries, e.g.: eef_link_names, finger_link_names, etc.\n                Default is string enumeration based on @self.n_arms.\n        \"\"\"\n        return [str(i) for i in range(self.n_arms)]\n\n    @property\n    def default_arm(self):\n        \"\"\"\n        Returns:\n            str: Default arm name for this robot, corresponds to the first entry in @arm_names by default\n        \"\"\"\n        return self.arm_names[0]\n\n    @property\n    @abstractmethod\n    def arm_link_names(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding arm link names,\n                should correspond to specific link names in this robot's underlying model file\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def arm_joint_names(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding arm joint names,\n                should correspond to specific joint names in this robot's underlying model file\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def eef_link_names(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding name of the EEF link,\n                should correspond to specific link name in this robot's underlying model file\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def finger_link_names(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to array of link names corresponding to\n                this robot's fingers\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def finger_joint_names(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to array of joint names corresponding to\n                this robot's fingers\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def arm_control_idx(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to indices in low-level control\n                vector corresponding to arm joints.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def gripper_control_idx(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to indices in low-level control\n                vector corresponding to gripper joints.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def arm_links(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot links corresponding to\n                that arm's links\n        \"\"\"\n        return {arm: [self._links[link] for link in self.arm_link_names[arm]] for arm in self.arm_names}\n\n    @property\n    def eef_links(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot link corresponding to that arm's\n                eef link\n        \"\"\"\n        return {arm: self._links[self.eef_link_names[arm]] for arm in self.arm_names}\n\n    @property\n    def finger_links(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot links corresponding to\n                that arm's finger links\n        \"\"\"\n        return {arm: [self._links[link] for link in self.finger_link_names[arm]] for arm in self.arm_names}\n\n    @property\n    def finger_joints(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to robot joints corresponding to\n                that arm's finger joints\n        \"\"\"\n        return {arm: [self._joints[joint] for joint in self.finger_joint_names[arm]] for arm in self.arm_names}\n\n    @property\n    def assisted_grasp_start_points(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping individual arm appendage names to array of GraspingPoint tuples,\n                composed of (link_name, position) values specifying valid grasping start points located at\n                cartesian (x,y,z) coordinates specified in link_name's local coordinate frame.\n                These values will be used in conjunction with\n                @self.assisted_grasp_end_points to trigger assisted grasps, where objects that intersect\n                with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in\n                @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper\n                appendage). By default, each entry returns None, and must be implemented by any robot subclass that\n                wishes to use assisted grasping.\n        \"\"\"\n        return {arm: None for arm in self.arm_names}\n\n    @property\n    def assisted_grasp_end_points(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping individual arm appendage names to array of GraspingPoint tuples,\n                composed of (link_name, position) values specifying valid grasping end points located at\n                cartesian (x,y,z) coordinates specified in link_name's local coordinate frame.\n                These values will be used in conjunction with\n                @self.assisted_grasp_start_points to trigger assisted grasps, where objects that intersect\n                with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in\n                @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper\n                appendage). By default, each entry returns None, and must be implemented by any robot subclass that\n                wishes to use assisted grasping.\n        \"\"\"\n        return {arm: None for arm in self.arm_names}\n\n    @property\n    def finger_lengths(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to corresponding length of the fingers in that\n                hand defined from the palm (assuming all fingers in one hand are equally long)\n        \"\"\"\n        raise NotImplementedError\n\n    def get_eef_position(self, arm=\"default\"):\n        \"\"\"\n        Args:\n            arm (str): specific arm to grab eef position. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n\n        Returns:\n            3-array: (x,y,z) global end-effector Cartesian position for this robot's end-effector corresponding\n                to arm @arm\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        return self._links[self.eef_link_names[arm]].get_position()\n\n    def get_eef_orientation(self, arm=\"default\"):\n        \"\"\"\n        Args:\n            arm (str): specific arm to grab eef orientation. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n\n        Returns:\n            3-array: (x,y,z,w) global quaternion orientation for this robot's end-effector corresponding\n                to arm @arm\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        return self._links[self.eef_link_names[arm]].get_orientation()\n\n    def get_relative_eef_pose(self, arm=\"default\", mat=False):\n        \"\"\"\n        Args:\n            arm (str): specific arm to grab eef pose. Default is \"default\" which corresponds to the first entry\n                in self.arm_names\n            mat (bool): whether to return pose in matrix form (mat=True) or (pos, quat) tuple (mat=False)\n\n        Returns:\n            2-tuple or (4, 4)-array: End-effector pose, either in 4x4 homogeneous\n                matrix form (if @mat=True) or (pos, quat) tuple (if @mat=False), corresponding to arm @arm\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        eef_link_pose = self.eef_links[arm].get_position_orientation()\n        base_link_pose = self.get_position_orientation()\n        pose = T.relative_pose_transform(*eef_link_pose, *base_link_pose)\n        return T.pose2mat(pose) if mat else pose\n\n    def get_relative_eef_position(self, arm=\"default\"):\n        \"\"\"\n        Args:\n            arm (str): specific arm to grab relative eef pos.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n\n\n        Returns:\n            3-array: (x,y,z) Cartesian position of end-effector relative to robot base frame\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        return self.get_relative_eef_pose(arm=arm)[0]\n\n    def get_relative_eef_orientation(self, arm=\"default\"):\n        \"\"\"\n        Args:\n            arm (str): specific arm to grab relative eef orientation.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n\n        Returns:\n            4-array: (x,y,z,w) quaternion orientation of end-effector relative to robot base frame\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        return self.get_relative_eef_pose(arm=arm)[1]\n\n    def _calculate_in_hand_object_rigid(self, arm=\"default\"):\n        \"\"\"\n        Calculates which object to assisted-grasp for arm @arm. Returns an (object_id, link_id) tuple or None\n        if no valid AG-enabled object can be found.\n\n        Args:\n            arm (str): specific arm to calculate in-hand object for.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n\n        Returns:\n            None or 2-tuple: If a valid assisted-grasp object is found, returns the corresponding\n                (object, object_link) (i.e.: (BaseObject, RigidPrim)) pair to the contacted in-hand object.\n                Otherwise, returns None\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n\n        # If we're not using physical grasping, we check for gripper contact\n        if self.grasping_mode != \"physical\":\n            candidates_set, robot_contact_links = self._find_gripper_contacts(arm=arm)\n            # If we're using assisted grasping, we further filter candidates via ray-casting\n            if self.grasping_mode == \"assisted\":\n                raise NotImplementedError(\"Not assisted grasp avaialble yet in OmnOmniGibson!\")\n        else:\n            raise ValueError(\"Invalid grasping mode for calculating in hand object: {}\".format(self.grasping_mode))\n\n        # Immediately return if there are no valid candidates\n        if len(candidates_set) == 0:\n            return None\n\n        # Find the closest object to the gripper center\n        gripper_center_pos = self.eef_links[arm].get_position()\n\n        candidate_data = []\n        for prim_path in candidates_set:\n            # Calculate position of the object link\n            # Note: this assumes the simulator is playing!\n            rb_handle = self._dc.get_rigid_body(prim_path)\n            pose = self._dc.get_rigid_body_pose(rb_handle)\n            link_pos = np.asarray(pose.p)\n            dist = np.linalg.norm(np.array(link_pos) - np.array(gripper_center_pos))\n            candidate_data.append((prim_path, dist))\n\n        candidate_data = sorted(candidate_data, key=lambda x: x[-1])\n\n        ag_prim_path, _ = candidate_data[0]\n\n        # Make sure the ag_prim_path is not a self collision\n        assert ag_prim_path not in self.link_prim_paths, \"assisted grasp object cannot be the robot itself!\"\n\n        # Make sure at least two fingers are in contact with this object\n        robot_contacts = robot_contact_links[ag_prim_path]\n        touching_at_least_two_fingers = len({link.prim_path for link in self.finger_links[arm]}.intersection(robot_contacts)) &gt;= 2\n\n        # TODO: Better heuristic, hacky, we assume the parent object prim path is the prim_path minus the last \"/\" item\n        ag_obj_prim_path = \"/\".join(prim_path.split(\"/\")[:-1])\n        ag_obj_link_name = prim_path.split(\"/\")[-1]\n        ag_obj = self._simulator.scene.object_registry(\"prim_path\", ag_obj_prim_path)\n        ag_obj_link = ag_obj.links[ag_obj_link_name]\n\n        # Return None if object cannot be assisted grasped or not touching at least two fingers\n        if ag_obj is None or (not can_assisted_grasp(ag_obj)) or (not touching_at_least_two_fingers):\n            return None\n\n        # Get object and its contacted link\n        return ag_obj, ag_obj_link\n\n    def _handle_release_window(self, arm=\"default\"):\n        \"\"\"\n        Handles releasing an object from arm @arm\n\n        Args:\n            arm (str): specific arm to handle release window.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        self._ag_release_counter[arm] += 1\n        time_since_release = self._ag_release_counter[arm] * self._simulator.get_rendering_dt()\n        if time_since_release &gt;= m.RELEASE_WINDOW:\n            # TODO: Verify not needed!\n            # Remove filtered collision restraints\n            # for finger_link in self.finger_links[arm]:\n            #     finger_link.remove_filtered_collision_pair(prim=self._ag_obj_in_hand[arm])\n            self._ag_obj_in_hand[arm] = None\n            self._ag_release_counter[arm] = None\n\n    def _freeze_gripper(self, arm=\"default\"):\n        \"\"\"\n        Freezes gripper finger joints - used in assisted grasping.\n\n        Args:\n            arm (str): specific arm to freeze gripper.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n        for joint_name, j_val in self._ag_freeze_joint_pos[arm].items():\n            joint = self._joints[joint_name]\n            joint.set_pos(pos=j_val)\n            joint.set_vel(vel=0.0)\n\n    @property\n    def robot_arm_descriptor_yamls(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to files path to the descriptor\n                of the robot for IK Controller.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def _default_arm_joint_controller_configs(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default controller config to control that\n                robot's arm. Uses velocity control by default.\n        \"\"\"\n        dic = {}\n        for arm in self.arm_names:\n            dic[arm] = {\n                \"name\": \"JointController\",\n                \"control_freq\": self._control_freq,\n                \"motor_type\": \"velocity\",\n                \"control_limits\": self.control_limits,\n                \"dof_idx\": self.arm_control_idx[arm],\n                \"command_output_limits\": \"default\",\n                \"use_delta_commands\": False,\n            }\n        return dic\n\n    @property\n    def _default_arm_ik_controller_configs(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default controller config for an\n                Inverse kinematics controller to control this robot's arm\n        \"\"\"\n        dic = {}\n        for arm in self.arm_names:\n            dic[arm] = {\n                \"name\": \"InverseKinematicsController\",\n                \"task_name\": f\"eef_{arm}\",\n                \"robot_description_path\": self.robot_arm_descriptor_yamls[arm],\n                \"robot_urdf_path\": self.urdf_path,\n                \"eef_name\": self.eef_link_names[arm],\n                \"control_freq\": self._control_freq,\n                \"default_joint_pos\": self.default_joint_pos,\n                \"control_limits\": self.control_limits,\n                \"dof_idx\": self.arm_control_idx[arm],\n                \"command_output_limits\": (\n                    np.array([-0.2, -0.2, -0.2, -0.5, -0.5, -0.5]),\n                    np.array([0.2, 0.2, 0.2, 0.5, 0.5, 0.5]),\n                ),\n                \"kv\": 2.0,\n                \"mode\": \"pose_delta_ori\",\n                \"smoothing_filter_size\": 2,\n                \"workspace_pose_limiter\": None,\n            }\n        return dic\n\n    @property\n    def _default_arm_null_joint_controller_configs(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default arm null controller config\n                to control this robot's arm i.e. dummy controller\n        \"\"\"\n        dic = {}\n        for arm in self.arm_names:\n            dic[arm] = {\n                \"name\": \"NullJointController\",\n                \"control_freq\": self._control_freq,\n                \"motor_type\": \"velocity\",\n                \"control_limits\": self.control_limits,\n                \"dof_idx\": self.arm_control_idx[arm],\n            }\n        return dic\n\n    @property\n    def _default_gripper_multi_finger_controller_configs(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default controller config to control\n                this robot's multi finger gripper. Assumes robot gripper idx has exactly two elements\n        \"\"\"\n        dic = {}\n        for arm in self.arm_names:\n            dic[arm] = {\n                \"name\": \"MultiFingerGripperController\",\n                \"control_freq\": self._control_freq,\n                \"motor_type\": \"position\",\n                \"control_limits\": self.control_limits,\n                \"dof_idx\": self.gripper_control_idx[arm],\n                \"command_output_limits\": \"default\",\n                \"mode\": \"binary\",\n                \"limit_tolerance\": 0.001,\n            }\n        return dic\n\n    @property\n    def _default_gripper_joint_controller_configs(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default gripper joint controller config\n                to control this robot's gripper\n        \"\"\"\n        dic = {}\n        for arm in self.arm_names:\n            dic[arm] = {\n                \"name\": \"JointController\",\n                \"control_freq\": self._control_freq,\n                \"motor_type\": \"velocity\",\n                \"control_limits\": self.control_limits,\n                \"dof_idx\": self.gripper_control_idx[arm],\n                \"command_output_limits\": \"default\",\n                \"use_delta_commands\": False,\n            }\n        return dic\n\n    @property\n    def _default_gripper_null_controller_configs(self):\n        \"\"\"\n        Returns:\n            dict: Dictionary mapping arm appendage name to default gripper null controller config\n                to control this robot's (non-prehensile) gripper i.e. dummy controller\n        \"\"\"\n        dic = {}\n        for arm in self.arm_names:\n            dic[arm] = {\n                \"name\": \"NullJointController\",\n                \"control_freq\": self._control_freq,\n                \"control_limits\": self.control_limits,\n            }\n        return dic\n\n    @property\n    def _default_controller_config(self):\n        # Always run super method first\n        cfg = super()._default_controller_config\n\n        arm_ik_configs = self._default_arm_ik_controller_configs\n        arm_joint_configs = self._default_arm_joint_controller_configs\n        arm_null_joint_configs = self._default_arm_null_joint_controller_configs\n        gripper_pj_configs = self._default_gripper_multi_finger_controller_configs\n        gripper_joint_configs = self._default_gripper_joint_controller_configs\n        gripper_null_configs = self._default_gripper_null_controller_configs\n\n        # Add arm and gripper defaults, per arm\n        for arm in self.arm_names:\n            cfg[\"arm_{}\".format(arm)] = {\n                arm_ik_configs[arm][\"name\"]: arm_ik_configs[arm],\n                arm_joint_configs[arm][\"name\"]: arm_joint_configs[arm],\n                arm_null_joint_configs[arm][\"name\"]: arm_null_joint_configs[arm],\n            }\n            cfg[\"gripper_{}\".format(arm)] = {\n                gripper_pj_configs[arm][\"name\"]: gripper_pj_configs[arm],\n                gripper_joint_configs[arm][\"name\"]: gripper_joint_configs[arm],\n                gripper_null_configs[arm][\"name\"]: gripper_null_configs[arm],\n            }\n\n        return cfg\n\n    def _establish_grasp_rigid(self, arm=\"default\", ag_data=None):\n        \"\"\"\n        Establishes an ag-assisted grasp, if enabled.\n\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n            ag_data (None or 2-tuple): if specified, assisted-grasp object, link tuple (i.e. :(BaseObject, RigidPrim)).\n                Otherwise, does a no-op\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n\n        # Return immediately if ag_data is None\n        if ag_data is None:\n            return\n        ag_obj, ag_link = ag_data\n\n        # Create a p2p joint if it's a child link of a fixed URDF that is connected by a revolute or prismatic joint\n        joint_type = \"FixedJoint\"\n        if ag_obj.fixed_base:\n            # We search up the tree path from the ag_link until we encounter the root (joint == 0) or a non fixed\n            # joint (e.g.: revolute or fixed)\n            link_handle = ag_link.handle\n            joint_handle = self._dc.get_rigid_body_parent_joint(link_handle)\n            while joint_handle != 0:\n                # If this joint type is not fixed, we've encountered a valid moving joint\n                # So we create a spherical joint rather than fixed joint\n                if self._dc.get_joint_type(joint_handle) != JointType.JOINT_FIXED:\n                    joint_type = \"SphericalJoint\"\n                    break\n                # Grab the parent link and its parent joint for the link\n                link_handle = self._dc.get_joint_parent_body(joint_handle)\n                joint_handle = self._dc.get_rigid_body_parent_joint(link_handle)\n\n        force_data, _ = self._find_gripper_contacts(arm=arm, return_contact_positions=True)\n        contact_pos = None\n        for c_link_prim_path, c_contact_pos in force_data:\n            if c_link_prim_path == ag_link.prim_path:\n                contact_pos = np.array(c_contact_pos)\n                break\n        assert contact_pos is not None\n\n        # Joint frame set at the contact point\n        # Need to find distance between robot and contact point in robot link's local frame and\n        # ag link and contact point in ag link's local frame\n        joint_frame_pos = contact_pos\n        joint_frame_orn = np.array([0, 0, 0, 1.0])\n        eef_link_pos, eef_link_orn = self.eef_links[arm].get_position_orientation()\n        parent_frame_pos, parent_frame_orn = T.relative_pose_transform(joint_frame_pos, joint_frame_orn, eef_link_pos, eef_link_orn)\n        obj_link_pos, obj_link_orn = ag_link.get_position_orientation()\n        child_frame_pos, child_frame_orn = T.relative_pose_transform(joint_frame_pos, joint_frame_orn, obj_link_pos, obj_link_orn)\n\n        # Create the joint\n        joint_prim_path = f\"{self.eef_links[arm].prim_path}/ag_constraint\"\n        joint_prim = create_joint(\n            prim_path=joint_prim_path,\n            joint_type=joint_type,\n            body0=self.eef_links[arm].prim_path,\n            body1=ag_link.prim_path,\n            enabled=False,\n            stage=self._simulator.stage,\n        )\n\n        # Set the local pose of this joint\n        joint_prim.GetAttribute(\"physics:localPos0\").Set(Gf.Vec3f(*(parent_frame_pos / self.scale)))\n        joint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*(parent_frame_orn[[3, 0, 1, 2]])))\n        joint_prim.GetAttribute(\"physics:localPos1\").Set(Gf.Vec3f(*(child_frame_pos / ag_obj.scale)))\n        joint_prim.GetAttribute(\"physics:localRot1\").Set(Gf.Quatf(*(child_frame_orn[[3, 0, 1, 2]])))\n\n        # We have to toggle the joint from off to on after a physics step because of an omni quirk\n        # Otherwise the joint transform is very weird\n        app.update()\n        joint_prim.GetAttribute(\"physics:jointEnabled\").Set(True)\n\n        # Save a reference to this joint prim\n        self._ag_obj_constraints[arm] = joint_prim\n\n        # Modify max force based on user-determined assist parameters\n        # TODO\n        max_force = m.ASSIST_FORCE if joint_type == \"FixedJoint\" else m.ASSIST_FORCE * m.ARTICULATED_ASSIST_FRACTION\n        # joint_prim.GetAttribute(\"physics:breakForce\").Set(max_force)\n\n        self._ag_obj_constraint_params[arm] = {\n            \"ag_obj_prim_path\": ag_obj.prim_path,\n            \"ag_link_prim_path\": ag_link.prim_path,\n            \"ag_joint_prim_path\": joint_prim_path,\n            \"joint_type\": joint_type,\n            \"gripper_pos\": self.get_joint_positions()[self.gripper_control_idx[arm]],\n            \"max_force\": max_force,\n        }\n        self._ag_obj_in_hand[arm] = ag_obj\n        self._ag_freeze_gripper[arm] = True\n        # Disable collisions while picking things up\n        # TODO: Verify not needed!\n        # for finger_link in self.finger_links[arm]:\n        #     finger_link.add_filtered_collision_pair(prim=ag_obj)\n        for joint in self.finger_joints[arm]:\n            j_val = joint.get_state()[0][0]\n            self._ag_freeze_joint_pos[arm][joint.joint_name] = j_val\n\n    def _handle_assisted_grasping(self, action):\n        \"\"\"\n        Handles assisted grasping.\n\n        Args:\n            action (n-array): gripper action to apply. &gt;= 0 is release (open), &lt; 0 is grasp (close).\n        \"\"\"\n        # Loop over all arms\n        for arm in self.arm_names:\n            # Make sure gripper action dimension is only 1\n            assert (\n                self._controllers[\"gripper_{}\".format(arm)].command_dim == 1\n            ), \"Gripper {} controller command dim must be 1 to use assisted grasping, got: {}\".format(\n                arm, self._controllers[\"gripper_{}\".format(arm)].command_dim\n            )\n\n            # TODO: Why are we separately checking for complementary conditions?\n            threshold = np.mean(self._controllers[\"gripper_{}\".format(arm)].command_input_limits)\n            applying_grasp = action[self.controller_action_idx[\"gripper_{}\".format(arm)]] &lt; threshold\n            releasing_grasp = action[self.controller_action_idx[\"gripper_{}\".format(arm)]] &gt; threshold\n\n            # Execute gradual release of object\n            if self._ag_obj_in_hand[arm]:\n                if self._ag_release_counter[arm] is not None:\n                    self._handle_release_window(arm=arm)\n                else:\n                    # constraint_violated = (\n                    #     get_constraint_violation(self._ag_obj_cid[arm]) &gt; m.CONSTRAINT_VIOLATION_THRESHOLD\n                    # )\n                    # if constraint_violated or releasing_grasp:\n                    if gm.AG_CLOTH:\n                        self._update_constraint_cloth(arm=arm)\n\n                    if releasing_grasp:\n                        self._release_grasp(arm=arm)\n\n            elif applying_grasp:\n                self._ag_data[arm] = self._calculate_in_hand_object(arm=arm)\n                self._establish_grasp(arm=arm, ag_data=self._ag_data[arm])\n\n    def _update_constraint_cloth(self, arm=\"default\"):\n        \"\"\"\n        Update the AG constraint for cloth: for the fixed joint between the attachment point and the world, we set\n        the local pos to match the current eef link position plus the attachment_point_pos_local offset. As a result,\n        the joint will drive the attachment point to the updated position, which will then drive the cloth.\n        See _establish_grasp_cloth for more details.\n\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n        \"\"\"\n        attachment_point_pos_local = self._ag_obj_constraint_params[arm][\"attachment_point_pos_local\"]\n        eef_link_pos, eef_link_orn = self.eef_links[arm].get_position_orientation()\n        attachment_point_pos, _ = T.pose_transform(eef_link_pos, eef_link_orn, attachment_point_pos_local, [0, 0, 0, 1])\n        joint_prim = self._ag_obj_constraints[arm]\n        joint_prim.GetAttribute(\"physics:localPos1\").Set(Gf.Vec3f(*attachment_point_pos.astype(float)))\n\n    def _calculate_in_hand_object(self, arm=\"default\"):\n        if gm.AG_CLOTH:\n            return self._calculate_in_hand_object_cloth(arm)\n        else:\n            return self._calculate_in_hand_object_rigid(arm)\n\n    def _establish_grasp(self, arm=\"default\", ag_data=None):\n        if gm.AG_CLOTH:\n            return self._establish_grasp_cloth(arm, ag_data)\n        else:\n            return self._establish_grasp_rigid(arm, ag_data)\n\n    def _calculate_in_hand_object_cloth(self, arm=\"default\"):\n        \"\"\"\n        Same as _calculate_in_hand_object_rigid, except for cloth. Only one should be used at any given time.\n\n        Calculates which object to assisted-grasp for arm @arm. Returns an (BaseObject, RigidPrim, np.ndarray) tuple or\n        None if no valid AG-enabled object can be found.\n\n        1) Check if the gripper is closed enough\n        2) Go through each of the cloth object, and check if its attachment point link position is within the \"ghost\"\n        box volume of the gripper link.\n\n        Only returns the first valid object and ignore the rest.\n\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n\n        Returns:\n            None or 3-tuple: If a valid assisted-grasp object is found,\n                returns the corresponding (object, object_link, attachment_point_position), i.e.\n                ((BaseObject, RigidPrim, np.ndarray)) to the contacted in-hand object. Otherwise, returns None\n        \"\"\"\n        # TODO (eric): Assume joint_pos = 0 means fully closed\n        GRIPPER_FINGER_CLOSE_THRESHOLD = 0.03\n        gripper_finger_pos = self.get_joint_positions()[self.gripper_control_idx[arm]]\n        gripper_finger_close = np.sum(gripper_finger_pos) &lt; GRIPPER_FINGER_CLOSE_THRESHOLD\n        if not gripper_finger_close:\n            return None\n\n        cloth_objs = self._simulator.scene.object_registry(\"prim_type\", PrimType.CLOTH)\n        if cloth_objs is None:\n            return None\n\n        # TODO (eric): Only AG one cloth at any given moment.\n        # Returns the first cloth that overlaps with the \"ghost\" box volume\n        for cloth_obj in cloth_objs:\n            attachment_point_pos = cloth_obj.links[\"attachment_point\"].get_position()\n            particles_in_volume = self._ag_check_in_volume[arm]([attachment_point_pos])\n            if particles_in_volume.sum() &gt; 0:\n                return cloth_obj, cloth_obj.links[\"attachment_point\"], attachment_point_pos\n\n        return None\n\n    def _establish_grasp_cloth(self, arm=\"default\", ag_data=None):\n        \"\"\"\n        Same as _establish_grasp_cloth, except for cloth. Only one should be used at any given time.\n        Establishes an ag-assisted grasp, if enabled.\n\n        Create a fixed joint between the attachment point link of the cloth object and the world.\n        In theory, we could have created a fixed joint to the eef link, but omni doesn't support this as the robot has\n        an articulation root API attached to it, which is incompatible with the attachment API.\n\n        We also store attachment_point_pos_local as the attachment point position in the eef link frame when the fixed\n        joint is created. As the eef link frame changes its pose, we will use attachment_point_pos_local to figure out\n        the new attachment_point_pos in the world frame and set the fixed joint to there. See _update_constraint_cloth\n        for more details.\n\n        Args:\n            arm (str): specific arm to establish grasp.\n                Default is \"default\" which corresponds to the first entry in self.arm_names\n            ag_data (None or 3-tuple): If specified, should be the corresponding\n                (object, object_link, attachment_point_position), i.e. ((BaseObject, RigidPrim, np.ndarray)) to the]\n                contacted in-hand object\n        \"\"\"\n        arm = self.default_arm if arm == \"default\" else arm\n\n        # Return immediately if ag_data is None\n        if ag_data is None:\n            return\n\n        ag_obj, ag_link, attachment_point_pos = ag_data\n\n        # Find the attachment point position in the eef frame\n        eef_link_pos, eef_link_orn = self.eef_links[arm].get_position_orientation()\n        attachment_point_pos_local, _ = \\\n            T.relative_pose_transform(attachment_point_pos, [0, 0, 0, 1], eef_link_pos, eef_link_orn)\n\n        # Create the joint\n        # self._simulator.pause()\n        joint_prim_path = f\"{ag_link.prim_path}/ag_constraint\"\n        joint_type = \"FixedJoint\"\n        joint_prim = create_joint(\n            prim_path=joint_prim_path,\n            joint_type=joint_type,\n            body0=ag_link.prim_path,\n            body1=None,\n            enabled=False,\n            stage=self._simulator.stage,\n        )\n\n        # Set the local pose of this joint\n        joint_prim.GetAttribute(\"physics:localPos1\").Set(Gf.Vec3f(*attachment_point_pos))\n\n        # We have to toggle the joint from off to on after a physics step because of an omni quirk\n        # Otherwise the joint transform is very weird\n        app.update()\n        joint_prim.GetAttribute(\"physics:jointEnabled\").Set(True)\n\n        # Save a reference to this joint prim\n        self._ag_obj_constraints[arm] = joint_prim\n\n        # Modify max force based on user-determined assist parameters\n        # TODO\n        max_force = m.ASSIST_FORCE\n        # joint_prim.GetAttribute(\"physics:breakForce\").Set(max_force)\n\n        self._ag_obj_constraint_params[arm] = {\n            \"ag_obj_prim_path\": ag_obj.prim_path,\n            \"ag_link_prim_path\": ag_link.prim_path,\n            \"ag_joint_prim_path\": joint_prim_path,\n            \"joint_type\": joint_type,\n            \"gripper_pos\": self.get_joint_positions()[self.gripper_control_idx[arm]],\n            \"max_force\": max_force,\n            \"attachment_point_pos_local\": attachment_point_pos_local,\n        }\n        self._ag_obj_in_hand[arm] = ag_obj\n        self._ag_freeze_gripper[arm] = True\n        # Disable collisions while picking things up\n        # for finger_link in self.finger_links[arm]:\n        #     finger_link.add_filtered_collision_pair(prim=ag_obj)\n        for joint in self.finger_joints[arm]:\n            j_val = joint.get_state()[0][0]\n            self._ag_freeze_joint_pos[arm][joint.joint_name] = j_val\n\n    def _dump_state(self):\n        # Call super first\n        state = super()._dump_state()\n\n        # If we're using actual physical grasping, no extra state needed to save\n        if self.grasping_mode == \"physical\":\n            return state\n\n        # TODO: Include AG_state\n\n        return state\n\n    def _load_state(self, state):\n        super()._load_state(state=state)\n\n        # No additional loading needed if we're using physical grasping\n        if self.grasping_mode == \"physical\":\n            return\n\n        # TODO: Include AG_state\n\n    def _serialize(self, state):\n        # Call super first\n        state_flat = super()._serialize(state=state)\n\n        # No additional serialization needed if we're using physical grasping\n        if self.grasping_mode == \"physical\":\n            return state_flat\n\n        # TODO AG\n        return state_flat\n\n    def _deserialize(self, state):\n        # Call super first\n        state_dict, idx = super()._deserialize(state=state)\n\n        # No additional deserialization needed if we're using physical grasping\n        if self.grasping_mode == \"physical\":\n            return state_dict, idx\n\n        # TODO AG\n        return state_dict, idx\n\n    def can_toggle(self, toggle_position, toggle_distance_threshold):\n        # Calculate for any fingers in any arm\n        for arm in self.arm_names:\n            for link in self.finger_links[arm]:\n                link_pos = link.get_position()\n                if np.linalg.norm(np.array(link_pos) - np.array(toggle_position)) &lt; toggle_distance_threshold:\n                    return True\n        return False\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"ManipulationRobot\")\n        return classes\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot"},{"title":"<code>arm_control_idx</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to indices in low-level control vector corresponding to arm joints.</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_control_idx"},{"title":"<code>arm_joint_names</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to corresponding arm joint names, should correspond to specific joint names in this robot's underlying model file</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_joint_names"},{"title":"<code>arm_link_names</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to corresponding arm link names, should correspond to specific link names in this robot's underlying model file</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_link_names"},{"title":"<code>arm_links</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to robot links corresponding to that arm's links</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_links"},{"title":"<code>arm_names</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>list of str: List of arm names for this robot. Should correspond to the keys used to index into arm- and gripper-related dictionaries, e.g.: eef_link_names, finger_link_names, etc. Default is string enumeration based on @self.n_arms.</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.arm_names"},{"title":"<code>assisted_grasp_end_points</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping individual arm appendage names to array of GraspingPoint tuples, composed of (link_name, position) values specifying valid grasping end points located at cartesian (x,y,z) coordinates specified in link_name's local coordinate frame. These values will be used in conjunction with @self.assisted_grasp_start_points to trigger assisted grasps, where objects that intersect with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper appendage). By default, each entry returns None, and must be implemented by any robot subclass that wishes to use assisted grasping.</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.assisted_grasp_end_points"},{"title":"<code>assisted_grasp_start_points</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping individual arm appendage names to array of GraspingPoint tuples, composed of (link_name, position) values specifying valid grasping start points located at cartesian (x,y,z) coordinates specified in link_name's local coordinate frame. These values will be used in conjunction with @self.assisted_grasp_end_points to trigger assisted grasps, where objects that intersect with any ray starting at any point in @self.assisted_grasp_start_points and terminating at any point in @self.assisted_grasp_end_points will trigger an assisted grasp (calculated individually for each gripper appendage). By default, each entry returns None, and must be implemented by any robot subclass that wishes to use assisted grasping.</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.assisted_grasp_start_points"},{"title":"<code>default_arm</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Default arm name for this robot, corresponds to the first entry in @arm_names by default</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.default_arm"},{"title":"<code>eef_link_names</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to corresponding name of the EEF link, should correspond to specific link name in this robot's underlying model file</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.eef_link_names"},{"title":"<code>eef_links</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to robot link corresponding to that arm's eef link</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.eef_links"},{"title":"<code>finger_joint_names</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to array of joint names corresponding to this robot's fingers</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_joint_names"},{"title":"<code>finger_joints</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to robot joints corresponding to that arm's finger joints</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_joints"},{"title":"<code>finger_lengths</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to corresponding length of the fingers in that hand defined from the palm (assuming all fingers in one hand are equally long)</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_lengths"},{"title":"<code>finger_link_names</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to array of link names corresponding to this robot's fingers</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_link_names"},{"title":"<code>finger_links</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to robot links corresponding to that arm's finger links</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.finger_links"},{"title":"<code>grasping_mode</code>  <code>property</code>","text":"<p>Grasping mode of this robot. Is one of AG_MODES</p> <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Grasping mode for this robot</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.grasping_mode"},{"title":"<code>gripper_control_idx</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to indices in low-level control vector corresponding to gripper joints.</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.gripper_control_idx"},{"title":"<code>n_arms</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of arms this robot has. Returns 1 by default</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.n_arms"},{"title":"<code>robot_arm_descriptor_yamls</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Dictionary mapping arm appendage name to files path to the descriptor of the robot for IK Controller.</p>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.robot_arm_descriptor_yamls"},{"title":"<code>__init__(prim_path, name=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, load_config=None, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', grasping_mode='physical', **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>control_freq</code>  <code>float</code>  <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p>  <code>None</code>    <code>controller_config</code>  <code>None or dict</code>  <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p>  <code>None</code>    <code>action_type</code>  <code>str</code>  <p>one of {discrete, continuous} - what type of action space to use</p>  <code>'continuous'</code>    <code>action_normalize</code>  <code>bool</code>  <p>whether to normalize inputted actions. This will override any default values specified by this class.</p>  <code>True</code>    <code>reset_joint_pos</code>  <code>None or n-array</code>  <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p>  <code>None</code>    <code>obs_modalities</code>  <code>str or list of str</code>  <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p>  <code>'all'</code>    <code>proprio_obs</code>  <code>str or list of str</code>  <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p>  <code>'default'</code>    <code>grasping_mode</code>  <code>str</code>  <p>One of {\"physical\", \"assisted\", \"sticky\"}. If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force). If \"assisted\", will magnetize any object touching and within the gripper's fingers. If \"sticky\", will magnetize any object touching the gripper's fingers.</p>  <code>'physical'</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>robots/manipulation_robot.py</code> <pre><code>def __init__(\n    self,\n    # Shared kwargs in hierarchy\n    prim_path,\n    name=None,\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    load_config=None,\n\n    # Unique to USDObject hierarchy\n    abilities=None,\n\n    # Unique to ControllableObject hierarchy\n    control_freq=None,\n    controller_config=None,\n    action_type=\"continuous\",\n    action_normalize=True,\n    reset_joint_pos=None,\n\n    # Unique to BaseRobot\n    obs_modalities=\"all\",\n    proprio_obs=\"default\",\n\n    # Unique to ManipulationRobot\n    grasping_mode=\"physical\",\n\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n            If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n            If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n            If \"sticky\", will magnetize any object touching the gripper's fingers.\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Store relevant internal vars\n    assert_valid_key(key=grasping_mode, valid_keys=AG_MODES, name=\"grasping_mode\")\n    self._grasping_mode = grasping_mode\n\n    # Initialize other variables used for assistive grasping\n    self._ag_data = {arm: None for arm in self.arm_names}\n    self._ag_freeze_joint_pos = {\n        arm: {} for arm in self.arm_names\n    }  # Frozen positions for keeping fingers held still\n    self._ag_obj_in_hand = {arm: None for arm in self.arm_names}\n    self._ag_obj_constraints = {arm: None for arm in self.arm_names}\n    self._ag_obj_constraint_params = {arm: {} for arm in self.arm_names}\n    self._ag_freeze_gripper = {arm: None for arm in self.arm_names}\n    self._ag_release_counter = {arm: None for arm in self.arm_names}\n    self._ag_check_in_volume = {arm: None for arm in self.arm_names}\n    self._ag_calculate_volume = {arm: None for arm in self.arm_names}\n\n    # Call super() method\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        load_config=load_config,\n        abilities=abilities,\n        control_freq=control_freq,\n        controller_config=controller_config,\n        action_type=action_type,\n        action_normalize=action_normalize,\n        reset_joint_pos=reset_joint_pos,\n        obs_modalities=obs_modalities,\n        proprio_obs=proprio_obs,\n        **kwargs,\n    )\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.__init__"},{"title":"<code>get_eef_orientation(arm='default')</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>arm</code>  <code>str</code>  <p>specific arm to grab eef orientation. Default is \"default\" which corresponds to the first entry in self.arm_names</p>  <code>'default'</code>     <p>Returns:</p>    Type Description       <p>3-array: (x,y,z,w) global quaternion orientation for this robot's end-effector corresponding to arm @arm</p>     Source code in <code>robots/manipulation_robot.py</code> <pre><code>def get_eef_orientation(self, arm=\"default\"):\n    \"\"\"\n    Args:\n        arm (str): specific arm to grab eef orientation. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n\n    Returns:\n        3-array: (x,y,z,w) global quaternion orientation for this robot's end-effector corresponding\n            to arm @arm\n    \"\"\"\n    arm = self.default_arm if arm == \"default\" else arm\n    return self._links[self.eef_link_names[arm]].get_orientation()\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_eef_orientation"},{"title":"<code>get_eef_position(arm='default')</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>arm</code>  <code>str</code>  <p>specific arm to grab eef position. Default is \"default\" which corresponds to the first entry in self.arm_names</p>  <code>'default'</code>     <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) global end-effector Cartesian position for this robot's end-effector corresponding to arm @arm</p>     Source code in <code>robots/manipulation_robot.py</code> <pre><code>def get_eef_position(self, arm=\"default\"):\n    \"\"\"\n    Args:\n        arm (str): specific arm to grab eef position. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n\n    Returns:\n        3-array: (x,y,z) global end-effector Cartesian position for this robot's end-effector corresponding\n            to arm @arm\n    \"\"\"\n    arm = self.default_arm if arm == \"default\" else arm\n    return self._links[self.eef_link_names[arm]].get_position()\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_eef_position"},{"title":"<code>get_relative_eef_orientation(arm='default')</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>arm</code>  <code>str</code>  <p>specific arm to grab relative eef orientation. Default is \"default\" which corresponds to the first entry in self.arm_names</p>  <code>'default'</code>     <p>Returns:</p>    Type Description       <p>4-array: (x,y,z,w) quaternion orientation of end-effector relative to robot base frame</p>     Source code in <code>robots/manipulation_robot.py</code> <pre><code>def get_relative_eef_orientation(self, arm=\"default\"):\n    \"\"\"\n    Args:\n        arm (str): specific arm to grab relative eef orientation.\n            Default is \"default\" which corresponds to the first entry in self.arm_names\n\n    Returns:\n        4-array: (x,y,z,w) quaternion orientation of end-effector relative to robot base frame\n    \"\"\"\n    arm = self.default_arm if arm == \"default\" else arm\n    return self.get_relative_eef_pose(arm=arm)[1]\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_relative_eef_orientation"},{"title":"<code>get_relative_eef_pose(arm='default', mat=False)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>arm</code>  <code>str</code>  <p>specific arm to grab eef pose. Default is \"default\" which corresponds to the first entry in self.arm_names</p>  <code>'default'</code>    <code>mat</code>  <code>bool</code>  <p>whether to return pose in matrix form (mat=True) or (pos, quat) tuple (mat=False)</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>2-tuple or (4, 4)-array: End-effector pose, either in 4x4 homogeneous matrix form (if @mat=True) or (pos, quat) tuple (if @mat=False), corresponding to arm @arm</p>     Source code in <code>robots/manipulation_robot.py</code> <pre><code>def get_relative_eef_pose(self, arm=\"default\", mat=False):\n    \"\"\"\n    Args:\n        arm (str): specific arm to grab eef pose. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n        mat (bool): whether to return pose in matrix form (mat=True) or (pos, quat) tuple (mat=False)\n\n    Returns:\n        2-tuple or (4, 4)-array: End-effector pose, either in 4x4 homogeneous\n            matrix form (if @mat=True) or (pos, quat) tuple (if @mat=False), corresponding to arm @arm\n    \"\"\"\n    arm = self.default_arm if arm == \"default\" else arm\n    eef_link_pose = self.eef_links[arm].get_position_orientation()\n    base_link_pose = self.get_position_orientation()\n    pose = T.relative_pose_transform(*eef_link_pose, *base_link_pose)\n    return T.pose2mat(pose) if mat else pose\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_relative_eef_pose"},{"title":"<code>get_relative_eef_position(arm='default')</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>arm</code>  <code>str</code>  <p>specific arm to grab relative eef pos. Default is \"default\" which corresponds to the first entry in self.arm_names</p>  <code>'default'</code>     <p>Returns:</p>    Type Description       <p>3-array: (x,y,z) Cartesian position of end-effector relative to robot base frame</p>     Source code in <code>robots/manipulation_robot.py</code> <pre><code>def get_relative_eef_position(self, arm=\"default\"):\n    \"\"\"\n    Args:\n        arm (str): specific arm to grab relative eef pos.\n            Default is \"default\" which corresponds to the first entry in self.arm_names\n\n\n    Returns:\n        3-array: (x,y,z) Cartesian position of end-effector relative to robot base frame\n    \"\"\"\n    arm = self.default_arm if arm == \"default\" else arm\n    return self.get_relative_eef_pose(arm=arm)[0]\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.get_relative_eef_position"},{"title":"<code>is_grasping(arm='default', candidate_obj=None)</code>","text":"<p>Returns True if the robot is grasping the target option @candidate_obj or any object if @candidate_obj is None.</p> <p>Parameters:</p>    Name Type Description Default     <code>arm</code>  <code>str</code>  <p>specific arm to check for grasping. Default is \"default\" which corresponds to the first entry in self.arm_names</p>  <code>'default'</code>    <code>candidate_obj</code>  <code>EntityPrim or None</code>  <p>object to check if this robot is currently grasping. If None, then will be a general (object-agnostic) check for grasping. Note: if self.grasping_mode is \"physical\", then @candidate_obj will be ignored completely</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>IsGraspingState</code>   <p>For the specific manipulator appendage, returns IsGraspingState.TRUE if it is grasping (potentially @candidate_obj if specified), IsGraspingState.FALSE if it is not grasping, and IsGraspingState.UNKNOWN if unknown.</p>     Source code in <code>robots/manipulation_robot.py</code> <pre><code>def is_grasping(self, arm=\"default\", candidate_obj=None):\n    \"\"\"\n    Returns True if the robot is grasping the target option @candidate_obj or any object if @candidate_obj is None.\n\n    Args:\n        arm (str): specific arm to check for grasping. Default is \"default\" which corresponds to the first entry\n            in self.arm_names\n        candidate_obj (EntityPrim or None): object to check if this robot is currently grasping. If None, then\n            will be a general (object-agnostic) check for grasping.\n            Note: if self.grasping_mode is \"physical\", then @candidate_obj will be ignored completely\n\n    Returns:\n        IsGraspingState: For the specific manipulator appendage, returns IsGraspingState.TRUE if it is grasping\n            (potentially @candidate_obj if specified), IsGraspingState.FALSE if it is not grasping,\n            and IsGraspingState.UNKNOWN if unknown.\n    \"\"\"\n    arm = self.default_arm if arm == \"default\" else arm\n    if self.grasping_mode != \"physical\":\n        is_grasping_obj = (\n            self._ag_obj_in_hand[arm] is not None\n            if candidate_obj is None\n            else self._ag_obj_in_hand[arm] == candidate_obj\n        )\n        is_grasping = (\n            IsGraspingState.TRUE\n            if is_grasping_obj and self._ag_release_counter[arm] is None\n            else IsGraspingState.FALSE\n        )\n    else:\n        # Infer from the gripper controller the state\n        is_grasping = self._controllers[\"gripper_{}\".format(arm)].is_grasping()\n        # If candidate obj is not None, we also check to see if our fingers are in contact with the object\n        if is_grasping and candidate_obj is not None:\n            grasping_obj = False\n            obj_links = {link.prim_path for link in candidate_obj.links.values()}\n            finger_links = {link.prim_path for link in self.finger_links[arm]}\n            for c in self.contact_list():\n                c_set = {c.body0, c.body1}\n                # Valid grasping of object if one of the set is a finger link and the other is the grasped object\n                if len(c_set - finger_links) == 1 and len(c_set - obj_links) == 1:\n                    grasping_obj = True\n                    break\n            # Update is_grasping\n            is_grasping = grasping_obj\n\n    return is_grasping\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.is_grasping"},{"title":"<code>release_grasp_immediately()</code>","text":"<p>Magic action to release this robot's grasp for all arms at once. As opposed to @_release_grasp, this method would byupass the release window mechanism and immediately release.</p>  Source code in <code>robots/manipulation_robot.py</code> <pre><code>def release_grasp_immediately(self):\n    \"\"\"\n    Magic action to release this robot's grasp for all arms at once.\n    As opposed to @_release_grasp, this method would byupass the release window mechanism and immediately release.\n    \"\"\"\n    for arm in self.arm_names:\n        if self._ag_obj_in_hand[arm] is not None:\n            self._release_grasp(arm=arm)\n            # TODO: Verify not needed!\n            # for finger_link in self.finger_links[arm]:\n            #     finger_link.remove_filtered_collision_pair(prim=self._ag_obj_in_hand[arm])\n            self._ag_obj_in_hand[arm] = None\n            self._ag_release_counter[arm] = None\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.ManipulationRobot.release_grasp_immediately"},{"title":"<code>can_assisted_grasp(obj)</code>","text":"<p>Check whether an object @obj can be grasped. This is done by checking its category to see if is in the allowlist.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object targeted for an assisted grasp</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether or not this object can be grasped</p>     Source code in <code>robots/manipulation_robot.py</code> <pre><code>def can_assisted_grasp(obj):\n    \"\"\"\n    Check whether an object @obj can be grasped. This is done\n    by checking its category to see if is in the allowlist.\n\n    Args:\n        obj (BaseObject): Object targeted for an assisted grasp\n\n    Returns:\n        bool: Whether or not this object can be grasped\n    \"\"\"\n\n    if isinstance(obj, DatasetObject) and obj.category != \"object\":\n        # Use manually defined allowlist\n        return obj.category in m.ASSIST_GRASP_OBJ_CATEGORIES\n    else:\n        # Use fallback based on mass\n        mass = obj.mass\n        print(f\"Mass for AG: obj: {mass}, max mass: {m.ASSIST_GRASP_MASS_THRESHOLD}, obj: {obj.name}\")\n        return mass &lt;= m.ASSIST_GRASP_MASS_THRESHOLD\n</code></pre>","location":"reference/robots/manipulation_robot.html#robots.manipulation_robot.can_assisted_grasp"},{"title":"robot_base","text":"","location":"reference/robots/robot_base.html"},{"title":"<code>BaseRobot</code>","text":"<p>         Bases: <code>USDObject</code>, <code>ControllableObject</code>, <code>GymObservable</code></p> <p>Base class for USD-based robot agents.</p> <p>This class handles object loading, and provides method interfaces that should be implemented by subclassed robots.</p>  Source code in <code>robots/robot_base.py</code> <pre><code>class BaseRobot(USDObject, ControllableObject, GymObservable):\n    \"\"\"\n    Base class for USD-based robot agents.\n\n    This class handles object loading, and provides method interfaces that should be\n    implemented by subclassed robots.\n    \"\"\"\n    def __init__(\n        self,\n        # Shared kwargs in hierarchy\n        prim_path,\n        name=None,\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        load_config=None,\n\n        # Unique to USDObject hierarchy\n        abilities=None,\n\n        # Unique to ControllableObject hierarchy\n        control_freq=None,\n        controller_config=None,\n        action_type=\"continuous\",\n        action_normalize=True,\n        reset_joint_pos=None,\n\n        # Unique to this class\n        obs_modalities=\"all\",\n        proprio_obs=\"default\",\n\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Store inputs\n        self._obs_modalities = obs_modalities if obs_modalities == \"all\" else \\\n            {obs_modalities} if isinstance(obs_modalities, str) else set(obs_modalities)              # this will get updated later when we fill in our sensors\n        self._proprio_obs = self.default_proprio_obs if proprio_obs == \"default\" else list(proprio_obs)\n\n        # Process abilities\n        robot_abilities = {\"robot\": {}}\n        abilities = robot_abilities if abilities is None else robot_abilities.update(abilities)\n\n        # Initialize internal attributes that will be loaded later\n        self._sensors = None                     # e.g.: scan sensor, vision sensor\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            usd_path=self.usd_path,\n            name=name,\n            category=m.ROBOT_CATEGORY,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            prim_type=PrimType.RIGID,\n            include_default_states=True,\n            load_config=load_config,\n            abilities=abilities,\n            control_freq=control_freq,\n            controller_config=controller_config,\n            action_type=action_type,\n            action_normalize=action_normalize,\n            reset_joint_pos=reset_joint_pos,\n            **kwargs,\n        )\n\n    def _post_load(self):\n        # Run super post load first\n        super()._post_load()\n\n        # Possibly force enabling of contact sensing for this robot if we set the global flag\n        # TODO: Remove this once we have a more optimized solution\n        # Only create contact report api if we're not visual only\n        if (not self._visual_only) and gm.ENABLE_ROBOT_CONTACT_REPORTING:\n            for link in self._links.values():\n                PhysxSchema.PhysxContactReportAPI(link.prim) if \\\n                    link.prim.HasAPI(PhysxSchema.PhysxContactReportAPI) else \\\n                    PhysxSchema.PhysxContactReportAPI.Apply(link.prim)\n\n        # Search for any sensors this robot might have attached to any of its links\n        self._sensors = OrderedDict()\n        obs_modalities = set()\n        for link_name, link in self._links.items():\n            # Search through all children prims and see if we find any sensor\n            for prim in link.prim.GetChildren():\n                prim_type = prim.GetPrimTypeInfo().GetTypeName()\n                if prim_type in SENSOR_PRIMS_TO_SENSOR_CLS:\n                    # Infer what obs modalities to use for this sensor\n                    sensor_cls = SENSOR_PRIMS_TO_SENSOR_CLS[prim_type]\n                    modalities = sensor_cls.all_modalities if self._obs_modalities == \"all\" else \\\n                        sensor_cls.all_modalities.intersection(self._obs_modalities)\n                    obs_modalities = obs_modalities.union(modalities)\n                    # Create the sensor and store it internally\n                    sensor = create_sensor(\n                        sensor_type=prim_type,\n                        prim_path=str(prim.GetPrimPath()),\n                        name=f\"{self.name}:{link_name}_{prim_type}_sensor\",\n                        modalities=modalities,\n                    )\n                    self._sensors[sensor.name] = sensor\n\n        # Since proprioception isn't an actual sensor, we need to possibly manually add it here as well\n        if self._obs_modalities == \"all\":\n            obs_modalities.add(\"proprio\")\n\n        # Update our overall obs modalities\n        self._obs_modalities = obs_modalities\n\n    def _initialize(self):\n        # Run super first\n        super()._initialize()\n\n        # Initialize all sensors\n        for sensor in self._sensors.values():\n            sensor.initialize()\n\n        # Validate this robot configuration\n        self._validate_configuration()\n\n    def _validate_configuration(self):\n        \"\"\"\n        Run any needed sanity checks to make sure this robot was created correctly.\n        \"\"\"\n        pass\n\n    def can_toggle(self, toggle_position, toggle_distance_threshold):\n        \"\"\"\n        Returns True if the part of the robot that can toggle a toggleable is within the given range of a\n        point corresponding to a toggle marker\n        by default, we assume robot cannot toggle toggle markers\n\n        Args:\n            toggle_position (3-array): (x,y,z) cartesian position values as a reference point for evaluating\n                whether a toggle can occur\n            toggle_distance_threshold (float): distance value below which a toggle is allowed\n\n        Returns:\n            bool: True if the part of the robot that can toggle a toggleable is within the given range of a\n                point corresponding to a toggle marker. By default, we assume robot cannot toggle toggle markers\n        \"\"\"\n        return False\n\n    def get_obs(self):\n        \"\"\"\n        Grabs all observations from the robot. This is keyword-mapped based on each observation modality\n            (e.g.: proprio, rgb, etc.)\n\n        Returns:\n            OrderedDict: Keyword-mapped dictionary mapping observation modality names to\n                observations (usually np arrays)\n        \"\"\"\n        # Our sensors already know what observation modalities it has, so we simply iterate over all of them\n        # and grab their observations, processing them into a flat dict\n        obs_dict = OrderedDict()\n        for sensor_name, sensor in self._sensors.items():\n            sensor_obs = sensor.get_obs()\n            for obs_modality, obs in sensor_obs.items():\n                obs_dict[f\"{sensor_name}_{obs_modality}\"] = obs\n\n        # Have to handle proprio separately since it's not an actual sensor\n        if \"proprio\" in self._obs_modalities:\n            obs_dict[\"proprio\"] = self.get_proprioception()\n\n        return obs_dict\n\n    def get_proprioception(self):\n        \"\"\"\n        Returns:\n            n-array: numpy array of all robot-specific proprioceptive observations.\n        \"\"\"\n        proprio_dict = self._get_proprioception_dict()\n        return np.concatenate([proprio_dict[obs] for obs in self._proprio_obs])\n\n    def _get_proprioception_dict(self):\n        \"\"\"\n        Returns:\n            OrderedDict: keyword-mapped proprioception observations available for this robot.\n                Can be extended by subclasses\n        \"\"\"\n        joint_positions = self.get_joint_positions(normalized=False)\n        joint_velocities = self.get_joint_velocities(normalized=False)\n        joint_efforts = self.get_joint_efforts(normalized=False)\n        pos, ori = self.get_position(), self.get_rpy()\n        return OrderedDict(\n            joint_qpos=joint_positions,\n            joint_qpos_sin=np.sin(joint_positions),\n            joint_qpos_cos=np.cos(joint_positions),\n            joint_qvel=joint_velocities,\n            joint_qeffort=joint_efforts,\n            robot_pos=pos,\n            robot_ori_cos=np.cos(ori),\n            robot_ori_sin=np.sin(ori),\n            robot_lin_vel=self.get_linear_velocity(),\n            robot_ang_vel=self.get_angular_velocity(),\n        )\n\n    def _load_observation_space(self):\n        # We compile observation spaces from our sensors\n        obs_space = OrderedDict()\n\n        for sensor_name, sensor in self._sensors.items():\n            # Load the sensor observation space\n            sensor_obs_space = sensor.load_observation_space()\n            for obs_modality, obs_modality_space in sensor_obs_space.items():\n                obs_space[f\"{sensor_name}_{obs_modality}\"] = obs_modality_space\n\n        # Have to handle proprio separately since it's not an actual sensor\n        if \"proprio\" in self._obs_modalities:\n            obs_space[\"proprio\"] = self._build_obs_box_space(shape=(self.proprioception_dim,), low=-np.inf, high=np.inf)\n\n        return obs_space\n\n    def add_obs_modality(self, modality):\n        \"\"\"\n        Adds observation modality @modality to this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES\n\n        Args:\n            modality (str): Observation modality to add to this robot\n        \"\"\"\n        # Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n        # then we add it\n        for sensor in self._sensors.values():\n            if modality in sensor.all_modalities:\n                sensor.add_modality(modality=modality)\n\n    def remove_obs_modality(self, modality):\n        \"\"\"\n        Remove observation modality @modality from this robot. Note: Should be one of\n        omnigibson.sensors.ALL_SENSOR_MODALITIES\n\n        Args:\n            modality (str): Observation modality to remove from this robot\n        \"\"\"\n        # Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n        # then we remove it\n        for sensor in self._sensors.values():\n            if modality in sensor.all_modalities:\n                sensor.remove_modality(modality=modality)\n\n    def visualize_sensors(self):\n        \"\"\"\n        Renders this robot's key sensors, visualizing them via matplotlib plots\n        \"\"\"\n        frames = OrderedDict()\n        remaining_obs_modalities = deepcopy(self.obs_modalities)\n        for sensor in self.sensors.values():\n            obs = sensor.get_obs()\n            sensor_frames = []\n            if isinstance(sensor, VisionSensor):\n                # We check for rgb, depth, normal, seg_instance\n                for modality in [\"rgb\", \"depth\", \"normal\", \"seg_instance\"]:\n                    if modality in sensor.modalities:\n                        ob = obs[modality]\n                        if modality == \"rgb\":\n                            # Ignore alpha channel, map to floats\n                            ob = ob[:, :, :3] / 255.0\n                        elif modality == \"seg_instance\":\n                            # Map IDs to rgb\n                            ob = segmentation_to_rgb(ob, N=256) / 255.0\n                        elif modality == \"normal\":\n                            # Re-map to 0 - 1 range\n                            ob = (ob + 1.0) / 2.0\n                        else:\n                            # Depth, nothing to do here\n                            pass\n                        # Add this observation to our frames and remove the modality\n                        sensor_frames.append((modality, ob))\n                        remaining_obs_modalities -= {modality}\n                    else:\n                        # Warn user that we didn't find this modality\n                        print(f\"Modality {modality} is not active in sensor {sensor.name}, skipping...\")\n            elif isinstance(sensor, ScanSensor):\n                # We check for occupancy_grid\n                occupancy_grid = obs.get(\"occupancy_grid\", None)\n                if occupancy_grid is not None:\n                    sensor_frames.append((\"occupancy_grid\", occupancy_grid))\n                    remaining_obs_modalities -= {\"occupancy_grid\"}\n\n            # Map the sensor name to the frames for that sensor\n            frames[sensor.name] = sensor_frames\n\n        # Warn user that any remaining modalities are not able to be visualized\n        if len(remaining_obs_modalities) &gt; 0:\n            print(f\"Modalities: {remaining_obs_modalities} cannot be visualized, skipping...\")\n\n        # Write all the frames to a plot\n        for sensor_name, sensor_frames in frames.items():\n            n_sensor_frames = len(sensor_frames)\n            if n_sensor_frames &gt; 0:\n                fig, axes = plt.subplots(nrows=1, ncols=n_sensor_frames)\n                if n_sensor_frames == 1:\n                    axes = [axes]\n                # Dump frames and set each subtitle\n                for i, (modality, frame) in enumerate(sensor_frames):\n                    axes[i].imshow(frame)\n                    axes[i].set_title(modality)\n                    axes[i].set_axis_off()\n                # Set title\n                fig.suptitle(sensor_name)\n                plt.show(block=False)\n\n        # One final plot show so all the figures get rendered\n        plt.show()\n\n    @property\n    def sensors(self):\n        \"\"\"\n        Returns:\n            OrderedDict: Keyword-mapped dictionary mapping sensor names to BaseSensor instances owned by this robot\n        \"\"\"\n        return self._sensors\n\n    @property\n    def obs_modalities(self):\n        \"\"\"\n        Returns:\n            set of str: Observation modalities used for this robot (e.g.: proprio, rgb, etc.)\n        \"\"\"\n        assert self._loaded, \"Cannot check observation modalities until we load this robot!\"\n        return self._obs_modalities\n\n    @property\n    def proprioception_dim(self):\n        \"\"\"\n        Returns:\n            int: Size of self.get_proprioception() vector\n        \"\"\"\n        return len(self.get_proprioception())\n\n    @property\n    def default_proprio_obs(self):\n        \"\"\"\n        Returns:\n            list of str: Default proprioception observations to use\n        \"\"\"\n        return []\n\n    @property\n    def model_name(self):\n        \"\"\"\n        Returns:\n            str: name of this robot model. usually corresponds to the class name of a given robot model\n        \"\"\"\n        return self.__class__.__name__\n\n    @property\n    @abstractmethod\n    def usd_path(self):\n        # For all robots, this must be specified a priori, before we actually initialize the USDObject constructor!\n        # So we override the parent implementation, and make this an abstract method\n        raise NotImplementedError\n\n    @property\n    def urdf_path(self):\n        \"\"\"\n        Returns:\n            str: file path to the robot urdf file.\n        \"\"\"\n        raise NotImplementedError\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseRobot\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global robot registry -- override super registry\n        global REGISTERED_ROBOTS\n        return REGISTERED_ROBOTS\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot"},{"title":"<code>default_proprio_obs</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>list of str: Default proprioception observations to use</p>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.default_proprio_obs"},{"title":"<code>model_name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>name of this robot model. usually corresponds to the class name of a given robot model</p>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.model_name"},{"title":"<code>obs_modalities</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>set of str: Observation modalities used for this robot (e.g.: proprio, rgb, etc.)</p>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.obs_modalities"},{"title":"<code>proprioception_dim</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Size of self.get_proprioception() vector</p>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.proprioception_dim"},{"title":"<code>sensors</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Keyword-mapped dictionary mapping sensor names to BaseSensor instances owned by this robot</p>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.sensors"},{"title":"<code>urdf_path</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>file path to the robot urdf file.</p>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.urdf_path"},{"title":"<code>__init__(prim_path, name=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, load_config=None, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>control_freq</code>  <code>float</code>  <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p>  <code>None</code>    <code>controller_config</code>  <code>None or dict</code>  <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p>  <code>None</code>    <code>action_type</code>  <code>str</code>  <p>one of {discrete, continuous} - what type of action space to use</p>  <code>'continuous'</code>    <code>action_normalize</code>  <code>bool</code>  <p>whether to normalize inputted actions. This will override any default values specified by this class.</p>  <code>True</code>    <code>reset_joint_pos</code>  <code>None or n-array</code>  <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p>  <code>None</code>    <code>obs_modalities</code>  <code>str or list of str</code>  <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p>  <code>'all'</code>    <code>proprio_obs</code>  <code>str or list of str</code>  <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p>  <code>'default'</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>robots/robot_base.py</code> <pre><code>def __init__(\n    self,\n    # Shared kwargs in hierarchy\n    prim_path,\n    name=None,\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    load_config=None,\n\n    # Unique to USDObject hierarchy\n    abilities=None,\n\n    # Unique to ControllableObject hierarchy\n    control_freq=None,\n    controller_config=None,\n    action_type=\"continuous\",\n    action_normalize=True,\n    reset_joint_pos=None,\n\n    # Unique to this class\n    obs_modalities=\"all\",\n    proprio_obs=\"default\",\n\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Store inputs\n    self._obs_modalities = obs_modalities if obs_modalities == \"all\" else \\\n        {obs_modalities} if isinstance(obs_modalities, str) else set(obs_modalities)              # this will get updated later when we fill in our sensors\n    self._proprio_obs = self.default_proprio_obs if proprio_obs == \"default\" else list(proprio_obs)\n\n    # Process abilities\n    robot_abilities = {\"robot\": {}}\n    abilities = robot_abilities if abilities is None else robot_abilities.update(abilities)\n\n    # Initialize internal attributes that will be loaded later\n    self._sensors = None                     # e.g.: scan sensor, vision sensor\n\n    # Run super init\n    super().__init__(\n        prim_path=prim_path,\n        usd_path=self.usd_path,\n        name=name,\n        category=m.ROBOT_CATEGORY,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        prim_type=PrimType.RIGID,\n        include_default_states=True,\n        load_config=load_config,\n        abilities=abilities,\n        control_freq=control_freq,\n        controller_config=controller_config,\n        action_type=action_type,\n        action_normalize=action_normalize,\n        reset_joint_pos=reset_joint_pos,\n        **kwargs,\n    )\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.__init__"},{"title":"<code>add_obs_modality(modality)</code>","text":"<p>Adds observation modality @modality to this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES</p> <p>Parameters:</p>    Name Type Description Default     <code>modality</code>  <code>str</code>  <p>Observation modality to add to this robot</p>  required      Source code in <code>robots/robot_base.py</code> <pre><code>def add_obs_modality(self, modality):\n    \"\"\"\n    Adds observation modality @modality to this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES\n\n    Args:\n        modality (str): Observation modality to add to this robot\n    \"\"\"\n    # Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n    # then we add it\n    for sensor in self._sensors.values():\n        if modality in sensor.all_modalities:\n            sensor.add_modality(modality=modality)\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.add_obs_modality"},{"title":"<code>can_toggle(toggle_position, toggle_distance_threshold)</code>","text":"<p>Returns True if the part of the robot that can toggle a toggleable is within the given range of a point corresponding to a toggle marker by default, we assume robot cannot toggle toggle markers</p> <p>Parameters:</p>    Name Type Description Default     <code>toggle_position</code>  <code>3-array</code>  <p>(x,y,z) cartesian position values as a reference point for evaluating whether a toggle can occur</p>  required    <code>toggle_distance_threshold</code>  <code>float</code>  <p>distance value below which a toggle is allowed</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if the part of the robot that can toggle a toggleable is within the given range of a point corresponding to a toggle marker. By default, we assume robot cannot toggle toggle markers</p>     Source code in <code>robots/robot_base.py</code> <pre><code>def can_toggle(self, toggle_position, toggle_distance_threshold):\n    \"\"\"\n    Returns True if the part of the robot that can toggle a toggleable is within the given range of a\n    point corresponding to a toggle marker\n    by default, we assume robot cannot toggle toggle markers\n\n    Args:\n        toggle_position (3-array): (x,y,z) cartesian position values as a reference point for evaluating\n            whether a toggle can occur\n        toggle_distance_threshold (float): distance value below which a toggle is allowed\n\n    Returns:\n        bool: True if the part of the robot that can toggle a toggleable is within the given range of a\n            point corresponding to a toggle marker. By default, we assume robot cannot toggle toggle markers\n    \"\"\"\n    return False\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.can_toggle"},{"title":"<code>get_obs()</code>","text":"<p>Grabs all observations from the robot. This is keyword-mapped based on each observation modality     (e.g.: proprio, rgb, etc.)</p> <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Keyword-mapped dictionary mapping observation modality names to observations (usually np arrays)</p>     Source code in <code>robots/robot_base.py</code> <pre><code>def get_obs(self):\n    \"\"\"\n    Grabs all observations from the robot. This is keyword-mapped based on each observation modality\n        (e.g.: proprio, rgb, etc.)\n\n    Returns:\n        OrderedDict: Keyword-mapped dictionary mapping observation modality names to\n            observations (usually np arrays)\n    \"\"\"\n    # Our sensors already know what observation modalities it has, so we simply iterate over all of them\n    # and grab their observations, processing them into a flat dict\n    obs_dict = OrderedDict()\n    for sensor_name, sensor in self._sensors.items():\n        sensor_obs = sensor.get_obs()\n        for obs_modality, obs in sensor_obs.items():\n            obs_dict[f\"{sensor_name}_{obs_modality}\"] = obs\n\n    # Have to handle proprio separately since it's not an actual sensor\n    if \"proprio\" in self._obs_modalities:\n        obs_dict[\"proprio\"] = self.get_proprioception()\n\n    return obs_dict\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.get_obs"},{"title":"<code>get_proprioception()</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: numpy array of all robot-specific proprioceptive observations.</p>     Source code in <code>robots/robot_base.py</code> <pre><code>def get_proprioception(self):\n    \"\"\"\n    Returns:\n        n-array: numpy array of all robot-specific proprioceptive observations.\n    \"\"\"\n    proprio_dict = self._get_proprioception_dict()\n    return np.concatenate([proprio_dict[obs] for obs in self._proprio_obs])\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.get_proprioception"},{"title":"<code>remove_obs_modality(modality)</code>","text":"<p>Remove observation modality @modality from this robot. Note: Should be one of omnigibson.sensors.ALL_SENSOR_MODALITIES</p> <p>Parameters:</p>    Name Type Description Default     <code>modality</code>  <code>str</code>  <p>Observation modality to remove from this robot</p>  required      Source code in <code>robots/robot_base.py</code> <pre><code>def remove_obs_modality(self, modality):\n    \"\"\"\n    Remove observation modality @modality from this robot. Note: Should be one of\n    omnigibson.sensors.ALL_SENSOR_MODALITIES\n\n    Args:\n        modality (str): Observation modality to remove from this robot\n    \"\"\"\n    # Iterate over all sensors we own, and if the requested modality is a part of its possible valid modalities,\n    # then we remove it\n    for sensor in self._sensors.values():\n        if modality in sensor.all_modalities:\n            sensor.remove_modality(modality=modality)\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.remove_obs_modality"},{"title":"<code>visualize_sensors()</code>","text":"<p>Renders this robot's key sensors, visualizing them via matplotlib plots</p>  Source code in <code>robots/robot_base.py</code> <pre><code>def visualize_sensors(self):\n    \"\"\"\n    Renders this robot's key sensors, visualizing them via matplotlib plots\n    \"\"\"\n    frames = OrderedDict()\n    remaining_obs_modalities = deepcopy(self.obs_modalities)\n    for sensor in self.sensors.values():\n        obs = sensor.get_obs()\n        sensor_frames = []\n        if isinstance(sensor, VisionSensor):\n            # We check for rgb, depth, normal, seg_instance\n            for modality in [\"rgb\", \"depth\", \"normal\", \"seg_instance\"]:\n                if modality in sensor.modalities:\n                    ob = obs[modality]\n                    if modality == \"rgb\":\n                        # Ignore alpha channel, map to floats\n                        ob = ob[:, :, :3] / 255.0\n                    elif modality == \"seg_instance\":\n                        # Map IDs to rgb\n                        ob = segmentation_to_rgb(ob, N=256) / 255.0\n                    elif modality == \"normal\":\n                        # Re-map to 0 - 1 range\n                        ob = (ob + 1.0) / 2.0\n                    else:\n                        # Depth, nothing to do here\n                        pass\n                    # Add this observation to our frames and remove the modality\n                    sensor_frames.append((modality, ob))\n                    remaining_obs_modalities -= {modality}\n                else:\n                    # Warn user that we didn't find this modality\n                    print(f\"Modality {modality} is not active in sensor {sensor.name}, skipping...\")\n        elif isinstance(sensor, ScanSensor):\n            # We check for occupancy_grid\n            occupancy_grid = obs.get(\"occupancy_grid\", None)\n            if occupancy_grid is not None:\n                sensor_frames.append((\"occupancy_grid\", occupancy_grid))\n                remaining_obs_modalities -= {\"occupancy_grid\"}\n\n        # Map the sensor name to the frames for that sensor\n        frames[sensor.name] = sensor_frames\n\n    # Warn user that any remaining modalities are not able to be visualized\n    if len(remaining_obs_modalities) &gt; 0:\n        print(f\"Modalities: {remaining_obs_modalities} cannot be visualized, skipping...\")\n\n    # Write all the frames to a plot\n    for sensor_name, sensor_frames in frames.items():\n        n_sensor_frames = len(sensor_frames)\n        if n_sensor_frames &gt; 0:\n            fig, axes = plt.subplots(nrows=1, ncols=n_sensor_frames)\n            if n_sensor_frames == 1:\n                axes = [axes]\n            # Dump frames and set each subtitle\n            for i, (modality, frame) in enumerate(sensor_frames):\n                axes[i].imshow(frame)\n                axes[i].set_title(modality)\n                axes[i].set_axis_off()\n            # Set title\n            fig.suptitle(sensor_name)\n            plt.show(block=False)\n\n    # One final plot show so all the figures get rendered\n    plt.show()\n</code></pre>","location":"reference/robots/robot_base.html#robots.robot_base.BaseRobot.visualize_sensors"},{"title":"tiago","text":"","location":"reference/robots/tiago.html"},{"title":"<code>Tiago</code>","text":"<p>         Bases: <code>ManipulationRobot</code>, <code>LocomotionRobot</code>, <code>ActiveCameraRobot</code></p> <p>Tiago Robot Reference: https://pal-robotics.com/robots/tiago/</p> <p>NOTE: If using IK Control for both the right and left arms, note that the left arm dictates control of the trunk, and the right arm passively must follow. That is, sending desired delta position commands to the right end effector will be computed independently from any trunk motion occurring during that timestep.</p>  Source code in <code>robots/tiago.py</code> <pre><code>class Tiago(ManipulationRobot, LocomotionRobot, ActiveCameraRobot):\n    \"\"\"\n    Tiago Robot\n    Reference: https://pal-robotics.com/robots/tiago/\n\n    NOTE: If using IK Control for both the right and left arms, note that the left arm dictates control of the trunk,\n    and the right arm passively must follow. That is, sending desired delta position commands to the right end effector\n    will be computed independently from any trunk motion occurring during that timestep.\n    \"\"\"\n\n    def __init__(\n        self,\n        # Shared kwargs in hierarchy\n        prim_path,\n        name=None,\n        class_id=None,\n        uuid=None,\n        scale=None,\n        visible=True,\n        fixed_base=False,\n        visual_only=False,\n        self_collisions=False,\n        load_config=None,\n\n        # Unique to USDObject hierarchy\n        abilities=None,\n\n        # Unique to ControllableObject hierarchy\n        control_freq=None,\n        controller_config=None,\n        action_type=\"continuous\",\n        action_normalize=True,\n        reset_joint_pos=None,\n\n        # Unique to BaseRobot\n        obs_modalities=\"all\",\n        proprio_obs=\"default\",\n\n        # Unique to ManipulationRobot\n        grasping_mode=\"physical\",\n\n        # Unique to Tiago\n        rigid_trunk=False,\n        default_trunk_offset=0.365,\n        default_arm_pose=\"vertical\",\n\n        **kwargs,\n    ):\n        \"\"\"\n        Args:\n            prim_path (str): global path in the stage to this object\n            name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n                generated at the time the object is added to the scene, using the object's category.\n            category (str): Category for the object. Defaults to \"object\".\n            class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n                If None, the ID will be inferred from this object's category.\n            uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n                If None is specified, then it will be auto-generated\n            scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n                for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n                3-array specifies per-axis scaling.\n            visible (bool): whether to render this object or not in the stage\n            fixed_base (bool): whether to fix the base of this object or not\n            visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n            self_collisions (bool): Whether to enable self collisions for this object\n            prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n            load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n                loading this prim at runtime.\n            abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n                a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n                the object state instance constructor.\n            control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n                simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n            controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n                configurations for this object. This will override any default values specified by this class.\n            action_type (str): one of {discrete, continuous} - what type of action space to use\n            action_normalize (bool): whether to normalize inputted actions. This will override any default values\n                specified by this class.\n            reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n                be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n            obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n                corresponds to all modalities being used.\n                Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n            proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n                observations. If str, should be exactly \"default\" -- this results in the default proprioception\n                observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n                for valid key choices\n            grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n                If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n                If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n                If \"sticky\", will magnetize any object touching the gripper's fingers.\n            rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n            default_trunk_offset (float): sets the default height of the robot's trunk\n            default_arm_pose (str): Default pose for the robot arm. Should be one of:\n                {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n            kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n                for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n        \"\"\"\n        # Store args\n        self.rigid_trunk = rigid_trunk\n        self.default_trunk_offset = default_trunk_offset\n        assert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\n        self.default_arm_pose = default_arm_pose\n\n        # Other args that will be created at runtime\n        self._world_base_fixed_joint_prim = None\n\n        # Parse reset joint pos if specifying special string\n        if isinstance(reset_joint_pos, str):\n            assert (\n                reset_joint_pos in RESET_JOINT_OPTIONS\n            ), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\n            reset_joint_pos = (\n                self.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n            )\n\n        # Run super init\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            class_id=class_id,\n            uuid=uuid,\n            scale=scale,\n            visible=visible,\n            fixed_base=fixed_base,\n            visual_only=visual_only,\n            self_collisions=self_collisions,\n            load_config=load_config,\n            abilities=abilities,\n            control_freq=control_freq,\n            controller_config=controller_config,\n            action_type=action_type,\n            action_normalize=action_normalize,\n            reset_joint_pos=reset_joint_pos,\n            obs_modalities=obs_modalities,\n            proprio_obs=proprio_obs,\n            grasping_mode=grasping_mode,\n            **kwargs,\n        )\n\n    @property\n    def arm_joint_names(self):\n        names = dict()\n        for arm in self.arm_names:\n            names[arm] = [\"torso_lift_joint\"] + [\n                f\"arm_{arm}_{i}_joint\" for i in range(1, 8)\n            ]\n        return names\n\n    @property\n    def model_name(self):\n        return \"Tiago\"\n\n    @property\n    def n_arms(self):\n        return 2\n\n    @property\n    def arm_names(self):\n        return [\"left\", \"right\"]\n\n    @property\n    def tucked_default_joint_pos(self):\n        pos = np.zeros(self.n_dof)\n        # Keep the current joint positions for the base joints\n        pos[self.base_idx] = self.get_joint_positions()[self.base_idx]\n        pos[self.trunk_control_idx] = 0\n        pos[self.camera_control_idx] = np.array([0.0, 0.0])\n        for arm in self.arm_names:\n            pos[self.gripper_control_idx[arm]] = np.array([0.045, 0.045])  # open gripper\n            pos[self.arm_control_idx[arm]] = np.array(\n                [-1.10, 1.47, 2.71, 1.71, -1.57, 1.39, 0]\n            )\n        return pos\n\n    @property\n    def untucked_default_joint_pos(self):\n        pos = np.zeros(self.n_dof)\n        # Keep the current joint positions for the base joints\n        pos[self.base_idx] = self.get_joint_positions()[self.base_idx]\n        pos[self.trunk_control_idx] = 0.02 + self.default_trunk_offset\n        pos[self.camera_control_idx] = np.array([0.0, 0.45])\n        pos[self.gripper_control_idx[self.default_arm]] = np.array([0.045, 0.045])  # open gripper\n\n        # Choose arm based on setting\n        if self.default_arm_pose == \"vertical\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n            )\n        elif self.default_arm_pose == \"diagonal15\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n            )\n        elif self.default_arm_pose == \"diagonal30\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n            )\n        elif self.default_arm_pose == \"diagonal45\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n            )\n        elif self.default_arm_pose == \"horizontal\":\n            pos[self.arm_control_idx[self.default_arm]] = np.array(\n                [0.22, 0.48, 1.52, 1.76, 0.04, -0.49, 0]\n            )\n        else:\n            raise ValueError(\"Unknown default arm pose: {}\".format(self.default_arm_pose))\n        return pos\n\n    def _create_discrete_action_space(self):\n        # Tiago does not support discrete actions\n        raise ValueError(\"Fetch does not support discrete actions!\")\n\n    @property\n    def discrete_action_list(self):\n        # Not supported for this robot\n        raise NotImplementedError()\n\n    def tuck(self):\n        \"\"\"\n        Immediately set this robot's configuration to be in tucked mode\n        \"\"\"\n        self.set_joint_positions(self.tucked_default_joint_pos)\n\n    def untuck(self):\n        \"\"\"\n        Immediately set this robot's configuration to be in untucked mode\n        \"\"\"\n        self.set_joint_positions(self.untucked_default_joint_pos)\n\n    def reset(self):\n        \"\"\"\n        Reset should not change the robot base pose.\n        We need to cache and restore the base joints to the world.\n        \"\"\"\n        base_joint_positions = self.get_joint_positions()[self.base_idx]\n        super().reset()\n        self.set_joint_positions(base_joint_positions, indices=self.base_idx)\n\n    def _post_load(self):\n        super()._post_load()\n        # The eef gripper links should be visual-only. They only contain a \"ghost\" box volume for detecting objects\n        # inside the gripper, in order to activate attachments (AG for Cloths).\n        for arm in self.arm_names:\n            self.eef_links[arm].visual_only = True\n            self.eef_links[arm].visible = False\n\n        self._world_base_fixed_joint_prim = get_prim_at_path(os.path.join(self.root_link.prim_path, \"world_base_joint\"))\n        position, orientation = self.get_position_orientation()\n        # Set the world-to-base fixed joint to be at the robot's current pose\n        self._world_base_fixed_joint_prim.GetAttribute(\"physics:localPos0\").Set(tuple(position))\n        self._world_base_fixed_joint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*orientation[[3, 0, 1, 2]]))\n\n    def _initialize(self):\n        # Run super method first\n        super()._initialize()\n\n        # Set the joint friction for EEF to be higher\n        for arm in self.arm_names:\n            for joint in self.finger_joints[arm]:\n                if joint.joint_type != JointType.JOINT_FIXED:\n                    joint.friction = 500\n\n    # Name of the actual root link that we are interested in. Note that this is different from self.root_link_name,\n    # which is \"base_footprint_x\", corresponding to the first of the 6 1DoF joints to control the base.\n    @property\n    def base_footprint_link_name(self):\n        return \"base_footprint\"\n\n    @property\n    def base_footprint_link(self):\n        \"\"\"\n        Returns:\n            RigidPrim: base footprint link of this object prim\n        \"\"\"\n        return self._links[self.base_footprint_link_name]\n\n    def _actions_to_control(self, action):\n        # Run super method first\n        u_vec, u_type_vec = super()._actions_to_control(action=action)\n\n        # Change the control from base_footprint_link (\"base_footprint\") frame to root_link (\"base_footprint_x\") frame\n        base_orn = self.base_footprint_link.get_orientation()\n        root_link_orn = self.root_link.get_orientation()\n\n        cur_orn = T.mat2quat(T.quat2mat(root_link_orn).T  @ T.quat2mat(base_orn))\n\n        # Rotate the linear and angular velocity to the desired frame\n        lin_vel_global, _ = T.pose_transform([0, 0, 0], cur_orn, u_vec[self.base_idx[:3]], [0, 0, 0, 1])\n        ang_vel_global, _ = T.pose_transform([0, 0, 0], cur_orn, u_vec[self.base_idx[3:]], [0, 0, 0, 1])\n\n        u_vec[self.base_control_idx] = np.array([lin_vel_global[0], lin_vel_global[1], ang_vel_global[2]])\n        return u_vec, u_type_vec\n\n    def _get_proprioception_dict(self):\n        dic = super()._get_proprioception_dict()\n\n        # Add trunk info\n        joint_positions = self.get_joint_positions(normalized=False)\n        joint_velocities = self.get_joint_velocities(normalized=False)\n        dic[\"trunk_qpos\"] = joint_positions[self.trunk_control_idx]\n        dic[\"trunk_qvel\"] = joint_velocities[self.trunk_control_idx]\n\n        return dic\n\n    @property\n    def control_limits(self):\n        # Overwrite the control limits with the maximum linear and angular velocities for the purpose of clip_control\n        # Note that when clip_control happens, the control is still in the base_footprint_link (\"base_footprint\") frame\n        # Omniverse still thinks these joints have no limits because when the control is transformed to the root_link\n        # (\"base_footprint_x\") frame, it can go above this limit.\n        limits = super().control_limits\n        limits[\"velocity\"][0][self.base_idx[:3]] = -m.MAX_LINEAR_VELOCITY\n        limits[\"velocity\"][1][self.base_idx[:3]] = m.MAX_LINEAR_VELOCITY\n        limits[\"velocity\"][0][self.base_idx[3:]] = -m.MAX_ANGULAR_VELOCITY\n        limits[\"velocity\"][1][self.base_idx[3:]] = m.MAX_ANGULAR_VELOCITY\n        return limits\n\n    def get_control_dict(self):\n        # Modify the right hand's pos_relative in the z-direction based on the trunk's value\n        # We do this so we decouple the trunk's dynamic value from influencing the IK controller solution for the right\n        # hand, which does not control the trunk\n        dic = super().get_control_dict()\n        dic[\"eef_right_pos_relative\"][2] = dic[\"eef_right_pos_relative\"][2] - self.get_joint_positions()[self.trunk_control_idx]\n\n        return dic\n\n    @property\n    def default_proprio_obs(self):\n        obs_keys = super().default_proprio_obs\n        return obs_keys + [\"trunk_qpos\"]\n\n    @property\n    def controller_order(self):\n        controllers = [\"base\", \"camera\"]\n        for arm in self.arm_names:\n            controllers += [\"arm_{}\".format(arm), \"gripper_{}\".format(arm)]\n\n        return controllers\n\n    @property\n    def _default_controllers(self):\n        # Always call super first\n        controllers = super()._default_controllers\n\n        # We use multi finger gripper, differential drive, and IK controllers as default\n        controllers[\"base\"] = \"JointController\"\n        controllers[\"camera\"] = \"JointController\"\n        for arm in self.arm_names:\n            controllers[\"arm_{}\".format(arm)] = \"InverseKinematicsController\"\n            controllers[\"gripper_{}\".format(arm)] = \"MultiFingerGripperController\"\n        return controllers\n\n    @property\n    def _default_base_controller_configs(self):\n        dic = {\n            \"name\": \"JointController\",\n            \"control_freq\": self._control_freq,\n            \"control_limits\": self.control_limits,\n            \"use_delta_commands\": False,\n            \"motor_type\": \"velocity\",\n            \"compute_delta_in_quat_space\": [(3, 4, 5)],\n            \"dof_idx\": self.base_control_idx,\n        }\n        return dic\n\n    @property\n    def _default_controller_config(self):\n        # Grab defaults from super method first\n        cfg = super()._default_controller_config\n\n        # Get default base controller for omnidirectional Tiago\n        cfg[\"base\"] = {\"JointController\": self._default_base_controller_configs}\n\n        for arm in self.arm_names:\n            for arm_cfg in cfg[\"arm_{}\".format(arm)].values():\n\n                if arm == \"left\":\n                    # Need to override joint idx being controlled to include trunk in default arm controller configs\n                    arm_cfg[\"dof_idx\"] = np.concatenate([self.trunk_control_idx, self.arm_control_idx[arm]])\n\n                # If using rigid trunk, we also clamp its limits\n                # TODO: How to handle for right arm which has a fixed trunk internally even though the trunk is moving\n                # via the left arm??\n                if self.rigid_trunk:\n                    arm_cfg[\"control_limits\"][\"position\"][0][self.trunk_control_idx] = \\\n                        self.untucked_default_joint_pos[self.trunk_control_idx]\n                    arm_cfg[\"control_limits\"][\"position\"][1][self.trunk_control_idx] = \\\n                        self.untucked_default_joint_pos[self.trunk_control_idx]\n\n        return cfg\n\n    @property\n    def default_joint_pos(self):\n        return self.tucked_default_joint_pos\n\n    @property\n    def assisted_grasp_start_points(self):\n        return {\n            arm: [\n                GraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[0.04, -0.012, 0.014]),\n                GraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[0.04, -0.012, -0.014]),\n                GraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[-0.04, -0.012, 0.014]),\n                GraspingPoint(link_name=\"gripper_{}_right_finger_link\".format(arm), position=[-0.04, -0.012, -0.014]),\n            ]\n            for arm in self.arm_names\n        }\n\n    @property\n    def assisted_grasp_end_points(self):\n        return {\n            arm: [\n                GraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[0.04, 0.012, 0.014]),\n                GraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[0.04, 0.012, -0.014]),\n                GraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[-0.04, 0.012, 0.014]),\n                GraspingPoint(link_name=\"gripper_{}_left_finger_link\".format(arm), position=[-0.04, 0.012, -0.014]),\n            ]\n            for arm in self.arm_names\n        }\n\n    @property\n    def base_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to the three controllable 1DoF base joints\n        \"\"\"\n        joints = list(self.joints.keys())\n        return np.array(\n            [\n                joints.index(f\"base_footprint_{component}_joint\")\n                for component in [\"x\", \"y\", \"rz\"]\n            ]\n        )\n\n    @property\n    def base_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to the six 1DoF base joints\n        \"\"\"\n        joints = list(self.joints.keys())\n        return np.array(\n            [\n                joints.index(f\"base_footprint_{component}_joint\")\n                for component in [\"x\", \"y\", \"z\", \"rx\", \"ry\", \"rz\"]\n            ]\n        )\n\n    @property\n    def trunk_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to trunk joint.\n        \"\"\"\n        return np.array([6])\n\n    @property\n    def camera_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.\n        \"\"\"\n        return np.array([9, 12])\n\n    @property\n    def arm_control_idx(self):\n        return {\"left\": np.array([7, 10, 13, 15, 17, 19, 21]), \"right\": np.array([8, 11, 14, 16, 18, 20, 22])}\n\n    @property\n    def gripper_control_idx(self):\n        return {\"left\": np.array([23, 24]), \"right\": np.array([25, 26])}\n\n    @property\n    def finger_lengths(self):\n        return {arm: 0.12 for arm in self.arm_names}\n\n    @property\n    def disabled_collision_pairs(self):\n        return []\n\n    @property\n    def arm_link_names(self):\n        return {arm: [f\"arm_{arm}_{i}_link\" for i in range(1, 8)] for arm in self.arm_names}\n\n    @property\n    def eef_link_names(self):\n        return {arm: \"gripper_{}_grasping_frame\".format(arm) for arm in self.arm_names}\n\n    @property\n    def finger_link_names(self):\n        return {arm: [\"gripper_{}_right_finger_link\".format(arm), \"gripper_{}_left_finger_link\".format(arm)] for arm in\n                self.arm_names}\n\n    @property\n    def finger_joint_names(self):\n        return {arm: [\"gripper_{}_right_finger_joint\".format(arm), \"gripper_{}_left_finger_joint\".format(arm)] for arm\n                in self.arm_names}\n\n    @property\n    def usd_path(self):\n        return os.path.join(og.assets_path, \"models/tiago/tiago_dual_omnidirectional_stanford/tiago_dual_omnidirectional_stanford_33.usd\")\n\n    @property\n    def robot_arm_descriptor_yamls(self):\n        return {\"left\": os.path.join(og.assets_path, \"models/tiago/tiago_dual_omnidirectional_stanford_left_arm_descriptor.yaml\"),\n                \"right\": os.path.join(og.assets_path, \"models/tiago/tiago_dual_omnidirectional_stanford_right_arm_fixed_trunk_descriptor.yaml\")}\n\n    @property\n    def urdf_path(self):\n        return os.path.join(og.assets_path, \"models/tiago/tiago_dual_omnidirectional_stanford.urdf\")\n\n    def get_position_orientation(self):\n        # If the simulator is playing, return the pose of the base_footprint link frame\n        if self._dc is not None and self._dc.is_simulating():\n            return self.base_footprint_link.get_position_orientation()\n\n        # Else, return the pose of the robot frame\n        else:\n            return super().get_position_orientation()\n\n    def set_position_orientation(self, position=None, orientation=None):\n        current_position, current_orientation = self.get_position_orientation()\n        if position is None:\n            position = current_position\n        if orientation is None:\n            orientation = current_orientation\n\n        # If the simulator is playing, set the 6 base joints to achieve the desired pose of base_footprint link frame\n        if self._dc is not None and self._dc.is_simulating():\n            # Find the relative transformation from base_footprint_link (\"base_footprint\") frame to root_link\n            # (\"base_footprint_x\") frame. Assign it to the 6 1DoF joints that control the base.\n            # Note that the 6 1DoF joints are originated from the root_link (\"base_footprint_x\") frame.\n            joint_pos, joint_orn = self.root_link.get_position_orientation()\n            inv_joint_pos, inv_joint_orn = T.mat2pose(T.pose_inv(T.pose2mat((joint_pos, joint_orn))))\n\n            relative_pos, relative_orn = T.pose_transform(inv_joint_pos, inv_joint_orn, position, orientation)\n            relative_rpy = T.quat2euler(relative_orn)\n            self.joints[\"base_footprint_x_joint\"].set_pos(relative_pos[0], target=False)\n            self.joints[\"base_footprint_y_joint\"].set_pos(relative_pos[1], target=False)\n            self.joints[\"base_footprint_z_joint\"].set_pos(relative_pos[2], target=False)\n            self.joints[\"base_footprint_rx_joint\"].set_pos(relative_rpy[0], target=False)\n            self.joints[\"base_footprint_ry_joint\"].set_pos(relative_rpy[1], target=False)\n            self.joints[\"base_footprint_rz_joint\"].set_pos(relative_rpy[2], target=False)\n\n        # Else, set the pose of the robot frame, and then move the joint frame of the world_base_joint to match it\n        else:\n            # Call the super() method to move the robot frame first\n            super().set_position_orientation(position, orientation)\n            # Move the joint frame for the world_base_joint\n            if self._world_base_fixed_joint_prim is not None:\n                self._world_base_fixed_joint_prim.GetAttribute(\"physics:localPos0\").Set(tuple(position))\n                self._world_base_fixed_joint_prim.GetAttribute(\"physics:localRot0\").Set(Gf.Quatf(*orientation[[3, 0, 1, 2]]))\n\n    def set_linear_velocity(self, velocity: np.ndarray):\n        # Transform the desired linear velocity from the world frame to the root_link (\"base_footprint_x\") frame\n        # Note that this will also set the target to be the desired linear velocity (i.e. the robot will try to maintain\n        # such velocity), which is different from the default behavior of set_linear_velocity for all other objects.\n        orn = self.root_link.get_orientation()\n        velocity_in_root_link = T.quat2mat(orn).T @ velocity\n        self.joints[\"base_footprint_x_joint\"].set_vel(velocity_in_root_link[0], target=False)\n        self.joints[\"base_footprint_y_joint\"].set_vel(velocity_in_root_link[1], target=False)\n        self.joints[\"base_footprint_z_joint\"].set_vel(velocity_in_root_link[2], target=False)\n\n    def get_linear_velocity(self) -&gt; np.ndarray:\n        # Note that the link we are interested in is self.base_footprint_link, not self.root_link\n        return self.base_footprint_link.get_linear_velocity()\n\n    def set_angular_velocity(self, velocity: np.ndarray) -&gt; None:\n        # See comments of self.set_linear_velocity\n        orn = self.root_link.get_orientation()\n        velocity_in_root_link = T.quat2mat(orn).T @ velocity\n        self.joints[\"base_footprint_rx_joint\"].set_vel(velocity_in_root_link[0], target=False)\n        self.joints[\"base_footprint_ry_joint\"].set_vel(velocity_in_root_link[1], target=False)\n        self.joints[\"base_footprint_rz_joint\"].set_vel(velocity_in_root_link[2], target=False)\n\n    def get_angular_velocity(self) -&gt; np.ndarray:\n        # Note that the link we are interested in is self.base_footprint_link, not self.root_link\n        return self.base_footprint_link.get_angular_velocity()\n</code></pre>","location":"reference/robots/tiago.html#robots.tiago.Tiago"},{"title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to the three controllable 1DoF base joints</p>","location":"reference/robots/tiago.html#robots.tiago.Tiago.base_control_idx"},{"title":"<code>base_footprint_link</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>RigidPrim</code>   <p>base footprint link of this object prim</p>","location":"reference/robots/tiago.html#robots.tiago.Tiago.base_footprint_link"},{"title":"<code>base_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to the six 1DoF base joints</p>","location":"reference/robots/tiago.html#robots.tiago.Tiago.base_idx"},{"title":"<code>camera_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to [tilt, pan] camera joints.</p>","location":"reference/robots/tiago.html#robots.tiago.Tiago.camera_control_idx"},{"title":"<code>trunk_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to trunk joint.</p>","location":"reference/robots/tiago.html#robots.tiago.Tiago.trunk_control_idx"},{"title":"<code>__init__(prim_path, name=None, class_id=None, uuid=None, scale=None, visible=True, fixed_base=False, visual_only=False, self_collisions=False, load_config=None, abilities=None, control_freq=None, controller_config=None, action_type='continuous', action_normalize=True, reset_joint_pos=None, obs_modalities='all', proprio_obs='default', grasping_mode='physical', rigid_trunk=False, default_trunk_offset=0.365, default_arm_pose='vertical', **kwargs)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>global path in the stage to this object</p>  required    <code>name</code>  <code>None or str</code>  <p>Name for the object. Names need to be unique per scene. If None, a name will be generated at the time the object is added to the scene, using the object's category.</p>  <code>None</code>    <code>category</code>  <code>str</code>  <p>Category for the object. Defaults to \"object\".</p>  required    <code>class_id</code>  <code>None or int</code>  <p>What class ID the object should be assigned in semantic segmentation rendering mode. If None, the ID will be inferred from this object's category.</p>  <code>None</code>    <code>uuid</code>  <code>None or int</code>  <p>Unique unsigned-integer identifier to assign to this object (max 8-numbers). If None is specified, then it will be auto-generated</p>  <code>None</code>    <code>scale</code>  <code>None or float or 3-array</code>  <p>if specified, sets either the uniform (float) or x,y,z (3-array) scale for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a 3-array specifies per-axis scaling.</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>whether to render this object or not in the stage</p>  <code>True</code>    <code>fixed_base</code>  <code>bool</code>  <p>whether to fix the base of this object or not</p>  <code>False</code>    <code>visual_only</code>  <code>bool</code>  <p>Whether this object should be visual only (and not collide with any other objects)</p>  <code>False</code>    <code>self_collisions</code>  <code>bool</code>  <p>Whether to enable self collisions for this object</p>  <code>False</code>    <code>prim_type</code>  <code>PrimType</code>  <p>Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}</p>  required    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this prim at runtime.</p>  <code>None</code>    <code>abilities</code>  <code>None or dict</code>  <p>If specified, manually adds specific object states to this object. It should be a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to the object state instance constructor.</p>  <code>None</code>    <code>control_freq</code>  <code>float</code>  <p>control frequency (in Hz) at which to control the object. If set to be None, simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.</p>  <code>None</code>    <code>controller_config</code>  <code>None or dict</code>  <p>nested dictionary mapping controller name(s) to specific controller configurations for this object. This will override any default values specified by this class.</p>  <code>None</code>    <code>action_type</code>  <code>str</code>  <p>one of {discrete, continuous} - what type of action space to use</p>  <code>'continuous'</code>    <code>action_normalize</code>  <code>bool</code>  <p>whether to normalize inputted actions. This will override any default values specified by this class.</p>  <code>True</code>    <code>reset_joint_pos</code>  <code>None or n-array</code>  <p>if specified, should be the joint positions that the object should be set to during a reset. If None (default), self.default_joint_pos will be used instead.</p>  <code>None</code>    <code>obs_modalities</code>  <code>str or list of str</code>  <p>Observation modalities to use for this robot. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.</p>  <code>'all'</code>    <code>proprio_obs</code>  <code>str or list of str</code>  <p>proprioception observation key(s) to use for generating proprioceptive observations. If str, should be exactly \"default\" -- this results in the default proprioception observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict for valid key choices</p>  <code>'default'</code>    <code>grasping_mode</code>  <code>str</code>  <p>One of {\"physical\", \"assisted\", \"sticky\"}. If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force). If \"assisted\", will magnetize any object touching and within the gripper's fingers. If \"sticky\", will magnetize any object touching the gripper's fingers.</p>  <code>'physical'</code>    <code>default_trunk_offset</code>  <code>float</code>  <p>sets the default height of the robot's trunk</p>  <code>0.365</code>    <code>default_arm_pose</code>  <code>str</code>  <p>Default pose for the robot arm. Should be one of:</p>  <code>'vertical'</code>    <code>kwargs</code>  <code>dict</code>  <p>Additional keyword arguments that are used for other super() calls from subclasses, allowing for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).</p>  <code>{}</code>      Source code in <code>robots/tiago.py</code> <pre><code>def __init__(\n    self,\n    # Shared kwargs in hierarchy\n    prim_path,\n    name=None,\n    class_id=None,\n    uuid=None,\n    scale=None,\n    visible=True,\n    fixed_base=False,\n    visual_only=False,\n    self_collisions=False,\n    load_config=None,\n\n    # Unique to USDObject hierarchy\n    abilities=None,\n\n    # Unique to ControllableObject hierarchy\n    control_freq=None,\n    controller_config=None,\n    action_type=\"continuous\",\n    action_normalize=True,\n    reset_joint_pos=None,\n\n    # Unique to BaseRobot\n    obs_modalities=\"all\",\n    proprio_obs=\"default\",\n\n    # Unique to ManipulationRobot\n    grasping_mode=\"physical\",\n\n    # Unique to Tiago\n    rigid_trunk=False,\n    default_trunk_offset=0.365,\n    default_arm_pose=\"vertical\",\n\n    **kwargs,\n):\n    \"\"\"\n    Args:\n        prim_path (str): global path in the stage to this object\n        name (None or str): Name for the object. Names need to be unique per scene. If None, a name will be\n            generated at the time the object is added to the scene, using the object's category.\n        category (str): Category for the object. Defaults to \"object\".\n        class_id (None or int): What class ID the object should be assigned in semantic segmentation rendering mode.\n            If None, the ID will be inferred from this object's category.\n        uuid (None or int): Unique unsigned-integer identifier to assign to this object (max 8-numbers).\n            If None is specified, then it will be auto-generated\n        scale (None or float or 3-array): if specified, sets either the uniform (float) or x,y,z (3-array) scale\n            for this object. A single number corresponds to uniform scaling along the x,y,z axes, whereas a\n            3-array specifies per-axis scaling.\n        visible (bool): whether to render this object or not in the stage\n        fixed_base (bool): whether to fix the base of this object or not\n        visual_only (bool): Whether this object should be visual only (and not collide with any other objects)\n        self_collisions (bool): Whether to enable self collisions for this object\n        prim_type (PrimType): Which type of prim the object is, Valid options are: {PrimType.RIGID, PrimType.CLOTH}\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this prim at runtime.\n        abilities (None or dict): If specified, manually adds specific object states to this object. It should be\n            a dict in the form of {ability: {param: value}} containing object abilities and parameters to pass to\n            the object state instance constructor.\n        control_freq (float): control frequency (in Hz) at which to control the object. If set to be None,\n            simulator.import_object will automatically set the control frequency to be 1 / render_timestep by default.\n        controller_config (None or dict): nested dictionary mapping controller name(s) to specific controller\n            configurations for this object. This will override any default values specified by this class.\n        action_type (str): one of {discrete, continuous} - what type of action space to use\n        action_normalize (bool): whether to normalize inputted actions. This will override any default values\n            specified by this class.\n        reset_joint_pos (None or n-array): if specified, should be the joint positions that the object should\n            be set to during a reset. If None (default), self.default_joint_pos will be used instead.\n        obs_modalities (str or list of str): Observation modalities to use for this robot. Default is \"all\", which\n            corresponds to all modalities being used.\n            Otherwise, valid options should be part of omnigibson.sensors.ALL_SENSOR_MODALITIES.\n        proprio_obs (str or list of str): proprioception observation key(s) to use for generating proprioceptive\n            observations. If str, should be exactly \"default\" -- this results in the default proprioception\n            observations being used, as defined by self.default_proprio_obs. See self._get_proprioception_dict\n            for valid key choices\n        grasping_mode (str): One of {\"physical\", \"assisted\", \"sticky\"}.\n            If \"physical\", no assistive grasping will be applied (relies on contact friction + finger force).\n            If \"assisted\", will magnetize any object touching and within the gripper's fingers.\n            If \"sticky\", will magnetize any object touching the gripper's fingers.\n        rigid_trunk (bool) if True, will prevent the trunk from moving during execution.\n        default_trunk_offset (float): sets the default height of the robot's trunk\n        default_arm_pose (str): Default pose for the robot arm. Should be one of:\n            {\"vertical\", \"diagonal15\", \"diagonal30\", \"diagonal45\", \"horizontal\"}\n        kwargs (dict): Additional keyword arguments that are used for other super() calls from subclasses, allowing\n            for flexible compositions of various object subclasses (e.g.: Robot is USDObject + ControllableObject).\n    \"\"\"\n    # Store args\n    self.rigid_trunk = rigid_trunk\n    self.default_trunk_offset = default_trunk_offset\n    assert_valid_key(key=default_arm_pose, valid_keys=DEFAULT_ARM_POSES, name=\"default_arm_pose\")\n    self.default_arm_pose = default_arm_pose\n\n    # Other args that will be created at runtime\n    self._world_base_fixed_joint_prim = None\n\n    # Parse reset joint pos if specifying special string\n    if isinstance(reset_joint_pos, str):\n        assert (\n            reset_joint_pos in RESET_JOINT_OPTIONS\n        ), \"reset_joint_pos should be one of {} if using a string!\".format(RESET_JOINT_OPTIONS)\n        reset_joint_pos = (\n            self.tucked_default_joint_pos if reset_joint_pos == \"tuck\" else self.untucked_default_joint_pos\n        )\n\n    # Run super init\n    super().__init__(\n        prim_path=prim_path,\n        name=name,\n        class_id=class_id,\n        uuid=uuid,\n        scale=scale,\n        visible=visible,\n        fixed_base=fixed_base,\n        visual_only=visual_only,\n        self_collisions=self_collisions,\n        load_config=load_config,\n        abilities=abilities,\n        control_freq=control_freq,\n        controller_config=controller_config,\n        action_type=action_type,\n        action_normalize=action_normalize,\n        reset_joint_pos=reset_joint_pos,\n        obs_modalities=obs_modalities,\n        proprio_obs=proprio_obs,\n        grasping_mode=grasping_mode,\n        **kwargs,\n    )\n</code></pre>","location":"reference/robots/tiago.html#robots.tiago.Tiago.__init__"},{"title":"<code>reset()</code>","text":"<p>Reset should not change the robot base pose. We need to cache and restore the base joints to the world.</p>  Source code in <code>robots/tiago.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Reset should not change the robot base pose.\n    We need to cache and restore the base joints to the world.\n    \"\"\"\n    base_joint_positions = self.get_joint_positions()[self.base_idx]\n    super().reset()\n    self.set_joint_positions(base_joint_positions, indices=self.base_idx)\n</code></pre>","location":"reference/robots/tiago.html#robots.tiago.Tiago.reset"},{"title":"<code>tuck()</code>","text":"<p>Immediately set this robot's configuration to be in tucked mode</p>  Source code in <code>robots/tiago.py</code> <pre><code>def tuck(self):\n    \"\"\"\n    Immediately set this robot's configuration to be in tucked mode\n    \"\"\"\n    self.set_joint_positions(self.tucked_default_joint_pos)\n</code></pre>","location":"reference/robots/tiago.html#robots.tiago.Tiago.tuck"},{"title":"<code>untuck()</code>","text":"<p>Immediately set this robot's configuration to be in untucked mode</p>  Source code in <code>robots/tiago.py</code> <pre><code>def untuck(self):\n    \"\"\"\n    Immediately set this robot's configuration to be in untucked mode\n    \"\"\"\n    self.set_joint_positions(self.untucked_default_joint_pos)\n</code></pre>","location":"reference/robots/tiago.html#robots.tiago.Tiago.untuck"},{"title":"turtlebot","text":"","location":"reference/robots/turtlebot.html"},{"title":"<code>Turtlebot</code>","text":"<p>         Bases: <code>TwoWheelRobot</code></p> <p>Turtlebot robot Reference: http://wiki.ros.org/Robots/TurtleBot Uses joint velocity control</p>  Source code in <code>robots/turtlebot.py</code> <pre><code>class Turtlebot(TwoWheelRobot):\n    \"\"\"\n    Turtlebot robot\n    Reference: http://wiki.ros.org/Robots/TurtleBot\n    Uses joint velocity control\n    \"\"\"\n\n    @property\n    def wheel_radius(self):\n        return 0.038\n\n    @property\n    def wheel_axle_length(self):\n        return 0.23\n\n    @property\n    def base_control_idx(self):\n        \"\"\"\n        Returns:\n            n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.\n        \"\"\"\n        return np.array([0, 1])\n\n    @property\n    def default_joint_pos(self):\n        return np.zeros(self.n_joints)\n\n    @property\n    def usd_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/turtlebot/turtlebot/turtlebot.usd\")\n\n    @property\n    def urdf_path(self):\n        return os.path.join(omnigibson.assets_path, \"models/turtlebot/turtlebot.urdf\")\n</code></pre>","location":"reference/robots/turtlebot.html#robots.turtlebot.Turtlebot"},{"title":"<code>base_control_idx</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Indices in low-level control vector corresponding to [Left, Right] wheel joints.</p>","location":"reference/robots/turtlebot.html#robots.turtlebot.Turtlebot.base_control_idx"},{"title":"two_wheel_robot","text":"","location":"reference/robots/two_wheel_robot.html"},{"title":"<code>TwoWheelRobot</code>","text":"<p>         Bases: <code>LocomotionRobot</code></p> <p>Robot that is is equipped with locomotive (navigational) capabilities, as defined by two wheels that can be used for differential drive (e.g.: Turtlebot). Provides common interface for a wide variety of robots.</p>  controller_config should, at the minimum, contain: <p>base: controller specifications for the controller to control this robot's base (locomotion).     Should include:</p> <pre><code>- name: Controller to create\n- &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n    values specified, but setting these individual kwargs will override them\n</code></pre>   Source code in <code>robots/two_wheel_robot.py</code> <pre><code>class TwoWheelRobot(LocomotionRobot):\n    \"\"\"\n    Robot that is is equipped with locomotive (navigational) capabilities, as defined by two wheels that can be used\n    for differential drive (e.g.: Turtlebot).\n    Provides common interface for a wide variety of robots.\n\n    NOTE: controller_config should, at the minimum, contain:\n        base: controller specifications for the controller to control this robot's base (locomotion).\n            Should include:\n\n            - name: Controller to create\n            - &lt;other kwargs&gt; relevant to the controller being created. Note that all values will have default\n                values specified, but setting these individual kwargs will override them\n    \"\"\"\n\n    def _validate_configuration(self):\n        # Make sure base only has two indices (i.e.: two wheels for differential drive)\n        assert len(self.base_control_idx) == 2, \"Differential drive can only be used with robot with two base joints!\"\n\n        # run super\n        super()._validate_configuration()\n\n    def _create_discrete_action_space(self):\n        # Set action list based on controller (joint or DD) used\n\n        # We set straight velocity to be 50% of max velocity for the wheels\n        max_wheel_joint_vels = self.control_limits[\"velocity\"][1][self.base_control_idx]\n        assert len(max_wheel_joint_vels) == 2, \"TwoWheelRobot must only have two base (wheel) joints!\"\n        assert max_wheel_joint_vels[0] == max_wheel_joint_vels[1], \"Both wheels must have the same max speed!\"\n        wheel_straight_vel = 0.5 * max_wheel_joint_vels[0]\n        wheel_rotate_vel = 0.5\n        if self._controller_config[\"base\"][\"name\"] == \"JointController\":\n            action_list = [\n                [wheel_straight_vel, wheel_straight_vel],\n                [-wheel_straight_vel, -wheel_straight_vel],\n                [wheel_rotate_vel, -wheel_rotate_vel],\n                [-wheel_rotate_vel, wheel_rotate_vel],\n                [0, 0],\n            ]\n        else:\n            # DifferentialDriveController\n            lin_vel = wheel_straight_vel * self.wheel_radius\n            ang_vel = wheel_rotate_vel * self.wheel_radius * 2.0 / self.wheel_axle_length\n            action_list = [\n                [lin_vel, 0],\n                [-lin_vel, 0],\n                [0, ang_vel],\n                [0, -ang_vel],\n                [0, 0],\n            ]\n\n        self.action_list = action_list\n\n        # Return this action space\n        return gym.spaces.Box(len(self.action_list))\n\n    def _get_proprioception_dict(self):\n        dic = super()._get_proprioception_dict()\n\n        # Grab wheel joint velocity info\n        joints = list(self._joints.values())\n        wheel_joints = [joints[idx] for idx in self.base_control_idx]\n        l_vel, r_vel = [jnt.get_state()[1] for jnt in wheel_joints]\n\n        # Compute linear and angular velocities\n        lin_vel = (l_vel + r_vel) / 2.0 * self.wheel_radius\n        ang_vel = (r_vel - l_vel) / self.wheel_axle_length\n\n        # Add info\n        dic[\"dd_base_lin_vel\"] = lin_vel        # lin_vel is already 1D np array of length 1\n        dic[\"dd_base_ang_vel\"] = ang_vel        # lin_vel is already 1D np array of length 1\n\n        return dic\n\n    @property\n    def default_proprio_obs(self):\n        obs_keys = super().default_proprio_obs\n        return obs_keys + [\"dd_base_lin_vel\", \"dd_base_ang_vel\"]\n\n    @property\n    def _default_controllers(self):\n        # Always call super first\n        controllers = super()._default_controllers\n\n        # Use DifferentialDrive as default\n        controllers[\"base\"] = \"DifferentialDriveController\"\n\n        return controllers\n\n    @property\n    def _default_base_differential_drive_controller_config(self):\n        \"\"\"\n        Returns:\n            dict: Default differential drive controller config to\n                control this robot's base.\n        \"\"\"\n        return {\n            \"name\": \"DifferentialDriveController\",\n            \"control_freq\": self._control_freq,\n            \"wheel_radius\": self.wheel_radius,\n            \"wheel_axle_length\": self.wheel_axle_length,\n            \"control_limits\": self.control_limits,\n            \"dof_idx\": self.base_control_idx,\n        }\n\n    @property\n    def _default_controller_config(self):\n        # Always run super method first\n        cfg = super()._default_controller_config\n\n        # Add differential drive option to base\n        cfg[\"base\"][\n            self._default_base_differential_drive_controller_config[\"name\"]\n        ] = self._default_base_differential_drive_controller_config\n\n        return cfg\n\n    @property\n    @abstractmethod\n    def wheel_radius(self):\n        \"\"\"\n        Returns:\n            float: radius of each wheel at the base, in metric units\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    @abstractmethod\n    def wheel_axle_length(self):\n        \"\"\"\n        Returns:\n            float: perpendicular distance between the robot's two wheels, in metric units\n        \"\"\"\n        raise NotImplementedError\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"TwoWheelRobot\")\n        return classes\n</code></pre>","location":"reference/robots/two_wheel_robot.html#robots.two_wheel_robot.TwoWheelRobot"},{"title":"<code>wheel_axle_length</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>perpendicular distance between the robot's two wheels, in metric units</p>","location":"reference/robots/two_wheel_robot.html#robots.two_wheel_robot.TwoWheelRobot.wheel_axle_length"},{"title":"<code>wheel_radius</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>radius of each wheel at the base, in metric units</p>","location":"reference/robots/two_wheel_robot.html#robots.two_wheel_robot.TwoWheelRobot.wheel_radius"},{"title":"scenes","text":"","location":"reference/scenes/index.html"},{"title":"interactive_traversable_scene","text":"","location":"reference/scenes/interactive_traversable_scene.html"},{"title":"<code>InteractiveTraversableScene</code>","text":"<p>         Bases: <code>TraversableScene</code></p> <p>Create an interactive scene defined from a scene json file. In general, this supports curated, pre-defined scene layouts with annotated objects. This adds semantic support via a segmentation map generated for this specific scene.</p>  Source code in <code>scenes/interactive_traversable_scene.py</code> <pre><code>class InteractiveTraversableScene(TraversableScene):\n    \"\"\"\n    Create an interactive scene defined from a scene json file.\n    In general, this supports curated, pre-defined scene layouts with annotated objects.\n    This adds semantic support via a segmentation map generated for this specific scene.\n    \"\"\"\n    def __init__(\n        self,\n        scene_model,\n        scene_instance=None,\n        scene_file=None,\n        trav_map_resolution=0.1,\n        trav_map_erosion=2,\n        trav_map_with_objects=True,\n        build_graph=True,\n        num_waypoints=10,\n        waypoint_resolution=0.2,\n        load_object_categories=None,\n        not_load_object_categories=None,\n        load_room_types=None,\n        load_room_instances=None,\n        seg_map_resolution=0.1,\n        include_robots=True,\n    ):\n        \"\"\"\n        Args:\n            scene_model (str): Scene model name, e.g.: Rs_int\n            scene_instance (None or str): name of json file to load (without .json); if None,\n                defaults to og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.urdf\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                This will override scene_instance and scene_model!\n            trav_map_resolution (float): traversability map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n            load_object_categories (None or list): if specified, only load these object categories into the scene\n            not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n            load_room_types (None or list): only load objects in these room types into the scene\n            load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n            seg_map_resolution (float): room segmentation map resolution\n            include_robots (bool): whether to also include the robot(s) defined in the scene\n        \"\"\"\n\n        # Store attributes from inputs\n        self.include_robots = include_robots\n\n        # Infer scene directory\n        self.scene_dir = get_og_scene_path(scene_model)\n\n        # Other values that will be loaded at runtime\n        self.load_object_categories = None\n        self.not_load_object_categories = None\n        self.load_room_instances = None\n\n        # Get scene information\n        if scene_file is None:\n            scene_file = self.get_scene_loading_info(\n                scene_model=scene_model,\n                scene_instance=scene_instance,\n            )\n\n        # Load room semantic and instance segmentation map (must occur AFTER inferring scene directory)\n        self._seg_map = SegmentationMap(scene_dir=self.scene_dir, map_resolution=seg_map_resolution)\n\n        # Decide which room(s) and object categories to load\n        self.filter_rooms_and_object_categories(\n            load_object_categories, not_load_object_categories, load_room_types, load_room_instances\n        )\n\n        # Run super init first\n        super().__init__(\n            scene_model=scene_model,\n            scene_file=scene_file,\n            trav_map_resolution=trav_map_resolution,\n            trav_map_erosion=trav_map_erosion,\n            trav_map_with_objects=trav_map_with_objects,\n            build_graph=build_graph,\n            num_waypoints=num_waypoints,\n            waypoint_resolution=waypoint_resolution,\n            use_floor_plane=False,\n        )\n\n    def get_scene_loading_info(self, scene_model, scene_instance=None):\n        \"\"\"\n        Gets scene loading info to know what single USD file to load, specified indirectly via @scene_instance if it\n        is specified, otherwise, will grab the \"best\" scene file to load.\n\n        Args:\n            scene_model (str): Name of the scene to load, e.g, Rs_int, etc.\n            scene_instance (None or str): If specified, should be name of json file to load. (without .json), default to\n                og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.json\n\n        Returns:\n            str: Absolute path to the desired scene file (.json) to load\n        \"\"\"\n        # Infer scene file from model and directory\n        fname = \"{}_best\".format(scene_model) if scene_instance is None else scene_instance\n        return os.path.join(self.scene_dir, \"json\", \"{}.json\".format(fname))\n\n    def filter_rooms_and_object_categories(\n        self, load_object_categories, not_load_object_categories, load_room_types, load_room_instances\n    ):\n        \"\"\"\n        Handle partial scene loading based on object categories, room types or room instances\n\n        Args:\n            load_object_categories (None or list): if specified, only load these object categories into the scene\n            not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n            load_room_types (None or list): only load objects in these room types into the scene\n            load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n        \"\"\"\n        self.load_object_categories = [load_object_categories] if \\\n            isinstance(load_object_categories, str) else load_object_categories\n\n        self.not_load_object_categories = [not_load_object_categories] if \\\n            isinstance(not_load_object_categories, str) else not_load_object_categories\n\n        if load_room_instances is not None:\n            if isinstance(load_room_instances, str):\n                load_room_instances = [load_room_instances]\n            load_room_instances_filtered = []\n            for room_instance in load_room_instances:\n                if room_instance in self._seg_map.room_ins_name_to_ins_id:\n                    load_room_instances_filtered.append(room_instance)\n                else:\n                    logging.warning(\"room_instance [{}] does not exist.\".format(room_instance))\n            self.load_room_instances = load_room_instances_filtered\n        elif load_room_types is not None:\n            if isinstance(load_room_types, str):\n                load_room_types = [load_room_types]\n            load_room_instances_filtered = []\n            for room_type in load_room_types:\n                if room_type in self._seg_map.room_sem_name_to_ins_name:\n                    load_room_instances_filtered.extend(self._seg_map.room_sem_name_to_ins_name[room_type])\n                else:\n                    logging.warning(\"room_type [{}] does not exist.\".format(room_type))\n            self.load_room_instances = load_room_instances_filtered\n        else:\n            self.load_room_instances = None\n\n    def _load(self, simulator):\n        # Run super first\n        super()._load(simulator=simulator)\n\n        # Load the traversability map if we have the connectivity graph\n        maps_path = os.path.join(self.scene_dir, \"layout\")\n        if self.has_connectivity_graph:\n            self._trav_map.load_map(maps_path)\n\n    def _should_load_object(self, obj_info):\n        category = obj_info[\"args\"].get(\"category\", \"object\")\n        in_rooms = obj_info[\"args\"].get(\"in_rooms\", [])\n\n        # Do not load these object categories (can blacklist building structures as well)\n        not_blacklisted = self.not_load_object_categories is None or category not in self.not_load_object_categories\n\n        # Only load these object categories (no need to white list building structures)\n        whitelisted = self.load_object_categories is None or category in self.load_object_categories\n\n        # This object is not located in one of the selected rooms, skip\n        valid_room = self.load_room_instances is None or len(set(self.load_room_instances) &amp; set(in_rooms)) &gt;= 0\n\n        # Check whether this is an agent and we allow agents\n        agent_ok = self.include_robots or category != robot_macros.ROBOT_CATEGORY\n\n        # We only load this model if all the above conditions are met\n        return not_blacklisted and whitelisted and valid_room and agent_ok\n\n    @property\n    def seg_map(self):\n        \"\"\"\n        Returns:\n            SegmentationMap: Map for segmenting this scene\n        \"\"\"\n        return self._seg_map\n\n    @classmethod\n    def modify_init_info_for_restoring(cls, init_info):\n        # Run super first\n        super().modify_init_info_for_restoring(init_info=init_info)\n\n        # We also make sure we load in any robots, and also pop any filters that were stored\n        init_info[\"args\"][\"include_robots\"] = True\n        init_info[\"args\"][\"load_object_categories\"] = None\n        init_info[\"args\"][\"not_load_object_categories\"] = None\n        init_info[\"args\"][\"load_room_types\"] = None\n        init_info[\"args\"][\"load_room_instances\"] = None\n</code></pre>","location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene"},{"title":"<code>seg_map</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>SegmentationMap</code>   <p>Map for segmenting this scene</p>","location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.seg_map"},{"title":"<code>__init__(scene_model, scene_instance=None, scene_file=None, trav_map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2, load_object_categories=None, not_load_object_categories=None, load_room_types=None, load_room_instances=None, seg_map_resolution=0.1, include_robots=True)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>scene_model</code>  <code>str</code>  <p>Scene model name, e.g.: Rs_int</p>  required    <code>scene_instance</code>  <code>None or str</code>  <p>name of json file to load (without .json); if None, defaults to og_dataset/scenes//json/.urdf  <code>None</code>    <code>scene_file</code>  <code>None or str</code>  <p>If specified, full path of JSON file to load (with .json). This will override scene_instance and scene_model!</p>  <code>None</code>    <code>trav_map_resolution</code>  <code>float</code>  <p>traversability map resolution</p>  <code>0.1</code>    <code>trav_map_erosion</code>  <code>float</code>  <p>erosion radius of traversability areas, should be robot footprint radius</p>  <code>2</code>    <code>trav_map_with_objects</code>  <code>bool</code>  <p>whether to use objects or not when constructing graph</p>  <code>True</code>    <code>build_graph</code>  <code>bool</code>  <p>build connectivity graph</p>  <code>True</code>    <code>num_waypoints</code>  <code>int</code>  <p>number of way points returned</p>  <code>10</code>    <code>waypoint_resolution</code>  <code>float</code>  <p>resolution of adjacent way points</p>  <code>0.2</code>    <code>load_object_categories</code>  <code>None or list</code>  <p>if specified, only load these object categories into the scene</p>  <code>None</code>    <code>not_load_object_categories</code>  <code>None or list</code>  <p>if specified, do not load these object categories into the scene</p>  <code>None</code>    <code>load_room_types</code>  <code>None or list</code>  <p>only load objects in these room types into the scene</p>  <code>None</code>    <code>load_room_instances</code>  <code>None or list</code>  <p>if specified, only load objects in these room instances into the scene</p>  <code>None</code>    <code>seg_map_resolution</code>  <code>float</code>  <p>room segmentation map resolution</p>  <code>0.1</code>    <code>include_robots</code>  <code>bool</code>  <p>whether to also include the robot(s) defined in the scene</p>  <code>True</code>      Source code in <code>scenes/interactive_traversable_scene.py</code> <pre><code>def __init__(\n    self,\n    scene_model,\n    scene_instance=None,\n    scene_file=None,\n    trav_map_resolution=0.1,\n    trav_map_erosion=2,\n    trav_map_with_objects=True,\n    build_graph=True,\n    num_waypoints=10,\n    waypoint_resolution=0.2,\n    load_object_categories=None,\n    not_load_object_categories=None,\n    load_room_types=None,\n    load_room_instances=None,\n    seg_map_resolution=0.1,\n    include_robots=True,\n):\n    \"\"\"\n    Args:\n        scene_model (str): Scene model name, e.g.: Rs_int\n        scene_instance (None or str): name of json file to load (without .json); if None,\n            defaults to og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.urdf\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            This will override scene_instance and scene_model!\n        trav_map_resolution (float): traversability map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n        load_object_categories (None or list): if specified, only load these object categories into the scene\n        not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n        load_room_types (None or list): only load objects in these room types into the scene\n        load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n        seg_map_resolution (float): room segmentation map resolution\n        include_robots (bool): whether to also include the robot(s) defined in the scene\n    \"\"\"\n\n    # Store attributes from inputs\n    self.include_robots = include_robots\n\n    # Infer scene directory\n    self.scene_dir = get_og_scene_path(scene_model)\n\n    # Other values that will be loaded at runtime\n    self.load_object_categories = None\n    self.not_load_object_categories = None\n    self.load_room_instances = None\n\n    # Get scene information\n    if scene_file is None:\n        scene_file = self.get_scene_loading_info(\n            scene_model=scene_model,\n            scene_instance=scene_instance,\n        )\n\n    # Load room semantic and instance segmentation map (must occur AFTER inferring scene directory)\n    self._seg_map = SegmentationMap(scene_dir=self.scene_dir, map_resolution=seg_map_resolution)\n\n    # Decide which room(s) and object categories to load\n    self.filter_rooms_and_object_categories(\n        load_object_categories, not_load_object_categories, load_room_types, load_room_instances\n    )\n\n    # Run super init first\n    super().__init__(\n        scene_model=scene_model,\n        scene_file=scene_file,\n        trav_map_resolution=trav_map_resolution,\n        trav_map_erosion=trav_map_erosion,\n        trav_map_with_objects=trav_map_with_objects,\n        build_graph=build_graph,\n        num_waypoints=num_waypoints,\n        waypoint_resolution=waypoint_resolution,\n        use_floor_plane=False,\n    )\n</code></pre>","location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.__init__"},{"title":"<code>filter_rooms_and_object_categories(load_object_categories, not_load_object_categories, load_room_types, load_room_instances)</code>","text":"<p>Handle partial scene loading based on object categories, room types or room instances</p> <p>Parameters:</p>    Name Type Description Default     <code>load_object_categories</code>  <code>None or list</code>  <p>if specified, only load these object categories into the scene</p>  required    <code>not_load_object_categories</code>  <code>None or list</code>  <p>if specified, do not load these object categories into the scene</p>  required    <code>load_room_types</code>  <code>None or list</code>  <p>only load objects in these room types into the scene</p>  required    <code>load_room_instances</code>  <code>None or list</code>  <p>if specified, only load objects in these room instances into the scene</p>  required      Source code in <code>scenes/interactive_traversable_scene.py</code> <pre><code>def filter_rooms_and_object_categories(\n    self, load_object_categories, not_load_object_categories, load_room_types, load_room_instances\n):\n    \"\"\"\n    Handle partial scene loading based on object categories, room types or room instances\n\n    Args:\n        load_object_categories (None or list): if specified, only load these object categories into the scene\n        not_load_object_categories (None or list): if specified, do not load these object categories into the scene\n        load_room_types (None or list): only load objects in these room types into the scene\n        load_room_instances (None or list): if specified, only load objects in these room instances into the scene\n    \"\"\"\n    self.load_object_categories = [load_object_categories] if \\\n        isinstance(load_object_categories, str) else load_object_categories\n\n    self.not_load_object_categories = [not_load_object_categories] if \\\n        isinstance(not_load_object_categories, str) else not_load_object_categories\n\n    if load_room_instances is not None:\n        if isinstance(load_room_instances, str):\n            load_room_instances = [load_room_instances]\n        load_room_instances_filtered = []\n        for room_instance in load_room_instances:\n            if room_instance in self._seg_map.room_ins_name_to_ins_id:\n                load_room_instances_filtered.append(room_instance)\n            else:\n                logging.warning(\"room_instance [{}] does not exist.\".format(room_instance))\n        self.load_room_instances = load_room_instances_filtered\n    elif load_room_types is not None:\n        if isinstance(load_room_types, str):\n            load_room_types = [load_room_types]\n        load_room_instances_filtered = []\n        for room_type in load_room_types:\n            if room_type in self._seg_map.room_sem_name_to_ins_name:\n                load_room_instances_filtered.extend(self._seg_map.room_sem_name_to_ins_name[room_type])\n            else:\n                logging.warning(\"room_type [{}] does not exist.\".format(room_type))\n        self.load_room_instances = load_room_instances_filtered\n    else:\n        self.load_room_instances = None\n</code></pre>","location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.filter_rooms_and_object_categories"},{"title":"<code>get_scene_loading_info(scene_model, scene_instance=None)</code>","text":"<p>Gets scene loading info to know what single USD file to load, specified indirectly via @scene_instance if it is specified, otherwise, will grab the \"best\" scene file to load.</p> <p>Parameters:</p>    Name Type Description Default     <code>scene_model</code>  <code>str</code>  <p>Name of the scene to load, e.g, Rs_int, etc.</p>  required    <code>scene_instance</code>  <code>None or str</code>  <p>If specified, should be name of json file to load. (without .json), default to og_dataset/scenes//json/.json  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Absolute path to the desired scene file (.json) to load</p>     Source code in <code>scenes/interactive_traversable_scene.py</code> <pre><code>def get_scene_loading_info(self, scene_model, scene_instance=None):\n    \"\"\"\n    Gets scene loading info to know what single USD file to load, specified indirectly via @scene_instance if it\n    is specified, otherwise, will grab the \"best\" scene file to load.\n\n    Args:\n        scene_model (str): Name of the scene to load, e.g, Rs_int, etc.\n        scene_instance (None or str): If specified, should be name of json file to load. (without .json), default to\n            og_dataset/scenes/&lt;scene_model&gt;/json/&lt;scene_instance&gt;.json\n\n    Returns:\n        str: Absolute path to the desired scene file (.json) to load\n    \"\"\"\n    # Infer scene file from model and directory\n    fname = \"{}_best\".format(scene_model) if scene_instance is None else scene_instance\n    return os.path.join(self.scene_dir, \"json\", \"{}.json\".format(fname))\n</code></pre>","location":"reference/scenes/interactive_traversable_scene.html#scenes.interactive_traversable_scene.InteractiveTraversableScene.get_scene_loading_info"},{"title":"scene_base","text":"","location":"reference/scenes/scene_base.html"},{"title":"<code>Scene</code>","text":"<p>         Bases: <code>Serializable</code>, <code>Registerable</code>, <code>Recreatable</code>, <code>ABC</code></p> <p>Base class for all Scene objects. Contains the base functionalities for an arbitary scene with an arbitrary set of added objects</p>  Source code in <code>scenes/scene_base.py</code> <pre><code>class Scene(Serializable, Registerable, Recreatable, ABC):\n    \"\"\"\n    Base class for all Scene objects.\n    Contains the base functionalities for an arbitary scene with an arbitrary set of added objects\n    \"\"\"\n    def __init__(\n            self,\n            scene_file=None,\n            use_floor_plane=True,\n            floor_plane_visible=True,\n            floor_plane_color=(1.0, 1.0, 1.0),\n    ):\n        \"\"\"\n        Args:\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                None results in no additional objects being loaded into the scene\n            use_floor_plane (bool): whether to load a flat floor plane into the simulator\n            floor_plane_visible (bool): whether to render the additionally added floor plane\n            floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n                to the generated floor plane\n        \"\"\"\n        # Store internal variables\n        self.scene_file = scene_file\n        self._loaded = False                    # Whether this scene exists in the stage or not\n        self._initialized = False               # Whether this scene has its internal handles / info initialized or not (occurs AFTER and INDEPENDENTLY from loading!)\n        self._registry = None\n        self._world_prim = None\n        self._initial_state = None\n        self._objects_info = None                       # Information associated with this scene\n        self._use_floor_plane = use_floor_plane\n        self._floor_plane_visible = floor_plane_visible\n        self._floor_plane_color = floor_plane_color\n        self._floor_plane = None\n\n        # Call super init\n        super().__init__()\n\n    @property\n    def registry(self):\n        \"\"\"\n        Returns:\n            SerializableRegistry: Master registry containing sub-registries of objects, robots, systems, etc.\n        \"\"\"\n        return self._registry\n\n    @property\n    def object_registry(self):\n        \"\"\"\n        Returns:\n            SerializableRegistry: Object registry containing all active standalone objects in the scene\n        \"\"\"\n        return self._registry(key=\"name\", value=\"object_registry\")\n\n    @property\n    def system_registry(self):\n        \"\"\"\n        Returns:\n            SerializableRegistry: System registry containing all physical systems in the scene (e.g.: WaterSystem,\n                DustSystem, etc.)\n        \"\"\"\n        return self._registry(key=\"name\", value=\"system_registry\")\n\n    @property\n    def objects(self):\n        \"\"\"\n        Get the objects in the scene.\n\n        Returns:\n            list of BaseObject: Standalone object(s) that are currently in this scene\n        \"\"\"\n        return self.object_registry.objects\n\n    @property\n    def robots(self):\n        \"\"\"\n        Robots in the scene\n\n        Returns:\n            list of BaseRobot: Robot(s) that are currently in this scene\n        \"\"\"\n        return list(self.object_registry(\"category\", robot_macros.ROBOT_CATEGORY, []))\n\n    @property\n    def systems(self):\n        \"\"\"\n        Systems in the scene\n\n        Returns:\n            list of BaseSystem: System(s) that are available to use in this scene\n        \"\"\"\n        return self.system_registry.objects\n\n    @property\n    def object_registry_unique_keys(self):\n        \"\"\"\n        Returns:\n            list of str: Keys with which to index into the object registry. These should be valid public attributes of\n                prims that we can use as unique IDs to reference prims, e.g., prim.prim_path, prim.name, prim.handle, etc.\n        \"\"\"\n        return [\"name\", \"prim_path\", \"root_handle\", \"uuid\"]\n\n    @property\n    def object_registry_group_keys(self):\n        \"\"\"\n        Returns:\n            list of str: Keys with which to index into the object registry. These should be valid public attributes of\n                prims that we can use as grouping IDs to reference prims, e.g., prim.in_rooms\n        \"\"\"\n        return [\"prim_type\", \"states\", \"category\", \"fixed_base\", \"in_rooms\", \"states\"]\n\n    @property\n    def loaded(self):\n        return self._loaded\n\n    @property\n    def initialized(self):\n        return self._initialized\n\n    def _load(self, simulator):\n        \"\"\"\n        Load the scene into simulator\n        The elements to load may include: floor, building, objects, etc.\n\n        Args:\n            simulator (Simulator): the simulator to load the scene into\n        \"\"\"\n        # We just add a ground plane if requested\n        if self._use_floor_plane:\n            self.add_ground_plane(color=self._floor_plane_color, visible=self._floor_plane_visible)\n\n    def _load_objects_from_scene_file(self, simulator):\n        \"\"\"\n        Loads scene objects based on metadata information found in the current USD stage's scene info\n        (information stored in the world prim's CustomData)\n        \"\"\"\n        # Grab objects info from the scene file\n        with open(self.scene_file, \"r\") as f:\n            scene_info = json.load(f)\n        init_info = scene_info[\"objects_info\"][\"init_info\"]\n        init_state = scene_info[\"state\"][\"object_registry\"]\n\n        # Iterate over all scene info, and instantiate object classes linked to the objects found on the stage\n        # accordingly\n        for obj_name, obj_info in init_info.items():\n            # Check whether we should load the object or not\n            if not self._should_load_object(obj_info=obj_info):\n                continue\n            # Create object class instance\n            obj = create_object_from_init_info(obj_info)\n            # Import into the simulator\n            simulator.import_object(obj)\n            # Set the init pose accordingly\n            obj.set_position_orientation(\n                position=init_state[obj_name][\"root_link\"][\"pos\"],\n                orientation=init_state[obj_name][\"root_link\"][\"ori\"],\n            )\n\n        # disable collision between the fixed links of the fixed objects\n        fixed_objs = self.object_registry(\"fixed_base\", True, default_val=[])\n        if len(fixed_objs) &gt; 1:\n            # We iterate over all pairwise combinations of fixed objects\n            for obj_a, obj_b in combinations(fixed_objs, 2):\n                obj_a.root_link.add_filtered_collision_pair(obj_b.root_link)\n\n    def _should_load_object(self, obj_info):\n        \"\"\"\n        Helper function to check whether we should load an object given its init_info. Useful for potentially filtering\n        objects based on, e.g., their category, size, etc.\n\n        Subclasses can implement additional logic. By default, this returns True\n\n        Args:\n            obj_info (dict): Dictionary of object kwargs that will be used to load the object\n\n        Returns:\n            bool: Whether this object should be loaded or not\n        \"\"\"\n        return True\n\n    def load(self, simulator):\n        \"\"\"\n        Load the scene into simulator\n        The elements to load may include: floor, building, objects, etc.\n\n        Args:\n            simulator (Simulator): the simulator to load the scene into\n        \"\"\"\n        # Make sure simulator is stopped\n        assert simulator.is_stopped(), \"Simulator should be stopped when loading this scene!\"\n\n        # Do not override this function. Override _load instead.\n        if self._loaded:\n            raise ValueError(\"This scene is already loaded.\")\n\n        # Create the registry for tracking all objects in the scene\n        self._registry = self._create_registry()\n\n        # Store world prim\n        self._world_prim = simulator.world_prim\n\n        # Clear the systems\n        self.clear_systems()\n\n        self._load(simulator)\n\n        # Initialize systems\n        self.initialize_systems(simulator)\n\n        # If we have any scene file specified, use it to load the objects within it\n        if self.scene_file is not None:\n            self._load_objects_from_scene_file(simulator)\n\n        # We're now loaded\n        self._loaded = True\n\n        # Always stop the sim if we started it internally\n        if not simulator.is_stopped():\n            simulator.stop()\n\n    def initialize_systems(self, simulator):\n        # Initialize registries\n        for system in self.systems:\n            print(f\"Initializing system: {system.name}\")\n            system.initialize(simulator=simulator)\n\n    def clear_systems(self):\n        # Clears systems so they can be re-initialized\n        for system in self.systems:\n            print(f\"Clearing system: {system.name}\")\n            system.clear()\n\n    def _initialize(self):\n        \"\"\"\n        Initializes state of this scene and sets up any references necessary post-loading. Should be implemented by\n        sub-class for extended utility\n        \"\"\"\n        pass\n\n    def initialize(self):\n        \"\"\"\n        Initializes state of this scene and sets up any references necessary post-loading. Subclasses should\n        implement / extend the _initialize() method.\n        \"\"\"\n        assert not self._initialized, \"Scene can only be initialized once! (It is already initialized)\"\n        self._initialize()\n\n        # Grab relevant objects info and re-initialize object registry by handle since now handles are populated\n        self.update_objects_info()\n        self.object_registry.update(keys=\"root_handle\")\n        self.wake_scene_objects()\n\n        self._initialized = True\n\n        # Store initial state, which may be loaded from a scene file if specified\n        if self.scene_file is None:\n            init_state = self.dump_state(serialized=False)\n        else:\n            with open(self.scene_file, \"r\") as f:\n                scene_info = json.load(f)\n            init_state = scene_info[\"state\"]\n            og.sim.load_state(init_state, serialized=False)\n\n        self._initial_state = init_state\n\n    def _create_registry(self):\n        \"\"\"\n        Creates the internal registry used for tracking all objects\n\n        Returns:\n            SerializableRegistry: registry for tracking all objects\n        \"\"\"\n\n        # Create meta registry and populate with internal registries for robots, objects, and systems\n        registry = SerializableRegistry(\n            name=\"master_registry\",\n            class_types=SerializableRegistry,\n        )\n\n        # Add registry for systems -- this is already created externally, so we just pull it directly\n        registry.add(obj=SYSTEMS_REGISTRY)\n\n        # Add registry for objects\n        registry.add(obj=SerializableRegistry(\n            name=\"object_registry\",\n            class_types=BaseObject,\n            default_key=\"name\",\n            unique_keys=self.object_registry_unique_keys,\n            group_keys=self.object_registry_group_keys,\n        ))\n\n        return registry\n\n    def wake_scene_objects(self):\n        \"\"\"\n        Force wakeup sleeping objects\n        \"\"\"\n        for obj in self.objects:\n            obj.wake()\n\n    def get_objects_with_state(self, state):\n        \"\"\"\n        Get the objects with a given state in the scene.\n\n        Args:\n            state (BaseObjectState): state of the objects to get\n\n        Returns:\n            set: all objects with the given state\n        \"\"\"\n        return self.object_registry(\"states\", state, set())\n\n    def _add_object(self, obj):\n        \"\"\"\n        Add an object to the scene's internal object tracking mechanisms.\n\n        Note that if the scene is not loaded, it should load this added object alongside its other objects when\n        scene.load() is called. The object should also be accessible through scene.objects.\n\n        Args:\n            obj (BaseObject): the object to load into the simulator\n        \"\"\"\n        pass\n\n    def add_object(self, obj, simulator, register=True, _is_call_from_simulator=False):\n        \"\"\"\n        Add an object to the scene, loading it if the scene is already loaded.\n\n        Note that calling add_object to an already loaded scene should only be done by the simulator's import_object()\n        function.\n\n        Args:\n            obj (BaseObject): the object to load\n            simulator (Simulator): the simulator to add the object to\n            register (bool): whether to track this object internally in the scene registry\n            _is_call_from_simulator (bool): whether the caller is the simulator. This should\n            **not** be set by any callers that are not the Simulator class\n\n        Returns:\n            Usd.Prim: the prim of the loaded object if the scene was already loaded, or None if the scene is not loaded\n                (in that case, the object is stored to be loaded together with the scene)\n        \"\"\"\n        # Make sure the simulator is the one calling this function\n        assert _is_call_from_simulator, \"Use import_object() for adding objects to a simulator and scene!\"\n\n        # If the scene is already loaded, we need to load this object separately. Otherwise, don't do anything now,\n        # let scene._load() load the object when called later on.\n        prim = obj.load(simulator)\n\n        # Add this object to our registry based on its type, if we want to register it\n        if register:\n            self.object_registry.add(obj)\n\n            # Run any additional scene-specific logic with the created object\n            self._add_object(obj)\n\n        return prim\n\n    def remove_object(self, obj, simulator):\n        \"\"\"\n        Method to remove an object from the simulator\n\n        Args:\n            obj (BaseObject): Object to remove\n            simulator (Simulator): current simulation context\n        \"\"\"\n        # Remove from the appropriate registry\n        self.object_registry.remove(obj)\n\n        # Remove from omni stage\n        obj.remove(simulator=simulator)\n\n    def reset(self):\n        \"\"\"\n        Resets this scene\n        \"\"\"\n        # Reset all systems\n        for system in self.systems:\n            system.reset()\n\n        # Reset all object and robot states\n        for obj in self.objects:\n            if isinstance(obj, StatefulObject):\n                obj.reset_states()\n\n        # Reset the pose and joint configuration of all scene objects.\n        if self._initial_state is not None:\n            self.load_state(self._initial_state)\n            og.app.update()\n\n    @property\n    def n_floors(self):\n        \"\"\"\n        Returns:\n            int: Number of floors in this scene\n        \"\"\"\n        # Default is a single floor\n        return 1\n\n    @property\n    def n_objects(self):\n        \"\"\"\n        Returns:\n            int: number of objects\n        \"\"\"\n        return len(self.objects)\n\n    @property\n    def fixed_objects(self):\n        \"\"\"\n        Returns:\n            dict: Keyword-mapped objects that are fixed in the scene. Maps object name to their object class instances\n                (DatasetObject)\n        \"\"\"\n        return {obj.name: obj for obj in self.object_registry(\"fixed_base\", True)}\n\n    def get_random_floor(self):\n        \"\"\"\n        Sample a random floor among all existing floor_heights in the scene.\n        Most scenes in OmniGibson only have a single floor.\n\n        Returns:\n            int: an integer between 0 and self.n_floors-1\n        \"\"\"\n        return np.random.randint(0, self.n_floors)\n\n    def get_random_point(self, floor=None):\n        \"\"\"\n        Sample a random point on the given floor number. If not given, sample a random floor number.\n        Should be implemented by subclass.\n\n        Args:\n            floor (None or int): floor number. None means the floor is randomly sampled\n\n        Returns:\n            2-tuple:\n                - int: floor number. This is the sampled floor number if @floor is None\n                - 3-array: (x,y,z) randomly sampled point\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n        \"\"\"\n        Get the shortest path from one point to another point.\n\n        Args:\n            floor (int): floor number\n            source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n            target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n            entire_path (bool): whether to return the entire path\n\n        Returns:\n            2-tuple:\n                - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n                - float: geodesic distance of the path\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_floor_height(self, floor=0):\n        \"\"\"\n        Get the height of the given floor. Default is 0.0, since we only have a single floor\n\n        Args:\n            floor: an integer identifying the floor\n\n        Returns:\n            int: height of the given floor\n        \"\"\"\n        return 0.0\n\n    def add_ground_plane(\n        self,\n        size=None,\n        z_position: float = 0,\n        name=\"ground_plane\",\n        prim_path: str = \"/World/groundPlane\",\n        static_friction: float = 0.5,\n        dynamic_friction: float = 0.5,\n        restitution: float = 0.8,\n        color=None,\n        visible=True,\n    ):\n        \"\"\"\n        Generate a ground plane into the simulator\n\n        Args:\n            size (None or float): If specified, sets the (x,y) size of the generated plane\n            z_position (float): Z position of the generated plane\n            name (str): Name to assign to the generated plane\n            prim_path (str): Prim path for the generated plane\n            static_friction (float): Static friction of the generated plane\n            dynamic_friction (float): Dynamics friction of the generated plane\n            restitution (float): Restitution of the generated plane\n            color (None or 3-array): If specified, sets the (R,G,B) color of the generated plane\n            visible (bool): Whether the plane should be visible or not\n        \"\"\"\n        plane = GroundPlane(\n            prim_path=prim_path,\n            name=name,\n            z_position=z_position,\n            size=size,\n            color=None if color is None else np.array(color),\n            visible=visible,\n\n            # TODO: update with new PhysicsMaterial API\n            # static_friction=static_friction,\n            # dynamic_friction=dynamic_friction,\n            # restitution=restitution,\n        )\n\n        self._floor_plane = XFormPrim(\n            prim_path=plane.prim_path,\n            name=plane.name,\n        )\n\n    def update_initial_state(self):\n        \"\"\"\n        Updates the initial state for this scene (which the scene will get reset to upon calling reset())\n        \"\"\"\n        self._initial_state = self.dump_state(serialized=False)\n\n    def update_objects_info(self):\n        \"\"\"\n        Updates the scene-relevant information and saves it to the active USD. Useful for reloading a scene directly\n        from a saved USD in this format.\n        \"\"\"\n        # Save relevant information\n\n        # Iterate over all objects and save their init info\n        init_info = {obj.name: obj.get_init_info() for obj in self.object_registry.objects}\n\n        # Compose as single dictionary and store internally\n        self._objects_info = OrderedDict(init_info=init_info)\n\n    def get_objects_info(self):\n        \"\"\"\n        Stored information, if any, for this scene. Structure is:\n\n            \"init_info\":\n                \"&lt;obj0&gt;\": &lt;obj0&gt; init kw/args\n                ...\n                \"&lt;robot0&gt;\": &lt;robot0&gt; init kw/args\n                ...\n\n        Returns:\n            None or dict: If it exists, nested dictionary of relevant objects' information\n        \"\"\"\n        return self._objects_info\n\n    @property\n    def state_size(self):\n        # Total state size is the state size of our registry\n        return self._registry.state_size\n\n    def _dump_state(self):\n        # Default state for the scene is from the registry alone\n        return self._registry.dump_state(serialized=False)\n\n    def _load_state(self, state):\n        # Default state for the scene is from the registry alone\n        self._registry.load_state(state=state, serialized=False)\n\n    def _serialize(self, state):\n        # Default state for the scene is from the registry alone\n        return self._registry.serialize(state=state)\n\n    def _deserialize(self, state):\n        # Default state for the scene is from the registry alone\n        # We split this into two explicit steps, because the actual registry state size might dynamically change\n        # as we're deserializing\n        state_dict = self._registry.deserialize(state=state)\n        return state_dict, self._registry.state_size\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_SCENES\n        return REGISTERED_SCENES\n\n    @classmethod\n    def modify_init_info_for_restoring(cls, init_info):\n        \"\"\"\n        Helper function to modify a given init info for restoring a scene from corresponding scene info.\n        Note that this function modifies IN-PLACE!\n\n        Args:\n            init_info (dict): Information for this scene from @self.get_init_info()\n        \"\"\"\n        # Default is pass\n        pass\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene"},{"title":"<code>fixed_objects</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Keyword-mapped objects that are fixed in the scene. Maps object name to their object class instances (DatasetObject)</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.fixed_objects"},{"title":"<code>n_floors</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of floors in this scene</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.n_floors"},{"title":"<code>n_objects</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>number of objects</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.n_objects"},{"title":"<code>object_registry</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>SerializableRegistry</code>   <p>Object registry containing all active standalone objects in the scene</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.object_registry"},{"title":"<code>object_registry_group_keys</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>list of str: Keys with which to index into the object registry. These should be valid public attributes of prims that we can use as grouping IDs to reference prims, e.g., prim.in_rooms</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.object_registry_group_keys"},{"title":"<code>object_registry_unique_keys</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>list of str: Keys with which to index into the object registry. These should be valid public attributes of prims that we can use as unique IDs to reference prims, e.g., prim.prim_path, prim.name, prim.handle, etc.</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.object_registry_unique_keys"},{"title":"<code>objects</code>  <code>property</code>","text":"<p>Get the objects in the scene.</p> <p>Returns:</p>    Type Description       <p>list of BaseObject: Standalone object(s) that are currently in this scene</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.objects"},{"title":"<code>registry</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>SerializableRegistry</code>   <p>Master registry containing sub-registries of objects, robots, systems, etc.</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.registry"},{"title":"<code>robots</code>  <code>property</code>","text":"<p>Robots in the scene</p> <p>Returns:</p>    Type Description       <p>list of BaseRobot: Robot(s) that are currently in this scene</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.robots"},{"title":"<code>system_registry</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>SerializableRegistry</code>   <p>System registry containing all physical systems in the scene (e.g.: WaterSystem, DustSystem, etc.)</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.system_registry"},{"title":"<code>systems</code>  <code>property</code>","text":"<p>Systems in the scene</p> <p>Returns:</p>    Type Description       <p>list of BaseSystem: System(s) that are available to use in this scene</p>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.systems"},{"title":"<code>__init__(scene_file=None, use_floor_plane=True, floor_plane_visible=True, floor_plane_color=(1.0, 1.0, 1.0))</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>scene_file</code>  <code>None or str</code>  <p>If specified, full path of JSON file to load (with .json). None results in no additional objects being loaded into the scene</p>  <code>None</code>    <code>use_floor_plane</code>  <code>bool</code>  <p>whether to load a flat floor plane into the simulator</p>  <code>True</code>    <code>floor_plane_visible</code>  <code>bool</code>  <p>whether to render the additionally added floor plane</p>  <code>True</code>    <code>floor_plane_color</code>  <code>3-array</code>  <p>if @floor_plane_visible is True, this determines the (R,G,B) color assigned to the generated floor plane</p>  <code>(1.0, 1.0, 1.0)</code>      Source code in <code>scenes/scene_base.py</code> <pre><code>def __init__(\n        self,\n        scene_file=None,\n        use_floor_plane=True,\n        floor_plane_visible=True,\n        floor_plane_color=(1.0, 1.0, 1.0),\n):\n    \"\"\"\n    Args:\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            None results in no additional objects being loaded into the scene\n        use_floor_plane (bool): whether to load a flat floor plane into the simulator\n        floor_plane_visible (bool): whether to render the additionally added floor plane\n        floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n            to the generated floor plane\n    \"\"\"\n    # Store internal variables\n    self.scene_file = scene_file\n    self._loaded = False                    # Whether this scene exists in the stage or not\n    self._initialized = False               # Whether this scene has its internal handles / info initialized or not (occurs AFTER and INDEPENDENTLY from loading!)\n    self._registry = None\n    self._world_prim = None\n    self._initial_state = None\n    self._objects_info = None                       # Information associated with this scene\n    self._use_floor_plane = use_floor_plane\n    self._floor_plane_visible = floor_plane_visible\n    self._floor_plane_color = floor_plane_color\n    self._floor_plane = None\n\n    # Call super init\n    super().__init__()\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.__init__"},{"title":"<code>add_ground_plane(size=None, z_position=0, name='ground_plane', prim_path='/World/groundPlane', static_friction=0.5, dynamic_friction=0.5, restitution=0.8, color=None, visible=True)</code>","text":"<p>Generate a ground plane into the simulator</p> <p>Parameters:</p>    Name Type Description Default     <code>size</code>  <code>None or float</code>  <p>If specified, sets the (x,y) size of the generated plane</p>  <code>None</code>    <code>z_position</code>  <code>float</code>  <p>Z position of the generated plane</p>  <code>0</code>    <code>name</code>  <code>str</code>  <p>Name to assign to the generated plane</p>  <code>'ground_plane'</code>    <code>prim_path</code>  <code>str</code>  <p>Prim path for the generated plane</p>  <code>'/World/groundPlane'</code>    <code>static_friction</code>  <code>float</code>  <p>Static friction of the generated plane</p>  <code>0.5</code>    <code>dynamic_friction</code>  <code>float</code>  <p>Dynamics friction of the generated plane</p>  <code>0.5</code>    <code>restitution</code>  <code>float</code>  <p>Restitution of the generated plane</p>  <code>0.8</code>    <code>color</code>  <code>None or 3-array</code>  <p>If specified, sets the (R,G,B) color of the generated plane</p>  <code>None</code>    <code>visible</code>  <code>bool</code>  <p>Whether the plane should be visible or not</p>  <code>True</code>      Source code in <code>scenes/scene_base.py</code> <pre><code>def add_ground_plane(\n    self,\n    size=None,\n    z_position: float = 0,\n    name=\"ground_plane\",\n    prim_path: str = \"/World/groundPlane\",\n    static_friction: float = 0.5,\n    dynamic_friction: float = 0.5,\n    restitution: float = 0.8,\n    color=None,\n    visible=True,\n):\n    \"\"\"\n    Generate a ground plane into the simulator\n\n    Args:\n        size (None or float): If specified, sets the (x,y) size of the generated plane\n        z_position (float): Z position of the generated plane\n        name (str): Name to assign to the generated plane\n        prim_path (str): Prim path for the generated plane\n        static_friction (float): Static friction of the generated plane\n        dynamic_friction (float): Dynamics friction of the generated plane\n        restitution (float): Restitution of the generated plane\n        color (None or 3-array): If specified, sets the (R,G,B) color of the generated plane\n        visible (bool): Whether the plane should be visible or not\n    \"\"\"\n    plane = GroundPlane(\n        prim_path=prim_path,\n        name=name,\n        z_position=z_position,\n        size=size,\n        color=None if color is None else np.array(color),\n        visible=visible,\n\n        # TODO: update with new PhysicsMaterial API\n        # static_friction=static_friction,\n        # dynamic_friction=dynamic_friction,\n        # restitution=restitution,\n    )\n\n    self._floor_plane = XFormPrim(\n        prim_path=plane.prim_path,\n        name=plane.name,\n    )\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.add_ground_plane"},{"title":"<code>add_object(obj, simulator, register=True, _is_call_from_simulator=False)</code>","text":"<p>Add an object to the scene, loading it if the scene is already loaded.</p> <p>Note that calling add_object to an already loaded scene should only be done by the simulator's import_object() function.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>the object to load</p>  required    <code>simulator</code>  <code>Simulator</code>  <p>the simulator to add the object to</p>  required    <code>register</code>  <code>bool</code>  <p>whether to track this object internally in the scene registry</p>  <code>True</code>    <code>_is_call_from_simulator</code>  <code>bool</code>  <p>whether the caller is the simulator. This should</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>Usd.Prim: the prim of the loaded object if the scene was already loaded, or None if the scene is not loaded (in that case, the object is stored to be loaded together with the scene)</p>     Source code in <code>scenes/scene_base.py</code> <pre><code>def add_object(self, obj, simulator, register=True, _is_call_from_simulator=False):\n    \"\"\"\n    Add an object to the scene, loading it if the scene is already loaded.\n\n    Note that calling add_object to an already loaded scene should only be done by the simulator's import_object()\n    function.\n\n    Args:\n        obj (BaseObject): the object to load\n        simulator (Simulator): the simulator to add the object to\n        register (bool): whether to track this object internally in the scene registry\n        _is_call_from_simulator (bool): whether the caller is the simulator. This should\n        **not** be set by any callers that are not the Simulator class\n\n    Returns:\n        Usd.Prim: the prim of the loaded object if the scene was already loaded, or None if the scene is not loaded\n            (in that case, the object is stored to be loaded together with the scene)\n    \"\"\"\n    # Make sure the simulator is the one calling this function\n    assert _is_call_from_simulator, \"Use import_object() for adding objects to a simulator and scene!\"\n\n    # If the scene is already loaded, we need to load this object separately. Otherwise, don't do anything now,\n    # let scene._load() load the object when called later on.\n    prim = obj.load(simulator)\n\n    # Add this object to our registry based on its type, if we want to register it\n    if register:\n        self.object_registry.add(obj)\n\n        # Run any additional scene-specific logic with the created object\n        self._add_object(obj)\n\n    return prim\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.add_object"},{"title":"<code>get_floor_height(floor=0)</code>","text":"<p>Get the height of the given floor. Default is 0.0, since we only have a single floor</p> <p>Parameters:</p>    Name Type Description Default     <code>floor</code>   <p>an integer identifying the floor</p>  <code>0</code>     <p>Returns:</p>    Name Type Description     <code>int</code>   <p>height of the given floor</p>     Source code in <code>scenes/scene_base.py</code> <pre><code>def get_floor_height(self, floor=0):\n    \"\"\"\n    Get the height of the given floor. Default is 0.0, since we only have a single floor\n\n    Args:\n        floor: an integer identifying the floor\n\n    Returns:\n        int: height of the given floor\n    \"\"\"\n    return 0.0\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_floor_height"},{"title":"<code>get_objects_info()</code>","text":"<p>Stored information, if any, for this scene. Structure is:</p> <pre><code>\"init_info\":\n    \"&lt;obj0&gt;\": &lt;obj0&gt; init kw/args\n    ...\n    \"&lt;robot0&gt;\": &lt;robot0&gt; init kw/args\n    ...\n</code></pre> <p>Returns:</p>    Type Description       <p>None or dict: If it exists, nested dictionary of relevant objects' information</p>     Source code in <code>scenes/scene_base.py</code> <pre><code>def get_objects_info(self):\n    \"\"\"\n    Stored information, if any, for this scene. Structure is:\n\n        \"init_info\":\n            \"&lt;obj0&gt;\": &lt;obj0&gt; init kw/args\n            ...\n            \"&lt;robot0&gt;\": &lt;robot0&gt; init kw/args\n            ...\n\n    Returns:\n        None or dict: If it exists, nested dictionary of relevant objects' information\n    \"\"\"\n    return self._objects_info\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_objects_info"},{"title":"<code>get_objects_with_state(state)</code>","text":"<p>Get the objects with a given state in the scene.</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>BaseObjectState</code>  <p>state of the objects to get</p>  required     <p>Returns:</p>    Name Type Description     <code>set</code>   <p>all objects with the given state</p>     Source code in <code>scenes/scene_base.py</code> <pre><code>def get_objects_with_state(self, state):\n    \"\"\"\n    Get the objects with a given state in the scene.\n\n    Args:\n        state (BaseObjectState): state of the objects to get\n\n    Returns:\n        set: all objects with the given state\n    \"\"\"\n    return self.object_registry(\"states\", state, set())\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_objects_with_state"},{"title":"<code>get_random_floor()</code>","text":"<p>Sample a random floor among all existing floor_heights in the scene. Most scenes in OmniGibson only have a single floor.</p> <p>Returns:</p>    Name Type Description     <code>int</code>   <p>an integer between 0 and self.n_floors-1</p>     Source code in <code>scenes/scene_base.py</code> <pre><code>def get_random_floor(self):\n    \"\"\"\n    Sample a random floor among all existing floor_heights in the scene.\n    Most scenes in OmniGibson only have a single floor.\n\n    Returns:\n        int: an integer between 0 and self.n_floors-1\n    \"\"\"\n    return np.random.randint(0, self.n_floors)\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_random_floor"},{"title":"<code>get_random_point(floor=None)</code>","text":"<p>Sample a random point on the given floor number. If not given, sample a random floor number. Should be implemented by subclass.</p> <p>Parameters:</p>    Name Type Description Default     <code>floor</code>  <code>None or int</code>  <p>floor number. None means the floor is randomly sampled</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - int: floor number. This is the sampled floor number if @floor is None - 3-array: (x,y,z) randomly sampled point</p>     Source code in <code>scenes/scene_base.py</code> <pre><code>def get_random_point(self, floor=None):\n    \"\"\"\n    Sample a random point on the given floor number. If not given, sample a random floor number.\n    Should be implemented by subclass.\n\n    Args:\n        floor (None or int): floor number. None means the floor is randomly sampled\n\n    Returns:\n        2-tuple:\n            - int: floor number. This is the sampled floor number if @floor is None\n            - 3-array: (x,y,z) randomly sampled point\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_random_point"},{"title":"<code>get_shortest_path(floor, source_world, target_world, entire_path=False)</code>","text":"<p>Get the shortest path from one point to another point.</p> <p>Parameters:</p>    Name Type Description Default     <code>floor</code>  <code>int</code>  <p>floor number</p>  required    <code>source_world</code>  <code>2-array</code>  <p>(x,y) 2D source location in world reference frame (metric)</p>  required    <code>target_world</code>  <code>2-array</code>  <p>(x,y) 2D target location in world reference frame (metric)</p>  required    <code>entire_path</code>  <code>bool</code>  <p>whether to return the entire path</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - (N, 2) array: array of path waypoints, where N is the number of generated waypoints - float: geodesic distance of the path</p>     Source code in <code>scenes/scene_base.py</code> <pre><code>def get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n    \"\"\"\n    Get the shortest path from one point to another point.\n\n    Args:\n        floor (int): floor number\n        source_world (2-array): (x,y) 2D source location in world reference frame (metric)\n        target_world (2-array): (x,y) 2D target location in world reference frame (metric)\n        entire_path (bool): whether to return the entire path\n\n    Returns:\n        2-tuple:\n            - (N, 2) array: array of path waypoints, where N is the number of generated waypoints\n            - float: geodesic distance of the path\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.get_shortest_path"},{"title":"<code>initialize()</code>","text":"<p>Initializes state of this scene and sets up any references necessary post-loading. Subclasses should implement / extend the _initialize() method.</p>  Source code in <code>scenes/scene_base.py</code> <pre><code>def initialize(self):\n    \"\"\"\n    Initializes state of this scene and sets up any references necessary post-loading. Subclasses should\n    implement / extend the _initialize() method.\n    \"\"\"\n    assert not self._initialized, \"Scene can only be initialized once! (It is already initialized)\"\n    self._initialize()\n\n    # Grab relevant objects info and re-initialize object registry by handle since now handles are populated\n    self.update_objects_info()\n    self.object_registry.update(keys=\"root_handle\")\n    self.wake_scene_objects()\n\n    self._initialized = True\n\n    # Store initial state, which may be loaded from a scene file if specified\n    if self.scene_file is None:\n        init_state = self.dump_state(serialized=False)\n    else:\n        with open(self.scene_file, \"r\") as f:\n            scene_info = json.load(f)\n        init_state = scene_info[\"state\"]\n        og.sim.load_state(init_state, serialized=False)\n\n    self._initial_state = init_state\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.initialize"},{"title":"<code>load(simulator)</code>","text":"<p>Load the scene into simulator The elements to load may include: floor, building, objects, etc.</p> <p>Parameters:</p>    Name Type Description Default     <code>simulator</code>  <code>Simulator</code>  <p>the simulator to load the scene into</p>  required      Source code in <code>scenes/scene_base.py</code> <pre><code>def load(self, simulator):\n    \"\"\"\n    Load the scene into simulator\n    The elements to load may include: floor, building, objects, etc.\n\n    Args:\n        simulator (Simulator): the simulator to load the scene into\n    \"\"\"\n    # Make sure simulator is stopped\n    assert simulator.is_stopped(), \"Simulator should be stopped when loading this scene!\"\n\n    # Do not override this function. Override _load instead.\n    if self._loaded:\n        raise ValueError(\"This scene is already loaded.\")\n\n    # Create the registry for tracking all objects in the scene\n    self._registry = self._create_registry()\n\n    # Store world prim\n    self._world_prim = simulator.world_prim\n\n    # Clear the systems\n    self.clear_systems()\n\n    self._load(simulator)\n\n    # Initialize systems\n    self.initialize_systems(simulator)\n\n    # If we have any scene file specified, use it to load the objects within it\n    if self.scene_file is not None:\n        self._load_objects_from_scene_file(simulator)\n\n    # We're now loaded\n    self._loaded = True\n\n    # Always stop the sim if we started it internally\n    if not simulator.is_stopped():\n        simulator.stop()\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.load"},{"title":"<code>modify_init_info_for_restoring(init_info)</code>  <code>classmethod</code>","text":"<p>Helper function to modify a given init info for restoring a scene from corresponding scene info. Note that this function modifies IN-PLACE!</p> <p>Parameters:</p>    Name Type Description Default     <code>init_info</code>  <code>dict</code>  <p>Information for this scene from @self.get_init_info()</p>  required      Source code in <code>scenes/scene_base.py</code> <pre><code>@classmethod\ndef modify_init_info_for_restoring(cls, init_info):\n    \"\"\"\n    Helper function to modify a given init info for restoring a scene from corresponding scene info.\n    Note that this function modifies IN-PLACE!\n\n    Args:\n        init_info (dict): Information for this scene from @self.get_init_info()\n    \"\"\"\n    # Default is pass\n    pass\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.modify_init_info_for_restoring"},{"title":"<code>remove_object(obj, simulator)</code>","text":"<p>Method to remove an object from the simulator</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object to remove</p>  required    <code>simulator</code>  <code>Simulator</code>  <p>current simulation context</p>  required      Source code in <code>scenes/scene_base.py</code> <pre><code>def remove_object(self, obj, simulator):\n    \"\"\"\n    Method to remove an object from the simulator\n\n    Args:\n        obj (BaseObject): Object to remove\n        simulator (Simulator): current simulation context\n    \"\"\"\n    # Remove from the appropriate registry\n    self.object_registry.remove(obj)\n\n    # Remove from omni stage\n    obj.remove(simulator=simulator)\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.remove_object"},{"title":"<code>reset()</code>","text":"<p>Resets this scene</p>  Source code in <code>scenes/scene_base.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Resets this scene\n    \"\"\"\n    # Reset all systems\n    for system in self.systems:\n        system.reset()\n\n    # Reset all object and robot states\n    for obj in self.objects:\n        if isinstance(obj, StatefulObject):\n            obj.reset_states()\n\n    # Reset the pose and joint configuration of all scene objects.\n    if self._initial_state is not None:\n        self.load_state(self._initial_state)\n        og.app.update()\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.reset"},{"title":"<code>update_initial_state()</code>","text":"<p>Updates the initial state for this scene (which the scene will get reset to upon calling reset())</p>  Source code in <code>scenes/scene_base.py</code> <pre><code>def update_initial_state(self):\n    \"\"\"\n    Updates the initial state for this scene (which the scene will get reset to upon calling reset())\n    \"\"\"\n    self._initial_state = self.dump_state(serialized=False)\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.update_initial_state"},{"title":"<code>update_objects_info()</code>","text":"<p>Updates the scene-relevant information and saves it to the active USD. Useful for reloading a scene directly from a saved USD in this format.</p>  Source code in <code>scenes/scene_base.py</code> <pre><code>def update_objects_info(self):\n    \"\"\"\n    Updates the scene-relevant information and saves it to the active USD. Useful for reloading a scene directly\n    from a saved USD in this format.\n    \"\"\"\n    # Save relevant information\n\n    # Iterate over all objects and save their init info\n    init_info = {obj.name: obj.get_init_info() for obj in self.object_registry.objects}\n\n    # Compose as single dictionary and store internally\n    self._objects_info = OrderedDict(init_info=init_info)\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.update_objects_info"},{"title":"<code>wake_scene_objects()</code>","text":"<p>Force wakeup sleeping objects</p>  Source code in <code>scenes/scene_base.py</code> <pre><code>def wake_scene_objects(self):\n    \"\"\"\n    Force wakeup sleeping objects\n    \"\"\"\n    for obj in self.objects:\n        obj.wake()\n</code></pre>","location":"reference/scenes/scene_base.html#scenes.scene_base.Scene.wake_scene_objects"},{"title":"static_traversable_scene","text":"","location":"reference/scenes/static_traversable_scene.html"},{"title":"<code>StaticTraversableScene</code>","text":"<p>         Bases: <code>TraversableScene</code></p> <p>Static traversable scene class for OmniGibson, where scene is defined by a singular mesh (no intereactable objects)</p>  Source code in <code>scenes/static_traversable_scene.py</code> <pre><code>class StaticTraversableScene(TraversableScene):\n    \"\"\"\n    Static traversable scene class for OmniGibson, where scene is defined by a singular mesh (no intereactable objects)\n    \"\"\"\n\n    def __init__(\n        self,\n        scene_model,\n        scene_file=None,\n        trav_map_resolution=0.1,\n        trav_map_erosion=2,\n        trav_map_with_objects=True,\n        build_graph=True,\n        num_waypoints=10,\n        waypoint_resolution=0.2,\n        floor_plane_visible=False,\n        floor_plane_color=(1.0, 1.0, 1.0),\n    ):\n        \"\"\"\n        Args:\n            scene_model (str): Scene model name, e.g.: Adrian\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                None results in no additional objects being loaded into the scene\n            trav_map_resolution (float): traversability map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n            floor_plane_visible (bool): whether to render the additionally added floor plane\n            floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n                to the generated floor plane\n        \"\"\"\n        # Store and initialize additional variables\n        self._floor_heights = None\n        self._scene_mesh = None\n\n        # Run super init\n        super().__init__(\n            scene_model=scene_model,\n            scene_file=scene_file,\n            trav_map_resolution=trav_map_resolution,\n            trav_map_erosion=trav_map_erosion,\n            trav_map_with_objects=trav_map_with_objects,\n            build_graph=build_graph,\n            num_waypoints=num_waypoints,\n            waypoint_resolution=waypoint_resolution,\n            use_floor_plane=True,\n            floor_plane_visible=floor_plane_visible,\n            floor_plane_color=floor_plane_color,\n        )\n\n    def _load(self, simulator):\n        # Run super first\n        super()._load(simulator=simulator)\n\n        # Load the scene mesh (use downsampled one if available)\n        filename = os.path.join(get_scene_path(self.scene_model), \"mesh_z_up_downsampled.obj\")\n        if not os.path.isfile(filename):\n            filename = os.path.join(get_scene_path(self.scene_model), \"mesh_z_up.obj\")\n\n        scene_prim = add_asset_to_stage(\n            asset_path=filename,\n            prim_path=f\"/World/scene_{self.scene_model}\",\n        )\n\n        # Grab the actual mesh prim\n        self._scene_mesh = CollisionVisualGeomPrim(\n            prim_path=f\"/World/scene_{self.scene_model}/mesh_z_up/{self.scene_model}_mesh_texture\",\n            name=f\"{self.scene_model}_mesh\",\n        )\n\n        # Load floor metadata\n        floor_height_path = os.path.join(get_scene_path(self.scene_model), \"floors.txt\")\n        assert os.path.isfile(floor_height_path), f\"floor_heights.txt cannot be found in model: {self.scene_model}\"\n        with open(floor_height_path, \"r\") as f:\n            self.floor_heights = sorted(list(map(float, f.readlines())))\n            logging.debug(\"Floors {}\".format(self.floor_heights))\n\n        # Move the floor plane to the first floor by default\n        self.move_floor_plane(floor=0)\n\n        # Filter the collision between the scene mesh and the floor plane\n        self._scene_mesh.add_filtered_collision_pair(prim=self._floor_plane)\n\n        # Load the traversability map\n        self._trav_map.load_map(get_scene_path(self.scene_model))\n\n    def move_floor_plane(self, floor=0, additional_elevation=0.02, height=None):\n        \"\"\"\n        Resets the floor plane to a new floor\n\n        Args:\n            floor (int): Integer identifying the floor to move the floor plane to\n            additional_elevation (float): Additional elevation with respect to the height of the floor\n            height (None or float): If specified, alternative parameter to directly control the height of the ground\n                plane. Note that this will override @additional_elevation and @floor!\n        \"\"\"\n        height = height if height is not None else self.floor_heights[floor] + additional_elevation\n        self._floor_plane.set_position(np.array([0, 0, height]))\n\n    def get_floor_height(self, floor=0):\n        \"\"\"\n        Return the current floor height (in meter)\n\n        Returns:\n            int: current floor height\n        \"\"\"\n        return self.floor_heights[floor]\n\n    @property\n    def n_floors(self):\n        return len(self._floor_heights)\n</code></pre>","location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene"},{"title":"<code>__init__(scene_model, scene_file=None, trav_map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2, floor_plane_visible=False, floor_plane_color=(1.0, 1.0, 1.0))</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>scene_model</code>  <code>str</code>  <p>Scene model name, e.g.: Adrian</p>  required    <code>scene_file</code>  <code>None or str</code>  <p>If specified, full path of JSON file to load (with .json). None results in no additional objects being loaded into the scene</p>  <code>None</code>    <code>trav_map_resolution</code>  <code>float</code>  <p>traversability map resolution</p>  <code>0.1</code>    <code>trav_map_erosion</code>  <code>float</code>  <p>erosion radius of traversability areas, should be robot footprint radius</p>  <code>2</code>    <code>trav_map_with_objects</code>  <code>bool</code>  <p>whether to use objects or not when constructing graph</p>  <code>True</code>    <code>build_graph</code>  <code>bool</code>  <p>build connectivity graph</p>  <code>True</code>    <code>num_waypoints</code>  <code>int</code>  <p>number of way points returned</p>  <code>10</code>    <code>waypoint_resolution</code>  <code>float</code>  <p>resolution of adjacent way points</p>  <code>0.2</code>    <code>floor_plane_visible</code>  <code>bool</code>  <p>whether to render the additionally added floor plane</p>  <code>False</code>    <code>floor_plane_color</code>  <code>3-array</code>  <p>if @floor_plane_visible is True, this determines the (R,G,B) color assigned to the generated floor plane</p>  <code>(1.0, 1.0, 1.0)</code>      Source code in <code>scenes/static_traversable_scene.py</code> <pre><code>def __init__(\n    self,\n    scene_model,\n    scene_file=None,\n    trav_map_resolution=0.1,\n    trav_map_erosion=2,\n    trav_map_with_objects=True,\n    build_graph=True,\n    num_waypoints=10,\n    waypoint_resolution=0.2,\n    floor_plane_visible=False,\n    floor_plane_color=(1.0, 1.0, 1.0),\n):\n    \"\"\"\n    Args:\n        scene_model (str): Scene model name, e.g.: Adrian\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            None results in no additional objects being loaded into the scene\n        trav_map_resolution (float): traversability map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n        floor_plane_visible (bool): whether to render the additionally added floor plane\n        floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n            to the generated floor plane\n    \"\"\"\n    # Store and initialize additional variables\n    self._floor_heights = None\n    self._scene_mesh = None\n\n    # Run super init\n    super().__init__(\n        scene_model=scene_model,\n        scene_file=scene_file,\n        trav_map_resolution=trav_map_resolution,\n        trav_map_erosion=trav_map_erosion,\n        trav_map_with_objects=trav_map_with_objects,\n        build_graph=build_graph,\n        num_waypoints=num_waypoints,\n        waypoint_resolution=waypoint_resolution,\n        use_floor_plane=True,\n        floor_plane_visible=floor_plane_visible,\n        floor_plane_color=floor_plane_color,\n    )\n</code></pre>","location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene.__init__"},{"title":"<code>get_floor_height(floor=0)</code>","text":"<p>Return the current floor height (in meter)</p> <p>Returns:</p>    Name Type Description     <code>int</code>   <p>current floor height</p>     Source code in <code>scenes/static_traversable_scene.py</code> <pre><code>def get_floor_height(self, floor=0):\n    \"\"\"\n    Return the current floor height (in meter)\n\n    Returns:\n        int: current floor height\n    \"\"\"\n    return self.floor_heights[floor]\n</code></pre>","location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene.get_floor_height"},{"title":"<code>move_floor_plane(floor=0, additional_elevation=0.02, height=None)</code>","text":"<p>Resets the floor plane to a new floor</p> <p>Parameters:</p>    Name Type Description Default     <code>floor</code>  <code>int</code>  <p>Integer identifying the floor to move the floor plane to</p>  <code>0</code>    <code>additional_elevation</code>  <code>float</code>  <p>Additional elevation with respect to the height of the floor</p>  <code>0.02</code>    <code>height</code>  <code>None or float</code>  <p>If specified, alternative parameter to directly control the height of the ground plane. Note that this will override @additional_elevation and @floor!</p>  <code>None</code>      Source code in <code>scenes/static_traversable_scene.py</code> <pre><code>def move_floor_plane(self, floor=0, additional_elevation=0.02, height=None):\n    \"\"\"\n    Resets the floor plane to a new floor\n\n    Args:\n        floor (int): Integer identifying the floor to move the floor plane to\n        additional_elevation (float): Additional elevation with respect to the height of the floor\n        height (None or float): If specified, alternative parameter to directly control the height of the ground\n            plane. Note that this will override @additional_elevation and @floor!\n    \"\"\"\n    height = height if height is not None else self.floor_heights[floor] + additional_elevation\n    self._floor_plane.set_position(np.array([0, 0, height]))\n</code></pre>","location":"reference/scenes/static_traversable_scene.html#scenes.static_traversable_scene.StaticTraversableScene.move_floor_plane"},{"title":"traversable_scene","text":"","location":"reference/scenes/traversable_scene.html"},{"title":"<code>TraversableScene</code>","text":"<p>         Bases: <code>Scene</code></p> <p>Traversable scene class. Contains the functionalities for navigation such as shortest path computation</p>  Source code in <code>scenes/traversable_scene.py</code> <pre><code>class TraversableScene(Scene):\n    \"\"\"\n    Traversable scene class.\n    Contains the functionalities for navigation such as shortest path computation\n    \"\"\"\n\n    def __init__(\n        self,\n        scene_model,\n        scene_file=None,\n        trav_map_resolution=0.1,\n        trav_map_erosion=2,\n        trav_map_with_objects=True,\n        build_graph=True,\n        num_waypoints=10,\n        waypoint_resolution=0.2,\n        use_floor_plane=True,\n        floor_plane_visible=True,\n        floor_plane_color=(1.0, 1.0, 1.0),\n    ):\n        \"\"\"\n        Args:\n            scene_model (str): Scene model name, e.g.: Adrian or Rs_int\n            scene_file (None or str): If specified, full path of JSON file to load (with .json).\n                None results in no additional objects being loaded into the scene\n            trav_map_resolution (float): traversability map resolution\n            trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n            trav_map_with_objects (bool): whether to use objects or not when constructing graph\n            build_graph (bool): build connectivity graph\n            num_waypoints (int): number of way points returned\n            waypoint_resolution (float): resolution of adjacent way points\n            use_floor_plane (bool): whether to load a flat floor plane into the simulator\n            floor_plane_visible (bool): whether to render the additionally added floor plane\n            floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n                to the generated floor plane\n        \"\"\"\n        logging.info(\"TraversableScene model: {}\".format(scene_model))\n        self.scene_model = scene_model\n\n        # Create traversable map\n        self._trav_map = TraversableMap(\n            map_resolution=trav_map_resolution,\n            trav_map_erosion=trav_map_erosion,\n            trav_map_with_objects=trav_map_with_objects,\n            build_graph=build_graph,\n            num_waypoints=num_waypoints,\n            waypoint_resolution=waypoint_resolution,\n        )\n        # Run super init\n        super().__init__(\n            scene_file=scene_file,\n            use_floor_plane=use_floor_plane,\n            floor_plane_visible=floor_plane_visible,\n            floor_plane_color=floor_plane_color,\n        )\n\n    @property\n    def trav_map(self):\n        \"\"\"\n        Returns:\n            TraversableMap: Map for computing connectivity between nodes for this scene\n        \"\"\"\n        return self._trav_map\n\n    @property\n    def has_connectivity_graph(self):\n        # Connectivity graph is determined by travserable map\n        return self._trav_map.build_graph\n\n    def get_random_point(self, floor=None):\n        return self._trav_map.get_random_point(floor=floor)\n\n    def get_shortest_path(self, floor, source_world, target_world, entire_path=False):\n        assert self._trav_map.build_graph, \"cannot get shortest path without building the graph\"\n\n        return self._trav_map.get_shortest_path(\n            floor=floor,\n            source_world=source_world,\n            target_world=target_world,\n            entire_path=entire_path,\n        )\n</code></pre>","location":"reference/scenes/traversable_scene.html#scenes.traversable_scene.TraversableScene"},{"title":"<code>trav_map</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>TraversableMap</code>   <p>Map for computing connectivity between nodes for this scene</p>","location":"reference/scenes/traversable_scene.html#scenes.traversable_scene.TraversableScene.trav_map"},{"title":"<code>__init__(scene_model, scene_file=None, trav_map_resolution=0.1, trav_map_erosion=2, trav_map_with_objects=True, build_graph=True, num_waypoints=10, waypoint_resolution=0.2, use_floor_plane=True, floor_plane_visible=True, floor_plane_color=(1.0, 1.0, 1.0))</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>scene_model</code>  <code>str</code>  <p>Scene model name, e.g.: Adrian or Rs_int</p>  required    <code>scene_file</code>  <code>None or str</code>  <p>If specified, full path of JSON file to load (with .json). None results in no additional objects being loaded into the scene</p>  <code>None</code>    <code>trav_map_resolution</code>  <code>float</code>  <p>traversability map resolution</p>  <code>0.1</code>    <code>trav_map_erosion</code>  <code>float</code>  <p>erosion radius of traversability areas, should be robot footprint radius</p>  <code>2</code>    <code>trav_map_with_objects</code>  <code>bool</code>  <p>whether to use objects or not when constructing graph</p>  <code>True</code>    <code>build_graph</code>  <code>bool</code>  <p>build connectivity graph</p>  <code>True</code>    <code>num_waypoints</code>  <code>int</code>  <p>number of way points returned</p>  <code>10</code>    <code>waypoint_resolution</code>  <code>float</code>  <p>resolution of adjacent way points</p>  <code>0.2</code>    <code>use_floor_plane</code>  <code>bool</code>  <p>whether to load a flat floor plane into the simulator</p>  <code>True</code>    <code>floor_plane_visible</code>  <code>bool</code>  <p>whether to render the additionally added floor plane</p>  <code>True</code>    <code>floor_plane_color</code>  <code>3-array</code>  <p>if @floor_plane_visible is True, this determines the (R,G,B) color assigned to the generated floor plane</p>  <code>(1.0, 1.0, 1.0)</code>      Source code in <code>scenes/traversable_scene.py</code> <pre><code>def __init__(\n    self,\n    scene_model,\n    scene_file=None,\n    trav_map_resolution=0.1,\n    trav_map_erosion=2,\n    trav_map_with_objects=True,\n    build_graph=True,\n    num_waypoints=10,\n    waypoint_resolution=0.2,\n    use_floor_plane=True,\n    floor_plane_visible=True,\n    floor_plane_color=(1.0, 1.0, 1.0),\n):\n    \"\"\"\n    Args:\n        scene_model (str): Scene model name, e.g.: Adrian or Rs_int\n        scene_file (None or str): If specified, full path of JSON file to load (with .json).\n            None results in no additional objects being loaded into the scene\n        trav_map_resolution (float): traversability map resolution\n        trav_map_erosion (float): erosion radius of traversability areas, should be robot footprint radius\n        trav_map_with_objects (bool): whether to use objects or not when constructing graph\n        build_graph (bool): build connectivity graph\n        num_waypoints (int): number of way points returned\n        waypoint_resolution (float): resolution of adjacent way points\n        use_floor_plane (bool): whether to load a flat floor plane into the simulator\n        floor_plane_visible (bool): whether to render the additionally added floor plane\n        floor_plane_color (3-array): if @floor_plane_visible is True, this determines the (R,G,B) color assigned\n            to the generated floor plane\n    \"\"\"\n    logging.info(\"TraversableScene model: {}\".format(scene_model))\n    self.scene_model = scene_model\n\n    # Create traversable map\n    self._trav_map = TraversableMap(\n        map_resolution=trav_map_resolution,\n        trav_map_erosion=trav_map_erosion,\n        trav_map_with_objects=trav_map_with_objects,\n        build_graph=build_graph,\n        num_waypoints=num_waypoints,\n        waypoint_resolution=waypoint_resolution,\n    )\n    # Run super init\n    super().__init__(\n        scene_file=scene_file,\n        use_floor_plane=use_floor_plane,\n        floor_plane_visible=floor_plane_visible,\n        floor_plane_color=floor_plane_color,\n    )\n</code></pre>","location":"reference/scenes/traversable_scene.html#scenes.traversable_scene.TraversableScene.__init__"},{"title":"setup","text":"<p>Helper script to setup this OmniGibson repository. Configures environment and downloads assets</p>","location":"reference/scripts/setup.html"},{"title":"sensors","text":"","location":"reference/sensors/index.html"},{"title":"<code>create_sensor(sensor_type, prim_path, name, modalities='all', sensor_kwargs=None, noise_type=None, noise_kwargs=None)</code>","text":"<p>Create a sensor of type @sensor_type with optional keyword args @sensor_kwargs that should be passed to the constructor. Also, additionally send noise of type @noise_type with corresponding keyword args @noise_kwargs that should be passed to the noise constructor.</p> <p>Parameters:</p>    Name Type Description Default     <code>sensor_type</code>  <code>str</code>  <p>Type of sensor to create. Should be either one of SENSOR_PRIM_TO_SENSOR.keys() or one of REGISTERED_SENSORS (i.e.: the string name of the desired class to create)</p>  required    <code>prim_path</code>  <code>str</code>  <p>prim path of the Sensor to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the sensor. Names need to be unique per scene.</p>  required    <code>modalities</code>  <code>str or list of str</code>  <p>Modality(s) supported by this sensor. Valid options are part of sensor.all_modalities. Default is \"all\", which corresponds to all modalities being used</p>  <code>'all'</code>    <code>sensor_kwargs</code>  <code>dict</code>  <p>Any keyword kwargs to pass to the constructor</p>  <code>None</code>    <code>noise_type</code>  <code>str</code>  <p>Type of sensor to create. Should be one of REGISTERED_SENSOR_NOISES (i.e.: the string name of the desired class to create)</p>  <code>None</code>    <code>noise_kwargs</code>  <code>dict</code>  <p>Any keyword kwargs to pass to the constructor</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>BaseSensor</code>   <p>Created sensor with specified params</p>     Source code in <code>sensors/__init__.py</code> <pre><code>def create_sensor(\n        sensor_type,\n        prim_path,\n        name,\n        modalities=\"all\",\n        sensor_kwargs=None,\n        noise_type=None,\n        noise_kwargs=None\n):\n    \"\"\"\n    Create a sensor of type @sensor_type with optional keyword args @sensor_kwargs that should be passed to the\n    constructor. Also, additionally send noise of type @noise_type with corresponding keyword args @noise_kwargs\n    that should be passed to the noise constructor.\n\n    Args:\n        sensor_type (str): Type of sensor to create. Should be either one of SENSOR_PRIM_TO_SENSOR.keys() or\n            one of REGISTERED_SENSORS (i.e.: the string name of the desired class to create)\n        prim_path (str): prim path of the Sensor to encapsulate or create.\n        name (str): Name for the sensor. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Valid options are part of\n            sensor.all_modalities. Default is \"all\", which corresponds to all modalities being used\n        sensor_kwargs (dict): Any keyword kwargs to pass to the constructor\n        noise_type (str): Type of sensor to create. Should be one of REGISTERED_SENSOR_NOISES\n            (i.e.: the string name of the desired class to create)\n        noise_kwargs (dict): Any keyword kwargs to pass to the constructor\n\n    Returns:\n        BaseSensor: Created sensor with specified params\n    \"\"\"\n    # Run basic sanity check\n    assert isinstance(sensor_type, str), \"Inputted sensor_type must be a string!\"\n\n    # Grab the requested sensor class\n    if sensor_type in SENSOR_PRIMS_TO_SENSOR_CLS:\n        sensor_cls = SENSOR_PRIMS_TO_SENSOR_CLS[sensor_type]\n    elif sensor_type in REGISTERED_SENSORS:\n        sensor_cls = REGISTERED_SENSORS[sensor_type]\n    else:\n        # This is an error, we didn't find the requested sensor ):\n        raise ValueError(f\"No sensor found with corresponding sensor_type: {sensor_type}\")\n\n    # Create the noise, and sanity check to make sure it's a valid type\n    noise = None\n    if noise_type is not None:\n        assert_valid_key(key=noise_type, valid_keys=REGISTERED_SENSOR_NOISES, name=\"sensor noise type\")\n        noise_kwargs = dict() if noise_kwargs is None else noise_kwargs\n        noise = REGISTERED_SENSOR_NOISES[noise_type](**noise_kwargs)\n\n    # Create the sensor\n    sensor_kwargs = dict() if sensor_kwargs is None else sensor_kwargs\n    sensor = sensor_cls(prim_path=prim_path, name=name, modalities=modalities, noise=noise, **sensor_kwargs)\n\n    return sensor\n</code></pre>","location":"reference/sensors/index.html#sensors.create_sensor"},{"title":"dropout_sensor_noise","text":"","location":"reference/sensors/dropout_sensor_noise.html"},{"title":"<code>DropoutSensorNoise</code>","text":"<p>         Bases: <code>BaseSensorNoise</code></p> <p>Naive dropout sensor noise model</p> <p>Parameters:</p>    Name Type Description Default     <code>dropout_prob</code>  <code>float</code>  <p>Value in [0.0, 1.0] representing fraction of a single observation to be replaced with @dropout_value</p>  <code>0.05</code>    <code>dropout_value</code>  <code>float</code>  <p>Value in [0.0, 1.0] to replace observations selected to be dropped out</p>  <code>1.0</code>    <code>enabled</code>  <code>bool</code>  <p>Whether this sensor should be enabled by default</p>  <code>True</code>      Source code in <code>sensors/dropout_sensor_noise.py</code> <pre><code>class DropoutSensorNoise(BaseSensorNoise):\n    \"\"\"\n    Naive dropout sensor noise model\n\n    Args:\n        dropout_prob (float): Value in [0.0, 1.0] representing fraction of a single observation to be replaced\n            with @dropout_value\n        dropout_value (float): Value in [0.0, 1.0] to replace observations selected to be dropped out\n        enabled (bool): Whether this sensor should be enabled by default\n    \"\"\"\n\n    def __init__(\n            self,\n            dropout_prob=0.05,\n            dropout_value=1.0,\n            enabled=True,\n    ):\n        # Store args, and make sure values are in acceptable range\n        for name, val in zip((\"dropout_prob\", \"dropout_value\"), (dropout_prob, dropout_value)):\n            assert 0.0 &lt;= val &lt;= 1.0, f\"{name} should be in range [0.0, 1.0], got: {val}\"\n        self._dropout_prob = dropout_prob\n        self._dropout_value = dropout_value\n\n        # Run super method\n        super().__init__(enabled=enabled)\n\n    def _corrupt(self, obs):\n        # If our noise rate is 0, we just return the obs\n        if self._dropout_prob == 0.0:\n            return obs\n\n        # Corrupt with randomized dropout\n        valid_mask = np.random.choice(2, obs.shape, p=[self._dropout_prob, 1.0 - self._dropout_prob])\n        obs[valid_mask == 0] = self._dropout_value\n        return obs\n\n    @property\n    def dropout_prob(self):\n        \"\"\"\n        Returns:\n            float: Value in [0.0, 1.0] representing fraction of a single observation to be replaced\n                with self.dropout_value\n        \"\"\"\n        return self._dropout_prob\n\n    @dropout_prob.setter\n    def dropout_prob(self, p):\n        \"\"\"\n        Set the dropout probability for this noise model.\n\n        Args:\n            p (float): Value in [0.0, 1.0] representing fraction of a single observation to be replaced\n                with self.dropout_value\n        \"\"\"\n        assert 0.0 &lt;= p &lt;= 1.0, f\"dropout_prob should be in range [0.0, 1.0], got: {p}\"\n        self._dropout_prob = p\n\n    @property\n    def dropout_value(self):\n        \"\"\"\n        Returns:\n            float: Value in [0.0, 1.0] to replace observations selected to be dropped out\n        \"\"\"\n        return self._dropout_value\n\n    @dropout_value.setter\n    def dropout_value(self, val):\n        \"\"\"\n        Set the dropout value for this noise model.\n\n        Args:\n            val (float): Value in [0.0, 1.0] to replace observations selected to be dropped out\n        \"\"\"\n        assert 0.0 &lt;= val &lt;= 1.0, f\"dropout_value should be in range [0.0, 1.0], got: {val}\"\n        self._dropout_value = val\n</code></pre>","location":"reference/sensors/dropout_sensor_noise.html#sensors.dropout_sensor_noise.DropoutSensorNoise"},{"title":"<code>dropout_prob</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Value in [0.0, 1.0] representing fraction of a single observation to be replaced with self.dropout_value</p>","location":"reference/sensors/dropout_sensor_noise.html#sensors.dropout_sensor_noise.DropoutSensorNoise.dropout_prob"},{"title":"<code>dropout_value</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Value in [0.0, 1.0] to replace observations selected to be dropped out</p>","location":"reference/sensors/dropout_sensor_noise.html#sensors.dropout_sensor_noise.DropoutSensorNoise.dropout_value"},{"title":"scan_sensor","text":"","location":"reference/sensors/scan_sensor.html"},{"title":"<code>ScanSensor</code>","text":"<p>         Bases: <code>BaseSensor</code></p> <p>General 2D LiDAR range sensor and occupancy grid sensor.</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>modalities</code>  <code>str or list of str</code>  <p>Modality(s) supported by this sensor. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of cls.all_modalities. For this scan sensor, this includes any of:     {scan, occupancy_grid} Note that in order for \"occupancy_grid\" to be used, \"scan\" must also be included.</p>  <code>'all'</code>    <code>enabled</code>  <code>bool</code>  <p>Whether this sensor should be enabled by default</p>  <code>True</code>    <code>noise</code>  <code>None or BaseSensorNoise</code>  <p>If specified, sensor noise model to apply to this sensor.</p>  <code>None</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this sensor's prim at runtime.</p>  <code>None</code>    <code>min_range</code>  <code>float</code>  <p>Minimum range to sense in meters</p>  <code>0.05</code>    <code>max_range</code>  <code>float</code>  <p>Maximum range to sense in meters</p>  <code>10.0</code>    <code>horizontal_fov</code>  <code>float</code>  <p>Field of view of sensor, in degrees</p>  <code>360.0</code>    <code>vertical_fov</code>  <code>float</code>  <p>Field of view of sensor, in degrees</p>  <code>1.0</code>    <code>yaw_offset</code>  <code>float</code>  <p>Degrees for offsetting this sensors horizontal FOV. Useful in cases where this sensor's forward direction is different than expected</p>  <code>0.0</code>    <code>horizontal_resolution</code>  <code>float</code>  <p>Degrees in between each horizontal scan hit</p>  <code>1.0</code>    <code>vertical_resolution</code>  <code>float</code>  <p>Degrees in between each vertical scan hit</p>  <code>1.0</code>    <code>rotation_rate</code>  <code>float</code>  <p>How fast the range sensor is rotating, in rotations per sec. Set to 0 for all scans be to hit at once</p>  <code>0.0</code>    <code>draw_points</code>  <code>bool</code>  <p>Whether to draw the points hit by this sensor</p>  <code>False</code>    <code>draw_lines</code>  <code>bool</code>  <p>Whether to draw the lines representing the scans from this sensor</p>  <code>False</code>    <code>occupancy_grid_resolution</code>  <code>int</code>  <p>How many discretized nodes in the occupancy grid. This will specify the height == width of the map</p>  <code>128</code>    <code>occupancy_grid_range</code>  <code>float</code>  <p>Range of the occupancy grid, in meters</p>  <code>5.0</code>    <code>occupancy_grid_inner_radius</code>  <code>float</code>  <p>Inner range of the occupancy grid that will assumed to be empty, in meters</p>  <code>0.5</code>    <code>occupancy_grid_local_link</code>  <code>None or XFormPrim</code>  <p>XForm prim that represents the \"origin\" of any generated occupancy grid, e.g.: if this scan sensor is attached to a robot, then this should possibly be the base link for that robot. If None is specified, then this will default to this own sensor's frame as the origin.</p>  <code>None</code>      Source code in <code>sensors/scan_sensor.py</code> <pre><code>class ScanSensor(BaseSensor):\n    \"\"\"\n    General 2D LiDAR range sensor and occupancy grid sensor.\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Default is \"all\", which corresponds\n            to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.\n            For this scan sensor, this includes any of:\n                {scan, occupancy_grid}\n            Note that in order for \"occupancy_grid\" to be used, \"scan\" must also be included.\n        enabled (bool): Whether this sensor should be enabled by default\n        noise (None or BaseSensorNoise): If specified, sensor noise model to apply to this sensor.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this sensor's prim at runtime.\n        min_range (float): Minimum range to sense in meters\n        max_range (float): Maximum range to sense in meters\n        horizontal_fov (float): Field of view of sensor, in degrees\n        vertical_fov (float): Field of view of sensor, in degrees\n        yaw_offset (float): Degrees for offsetting this sensors horizontal FOV.\n            Useful in cases where this sensor's forward direction is different than expected\n        horizontal_resolution (float): Degrees in between each horizontal scan hit\n        vertical_resolution (float): Degrees in between each vertical scan hit\n        rotation_rate (float): How fast the range sensor is rotating, in rotations per sec. Set to 0 for all scans\n            be to hit at once\n        draw_points (bool): Whether to draw the points hit by this sensor\n        draw_lines (bool): Whether to draw the lines representing the scans from this sensor\n        occupancy_grid_resolution (int): How many discretized nodes in the occupancy grid. This will specify the\n            height == width of the map\n        occupancy_grid_range (float): Range of the occupancy grid, in meters\n        occupancy_grid_inner_radius (float): Inner range of the occupancy grid that will assumed to be empty, in meters\n        occupancy_grid_local_link (None or XFormPrim): XForm prim that represents the \"origin\" of any generated\n            occupancy grid, e.g.: if this scan sensor is attached to a robot, then this should possibly be the base link\n            for that robot. If None is specified, then this will default to this own sensor's frame as the origin.\n    \"\"\"\n    def __init__(\n        self,\n        prim_path,\n        name,\n        modalities=\"all\",\n        enabled=True,\n        noise=None,\n        load_config=None,\n\n        # Basic LIDAR kwargs\n        min_range=0.05,\n        max_range=10.0,\n        horizontal_fov=360.0,\n        vertical_fov=1.0,\n        yaw_offset=0.0,\n        horizontal_resolution=1.0,\n        vertical_resolution=1.0,\n        rotation_rate=0.0,\n        draw_points=False,\n        draw_lines=False,\n\n        # Occupancy Grid kwargs\n        occupancy_grid_resolution=128,\n        occupancy_grid_range=5.0,\n        occupancy_grid_inner_radius=0.5,\n        occupancy_grid_local_link=None,\n    ):\n        # Store settings\n        self.occupancy_grid_resolution = occupancy_grid_resolution\n        self.occupancy_grid_range = occupancy_grid_range\n        self.occupancy_grid_inner_radius = int(occupancy_grid_inner_radius * occupancy_grid_resolution\n                                                / occupancy_grid_range)\n        self.occupancy_grid_local_link = self if occupancy_grid_local_link is None else occupancy_grid_local_link\n\n        # Create variables that will be filled in at runtime\n        self._rs = None                 # Range sensor interface, analagous to others, e.g.: dynamic control interface\n\n        # Create load config from inputs\n        load_config = dict() if load_config is None else load_config\n        load_config[\"min_range\"] = min_range\n        load_config[\"max_range\"] = max_range\n        load_config[\"horizontal_fov\"] = horizontal_fov\n        load_config[\"vertical_fov\"] = vertical_fov\n        load_config[\"yaw_offset\"] = yaw_offset\n        load_config[\"horizontal_resolution\"] = horizontal_resolution\n        load_config[\"vertical_resolution\"] = vertical_resolution\n        load_config[\"rotation_rate\"] = rotation_rate\n        load_config[\"draw_points\"] = draw_points\n        load_config[\"draw_lines\"] = draw_lines\n\n        # Sanity check modalities -- if we're using occupancy_grid without scan modality, raise an error\n        if isinstance(modalities, Iterable) and not isinstance(modalities, str) and \"occupancy_grid\" in modalities:\n            assert \"scan\" in modalities, f\"'scan' modality must be included in order to get occupancy_grid modality!\"\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            modalities=modalities,\n            enabled=enabled,\n            noise=noise,\n            load_config=load_config,\n        )\n\n    def _load(self, simulator=None):\n        # Define a LIDAR prim at the current stage\n        result, lidar = execute(\"RangeSensorCreateLidar\", path=self._prim_path)\n\n        return lidar.GetPrim()\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # Set all the lidar kwargs\n        self.min_range = self._load_config[\"min_range\"]\n        self.max_range = self._load_config[\"max_range\"]\n        self.horizontal_fov = self._load_config[\"horizontal_fov\"]\n        self.vertical_fov = self._load_config[\"vertical_fov\"]\n        self.yaw_offset = self._load_config[\"yaw_offset\"]\n        self.horizontal_resolution = self._load_config[\"horizontal_resolution\"]\n        self.vertical_resolution = self._load_config[\"vertical_resolution\"]\n        self.rotation_rate = self._load_config[\"rotation_rate\"]\n        self.draw_points = self._load_config[\"draw_points\"]\n        self.draw_lines = self._load_config[\"draw_lines\"]\n\n    def _initialize(self):\n        # run super first\n        super()._initialize()\n\n        # Initialize lidar sensor interface\n        self._rs = _range_sensor.acquire_lidar_sensor_interface()\n\n    @property\n    def _obs_space_mapping(self):\n        # Set the remaining modalities' values\n        # (obs modality, shape, low, high)\n        obs_space_mapping = OrderedDict(\n            scan=((self.n_horizontal_rays, self.n_vertical_rays), 0.0, 1.0, np.float32),\n            occupancy_grid=((self.occupancy_grid_resolution, self.occupancy_grid_resolution, 1), 0.0, 1.0, np.float32),\n        )\n\n        return obs_space_mapping\n\n    def get_local_occupancy_grid(self, scan):\n        \"\"\"\n        Get local occupancy grid based on current 1D scan\n\n        Args:\n            n-array: 1D LiDAR scan\n\n        Returns:\n            2D-array: (occupancy_grid_resolution, occupancy_grid_resolution)-sized numpy array of the local occupancy grid\n        \"\"\"\n        # Run sanity checks first\n        assert \"occupancy_grid\" in self._modalities, \"Occupancy grid is not enabled for this range sensor!\"\n        assert self.n_vertical_rays == 1, \"Occupancy grid is only valid for a 1D range sensor (n_vertical_rays = 1)!\"\n\n        # Grab vector of corresponding angles for each scan line\n        angles = np.arange(\n            -np.radians(self.horizontal_fov / 2),\n            np.radians(self.horizontal_fov / 2),\n            np.radians(self.horizontal_resolution),\n        )\n\n        # Convert into 3D unit vectors for each angle\n        unit_vector_laser = np.array([[np.cos(ang), np.sin(ang), 0.0] for ang in angles])\n\n        # Scale unit vectors by corresponding laser scan distnaces\n        assert ((scan &gt;= 0.0) &amp; (scan &lt;= 1.0)).all(), \"scan out of valid range [0, 1]\"\n        scan_laser = unit_vector_laser * (scan * (self.max_range - self.min_range) + self.min_range)\n\n        # Convert scans from laser frame to world frame\n        pos, ori = self.get_position_orientation()\n        scan_world = quat2mat(ori).dot(scan_laser.T).T + pos\n\n        # Convert scans from world frame to local base frame\n        base_pos, base_ori = self.occupancy_grid_local_link.get_position_orientation()\n        scan_local = quat2mat(base_ori).T.dot((scan_world - base_pos).T).T\n        scan_local = scan_local[:, :2]\n        scan_local = np.concatenate([np.array([[0, 0]]), scan_local, np.array([[0, 0]])], axis=0)\n\n        # flip y axis\n        scan_local[:, 1] *= -1\n\n        # Initialize occupancy grid -- default is unknown values\n        occupancy_grid = np.zeros((self.occupancy_grid_resolution, self.occupancy_grid_resolution)).astype(np.uint8)\n        occupancy_grid.fill(int(OccupancyGridState.UNKNOWN * 2.0))\n\n        # Convert local scans into the corresponding OG square it should belong to (note now all values are &gt; 0, since\n        # OG ranges from [0, resolution] x [0, resolution])\n        scan_local_in_map = scan_local / self.occupancy_grid_range * self.occupancy_grid_resolution + \\\n                            (self.occupancy_grid_resolution / 2)\n        scan_local_in_map = scan_local_in_map.reshape((1, -1, 1, 2)).astype(np.int32)\n\n        # For each scan hit,\n        for i in range(scan_local_in_map.shape[1]):\n            cv2.circle(\n                img=occupancy_grid,\n                center=(scan_local_in_map[0, i, 0, 0], scan_local_in_map[0, i, 0, 1]),\n                radius=2,\n                color=int(OccupancyGridState.OBSTACLES * 2.0),\n                thickness=-1,\n            )\n        cv2.fillPoly(\n            img=occupancy_grid, pts=scan_local_in_map, color=int(OccupancyGridState.FREESPACE * 2.0), lineType=1\n        )\n        cv2.circle(\n            img=occupancy_grid,\n            center=(self.occupancy_grid_resolution // 2, self.occupancy_grid_resolution // 2),\n            radius=self.occupancy_grid_inner_radius,\n            color=int(OccupancyGridState.FREESPACE * 2.0),\n            thickness=-1,\n        )\n\n        return occupancy_grid[:, :, None].astype(np.float32) / 2.0\n\n    def _get_obs(self):\n        # Run super first to grab any upstream obs\n        obs = super()._get_obs()\n\n        # Add scan info (normalized to [0.0, 1.0])\n        if \"scan\" in self._modalities:\n            raw_scan = self._rs.get_linear_depth_data(self._prim_path)\n            # Sometimes get_linear_depth_data will return values that are slightly out of range, needs clipping\n            raw_scan = np.clip(raw_scan, self.min_range, self.max_range)\n            obs[\"scan\"] = (raw_scan - self.min_range) / (self.max_range - self.min_range)\n\n            # Optionally add occupancy grid info\n            if \"occupancy_grid\" in self._modalities:\n                obs[\"occupancy_grid\"] = self.get_local_occupancy_grid(scan=obs[\"scan\"])\n\n        return obs\n\n    @property\n    def n_horizontal_rays(self):\n        \"\"\"\n        Returns:\n            int: Number of horizontal rays for this range sensor\n        \"\"\"\n        return int(self.horizontal_fov // self.horizontal_resolution)\n\n    @property\n    def n_vertical_rays(self):\n        \"\"\"\n        Returns:\n            int: Number of vertical rays for this range sensor\n        \"\"\"\n        return int(self.vertical_fov // self.vertical_resolution)\n\n    @property\n    def min_range(self):\n        \"\"\"\n        Gets this range sensor's min_range (minimum distance in meters which will register a hit)\n\n        Returns:\n            float: minimum range for this range sensor, in meters\n        \"\"\"\n        return self.get_attribute(\"minRange\")\n\n    @min_range.setter\n    def min_range(self, val):\n        \"\"\"\n        Sets this range sensor's min_range (minimum distance in meters which will register a hit)\n\n        Args:\n            val (float): minimum range for this range sensor, in meters\n        \"\"\"\n        self.set_attribute(\"minRange\", val)\n\n    @property\n    def max_range(self):\n        \"\"\"\n        Gets this range sensor's max_range (maximum distance in meters which will register a hit)\n\n        Returns:\n            float: maximum range for this range sensor, in meters\n        \"\"\"\n        return self.get_attribute(\"maxRange\")\n\n    @max_range.setter\n    def max_range(self, val):\n        \"\"\"\n        Sets this range sensor's max_range (maximum distance in meters which will register a hit)\n\n        Args:\n            val (float): maximum range for this range sensor, in meters\n        \"\"\"\n        self.set_attribute(\"maxRange\", val)\n\n    @property\n    def draw_lines(self):\n        \"\"\"\n        Gets whether range lines are drawn for this sensor\n\n        Returns:\n            bool: Whether range lines are drawn for this sensor\n        \"\"\"\n        return self.get_attribute(\"drawLines\")\n\n    @draw_lines.setter\n    def draw_lines(self, draw):\n        \"\"\"\n        Sets whether range lines are drawn for this sensor\n\n        Args:\n            draw (float): Whether range lines are drawn for this sensor\n        \"\"\"\n        self.set_attribute(\"drawLines\", draw)\n\n    @property\n    def draw_points(self):\n        \"\"\"\n        Gets whether range points are drawn for this sensor\n\n        Returns:\n            bool: Whether range points are drawn for this sensor\n        \"\"\"\n        return self.get_attribute(\"drawPoints\")\n\n    @draw_points.setter\n    def draw_points(self, draw):\n        \"\"\"\n        Sets whether range points are drawn for this sensor\n\n        Args:\n            draw (float): Whether range points are drawn for this sensor\n        \"\"\"\n        self.set_attribute(\"drawPoints\", draw)\n\n    @property\n    def horizontal_fov(self):\n        \"\"\"\n        Gets this range sensor's horizontal_fov\n\n        Returns:\n            float: horizontal field of view for this range sensor\n        \"\"\"\n        return self.get_attribute(\"horizontalFov\")\n\n    @horizontal_fov.setter\n    def horizontal_fov(self, fov):\n        \"\"\"\n        Sets this range sensor's horizontal_fov\n\n        Args:\n            fov (float): horizontal field of view to set\n        \"\"\"\n        self.set_attribute(\"horizontalFov\", fov)\n\n    @property\n    def horizontal_resolution(self):\n        \"\"\"\n        Gets this range sensor's horizontal_resolution (degrees in between each horizontal hit)\n\n        Returns:\n            float: horizontal resolution for this range sensor, in degrees\n        \"\"\"\n        return self.get_attribute(\"horizontalResolution\")\n\n    @horizontal_resolution.setter\n    def horizontal_resolution(self, resolution):\n        \"\"\"\n        Sets this range sensor's horizontal_resolution (degrees in between each horizontal hit)\n\n        Args:\n            resolution (float): horizontal resolution to set, in degrees\n        \"\"\"\n        self.set_attribute(\"horizontalResolution\", resolution)\n\n    @property\n    def vertical_fov(self):\n        \"\"\"\n        Gets this range sensor's vertical_fov\n\n        Returns:\n            float: vertical field of view for this range sensor\n        \"\"\"\n        return self.get_attribute(\"verticalFov\")\n\n    @vertical_fov.setter\n    def vertical_fov(self, fov):\n        \"\"\"\n        Sets this range sensor's vertical_fov\n\n        Args:\n            fov (float): vertical field of view to set\n        \"\"\"\n        self.set_attribute(\"verticalFov\", fov)\n\n    @property\n    def vertical_resolution(self):\n        \"\"\"\n        Gets this range sensor's vertical_resolution (degrees in between each vertical hit)\n\n        Returns:\n            float: vertical resolution for this range sensor, in degrees\n        \"\"\"\n        return self.get_attribute(\"verticalResolution\")\n\n    @vertical_resolution.setter\n    def vertical_resolution(self, resolution):\n        \"\"\"\n        Sets this range sensor's vertical_resolution (degrees in between each vertical hit)\n\n        Args:\n            resolution (float): vertical resolution to set, in degrees\n        \"\"\"\n        self.set_attribute(\"verticalResolution\", resolution)\n\n    @property\n    def yaw_offset(self):\n        \"\"\"\n        Gets this range sensor's yaw_offset (used in cases where this sensor's forward direction is different than expected)\n\n        Returns:\n            float: yaw offset for this range sensor in degrees\n        \"\"\"\n        return self.get_attribute(\"yawOffset\")\n\n    @yaw_offset.setter\n    def yaw_offset(self, offset):\n        \"\"\"\n        Sets this range sensor's yaw_offset (used in cases where this sensor's forward direction is different than expected)\n\n        Args:\n            offset (float): yaw offset to set in degrees.\n        \"\"\"\n        self.set_attribute(\"yawOffset\", offset)\n\n    @property\n    def rotation_rate(self):\n        \"\"\"\n        Gets this range sensor's rotation_rate, in degrees per second. Note that a 0 value corresponds to no rotation,\n        and all range hits are assumed to be received at the exact same time.\n\n        Returns:\n            float: rotation rate for this range sensor in degrees per second\n        \"\"\"\n        return self.get_attribute(\"rotationRate\")\n\n    @rotation_rate.setter\n    def rotation_rate(self, rate):\n        \"\"\"\n        Sets this range sensor's rotation_rate, in degrees per second. Note that a 0 value corresponds to no rotation,\n        and all range hits are assumed to be received at the exact same time.\n\n        Args:\n            rate (float): rotation rate for this range sensor in degrees per second\n        \"\"\"\n        self.set_attribute(\"rotationRate\", rate)\n\n    @classproperty\n    def all_modalities(cls):\n        return {\"scan\", \"occupancy_grid\"}\n\n    @classproperty\n    def no_noise_modalities(cls):\n        # Occupancy grid should have no noise\n        return {\"occupancy_grid\"}\n\n    @property\n    def enabled(self):\n        # Just use super\n        return super().enabled\n\n    @enabled.setter\n    def enabled(self, enabled):\n        # We must use super and additionally directly en/disable the sensor in the simulation\n        # Note: weird syntax below required to \"extend\" super class's implementation, see:\n        # https://stackoverflow.com/a/37663266\n        super(ScanSensor, self.__class__).enabled.fset(self, enabled)\n        self.set_attribute(\"enabled\", enabled)\n</code></pre>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor"},{"title":"<code>draw_lines</code>  <code>writable</code> <code>property</code>","text":"<p>Gets whether range lines are drawn for this sensor</p> <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether range lines are drawn for this sensor</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.draw_lines"},{"title":"<code>draw_points</code>  <code>writable</code> <code>property</code>","text":"<p>Gets whether range points are drawn for this sensor</p> <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether range points are drawn for this sensor</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.draw_points"},{"title":"<code>horizontal_fov</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's horizontal_fov</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>horizontal field of view for this range sensor</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.horizontal_fov"},{"title":"<code>horizontal_resolution</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's horizontal_resolution (degrees in between each horizontal hit)</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>horizontal resolution for this range sensor, in degrees</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.horizontal_resolution"},{"title":"<code>max_range</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's max_range (maximum distance in meters which will register a hit)</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>maximum range for this range sensor, in meters</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.max_range"},{"title":"<code>min_range</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's min_range (minimum distance in meters which will register a hit)</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>minimum range for this range sensor, in meters</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.min_range"},{"title":"<code>n_horizontal_rays</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of horizontal rays for this range sensor</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.n_horizontal_rays"},{"title":"<code>n_vertical_rays</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of vertical rays for this range sensor</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.n_vertical_rays"},{"title":"<code>rotation_rate</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's rotation_rate, in degrees per second. Note that a 0 value corresponds to no rotation, and all range hits are assumed to be received at the exact same time.</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>rotation rate for this range sensor in degrees per second</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.rotation_rate"},{"title":"<code>vertical_fov</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's vertical_fov</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>vertical field of view for this range sensor</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.vertical_fov"},{"title":"<code>vertical_resolution</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's vertical_resolution (degrees in between each vertical hit)</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>vertical resolution for this range sensor, in degrees</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.vertical_resolution"},{"title":"<code>yaw_offset</code>  <code>writable</code> <code>property</code>","text":"<p>Gets this range sensor's yaw_offset (used in cases where this sensor's forward direction is different than expected)</p> <p>Returns:</p>    Name Type Description     <code>float</code>   <p>yaw offset for this range sensor in degrees</p>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.yaw_offset"},{"title":"<code>get_local_occupancy_grid(scan)</code>","text":"<p>Get local occupancy grid based on current 1D scan</p> <p>Parameters:</p>    Name Type Description Default     <code>n-array</code>   <p>1D LiDAR scan</p>  required     <p>Returns:</p>    Type Description       <p>2D-array: (occupancy_grid_resolution, occupancy_grid_resolution)-sized numpy array of the local occupancy grid</p>     Source code in <code>sensors/scan_sensor.py</code> <pre><code>def get_local_occupancy_grid(self, scan):\n    \"\"\"\n    Get local occupancy grid based on current 1D scan\n\n    Args:\n        n-array: 1D LiDAR scan\n\n    Returns:\n        2D-array: (occupancy_grid_resolution, occupancy_grid_resolution)-sized numpy array of the local occupancy grid\n    \"\"\"\n    # Run sanity checks first\n    assert \"occupancy_grid\" in self._modalities, \"Occupancy grid is not enabled for this range sensor!\"\n    assert self.n_vertical_rays == 1, \"Occupancy grid is only valid for a 1D range sensor (n_vertical_rays = 1)!\"\n\n    # Grab vector of corresponding angles for each scan line\n    angles = np.arange(\n        -np.radians(self.horizontal_fov / 2),\n        np.radians(self.horizontal_fov / 2),\n        np.radians(self.horizontal_resolution),\n    )\n\n    # Convert into 3D unit vectors for each angle\n    unit_vector_laser = np.array([[np.cos(ang), np.sin(ang), 0.0] for ang in angles])\n\n    # Scale unit vectors by corresponding laser scan distnaces\n    assert ((scan &gt;= 0.0) &amp; (scan &lt;= 1.0)).all(), \"scan out of valid range [0, 1]\"\n    scan_laser = unit_vector_laser * (scan * (self.max_range - self.min_range) + self.min_range)\n\n    # Convert scans from laser frame to world frame\n    pos, ori = self.get_position_orientation()\n    scan_world = quat2mat(ori).dot(scan_laser.T).T + pos\n\n    # Convert scans from world frame to local base frame\n    base_pos, base_ori = self.occupancy_grid_local_link.get_position_orientation()\n    scan_local = quat2mat(base_ori).T.dot((scan_world - base_pos).T).T\n    scan_local = scan_local[:, :2]\n    scan_local = np.concatenate([np.array([[0, 0]]), scan_local, np.array([[0, 0]])], axis=0)\n\n    # flip y axis\n    scan_local[:, 1] *= -1\n\n    # Initialize occupancy grid -- default is unknown values\n    occupancy_grid = np.zeros((self.occupancy_grid_resolution, self.occupancy_grid_resolution)).astype(np.uint8)\n    occupancy_grid.fill(int(OccupancyGridState.UNKNOWN * 2.0))\n\n    # Convert local scans into the corresponding OG square it should belong to (note now all values are &gt; 0, since\n    # OG ranges from [0, resolution] x [0, resolution])\n    scan_local_in_map = scan_local / self.occupancy_grid_range * self.occupancy_grid_resolution + \\\n                        (self.occupancy_grid_resolution / 2)\n    scan_local_in_map = scan_local_in_map.reshape((1, -1, 1, 2)).astype(np.int32)\n\n    # For each scan hit,\n    for i in range(scan_local_in_map.shape[1]):\n        cv2.circle(\n            img=occupancy_grid,\n            center=(scan_local_in_map[0, i, 0, 0], scan_local_in_map[0, i, 0, 1]),\n            radius=2,\n            color=int(OccupancyGridState.OBSTACLES * 2.0),\n            thickness=-1,\n        )\n    cv2.fillPoly(\n        img=occupancy_grid, pts=scan_local_in_map, color=int(OccupancyGridState.FREESPACE * 2.0), lineType=1\n    )\n    cv2.circle(\n        img=occupancy_grid,\n        center=(self.occupancy_grid_resolution // 2, self.occupancy_grid_resolution // 2),\n        radius=self.occupancy_grid_inner_radius,\n        color=int(OccupancyGridState.FREESPACE * 2.0),\n        thickness=-1,\n    )\n\n    return occupancy_grid[:, :, None].astype(np.float32) / 2.0\n</code></pre>","location":"reference/sensors/scan_sensor.html#sensors.scan_sensor.ScanSensor.get_local_occupancy_grid"},{"title":"sensor_base","text":"","location":"reference/sensors/sensor_base.html"},{"title":"<code>BaseSensor</code>","text":"<p>         Bases: <code>XFormPrim</code>, <code>GymObservable</code>, <code>Registerable</code></p> <p>Base Sensor class. Sensor-specific get_obs method is implemented in subclasses</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Sensor to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the sensor. Names need to be unique per scene.</p>  required    <code>modalities</code>  <code>str or list of str</code>  <p>Modality(s) supported by this sensor. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.</p>  <code>'all'</code>    <code>enabled</code>  <code>bool</code>  <p>Whether this sensor should be enabled by default</p>  <code>True</code>    <code>noise</code>  <code>None or BaseSensorNoise</code>  <p>If specified, sensor noise model to apply to this sensor.</p>  <code>None</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this sensor's prim at runtime.</p>  <code>None</code>      Source code in <code>sensors/sensor_base.py</code> <pre><code>class BaseSensor(XFormPrim, GymObservable, Registerable, metaclass=ABCMeta):\n    \"\"\"\n    Base Sensor class.\n    Sensor-specific get_obs method is implemented in subclasses\n\n    Args:\n        prim_path (str): prim path of the Sensor to encapsulate or create.\n        name (str): Name for the sensor. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Default is \"all\", which corresponds\n            to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.\n        enabled (bool): Whether this sensor should be enabled by default\n        noise (None or BaseSensorNoise): If specified, sensor noise model to apply to this sensor.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this sensor's prim at runtime.\n    \"\"\"\n    def __init__(\n        self,\n        prim_path,\n        name,\n        modalities=\"all\",\n        enabled=True,\n        noise=None,\n        load_config=None,\n    ):\n        # Store inputs (and sanity check modalities along the way)\n        if modalities == \"all\":\n            modalities = self.all_modalities\n        else:\n            modalities = [modalities] if isinstance(modalities, str) else modalities\n            for modality in modalities:\n                assert_valid_key(key=modality, valid_keys=self.all_modalities, name=\"modality\")\n        self._modalities = set(modalities)\n        self._enabled = enabled\n        self._noise = noise\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            load_config=load_config,\n        )\n\n    def _load(self, simulator=None):\n        # Sub-sensors must implement this class directly! Cannot use parent XForm class by default\n        raise NotImplementedError(\"Sensor class must implement _load!\")\n\n    def _post_load(self):\n        # Run super first\n        super()._post_load()\n\n        # Set the enabled property based on the internal value\n        # This is done so that any subclassed sensors which require simulator specific enabling can handle this now\n        self.enabled = self._enabled\n\n    def get_obs(self):\n        # Get sensor reading, and optionally corrupt the readings with noise using self.noise if\n        # self.noise.enabled is True.\n        # Note that the returned dictionary will only be filled in if this sensor is enabled!\n        if not self._enabled:\n            return OrderedDict()\n\n        obs = self._get_obs()\n\n        if self._noise is not None:\n            for k, v in obs.items():\n                if k not in self.no_noise_modalities:\n                    obs[k] = self._noise(v)\n\n        return obs\n\n    def _get_obs(self):\n        \"\"\"\n        Get sensor reading. Should generally be extended by subclass.\n\n        Returns:\n            OrderedDict: Keyword-mapped observations mapping modality names to numpy arrays of arbitrary dimension\n        \"\"\"\n        # Default is returning an empty dict\n        return OrderedDict()\n\n    def _load_observation_space(self):\n        # Fill in observation space based on mapping and active modalities\n        obs_space = OrderedDict()\n        for modality, space in self._obs_space_mapping.items():\n            if modality in self._modalities:\n                if isinstance(space, Space):\n                    # Directly add this space\n                    obs_space[modality] = space\n                else:\n                    # Assume we are procedurally generating a box space\n                    shape, low, high, dtype = space\n                    obs_space[modality] = self._build_obs_box_space(shape=shape, low=low, high=high, dtype=dtype)\n\n        return obs_space\n\n    def add_modality(self, modality):\n        \"\"\"\n        Add a modality to this sensor. Must be a valid modality (one of self.all_modalities)\n\n        Args:\n            modality (str): Name of the modality to add to this sensor\n        \"\"\"\n        assert_valid_key(key=modality, valid_keys=self.all_modalities, name=\"modality\")\n        if modality not in self._modalities:\n            self._modalities.add(modality)\n            # Update observation space\n            self.load_observation_space()\n\n    def remove_modality(self, modality):\n        \"\"\"\n        Remove a modality from this sensor. Must be a valid modality that is active (one of self.modalities)\n\n        Args:\n            modality (str): Name of the modality to remove from this sensor\n        \"\"\"\n        assert_valid_key(key=modality, valid_keys=self._modalities, name=\"modality\")\n        if modality in self._modalities:\n            self._modalities.remove(modality)\n            # Update observation space\n            self.load_observation_space()\n\n    @property\n    def modalities(self):\n        \"\"\"\n        Returns:\n            set: Name of modalities provided by this sensor. This should correspond to all the keys provided\n                in self.get_obs()\n        \"\"\"\n        return self._modalities\n\n    @property\n    def _obs_space_mapping(self):\n        \"\"\"\n        Returns:\n            OrderedDict: Keyword-mapped observation space settings for each modality. For each modality in\n                cls.all_modalities, its name should map directly to the corresponding gym space Space for that modality\n                or a 4-tuple entry (shape, low, high, dtype) for procedurally generating the appropriate Box Space\n                for that modality\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def all_modalities(cls):\n        \"\"\"\n        Returns:\n            set: All possible valid modalities for this sensor. Should be implemented by subclass.\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def noise(self):\n        \"\"\"\n        Returns:\n            None or BaseSensorNoise: Noise model to use for this sensor\n        \"\"\"\n        return self._noise\n\n    @classproperty\n    def no_noise_modalities(cls):\n        \"\"\"\n        Returns:\n            set: Modalities that should NOT be passed through noise, irregardless of whether noise is enabled or not.\n                This is useful for some modalities which are not exclusively numerical arrays.\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def enabled(self):\n        \"\"\"\n        Returns:\n            bool: Whether this sensor is enabled or not\n        \"\"\"\n        # By default, we simply return the internal value. Subclasses may need to extend this functionality,\n        # e.g. by disabling actual sim functionality for better computational efficiency\n        return self._enabled\n\n    @enabled.setter\n    def enabled(self, enabled):\n        \"\"\"\n        Args:\n            enabled (bool): Whether this sensor should be enabled or not\n        \"\"\"\n        # By default, we simply store the value internally. Subclasses may need to extend this functionality,\n        # e.g. by disabling actual sim functionality for better computational efficiency\n        self._enabled = enabled\n\n    @classproperty\n    def sensor_type(cls):\n        \"\"\"\n        Returns:\n            str: Type of this sensor. By default, this is the sensor class name\n        \"\"\"\n        return cls.__name__\n\n    @classmethod\n    def _register_cls(cls):\n        global ALL_SENSOR_MODALITIES\n\n        # Run super first\n        super()._register_cls()\n\n        # Also store modalities from this sensor class if we're registering it\n        if cls.__name__ not in cls._do_not_register_classes:\n            ALL_SENSOR_MODALITIES.union(cls.all_modalities)\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseSensor\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_SENSORS\n        return REGISTERED_SENSORS\n</code></pre>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor"},{"title":"<code>enabled</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this sensor is enabled or not</p>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.enabled"},{"title":"<code>modalities</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>set</code>   <p>Name of modalities provided by this sensor. This should correspond to all the keys provided in self.get_obs()</p>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.modalities"},{"title":"<code>noise</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>None or BaseSensorNoise: Noise model to use for this sensor</p>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.noise"},{"title":"<code>add_modality(modality)</code>","text":"<p>Add a modality to this sensor. Must be a valid modality (one of self.all_modalities)</p> <p>Parameters:</p>    Name Type Description Default     <code>modality</code>  <code>str</code>  <p>Name of the modality to add to this sensor</p>  required      Source code in <code>sensors/sensor_base.py</code> <pre><code>def add_modality(self, modality):\n    \"\"\"\n    Add a modality to this sensor. Must be a valid modality (one of self.all_modalities)\n\n    Args:\n        modality (str): Name of the modality to add to this sensor\n    \"\"\"\n    assert_valid_key(key=modality, valid_keys=self.all_modalities, name=\"modality\")\n    if modality not in self._modalities:\n        self._modalities.add(modality)\n        # Update observation space\n        self.load_observation_space()\n</code></pre>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.add_modality"},{"title":"<code>all_modalities()</code>","text":"<p>Returns:</p>    Name Type Description     <code>set</code>   <p>All possible valid modalities for this sensor. Should be implemented by subclass.</p>     Source code in <code>sensors/sensor_base.py</code> <pre><code>@classproperty\ndef all_modalities(cls):\n    \"\"\"\n    Returns:\n        set: All possible valid modalities for this sensor. Should be implemented by subclass.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.all_modalities"},{"title":"<code>no_noise_modalities()</code>","text":"<p>Returns:</p>    Name Type Description     <code>set</code>   <p>Modalities that should NOT be passed through noise, irregardless of whether noise is enabled or not. This is useful for some modalities which are not exclusively numerical arrays.</p>     Source code in <code>sensors/sensor_base.py</code> <pre><code>@classproperty\ndef no_noise_modalities(cls):\n    \"\"\"\n    Returns:\n        set: Modalities that should NOT be passed through noise, irregardless of whether noise is enabled or not.\n            This is useful for some modalities which are not exclusively numerical arrays.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.no_noise_modalities"},{"title":"<code>remove_modality(modality)</code>","text":"<p>Remove a modality from this sensor. Must be a valid modality that is active (one of self.modalities)</p> <p>Parameters:</p>    Name Type Description Default     <code>modality</code>  <code>str</code>  <p>Name of the modality to remove from this sensor</p>  required      Source code in <code>sensors/sensor_base.py</code> <pre><code>def remove_modality(self, modality):\n    \"\"\"\n    Remove a modality from this sensor. Must be a valid modality that is active (one of self.modalities)\n\n    Args:\n        modality (str): Name of the modality to remove from this sensor\n    \"\"\"\n    assert_valid_key(key=modality, valid_keys=self._modalities, name=\"modality\")\n    if modality in self._modalities:\n        self._modalities.remove(modality)\n        # Update observation space\n        self.load_observation_space()\n</code></pre>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.remove_modality"},{"title":"<code>sensor_type()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Type of this sensor. By default, this is the sensor class name</p>     Source code in <code>sensors/sensor_base.py</code> <pre><code>@classproperty\ndef sensor_type(cls):\n    \"\"\"\n    Returns:\n        str: Type of this sensor. By default, this is the sensor class name\n    \"\"\"\n    return cls.__name__\n</code></pre>","location":"reference/sensors/sensor_base.html#sensors.sensor_base.BaseSensor.sensor_type"},{"title":"sensor_noise_base","text":"","location":"reference/sensors/sensor_noise_base.html"},{"title":"<code>BaseSensorNoise</code>","text":"<p>         Bases: <code>Registerable</code></p> <p>Base SensorNoise class. Sensor noise-specific add_noise method is implemented in subclasses</p> <p>Parameters:</p>    Name Type Description Default     <code>enabled</code>  <code>bool</code>  <p>Whether this sensor should be enabled by default</p>  <code>True</code>      Source code in <code>sensors/sensor_noise_base.py</code> <pre><code>class BaseSensorNoise(Registerable, metaclass=ABCMeta):\n    \"\"\"\n    Base SensorNoise class.\n    Sensor noise-specific add_noise method is implemented in subclasses\n\n    Args:\n        enabled (bool): Whether this sensor should be enabled by default\n    \"\"\"\n    def __init__(self, enabled=True):\n        # Store whether this noise model is enabled or not\n        self._enabled = enabled\n\n    def __call__(self, obs):\n        \"\"\"\n        If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading. This is an\n        identical call to self.corrupt(...)\n\n        Args:\n            obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n\n        Returns:\n            np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n        \"\"\"\n        return self.corrupt(obs=obs)\n\n    def corrupt(self, obs):\n        \"\"\"\n        If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading.\n\n        Args:\n            obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n\n        Returns:\n            np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n        \"\"\"\n        # Run sanity check to make sure obs is in acceptable range\n        assert len(obs[(obs &lt; 0.0) | (obs &gt; 1.0)]) == 0, \"sensor reading has to be between [0.0, 1.0]\"\n\n        return self._corrupt(obs=obs) if self._enabled else obs\n\n    @abstractmethod\n    def _corrupt(self, obs):\n        \"\"\"\n        Corrupts observation @obs by adding sensor noise to sensor reading\n\n        Args:\n            obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n\n        Returns:\n            np.array: Corrupted observation numpy array\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def enabled(self):\n        \"\"\"\n        Returns:\n            bool: Whether this noise model is enabled or not\n        \"\"\"\n        return self._enabled\n\n    @enabled.setter\n    def enabled(self, enabled):\n        \"\"\"\n        En/disables this noise model\n\n        Args:\n            enabled (bool): Whether this noise model should be enabled or not\n        \"\"\"\n        self._enabled = enabled\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseSensorNoise\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_SENSOR_NOISES\n        return REGISTERED_SENSOR_NOISES\n</code></pre>","location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise"},{"title":"<code>enabled</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this noise model is enabled or not</p>","location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise.enabled"},{"title":"<code>__call__(obs)</code>","text":"<p>If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading. This is an identical call to self.corrupt(...)</p> <p>Parameters:</p>    Name Type Description Default     <code>obs</code>  <code>np.array</code>  <p>observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]</p>  required     <p>Returns:</p>    Type Description       <p>np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through</p>     Source code in <code>sensors/sensor_noise_base.py</code> <pre><code>def __call__(self, obs):\n    \"\"\"\n    If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading. This is an\n    identical call to self.corrupt(...)\n\n    Args:\n        obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n\n    Returns:\n        np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n    \"\"\"\n    return self.corrupt(obs=obs)\n</code></pre>","location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise.__call__"},{"title":"<code>corrupt(obs)</code>","text":"<p>If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading.</p> <p>Parameters:</p>    Name Type Description Default     <code>obs</code>  <code>np.array</code>  <p>observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]</p>  required     <p>Returns:</p>    Type Description       <p>np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through</p>     Source code in <code>sensors/sensor_noise_base.py</code> <pre><code>def corrupt(self, obs):\n    \"\"\"\n    If this noise is enabled, corrupts observation @obs by adding sensor noise to sensor reading.\n\n    Args:\n        obs (np.array): observation numpy array of values of arbitrary dimension normalized to range [0.0, 1.0]\n\n    Returns:\n        np.array: Corrupted observation numpy array if self.enabled is True, otherwise this is a pass-through\n    \"\"\"\n    # Run sanity check to make sure obs is in acceptable range\n    assert len(obs[(obs &lt; 0.0) | (obs &gt; 1.0)]) == 0, \"sensor reading has to be between [0.0, 1.0]\"\n\n    return self._corrupt(obs=obs) if self._enabled else obs\n</code></pre>","location":"reference/sensors/sensor_noise_base.html#sensors.sensor_noise_base.BaseSensorNoise.corrupt"},{"title":"vision_sensor","text":"","location":"reference/sensors/vision_sensor.html"},{"title":"<code>VisionSensor</code>","text":"<p>         Bases: <code>BaseSensor</code></p> <p>Vision sensor that handles a variety of modalities, including:</p> <pre><code>- RGB (normal)\n- Depth (normal, linear)\n- Normals\n- Segmentation (semantic, instance)\n- Optical flow\n- 2D Bounding boxes (tight, loose)\n- 3D Bounding boxes\n- Camera state\n</code></pre> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>modalities</code>  <code>str or list of str</code>  <p>Modality(s) supported by this sensor. Default is \"all\", which corresponds to all modalities being used. Otherwise, valid options should be part of cls.all_modalities. For this vision sensor, this includes any of:     {rgb, depth, depth_linear, normal, seg_semantic, seg_instance, flow, bbox_2d_tight,     bbox_2d_loose, bbox_3d, camera}</p>  <code>'all'</code>    <code>enabled</code>  <code>bool</code>  <p>Whether this sensor should be enabled by default</p>  <code>True</code>    <code>noise</code>  <code>None or BaseSensorNoise</code>  <p>If specified, sensor noise model to apply to this sensor.</p>  <code>None</code>    <code>load_config</code>  <code>None or dict</code>  <p>If specified, should contain keyword-mapped values that are relevant for loading this sensor's prim at runtime.</p>  <code>None</code>    <code>image_height</code>  <code>int</code>  <p>Height of generated images, in pixels</p>  <code>128</code>    <code>image_width</code>  <code>int</code>  <p>Width of generated images, in pixels</p>  <code>128</code>    <code>viewport_name</code>  <code>None or str</code>  <p>If specified, will link this camera to the specified viewport, overriding its current camera. Otherwise, creates a new viewport</p>  <code>None</code>      Source code in <code>sensors/vision_sensor.py</code> <pre><code>class VisionSensor(BaseSensor):\n    \"\"\"\n    Vision sensor that handles a variety of modalities, including:\n\n        - RGB (normal)\n        - Depth (normal, linear)\n        - Normals\n        - Segmentation (semantic, instance)\n        - Optical flow\n        - 2D Bounding boxes (tight, loose)\n        - 3D Bounding boxes\n        - Camera state\n\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        modalities (str or list of str): Modality(s) supported by this sensor. Default is \"all\", which corresponds\n            to all modalities being used. Otherwise, valid options should be part of cls.all_modalities.\n            For this vision sensor, this includes any of:\n                {rgb, depth, depth_linear, normal, seg_semantic, seg_instance, flow, bbox_2d_tight,\n                bbox_2d_loose, bbox_3d, camera}\n        enabled (bool): Whether this sensor should be enabled by default\n        noise (None or BaseSensorNoise): If specified, sensor noise model to apply to this sensor.\n        load_config (None or dict): If specified, should contain keyword-mapped values that are relevant for\n            loading this sensor's prim at runtime.\n        image_height (int): Height of generated images, in pixels\n        image_width (int): Width of generated images, in pixels\n        viewport_name (None or str): If specified, will link this camera to the specified viewport, overriding its\n            current camera. Otherwise, creates a new viewport\n    \"\"\"\n    _SENSOR_HELPERS = OrderedDict(\n        rgb=sensors_util.get_rgb,\n        depth=sensors_util.get_depth,\n        depth_linear=sensors_util.get_depth_linear,\n        normal=sensors_util.get_normals,\n        seg_semantic=sensors_util.get_semantic_segmentation,\n        seg_instance=sensors_util.get_instance_segmentation,\n        flow=sensors_util.get_motion_vector,\n        bbox_2d_tight=sensors_util.get_bounding_box_2d_tight,\n        bbox_2d_loose=sensors_util.get_bounding_box_2d_loose,\n        bbox_3d=sensors_util.get_bounding_box_3d,\n        camera=get_camera_params,\n    )\n\n    # Define raw sensor types\n    _RAW_SENSOR_TYPES = OrderedDict(\n        rgb=sensor_types.Rgb,\n        depth=sensor_types.Depth,\n        depth_linear=sensor_types.DepthLinear,\n        normal=sensor_types.Normal,\n        seg_semantic=sensor_types.SemanticSegmentation,\n        seg_instance=sensor_types.InstanceSegmentation,\n        flow=sensor_types.MotionVector,\n        bbox_2d_tight=sensor_types.BoundingBox2DTight,\n        bbox_2d_loose=sensor_types.BoundingBox2DLoose,\n        bbox_3d=sensor_types.BoundingBox3D,\n    )\n\n    # Persistent dictionary of sensors, mapped from prim_path to sensor\n    SENSORS = OrderedDict()\n\n    def __init__(\n        self,\n        prim_path,\n        name,\n        modalities=\"all\",\n        enabled=True,\n        noise=None,\n        load_config=None,\n        image_height=128,\n        image_width=128,\n        viewport_name=None,\n    ):\n        # Create load config from inputs\n        load_config = dict() if load_config is None else load_config\n        load_config[\"image_height\"] = image_height\n        load_config[\"image_width\"] = image_width\n        load_config[\"viewport_name\"] = viewport_name\n\n        # Create variables that will be filled in later at runtime\n        self._sd = None             # synthetic data interface\n        self._viewport = None       # Viewport from which to grab data\n\n        # Run super method\n        super().__init__(\n            prim_path=prim_path,\n            name=name,\n            modalities=modalities,\n            enabled=enabled,\n            noise=noise,\n            load_config=load_config,\n        )\n\n    def _load(self, simulator=None):\n        # Define a new camera prim at the current stage\n        stage = get_current_stage()\n        prim = UsdGeom.Camera.Define(stage, self._prim_path).GetPrim()\n        return prim\n\n    def _post_load(self):\n        # run super first\n        super()._post_load()\n\n        # Add this sensor to the list of global sensors\n        self.SENSORS[self._prim_path] = self\n\n        # Get synthetic data interface\n        self._sd = sd.acquire_syntheticdata_interface()\n\n        # Create a new viewport to link to this camera or link to a pre-existing one\n        vp = acquire_viewport_interface()\n        viewport_name = self._load_config[\"viewport_name\"]\n        if viewport_name is not None:\n            vp_names_to_handles = {vp.get_viewport_window_name(h): h for h in vp.get_instance_list()}\n            assert_valid_key(key=viewport_name, valid_keys=vp_names_to_handles, name=\"viewport name\")\n            viewport_handle = vp_names_to_handles[viewport_name]\n        else:\n            viewport_handle = vp.create_instance()\n        self._viewport = vp.get_viewport_window(viewport_handle)\n\n        # Link the camera and viewport together\n        self._viewport.set_active_camera(self._prim_path)\n\n        # Set the viewer size\n        self._viewport.set_texture_resolution(self._load_config[\"image_width\"], self._load_config[\"image_height\"])\n        self._viewport.set_window_size(self._load_config[\"image_height\"], self._load_config[\"image_width\"])\n        # Requires 3 updates to propagate changes\n        for i in range(3):\n            app.update()\n\n    def _initialize(self):\n        # Run super first\n        super()._initialize()\n\n        # Initialize sensors\n        self.initialize_sensors(names=self._modalities)\n\n    def initialize_sensors(self, names, timeout=10.0):\n        \"\"\"Initializes a raw sensor in the simulation.\n\n        Args:\n            names (str or list of str): Name of the raw sensor(s) to initialize.\n                If they are not part of self._RAW_SENSOR_TYPES' keys, we will simply pass over them\n            timeout (int): Maximum time in seconds to attempt to initialize sensors.\n        \"\"\"\n        # Standardize the input and grab the intersection with all possible raw sensors\n        names = set([names]) if isinstance(names, str) else set(names)\n        names = names.intersection(set(self._RAW_SENSOR_TYPES.keys()))\n\n        # Record the start time so we know how long this takes\n        start = time.time()\n        is_initialized = False\n        sensors = []\n\n        # Initialize sensors\n        for name in names:\n            sensors.append(sensors_util.create_or_retrieve_sensor(self._viewport, self._RAW_SENSOR_TYPES[name]))\n        app.update()\n        app.update()  # Extra frame required to prevent access violation error\n\n    def _get_obs(self):\n        # Make sure we're initialized\n        assert self.initialized, \"Cannot grab vision observations without first initializing this VisionSensor!\"\n\n        # Run super first to grab any upstream obs\n        obs = super()._get_obs()\n\n        # Process each sensor modality individually\n        for modality in self.modalities:\n            mod_kwargs = dict()\n            mod_kwargs[\"viewport\"] = self._viewport\n            if modality == \"seg_instance\":\n                mod_kwargs.update({\"parsed\": True, \"return_mapping\": False})\n            elif modality == \"bbox_3d\":\n                mod_kwargs.update({\"parsed\": True, \"return_corners\": True})\n            obs[modality] = self._SENSOR_HELPERS[modality](**mod_kwargs)\n\n        return obs\n\n    def add_modality(self, modality):\n        # Check if we already have this modality (if so, no need to initialize it explicitly)\n        should_initialize = modality not in self._modalities\n\n        # Run super\n        super().add_modality(modality=modality)\n\n        # We also need to initialize this new modality\n        if should_initialize:\n            self.initialize_sensors(names=modality)\n\n    def get_local_pose(self):\n        # We have to overwrite this because camera prims can't set their quat for some reason ):\n        xform_translate_op = self.get_attribute(\"xformOp:translate\")\n        xform_orient_op = self.get_attribute(\"xformOp:rotateXYZ\")\n        return np.array(xform_translate_op), euler2quat(np.array(xform_orient_op))\n\n    def set_window_position(self, x, y):\n        \"\"\"Set the position of the viewport window.\n\n        :param x: x position of the viewport window\n        :param y: y position of the viewport window\n        \"\"\"\n        self._viewport.set_window_pos(x ,y)\n\n    def set_window_size(self, width, height):\n        \"\"\"Set the size of the viewport window.\n\n        :param width: width of the viewport window\n        :param height: height of the viewport window\n        \"\"\"\n        self._viewport.set_window_size(width, height)\n\n    def set_camera_position(self, x, y, z, rotate=True):\n        \"\"\"Set the position of the active camera.\n\n        :param x: x coordinate of the camera\n        :param y: y coordinate of the camera\n        :param z: z coordinate of the camera\n        :param rotate: set rotate=True to move the camera, but rotate to keep its focus;\n            set rotate=False to move the camera and look at a new point\n        \"\"\"\n        self._viewport.set_camera_position(self._prim_path, x, y, z, rotate)\n\n    def set_camera_target(self, x, y, z, rotate=True):\n        \"\"\"Set the target of the active camera.\n\n        :param x: x coordinate of the camera\n        :param y: y coordinate of the camera\n        :param z: z coordinate of the camera\n        :param rotate: rotate=True to rotate the camera to look at the target;\n            set rotate=False to move the camera to look at the target\n        \"\"\"\n        self._viewport.set_camera_target(self._prim_path, x, y, z, rotate)\n\n    def remove(self, simulator=None):\n        # Run super first\n        super().remove(simulator=simulator)\n\n        # Also remove this from the global sensors dict\n        self.SENSORS.pop(self._prim_path)\n\n    @property\n    def viewer_visibility(self):\n        \"\"\"\n        Returns:\n            bool: Whether the viewer is visible or not\n        \"\"\"\n        return self._viewport.is_visible()\n\n    @viewer_visibility.setter\n    def viewer_visibility(self, visible):\n        \"\"\"\n        Sets whether the viewer should be visible or not in the Omni UI\n\n        Args:\n            visible (bool): Whether the viewer should be visible or not\n        \"\"\"\n        self._viewport.set_visible(visible)\n        # Requires 1 update to propagate changes\n        app.update()\n\n    @property\n    def image_height(self):\n        \"\"\"\n        Returns:\n            int: Image height of this sensor, in pixels\n        \"\"\"\n        return self._viewport.get_texture_resolution()[1]\n\n    @image_height.setter\n    def image_height(self, height):\n        \"\"\"\n        Sets the image height @height for this sensor\n\n        Args:\n            height (int): Image height of this sensor, in pixels\n        \"\"\"\n        width, _ = self._viewport.get_texture_resolution()\n        self._viewport.set_texture_resolution(width, height)\n        # Requires 3 updates to propagate changes\n        for i in range(3):\n            app.update()\n\n    @property\n    def image_width(self):\n        \"\"\"\n        Returns:\n            int: Image width of this sensor, in pixels\n        \"\"\"\n        return self._viewport.get_texture_resolution()[0]\n\n    @image_width.setter\n    def image_width(self, width):\n        \"\"\"\n        Sets the image width @width for this sensor\n\n        Args:\n            width (int): Image width of this sensor, in pixels\n        \"\"\"\n        _, height = self._viewport.get_texture_resolution()\n        self._viewport.set_texture_resolution(width, height)\n        # Requires 3 updates to propagate changes\n        for i in range(3):\n            app.update()\n\n    @property\n    def clipping_range(self):\n        \"\"\"\n        Returns:\n            2-tuple: [min, max] value of the sensor's clipping range, in meters\n        \"\"\"\n        return np.array(self.get_attribute(\"clippingRange\"))\n\n    @clipping_range.setter\n    def clipping_range(self, limits):\n        \"\"\"\n        Sets the clipping range @limits for this sensor\n\n        Args:\n            limits (2-tuple): [min, max] value of the sensor's clipping range, in meters\n        \"\"\"\n        self.set_attribute(attr=\"clippingRange\", val=Gf.Vec2f(*limits))\n        # In order for sensor changes to propagate, we must toggle its visibility\n        self.visible = False\n        # A single update step has to happen here before we toggle visibility for changes to propagate\n        app.update()\n        self.visible = True\n\n    @property\n    def focal_length(self):\n        \"\"\"\n        Returns:\n            float: focal length of this sensor, in meters\n        \"\"\"\n        return self.get_attribute(\"focalLength\")\n\n    @focal_length.setter\n    def focal_length(self, length):\n        \"\"\"\n        Sets the focal length @length for this sensor\n\n        Args:\n            length (float): focal length of this sensor, in meters\n        \"\"\"\n        self.set_attribute(\"focalLength\", length)\n\n    @property\n    def _obs_space_mapping(self):\n        # Generate the complex space types for special modalities:\n        # {\"bbox_2d_tight\", \"bbox_2d_loose\", \"bbox_3d\", \"camera\"}\n        bbox_3d_space = gym.spaces.Sequence(space=gym.spaces.Tuple((\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=int),  # uniqueId\n            gym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # name\n            gym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # semanticLabel\n            gym.spaces.Text(min_length=0, max_length=50, charset=VALID_OMNI_CHARS),  # metadata\n            gym.spaces.Sequence(space=gym.spaces.Box(low=0, high=MAX_INSTANCE_COUNT, shape=(), dtype=np.uint)),   # instanceIds\n            gym.spaces.Box(low=0, high=MAX_CLASS_COUNT, shape=(), dtype=np.uint),  # semanticId\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # x_min\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # y_min\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # z_min\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # x_max\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # y_max\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=float), # z_max\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4, 4), dtype=float), # transform\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(8, 3), dtype=float), # corners\n        )))\n\n        bbox_2d_space = gym.spaces.Sequence(space=gym.spaces.Tuple((\n            gym.spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=int),  # uniqueId\n            gym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # name\n            gym.spaces.Text(min_length=1, max_length=50, charset=VALID_OMNI_CHARS),  # semanticLabel\n            gym.spaces.Text(min_length=0, max_length=50, charset=VALID_OMNI_CHARS),  # metadata\n            gym.spaces.Sequence(space=gym.spaces.Box(low=0, high=MAX_INSTANCE_COUNT, shape=(), dtype=np.uint)), # instanceIds\n            gym.spaces.Box(low=0, high=MAX_CLASS_COUNT, shape=(), dtype=np.uint),  # semanticId\n            gym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # x_min\n            gym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # y_min\n            gym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # x_max\n            gym.spaces.Box(low=0, high=MAX_VIEWER_SIZE, shape=(), dtype=int),  # y_max\n        )))\n\n        camera_space = gym.spaces.Dict(OrderedDict(\n            pose=gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4, 4), dtype=float),\n            fov=gym.spaces.Box(low=0, high=np.inf, shape=(), dtype=float),\n            focal_length=gym.spaces.Box(low=0, high=np.inf, shape=(), dtype=float),\n            horizontal_aperature=gym.spaces.Box(low=0, high=np.inf, shape=(), dtype=float),\n            view_projection_matrix=gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4, 4), dtype=float),\n            resolution=gym.spaces.Dict(OrderedDict(\n                width=gym.spaces.Box(low=1, high=MAX_VIEWER_SIZE, shape=(), dtype=np.uint),\n                height=gym.spaces.Box(low=1, high=MAX_VIEWER_SIZE, shape=(), dtype=np.uint),\n            )),\n            clipping_range=gym.spaces.Box(low=0, high=np.inf, shape=(2,), dtype=float),\n        ))\n\n        obs_space_mapping = OrderedDict(\n            rgb=((self.image_height, self.image_width, 4), 0, 255, np.uint8),\n            depth=((self.image_height, self.image_width), 0.0, 1.0, np.float32),\n            depth_linear=((self.image_height, self.image_width), 0.0, np.inf, np.float32),\n            normal=((self.image_height, self.image_width, 3), -1.0, 1.0, np.float32),\n            seg_semantic=((self.image_height, self.image_width), 0, MAX_CLASS_COUNT, np.uint32),\n            seg_instance=((self.image_height, self.image_width), 0, MAX_INSTANCE_COUNT, np.uint32),\n            flow=((self.image_height, self.image_width, 3), -np.inf, np.inf, np.float32),\n            bbox_2d_tight=bbox_2d_space,\n            bbox_2d_loose=bbox_2d_space,\n            bbox_3d=bbox_3d_space,\n            camera=camera_space,\n        )\n\n        return obs_space_mapping\n\n    @classproperty\n    def all_modalities(cls):\n        return {k for k in cls._SENSOR_HELPERS.keys()}\n\n    @classproperty\n    def no_noise_modalities(cls):\n        # bounding boxes and camera state should not have noise\n        return {\"bbox_2d_tight\", \"bbox_2d_loose\", \"bbox_3d\", \"camera\"}\n</code></pre>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor"},{"title":"<code>clipping_range</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>2-tuple: [min, max] value of the sensor's clipping range, in meters</p>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.clipping_range"},{"title":"<code>focal_length</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>focal length of this sensor, in meters</p>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.focal_length"},{"title":"<code>image_height</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Image height of this sensor, in pixels</p>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.image_height"},{"title":"<code>image_width</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Image width of this sensor, in pixels</p>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.image_width"},{"title":"<code>viewer_visibility</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether the viewer is visible or not</p>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.viewer_visibility"},{"title":"<code>initialize_sensors(names, timeout=10.0)</code>","text":"<p>Initializes a raw sensor in the simulation.</p> <p>Parameters:</p>    Name Type Description Default     <code>names</code>  <code>str or list of str</code>  <p>Name of the raw sensor(s) to initialize. If they are not part of self._RAW_SENSOR_TYPES' keys, we will simply pass over them</p>  required    <code>timeout</code>  <code>int</code>  <p>Maximum time in seconds to attempt to initialize sensors.</p>  <code>10.0</code>      Source code in <code>sensors/vision_sensor.py</code> <pre><code>def initialize_sensors(self, names, timeout=10.0):\n    \"\"\"Initializes a raw sensor in the simulation.\n\n    Args:\n        names (str or list of str): Name of the raw sensor(s) to initialize.\n            If they are not part of self._RAW_SENSOR_TYPES' keys, we will simply pass over them\n        timeout (int): Maximum time in seconds to attempt to initialize sensors.\n    \"\"\"\n    # Standardize the input and grab the intersection with all possible raw sensors\n    names = set([names]) if isinstance(names, str) else set(names)\n    names = names.intersection(set(self._RAW_SENSOR_TYPES.keys()))\n\n    # Record the start time so we know how long this takes\n    start = time.time()\n    is_initialized = False\n    sensors = []\n\n    # Initialize sensors\n    for name in names:\n        sensors.append(sensors_util.create_or_retrieve_sensor(self._viewport, self._RAW_SENSOR_TYPES[name]))\n    app.update()\n    app.update()  # Extra frame required to prevent access violation error\n</code></pre>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.initialize_sensors"},{"title":"<code>set_camera_position(x, y, z, rotate=True)</code>","text":"<p>Set the position of the active camera.</p> <p>:param x: x coordinate of the camera :param y: y coordinate of the camera :param z: z coordinate of the camera :param rotate: set rotate=True to move the camera, but rotate to keep its focus;     set rotate=False to move the camera and look at a new point</p>  Source code in <code>sensors/vision_sensor.py</code> <pre><code>def set_camera_position(self, x, y, z, rotate=True):\n    \"\"\"Set the position of the active camera.\n\n    :param x: x coordinate of the camera\n    :param y: y coordinate of the camera\n    :param z: z coordinate of the camera\n    :param rotate: set rotate=True to move the camera, but rotate to keep its focus;\n        set rotate=False to move the camera and look at a new point\n    \"\"\"\n    self._viewport.set_camera_position(self._prim_path, x, y, z, rotate)\n</code></pre>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.set_camera_position"},{"title":"<code>set_camera_target(x, y, z, rotate=True)</code>","text":"<p>Set the target of the active camera.</p> <p>:param x: x coordinate of the camera :param y: y coordinate of the camera :param z: z coordinate of the camera :param rotate: rotate=True to rotate the camera to look at the target;     set rotate=False to move the camera to look at the target</p>  Source code in <code>sensors/vision_sensor.py</code> <pre><code>def set_camera_target(self, x, y, z, rotate=True):\n    \"\"\"Set the target of the active camera.\n\n    :param x: x coordinate of the camera\n    :param y: y coordinate of the camera\n    :param z: z coordinate of the camera\n    :param rotate: rotate=True to rotate the camera to look at the target;\n        set rotate=False to move the camera to look at the target\n    \"\"\"\n    self._viewport.set_camera_target(self._prim_path, x, y, z, rotate)\n</code></pre>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.set_camera_target"},{"title":"<code>set_window_position(x, y)</code>","text":"<p>Set the position of the viewport window.</p> <p>:param x: x position of the viewport window :param y: y position of the viewport window</p>  Source code in <code>sensors/vision_sensor.py</code> <pre><code>def set_window_position(self, x, y):\n    \"\"\"Set the position of the viewport window.\n\n    :param x: x position of the viewport window\n    :param y: y position of the viewport window\n    \"\"\"\n    self._viewport.set_window_pos(x ,y)\n</code></pre>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.set_window_position"},{"title":"<code>set_window_size(width, height)</code>","text":"<p>Set the size of the viewport window.</p> <p>:param width: width of the viewport window :param height: height of the viewport window</p>  Source code in <code>sensors/vision_sensor.py</code> <pre><code>def set_window_size(self, width, height):\n    \"\"\"Set the size of the viewport window.\n\n    :param width: width of the viewport window\n    :param height: height of the viewport window\n    \"\"\"\n    self._viewport.set_window_size(width, height)\n</code></pre>","location":"reference/sensors/vision_sensor.html#sensors.vision_sensor.VisionSensor.set_window_size"},{"title":"systems","text":"","location":"reference/systems/index.html"},{"title":"macro_particle_system","text":"","location":"reference/systems/macro_particle_system.html"},{"title":"<code>MacroParticleSystem</code>","text":"<p>         Bases: <code>BaseParticleSystem</code></p> <p>Global system for modeling \"macro\" level particles, e.g.: dirt, dust, etc.</p>  Source code in <code>systems/macro_particle_system.py</code> <pre><code>class MacroParticleSystem(BaseParticleSystem):\n    \"\"\"\n    Global system for modeling \"macro\" level particles, e.g.: dirt, dust, etc.\n    \"\"\"\n    # Template object to use -- this should be some instance of BasePrim. This will be the\n    # object that symbolizes a single particle, and will be duplicated to generate the particle system.\n    # Note that this object is NOT part of the actual particle system itself!\n    particle_object = None\n\n    # OrderedDict, array of particle objects, mapped by their prim names\n    particles = None\n\n    # Scaling factor to sample from when generating a new particle\n    min_scale = None              # (x,y,z) scaling\n    max_scale = None              # (x,y,z) scaling\n\n    # Max particle identification number -- this monotonically increases until reset() is called\n    max_particle_idn = None\n\n    # Color associated with this system (NOTE: external queries should call cls.color)\n    _color = None\n\n    @classmethod\n    def initialize(cls, simulator):\n        # Run super method first\n        super().initialize(simulator=simulator)\n\n        # Initialize mutable class variables so they don't automatically get overridden by children classes\n        cls.particles = OrderedDict()\n        cls.min_scale = np.ones(3)\n        cls.max_scale = np.ones(3)\n        cls.max_particle_idn = -1\n\n        # Load the particle template\n        particle_template = cls._create_particle_template()\n        simulator.import_object(obj=particle_template, register=False, auto_initialize=True)\n\n        # Class particle objet is assumed to be the first and only visual mesh belonging to the root link\n        cls.set_particle_template_object(obj=list(particle_template.root_link.visual_meshes.values())[0])\n\n    @classmethod\n    def _create_particle_template(cls):\n        \"\"\"\n        Creates the particle template to be used for this system.\n\n        NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n            visual mesh attached to its root link, since this will be the actual visual mesh used\n\n        Returns:\n            EntityPrim: Particle template that will be duplicated when generating future particle groups\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def reset(cls):\n        # Reset all internal variables\n        cls.remove_all_particles()\n        cls.max_particle_idn = -1\n\n    @classproperty\n    def n_particles(cls):\n        \"\"\"\n        Returns:\n            int: Number of active particles in this system\n        \"\"\"\n        return len(cls.particles)\n\n    @classproperty\n    def particle_name_prefix(cls):\n        \"\"\"\n        Returns:\n            str: Naming prefix used for all generated particles. This is coupled with the unique particle ID to generate\n                the full particle name\n        \"\"\"\n        return f\"{cls.name}Particle\"\n\n    @classproperty\n    def state_size(cls):\n        # We have max_particle_idn (1), n_particles (1), each particle pose (7*n), scale (3*n), and\n        # possibly template pose (7), and template scale (3)\n        state_size = 10 * cls.n_particles + 2\n        return state_size if cls.particle_object is None else state_size + 10\n\n    @classmethod\n    def _dump_state(cls):\n        return OrderedDict(\n            max_particle_idn=cls.max_particle_idn,\n            n_particles=cls.n_particles,\n            poses=[particle.get_local_pose() for particle in cls.particles.values()],\n            scales=[particle.scale for particle in cls.particles.values()],\n            template_pose=cls.particle_object.get_local_pose() if cls.particle_object is not None else None,\n            template_scale=cls.particle_object.scale if cls.particle_object is not None else None,\n        )\n\n    @classmethod\n    def _load_state(cls, state):\n        \"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to set\n        \"\"\"\n        # Sanity check loading particles\n        assert cls.n_particles == state[\"n_particles\"], f\"Inconsistent number of particles found when loading \" \\\n                                                        f\"particles state! Current number: {cls.n_particles}, \" \\\n                                                        f\"loaded number: {state['n_particles']}\"\n        cls.max_particle_idn = state[\"max_particle_idn\"]\n\n        # Load the poses and scales\n        for particle, pose, scale in zip(cls.particles.values(), state[\"poses\"], state[\"scales\"]):\n            particle.set_local_pose(*pose)\n            particle.scale = scale\n\n        # Load template pose and scale if it exists\n        if state[\"template_pose\"] is not None:\n            cls.particle_object.set_local_pose(*state[\"template_pose\"])\n            cls.particle_object.scale = state[\"template_scale\"]\n\n    @classmethod\n    def _serialize(cls, state):\n        # Array is n_particles + poses for all particles, then the template info\n        states_flat = [\n            [state[\"max_particle_idn\"]],\n            [state[\"n_particles\"]],\n            *[np.concatenate(pose) for pose in state[\"poses\"]],\n            *state[\"scales\"]\n        ]\n\n        # Optionally add template pose and scale if it's not None\n        if state[\"template_pose\"] is not None:\n            states_flat += [*state[\"template_pose\"], state[\"template_scale\"]]\n\n        return np.concatenate(states_flat).astype(float)\n\n    @classmethod\n    def _deserialize(cls, state):\n        # First index is number of particles, rest are the individual particle poses\n        state_dict = OrderedDict()\n        state_dict[\"max_particle_idn\"] = state[0]\n        n_particles = int(state[1])\n        state_dict[\"n_particles\"] = n_particles\n\n        poses, scales = [], []\n        pose_offset_idx = 2                                 # This is where the pose info begins in the flattened array\n        scale_offset_idx = n_particles * 7 + pose_offset_idx  # This is where the scale info begins in the flattened array\n        for i in range(n_particles):\n            poses.append([\n                state[7*i + pose_offset_idx: 7*i + pose_offset_idx + 3],\n                state[7*i + pose_offset_idx + 3: 7*(i+1) + pose_offset_idx]\n            ])      # pos, ori\n            scales.append(state[3*i + scale_offset_idx : 3*(i + 1) + scale_offset_idx])      # scale\n\n        state_dict[\"poses\"] = poses\n        state_dict[\"scales\"] = scales\n\n        # Update idx -- two from max_n_particles and n_particles + 10*n_particles for pose + scale\n        idx = 2 + n_particles * 10\n\n        template_pose, template_scale = None, None\n        # If our state size is larger than the current index we're at, this corresponds to the template info\n        if cls.state_size &gt; idx:\n            template_pose = [\n                state[idx: idx + 3],\n                state[idx + 3: idx + 7],\n            ]\n            template_scale = state[idx + 7: idx + 10]\n            idx += 10\n\n        state_dict[\"template_pose\"] = template_pose\n        state_dict[\"template_scale\"] = template_scale\n\n        return state_dict, idx\n\n    @classmethod\n    def set_particle_template_object(cls, obj):\n        \"\"\"\n        Sets the template particle object that will be used for duplication purposes. Note that this automatically\n        adds @obj itself to the ongoing array of particles!\n\n        Args:\n            obj (BasePrim): Object to serve as template\n        \"\"\"\n        # Update color if it exists and store particle object\n        color = np.ones(3)\n        if obj.has_material():\n            diffuse_texture = obj.material.diffuse_texture\n            color = plt.imread(diffuse_texture).mean(axis=(0, 1)) if diffuse_texture else obj.material.diffuse_color_constant\n        cls._color = color\n        cls.particle_object = obj\n\n    @classmethod\n    def set_scale_limits(cls, minimum=None, maximum=None):\n        \"\"\"\n        Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n\n        Args:\n            minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n                particles\n            maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n                particles\n        \"\"\"\n        if minimum is not None:\n            cls.min_scale = np.array(minimum)\n        if maximum is not None:\n            cls.max_scale = np.array(maximum)\n\n    @classmethod\n    def remove_all_particles(cls):\n        \"\"\"\n        Removes all particles and deletes them from the simulator\n        \"\"\"\n        # Use list explicitly to prevent mid-loop mutation of dict\n        for particle_name in list(cls.particles.keys()):\n            cls.remove_particle(name=particle_name)\n\n    @classmethod\n    def add_particle(cls, prim_path, idn=None, scale=None, position=None, orientation=None):\n        \"\"\"\n        Adds a particle to this system.\n\n        Args:\n            prim_path (str): Absolute path to the newly created particle, minus the name for this particle\n            idn (None or int): If specified, should be unique identifier to assign to this particle. If not, will\n                automatically generate a new unique one\n            scale (None or 3-array): Relative (x,y,z) scale of the particle, if any. If not specified, will\n                automatically be sampled based on cls.min_scale and cls.max_scale\n            position (None or 3-array): Global (x,y,z) position to set this particle to, if any\n            orientation (None or 4-array): Global (x,y,z,w) quaternion orientation to set this particle to, if any\n\n        Returns:\n            XFormPrim: Newly created particle instance, which is added internally as well\n        \"\"\"\n        # Generate the new particle\n        name = cls.particle_idn2name(idn=cls.get_next_particle_unique_idn() if idn is None else idn)\n        # Make sure name doesn't already exist\n        assert name not in cls.particles.keys(), f\"Cannot create particle with name {name} because it already exists!\"\n        new_particle = cls._load_new_particle(prim_path=f\"{prim_path}/{name}\", name=name)\n\n        # Sample the scale and also make sure the particle is visible\n        new_particle.scale *= np.random.uniform(cls.min_scale, cls.max_scale) if scale is None else scale\n        new_particle.visible = True\n\n        # Set the pose\n        new_particle.set_position_orientation(position=position, orientation=orientation)\n\n        # Track this particle as well\n        cls.particles[new_particle.name] = new_particle\n\n        # Increment idn counter\n        cls.max_particle_idn += 1\n\n        return new_particle\n\n    @classmethod\n    def remove_particle(cls, name):\n        \"\"\"\n        Remove particle with name @name from both the simulator as well as internally\n\n        Args:\n            name (str): Name of the particle to remove\n        \"\"\"\n        assert name in cls.particles, f\"Got invalid name for particle to remove {name}\"\n\n        particle = cls.particles.pop(name)\n        particle.remove(simulator=cls.simulator)\n\n    @classmethod\n    def _load_new_particle(cls, prim_path, name):\n        \"\"\"\n        Loads a new particle into the current stage, leveraging @cls.particle_object as a template for the new particle\n        to load. This function should be implemented by any subclasses.\n\n        Args:\n            prim_path (str): The absolute stage path at which to create the new particle\n            name (str): The name to assign to this new particle at the path\n\n        Returns:\n            XFormPrim: Loaded particle\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def particle_name2idn(cls, name):\n        \"\"\"\n        Args:\n            name (str): Particle name to grab its corresponding unique id number for\n\n        Returns:\n            int: Unique ID assigned to the particle based on its name\n        \"\"\"\n        assert cls.particle_name_prefix in name, \\\n            f\"Particle name should have '{cls.particle_name_prefix}' in it when checking ID! Got: {name}\"\n        return int(name.split(cls.particle_name_prefix)[-1])\n\n    @classmethod\n    def particle_idn2name(cls, idn):\n        \"\"\"\n        Args:\n            idn (int): Unique ID number assigned to the particle to grab the name for\n\n        Returns:\n            str: Particle name corresponding to its unique id number\n        \"\"\"\n        assert isinstance(idn, int), \\\n            f\"Particle idn must be an integer when checking name! Got: {idn}. Type: {type(idn)}\"\n        return f\"{cls.particle_name_prefix}{idn}\"\n\n    @classmethod\n    def get_next_particle_unique_idn(cls):\n        \"\"\"\n        Returns:\n            int: Minimum unique ID number greater than zero that can be assigned to a new particle\n                Note: This is\n        \"\"\"\n        return cls.max_particle_idn + 1\n\n    @classproperty\n    def color(cls):\n        return np.array(cls._color)\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem"},{"title":"<code>add_particle(prim_path, idn=None, scale=None, position=None, orientation=None)</code>  <code>classmethod</code>","text":"<p>Adds a particle to this system.</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Absolute path to the newly created particle, minus the name for this particle</p>  required    <code>idn</code>  <code>None or int</code>  <p>If specified, should be unique identifier to assign to this particle. If not, will automatically generate a new unique one</p>  <code>None</code>    <code>scale</code>  <code>None or 3-array</code>  <p>Relative (x,y,z) scale of the particle, if any. If not specified, will automatically be sampled based on cls.min_scale and cls.max_scale</p>  <code>None</code>    <code>position</code>  <code>None or 3-array</code>  <p>Global (x,y,z) position to set this particle to, if any</p>  <code>None</code>    <code>orientation</code>  <code>None or 4-array</code>  <p>Global (x,y,z,w) quaternion orientation to set this particle to, if any</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>XFormPrim</code>   <p>Newly created particle instance, which is added internally as well</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef add_particle(cls, prim_path, idn=None, scale=None, position=None, orientation=None):\n    \"\"\"\n    Adds a particle to this system.\n\n    Args:\n        prim_path (str): Absolute path to the newly created particle, minus the name for this particle\n        idn (None or int): If specified, should be unique identifier to assign to this particle. If not, will\n            automatically generate a new unique one\n        scale (None or 3-array): Relative (x,y,z) scale of the particle, if any. If not specified, will\n            automatically be sampled based on cls.min_scale and cls.max_scale\n        position (None or 3-array): Global (x,y,z) position to set this particle to, if any\n        orientation (None or 4-array): Global (x,y,z,w) quaternion orientation to set this particle to, if any\n\n    Returns:\n        XFormPrim: Newly created particle instance, which is added internally as well\n    \"\"\"\n    # Generate the new particle\n    name = cls.particle_idn2name(idn=cls.get_next_particle_unique_idn() if idn is None else idn)\n    # Make sure name doesn't already exist\n    assert name not in cls.particles.keys(), f\"Cannot create particle with name {name} because it already exists!\"\n    new_particle = cls._load_new_particle(prim_path=f\"{prim_path}/{name}\", name=name)\n\n    # Sample the scale and also make sure the particle is visible\n    new_particle.scale *= np.random.uniform(cls.min_scale, cls.max_scale) if scale is None else scale\n    new_particle.visible = True\n\n    # Set the pose\n    new_particle.set_position_orientation(position=position, orientation=orientation)\n\n    # Track this particle as well\n    cls.particles[new_particle.name] = new_particle\n\n    # Increment idn counter\n    cls.max_particle_idn += 1\n\n    return new_particle\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.add_particle"},{"title":"<code>get_next_particle_unique_idn()</code>  <code>classmethod</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Minimum unique ID number greater than zero that can be assigned to a new particle Note: This is</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef get_next_particle_unique_idn(cls):\n    \"\"\"\n    Returns:\n        int: Minimum unique ID number greater than zero that can be assigned to a new particle\n            Note: This is\n    \"\"\"\n    return cls.max_particle_idn + 1\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.get_next_particle_unique_idn"},{"title":"<code>n_particles()</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of active particles in this system</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef n_particles(cls):\n    \"\"\"\n    Returns:\n        int: Number of active particles in this system\n    \"\"\"\n    return len(cls.particles)\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.n_particles"},{"title":"<code>particle_idn2name(idn)</code>  <code>classmethod</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>idn</code>  <code>int</code>  <p>Unique ID number assigned to the particle to grab the name for</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Particle name corresponding to its unique id number</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef particle_idn2name(cls, idn):\n    \"\"\"\n    Args:\n        idn (int): Unique ID number assigned to the particle to grab the name for\n\n    Returns:\n        str: Particle name corresponding to its unique id number\n    \"\"\"\n    assert isinstance(idn, int), \\\n        f\"Particle idn must be an integer when checking name! Got: {idn}. Type: {type(idn)}\"\n    return f\"{cls.particle_name_prefix}{idn}\"\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.particle_idn2name"},{"title":"<code>particle_name2idn(name)</code>  <code>classmethod</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>Particle name to grab its corresponding unique id number for</p>  required     <p>Returns:</p>    Name Type Description     <code>int</code>   <p>Unique ID assigned to the particle based on its name</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef particle_name2idn(cls, name):\n    \"\"\"\n    Args:\n        name (str): Particle name to grab its corresponding unique id number for\n\n    Returns:\n        int: Unique ID assigned to the particle based on its name\n    \"\"\"\n    assert cls.particle_name_prefix in name, \\\n        f\"Particle name should have '{cls.particle_name_prefix}' in it when checking ID! Got: {name}\"\n    return int(name.split(cls.particle_name_prefix)[-1])\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.particle_name2idn"},{"title":"<code>particle_name_prefix()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Naming prefix used for all generated particles. This is coupled with the unique particle ID to generate the full particle name</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef particle_name_prefix(cls):\n    \"\"\"\n    Returns:\n        str: Naming prefix used for all generated particles. This is coupled with the unique particle ID to generate\n            the full particle name\n    \"\"\"\n    return f\"{cls.name}Particle\"\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.particle_name_prefix"},{"title":"<code>remove_all_particles()</code>  <code>classmethod</code>","text":"<p>Removes all particles and deletes them from the simulator</p>  Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_all_particles(cls):\n    \"\"\"\n    Removes all particles and deletes them from the simulator\n    \"\"\"\n    # Use list explicitly to prevent mid-loop mutation of dict\n    for particle_name in list(cls.particles.keys()):\n        cls.remove_particle(name=particle_name)\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.remove_all_particles"},{"title":"<code>remove_particle(name)</code>  <code>classmethod</code>","text":"<p>Remove particle with name @name from both the simulator as well as internally</p> <p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>Name of the particle to remove</p>  required      Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_particle(cls, name):\n    \"\"\"\n    Remove particle with name @name from both the simulator as well as internally\n\n    Args:\n        name (str): Name of the particle to remove\n    \"\"\"\n    assert name in cls.particles, f\"Got invalid name for particle to remove {name}\"\n\n    particle = cls.particles.pop(name)\n    particle.remove(simulator=cls.simulator)\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.remove_particle"},{"title":"<code>set_particle_template_object(obj)</code>  <code>classmethod</code>","text":"<p>Sets the template particle object that will be used for duplication purposes. Note that this automatically adds @obj itself to the ongoing array of particles!</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BasePrim</code>  <p>Object to serve as template</p>  required      Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef set_particle_template_object(cls, obj):\n    \"\"\"\n    Sets the template particle object that will be used for duplication purposes. Note that this automatically\n    adds @obj itself to the ongoing array of particles!\n\n    Args:\n        obj (BasePrim): Object to serve as template\n    \"\"\"\n    # Update color if it exists and store particle object\n    color = np.ones(3)\n    if obj.has_material():\n        diffuse_texture = obj.material.diffuse_texture\n        color = plt.imread(diffuse_texture).mean(axis=(0, 1)) if diffuse_texture else obj.material.diffuse_color_constant\n    cls._color = color\n    cls.particle_object = obj\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.set_particle_template_object"},{"title":"<code>set_scale_limits(minimum=None, maximum=None)</code>  <code>classmethod</code>","text":"<p>Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles</p> <p>Parameters:</p>    Name Type Description Default     <code>minimum</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) minimum scaling factor to apply to generated particles</p>  <code>None</code>    <code>maximum</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) maximum scaling factor to apply to generated particles</p>  <code>None</code>      Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef set_scale_limits(cls, minimum=None, maximum=None):\n    \"\"\"\n    Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n\n    Args:\n        minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n            particles\n        maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n            particles\n    \"\"\"\n    if minimum is not None:\n        cls.min_scale = np.array(minimum)\n    if maximum is not None:\n        cls.max_scale = np.array(maximum)\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.MacroParticleSystem.set_scale_limits"},{"title":"<code>VisualParticleSystem</code>","text":"<p>         Bases: <code>MacroParticleSystem</code></p> <p>Particle system class that additionally includes sampling utilities for placing particles on specific objects</p>  Source code in <code>systems/macro_particle_system.py</code> <pre><code>class VisualParticleSystem(MacroParticleSystem):\n    \"\"\"\n    Particle system class that additionally includes sampling utilities for placing particles on specific objects\n    \"\"\"\n    # Maps group name to the particles associated with it\n    # This is an ordered dict of ordered dict (nested ordered dict maps particle names to particle instance)\n    _group_particles = None\n\n    # Maps group name to the parent object (the object with particles attached to it) of the group\n    _group_objects = None\n\n    # Default behavior for this class -- whether to clip generated particles halfway into objects when sampling\n    # their locations on the surface of the given object\n    _CLIP_INTO_OBJECTS = False\n\n    # Default number of particles to sample per group\n    _N_PARTICLES_PER_GROUP = 20\n\n    # Default parameters for sampling particle locations\n    # See omnigibson/utils/sampling_utils.py for how they are used.\n    _SAMPLING_AXIS_PROBABILITIES = (0.25, 0.25, 0.5)\n    _SAMPLING_AABB_OFFSET = 0.01\n    _SAMPLING_BIMODAL_MEAN_FRACTION = 0.9\n    _SAMPLING_BIMODAL_STDEV_FRACTION = 0.2\n    _SAMPLING_MAX_ATTEMPTS = 20\n\n    @classmethod\n    def initialize(cls, simulator):\n        # Run super method first\n        super().initialize(simulator=simulator)\n\n        # Initialize mutable class variables so they don't automatically get overridden by children classes\n        cls._group_particles = OrderedDict()\n        cls._group_objects = OrderedDict()\n\n    @classproperty\n    def groups(cls):\n        \"\"\"\n        Returns:\n            set of str: Current attachment particle group names\n        \"\"\"\n        return set(cls._group_particles.keys())\n\n    @classproperty\n    def state_size(cls):\n        # Get super size first\n        state_size = super().state_size\n\n        # Additionally, we have n_groups (1), with m_particles for each group (n), attached_obj_uuids (n), and\n        # particle ids and corresponding link info for each particle (m * 2)\n        return state_size + 1 + 2 * len(cls._group_particles) + \\\n               sum([2 * cls.num_group_particles(group) for group in cls.groups])\n\n    @classmethod\n    def _load_new_particle(cls, prim_path, name):\n        # We copy the template prim and generate the new object if the prim doesn't already exist, otherwise we\n        # reference the pre-existing one\n        if not get_prim_at_path(prim_path):\n            omni.kit.commands.execute(\n                \"CopyPrim\",\n                path_from=cls.particle_object.prim_path,\n                path_to=prim_path,\n            )\n        return VisualGeomPrim(prim_path=prim_path, name=name)\n\n    @classmethod\n    def set_particle_template_object(cls, obj):\n        # Sanity check to make sure the added object is an instance of VisualGeomPrim\n        assert isinstance(obj, VisualGeomPrim), \\\n            f\"Particle template object for {cls.name} must be a VisualGeomPrim instance!\"\n\n        # Run super method\n        super().set_particle_template_object(obj=obj)\n\n    @classmethod\n    def remove_all_particles(cls):\n        # Run super method first\n        super().remove_all_particles()\n\n        # Clear all groups as well\n        cls._group_particles = OrderedDict()\n        cls._group_objects = OrderedDict()\n\n    @classmethod\n    def remove_particle(cls, name):\n        \"\"\"\n        Remove particle with name @name from both the simulator as well as internally\n\n        Args:\n            name (str): Name of the particle to remove\n        \"\"\"\n        # Run super first\n        super().remove_particle(name=name)\n\n        # Remove this particle from its respective group as well\n        for group in cls._group_particles.values():\n            # Maybe make this better? We have to manually search through the groups for this particle\n            if name in group:\n                group.pop(name)\n                break\n\n    @classmethod\n    def remove_all_group_particles(cls, group):\n        \"\"\"\n        Remove particle with name @name from both the simulator as well as internally\n\n        Args:\n            group (str): Name of the attachment group to remove all particles from\n        \"\"\"\n        # Make sure the group exists\n        cls._validate_group(group=group)\n        # Remove all particles from the group\n        for particle_name in list(cls._group_particles[group].keys()):\n            cls.remove_particle(name=particle_name)\n\n    @classmethod\n    def num_group_particles(cls, group):\n        \"\"\"\n        Gets the number of particles for the given group in the simulator\n\n        Args:\n            group (str): Name of the attachment group to remove all particles from.\n\n        Returns:\n            int: Number of particles allocated to this group in the scene. Note that if @group does not\n                exist, this will return 0\n        \"\"\"\n        # Make sure the group exists\n        cls._validate_group(group=group)\n        return len(cls._group_particles[group])\n\n    @classmethod\n    def get_group_name(cls, obj):\n        \"\"\"\n        Grabs the corresponding group name for object @obj\n\n        Args:\n            obj (BaseObject): Object for which its procedurally generated particle attachment name should be grabbed\n\n        Returns:\n            str: Name of the attachment group to use when executing commands from this class on\n                that specific attachment group\n        \"\"\"\n        return obj.name\n\n    @classmethod\n    def create_attachment_group(cls, obj):\n        \"\"\"\n        Creates an attachment group internally for object @obj. Note that this does NOT automatically generate particles\n        for this object (should call generate_group_particles(...) ).\n\n        Args:\n            obj (BaseObject): Object for which a new particle attachment group will be created for\n\n        Returns:\n            str: Name of the attachment group to use when executing commands from this class on\n                that specific attachment group\n        \"\"\"\n        group = cls.get_group_name(obj=obj)\n        # This should only happen once for a single attachment group, so we explicitly check to make sure the object\n        # doesn't already exist\n        assert group not in cls.groups, \\\n            f\"Cannot create new attachment group because group with name {group} already exists!\"\n\n        # Create the group\n        cls._group_particles[group] = OrderedDict()\n        cls._group_objects[group] = obj\n\n        return group\n\n    @classmethod\n    def remove_attachment_group(cls, group):\n        \"\"\"\n        Removes an attachment group internally for object @obj. Note that this will automatically remove any particles\n        currently assigned to that group\n\n        Args:\n            group (str): Name of the attachment group to remove\n\n        Returns:\n            str: Name of the attachment group to use when executing commands from this class on\n                that specific attachment group\n        \"\"\"\n        # Make sure the group exists\n        cls._validate_group(group=group)\n\n        # Remove all particles from the group\n        cls.remove_all_group_particles(group=group)\n\n        # Remove the actual groups\n        cls._group_particles.pop(group)\n        cls._group_objects.pop(group)\n\n        return group\n\n    @classmethod\n    def update_particle_scaling(cls, group):\n        \"\"\"\n        Update particle scaling for group @group before generating group particles. Default is a no-op\n        (i.e.: returns the current cls.min_scale, cls.max_scale)\n\n        Args:\n            group (str): Specific group for which to modify the particle scaling\n\n        Returns:\n            2-tuple:\n                - 3-array: min scaling factor to set\n                - 3-array: max scaling factor to set\n        \"\"\"\n        return cls.min_scale, cls.max_scale\n\n    @classmethod\n    def sample_scales(cls, group, n):\n        \"\"\"\n        Samples @n particle scales for group @group.\n\n        Args:\n            group (str): Specific group for which to sample scales\n            n (int): Number of scales to sample\n\n        Returns:\n            (n, 3) array: Array of sampled scales\n        \"\"\"\n        # Make sure the group exists\n        cls._validate_group(group=group)\n\n        # Update scaling and grab object\n        cls.set_scale_limits(*cls.update_particle_scaling(group=group))\n        obj = cls._group_objects[group]\n\n        # Sample scales of the particles to generate\n        # Since the particles will be placed under the object, it will be affected/stretched by obj.scale. In order to\n        # preserve the absolute size of the particles, we need to scale the particle by obj.scale in some way. However,\n        # since the particles have a relative rotation w.r.t the object, the scale between the two don't align. As a\n        # heuristics, we divide it by the avg_scale, which is the cubic root of the product of the scales along 3 axes.\n        avg_scale = np.cbrt(np.product(obj.scale))\n        return np.random.uniform(cls.min_scale, cls.max_scale, (n, 3)) / avg_scale\n\n    @classmethod\n    def generate_group_particles(\n            cls,\n            group,\n            positions,\n            orientations=None,\n            scales=None,\n            link_prim_paths=None,\n    ):\n        \"\"\"\n        Generates new particle objects within group @group at the specified pose (@positions, @orientations) with\n        corresponding scales @scales.\n\n        NOTE: Assumes positions are the exact contact point on @group object's surface. If cls._CLIP_INTO_OBJECTS\n            is not True, then the positions will be offset away from the object by half of its bbox\n\n        Args:\n            group (str): Object on which to sample particle locations\n            positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions\n            orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n                orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n            scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scaling in its\n                local frame. If not specified, all we randomly sampled based on @cls.min_scale and @cls.max_scale\n            link_prim_paths (None or list of str): Determines which link each generated particle will\n                be attached to. If not specified, all will be attached to the group object's root link\n        \"\"\"\n        # Make sure the group exists\n        cls._validate_group(group=group)\n\n        # Update scaling\n        cls.set_scale_limits(*cls.update_particle_scaling(group=group))\n\n        # Standardize orientations and links\n        obj = cls._group_objects[group]\n        n_particles = positions.shape[0]\n        if orientations is None:\n            orientations = np.zeros((n_particles, 4))\n            orientations[:, -1] = 1.0\n        link_prim_paths = [obj.root_link.prim_path] * n_particles if link_prim_paths is None else link_prim_paths\n\n        if scales is None:\n            scales = cls.sample_scales(group=group, n=n_particles)\n        bbox_extents_local = [(cls.particle_object.aabb_extent * scale).tolist() for scale in scales]\n\n        # Generate particles\n        z_up = np.zeros((3, 1))\n        z_up[-1] = 1.0\n        for position, orientation, scale, bbox_extent_local, link_prim_path in \\\n                zip(positions, orientations, scales, bbox_extents_local, link_prim_paths):\n            # Possibly shift the particle slightly away from the object if we're not clipping into objects\n            if cls._CLIP_INTO_OBJECTS:\n                # Shift the particle halfway down\n                base_to_center = bbox_extent_local[2] / 2.0\n                normal = (T.quat2mat(orientation) @ z_up).flatten()\n                position -= normal * base_to_center\n\n            # Create particle\n            particle = cls.add_particle(\n                prim_path=link_prim_path,\n                position=position,\n                orientation=orientation,\n                scale=scale,\n            )\n\n            # Add to group\n            cls._group_particles[group][particle.name] = particle\n\n    @classmethod\n    def generate_group_particles_on_object(cls, group, n_particles=None, min_particles_for_success=1):\n        \"\"\"\n        Generates @n_particles new particle objects and samples their locations on the surface of object @obj. Note\n        that if any objects are in the group already, they will be removed\n\n        Args:\n            group (str): Object on which to sample particle locations\n            n_particles (None or int): Number of particles to sample on the surface of @obj. If None, default number\n                will be used (cls._N_PARTICLES_PER_GROUP)\n            min_particles_for_success (int): Minimum number of particles required to be sampled successfully in order\n                for this generation process to be considered successful\n\n        Returns:\n            bool: True if enough particles were generated successfully (number of successfully sampled points &gt;=\n                min_particles_for_success), otherwise False\n        \"\"\"\n        # Make sure the group exists\n        cls._validate_group(group=group)\n\n        # Remove all stale particles\n        cls.remove_all_group_particles(group=group)\n\n        # Generate requested number of particles\n        obj = cls._group_objects[group]\n\n        # Sample scales of the particles to generate\n        n_particles = cls._N_PARTICLES_PER_GROUP if n_particles is None else n_particles\n\n        # Sample scales and corresponding bbox extents\n        scales = cls.sample_scales(group=group, n=n_particles)\n        # For sampling particle positions, we need the global bbox extents, NOT the local extents\n        # which is what we would get naively if we directly use @scales\n        avg_scale = np.cbrt(np.product(obj.scale))\n        bbox_extents_global = [(cls.particle_object.aabb_extent * scale * avg_scale).tolist() for scale in scales]\n\n        # Sample locations for all particles\n        # TODO: Does simulation need to play at this point in time? Answer: yes\n        results = sample_cuboid_on_object_symmetric_bimodal_distribution(\n            obj=obj,\n            num_samples=n_particles,\n            cuboid_dimensions=bbox_extents_global,\n            bimodal_mean_fraction=cls._SAMPLING_BIMODAL_MEAN_FRACTION,\n            bimodal_stdev_fraction=cls._SAMPLING_BIMODAL_STDEV_FRACTION,\n            axis_probabilities=cls._SAMPLING_AXIS_PROBABILITIES,\n            undo_cuboid_bottom_padding=True,\n            aabb_offset=cls._SAMPLING_AABB_OFFSET,\n            max_sampling_attempts=cls._SAMPLING_MAX_ATTEMPTS,\n            refuse_downwards=True,\n        )\n\n        # Use sampled points\n        positions, orientations, particle_scales, link_prim_paths = [], [], [], []\n        for result, scale in zip(results, scales):\n            position, normal, quaternion, hit_link, reasons = result\n            if position is not None:\n                positions.append(position)\n                orientations.append(quaternion)\n                particle_scales.append(scale)\n                link_prim_paths.append(hit_link)\n\n        success = len(positions) &gt;= min_particles_for_success\n        # If we generated a sufficient number of points, generate them in the simulator\n        if success:\n            cls.generate_group_particles(\n                group=group,\n                positions=np.array(positions),\n                orientations=np.array(orientations),\n                scales=np.array(scales),\n                link_prim_paths=link_prim_paths,\n            )\n\n        return success\n\n    @classmethod\n    def _validate_group(cls, group):\n        \"\"\"\n        Checks if particle attachment group @group exists. (If not, can create the group via create_attachment_group).\n        This will raise a ValueError if it doesn't exist.\n\n        Args:\n            group: Name of the group to check for\n        \"\"\"\n        if group not in cls.groups:\n            raise ValueError(f\"Particle attachment group {group} does not exist!\")\n\n    @classmethod\n    def _sync_particle_groups(cls, group_objects, particle_idns, particle_attached_link_names):\n        \"\"\"\n        Synchronizes the particle groups based on desired identification numbers @group_idns\n\n        Args:\n            group_objects (list of None or BaseObject): Desired unique group objects that should be active for\n            this particle system. Any objects that aren't found will be skipped over\n            particle_idns (list of list of int): Per-group unique id numbers for the particles assigned to that group.\n                List should be same length as @group_idns with sub-entries corresponding to the desired number of\n                particles assigned to that group\n            particle_attached_link_names (list of list of str): Per-group link names corresponding to the specific\n                links each particle is attached for each group. List should be same length as @group_idns with\n                sub-entries corresponding to the desired number of particles assigned to that group\n        \"\"\"\n        # We have to be careful here -- some particle groups may have been deleted / are mismatched, so we need\n        # to update accordingly, potentially deleting stale groups and creating new groups as needed\n        name_to_info_mapping = {obj.name: {\n            \"n_particles\": len(p_idns),\n            \"particle_idns\": p_idns,\n            \"link_names\": link_names,\n        }\n            for obj, p_idns, link_names in\n            zip(group_objects, particle_idns, particle_attached_link_names) if obj is not None}\n\n        current_group_names = cls.groups\n        desired_group_names = set(obj.name for obj in group_objects if obj is not None)\n        groups_to_delete = current_group_names - desired_group_names\n        groups_to_create = desired_group_names - current_group_names\n        common_groups = current_group_names.intersection(desired_group_names)\n\n        # Sanity check the common groups, we will recreate any where there is a mismatch\n        for name in common_groups:\n            info = name_to_info_mapping[name]\n            if cls.num_group_particles(group=name) != info[\"n_particles\"]:\n                logging.debug(f\"Got mismatch in particle group {name} when syncing, \"\n                                f\"deleting and recreating group now.\")\n                # Add this group to both the delete and creation pile\n                groups_to_delete.add(name)\n                groups_to_create.add(name)\n\n        # Delete any groups we no longer want\n        for name in groups_to_delete:\n            cls.remove_attachment_group(group=name)\n\n        # Create any groups we don't already have\n        for name in groups_to_create:\n            obj = cls.simulator.scene.object_registry(\"name\", name)\n            info = name_to_info_mapping[name]\n            cls.create_attachment_group(obj=obj)\n\n            for particle_idn, link_name in zip(info[\"particle_idns\"], info[\"link_names\"]):\n                # Create the necessary particles\n                particle = cls.add_particle(\n                    prim_path=f\"{obj.prim_path}/{link_name}\",\n                    idn=int(particle_idn),\n                )\n                cls._group_particles[name][particle.name] = particle\n\n    @classmethod\n    def create(cls, particle_name, n_particles_per_group, create_particle_template, min_scale=None, max_scale=None, **kwargs):\n        \"\"\"\n        Utility function to programmatically generate monolithic visual particle system classes.\n\n        Note: If using super() calls in any functions, we have to use slightly esoteric syntax in order to\n        accommodate this procedural method for using super calls\n        cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\n            Use: super(cls).__get__(cls).&lt;METHOD_NAME&gt;(&lt;KWARGS&gt;)\n\n        Args:\n            particle_name (str): Name of the visual particles\n            n_particles_per_group (int): Number of particles to generate per group of these particles\n            min_scale (None or 3-array): If specified, sets the minumum bound for the visual particles' relative scale.\n                Else, defaults to 1\n            max_scale (None or 3-array): If specified, sets the maximum bound for the visual particles' relative scale.\n                Else, defaults to 1\n            create_particle_template (function): Method for generating the visual particle template that will be duplicated\n                when generating groups of particles.\n                Expected signature:\n\n                create_particle_template(prim_path: str, name: str) --&gt; EntityPrim\n\n                where @prim_path and @name are the parameters to assign to the generated EntityPrim.\n                NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n                    visual mesh attached to its root link, since this will be the actual visual mesh used\n\n            **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n                the class attribute to modify and the values represent the functions / value to set\n                (Note: These values should have either @classproperty or @classmethod decorators!)\n\n        Returns:\n            VisualParticleSystem: Generated visual particle system class\n        \"\"\"\n        # Override the necessary parameters\n        @classproperty\n        def cp_register_system(cls):\n            # We should register this system since it's an \"actual\" system (not an intermediate class)\n            return True\n\n        @classmethod\n        def cm_initialize(cls, simulator):\n            # Run super first (we have to use a bit esoteric syntax in order to accommodate this procedural method for\n            # using super calls -- cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\n            super(cls).__get__(cls).initialize(simulator=simulator)\n\n            # Potentially override the min / max scales\n            if min_scale is not None:\n                cls.min_scale = np.array(min_scale)\n            if max_scale is not None:\n                cls.max_scale = np.array(max_scale)\n\n        @classmethod\n        def cm_create_particle_template(cls):\n            name = f\"{particle_name}_template\"\n            return create_particle_template(prim_path=f\"/World/{cls.name}/{name}\", name=name)\n\n        # Add to any other params specified\n        kwargs[\"_register_system\"] = cp_register_system\n        kwargs[\"_N_PARTICLES_PER_GROUP\"] = n_particles_per_group\n        kwargs[\"initialize\"] = cm_initialize\n        kwargs[\"_create_particle_template\"] = cm_create_particle_template\n\n        # Create and return the class\n        return subclass_factory(name=f\"{particle_name}System\", base_classes=cls, **kwargs)\n\n    @classmethod\n    def _dump_state(cls):\n        state = super()._dump_state()\n\n        # Add in per-group information\n        groups_dict = OrderedDict()\n        for group_name, group_particles in cls._group_particles.items():\n            groups_dict[group_name] = OrderedDict(\n                particle_attached_obj_uuid=cls._group_objects[group_name].uuid,\n                n_particles=len(group_particles),\n                particle_idns=[cls.particle_name2idn(name=name) for name in group_particles.keys()],\n                particle_attached_link_names=[prim.prim_path.split(\"/\")[-2] for prim in group_particles.values()],\n            )\n\n        state[\"n_groups\"] = len(cls._group_particles)\n        state[\"groups\"] = groups_dict\n\n        return state\n\n    @classmethod\n    def _load_state(cls, state):\n        # First, we sync our particle systems\n        \"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to set\n        \"\"\"\n        # Make sure max particle index is updated\n        cls.max_particle_idn = state[\"max_particle_idn\"]\n\n        # Synchronize particle groups\n        cls._sync_particle_groups(\n            group_objects=[cls.simulator.scene.object_registry(\"uuid\", info[\"particle_attached_obj_uuid\"], None)\n                           for info in state[\"groups\"].values()],\n            particle_idns=[info[\"particle_idns\"] for info in state[\"groups\"].values()],\n            particle_attached_link_names=[info[\"particle_attached_link_names\"] for info in state[\"groups\"].values()],\n        )\n\n        # Sanity check loading particles\n        assert cls.n_particles == state[\"n_particles\"], f\"Inconsistent number of particles found when loading \" \\\n                                                        f\"particles state! Current number: {cls.n_particles}, \" \\\n                                                        f\"loaded number: {state['n_particles']}\"\n\n        # Run super\n        super()._load_state(state=state)\n\n    @classmethod\n    def _serialize(cls, state):\n        # Run super first\n        state_flat = super()._serialize(state=state)\n\n        groups_dict = state[\"groups\"]\n        state_group_flat = [[state[\"n_groups\"]]]\n        for group_name, group_dict in groups_dict.items():\n            group_obj_link2id = {link_name: i for i, link_name in enumerate(cls._group_objects[group_name].links.keys())}\n            state_group_flat += [\n                [group_dict[\"particle_attached_obj_uuid\"]],\n                [group_dict[\"n_particles\"]],\n                group_dict[\"particle_idns\"],\n                [group_obj_link2id[link_name] for link_name in group_dict[\"particle_attached_link_names\"]],\n            ]\n\n        return np.concatenate([*state_group_flat, state_flat]).astype(float)\n\n    @classmethod\n    def _deserialize(cls, state):\n        # Synchronize the particle groups\n        n_groups = int(state[0])\n        groups_dict = OrderedDict()\n        group_objs = []\n        # Index starts at 1 because index 0 is n_groups\n        idx = 1\n        for i in range(n_groups):\n            obj_uuid, n_particles = int(state[idx]), int(state[idx + 1])\n            obj = cls.simulator.scene.object_registry(\"uuid\", obj_uuid)\n            group_obj_id2link = {i: link_name for i, link_name in enumerate(obj.links.keys())}\n            group_objs.append(obj)\n            groups_dict[obj.name] = OrderedDict(\n                particle_attached_obj_uuid=obj_uuid,\n                n_particles=n_particles,\n                particle_idns=[int(idn) for idn in state[idx + 2 : idx + 2 + n_particles]], # Idx + 2 because the first two are obj_uuid and n_particles\n                particle_attached_link_names=[group_obj_id2link[int(idn)] for idn in state[idx + 2 + n_particles : idx + 2 + n_particles * 2]],\n            )\n            idx += 2 + n_particles * 2\n        logging.debug(f\"Syncing {cls.name} particles with {n_groups} groups..\")\n        cls._sync_particle_groups(\n            group_objects=group_objs,\n            particle_idns=[group_info[\"particle_idns\"] for group_info in groups_dict.values()],\n            particle_attached_link_names=[group_info[\"particle_attached_link_names\"] for group_info in groups_dict.values()],\n        )\n\n        # Get super method\n        state_dict, idx_super = super()._deserialize(state=state[idx:])\n        state_dict[\"groups\"] = groups_dict\n\n        return state_dict, idx + idx_super\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem"},{"title":"<code>create(particle_name, n_particles_per_group, create_particle_template, min_scale=None, max_scale=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Utility function to programmatically generate monolithic visual particle system classes.</p> <p>Note: If using super() calls in any functions, we have to use slightly esoteric syntax in order to accommodate this procedural method for using super calls cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python     Use: super(cls).get(cls).() <p>Parameters:</p>    Name Type Description Default     <code>particle_name</code>  <code>str</code>  <p>Name of the visual particles</p>  required    <code>n_particles_per_group</code>  <code>int</code>  <p>Number of particles to generate per group of these particles</p>  required    <code>min_scale</code>  <code>None or 3-array</code>  <p>If specified, sets the minumum bound for the visual particles' relative scale. Else, defaults to 1</p>  <code>None</code>    <code>max_scale</code>  <code>None or 3-array</code>  <p>If specified, sets the maximum bound for the visual particles' relative scale. Else, defaults to 1</p>  <code>None</code>    <code>create_particle_template</code>  <code>function</code>  <p>Method for generating the visual particle template that will be duplicated when generating groups of particles. Expected signature:</p> <p>create_particle_template(prim_path: str, name: str) --&gt; EntityPrim</p> <p>where @prim_path and @name are the parameters to assign to the generated EntityPrim. NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single     visual mesh attached to its root link, since this will be the actual visual mesh used</p>  required    <code>**kwargs</code>  <code>any</code>  <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class attribute to modify and the values represent the functions / value to set (Note: These values should have either @classproperty or @classmethod decorators!)</p>  <code>{}</code>     <p>Returns:</p>    Name Type Description     <code>VisualParticleSystem</code>   <p>Generated visual particle system class</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef create(cls, particle_name, n_particles_per_group, create_particle_template, min_scale=None, max_scale=None, **kwargs):\n    \"\"\"\n    Utility function to programmatically generate monolithic visual particle system classes.\n\n    Note: If using super() calls in any functions, we have to use slightly esoteric syntax in order to\n    accommodate this procedural method for using super calls\n    cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\n        Use: super(cls).__get__(cls).&lt;METHOD_NAME&gt;(&lt;KWARGS&gt;)\n\n    Args:\n        particle_name (str): Name of the visual particles\n        n_particles_per_group (int): Number of particles to generate per group of these particles\n        min_scale (None or 3-array): If specified, sets the minumum bound for the visual particles' relative scale.\n            Else, defaults to 1\n        max_scale (None or 3-array): If specified, sets the maximum bound for the visual particles' relative scale.\n            Else, defaults to 1\n        create_particle_template (function): Method for generating the visual particle template that will be duplicated\n            when generating groups of particles.\n            Expected signature:\n\n            create_particle_template(prim_path: str, name: str) --&gt; EntityPrim\n\n            where @prim_path and @name are the parameters to assign to the generated EntityPrim.\n            NOTE: The loaded particle template is expected to be a non-articulated, single-link object with a single\n                visual mesh attached to its root link, since this will be the actual visual mesh used\n\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class attribute to modify and the values represent the functions / value to set\n            (Note: These values should have either @classproperty or @classmethod decorators!)\n\n    Returns:\n        VisualParticleSystem: Generated visual particle system class\n    \"\"\"\n    # Override the necessary parameters\n    @classproperty\n    def cp_register_system(cls):\n        # We should register this system since it's an \"actual\" system (not an intermediate class)\n        return True\n\n    @classmethod\n    def cm_initialize(cls, simulator):\n        # Run super first (we have to use a bit esoteric syntax in order to accommodate this procedural method for\n        # using super calls -- cf. https://stackoverflow.com/questions/22403897/what-does-it-mean-by-the-super-object-returned-is-unbound-in-python\n        super(cls).__get__(cls).initialize(simulator=simulator)\n\n        # Potentially override the min / max scales\n        if min_scale is not None:\n            cls.min_scale = np.array(min_scale)\n        if max_scale is not None:\n            cls.max_scale = np.array(max_scale)\n\n    @classmethod\n    def cm_create_particle_template(cls):\n        name = f\"{particle_name}_template\"\n        return create_particle_template(prim_path=f\"/World/{cls.name}/{name}\", name=name)\n\n    # Add to any other params specified\n    kwargs[\"_register_system\"] = cp_register_system\n    kwargs[\"_N_PARTICLES_PER_GROUP\"] = n_particles_per_group\n    kwargs[\"initialize\"] = cm_initialize\n    kwargs[\"_create_particle_template\"] = cm_create_particle_template\n\n    # Create and return the class\n    return subclass_factory(name=f\"{particle_name}System\", base_classes=cls, **kwargs)\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.create"},{"title":"<code>create_attachment_group(obj)</code>  <code>classmethod</code>","text":"<p>Creates an attachment group internally for object @obj. Note that this does NOT automatically generate particles for this object (should call generate_group_particles(...) ).</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object for which a new particle attachment group will be created for</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of the attachment group to use when executing commands from this class on that specific attachment group</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef create_attachment_group(cls, obj):\n    \"\"\"\n    Creates an attachment group internally for object @obj. Note that this does NOT automatically generate particles\n    for this object (should call generate_group_particles(...) ).\n\n    Args:\n        obj (BaseObject): Object for which a new particle attachment group will be created for\n\n    Returns:\n        str: Name of the attachment group to use when executing commands from this class on\n            that specific attachment group\n    \"\"\"\n    group = cls.get_group_name(obj=obj)\n    # This should only happen once for a single attachment group, so we explicitly check to make sure the object\n    # doesn't already exist\n    assert group not in cls.groups, \\\n        f\"Cannot create new attachment group because group with name {group} already exists!\"\n\n    # Create the group\n    cls._group_particles[group] = OrderedDict()\n    cls._group_objects[group] = obj\n\n    return group\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.create_attachment_group"},{"title":"<code>generate_group_particles(group, positions, orientations=None, scales=None, link_prim_paths=None)</code>  <code>classmethod</code>","text":"<p>Generates new particle objects within group @group at the specified pose (@positions, @orientations) with corresponding scales @scales.</p>  Assumes positions are the exact contact point on @group object's surface. If cls._CLIP_INTO_OBJECTS <p>is not True, then the positions will be offset away from the object by half of its bbox</p>  <p>Parameters:</p>    Name Type Description Default     <code>group</code>  <code>str</code>  <p>Object on which to sample particle locations</p>  required    <code>positions</code>  <code>np.array</code>  <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) positions</p>  required    <code>orientations</code>  <code>None or np.array</code>  <p>(n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)</p>  <code>None</code>    <code>scales</code>  <code>None or np.array</code>  <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) scaling in its local frame. If not specified, all we randomly sampled based on @cls.min_scale and @cls.max_scale</p>  <code>None</code>    <code>link_prim_paths</code>  <code>None or list of str</code>  <p>Determines which link each generated particle will be attached to. If not specified, all will be attached to the group object's root link</p>  <code>None</code>      Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef generate_group_particles(\n        cls,\n        group,\n        positions,\n        orientations=None,\n        scales=None,\n        link_prim_paths=None,\n):\n    \"\"\"\n    Generates new particle objects within group @group at the specified pose (@positions, @orientations) with\n    corresponding scales @scales.\n\n    NOTE: Assumes positions are the exact contact point on @group object's surface. If cls._CLIP_INTO_OBJECTS\n        is not True, then the positions will be offset away from the object by half of its bbox\n\n    Args:\n        group (str): Object on which to sample particle locations\n        positions (np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions\n        orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n            orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scaling in its\n            local frame. If not specified, all we randomly sampled based on @cls.min_scale and @cls.max_scale\n        link_prim_paths (None or list of str): Determines which link each generated particle will\n            be attached to. If not specified, all will be attached to the group object's root link\n    \"\"\"\n    # Make sure the group exists\n    cls._validate_group(group=group)\n\n    # Update scaling\n    cls.set_scale_limits(*cls.update_particle_scaling(group=group))\n\n    # Standardize orientations and links\n    obj = cls._group_objects[group]\n    n_particles = positions.shape[0]\n    if orientations is None:\n        orientations = np.zeros((n_particles, 4))\n        orientations[:, -1] = 1.0\n    link_prim_paths = [obj.root_link.prim_path] * n_particles if link_prim_paths is None else link_prim_paths\n\n    if scales is None:\n        scales = cls.sample_scales(group=group, n=n_particles)\n    bbox_extents_local = [(cls.particle_object.aabb_extent * scale).tolist() for scale in scales]\n\n    # Generate particles\n    z_up = np.zeros((3, 1))\n    z_up[-1] = 1.0\n    for position, orientation, scale, bbox_extent_local, link_prim_path in \\\n            zip(positions, orientations, scales, bbox_extents_local, link_prim_paths):\n        # Possibly shift the particle slightly away from the object if we're not clipping into objects\n        if cls._CLIP_INTO_OBJECTS:\n            # Shift the particle halfway down\n            base_to_center = bbox_extent_local[2] / 2.0\n            normal = (T.quat2mat(orientation) @ z_up).flatten()\n            position -= normal * base_to_center\n\n        # Create particle\n        particle = cls.add_particle(\n            prim_path=link_prim_path,\n            position=position,\n            orientation=orientation,\n            scale=scale,\n        )\n\n        # Add to group\n        cls._group_particles[group][particle.name] = particle\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.generate_group_particles"},{"title":"<code>generate_group_particles_on_object(group, n_particles=None, min_particles_for_success=1)</code>  <code>classmethod</code>","text":"<p>Generates @n_particles new particle objects and samples their locations on the surface of object @obj. Note that if any objects are in the group already, they will be removed</p> <p>Parameters:</p>    Name Type Description Default     <code>group</code>  <code>str</code>  <p>Object on which to sample particle locations</p>  required    <code>n_particles</code>  <code>None or int</code>  <p>Number of particles to sample on the surface of @obj. If None, default number will be used (cls._N_PARTICLES_PER_GROUP)</p>  <code>None</code>    <code>min_particles_for_success</code>  <code>int</code>  <p>Minimum number of particles required to be sampled successfully in order for this generation process to be considered successful</p>  <code>1</code>     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if enough particles were generated successfully (number of successfully sampled points &gt;= min_particles_for_success), otherwise False</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef generate_group_particles_on_object(cls, group, n_particles=None, min_particles_for_success=1):\n    \"\"\"\n    Generates @n_particles new particle objects and samples their locations on the surface of object @obj. Note\n    that if any objects are in the group already, they will be removed\n\n    Args:\n        group (str): Object on which to sample particle locations\n        n_particles (None or int): Number of particles to sample on the surface of @obj. If None, default number\n            will be used (cls._N_PARTICLES_PER_GROUP)\n        min_particles_for_success (int): Minimum number of particles required to be sampled successfully in order\n            for this generation process to be considered successful\n\n    Returns:\n        bool: True if enough particles were generated successfully (number of successfully sampled points &gt;=\n            min_particles_for_success), otherwise False\n    \"\"\"\n    # Make sure the group exists\n    cls._validate_group(group=group)\n\n    # Remove all stale particles\n    cls.remove_all_group_particles(group=group)\n\n    # Generate requested number of particles\n    obj = cls._group_objects[group]\n\n    # Sample scales of the particles to generate\n    n_particles = cls._N_PARTICLES_PER_GROUP if n_particles is None else n_particles\n\n    # Sample scales and corresponding bbox extents\n    scales = cls.sample_scales(group=group, n=n_particles)\n    # For sampling particle positions, we need the global bbox extents, NOT the local extents\n    # which is what we would get naively if we directly use @scales\n    avg_scale = np.cbrt(np.product(obj.scale))\n    bbox_extents_global = [(cls.particle_object.aabb_extent * scale * avg_scale).tolist() for scale in scales]\n\n    # Sample locations for all particles\n    # TODO: Does simulation need to play at this point in time? Answer: yes\n    results = sample_cuboid_on_object_symmetric_bimodal_distribution(\n        obj=obj,\n        num_samples=n_particles,\n        cuboid_dimensions=bbox_extents_global,\n        bimodal_mean_fraction=cls._SAMPLING_BIMODAL_MEAN_FRACTION,\n        bimodal_stdev_fraction=cls._SAMPLING_BIMODAL_STDEV_FRACTION,\n        axis_probabilities=cls._SAMPLING_AXIS_PROBABILITIES,\n        undo_cuboid_bottom_padding=True,\n        aabb_offset=cls._SAMPLING_AABB_OFFSET,\n        max_sampling_attempts=cls._SAMPLING_MAX_ATTEMPTS,\n        refuse_downwards=True,\n    )\n\n    # Use sampled points\n    positions, orientations, particle_scales, link_prim_paths = [], [], [], []\n    for result, scale in zip(results, scales):\n        position, normal, quaternion, hit_link, reasons = result\n        if position is not None:\n            positions.append(position)\n            orientations.append(quaternion)\n            particle_scales.append(scale)\n            link_prim_paths.append(hit_link)\n\n    success = len(positions) &gt;= min_particles_for_success\n    # If we generated a sufficient number of points, generate them in the simulator\n    if success:\n        cls.generate_group_particles(\n            group=group,\n            positions=np.array(positions),\n            orientations=np.array(orientations),\n            scales=np.array(scales),\n            link_prim_paths=link_prim_paths,\n        )\n\n    return success\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.generate_group_particles_on_object"},{"title":"<code>get_group_name(obj)</code>  <code>classmethod</code>","text":"<p>Grabs the corresponding group name for object @obj</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object for which its procedurally generated particle attachment name should be grabbed</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of the attachment group to use when executing commands from this class on that specific attachment group</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef get_group_name(cls, obj):\n    \"\"\"\n    Grabs the corresponding group name for object @obj\n\n    Args:\n        obj (BaseObject): Object for which its procedurally generated particle attachment name should be grabbed\n\n    Returns:\n        str: Name of the attachment group to use when executing commands from this class on\n            that specific attachment group\n    \"\"\"\n    return obj.name\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.get_group_name"},{"title":"<code>groups()</code>","text":"<p>Returns:</p>    Type Description       <p>set of str: Current attachment particle group names</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classproperty\ndef groups(cls):\n    \"\"\"\n    Returns:\n        set of str: Current attachment particle group names\n    \"\"\"\n    return set(cls._group_particles.keys())\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.groups"},{"title":"<code>num_group_particles(group)</code>  <code>classmethod</code>","text":"<p>Gets the number of particles for the given group in the simulator</p> <p>Parameters:</p>    Name Type Description Default     <code>group</code>  <code>str</code>  <p>Name of the attachment group to remove all particles from.</p>  required     <p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of particles allocated to this group in the scene. Note that if @group does not exist, this will return 0</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef num_group_particles(cls, group):\n    \"\"\"\n    Gets the number of particles for the given group in the simulator\n\n    Args:\n        group (str): Name of the attachment group to remove all particles from.\n\n    Returns:\n        int: Number of particles allocated to this group in the scene. Note that if @group does not\n            exist, this will return 0\n    \"\"\"\n    # Make sure the group exists\n    cls._validate_group(group=group)\n    return len(cls._group_particles[group])\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.num_group_particles"},{"title":"<code>remove_all_group_particles(group)</code>  <code>classmethod</code>","text":"<p>Remove particle with name @name from both the simulator as well as internally</p> <p>Parameters:</p>    Name Type Description Default     <code>group</code>  <code>str</code>  <p>Name of the attachment group to remove all particles from</p>  required      Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_all_group_particles(cls, group):\n    \"\"\"\n    Remove particle with name @name from both the simulator as well as internally\n\n    Args:\n        group (str): Name of the attachment group to remove all particles from\n    \"\"\"\n    # Make sure the group exists\n    cls._validate_group(group=group)\n    # Remove all particles from the group\n    for particle_name in list(cls._group_particles[group].keys()):\n        cls.remove_particle(name=particle_name)\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.remove_all_group_particles"},{"title":"<code>remove_attachment_group(group)</code>  <code>classmethod</code>","text":"<p>Removes an attachment group internally for object @obj. Note that this will automatically remove any particles currently assigned to that group</p> <p>Parameters:</p>    Name Type Description Default     <code>group</code>  <code>str</code>  <p>Name of the attachment group to remove</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of the attachment group to use when executing commands from this class on that specific attachment group</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_attachment_group(cls, group):\n    \"\"\"\n    Removes an attachment group internally for object @obj. Note that this will automatically remove any particles\n    currently assigned to that group\n\n    Args:\n        group (str): Name of the attachment group to remove\n\n    Returns:\n        str: Name of the attachment group to use when executing commands from this class on\n            that specific attachment group\n    \"\"\"\n    # Make sure the group exists\n    cls._validate_group(group=group)\n\n    # Remove all particles from the group\n    cls.remove_all_group_particles(group=group)\n\n    # Remove the actual groups\n    cls._group_particles.pop(group)\n    cls._group_objects.pop(group)\n\n    return group\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.remove_attachment_group"},{"title":"<code>remove_particle(name)</code>  <code>classmethod</code>","text":"<p>Remove particle with name @name from both the simulator as well as internally</p> <p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>Name of the particle to remove</p>  required      Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef remove_particle(cls, name):\n    \"\"\"\n    Remove particle with name @name from both the simulator as well as internally\n\n    Args:\n        name (str): Name of the particle to remove\n    \"\"\"\n    # Run super first\n    super().remove_particle(name=name)\n\n    # Remove this particle from its respective group as well\n    for group in cls._group_particles.values():\n        # Maybe make this better? We have to manually search through the groups for this particle\n        if name in group:\n            group.pop(name)\n            break\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.remove_particle"},{"title":"<code>sample_scales(group, n)</code>  <code>classmethod</code>","text":"<p>Samples @n particle scales for group @group.</p> <p>Parameters:</p>    Name Type Description Default     <code>group</code>  <code>str</code>  <p>Specific group for which to sample scales</p>  required    <code>n</code>  <code>int</code>  <p>Number of scales to sample</p>  required     <p>Returns:</p>    Type Description       <p>(n, 3) array: Array of sampled scales</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef sample_scales(cls, group, n):\n    \"\"\"\n    Samples @n particle scales for group @group.\n\n    Args:\n        group (str): Specific group for which to sample scales\n        n (int): Number of scales to sample\n\n    Returns:\n        (n, 3) array: Array of sampled scales\n    \"\"\"\n    # Make sure the group exists\n    cls._validate_group(group=group)\n\n    # Update scaling and grab object\n    cls.set_scale_limits(*cls.update_particle_scaling(group=group))\n    obj = cls._group_objects[group]\n\n    # Sample scales of the particles to generate\n    # Since the particles will be placed under the object, it will be affected/stretched by obj.scale. In order to\n    # preserve the absolute size of the particles, we need to scale the particle by obj.scale in some way. However,\n    # since the particles have a relative rotation w.r.t the object, the scale between the two don't align. As a\n    # heuristics, we divide it by the avg_scale, which is the cubic root of the product of the scales along 3 axes.\n    avg_scale = np.cbrt(np.product(obj.scale))\n    return np.random.uniform(cls.min_scale, cls.max_scale, (n, 3)) / avg_scale\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.sample_scales"},{"title":"<code>update_particle_scaling(group)</code>  <code>classmethod</code>","text":"<p>Update particle scaling for group @group before generating group particles. Default is a no-op (i.e.: returns the current cls.min_scale, cls.max_scale)</p> <p>Parameters:</p>    Name Type Description Default     <code>group</code>  <code>str</code>  <p>Specific group for which to modify the particle scaling</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: min scaling factor to set - 3-array: max scaling factor to set</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>@classmethod\ndef update_particle_scaling(cls, group):\n    \"\"\"\n    Update particle scaling for group @group before generating group particles. Default is a no-op\n    (i.e.: returns the current cls.min_scale, cls.max_scale)\n\n    Args:\n        group (str): Specific group for which to modify the particle scaling\n\n    Returns:\n        2-tuple:\n            - 3-array: min scaling factor to set\n            - 3-array: max scaling factor to set\n    \"\"\"\n    return cls.min_scale, cls.max_scale\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.VisualParticleSystem.update_particle_scaling"},{"title":"<code>get_visual_particle_systems()</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Mapping from fluid system name to fluid system</p>     Source code in <code>systems/macro_particle_system.py</code> <pre><code>def get_visual_particle_systems():\n    \"\"\"\n    Returns:\n        OrderedDict: Mapping from fluid system name to fluid system\n    \"\"\"\n    systems = OrderedDict()\n    for system in SYSTEMS_REGISTRY.objects:\n        if issubclass(system, VisualParticleSystem):\n            systems[system.name] = system\n\n    return systems\n</code></pre>","location":"reference/systems/macro_particle_system.html#systems.macro_particle_system.get_visual_particle_systems"},{"title":"micro_particle_system","text":"","location":"reference/systems/micro_particle_system.html"},{"title":"<code>ClothSystem</code>","text":"<p>         Bases: <code>MicroParticleSystem</code></p> <p>Particle system class to simulate cloth.</p>  Source code in <code>systems/micro_particle_system.py</code> <pre><code>class ClothSystem(MicroParticleSystem):\n    \"\"\"\n    Particle system class to simulate cloth.\n    \"\"\"\n    @classproperty\n    def _register_system(cls):\n        # We should register this system since it's an \"actual\" system (not an intermediate class)\n        return True\n\n    @classproperty\n    def particle_contact_offset(cls):\n        # TODO (eric): figure out whether one offset can fit all\n        return 0.005\n\n    @classproperty\n    def is_fluid(cls):\n        return False\n\n    @classproperty\n    def visual_only(cls):\n        return False\n\n    @classproperty\n    def use_smoothing(cls):\n        return False\n\n    @classproperty\n    def use_anisotropy(cls):\n        return False\n\n    @classproperty\n    def use_isosurface(cls):\n        return False\n\n    @classmethod\n    def _create_particle_prototypes(cls):\n        return []\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.ClothSystem"},{"title":"<code>FluidSystem</code>","text":"<p>         Bases: <code>MicroParticleSystem</code></p> <p>Particle system class simulating fluids, leveraging isosurface feature in omniverse to render nice PBR fluid texture. Individual particles are composed of spheres.</p>  Source code in <code>systems/micro_particle_system.py</code> <pre><code>class FluidSystem(MicroParticleSystem):\n    \"\"\"\n    Particle system class simulating fluids, leveraging isosurface feature in omniverse to render nice PBR fluid\n    texture. Individual particles are composed of spheres.\n    \"\"\"\n\n    @classproperty\n    def is_fluid(cls):\n        return True\n\n    @classproperty\n    def visual_only(cls):\n        return False\n\n    @classproperty\n    def use_smoothing(cls):\n        return False\n\n    @classproperty\n    def use_anisotropy(cls):\n        return False\n\n    @classproperty\n    def use_isosurface(cls):\n        return True\n\n    @classproperty\n    def _material_mtl_name(cls):\n        \"\"\"\n        Returns:\n            None or str: Material mdl preset name to use for generating this fluid material. NOTE: Should be an\n                entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string. If None if specified, will default\n                to the generic OmniSurface material\n        \"\"\"\n        return None\n\n    @classmethod\n    def _create_particle_prototypes(cls):\n        # Simulate particles with simple spheres\n        prototype = UsdGeom.Sphere.Define(cls.simulator.stage, f\"{cls.prim_path}/{cls.name}ParticlePrototype\")\n        prototype.CreateRadiusAttr().Set(cls.particle_radius)\n        return [prototype.GetPrim()]\n\n    @classmethod\n    def update(cls):\n        # For each particle instance, garbage collect particles if the number of visible particles\n        # is below the garbage collection threshold (m.GC_THRESHOLD)\n        instancer_names = list(cls.particle_instancers.keys())\n        for inst_name in instancer_names: # type: ignore\n            if np.mean(cls.particle_instancers[inst_name].particle_visibilities) &lt;= m.GC_THRESHOLD:\n                cls.remove_particle_instancer(inst_name)\n\n    @classmethod\n    def _create_particle_material_template(cls):\n        # We use a template from OmniPresets if @_material_mtl_name is specified, else the default OmniSurface\n        return MaterialPrim(\n            prim_path=cls.mat_path,\n            name=cls.mat_name,\n            load_config={\n                \"mdl_name\": f\"OmniSurface{'' if cls._material_mtl_name is None else 'Presets'}.mdl\",\n                \"mtl_name\": f\"OmniSurface{'' if cls._material_mtl_name is None else ('_' + cls._material_mtl_name)}\"\n            }\n        )\n\n    @classmethod\n    def create(\n        cls,\n        fluid_name,\n        particle_contact_offset,\n        particle_density,\n        material_mtl_name=None,\n        customize_particle_material=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Utility function to programmatically generate monolithic fluid system classes.\n\n        Args:\n            fluid_name (str): Name of the fluid\n            particle_contact_offset (float): Contact offset for the generated fluid system\n            particle_density (float): Particle density for the generated fluid system\n            material_mtl_name (None or str): Material mdl preset name to use for generating this fluid material.\n                NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string.\n                If None if specified, will default to the generic OmniSurface material\n            customize_particle_material (None or function): Method for customizing the particle material for the fluid\n                after it has been loaded. Default is None, which will produce a no-op.\n                If specified, expected signature:\n\n                _customize_particle_material(mat: MaterialPrim) --&gt; None\n\n                where @MaterialPrim is the material to modify in-place\n\n            **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n                the class attribute to modify and the values represent the functions / value to set\n                (Note: These values should have either @classproperty or @classmethod decorators!)\n\n        Returns:\n            FluidSystem: Generated fluid system class\n        \"\"\"\n\n        # Override the necessary parameters\n        @classproperty\n        def cp_register_system(cls):\n            # We should register this system since it's an \"actual\" system (not an intermediate class)\n            return True\n\n        @classproperty\n        def cp_particle_contact_offset(cls):\n            return particle_contact_offset\n\n        @classproperty\n        def cp_particle_density(cls):\n            return particle_density\n\n        @classproperty\n        def cp_material_mtl_name(cls):\n            return material_mtl_name\n\n        @classmethod\n        def cm_customize_particle_material(cls):\n            if customize_particle_material is not None:\n                customize_particle_material(mat=cls._material)\n\n        # Add to any other params specified\n        kwargs[\"_register_system\"] = cp_register_system\n        kwargs[\"particle_contact_offset\"] = cp_particle_contact_offset\n        kwargs[\"particle_density\"] = cp_particle_density\n        kwargs[\"_material_mtl_name\"] = cp_material_mtl_name\n        kwargs[\"_customize_particle_material\"] = cm_customize_particle_material\n\n        # Create and return the class\n        return subclass_factory(name=f\"{fluid_name}System\", base_classes=FluidSystem, **kwargs)\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.FluidSystem"},{"title":"<code>create(fluid_name, particle_contact_offset, particle_density, material_mtl_name=None, customize_particle_material=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Utility function to programmatically generate monolithic fluid system classes.</p> <p>Parameters:</p>    Name Type Description Default     <code>fluid_name</code>  <code>str</code>  <p>Name of the fluid</p>  required    <code>particle_contact_offset</code>  <code>float</code>  <p>Contact offset for the generated fluid system</p>  required    <code>particle_density</code>  <code>float</code>  <p>Particle density for the generated fluid system</p>  required    <code>material_mtl_name</code>  <code>None or str</code>  <p>Material mdl preset name to use for generating this fluid material. NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string. If None if specified, will default to the generic OmniSurface material</p>  <code>None</code>    <code>customize_particle_material</code>  <code>None or function</code>  <p>Method for customizing the particle material for the fluid after it has been loaded. Default is None, which will produce a no-op. If specified, expected signature:</p> <p>_customize_particle_material(mat: MaterialPrim) --&gt; None</p> <p>where @MaterialPrim is the material to modify in-place</p>  <code>None</code>    <code>**kwargs</code>  <code>any</code>  <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class attribute to modify and the values represent the functions / value to set (Note: These values should have either @classproperty or @classmethod decorators!)</p>  <code>{}</code>     <p>Returns:</p>    Name Type Description     <code>FluidSystem</code>   <p>Generated fluid system class</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    fluid_name,\n    particle_contact_offset,\n    particle_density,\n    material_mtl_name=None,\n    customize_particle_material=None,\n    **kwargs,\n):\n    \"\"\"\n    Utility function to programmatically generate monolithic fluid system classes.\n\n    Args:\n        fluid_name (str): Name of the fluid\n        particle_contact_offset (float): Contact offset for the generated fluid system\n        particle_density (float): Particle density for the generated fluid system\n        material_mtl_name (None or str): Material mdl preset name to use for generating this fluid material.\n            NOTE: Should be an entry from OmniSurfacePresets.mdl, minus the \"OmniSurface_\" string.\n            If None if specified, will default to the generic OmniSurface material\n        customize_particle_material (None or function): Method for customizing the particle material for the fluid\n            after it has been loaded. Default is None, which will produce a no-op.\n            If specified, expected signature:\n\n            _customize_particle_material(mat: MaterialPrim) --&gt; None\n\n            where @MaterialPrim is the material to modify in-place\n\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class attribute to modify and the values represent the functions / value to set\n            (Note: These values should have either @classproperty or @classmethod decorators!)\n\n    Returns:\n        FluidSystem: Generated fluid system class\n    \"\"\"\n\n    # Override the necessary parameters\n    @classproperty\n    def cp_register_system(cls):\n        # We should register this system since it's an \"actual\" system (not an intermediate class)\n        return True\n\n    @classproperty\n    def cp_particle_contact_offset(cls):\n        return particle_contact_offset\n\n    @classproperty\n    def cp_particle_density(cls):\n        return particle_density\n\n    @classproperty\n    def cp_material_mtl_name(cls):\n        return material_mtl_name\n\n    @classmethod\n    def cm_customize_particle_material(cls):\n        if customize_particle_material is not None:\n            customize_particle_material(mat=cls._material)\n\n    # Add to any other params specified\n    kwargs[\"_register_system\"] = cp_register_system\n    kwargs[\"particle_contact_offset\"] = cp_particle_contact_offset\n    kwargs[\"particle_density\"] = cp_particle_density\n    kwargs[\"_material_mtl_name\"] = cp_material_mtl_name\n    kwargs[\"_customize_particle_material\"] = cm_customize_particle_material\n\n    # Create and return the class\n    return subclass_factory(name=f\"{fluid_name}System\", base_classes=FluidSystem, **kwargs)\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.FluidSystem.create"},{"title":"<code>MicroParticleSystem</code>","text":"<p>         Bases: <code>BaseParticleSystem</code></p> <p>Global system for modeling \"micro\" level particles, e.g.: water, seeds, rice, etc. This system leverages Omniverse's native physx particle systems</p>  Source code in <code>systems/micro_particle_system.py</code> <pre><code>class MicroParticleSystem(BaseParticleSystem):\n    \"\"\"\n    Global system for modeling \"micro\" level particles, e.g.: water, seeds, rice, etc. This system leverages\n    Omniverse's native physx particle systems\n    \"\"\"\n    # Particle system prim in the scene, should be generated at runtime\n    prim = None\n\n    # Particle prototypes -- will be list of mesh prims to use as particle prototypes for this system\n    particle_prototypes = None\n\n    # Particle instancers -- maps name to particle instancer prims (OrderedDict)\n    particle_instancers = None\n\n    # Material -- either a MaterialPrim or None if no material is used for this particle system\n    _material = None\n\n    # Color associated with this system (NOTE: external queries should call cls.color)\n    _color = None\n\n    # Scaling factor to sample from when generating a new particle\n    min_scale = None                # (x,y,z) scaling\n    max_scale = None                # (x,y,z) scaling\n\n    # Max particle instancer identification number -- this monotonically increases until reset() is called\n    max_instancer_idn = None\n\n    # State cache -- OrderedDict, anything that should be updated exactly once between simulation step calls\n    state_cache = None\n\n    @classproperty\n    def n_particles(cls):\n        \"\"\"\n        Returns:\n            int: Number of active particles in this system\n        \"\"\"\n        return sum([instancer.n_particles for instancer in cls.particle_instancers.values()])\n\n    @classproperty\n    def prim_path(cls):\n        \"\"\"\n        Returns:\n            str: Path to this system's prim in the scene stage\n        \"\"\"\n        return f\"/World/{cls.name}\"\n\n    @classproperty\n    def mat_path(cls):\n        \"\"\"\n        Returns:\n            str: Path to this system's material in the scene stage\n        \"\"\"\n        return f\"{cls.prim_path}/{cls.name}_material\"\n\n    @classproperty\n    def mat_name(cls):\n        \"\"\"\n        Returns:\n            str: Name of this system's material\n        \"\"\"\n        return f\"{cls.name}:material\"\n\n    @classproperty\n    def material(cls):\n        \"\"\"\n        Returns:\n            None or MaterialPrim: The bound material to this prim, if there is one\n        \"\"\"\n        return cls._material\n\n    @classmethod\n    def initialize(cls, simulator):\n        # Run super first\n        super().initialize(simulator=simulator)\n\n        # Initialize class variables that are mutable so they don't get overridden by children classes\n        cls.particle_instancers = OrderedDict()\n\n        # Set the default scales\n        cls.min_scale = np.ones(3)\n        cls.max_scale = np.ones(3)\n\n        # Initialize max instancer idn\n        cls.max_instancer_idn = -1\n\n        # Initialize state cache\n        cls.state_cache = OrderedDict()\n\n        # Create the particle system if it doesn't already exist, otherwise sync with the pre-existing system\n        prototype_path = get_prototype_path_from_particle_system_path(particle_system_path=cls.prim_path)\n\n        if cls.particle_system_exists:\n            cls.prim = get_prim_at_path(cls.prim_path)\n            # If Material already exists on stage, just create a MaterialPrim wrapper around it (run its post_load())\n            if is_prim_path_valid(cls.mat_path):\n                cls._material = cls._create_particle_material_template()\n                cls._material.shader_force_populate()\n            prototype_dir_prim = get_prim_at_path(prototype_path)\n            cls.particle_prototypes = [prototype_prim for prototype_prim in prototype_dir_prim.GetChildren()]\n\n            # Also need to synchronize any instancers we have\n            for prim in cls.prim.GetChildren():\n                name = prim.GetName()\n                if prim.GetPrimTypeInfo().GetTypeName() == \"PointInstancer\":\n                    cls.particle_instancers[name] = PhysxParticleInstancer(\n                        prim_path=prim.GetPrimPath().pathString,\n                        name=name,\n                        idn=cls.particle_instancer_name_to_idn(name=name),\n                    )\n        else:\n            cls.prim = cls._create_particle_system()\n            # Create the particle material (only if we're using high-quality rendering since this takes time)\n            cls._material = cls._create_particle_material_template() if gm.ENABLE_HQ_RENDERING else None\n            if cls._material is not None:\n                # Load the material\n                cls._material.load()\n                # Bind the material to the particle system\n                cls._material.bind(cls.prim_path)\n                # Also apply physics to this material\n                particleUtils.add_pbd_particle_material(cls.simulator.stage, cls.mat_path)\n                # Force populate inputs and outputs of the shader\n                cls._material.shader_force_populate()\n                # Potentially modify the material\n                cls._customize_particle_material()\n            # Create the particle prototypes, move them to the appropriate directory, and make them all invisible\n            prototypes = cls._create_particle_prototypes()\n            cls.particle_prototypes = []\n            cls.simulator.stage.DefinePrim(prototype_path, \"Scope\")\n            cls.simulator.stage.DefinePrim(f\"{prototype_path}/{cls.name}\", \"Scope\")\n            for i, prototype_prim in enumerate(prototypes):\n                # TODO: Omni no longer likes prototypes being created in nested locations. Where to place now?\n                path_from = prototype_prim.GetPrimPath().pathString\n                path_to = f\"{prototype_path}/{cls.name}/ParticlePrototype{i}\"\n                omni.kit.commands.execute(\"MovePrim\", path_from=path_from, path_to=path_to)\n                # path_to = prototype_prim.GetPrimPath().pathString\n                prototype_prim_new = get_prim_at_path(path_to)\n                UsdGeom.Imageable(prototype_prim_new).MakeInvisible()\n                cls.particle_prototypes.append(prototype_prim_new)\n\n        # Set custom rendering settings if we're using a fluid isosurface\n        if cls.is_fluid and cls.use_isosurface and gm.ENABLE_HQ_RENDERING:\n            set_carb_settings_for_fluid_isosurface()\n\n            # We also modify the grid smoothing radius to avoid \"blobby\" appearances\n            cls.prim.GetAttribute(\"physxParticleIsosurface:gridSmoothingRadius\").Set(0.0001)\n\n        # Set the color for this system\n        if cls._material is not None:\n            base_color_weight = cls._material.diffuse_reflection_weight\n            transmission_weight = cls._material.enable_specular_transmission * cls._material.specular_transmission_weight\n            total_weight = base_color_weight + transmission_weight\n            if total_weight == 0.0:\n                # If the fluid doesn't have any color, we add a \"blue\" tint by default\n                color = np.array([0.0, 0.0, 1.0])\n            else:\n                base_color_weight /= total_weight\n                transmission_weight /= total_weight\n                # Weighted sum of base color and transmission color\n                color = base_color_weight * cls._material.diffuse_reflection_color + \\\n                        transmission_weight * (0.5 * cls._material.specular_transmission_color + \\\n                                               0.5 * cls._material.specular_transmission_scattering_color)\n            cls._color = color\n\n    @classmethod\n    def reset(cls):\n        # Reset all internal variables\n        cls.remove_all_particle_instancers()\n        cls.max_instancer_idn = -1\n        cls.state_cache = OrderedDict()\n\n    @classproperty\n    def state_size(cls):\n        # We have the number of particle instancers (1), the instancer groups, particle groups, and,\n        # number of particles in each instancer (3n),\n        # and the corresponding states in each instancer (X)\n        return 1 + 3 * len(cls.particle_instancers) + sum(inst.state_size for inst in cls.particle_instancers.values())\n\n    @classproperty\n    def particle_system_exists(cls):\n        \"\"\"\n        Returns:\n            bool: Whether this particle system already exists on the current stage. Useful for internal logic\n                synchronization during, e.g., initialization, where a USD snapshot may have been loaded with a particle\n                system already on the stage\n        \"\"\"\n        return is_prim_path_valid(cls.prim_path)\n\n    @classproperty\n    def color(cls):\n        return cls._color\n\n    @classproperty\n    def is_fluid(cls):\n        \"\"\"\n        Returns:\n            bool: Whether this system is modeling fluid or not\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def visual_only(cls):\n        \"\"\"\n        Returns:\n            bool: Whether this particle system should be visual-only, i.e.: not subject to collisions and physics. If True,\n                the generated particles will not move or collide\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def particle_contact_offset(cls):\n        \"\"\"\n        Returns:\n            float: Contact offset value to use for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#particle-system-configuration\n                for more information\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def use_smoothing(cls):\n        \"\"\"\n        Returns:\n            bool: Whether to use smoothing or not for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#smoothing\n                for more information\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def use_anisotropy(cls):\n        \"\"\"\n        Returns:\n            bool: Whether to use anisotropy or not for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#anisotropy\n                for more information\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def use_isosurface(cls):\n        \"\"\"\n        Returns:\n            bool: Whether to use isosurface or not for this particle system.\n                See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#isosurface\n                for more information\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def particle_radius(cls):\n        \"\"\"\n        Returns:\n            float: Radius for the particles to be generated, since all fluids are composed of spheres\n        \"\"\"\n        # Magic number from omni tutorials\n        # See https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_physics.html#offset-autocomputation\n        return 0.99 * 0.6 * cls.particle_contact_offset if cls.is_fluid else 0.99 * cls.particle_contact_offset\n\n    @classproperty\n    def particle_density(cls):\n        \"\"\"\n        Returns:\n            float: The per-particle density, in kg / m^3\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def _create_particle_prototypes(cls):\n        \"\"\"\n        Creates any relevant particle prototypes to be used by this particle system.\n\n        Returns:\n            list of Usd.Prim: Mesh prim(s) to use as this system's particle prototype(s)\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def _create_particle_material_template(cls):\n        \"\"\"\n        Creates the particle material template to be used for this particle system. Prim path does not matter,\n        as it will be overridden internally such that it is a child prim of this particle system's prim.\n\n        NOTE: This material is a template because it is loading an Omni material present. It can then be customized (in\n        addition to modifying its physical material properties) via @_modify_particle_material\n\n        Returns:\n            None or MaterialPrim: If specified, is the material to apply to all particles. If None, no material\n                will be used. Default is None\n        \"\"\"\n        return None\n\n    @classmethod\n    def _customize_particle_material(cls):\n        \"\"\"\n        Modifies this particle system's particle material once it is loaded. Default is a no-op\n        \"\"\"\n        pass\n\n    @classmethod\n    def _create_particle_system(cls):\n        \"\"\"\n        Creates the single, global particle system. This should only be ever called once, and during initialize()\n\n        Returns:\n            Usd.Prim: Particle system prim created\n        \"\"\"\n        return create_physx_particle_system(\n            prim_path=cls.prim_path,\n            physics_scene_path=cls.simulator.get_physics_context().get_current_physics_scene_prim().GetPrimPath().pathString,\n            particle_contact_offset=cls.particle_contact_offset,\n            visual_only=cls.visual_only,\n            smoothing=cls.use_smoothing and gm.ENABLE_HQ_RENDERING,\n            anisotropy=cls.use_anisotropy and gm.ENABLE_HQ_RENDERING,\n            isosurface=cls.use_isosurface and gm.ENABLE_HQ_RENDERING,\n        ).GetPrim()\n\n    @classmethod\n    def generate_particle_instancer(\n            cls,\n            n_particles,\n            idn=None,\n            particle_group=0,\n            positions=None,\n            velocities=None,\n            orientations=None,\n            scales=None,\n            self_collision=True,\n            prototype_indices=None,\n    ):\n        \"\"\"\n        Generates a new particle instancer with unique identification number @idn, and registers it internally\n\n        Args:\n            n_particles (int): Number of particles to generate for this instancer\n            idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n                deterministically reproduce individual particle instancer states dynamically, even if we\n                delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n                identifier automatically.\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n                with each other. Particles in the same group will have collision behavior dictated by @self_collision\n            positions (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n                If not specified, will be set to the origin by default\n            velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n                If not specified, all will be set to 0\n            orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n                orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n            scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n                If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not\n            prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n                each particle. If None, will use all 0s (i.e.: the first prototype created)\n\n        Returns:\n            PhysxParticleInstancer: Generated particle instancer\n        \"\"\"\n        # Run sanity checks\n        assert cls.initialized, \"Must initialize system before generating particle instancers!\"\n\n        # Automatically generate an identification number for this instancer if none is specified\n        if idn is None:\n            idn = cls.max_instancer_idn + 1\n            # Also increment this counter\n            cls.max_instancer_idn += 1\n\n        # Generate standardized prim path for this instancer\n        name = cls.particle_instancer_idn_to_name(idn=idn)\n\n        # Create the instancer\n        instance = create_physx_particleset_pointinstancer(\n            name=name,\n            particle_system_path=cls.prim_path,\n            particle_group=particle_group,\n            positions=np.zeros((n_particles, 3)) if positions is None else positions,\n            self_collision=self_collision,\n            fluid=cls.is_fluid,\n            particle_mass=None,\n            particle_density=cls.particle_density,\n            orientations=orientations,\n            velocities=velocities,\n            angular_velocities=None,\n            scales=np.random.uniform(cls.min_scale, cls.max_scale, size=(n_particles, 3)) if scales is None else scales,\n            prototype_prim_paths=[pp.GetPrimPath().pathString for pp in cls.particle_prototypes],\n            prototype_indices=prototype_indices,\n            enabled=not cls.visual_only,\n        )\n\n        # Create the instancer object that wraps the raw prim\n        instancer = PhysxParticleInstancer(\n            prim_path=instance.GetPrimPath().pathString,\n            name=name,\n            idn=idn,\n        )\n        instancer.initialize()\n        cls.particle_instancers[name] = instancer\n\n        return instancer\n\n    @classmethod\n    def generate_particle_instancer_from_link(\n            cls,\n            obj,\n            link,\n            mesh_name_prefixes=None,\n            idn=None,\n            particle_group=0,\n            sampling_distance=None,\n            max_samples=5e5,\n            sample_volume=True,\n            self_collision=True,\n            prototype_indices_choices=None,\n    ):\n        \"\"\"\n        Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh\n        located at @mesh_prim_path, and registers it internally\n\n        Args:\n            obj (EntityPrim): Object whose @link's visual meshes will be converted into sampled particles\n            link (RigidPrim): @obj's link whose visual meshes will be converted into sampled particles\n            mesh_name_prefixes (None or str): If specified, specifies the substring that must exist in @link's\n            mesh names in order for that mesh to be included in the particle generator function. If None, no filtering\n            will be used.\n            idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n                deterministically reproduce individual particle instancer states dynamically, even if we\n                delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n                identifier automatically.\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n                with each other. Particles in the same group will have collision behavior dictated by @self_collision\n            sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n                a simulator autocomputed value will be used\n            max_samples (int): Maximum number of particles to sample\n            sample_volume (bool): Whether to sample the particles at the mesh's surface or throughout its entire volume\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not\n            prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n                should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n                single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n                sample from those IDs for each particle.\n\n        Returns:\n            PhysxParticleInstancer: Generated particle instancer\n        \"\"\"\n        # Run sanity checks\n        assert cls.initialized, \"Must initialize system before generating particle instancers!\"\n        # TODO: Implement!\n        assert sample_volume, \"Sampling surface of link for particles is not supported yet!\"\n\n        # Generate a checker function to see if particles are within the link's volumes\n        check_in_volume, _ = generate_points_in_volume_checker_function(\n            obj=obj,\n            volume_link=link,\n            use_visual_meshes=True,\n            mesh_name_prefixes=mesh_name_prefixes,\n        )\n\n        # Grab the link's AABB (or fallback to obj AABB if link does not have a valid AABB),\n        # and generate a grid of points based on the sampling distance\n        try:\n            low, high = link.aabb\n            extent = link.aabb_extent\n        except ValueError:\n            low, high = obj.aabb\n            extent = obj.aabb_extent\n        # We sample the range of each extent minus\n        sampling_distance = 2 * cls.particle_radius if sampling_distance is None else sampling_distance\n        n_particles_per_axis = ((extent - 2 * cls.particle_radius) / sampling_distance).astype(int) + 1\n        arrs = [np.linspace(lo + cls.particle_radius, hi - cls.particle_radius, n) for lo, hi, n in zip(low, high, n_particles_per_axis)]\n        # Generate 3D-rectangular grid of points\n        particle_positions = np.stack([arr.flatten() for arr in np.meshgrid(*arrs)]).T\n        # Check which points are inside the volume and only keep those\n        particle_positions = particle_positions[np.where(check_in_volume(particle_positions))[0]]\n        # Also potentially sub-sample if we're past our limit\n        if len(particle_positions) &gt; max_samples:\n            particle_positions = particle_positions[np.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n\n        # Get information about our sampled points\n        n_particles = len(particle_positions)\n        if prototype_indices_choices is not None:\n            prototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n                isinstance(prototype_indices_choices, int) else \\\n                np.random.choice(prototype_indices_choices, size=(n_particles,))\n        else:\n            prototype_indices = None\n\n        # Create and return the generated instancer\n        return cls.generate_particle_instancer(\n            idn=idn,\n            particle_group=particle_group,\n            n_particles=n_particles,\n            positions=particle_positions,\n            velocities=None,\n            orientations=None,\n            scales=None,\n            self_collision=self_collision,\n            prototype_indices=prototype_indices,\n        )\n\n    @classmethod\n    def generate_particle_instancer_from_mesh(\n            cls,\n            mesh_prim_path,\n            idn=None,\n            particle_group=0,\n            sampling_distance=None,\n            max_samples=5e5,\n            sample_volume=True,\n            self_collision=True,\n            prototype_indices_choices=None,\n    ):\n        \"\"\"\n        Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh\n        located at @mesh_prim_path, and registers it internally\n\n        Args:\n            mesh_prim_path (str): Stage path to the mesh prim which will be converted into sampled particles\n            idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n                deterministically reproduce individual particle instancer states dynamically, even if we\n                delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n                identifier automatically.\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n                with each other. Particles in the same group will have collision behavior dictated by @self_collision\n            sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n                a simulator autocomputed value will be used\n            max_samples (int): Maximum number of particles to sample\n            sample_volume (bool): Whether to sample the particles at the mesh's surface or throughout its entire volume\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not\n            prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n                should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n                single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n                sample from those IDs for each particle.\n\n        Returns:\n            PhysxParticleInstancer: Generated particle instancer\n        \"\"\"\n        # Run sanity checks\n        assert cls.initialized, \"Must initialize system before generating particle instancers!\"\n        assert cls.simulator.is_stopped(), \"Can only sample particles from a mesh using Omni's API when simulator is stopped!\"\n\n        # Create points prim (this is used initially to generate the particles) and apply particle set API\n        points_prim_path = f\"{cls.prim_path}/tempSampledPoints\"\n        points = UsdGeom.Points.Define(cls.simulator.stage, points_prim_path).GetPrim()\n        particle_set_api = PhysxSchema.PhysxParticleSetAPI.Apply(points)\n        particle_set_api.CreateParticleSystemRel().SetTargets([cls.prim_path])\n\n        # Apply the sampling API to our mesh prim and apply the sampling\n        mesh_prim = get_prim_at_path(mesh_prim_path)\n        sampling_api = PhysxSchema.PhysxParticleSamplingAPI.Apply(mesh_prim)\n        sampling_api.CreateParticlesRel().AddTarget(points_prim_path)\n        sampling_api.CreateSamplingDistanceAttr().Set(0 if sampling_distance is None else sampling_distance)\n        sampling_api.CreateMaxSamplesAttr().Set(max_samples)\n        sampling_api.CreateVolumeAttr().Set(sample_volume)\n\n        # We apply 1 physics step to propagate the sampling (make sure to pause the sim since particles still propagate\n        # forward even if we don't explicitly call sim.step())\n        with cls.simulator.paused():\n            cls.simulator.step_physics()\n        time.sleep(0.1)                         # Empirically validated for ~2500 samples (0.02 time doesn't work)\n        cls.simulator.render()                  # Rendering is needed after an initial, nontrivial amount of time for the particles to actually be sampled\n\n        # Grab the actual positions, we will write this to a new instancer that's not tied to the sampler\n        # The points / instancer tied to the sampled mesh seems to operate a bit weirdly, which is why we do it this way\n        attr = \"positions\" if points.GetPrimTypeInfo().GetTypeName() == \"PointInstancer\" else \"points\"\n        pos = points.GetAttribute(attr).Get()\n\n        # Make sure sampling was successful\n        assert pos is not None and len(pos) &gt; 0, \"Failed to sample particle points from mesh prim!\"\n\n        # Delete the points prim and sampling API, we don't need it anymore, and make the mesh prim invisible again\n        cls.simulator.stage.RemovePrim(points_prim_path)\n        mesh_prim.RemoveAPI(PhysxSchema.PhysxParticleSamplingAPI)\n        UsdGeom.Imageable(mesh_prim).MakeInvisible()\n\n        # Get information about our sampled points\n        n_particles = len(pos)\n        if prototype_indices_choices is not None:\n            prototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n                isinstance(prototype_indices_choices, int) else \\\n                np.random.choice(prototype_indices_choices, size=(n_particles,))\n        else:\n            prototype_indices = None\n\n        # Create and return the generated instancer\n        return cls.generate_particle_instancer(\n            idn=idn,\n            particle_group=particle_group,\n            n_particles=n_particles,\n            positions=pos,\n            velocities=None,\n            orientations=None,\n            scales=None,\n            self_collision=self_collision,\n            prototype_indices=prototype_indices,\n        )\n\n    @classmethod\n    def generate_particle_instancer_on_object(\n            cls,\n            obj,\n            idn=None,\n            particle_group=0,\n            sampling_distance=None,\n            max_samples=5e5,\n            self_collision=True,\n            prototype_indices_choices=None,\n    ):\n        \"\"\"\n        Generates @n_particles new particle objects and samples their locations on the top surface of object @obj\n\n        Args:\n            obj (BaseObject): Object on which to generate a particle instancer with sampled particles on the object's\n                top surface\n            idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n                deterministically reproduce individual particle instancer states dynamically, even if we\n                delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n                identifier automatically.\n            particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n                a simulator autocomputed value will be used\n            max_samples (int): Maximum number of particles to sample\n            self_collision (bool): Whether to enable particle-particle collision within the set\n                (as defined by @particle_group) or not\n            prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n                should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n                single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n                sample from those IDs for each particle.\n\n        Returns:\n            PhysxParticleInstancer: Generated particle instancer\n        \"\"\"\n        # We densely sample a grid of points by ray-casting from top to bottom to find the valid positions\n        radius = cls.particle_radius\n        results = sample_cuboid_on_object_full_grid_topdown(\n            obj,\n            # the grid is fully dense - particles are sitting next to each other\n            ray_spacing=radius * 2 if sampling_distance is None else sampling_distance,\n            # assume the particles are extremely small - sample cuboids of size 0 for better performance\n            cuboid_dimensions=np.zeros(3),\n            # raycast start inside the aabb in x-y plane and outside the aabb in the z-axis\n            aabb_offset=np.array([-radius, -radius, radius]),\n            # bottom padding should be the same as the particle radius\n            cuboid_bottom_padding=radius,\n            # undo_cuboid_bottom_padding should be False - the sampled positions are above the surface by its radius\n            undo_cuboid_bottom_padding=False,\n        )\n        particle_positions = np.array([result[0] for result in results if result[0] is not None])\n        # Also potentially sub-sample if we're past our limit\n        if len(particle_positions) &gt; max_samples:\n            particle_positions = particle_positions[np.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n\n        # Get information about our sampled points\n        n_particles = len(particle_positions)\n        if prototype_indices_choices is not None:\n            prototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n                isinstance(prototype_indices_choices, int) else \\\n                np.random.choice(prototype_indices_choices, size=(n_particles,))\n        else:\n            prototype_indices = None\n\n        # Spawn the particles at the valid positions\n        cls.generate_particle_instancer(\n            n_particles=n_particles,\n            positions=particle_positions,\n            idn=idn,\n            particle_group=particle_group,\n            self_collision=self_collision,\n            prototype_indices=prototype_indices,\n        )\n\n    @classmethod\n    def remove_particle_instancer(cls, name):\n        \"\"\"\n        Removes particle instancer with name @name from this system.\n\n        Args:\n            name (str): Particle instancer name to remove. If it does not exist, then an error will be raised\n        \"\"\"\n        # Make sure the instancer actually exists\n        assert_valid_key(key=name, valid_keys=cls.particle_instancers, name=\"particle instancer\")\n        # Remove instancer from our tracking and delete its prim\n        instancer = cls.particle_instancers.pop(name)\n        instancer.remove(simulator=cls.simulator)\n        cls.simulator.stage.RemovePrim(f\"{get_prototype_path_from_particle_system_path(particle_system_path=cls.prim_path)}/{name}\")\n\n    @classmethod\n    def particle_instancer_name_to_idn(cls, name):\n        \"\"\"\n        Args:\n            name (str): Particle instancer name\n\n        Returns:\n            int: Particle instancer identification number\n        \"\"\"\n        return int(name.split(f\"{cls.name}Instancer\")[-1])\n\n    @classmethod\n    def particle_instancer_idn_to_name(cls, idn):\n        \"\"\"\n        Args:\n            idn (idn): Particle instancer identification number\n\n        Returns:\n            str: Name of the particle instancer auto-generated from its unique identification number\n        \"\"\"\n        return f\"{cls.name}Instancer{idn}\"\n\n    @classmethod\n    def _sync_particle_instancers(cls, idns, particle_groups, particle_counts):\n        \"\"\"\n        Synchronizes the particle instancers based on desired identification numbers @idns\n\n        Args:\n            idns (list of int): Desired unique instancers that should be active for this particle system\n            particle_groups (list of int): Desired particle groups that each instancer should be. Length of this\n                list should be the same length as @idns\n            particle_counts (list of int): Desired particle counts that should exist per instancer. Length of this\n                list should be the same length as @idns\n        \"\"\"\n        # We have to be careful here -- some particle instancers may have been deleted / are mismatched, so we need\n        # to update accordingly, potentially deleting stale instancers and creating new instancers as needed\n        idn_to_info_mapping = {idn: {\"group\": group, \"count\": count}\n                               for idn, group, count in zip(idns, particle_groups, particle_counts)}\n        current_instancer_names = set(cls.particle_instancers.keys())\n        desired_instancer_names = set(cls.particle_instancer_idn_to_name(idn=idn) for idn in idns)\n        instancers_to_delete = current_instancer_names - desired_instancer_names\n        instancers_to_create = desired_instancer_names - current_instancer_names\n        common_instancers = current_instancer_names.intersection(desired_instancer_names)\n\n        # Sanity check the common instancers, we will recreate any where there is a mismatch\n        for name in common_instancers:\n            idn = cls.particle_instancer_name_to_idn(name=name)\n            info = idn_to_info_mapping[idn]\n            instancer = cls.particle_instancers[name]\n            if instancer.particle_group != info[\"group\"] or instancer.n_particles != info[\"count\"]:\n                logging.debug(f\"Got mismatch in particle instancer {name} when syncing, deleting and recreating instancer now.\")\n                # Add this instancer to both the delete and creation pile\n                instancers_to_delete.add(name)\n                instancers_to_create.add(name)\n\n        # Delete any instancers we no longer want\n        for name in instancers_to_delete:\n            cls.remove_particle_instancer(name=name)\n\n        # Create any instancers we don't already have\n        for name in instancers_to_create:\n            idn = cls.particle_instancer_name_to_idn(name=name)\n            info = idn_to_info_mapping[idn]\n            cls.generate_particle_instancer(idn=idn, particle_group=info[\"group\"], n_particles=info[\"count\"])\n\n    @classmethod\n    def _dump_state(cls):\n        return OrderedDict(\n            n_particle_instancers=len(cls.particle_instancers),\n            instancer_idns=[inst.idn for inst in cls.particle_instancers.values()],\n            instancer_particle_groups=[inst.particle_group for inst in cls.particle_instancers.values()],\n            instancer_particle_counts=[inst.n_particles for inst in cls.particle_instancers.values()],\n            particle_states=OrderedDict(((name, inst.dump_state(serialized=False))\n                                         for name, inst in cls.particle_instancers.items())),\n        )\n\n    @classmethod\n    def _load_state(cls, state):\n        # TODO: Verify this is no longer an issue once omni's fluid writing is ready\n        if og.sim.is_playing():\n            # Post disclaimer, we cannot write to omni particle states when sim is playing currently\n            disclaimer(f\"We are attempting to load the [{cls.name}], a particle system, state, which requires writing \"\n                       f\"to individual particle positions.\\n\"\n                       f\"Currently, Omniverse does not respect writing to these \"\n                       f\"states, but this should be resolved by the next public release.\\n\"\n                       f\"As a result, the fluid state may not be set correctly.\\n\"\n                       f\"Two explicit cases where a failure case will occur:\\n\"\n                       f\"    - Isosurfaces: Because an extra physics step is required to render the fluid correctly\"\n                       f\"           when generating isosurfaces, we lose the ability to set positions afterwards\\n\"\n                       f\"    - Existing instance with different positions: Because this instance will not be deleted \"\n                       f\"           and recreated in the simulator, we lose the ability to set positions.\")\n\n        # Synchronize the particle instancers\n        cls._sync_particle_instancers(\n            idns=state[\"instancer_idns\"],\n            particle_groups=state[\"instancer_particle_groups\"],\n            particle_counts=state[\"instancer_particle_counts\"],\n        )\n\n        # Iterate over all particle states and load their respective states\n        for name, inst_state in state[\"particle_states\"].items():\n            cls.particle_instancers[name].load_state(inst_state, serialized=False)\n\n    @classmethod\n    def _serialize(cls, state):\n        # Array is number of particle instancers, then the corresponding states for each particle instancer\n        return np.concatenate([\n            [state[\"n_particle_instancers\"]],\n            state[\"instancer_idns\"],\n            state[\"instancer_particle_groups\"],\n            state[\"instancer_particle_counts\"],\n            *[cls.particle_instancers[name].serialize(inst_state)\n              for name, inst_state in state[\"particle_states\"].items()],\n        ]).astype(float)\n\n    @classmethod\n    def _deserialize(cls, state):\n        # Synchronize the particle instancers\n        n_instancers = int(state[0])\n        instancer_info = OrderedDict()\n        idx = 1\n        for info_name in (\"instancer_idns\", \"instancer_particle_groups\", \"instancer_particle_counts\"):\n            instancer_info[info_name] = state[idx: idx + n_instancers].astype(int).tolist()\n            idx += n_instancers\n        logging.debug(f\"Syncing {cls.name} particles with {n_instancers} instancers..\")\n        cls._sync_particle_instancers(\n            idns=instancer_info[\"instancer_idns\"],\n            particle_groups=instancer_info[\"instancer_particle_groups\"],\n            particle_counts=instancer_info[\"instancer_particle_counts\"],\n        )\n\n        # Procedurally deserialize the particle states\n        particle_states = OrderedDict()\n        for idn in instancer_info[\"instancer_idns\"]:\n            name = cls.particle_instancer_idn_to_name(idn=idn)\n            state_size = cls.particle_instancers[name].state_size\n            particle_states[name] = cls.particle_instancers[name].deserialize(state[idx: idx + state_size])\n            idx += state_size\n\n        return OrderedDict(\n            n_particle_instancers=n_instancers,\n            **instancer_info,\n            particle_states=particle_states,\n        ), idx\n\n    @classmethod\n    def set_scale_limits(cls, minimum=None, maximum=None):\n        \"\"\"\n        Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n\n        Args:\n            minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n                particles\n            maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n                particles\n        \"\"\"\n        if minimum is not None:\n            cls.min_scale = np.array(minimum)\n        if maximum is not None:\n            cls.max_scale = np.array(maximum)\n\n    @classmethod\n    def remove_all_particle_instancers(cls):\n        \"\"\"\n        Removes all particle instancers and deletes them from the simulator\n        \"\"\"\n        cls._sync_particle_instancers(idns=[], particle_groups=[], particle_counts=[])\n\n    @classmethod\n    def cache(cls):\n        \"\"\"\n        Cache the collision hits for all particle systems, to be used by the object state system to determine\n        if a particle is in contact with a given object.\n\n        Currently, state_cache includes the following entries:\n\n        \"obj_particle_contacts\": {\n            obj0: {\n                inst0: {particle_idx0, ...},\n                inst1: {...},\n                ...\n            },\n            obj1: ...,\n        },\n\n        where obji is an instance of BaseObject\n\n        \"link_particle_contacts\": {\n            link0: {\n                inst0: {particle_idx0, ...},\n                inst1: {...},\n                ...\n            },\n            link1: ...,\n        },\n\n        where linki is a string representing the link's (rigid body's) prim path\n\n        \"\"\"\n        obj_particle_contacts = defaultdict(lambda: defaultdict(set))\n        link_particle_contacts = defaultdict(lambda: defaultdict(set))\n\n        particle_instancer = None\n        particle_idx = 0\n\n        def report_hit(hit):\n            base, body = \"/\".join(hit.rigid_body.split(\"/\")[:-1]), hit.rigid_body.split(\"/\")[-1]\n            obj = cls.simulator.scene.object_registry(\"prim_path\", base)\n            if obj is not None:\n                link = obj.links[body]\n                obj_particle_contacts[obj][particle_instancer].add(particle_idx)\n                link_particle_contacts[link][particle_instancer].add(particle_idx)\n            return True\n\n        for inst_name, inst in cls.particle_instancers.items():\n            visibilities = inst.particle_visibilities\n            for idx, pos in enumerate(inst.particle_positions):\n                particle_idx = idx\n                particle_instancer = inst\n                # Only run the scene query if the particle is not hidden\n                if visibilities[idx]:\n                    get_physx_scene_query_interface().overlap_sphere(cls.particle_contact_offset, pos, report_hit, False)\n\n        cls.state_cache[\"obj_particle_contacts\"] = obj_particle_contacts\n        cls.state_cache[\"link_particle_contacts\"] = link_particle_contacts\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem"},{"title":"<code>cache()</code>  <code>classmethod</code>","text":"<p>Cache the collision hits for all particle systems, to be used by the object state system to determine if a particle is in contact with a given object.</p> <p>Currently, state_cache includes the following entries:</p> <p>\"obj_particle_contacts\": {     obj0: {         inst0: {particle_idx0, ...},         inst1: {...},         ...     },     obj1: ..., },</p> <p>where obji is an instance of BaseObject</p> <p>\"link_particle_contacts\": {     link0: {         inst0: {particle_idx0, ...},         inst1: {...},         ...     },     link1: ..., },</p> <p>where linki is a string representing the link's (rigid body's) prim path</p>  Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef cache(cls):\n    \"\"\"\n    Cache the collision hits for all particle systems, to be used by the object state system to determine\n    if a particle is in contact with a given object.\n\n    Currently, state_cache includes the following entries:\n\n    \"obj_particle_contacts\": {\n        obj0: {\n            inst0: {particle_idx0, ...},\n            inst1: {...},\n            ...\n        },\n        obj1: ...,\n    },\n\n    where obji is an instance of BaseObject\n\n    \"link_particle_contacts\": {\n        link0: {\n            inst0: {particle_idx0, ...},\n            inst1: {...},\n            ...\n        },\n        link1: ...,\n    },\n\n    where linki is a string representing the link's (rigid body's) prim path\n\n    \"\"\"\n    obj_particle_contacts = defaultdict(lambda: defaultdict(set))\n    link_particle_contacts = defaultdict(lambda: defaultdict(set))\n\n    particle_instancer = None\n    particle_idx = 0\n\n    def report_hit(hit):\n        base, body = \"/\".join(hit.rigid_body.split(\"/\")[:-1]), hit.rigid_body.split(\"/\")[-1]\n        obj = cls.simulator.scene.object_registry(\"prim_path\", base)\n        if obj is not None:\n            link = obj.links[body]\n            obj_particle_contacts[obj][particle_instancer].add(particle_idx)\n            link_particle_contacts[link][particle_instancer].add(particle_idx)\n        return True\n\n    for inst_name, inst in cls.particle_instancers.items():\n        visibilities = inst.particle_visibilities\n        for idx, pos in enumerate(inst.particle_positions):\n            particle_idx = idx\n            particle_instancer = inst\n            # Only run the scene query if the particle is not hidden\n            if visibilities[idx]:\n                get_physx_scene_query_interface().overlap_sphere(cls.particle_contact_offset, pos, report_hit, False)\n\n    cls.state_cache[\"obj_particle_contacts\"] = obj_particle_contacts\n    cls.state_cache[\"link_particle_contacts\"] = link_particle_contacts\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.cache"},{"title":"<code>generate_particle_instancer(n_particles, idn=None, particle_group=0, positions=None, velocities=None, orientations=None, scales=None, self_collision=True, prototype_indices=None)</code>  <code>classmethod</code>","text":"<p>Generates a new particle instancer with unique identification number @idn, and registers it internally</p> <p>Parameters:</p>    Name Type Description Default     <code>n_particles</code>  <code>int</code>  <p>Number of particles to generate for this instancer</p>  required    <code>idn</code>  <code>None or int</code>  <p>Unique identification number to assign to this particle instancer. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If None, this system will generate a unique identifier automatically.</p>  <code>None</code>    <code>particle_group</code>  <code>int</code>  <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision</p>  <code>0</code>    <code>positions</code>  <code>None or np.array</code>  <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) positions. If not specified, will be set to the origin by default</p>  <code>None</code>    <code>velocities</code>  <code>None or np.array</code>  <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) velocities. If not specified, all will be set to 0</p>  <code>None</code>    <code>orientations</code>  <code>None or np.array</code>  <p>(n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)</p>  <code>None</code>    <code>scales</code>  <code>None or np.array</code>  <p>(n_particles, 3) shaped array specifying per-particle (x,y,z) scales. If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)</p>  <code>None</code>    <code>self_collision</code>  <code>bool</code>  <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p>  <code>True</code>    <code>prototype_indices</code>  <code>None or list of int</code>  <p>If specified, should specify which prototype should be used for each particle. If None, will use all 0s (i.e.: the first prototype created)</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>PhysxParticleInstancer</code>   <p>Generated particle instancer</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particle_instancer(\n        cls,\n        n_particles,\n        idn=None,\n        particle_group=0,\n        positions=None,\n        velocities=None,\n        orientations=None,\n        scales=None,\n        self_collision=True,\n        prototype_indices=None,\n):\n    \"\"\"\n    Generates a new particle instancer with unique identification number @idn, and registers it internally\n\n    Args:\n        n_particles (int): Number of particles to generate for this instancer\n        idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n            deterministically reproduce individual particle instancer states dynamically, even if we\n            delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n            identifier automatically.\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision\n        positions (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) positions.\n            If not specified, will be set to the origin by default\n        velocities (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) velocities.\n            If not specified, all will be set to 0\n        orientations (None or np.array): (n_particles, 4) shaped array specifying per-particle (x,y,z,w) quaternion\n            orientations. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        scales (None or np.array): (n_particles, 3) shaped array specifying per-particle (x,y,z) scales.\n            If not specified, will be uniformly randomly sampled from (cls.min_scale, cls.max_scale)\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n            each particle. If None, will use all 0s (i.e.: the first prototype created)\n\n    Returns:\n        PhysxParticleInstancer: Generated particle instancer\n    \"\"\"\n    # Run sanity checks\n    assert cls.initialized, \"Must initialize system before generating particle instancers!\"\n\n    # Automatically generate an identification number for this instancer if none is specified\n    if idn is None:\n        idn = cls.max_instancer_idn + 1\n        # Also increment this counter\n        cls.max_instancer_idn += 1\n\n    # Generate standardized prim path for this instancer\n    name = cls.particle_instancer_idn_to_name(idn=idn)\n\n    # Create the instancer\n    instance = create_physx_particleset_pointinstancer(\n        name=name,\n        particle_system_path=cls.prim_path,\n        particle_group=particle_group,\n        positions=np.zeros((n_particles, 3)) if positions is None else positions,\n        self_collision=self_collision,\n        fluid=cls.is_fluid,\n        particle_mass=None,\n        particle_density=cls.particle_density,\n        orientations=orientations,\n        velocities=velocities,\n        angular_velocities=None,\n        scales=np.random.uniform(cls.min_scale, cls.max_scale, size=(n_particles, 3)) if scales is None else scales,\n        prototype_prim_paths=[pp.GetPrimPath().pathString for pp in cls.particle_prototypes],\n        prototype_indices=prototype_indices,\n        enabled=not cls.visual_only,\n    )\n\n    # Create the instancer object that wraps the raw prim\n    instancer = PhysxParticleInstancer(\n        prim_path=instance.GetPrimPath().pathString,\n        name=name,\n        idn=idn,\n    )\n    instancer.initialize()\n    cls.particle_instancers[name] = instancer\n\n    return instancer\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.generate_particle_instancer"},{"title":"<code>generate_particle_instancer_from_link(obj, link, mesh_name_prefixes=None, idn=None, particle_group=0, sampling_distance=None, max_samples=500000.0, sample_volume=True, self_collision=True, prototype_indices_choices=None)</code>  <code>classmethod</code>","text":"<p>Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh located at @mesh_prim_path, and registers it internally</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>EntityPrim</code>  <p>Object whose @link's visual meshes will be converted into sampled particles</p>  required    <code>link</code>  <code>RigidPrim</code>  <p>@obj's link whose visual meshes will be converted into sampled particles</p>  required    <code>mesh_name_prefixes</code>  <code>None or str</code>  <p>If specified, specifies the substring that must exist in @link's</p>  <code>None</code>    <code>idn</code>  <code>None or int</code>  <p>Unique identification number to assign to this particle instancer. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If None, this system will generate a unique identifier automatically.</p>  <code>None</code>    <code>particle_group</code>  <code>int</code>  <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision</p>  <code>0</code>    <code>sampling_distance</code>  <code>None or float</code>  <p>If specified, sets the distance between sampled particles. If None, a simulator autocomputed value will be used</p>  <code>None</code>    <code>max_samples</code>  <code>int</code>  <p>Maximum number of particles to sample</p>  <code>500000.0</code>    <code>sample_volume</code>  <code>bool</code>  <p>Whether to sample the particles at the mesh's surface or throughout its entire volume</p>  <code>True</code>    <code>self_collision</code>  <code>bool</code>  <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p>  <code>True</code>    <code>prototype_indices_choices</code>  <code>None or int or list of int</code>  <p>If specified, should specify which prototype(s) should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly sample from those IDs for each particle.</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>PhysxParticleInstancer</code>   <p>Generated particle instancer</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particle_instancer_from_link(\n        cls,\n        obj,\n        link,\n        mesh_name_prefixes=None,\n        idn=None,\n        particle_group=0,\n        sampling_distance=None,\n        max_samples=5e5,\n        sample_volume=True,\n        self_collision=True,\n        prototype_indices_choices=None,\n):\n    \"\"\"\n    Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh\n    located at @mesh_prim_path, and registers it internally\n\n    Args:\n        obj (EntityPrim): Object whose @link's visual meshes will be converted into sampled particles\n        link (RigidPrim): @obj's link whose visual meshes will be converted into sampled particles\n        mesh_name_prefixes (None or str): If specified, specifies the substring that must exist in @link's\n        mesh names in order for that mesh to be included in the particle generator function. If None, no filtering\n        will be used.\n        idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n            deterministically reproduce individual particle instancer states dynamically, even if we\n            delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n            identifier automatically.\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision\n        sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n            a simulator autocomputed value will be used\n        max_samples (int): Maximum number of particles to sample\n        sample_volume (bool): Whether to sample the particles at the mesh's surface or throughout its entire volume\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n            should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n            single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n            sample from those IDs for each particle.\n\n    Returns:\n        PhysxParticleInstancer: Generated particle instancer\n    \"\"\"\n    # Run sanity checks\n    assert cls.initialized, \"Must initialize system before generating particle instancers!\"\n    # TODO: Implement!\n    assert sample_volume, \"Sampling surface of link for particles is not supported yet!\"\n\n    # Generate a checker function to see if particles are within the link's volumes\n    check_in_volume, _ = generate_points_in_volume_checker_function(\n        obj=obj,\n        volume_link=link,\n        use_visual_meshes=True,\n        mesh_name_prefixes=mesh_name_prefixes,\n    )\n\n    # Grab the link's AABB (or fallback to obj AABB if link does not have a valid AABB),\n    # and generate a grid of points based on the sampling distance\n    try:\n        low, high = link.aabb\n        extent = link.aabb_extent\n    except ValueError:\n        low, high = obj.aabb\n        extent = obj.aabb_extent\n    # We sample the range of each extent minus\n    sampling_distance = 2 * cls.particle_radius if sampling_distance is None else sampling_distance\n    n_particles_per_axis = ((extent - 2 * cls.particle_radius) / sampling_distance).astype(int) + 1\n    arrs = [np.linspace(lo + cls.particle_radius, hi - cls.particle_radius, n) for lo, hi, n in zip(low, high, n_particles_per_axis)]\n    # Generate 3D-rectangular grid of points\n    particle_positions = np.stack([arr.flatten() for arr in np.meshgrid(*arrs)]).T\n    # Check which points are inside the volume and only keep those\n    particle_positions = particle_positions[np.where(check_in_volume(particle_positions))[0]]\n    # Also potentially sub-sample if we're past our limit\n    if len(particle_positions) &gt; max_samples:\n        particle_positions = particle_positions[np.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n\n    # Get information about our sampled points\n    n_particles = len(particle_positions)\n    if prototype_indices_choices is not None:\n        prototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n            isinstance(prototype_indices_choices, int) else \\\n            np.random.choice(prototype_indices_choices, size=(n_particles,))\n    else:\n        prototype_indices = None\n\n    # Create and return the generated instancer\n    return cls.generate_particle_instancer(\n        idn=idn,\n        particle_group=particle_group,\n        n_particles=n_particles,\n        positions=particle_positions,\n        velocities=None,\n        orientations=None,\n        scales=None,\n        self_collision=self_collision,\n        prototype_indices=prototype_indices,\n    )\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.generate_particle_instancer_from_link"},{"title":"<code>generate_particle_instancer_from_mesh(mesh_prim_path, idn=None, particle_group=0, sampling_distance=None, max_samples=500000.0, sample_volume=True, self_collision=True, prototype_indices_choices=None)</code>  <code>classmethod</code>","text":"<p>Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh located at @mesh_prim_path, and registers it internally</p> <p>Parameters:</p>    Name Type Description Default     <code>mesh_prim_path</code>  <code>str</code>  <p>Stage path to the mesh prim which will be converted into sampled particles</p>  required    <code>idn</code>  <code>None or int</code>  <p>Unique identification number to assign to this particle instancer. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If None, this system will generate a unique identifier automatically.</p>  <code>None</code>    <code>particle_group</code>  <code>int</code>  <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision</p>  <code>0</code>    <code>sampling_distance</code>  <code>None or float</code>  <p>If specified, sets the distance between sampled particles. If None, a simulator autocomputed value will be used</p>  <code>None</code>    <code>max_samples</code>  <code>int</code>  <p>Maximum number of particles to sample</p>  <code>500000.0</code>    <code>sample_volume</code>  <code>bool</code>  <p>Whether to sample the particles at the mesh's surface or throughout its entire volume</p>  <code>True</code>    <code>self_collision</code>  <code>bool</code>  <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p>  <code>True</code>    <code>prototype_indices_choices</code>  <code>None or int or list of int</code>  <p>If specified, should specify which prototype(s) should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly sample from those IDs for each particle.</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>PhysxParticleInstancer</code>   <p>Generated particle instancer</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particle_instancer_from_mesh(\n        cls,\n        mesh_prim_path,\n        idn=None,\n        particle_group=0,\n        sampling_distance=None,\n        max_samples=5e5,\n        sample_volume=True,\n        self_collision=True,\n        prototype_indices_choices=None,\n):\n    \"\"\"\n    Generates a new particle instancer with unique identification number @idn, with particles sampled from the mesh\n    located at @mesh_prim_path, and registers it internally\n\n    Args:\n        mesh_prim_path (str): Stage path to the mesh prim which will be converted into sampled particles\n        idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n            deterministically reproduce individual particle instancer states dynamically, even if we\n            delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n            identifier automatically.\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision\n        sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n            a simulator autocomputed value will be used\n        max_samples (int): Maximum number of particles to sample\n        sample_volume (bool): Whether to sample the particles at the mesh's surface or throughout its entire volume\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n            should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n            single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n            sample from those IDs for each particle.\n\n    Returns:\n        PhysxParticleInstancer: Generated particle instancer\n    \"\"\"\n    # Run sanity checks\n    assert cls.initialized, \"Must initialize system before generating particle instancers!\"\n    assert cls.simulator.is_stopped(), \"Can only sample particles from a mesh using Omni's API when simulator is stopped!\"\n\n    # Create points prim (this is used initially to generate the particles) and apply particle set API\n    points_prim_path = f\"{cls.prim_path}/tempSampledPoints\"\n    points = UsdGeom.Points.Define(cls.simulator.stage, points_prim_path).GetPrim()\n    particle_set_api = PhysxSchema.PhysxParticleSetAPI.Apply(points)\n    particle_set_api.CreateParticleSystemRel().SetTargets([cls.prim_path])\n\n    # Apply the sampling API to our mesh prim and apply the sampling\n    mesh_prim = get_prim_at_path(mesh_prim_path)\n    sampling_api = PhysxSchema.PhysxParticleSamplingAPI.Apply(mesh_prim)\n    sampling_api.CreateParticlesRel().AddTarget(points_prim_path)\n    sampling_api.CreateSamplingDistanceAttr().Set(0 if sampling_distance is None else sampling_distance)\n    sampling_api.CreateMaxSamplesAttr().Set(max_samples)\n    sampling_api.CreateVolumeAttr().Set(sample_volume)\n\n    # We apply 1 physics step to propagate the sampling (make sure to pause the sim since particles still propagate\n    # forward even if we don't explicitly call sim.step())\n    with cls.simulator.paused():\n        cls.simulator.step_physics()\n    time.sleep(0.1)                         # Empirically validated for ~2500 samples (0.02 time doesn't work)\n    cls.simulator.render()                  # Rendering is needed after an initial, nontrivial amount of time for the particles to actually be sampled\n\n    # Grab the actual positions, we will write this to a new instancer that's not tied to the sampler\n    # The points / instancer tied to the sampled mesh seems to operate a bit weirdly, which is why we do it this way\n    attr = \"positions\" if points.GetPrimTypeInfo().GetTypeName() == \"PointInstancer\" else \"points\"\n    pos = points.GetAttribute(attr).Get()\n\n    # Make sure sampling was successful\n    assert pos is not None and len(pos) &gt; 0, \"Failed to sample particle points from mesh prim!\"\n\n    # Delete the points prim and sampling API, we don't need it anymore, and make the mesh prim invisible again\n    cls.simulator.stage.RemovePrim(points_prim_path)\n    mesh_prim.RemoveAPI(PhysxSchema.PhysxParticleSamplingAPI)\n    UsdGeom.Imageable(mesh_prim).MakeInvisible()\n\n    # Get information about our sampled points\n    n_particles = len(pos)\n    if prototype_indices_choices is not None:\n        prototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n            isinstance(prototype_indices_choices, int) else \\\n            np.random.choice(prototype_indices_choices, size=(n_particles,))\n    else:\n        prototype_indices = None\n\n    # Create and return the generated instancer\n    return cls.generate_particle_instancer(\n        idn=idn,\n        particle_group=particle_group,\n        n_particles=n_particles,\n        positions=pos,\n        velocities=None,\n        orientations=None,\n        scales=None,\n        self_collision=self_collision,\n        prototype_indices=prototype_indices,\n    )\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.generate_particle_instancer_from_mesh"},{"title":"<code>generate_particle_instancer_on_object(obj, idn=None, particle_group=0, sampling_distance=None, max_samples=500000.0, self_collision=True, prototype_indices_choices=None)</code>  <code>classmethod</code>","text":"<p>Generates @n_particles new particle objects and samples their locations on the top surface of object @obj</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object on which to generate a particle instancer with sampled particles on the object's top surface</p>  required    <code>idn</code>  <code>None or int</code>  <p>Unique identification number to assign to this particle instancer. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation. If None, this system will generate a unique identifier automatically.</p>  <code>None</code>    <code>particle_group</code>  <code>int</code>  <p>ID for this particle set. Particles from different groups will automatically collide</p>  <code>0</code>    <code>sampling_distance</code>  <code>None or float</code>  <p>If specified, sets the distance between sampled particles. If None, a simulator autocomputed value will be used</p>  <code>None</code>    <code>max_samples</code>  <code>int</code>  <p>Maximum number of particles to sample</p>  <code>500000.0</code>    <code>self_collision</code>  <code>bool</code>  <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p>  <code>True</code>    <code>prototype_indices_choices</code>  <code>None or int or list of int</code>  <p>If specified, should specify which prototype(s) should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly sample from those IDs for each particle.</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>PhysxParticleInstancer</code>   <p>Generated particle instancer</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef generate_particle_instancer_on_object(\n        cls,\n        obj,\n        idn=None,\n        particle_group=0,\n        sampling_distance=None,\n        max_samples=5e5,\n        self_collision=True,\n        prototype_indices_choices=None,\n):\n    \"\"\"\n    Generates @n_particles new particle objects and samples their locations on the top surface of object @obj\n\n    Args:\n        obj (BaseObject): Object on which to generate a particle instancer with sampled particles on the object's\n            top surface\n        idn (None or int): Unique identification number to assign to this particle instancer. This is used to\n            deterministically reproduce individual particle instancer states dynamically, even if we\n            delete / add additional ones at runtime during simulation. If None, this system will generate a unique\n            identifier automatically.\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n        sampling_distance (None or float): If specified, sets the distance between sampled particles. If None,\n            a simulator autocomputed value will be used\n        max_samples (int): Maximum number of particles to sample\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        prototype_indices_choices (None or int or list of int): If specified, should specify which prototype(s)\n            should be used for each particle. If None, will use all 0s (i.e.: the first prototype created). If a\n            single number, will use that prototype ID for all sampled particles. If a list of int, will uniformly\n            sample from those IDs for each particle.\n\n    Returns:\n        PhysxParticleInstancer: Generated particle instancer\n    \"\"\"\n    # We densely sample a grid of points by ray-casting from top to bottom to find the valid positions\n    radius = cls.particle_radius\n    results = sample_cuboid_on_object_full_grid_topdown(\n        obj,\n        # the grid is fully dense - particles are sitting next to each other\n        ray_spacing=radius * 2 if sampling_distance is None else sampling_distance,\n        # assume the particles are extremely small - sample cuboids of size 0 for better performance\n        cuboid_dimensions=np.zeros(3),\n        # raycast start inside the aabb in x-y plane and outside the aabb in the z-axis\n        aabb_offset=np.array([-radius, -radius, radius]),\n        # bottom padding should be the same as the particle radius\n        cuboid_bottom_padding=radius,\n        # undo_cuboid_bottom_padding should be False - the sampled positions are above the surface by its radius\n        undo_cuboid_bottom_padding=False,\n    )\n    particle_positions = np.array([result[0] for result in results if result[0] is not None])\n    # Also potentially sub-sample if we're past our limit\n    if len(particle_positions) &gt; max_samples:\n        particle_positions = particle_positions[np.random.choice(len(particle_positions), size=(max_samples,), replace=False)]\n\n    # Get information about our sampled points\n    n_particles = len(particle_positions)\n    if prototype_indices_choices is not None:\n        prototype_indices = np.ones(n_particles, dtype=int) * prototype_indices_choices if \\\n            isinstance(prototype_indices_choices, int) else \\\n            np.random.choice(prototype_indices_choices, size=(n_particles,))\n    else:\n        prototype_indices = None\n\n    # Spawn the particles at the valid positions\n    cls.generate_particle_instancer(\n        n_particles=n_particles,\n        positions=particle_positions,\n        idn=idn,\n        particle_group=particle_group,\n        self_collision=self_collision,\n        prototype_indices=prototype_indices,\n    )\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.generate_particle_instancer_on_object"},{"title":"<code>is_fluid()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this system is modeling fluid or not</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef is_fluid(cls):\n    \"\"\"\n    Returns:\n        bool: Whether this system is modeling fluid or not\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.is_fluid"},{"title":"<code>mat_name()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this system's material</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef mat_name(cls):\n    \"\"\"\n    Returns:\n        str: Name of this system's material\n    \"\"\"\n    return f\"{cls.name}:material\"\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.mat_name"},{"title":"<code>mat_path()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Path to this system's material in the scene stage</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef mat_path(cls):\n    \"\"\"\n    Returns:\n        str: Path to this system's material in the scene stage\n    \"\"\"\n    return f\"{cls.prim_path}/{cls.name}_material\"\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.mat_path"},{"title":"<code>material()</code>","text":"<p>Returns:</p>    Type Description       <p>None or MaterialPrim: The bound material to this prim, if there is one</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef material(cls):\n    \"\"\"\n    Returns:\n        None or MaterialPrim: The bound material to this prim, if there is one\n    \"\"\"\n    return cls._material\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.material"},{"title":"<code>n_particles()</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of active particles in this system</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef n_particles(cls):\n    \"\"\"\n    Returns:\n        int: Number of active particles in this system\n    \"\"\"\n    return sum([instancer.n_particles for instancer in cls.particle_instancers.values()])\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.n_particles"},{"title":"<code>particle_contact_offset()</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Contact offset value to use for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#particle-system-configuration for more information</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_contact_offset(cls):\n    \"\"\"\n    Returns:\n        float: Contact offset value to use for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#particle-system-configuration\n            for more information\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_contact_offset"},{"title":"<code>particle_density()</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>The per-particle density, in kg / m^3</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_density(cls):\n    \"\"\"\n    Returns:\n        float: The per-particle density, in kg / m^3\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_density"},{"title":"<code>particle_instancer_idn_to_name(idn)</code>  <code>classmethod</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>idn</code>  <code>idn</code>  <p>Particle instancer identification number</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of the particle instancer auto-generated from its unique identification number</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef particle_instancer_idn_to_name(cls, idn):\n    \"\"\"\n    Args:\n        idn (idn): Particle instancer identification number\n\n    Returns:\n        str: Name of the particle instancer auto-generated from its unique identification number\n    \"\"\"\n    return f\"{cls.name}Instancer{idn}\"\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_instancer_idn_to_name"},{"title":"<code>particle_instancer_name_to_idn(name)</code>  <code>classmethod</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>Particle instancer name</p>  required     <p>Returns:</p>    Name Type Description     <code>int</code>   <p>Particle instancer identification number</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef particle_instancer_name_to_idn(cls, name):\n    \"\"\"\n    Args:\n        name (str): Particle instancer name\n\n    Returns:\n        int: Particle instancer identification number\n    \"\"\"\n    return int(name.split(f\"{cls.name}Instancer\")[-1])\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_instancer_name_to_idn"},{"title":"<code>particle_radius()</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Radius for the particles to be generated, since all fluids are composed of spheres</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_radius(cls):\n    \"\"\"\n    Returns:\n        float: Radius for the particles to be generated, since all fluids are composed of spheres\n    \"\"\"\n    # Magic number from omni tutorials\n    # See https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_physics.html#offset-autocomputation\n    return 0.99 * 0.6 * cls.particle_contact_offset if cls.is_fluid else 0.99 * cls.particle_contact_offset\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_radius"},{"title":"<code>particle_system_exists()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this particle system already exists on the current stage. Useful for internal logic synchronization during, e.g., initialization, where a USD snapshot may have been loaded with a particle system already on the stage</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef particle_system_exists(cls):\n    \"\"\"\n    Returns:\n        bool: Whether this particle system already exists on the current stage. Useful for internal logic\n            synchronization during, e.g., initialization, where a USD snapshot may have been loaded with a particle\n            system already on the stage\n    \"\"\"\n    return is_prim_path_valid(cls.prim_path)\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.particle_system_exists"},{"title":"<code>prim_path()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Path to this system's prim in the scene stage</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef prim_path(cls):\n    \"\"\"\n    Returns:\n        str: Path to this system's prim in the scene stage\n    \"\"\"\n    return f\"/World/{cls.name}\"\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.prim_path"},{"title":"<code>remove_all_particle_instancers()</code>  <code>classmethod</code>","text":"<p>Removes all particle instancers and deletes them from the simulator</p>  Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef remove_all_particle_instancers(cls):\n    \"\"\"\n    Removes all particle instancers and deletes them from the simulator\n    \"\"\"\n    cls._sync_particle_instancers(idns=[], particle_groups=[], particle_counts=[])\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.remove_all_particle_instancers"},{"title":"<code>remove_particle_instancer(name)</code>  <code>classmethod</code>","text":"<p>Removes particle instancer with name @name from this system.</p> <p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>Particle instancer name to remove. If it does not exist, then an error will be raised</p>  required      Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef remove_particle_instancer(cls, name):\n    \"\"\"\n    Removes particle instancer with name @name from this system.\n\n    Args:\n        name (str): Particle instancer name to remove. If it does not exist, then an error will be raised\n    \"\"\"\n    # Make sure the instancer actually exists\n    assert_valid_key(key=name, valid_keys=cls.particle_instancers, name=\"particle instancer\")\n    # Remove instancer from our tracking and delete its prim\n    instancer = cls.particle_instancers.pop(name)\n    instancer.remove(simulator=cls.simulator)\n    cls.simulator.stage.RemovePrim(f\"{get_prototype_path_from_particle_system_path(particle_system_path=cls.prim_path)}/{name}\")\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.remove_particle_instancer"},{"title":"<code>set_scale_limits(minimum=None, maximum=None)</code>  <code>classmethod</code>","text":"<p>Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles</p> <p>Parameters:</p>    Name Type Description Default     <code>minimum</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) minimum scaling factor to apply to generated particles</p>  <code>None</code>    <code>maximum</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) maximum scaling factor to apply to generated particles</p>  <code>None</code>      Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classmethod\ndef set_scale_limits(cls, minimum=None, maximum=None):\n    \"\"\"\n    Set the min and / or max scaling limits that will be uniformly sampled from when generating new particles\n\n    Args:\n        minimum (None or 3-array): If specified, should be (x,y,z) minimum scaling factor to apply to generated\n            particles\n        maximum (None or 3-array): If specified, should be (x,y,z) maximum scaling factor to apply to generated\n            particles\n    \"\"\"\n    if minimum is not None:\n        cls.min_scale = np.array(minimum)\n    if maximum is not None:\n        cls.max_scale = np.array(maximum)\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.set_scale_limits"},{"title":"<code>use_anisotropy()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether to use anisotropy or not for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#anisotropy for more information</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef use_anisotropy(cls):\n    \"\"\"\n    Returns:\n        bool: Whether to use anisotropy or not for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#anisotropy\n            for more information\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.use_anisotropy"},{"title":"<code>use_isosurface()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether to use isosurface or not for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#isosurface for more information</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef use_isosurface(cls):\n    \"\"\"\n    Returns:\n        bool: Whether to use isosurface or not for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#isosurface\n            for more information\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.use_isosurface"},{"title":"<code>use_smoothing()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether to use smoothing or not for this particle system. See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#smoothing for more information</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef use_smoothing(cls):\n    \"\"\"\n    Returns:\n        bool: Whether to use smoothing or not for this particle system.\n            See https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#smoothing\n            for more information\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.use_smoothing"},{"title":"<code>visual_only()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this particle system should be visual-only, i.e.: not subject to collisions and physics. If True, the generated particles will not move or collide</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>@classproperty\ndef visual_only(cls):\n    \"\"\"\n    Returns:\n        bool: Whether this particle system should be visual-only, i.e.: not subject to collisions and physics. If True,\n            the generated particles will not move or collide\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.MicroParticleSystem.visual_only"},{"title":"<code>PhysxParticleInstancer</code>","text":"<p>         Bases: <code>BasePrim</code></p> <p>Simple class that wraps the raw omniverse point instancer prim and provides convenience functions for particle access</p>  Source code in <code>systems/micro_particle_system.py</code> <pre><code>class PhysxParticleInstancer(BasePrim):\n    \"\"\"\n    Simple class that wraps the raw omniverse point instancer prim and provides convenience functions for\n    particle access\n    \"\"\"\n    def __init__(self, prim_path, name, idn):\n        \"\"\"\n        Args:\n            prim_path (str): prim path of the Prim to encapsulate or create.\n            name (str): Name for the object. Names need to be unique per scene.\n            idn (int): Unique identification number to assign to this particle instancer. This is used to\n                deterministically reproduce individual particle instancer states dynamically, even if we\n                delete / add additional ones at runtime during simulation.\n        \"\"\"\n        # Store inputs\n        self._idn = idn\n\n        # Values loaded at runtime\n        self._n_particles = None\n\n        # Run super method directly\n        super().__init__(prim_path=prim_path, name=name)\n\n    def _load(self, simulator=None):\n        # We raise an error, this should NOT be created from scratch\n        raise NotImplementedError(\"PhysxPointInstancer should NOT be loaded via this class! Should be created before.\")\n\n    def _post_load(self):\n        # Run super\n        super()._post_load()\n\n        # Store how many particles we have\n        self._n_particles = len(self.particle_positions)\n\n        # Set the invisibleIds to be 0, and all particles to be 1\n        self.set_attribute(attr=\"ids\", val=np.ones(self._n_particles))\n        self.set_attribute(attr=\"invisibleIds\", val=[0])\n\n    def _initialize(self):\n        # Run super first\n        super()._initialize()\n\n    @property\n    def n_particles(self):\n        \"\"\"\n        Returns:\n            int: Number of particles owned by this instancer\n        \"\"\"\n        return self._n_particles\n\n    @property\n    def idn(self):\n        \"\"\"\n        Returns:\n            int: Identification number of this particle instancer\n        \"\"\"\n        return self._idn\n\n    @property\n    def particle_group(self):\n        \"\"\"\n        Returns:\n            int: Particle group this instancer belongs to\n        \"\"\"\n        return self.get_attribute(attr=\"physxParticle:particleGroup\")\n\n    @property\n    def position(self):\n        \"\"\"\n        Returns:\n            3-array: (x,y,z) translation of this point instancer relative to its parent prim\n        \"\"\"\n        return np.array(self.get_attribute(attr=\"xformOp:translate\"))\n\n    @position.setter\n    def position(self, pos):\n        \"\"\"\n        Sets this point instancer's (x,y,z) cartesian translation relative to its parent prim\n\n        Args:\n            pos (3-array): (x,y,z) relative position to set this prim relative to its parent prim\n        \"\"\"\n        self.set_attribute(attr=\"xformOp:translate\", val=Gf.Vec3f(*(pos.astype(float))))\n\n    @property\n    def particle_positions(self):\n        \"\"\"\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\n        return np.array(self.get_attribute(attr=\"positions\")) + self.position\n\n    @particle_positions.setter\n    def particle_positions(self, pos):\n        \"\"\"\n        Set the particle positions for this instancer\n\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired positions are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\n        assert pos.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {pos.shape[0]}, vs. number of particles {self._n_particles}!\"\n        pos = (pos - self.position).astype(float)\n        self.set_attribute(attr=\"positions\", val=array_to_vtarray(arr=pos, element_type=Gf.Vec3f))\n\n    @property\n    def particle_orientations(self):\n        \"\"\"\n        Returns:\n            np.array: (N, 4) numpy array, where each of the N particles' orientations are expressed in (x,y,z,w)\n                quaternion coordinates relative to this instancer's parent prim\n        \"\"\"\n        oris = self.get_attribute(attr=\"orientations\")\n        if oris is None:\n            # Default orientations for all particles\n            oris = np.zeros((self.n_particles, 4))\n            oris[:, -1] = 1.0\n        return np.array(oris)\n\n    @particle_orientations.setter\n    def particle_orientations(self, quat):\n        \"\"\"\n        Set the particle positions for this instancer\n\n        Args:\n            np.array: (N, 4) numpy array, where each of the N particles' desired orientations are expressed in (x,y,z,w)\n                quaternion coordinates relative to this instancer's parent prim\n        \"\"\"\n        assert quat.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {quat.shape[0]}, vs. number of particles {self._n_particles}!\"\n        # Swap w position, since Quath takes (w,x,y,z)\n        quat = quat.astype(float)\n        quat = quat[:, [3, 0, 1, 2]]\n        self.set_attribute(attr=\"orientations\", val=array_to_vtarray(arr=quat, element_type=Gf.Quath))\n\n    @property\n    def particle_velocities(self):\n        \"\"\"\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' velocities are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\n        return np.array(self.get_attribute(attr=\"velocities\"))\n\n    @particle_velocities.setter\n    def particle_velocities(self, vel):\n        \"\"\"\n        Set the particle velocities for this instancer\n\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired velocities are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\n        assert vel.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {vel.shape[0]}, vs. number of particles {self._n_particles}!\"\n        vel = vel.astype(float)\n        self.set_attribute(attr=\"velocities\", val=array_to_vtarray(arr=vel, element_type=Gf.Vec3f))\n\n    @property\n    def particle_scales(self):\n        \"\"\"\n        Returns:\n            np.array: (N, 3) numpy array, where each of the N particles' scales are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\n        scales = self.get_attribute(attr=\"scales\")\n        return np.ones((self._n_particles, 3)) if scales is None else np.array(scales)\n\n    @particle_scales.setter\n    def particle_scales(self, scales):\n        \"\"\"\n        Set the particle scales for this instancer\n\n        Args:\n            np.array: (N, 3) numpy array, where each of the N particles' desired scales are expressed in (x,y,z)\n                cartesian coordinates relative to this instancer's parent prim\n        \"\"\"\n        assert scales.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {scales.shape[0]}, vs. number of particles {self._n_particles}!\"\n        scales = scales.astype(float)\n        self.set_attribute(attr=\"scales\", val=array_to_vtarray(arr=scales, element_type=Gf.Vec3f))\n\n    @property\n    def particle_prototype_ids(self):\n        \"\"\"\n        Returns:\n            np.array: (N,) numpy array, where each of the N particles' prototype_id (i.e.: which prototype is being used\n                for that particle)\n        \"\"\"\n        ids = self.get_attribute(attr=\"protoIndices\")\n        return np.zeros(self.n_particles) if ids is None else np.array(ids)\n\n    @particle_prototype_ids.setter\n    def particle_prototype_ids(self, prototype_ids):\n        \"\"\"\n        Set the particle prototype_ids for this instancer\n\n        Args:\n            np.array: (N,) numpy array, where each of the N particles' desired prototype_id\n                (i.e.: which prototype is being used for that particle)\n        \"\"\"\n        assert prototype_ids.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {prototype_ids.shape[0]}, vs. number of particles {self._n_particles}!\"\n        self.set_attribute(attr=\"protoIndices\", val=prototype_ids)\n\n    @property\n    def particle_visibilities(self):\n        \"\"\"\n        Returns:\n            np.array: (N,) numpy array, where each entry is the specific particle's visibility\n                (1 if visible, 0 otherwise)\n        \"\"\"\n        # We leverage the ids + invisibleIds prim fields to infer visibility\n        # id = 1 means visible, id = 0 means invisible\n        ids = self.get_attribute(\"ids\")\n        return np.ones(self.n_particles) if ids is None else np.array(ids)\n\n    @particle_visibilities.setter\n    def particle_visibilities(self, visibilities):\n        \"\"\"\n        Set the particle visibilities for this instancer\n\n        Args:\n            np.array: (N,) numpy array, where each entry is the specific particle's desired visibility\n                (1 if visible, 0 otherwise)\n        \"\"\"\n        assert visibilities.shape[0] == self._n_particles, \\\n            f\"Got mismatch in particle setting size: {visibilities.shape[0]}, vs. number of particles {self._n_particles}!\"\n        # We leverage the ids + invisibleIds prim fields to infer visibility\n        # id = 1 means visible, id = 0 means invisible\n        self.set_attribute(attr=\"ids\", val=visibilities)\n\n    def _dump_state(self):\n        return OrderedDict(\n            idn=self._idn,\n            particle_group=self.particle_group,\n            n_particles=self._n_particles,\n            position=self.position,\n            particle_positions=self.particle_positions,\n            particle_velocities=self.particle_velocities,\n            particle_orientations=self.particle_orientations,\n            particle_scales=self.particle_scales,\n            particle_prototype_ids=self.particle_prototype_ids,\n        )\n\n    def _load_state(self, state):\n        # Sanity check the identification number and particle group\n        assert self._idn == state[\"idn\"], f\"Got mismatch in identification number for this particle instancer when \" \\\n            f\"loading state! Should be: {self._idn}, got: {state['idn']}.\"\n        assert self.particle_group == state[\"particle_group\"], f\"Got mismatch in particle group for this particle \" \\\n            f\"instancer when loading state! Should be: {self.particle_group}, got: {state['particle_group']}.\"\n\n        # Set values appropriately\n        self._n_particles = state[\"n_particles\"]\n        for attr in (\"positions\", \"velocities\", \"orientations\", \"scales\", \"prototype_ids\"):\n            attr_name = f\"particle_{attr}\"\n            # Make sure the loaded state is a numpy array, it could have been accidentally casted into a list during\n            # JSON-serialization\n            attr_val = np.array(state[attr_name]) if not isinstance(attr_name, np.ndarray) else state[attr_name]\n            setattr(self, attr_name, attr_val)\n\n    def _serialize(self, state):\n        # Compress into a 1D array\n         return np.concatenate([\n             [state[\"idn\"], state[\"particle_group\"], state[\"n_particles\"]],\n             state[\"position\"],\n             state[\"particle_positions\"].reshape(-1),\n             state[\"particle_velocities\"].reshape(-1),\n             state[\"particle_orientations\"].reshape(-1),\n             state[\"particle_scales\"].reshape(-1),\n             state[\"particle_prototype_ids\"],\n         ]).astype(float)\n\n    def _deserialize(self, state):\n        # Sanity check the identification number\n        assert self._idn == state[0], f\"Got mismatch in identification number for this particle instancer when \" \\\n            f\"deserializing state! Should be: {self._idn}, got: {state[0]}.\"\n        assert self.particle_group == state[1], f\"Got mismatch in particle group for this particle \" \\\n            f\"instancer when deserializing state! Should be: {self.particle_group}, got: {state[1]}.\"\n\n        # De-compress from 1D array\n        n_particles = int(state[2])\n        state_dict = OrderedDict(\n            idn=int(state[0]),\n            particle_group=int(state[1]),\n            n_particles=n_particles,\n        )\n\n        # Process remaining keys and reshape automatically\n        keys = (\"position\", \"particle_positions\", \"particle_velocities\", \"particle_orientations\", \"particle_scales\", \"particle_prototype_ids\")\n        sizes = ((3,), (n_particles, 3), (n_particles, 3), (n_particles, 4), (n_particles, 3), (n_particles,))\n\n        idx = 3\n        for key, size in zip(keys, sizes):\n            length = np.product(size)\n            state_dict[key] = state[idx: idx + length].reshape(size)\n            idx += length\n\n        return state_dict, idx\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer"},{"title":"<code>idn</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Identification number of this particle instancer</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.idn"},{"title":"<code>n_particles</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of particles owned by this instancer</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.n_particles"},{"title":"<code>particle_group</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Particle group this instancer belongs to</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_group"},{"title":"<code>particle_orientations</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>np.array: (N, 4) numpy array, where each of the N particles' orientations are expressed in (x,y,z,w) quaternion coordinates relative to this instancer's parent prim</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_orientations"},{"title":"<code>particle_positions</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>np.array: (N, 3) numpy array, where each of the N particles' positions are expressed in (x,y,z) cartesian coordinates relative to this instancer's parent prim</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_positions"},{"title":"<code>particle_prototype_ids</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>np.array: (N,) numpy array, where each of the N particles' prototype_id (i.e.: which prototype is being used for that particle)</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_prototype_ids"},{"title":"<code>particle_scales</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>np.array: (N, 3) numpy array, where each of the N particles' scales are expressed in (x,y,z) cartesian coordinates relative to this instancer's parent prim</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_scales"},{"title":"<code>particle_velocities</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>np.array: (N, 3) numpy array, where each of the N particles' velocities are expressed in (x,y,z) cartesian coordinates relative to this instancer's parent prim</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_velocities"},{"title":"<code>particle_visibilities</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>np.array: (N,) numpy array, where each entry is the specific particle's visibility (1 if visible, 0 otherwise)</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.particle_visibilities"},{"title":"<code>position</code>  <code>writable</code> <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: (x,y,z) translation of this point instancer relative to its parent prim</p>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.position"},{"title":"<code>__init__(prim_path, name, idn)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>prim path of the Prim to encapsulate or create.</p>  required    <code>name</code>  <code>str</code>  <p>Name for the object. Names need to be unique per scene.</p>  required    <code>idn</code>  <code>int</code>  <p>Unique identification number to assign to this particle instancer. This is used to deterministically reproduce individual particle instancer states dynamically, even if we delete / add additional ones at runtime during simulation.</p>  required      Source code in <code>systems/micro_particle_system.py</code> <pre><code>def __init__(self, prim_path, name, idn):\n    \"\"\"\n    Args:\n        prim_path (str): prim path of the Prim to encapsulate or create.\n        name (str): Name for the object. Names need to be unique per scene.\n        idn (int): Unique identification number to assign to this particle instancer. This is used to\n            deterministically reproduce individual particle instancer states dynamically, even if we\n            delete / add additional ones at runtime during simulation.\n    \"\"\"\n    # Store inputs\n    self._idn = idn\n\n    # Values loaded at runtime\n    self._n_particles = None\n\n    # Run super method directly\n    super().__init__(prim_path=prim_path, name=name)\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.PhysxParticleInstancer.__init__"},{"title":"<code>get_fluid_systems()</code>","text":"<p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Mapping from fluid system name to fluid system</p>     Source code in <code>systems/micro_particle_system.py</code> <pre><code>def get_fluid_systems():\n    \"\"\"\n    Returns:\n        OrderedDict: Mapping from fluid system name to fluid system\n    \"\"\"\n    systems = OrderedDict()\n    for system in SYSTEMS_REGISTRY.objects:\n        if issubclass(system, FluidSystem):\n            systems[system.name] = system\n\n    return systems\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.get_fluid_systems"},{"title":"<code>set_carb_settings_for_fluid_isosurface()</code>","text":"<p>Sets relevant rendering settings in the carb settings in order to use isosurface effectively</p>  Source code in <code>systems/micro_particle_system.py</code> <pre><code>def set_carb_settings_for_fluid_isosurface():\n    \"\"\"\n    Sets relevant rendering settings in the carb settings in order to use isosurface effectively\n    \"\"\"\n    # Settings for Isosurface\n    isregistry = carb.settings.acquire_settings_interface()\n    # disable grid and lights\n    dOptions = isregistry.get_as_int(\"persistent/app/viewport/displayOptions\")\n    dOptions &amp;= ~(1 &lt;&lt; 6 | 1 &lt;&lt; 8)\n    isregistry.set_int(\"persistent/app/viewport/displayOptions\", dOptions)\n    isregistry.set_bool(SETTING_UPDATE_TO_USD, True)\n    isregistry.set_int(SETTING_NUM_THREADS, 8)\n    isregistry.set_bool(SETTING_UPDATE_VELOCITIES_TO_USD, False)\n    isregistry.set_bool(SETTING_UPDATE_PARTICLES_TO_USD, True)     # TODO: Why does setting this value --&gt; True result in no isosurface being rendered?\n    isregistry.set_int(\"persistent/simulation/minFrameRate\", 60)\n    isregistry.set_bool(\"rtx-defaults/pathtracing/lightcache/cached/enabled\", False)\n    isregistry.set_bool(\"rtx-defaults/pathtracing/cached/enabled\", False)\n    isregistry.set_int(\"rtx-defaults/pathtracing/fireflyFilter/maxIntensityPerSample\", 10000)\n    isregistry.set_int(\"rtx-defaults/pathtracing/fireflyFilter/maxIntensityPerSampleDiffuse\", 50000)\n    isregistry.set_float(\"rtx-defaults/pathtracing/optixDenoiser/blendFactor\", 0.09)\n    isregistry.set_int(\"rtx-defaults/pathtracing/aa/op\", 2)\n    isregistry.set_int(\"rtx-defaults/pathtracing/maxBounces\", 32)\n    isregistry.set_int(\"rtx-defaults/pathtracing/maxSpecularAndTransmissionBounces\", 16)\n    isregistry.set_int(\"rtx-defaults/post/dlss/execMode\", 1)\n    isregistry.set_int(\"rtx-defaults/translucency/maxRefractionBounces\", 12)\n</code></pre>","location":"reference/systems/micro_particle_system.html#systems.micro_particle_system.set_carb_settings_for_fluid_isosurface"},{"title":"particle_system_base","text":"","location":"reference/systems/particle_system_base.html"},{"title":"<code>BaseParticleSystem</code>","text":"<p>         Bases: <code>BaseSystem</code></p> <p>Global system for modeling particles, e.g.: dirt, water, etc.</p>  Source code in <code>systems/particle_system_base.py</code> <pre><code>class BaseParticleSystem(BaseSystem):\n    \"\"\"\n    Global system for modeling particles, e.g.: dirt, water, etc.\n    \"\"\"\n\n    @classproperty\n    def n_particles(cls):\n        \"\"\"\n        Returns:\n            int: Number of active particles in this system\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def color(cls):\n        \"\"\"\n        Returns:\n            3-array: (R,G,B) color of the particles generated from this system\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>","location":"reference/systems/particle_system_base.html#systems.particle_system_base.BaseParticleSystem"},{"title":"<code>color()</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: (R,G,B) color of the particles generated from this system</p>     Source code in <code>systems/particle_system_base.py</code> <pre><code>@classproperty\ndef color(cls):\n    \"\"\"\n    Returns:\n        3-array: (R,G,B) color of the particles generated from this system\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/particle_system_base.html#systems.particle_system_base.BaseParticleSystem.color"},{"title":"<code>n_particles()</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Number of active particles in this system</p>     Source code in <code>systems/particle_system_base.py</code> <pre><code>@classproperty\ndef n_particles(cls):\n    \"\"\"\n    Returns:\n        int: Number of active particles in this system\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/systems/particle_system_base.html#systems.particle_system_base.BaseParticleSystem.n_particles"},{"title":"system_base","text":"","location":"reference/systems/system_base.html"},{"title":"<code>BaseSystem</code>","text":"<p>         Bases: <code>SerializableNonInstance</code>, <code>UniquelyNamedNonInstance</code></p> <p>Base class for all systems. These are non-instance objects that should be used globally for a given environment. This is useful for items in a scene that are non-discrete / cannot be distinguished into individual instances, e.g.: water, particles, etc.</p>  Source code in <code>systems/system_base.py</code> <pre><code>class BaseSystem(SerializableNonInstance, UniquelyNamedNonInstance):\n    \"\"\"\n    Base class for all systems. These are non-instance objects that should be used globally for a given environment.\n    This is useful for items in a scene that are non-discrete / cannot be distinguished into individual instances,\n    e.g.: water, particles, etc.\n    \"\"\"\n    def __init_subclass__(cls, **kwargs):\n        # Run super init\n        super().__init_subclass__(**kwargs)\n\n        global SYSTEMS_REGISTRY\n        # Register this system if requested\n        if cls._register_system:\n            print(f\"registering system: {cls.name}\")\n            SYSTEMS_REGISTRY.add(obj=cls)\n\n    # Simulator reference\n    simulator = None\n\n    @classproperty\n    def name(cls):\n        # Class name is the unique name assigned\n        return cls.__name__\n\n    @classproperty\n    def _register_system(cls):\n        \"\"\"\n        Returns:\n            bool: True if this system should be registered (i.e.: it is not an intermediate class but a \"final\" subclass\n                representing a system we'd actually like to use, e.g.: WaterSystem, DustSystem, etc. Should be set by\n                the subclass\n        \"\"\"\n        # We assume we aren't registering by default\n        return False\n\n    @classproperty\n    def initialized(cls):\n        \"\"\"\n        Returns:\n            bool: True if this system has been initialized via cls.initialize(...), else False\n        \"\"\"\n        # We are initialized if we have an internal simulator reference\n        return cls.simulator is not None\n\n    @classmethod\n    def initialize(cls, simulator):\n        \"\"\"\n        Initializes this system. Default behavior is to simply store the @simulator reference internally\n        \"\"\"\n        assert not cls.initialized, f\"Already initialized system {cls.name}!\"\n        cls.simulator = simulator\n\n    @classmethod\n    def clear(cls):\n        \"\"\"\n        Clears this system, so that it may possibly be re-initialized. Useful for, e.g., when loading from a new\n        scene during the same sim instance\n        \"\"\"\n        if cls.initialized:\n            cls.reset()\n            cls.simulator = None\n\n    @classmethod\n    def cache(cls):\n        \"\"\"\n        Cache any necessary system level state info used by the object state system.\n        \"\"\"\n        pass\n\n    @classmethod\n    def update(cls):\n        \"\"\"\n        Conduct any necessary internal updates after a simulation step\n        \"\"\"\n        pass\n\n    @classmethod\n    def reset(cls):\n        \"\"\"\n        Reset this system\n        \"\"\"\n        pass\n\n    def __init__(self):\n        raise ValueError(\"System classes should not be created!\")\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.BaseSystem"},{"title":"<code>cache()</code>  <code>classmethod</code>","text":"<p>Cache any necessary system level state info used by the object state system.</p>  Source code in <code>systems/system_base.py</code> <pre><code>@classmethod\ndef cache(cls):\n    \"\"\"\n    Cache any necessary system level state info used by the object state system.\n    \"\"\"\n    pass\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.BaseSystem.cache"},{"title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clears this system, so that it may possibly be re-initialized. Useful for, e.g., when loading from a new scene during the same sim instance</p>  Source code in <code>systems/system_base.py</code> <pre><code>@classmethod\ndef clear(cls):\n    \"\"\"\n    Clears this system, so that it may possibly be re-initialized. Useful for, e.g., when loading from a new\n    scene during the same sim instance\n    \"\"\"\n    if cls.initialized:\n        cls.reset()\n        cls.simulator = None\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.BaseSystem.clear"},{"title":"<code>initialize(simulator)</code>  <code>classmethod</code>","text":"<p>Initializes this system. Default behavior is to simply store the @simulator reference internally</p>  Source code in <code>systems/system_base.py</code> <pre><code>@classmethod\ndef initialize(cls, simulator):\n    \"\"\"\n    Initializes this system. Default behavior is to simply store the @simulator reference internally\n    \"\"\"\n    assert not cls.initialized, f\"Already initialized system {cls.name}!\"\n    cls.simulator = simulator\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.BaseSystem.initialize"},{"title":"<code>initialized()</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if this system has been initialized via cls.initialize(...), else False</p>     Source code in <code>systems/system_base.py</code> <pre><code>@classproperty\ndef initialized(cls):\n    \"\"\"\n    Returns:\n        bool: True if this system has been initialized via cls.initialize(...), else False\n    \"\"\"\n    # We are initialized if we have an internal simulator reference\n    return cls.simulator is not None\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.BaseSystem.initialized"},{"title":"<code>reset()</code>  <code>classmethod</code>","text":"<p>Reset this system</p>  Source code in <code>systems/system_base.py</code> <pre><code>@classmethod\ndef reset(cls):\n    \"\"\"\n    Reset this system\n    \"\"\"\n    pass\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.BaseSystem.reset"},{"title":"<code>update()</code>  <code>classmethod</code>","text":"<p>Conduct any necessary internal updates after a simulation step</p>  Source code in <code>systems/system_base.py</code> <pre><code>@classmethod\ndef update(cls):\n    \"\"\"\n    Conduct any necessary internal updates after a simulation step\n    \"\"\"\n    pass\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.BaseSystem.update"},{"title":"<code>get_element_name_from_system(system)</code>","text":"<p>Grabs system element name representing the element being controlled by system @system</p> <p>Parameters:</p>    Name Type Description Default     <code>system</code>  <code>BaseSystem</code>  <p>system from which to grab element name</p>  required     <p>Returns:</p>    Name Type Description     <code>BaseSystem</code>   <p>Corresponding system singleton</p>     Source code in <code>systems/system_base.py</code> <pre><code>def get_element_name_from_system(system):\n    \"\"\"\n    Grabs system element name representing the element being controlled by system @system\n\n    Args:\n        system (BaseSystem): system from which to grab element name\n\n    Returns:\n        BaseSystem: Corresponding system singleton\n    \"\"\"\n    systems = {v: k for k, v in SYSTEMS_REGISTRY.get_dict(\"__name__\").items()}\n    assert_valid_key(key=system, valid_keys=systems, name=\"system\")\n    return systems[system].split(\"System\")[0]\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.get_element_name_from_system"},{"title":"<code>get_system_from_element_name(name)</code>","text":"<p>Grabs system based on its element name @name that it controls (e.g.: Water, Dust, Stain, etc....)</p> <p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>element name corresponding to the desired system to grab</p>  required     <p>Returns:</p>    Name Type Description     <code>BaseSystem</code>   <p>Corresponding system singleton</p>     Source code in <code>systems/system_base.py</code> <pre><code>def get_system_from_element_name(name):\n    \"\"\"\n    Grabs system based on its element name @name that it controls (e.g.: Water, Dust, Stain, etc....)\n\n    Args:\n        name (str): element name corresponding to the desired system to grab\n\n    Returns:\n        BaseSystem: Corresponding system singleton\n    \"\"\"\n    systems = SYSTEMS_REGISTRY.get_dict(\"__name__\")\n    system_name = f\"{name}System\"\n    assert_valid_key(key=system_name, valid_keys=systems, name=\"system name\")\n    return systems[system_name]\n</code></pre>","location":"reference/systems/system_base.html#systems.system_base.get_system_from_element_name"},{"title":"tasks","text":"","location":"reference/tasks/index.html"},{"title":"bddl_backend","text":"","location":"reference/tasks/bddl_backend.html"},{"title":"behavior_task","text":"","location":"reference/tasks/behavior_task.html"},{"title":"<code>BehaviorTask</code>","text":"<p>         Bases: <code>BaseTask</code></p> <p>Task for BEHAVIOR</p> <p>Parameters:</p>    Name Type Description Default     <code>activity_name</code>  <code>None or str</code>  <p>Name of the Behavior Task to instantiate</p>  <code>None</code>    <code>activity_definition_id</code>  <code>int</code>  <p>Specification to load for the desired task. For a given Behavior Task, multiple task specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This ID determines which specification to use</p>  <code>0</code>    <code>activity_instance_id</code>  <code>int</code>  <p>Specific pre-configured instance of a scene to load for this BehaviorTask. This will be used only if @online_object_sampling is False.</p>  <code>0</code>    <code>predefined_problem</code>  <code>None or str</code>  <p>If specified, specifies the raw string definition of the Behavior Task to load. This will automatically override @activity_name and @activity_definition_id.</p>  <code>None</code>    <code>online_object_sampling</code>  <code>bool</code>  <p>whether to sample object locations online at runtime or not</p>  <code>False</code>    <code>debug_object_sampling</code>  <code>None or str</code>  <p>if specified, should be the object name to debug for placement functionality</p>  <code>None</code>    <code>highlight_task_relevant_objects</code>  <code>bool</code>  <p>whether to overlay task-relevant objects in the scene with a colored mask</p>  <code>False</code>    <code>termination_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p>  <code>None</code>    <code>reward_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p>  <code>None</code>      Source code in <code>tasks/behavior_task.py</code> <pre><code>class BehaviorTask(BaseTask):\n    \"\"\"\n    Task for BEHAVIOR\n\n    Args:\n        activity_name (None or str): Name of the Behavior Task to instantiate\n        activity_definition_id (int): Specification to load for the desired task. For a given Behavior Task, multiple task\n            specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This\n            ID determines which specification to use\n        activity_instance_id (int): Specific pre-configured instance of a scene to load for this BehaviorTask. This\n            will be used only if @online_object_sampling is False.\n        predefined_problem (None or str): If specified, specifies the raw string definition of the Behavior Task to\n            load. This will automatically override @activity_name and @activity_definition_id.\n        online_object_sampling (bool): whether to sample object locations online at runtime or not\n        debug_object_sampling (None or str): if specified, should be the object name to debug for placement functionality\n        highlight_task_relevant_objects (bool): whether to overlay task-relevant objects in the scene with a colored mask\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\n    def __init__(\n            self,\n            activity_name=None,\n            activity_definition_id=0,\n            activity_instance_id=0,\n            predefined_problem=None,\n            online_object_sampling=False,\n            debug_object_sampling=None,\n            highlight_task_relevant_objects=False,\n            termination_config=None,\n            reward_config=None,\n    ):\n        # Make sure task name is valid\n        with open(os.path.join(os.path.dirname(bddl.__file__), \"activity_manifest.txt\")) as f:\n            all_activities = {line.strip() for line in f.readlines()}\n            assert_valid_key(key=activity_name, valid_keys=all_activities, name=\"Behavior Task\")\n\n        # Initialize relevant variables\n\n        # BDDL\n        self.backend = OmniGibsonBDDLBackend()\n\n        # Activity info\n        self.activity_name = None\n        self.activity_definition_id = activity_definition_id\n        self.activity_instance_id = activity_instance_id\n        self.activity_conditions = None\n        self.activity_initial_conditions = None\n        self.activity_goal_conditions = None\n        self.activity_natural_language_goal_conditions = None\n        self.ground_goal_state_options = None\n        self.instruction_order = None\n        self.feedback = None\n        self.scene_model = None\n\n        # Object info\n        self.object_taxonomy = ObjectTaxonomy()\n        self.debug_object_sampling = debug_object_sampling\n        self.online_object_sampling = online_object_sampling\n        self.highlight_task_relevant_objs = highlight_task_relevant_objects\n        self.object_scope = None\n        self.object_instance_to_category = None\n        self.room_type_to_object_instance = None\n        self.non_sampleable_object_instances = None\n        self.non_sampleable_object_scope = None\n        self.non_sampleable_object_conditions = None\n        self.non_sampleable_object_scope_filtered_initial = None\n        self.object_sampling_orders = None\n        self.sampled_objects = None\n        self.sampleable_object_conditions = None\n\n        # Logic-tracking info\n        self.currently_viewed_index = None\n        self.currently_viewed_instruction = None\n\n        # Load the initial behavior configuration\n        self.update_activity(activity_name=activity_name, activity_definition_id=activity_definition_id, predefined_problem=predefined_problem)\n\n        # Run super init\n        super().__init__(termination_config=termination_config, reward_config=reward_config)\n\n    def _create_termination_conditions(self):\n        # Initialize termination conditions dict and fill in with Timeout and PredicateGoal\n        terminations = OrderedDict()\n\n        terminations[\"timeout\"] = Timeout(max_steps=self._termination_config[\"max_steps\"])\n        terminations[\"predicate\"] = PredicateGoal(goal_fcn=lambda: self.activity_goal_conditions)\n\n        return terminations\n\n    def _create_reward_functions(self):\n        # Initialize reward functions dict and fill in with Potential reward\n        rewards = OrderedDict()\n\n        rewards[\"potential\"] = PotentialReward(\n            potential_fcn=self.get_potential,\n            r_potential=self._reward_config[\"r_potential\"],\n        )\n\n        return rewards\n\n    def _load(self, env):\n        # Get the name of the scene\n        self.scene_model = og.sim.scene.scene_model\n\n        # Initialize the current activity\n        success, self.feedback = self.initialize_activity(env=env)\n        if not success:\n            print(f\"Failed to initialize Behavior Activity. Feedback:\\n{self.feedback}\")\n\n        # Also reset the agent\n        self._reset_agent(env=env)\n\n        # Highlight any task relevant objects if requested\n        if self.highlight_task_relevant_objs:\n            for obj_name, obj in self.object_scope.items():\n                if isinstance(obj, BaseRobot):\n                    continue\n                obj.highlighted = True\n\n    def _load_non_low_dim_observation_space(self):\n        # No non-low dim observations so we return an empty dict\n        return OrderedDict()\n\n    def update_activity(self, activity_name, activity_definition_id, predefined_problem=None):\n        \"\"\"\n        Update the active Behavior activity being deployed\n\n        Args:\n            activity_name (None or str): Name of the Behavior Task to instantiate\n            activity_definition_id (int): Specification to load for the desired task. For a given Behavior Task, multiple task\n                specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This\n                ID determines which specification to use\n            predefined_problem (None or str): If specified, specifies the raw string definition of the Behavior Task to\n                load. This will automatically override @activity_name and @activity_definition_id.\n        \"\"\"\n        # Update internal variables based on values\n\n        # Activity info\n        self.activity_name = activity_name\n        self.activity_definition_id = activity_definition_id\n        self.activity_conditions = Conditions(\n            activity_name,\n            activity_definition_id,\n            simulator_name=\"igibson\",       # TODO: Update!\n            predefined_problem=predefined_problem,\n        )\n\n        # Object info\n        self.object_scope = get_object_scope(self.activity_conditions)\n        self.object_instance_to_category = {\n            obj_inst: obj_cat\n            for obj_cat in self.activity_conditions.parsed_objects\n            for obj_inst in self.activity_conditions.parsed_objects[obj_cat]\n        }\n\n        # Generate initial and goal conditions\n        self.activity_initial_conditions = get_initial_conditions(self.activity_conditions, self.backend, self.object_scope)\n        self.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\n        self.ground_goal_state_options = get_ground_goal_state_options(\n            self.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n        )\n\n        # Demo attributes\n        self.instruction_order = np.arange(len(self.activity_conditions.parsed_goal_conditions))\n        np.random.shuffle(self.instruction_order)\n        self.currently_viewed_index = 0\n        self.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\n        self.activity_natural_language_goal_conditions = get_natural_goal_conditions(self.activity_conditions)\n\n    def get_potential(self, env):\n        \"\"\"\n        Compute task-specific potential: distance to the goal\n\n        Args:\n            env (Environment): Current active environment instance\n\n        Returns:\n            float: Computed potential\n        \"\"\"\n        # Evaluate the first ground goal state option as the potential\n        _, satisfied_predicates = evaluate_goal_conditions(self.ground_goal_state_options[0])\n        success_score = len(satisfied_predicates[\"satisfied\"]) / (\n            len(satisfied_predicates[\"satisfied\"]) + len(satisfied_predicates[\"unsatisfied\"])\n        )\n        return -success_score\n\n    def initialize_activity(self, env):\n        \"\"\"\n        Initializes the desired activity in the current environment @env\n\n        Args:\n            env (Environment): Current active environment instance\n\n        Returns:\n            2-tuple:\n                - bool: Whether the generated scene activity should be accepted or not\n                - dict: Any feedback from the sampling / initialization process\n        \"\"\"\n        accept_scene = True\n        feedback = None\n\n        if self.online_object_sampling:\n            # Reject scenes with missing non-sampleable objects\n            # Populate object_scope with sampleable objects and the robot\n            accept_scene, feedback = self.check_scene(env)\n            if not accept_scene:\n                return accept_scene, feedback\n            # Sample objects to satisfy initial conditions\n            accept_scene, feedback = self.sample(env)\n            if not accept_scene:\n                return accept_scene, feedback\n        else:\n            # Load existing scene cache and assign object scope accordingly\n            self.assign_object_scope_with_cache(env)\n\n        # Generate goal condition with the fully populated self.object_scope\n        self.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\n        self.ground_goal_state_options = get_ground_goal_state_options(\n            self.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n        )\n        return accept_scene, feedback\n\n    def parse_non_sampleable_object_room_assignment(self, env):\n        \"\"\"\n        Infers which rooms each object is assigned to\n\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\n        self.room_type_to_object_instance = OrderedDict()\n        self.non_sampleable_object_instances = set()\n        for cond in self.activity_conditions.parsed_initial_conditions:\n            if cond[0] == \"inroom\":\n                obj_inst, room_type = cond[1], cond[2]\n                obj_cat = self.object_instance_to_category[obj_inst]\n                if obj_cat not in NON_SAMPLEABLE_OBJECTS:\n                    # Invalid room assignment\n                    return \"You have assigned room type for [{}], but [{}] is sampleable. Only non-sampleable objects can have room assignment.\".format(\n                        obj_cat, obj_cat\n                    )\n                if room_type not in og.sim.scene.seg_map.room_sem_name_to_ins_name:\n                    # Missing room type\n                    return \"Room type [{}] missing in scene [{}].\".format(room_type, og.sim.scene.scene_model)\n                if room_type not in self.room_type_to_object_instance:\n                    self.room_type_to_object_instance[room_type] = []\n                self.room_type_to_object_instance[room_type].append(obj_inst)\n\n                if obj_inst in self.non_sampleable_object_instances:\n                    # Duplicate room assignment\n                    return \"Object [{}] has more than one room assignment\".format(obj_inst)\n\n                self.non_sampleable_object_instances.add(obj_inst)\n\n        for obj_cat in self.activity_conditions.parsed_objects:\n            if obj_cat not in NON_SAMPLEABLE_OBJECTS:\n                continue\n            for obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\n                if obj_inst not in self.non_sampleable_object_instances:\n                    # Missing room assignment\n                    return \"All non-sampleable objects should have room assignment. [{}] does not have one.\".format(\n                        obj_inst\n                    )\n\n    def build_sampling_order(self, env):\n        \"\"\"\n        Sampling orders is a list of lists: [[batch_1_inst_1, ... batch_1_inst_N], [batch_2_inst_1, batch_2_inst_M], ...]\n        Sampling should happen for batch 1 first, then batch 2, so on and so forth\n        Example: OnTop(plate, table) should belong to batch 1, and OnTop(apple, plate) should belong to batch 2\n\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\n        self.object_sampling_orders = []\n        cur_batch = self.non_sampleable_object_instances\n        while len(cur_batch) &gt; 0:\n            self.object_sampling_orders.append(cur_batch)\n            next_batch = set()\n            for cond in self.activity_conditions.parsed_initial_conditions:\n                if len(cond) == 3 and cond[2] in cur_batch:\n                    next_batch.add(cond[1])\n            cur_batch = next_batch\n\n        if len(self.object_sampling_orders) &gt; 0:\n            remaining_objs = self.object_scope.keys() - set.union(*self.object_sampling_orders)\n        else:\n            remaining_objs = self.object_scope.keys()\n\n        # Macro particles and water don't need initial conditions\n        remaining_objs = {obj_inst for obj_inst in remaining_objs\n                          if self.object_instance_to_category[obj_inst] not in MACRO_PARTICLE_SYNSETS.union(WATER_SYNSETS)}\n        if len(remaining_objs) != 0:\n            return \"Some objects do not have any kinematic condition defined for them in the initial conditions: {}\".format(\n                \", \".join(remaining_objs)\n            )\n\n    def build_non_sampleable_object_scope(self, env):\n        \"\"\"\n        Store simulator object options for non-sampleable objects in self.non_sampleable_object_scope\n        {\n            \"living_room\": {\n                \"table1\": {\n                    \"living_room_0\": [URDFObject, URDFObject, URDFObject],\n                    \"living_room_1\": [URDFObject]\n                },\n                \"table2\": {\n                    \"living_room_0\": [URDFObject, URDFObject],\n                    \"living_room_1\": [URDFObject, URDFObject]\n                },\n                \"chair1\": {\n                    \"living_room_0\": [URDFObject],\n                    \"living_room_1\": [URDFObject]\n                },\n            }\n        }\n\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\n        room_type_to_scene_objs = {}\n        for room_type in self.room_type_to_object_instance:\n            room_type_to_scene_objs[room_type] = {}\n            for obj_inst in self.room_type_to_object_instance[room_type]:\n                room_type_to_scene_objs[room_type][obj_inst] = {}\n                obj_cat = self.object_instance_to_category[obj_inst]\n\n                # We allow burners to be used as if they are stoves\n                categories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\n                if obj_cat == \"stove.n.01\":\n                    categories += self.object_taxonomy.get_subtree_igibson_categories(\"burner.n.02\")\n\n                for room_inst in og.sim.scene.seg_map.room_sem_name_to_ins_name[room_type]:\n                    # A list of scene objects that satisfy the requested categories\n                    room_objs = og.sim.scene.object_registry(\"in_rooms\", room_inst, default_val=[])\n                    scene_objs = [obj for obj in room_objs if obj.category in categories]\n\n                    if len(scene_objs) != 0:\n                        room_type_to_scene_objs[room_type][obj_inst][room_inst] = scene_objs\n\n        error_msg = self.consolidate_room_instance(room_type_to_scene_objs, \"initial_pre-sampling\")\n        if error_msg:\n            return error_msg\n        self.non_sampleable_object_scope = room_type_to_scene_objs\n\n    def import_sampleable_objects(self, env):\n        \"\"\"\n        Import all objects that can be sampled\n\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\n        assert og.sim.is_playing()\n        og.sim.stop()\n\n        # Move the robot object frame to a far away location, similar to other newly imported objects below\n        env.robots[0].set_position_orientation([300, 300, 300], [0, 0, 0, 1])\n\n        self.sampled_objects = set()\n        num_new_obj = 0\n        # Only populate self.object_scope for sampleable objects\n        avg_category_spec = get_og_avg_category_specs()\n        for obj_cat in self.activity_conditions.parsed_objects:\n            if obj_cat == \"agent.n.01\":\n                continue\n            if obj_cat in NON_SAMPLEABLE_OBJECTS:\n                continue\n            if obj_cat in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\n                assert len(self.activity_conditions.parsed_objects[obj_cat]) == 1, \"Systems are singletons\"\n                obj_inst = self.activity_conditions.parsed_objects[obj_cat][0]\n                self.object_scope[obj_inst] = get_system_from_element_name(SYSTEM_SYNSETS_TO_SYSTEM_NAMES[obj_cat])\n                continue\n\n            is_sliceable = self.object_taxonomy.has_ability(obj_cat, \"sliceable\")\n            categories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\n\n            # TODO: temporary hack\n            remove_categories = [\n                \"pop_case\",  # too large\n                \"jewel\",  # too small\n                \"ring\",  # too small\n            ]\n            for remove_category in remove_categories:\n                if remove_category in categories:\n                    categories.remove(remove_category)\n\n            for obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\n                category = np.random.choice(categories)\n                # for sliceable objects, only get the whole objects\n                try:\n                    model_choices = get_object_models_of_category(\n                        category, filter_method=\"sliceable_whole\" if is_sliceable else None\n                    )\n                except:\n                    og.sim.play()\n                    return f\"Missing object category: {category}\"\n\n                if len(model_choices) == 0:\n                    # restore back to the play state\n                    og.sim.play()\n                    return f\"Missing valid object models for category: {category}\"\n\n                # TODO: This no longer works because model ID changes in the new asset\n                # Filter object models if the object category is openable\n                # synset = self.object_taxonomy.get_class_name_from_igibson_category(category)\n                # if self.object_taxonomy.has_ability(synset, \"openable\"):\n                #     # Always use the articulated version of a certain object if its category is openable\n                #     # E.g. backpack, jar, etc\n                #     model_choices = [m for m in model_choices if \"articulated_\" in m]\n                #     if len(model_choices) == 0:\n                #         return \"{} is Openable, but does not have articulated models.\".format(category)\n\n                # Randomly select an object model\n                model = np.random.choice(model_choices)\n\n                # TODO: temporary hack no longer works because model ID changes in the new asset\n                # for \"collecting aluminum cans\", we need pop cans (not bottles)\n                # if category == \"pop\" and self.activity_name in [\"collecting_aluminum_cans\"]:\n                #     model = np.random.choice([str(i) for i in range(40, 46)])\n                # if category == \"spoon\" and self.activity_name in [\"polishing_silver\"]:\n                #     model = np.random.choice([str(i) for i in [2, 5, 6]])\n\n                model_path = get_og_model_path(category, model)\n                usd_path = os.path.join(model_path, \"usd\", f\"{model}.usd\")\n                obj_name = \"{}_{}\".format(category, len(og.sim.scene.objects))\n\n                # create the object\n                simulator_obj = DatasetObject(\n                    prim_path=f\"/World/{obj_name}\",\n                    usd_path=usd_path,\n                    name=obj_name,\n                    category=category,\n                    fit_avg_dim_volume=True,\n                )\n                num_new_obj += 1\n\n                # Load the object into the simulator\n                assert og.sim.scene.loaded, \"Scene is not loaded\"\n                og.sim.import_object(simulator_obj)\n\n                # Set these objects to be far-away locations\n                simulator_obj.set_position(np.array([100.0 + num_new_obj - 1, 100.0, -100.0]))\n\n                self.sampled_objects.add(simulator_obj)\n                self.object_scope[obj_inst] = simulator_obj\n\n        # Play the sim again to initialize all the newly imported objects.\n        og.sim.play()\n        # Also reset the agent\n        env.robots[0].reset()\n        # Take one extra step so that the bounding box of the agent is up-to-date.\n        og.sim.step()\n\n    def check_scene(self, env):\n        \"\"\"\n        Runs sanity checks for the current scene for the given BEHAVIOR task\n\n        Args:\n            env (Environment): Current active environment instance\n\n        Returns:\n            2-tuple:\n                - bool: Whether the generated scene activity should be accepted or not\n                - dict: Any feedback from the sampling / initialization process\n        \"\"\"\n        error_msg = self.parse_non_sampleable_object_room_assignment(env)\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n        error_msg = self.build_sampling_order(env)\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n        error_msg = self.build_non_sampleable_object_scope(env)\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n        error_msg = self.import_sampleable_objects(env)\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n        self.object_scope[\"agent.n.01_1\"] = self.get_agent(env)\n\n        return True, None\n\n    def get_agent(self, env):\n        \"\"\"\n        Grab the 0th agent from @env\n\n        Args:\n            env (Environment): Current active environment instance\n\n        Returns:\n            BaseRobot: The 0th robot from the environment instance\n        \"\"\"\n        # We assume the relevant agent is the first agent in the scene\n        return env.robots[0]\n\n    def assign_object_scope_with_cache(self, env):\n        \"\"\"\n        Assigns objects within the current object scope\n\n        Args:\n            env (Environment): Current active environment instance\n        \"\"\"\n        # Assign object_scope based on a cached scene\n        for obj_inst in self.object_scope:\n            matched_sim_obj = None\n            # If the object scope points to the agent\n            if obj_inst == \"agent.n.01_1\":\n                matched_sim_obj = self.get_agent(env)\n            # If the object scope points to a system\n            elif self.object_instance_to_category[obj_inst] in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\n                matched_sim_obj = get_system_from_element_name(\n                    SYSTEM_SYNSETS_TO_SYSTEM_NAMES[self.object_instance_to_category[obj_inst]])\n            else:\n                logging.info(f\"checking objects...\")\n                for sim_obj in og.sim.scene.objects:\n                    logging.info(f\"checking bddl obj scope for obj: {sim_obj.name}\")\n                    if hasattr(sim_obj, \"bddl_object_scope\") and sim_obj.bddl_object_scope == obj_inst:\n                        matched_sim_obj = sim_obj\n                        break\n            assert matched_sim_obj is not None, obj_inst\n            self.object_scope[obj_inst] = matched_sim_obj\n\n    def process_single_condition(self, condition):\n        \"\"\"\n        Processes a single BDDL condition\n\n        Args:\n            condition (Condition): Condition to process\n\n        Returns:\n            2-tuple:\n                - Expression: Condition's expression\n                - bool: Whether this evaluated condition is positive or negative\n        \"\"\"\n        if not isinstance(condition.children[0], Negation) and not isinstance(condition.children[0], AtomicFormula):\n            logging.warning((\"Skipping over sampling of predicate that is not a negation or an atomic formula\"))\n            return None, None\n\n        if isinstance(condition.children[0], Negation):\n            condition = condition.children[0].children[0]\n            positive = False\n        else:\n            condition = condition.children[0]\n            positive = True\n\n        return condition, positive\n\n    def group_initial_conditions(self):\n        \"\"\"\n        We group initial conditions by first splitting the desired task-relevant objects into non-sampleable objects\n        and sampleable objects.\n\n        Non-sampleable objects are objects that should ALREADY be in the scene, and should NOT be generated / sampled\n        on the fly\n\n        Sampleable objects are objects that need to be additionally imported into the scene.\n\n        Returns:\n            None or str: None if successful, otherwise failure string\n        \"\"\"\n        self.non_sampleable_object_conditions = []\n        self.sampleable_object_conditions = []\n\n        # TODO: currently we assume self.initial_conditions is a list of\n        # bddl.condition_evaluation.HEAD, each with one child.\n        # This child is either a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate or\n        # a Negation of a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate\n        for condition in self.activity_initial_conditions:\n            condition, positive = self.process_single_condition(condition)\n            if condition is None:\n                continue\n\n            # Sampled conditions must always be positive\n            # Non-positive (e.g.: NOT onTop) is not restrictive enough for sampling\n            if condition.STATE_NAME in KINEMATICS_STATES and not positive:\n                return \"Initial condition has negative kinematic conditions: {}\".format(condition.body)\n\n            condition_body = set(condition.body)\n\n            # If the condition involves any non-sampleable object (e.g.: furniture), it's a non-sampleable condition\n            # This means that there's no ordering constraint in terms of sampling, because we know the, e.g., furniture\n            # object already exists in the scene and is placed, so these specific conditions can be sampled without\n            # any dependencies\n            if len(self.non_sampleable_object_instances.intersection(condition_body)) &gt; 0:\n                self.non_sampleable_object_conditions.append((condition, positive))\n            else:\n                # There are dependencies that must be taken into account\n                self.sampleable_object_conditions.append((condition, positive))\n\n    def filter_object_scope(self, input_object_scope, conditions, condition_type):\n        \"\"\"\n        Filters the object scope based on given @input_object_scope, @conditions, and @condition_type\n\n        Args:\n            input_object_scope (dict):\n            conditions (list): List of conditions to filter scope with, where each list entry is\n                a tuple of (condition, positive), where @positive is True if the condition has a positive\n                evaluation.\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n\n        Returns:\n            dict: Filtered object scope\n        \"\"\"\n        filtered_object_scope = {}\n        for room_type in input_object_scope:\n            filtered_object_scope[room_type] = {}\n            for scene_obj in input_object_scope[room_type]:\n                filtered_object_scope[room_type][scene_obj] = {}\n                for room_inst in input_object_scope[room_type][scene_obj]:\n                    # These are a list of candidate simulator objects that need sampling test\n                    for obj in input_object_scope[room_type][scene_obj][room_inst]:\n                        # Temporarily set object_scope to point to this candidate object\n                        self.object_scope[scene_obj] = obj\n\n                        success = True\n                        # If this candidate object is not involved in any conditions,\n                        # success will be True by default and this object will qualify\n                        for condition, positive in conditions:\n                            # Sample positive kinematic conditions that involve this candidate object\n                            if condition.STATE_NAME in KINEMATICS_STATES and positive and scene_obj in condition.body:\n                                # Use pybullet GUI for debugging\n                                if self.debug_object_sampling is not None and self.debug_object_sampling == condition.body[0]:\n                                    og.debug_sampling = True\n\n                                success = condition.sample(binary_state=positive)\n                                log_msg = \" \".join(\n                                    [\n                                        \"{} condition sampling\".format(condition_type),\n                                        room_type,\n                                        scene_obj,\n                                        room_inst,\n                                        obj.name,\n                                        condition.STATE_NAME,\n                                        str(condition.body),\n                                        str(success),\n                                    ]\n                                )\n                                logging.warning(log_msg)\n\n                                # If any condition fails for this candidate object, skip\n                                if not success:\n                                    break\n\n                        # If this candidate object fails, move on to the next candidate object\n                        if not success:\n                            continue\n\n                        if room_inst not in filtered_object_scope[room_type][scene_obj]:\n                            filtered_object_scope[room_type][scene_obj][room_inst] = []\n                        filtered_object_scope[room_type][scene_obj][room_inst].append(obj)\n\n        return filtered_object_scope\n\n    def consolidate_room_instance(self, filtered_object_scope, condition_type):\n        \"\"\"\n        Consolidates room instances\n\n        Args:\n            filtered_object_scope (dict): Filtered object scope\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n        \"\"\"\n        for room_type in filtered_object_scope:\n            # For each room_type, filter in room_inst that has successful\n            # sampling options for all obj_inst in this room_type\n            room_inst_satisfied = set.intersection(\n                *[\n                    set(filtered_object_scope[room_type][obj_inst].keys())\n                    for obj_inst in filtered_object_scope[room_type]\n                ]\n            )\n\n            if len(room_inst_satisfied) == 0:\n                error_msg = \"{}: Room type [{}] of scene [{}] do not contain or cannot sample all the objects needed.\\nThe following are the possible room instances for each object, the intersection of which is an empty set.\\n\".format(\n                    condition_type, room_type, self.scene_model\n                )\n                for obj_inst in filtered_object_scope[room_type]:\n                    error_msg += (\n                        \"{}: \".format(obj_inst) + \", \".join(filtered_object_scope[room_type][obj_inst].keys()) + \"\\n\"\n                    )\n\n                return error_msg\n\n            for obj_inst in filtered_object_scope[room_type]:\n                filtered_object_scope[room_type][obj_inst] = {\n                    key: val\n                    for key, val in filtered_object_scope[room_type][obj_inst].items()\n                    if key in room_inst_satisfied\n                }\n\n    def maximum_bipartite_matching(self, filtered_object_scope, condition_type):\n        \"\"\"\n        Matches objects from @filtered_object_scope to specific room instances it can be\n        sampled from\n\n        Args:\n            filtered_object_scope (dict): Filtered object scope\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\n        # For each room instance, perform maximum bipartite matching between object instance in scope to simulator objects\n        # Left nodes: a list of object instance in scope\n        # Right nodes: a list of simulator objects\n        # Edges: if the simulator object can support the sampling requirement of ths object instance\n        for room_type in filtered_object_scope:\n            # The same room instances will be shared across all scene obj in a given room type\n            some_obj = list(filtered_object_scope[room_type].keys())[0]\n            room_insts = list(filtered_object_scope[room_type][some_obj].keys())\n            success = False\n            # Loop through each room instance\n            for room_inst in room_insts:\n                graph = nx.Graph()\n                # For this given room instance, gether mapping from obj instance to a list of simulator obj\n                obj_inst_to_obj_per_room_inst = {}\n                for obj_inst in filtered_object_scope[room_type]:\n                    obj_inst_to_obj_per_room_inst[obj_inst] = filtered_object_scope[room_type][obj_inst][room_inst]\n                top_nodes = []\n                log_msg = \"MBM for room instance [{}]\".format(room_inst)\n                logging.warning((log_msg))\n                for obj_inst in obj_inst_to_obj_per_room_inst:\n                    for obj in obj_inst_to_obj_per_room_inst[obj_inst]:\n                        # Create an edge between obj instance and each of the simulator obj that supports sampling\n                        graph.add_edge(obj_inst, obj)\n                        log_msg = \"Adding edge: {} &lt;-&gt; {}\".format(obj_inst, obj.name)\n                        logging.warning((log_msg))\n                        top_nodes.append(obj_inst)\n                # Need to provide top_nodes that contain all nodes in one bipartite node set\n                # The matches will have two items for each match (e.g. A -&gt; B, B -&gt; A)\n                matches = nx.bipartite.maximum_matching(graph, top_nodes=top_nodes)\n                if len(matches) == 2 * len(obj_inst_to_obj_per_room_inst):\n                    logging.warning((\"Object scope finalized:\"))\n                    for obj_inst, obj in matches.items():\n                        if obj_inst in obj_inst_to_obj_per_room_inst:\n                            self.object_scope[obj_inst] = obj\n                            logging.warning((obj_inst, obj.name))\n                    success = True\n                    break\n            if not success:\n                return \"{}: Room type [{}] of scene [{}] do not have enough simulator objects that can successfully sample all the objects needed. This is usually caused by specifying too many object instances in the object scope or the conditions are so stringent that too few simulator objects can satisfy them via sampling.\\n\".format(\n                    condition_type, room_type, self.scene_model\n                )\n\n    def sample_conditions(self, input_object_scope, conditions, condition_type):\n        \"\"\"\n        Sample conditions\n\n        Args:\n            input_object_scope (dict):\n            conditions (list): List of conditions to filter scope with, where each list entry is\n                a tuple of (condition, positive), where @positive is True if the condition has a positive\n                evaluation.\n            condition_type (str): What type of condition to sample, e.g., \"initial\"\n\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\n        filtered_object_scope = self.filter_object_scope(input_object_scope, conditions, condition_type)\n        error_msg = self.consolidate_room_instance(filtered_object_scope, condition_type)\n        if error_msg:\n            return error_msg, None\n        return self.maximum_bipartite_matching(filtered_object_scope, condition_type), filtered_object_scope\n\n    def sample_initial_conditions(self):\n        \"\"\"\n        Sample initial conditions\n\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\n        error_msg, self.non_sampleable_object_scope_filtered_initial = self.sample_conditions(\n            self.non_sampleable_object_scope, self.non_sampleable_object_conditions, \"initial\"\n        )\n        return error_msg\n\n    def sample_goal_conditions(self):\n        \"\"\"\n        Sample goal conditions\n\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\n        np.random.shuffle(self.ground_goal_state_options)\n        logging.warning((\"number of ground_goal_state_options\", len(self.ground_goal_state_options)))\n        num_goal_condition_set_to_test = 10\n\n        goal_condition_success = False\n        # Try to fulfill different set of ground goal conditions (maximum num_goal_condition_set_to_test)\n        for goal_condition_set in self.ground_goal_state_options[:num_goal_condition_set_to_test]:\n            goal_condition_processed = []\n            for condition in goal_condition_set:\n                condition, positive = self.process_single_condition(condition)\n                if condition is None:\n                    continue\n                goal_condition_processed.append((condition, positive))\n\n            error_msg, _ = self.sample_conditions(\n                self.non_sampleable_object_scope_filtered_initial, goal_condition_processed, \"goal\"\n            )\n            if not error_msg:\n                # if one set of goal conditions (and initial conditions) are satisfied, sampling is successful\n                goal_condition_success = True\n                break\n\n        if not goal_condition_success:\n            return error_msg\n\n    def sample_initial_conditions_final(self):\n        \"\"\"\n        Sample final initial conditions\n\n        Returns:\n            None or str: If successful, returns None. Otherwise, returns an error message\n        \"\"\"\n        # Do the final round of sampling with object scope fixed\n        for condition, positive in self.non_sampleable_object_conditions:\n            num_trials = 10\n            for _ in range(num_trials):\n                success = condition.sample(binary_state=positive)\n                if success:\n                    break\n            if not success:\n                error_msg = \"Non-sampleable object conditions failed even after successful matching: {}\".format(\n                    condition.body\n                )\n                return error_msg\n\n        # Use ray casting for ontop and inside sampling for sampleable objects\n        for condition, positive in self.sampleable_object_conditions:\n            if condition.STATE_NAME in [\"inside\", \"ontop\"]:\n                condition.kwargs[\"use_ray_casting_method\"] = True\n\n        if len(self.object_sampling_orders) &gt; 0:\n            # Pop non-sampleable objects\n            self.object_sampling_orders.pop(0)\n            for cur_batch in self.object_sampling_orders:\n                # First sample non-sliced conditions\n                for condition, positive in self.sampleable_object_conditions:\n                    if condition.STATE_NAME == \"sliced\":\n                        continue\n                    # Sample conditions that involve the current batch of objects\n                    if condition.body[0] in cur_batch:\n                        num_trials = 10\n                        for _ in range(num_trials):\n                            success = condition.sample(binary_state=positive)\n                            if success:\n                                break\n                        if not success:\n                            return \"Sampleable object conditions failed: {} {}\".format(\n                                condition.STATE_NAME, condition.body\n                            )\n\n                # Then sample sliced conditions\n                for condition, positive in self.sampleable_object_conditions:\n                    if condition.STATE_NAME != \"sliced\":\n                        continue\n                    # Sample conditions that involve the current batch of objects\n                    if condition.body[0] in cur_batch:\n                        success = condition.sample(binary_state=positive)\n                        if not success:\n                            return \"Sampleable object conditions failed: {}\".format(condition.body)\n\n        # One more sim step to make sure the object states are propagated correctly\n        # E.g. after sampling Filled.set_value(True), Filled.get_value() will become True only after one step\n        og.sim.step()\n\n    def sample(self, env, validate_goal=False):\n        \"\"\"\n        Run sampling for this BEHAVIOR task\n\n        Args:\n            env (Environment): Current active environment instance\n            validate_goal (bool): Whether the goal should be validated or not\n\n        Returns:\n            2-tuple:\n                - bool: Whether sampling was successful or not\n                - None or str: None if successful, otherwise the associated error message\n        \"\"\"\n\n        error_msg = self.group_initial_conditions()\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n        error_msg = self.sample_initial_conditions()\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n        if validate_goal:\n            error_msg = self.sample_goal_conditions()\n            if error_msg:\n                logging.warning(error_msg)\n                return False, error_msg\n\n        error_msg = self.sample_initial_conditions_final()\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n        return True, None\n\n    def _get_obs(self, env):\n        low_dim_obs = OrderedDict()\n        low_dim_obs[\"robot_pos\"] = np.array(env.robots[0].get_position())\n        low_dim_obs[\"robot_ori_cos\"] = np.cos(env.robots[0].get_rpy())\n        low_dim_obs[\"robot_ori_sin\"] = np.sin(env.robots[0].get_rpy())\n\n        i = 0\n        for _, v in self.object_scope.items():\n            # TODO: May need to update checking here to USDObject? Or even baseobject?\n            if isinstance(v, DatasetObject):\n                low_dim_obs[f\"obj_{i}_valid\"] = np.array([1.0])\n                low_dim_obs[f\"obj_{i}_pos\"] = v.get_position()\n                low_dim_obs[f\"obj_{i}_ori_cos\"] = np.cos(v.get_rpy())\n                low_dim_obs[f\"obj_{i}_ori_sin\"] = np.sin(v.get_rpy())\n                for arm in env.robots[0].arm_names:\n                    grasping_object = env.robots[0].is_grasping(arm=arm, candidate_obj=v)\n                    low_dim_obs[f\"obj_{i}_pos_in_gripper_{arm}\"] = np.array([float(grasping_object)])\n                i += 1\n\n        return low_dim_obs, OrderedDict()\n\n    def _step_termination(self, env, action, info=None):\n        # Run super first\n        done, info = super()._step_termination(env=env, action=action, info=info)\n\n        # Add additional info\n        info[\"goal_status\"] = self._termination_conditions[\"predicate\"].goal_status\n\n        return done, info\n\n    def show_instruction(self):\n        \"\"\"\n        Get current instruction for user\n\n        Returns:\n            3-tuple:\n                - str: Current goal condition in natural language\n                - 3-tuple: (R,G,B) color to assign to text\n                - list of BaseObject: Relevant objects for the current instruction\n        \"\"\"\n        satisfied = self.currently_viewed_instruction in self._termination_conditions[\"predicate\"].goal_status[\"satisfied\"]\n        natural_language_condition = self.activity_natural_language_goal_conditions[self.currently_viewed_instruction]\n        objects = self.activity_goal_conditions[self.currently_viewed_instruction].get_relevant_objects()\n        text_color = (\n            [83.0 / 255.0, 176.0 / 255.0, 72.0 / 255.0] if satisfied else [255.0 / 255.0, 51.0 / 255.0, 51.0 / 255.0]\n        )\n\n        return natural_language_condition, text_color, objects\n\n    def iterate_instruction(self):\n        \"\"\"\n        Increment the instruction\n        \"\"\"\n        self.currently_viewed_index = (self.currently_viewed_index + 1) % len(self.activity_conditions.parsed_goal_conditions)\n        self.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\n\n    @property\n    def name(self):\n        \"\"\"\n        Returns:\n            str: Name of this task. Defaults to class name\n        \"\"\"\n        name_base = super().name\n\n        # Add activity name, def id, and inst id\n        return f\"{name_base}_{self.activity_name}_{self.activity_definition_id}_{self.activity_instance_id}\"\n\n    @classproperty\n    def valid_scene_types(cls):\n        # Must be an interactive traversable scene\n        return {InteractiveTraversableScene}\n\n    @classproperty\n    def default_termination_config(cls):\n        return {\n            \"max_steps\": 500,\n        }\n\n    @classproperty\n    def default_reward_config(cls):\n        return {\n            \"r_potential\": 1.0,\n        }\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask"},{"title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this task. Defaults to class name</p>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.name"},{"title":"<code>assign_object_scope_with_cache(env)</code>","text":"<p>Assigns objects within the current object scope</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required      Source code in <code>tasks/behavior_task.py</code> <pre><code>def assign_object_scope_with_cache(self, env):\n    \"\"\"\n    Assigns objects within the current object scope\n\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\n    # Assign object_scope based on a cached scene\n    for obj_inst in self.object_scope:\n        matched_sim_obj = None\n        # If the object scope points to the agent\n        if obj_inst == \"agent.n.01_1\":\n            matched_sim_obj = self.get_agent(env)\n        # If the object scope points to a system\n        elif self.object_instance_to_category[obj_inst] in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\n            matched_sim_obj = get_system_from_element_name(\n                SYSTEM_SYNSETS_TO_SYSTEM_NAMES[self.object_instance_to_category[obj_inst]])\n        else:\n            logging.info(f\"checking objects...\")\n            for sim_obj in og.sim.scene.objects:\n                logging.info(f\"checking bddl obj scope for obj: {sim_obj.name}\")\n                if hasattr(sim_obj, \"bddl_object_scope\") and sim_obj.bddl_object_scope == obj_inst:\n                    matched_sim_obj = sim_obj\n                    break\n        assert matched_sim_obj is not None, obj_inst\n        self.object_scope[obj_inst] = matched_sim_obj\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.assign_object_scope_with_cache"},{"title":"<code>build_non_sampleable_object_scope(env)</code>","text":"<p>Store simulator object options for non-sampleable objects in self.non_sampleable_object_scope {     \"living_room\": {         \"table1\": {             \"living_room_0\": [URDFObject, URDFObject, URDFObject],             \"living_room_1\": [URDFObject]         },         \"table2\": {             \"living_room_0\": [URDFObject, URDFObject],             \"living_room_1\": [URDFObject, URDFObject]         },         \"chair1\": {             \"living_room_0\": [URDFObject],             \"living_room_1\": [URDFObject]         },     } }</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required      Source code in <code>tasks/behavior_task.py</code> <pre><code>def build_non_sampleable_object_scope(self, env):\n    \"\"\"\n    Store simulator object options for non-sampleable objects in self.non_sampleable_object_scope\n    {\n        \"living_room\": {\n            \"table1\": {\n                \"living_room_0\": [URDFObject, URDFObject, URDFObject],\n                \"living_room_1\": [URDFObject]\n            },\n            \"table2\": {\n                \"living_room_0\": [URDFObject, URDFObject],\n                \"living_room_1\": [URDFObject, URDFObject]\n            },\n            \"chair1\": {\n                \"living_room_0\": [URDFObject],\n                \"living_room_1\": [URDFObject]\n            },\n        }\n    }\n\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\n    room_type_to_scene_objs = {}\n    for room_type in self.room_type_to_object_instance:\n        room_type_to_scene_objs[room_type] = {}\n        for obj_inst in self.room_type_to_object_instance[room_type]:\n            room_type_to_scene_objs[room_type][obj_inst] = {}\n            obj_cat = self.object_instance_to_category[obj_inst]\n\n            # We allow burners to be used as if they are stoves\n            categories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\n            if obj_cat == \"stove.n.01\":\n                categories += self.object_taxonomy.get_subtree_igibson_categories(\"burner.n.02\")\n\n            for room_inst in og.sim.scene.seg_map.room_sem_name_to_ins_name[room_type]:\n                # A list of scene objects that satisfy the requested categories\n                room_objs = og.sim.scene.object_registry(\"in_rooms\", room_inst, default_val=[])\n                scene_objs = [obj for obj in room_objs if obj.category in categories]\n\n                if len(scene_objs) != 0:\n                    room_type_to_scene_objs[room_type][obj_inst][room_inst] = scene_objs\n\n    error_msg = self.consolidate_room_instance(room_type_to_scene_objs, \"initial_pre-sampling\")\n    if error_msg:\n        return error_msg\n    self.non_sampleable_object_scope = room_type_to_scene_objs\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.build_non_sampleable_object_scope"},{"title":"<code>build_sampling_order(env)</code>","text":"<p>Sampling orders is a list of lists: [[batch_1_inst_1, ... batch_1_inst_N], [batch_2_inst_1, batch_2_inst_M], ...] Sampling should happen for batch 1 first, then batch 2, so on and so forth Example: OnTop(plate, table) should belong to batch 1, and OnTop(apple, plate) should belong to batch 2</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required      Source code in <code>tasks/behavior_task.py</code> <pre><code>def build_sampling_order(self, env):\n    \"\"\"\n    Sampling orders is a list of lists: [[batch_1_inst_1, ... batch_1_inst_N], [batch_2_inst_1, batch_2_inst_M], ...]\n    Sampling should happen for batch 1 first, then batch 2, so on and so forth\n    Example: OnTop(plate, table) should belong to batch 1, and OnTop(apple, plate) should belong to batch 2\n\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\n    self.object_sampling_orders = []\n    cur_batch = self.non_sampleable_object_instances\n    while len(cur_batch) &gt; 0:\n        self.object_sampling_orders.append(cur_batch)\n        next_batch = set()\n        for cond in self.activity_conditions.parsed_initial_conditions:\n            if len(cond) == 3 and cond[2] in cur_batch:\n                next_batch.add(cond[1])\n        cur_batch = next_batch\n\n    if len(self.object_sampling_orders) &gt; 0:\n        remaining_objs = self.object_scope.keys() - set.union(*self.object_sampling_orders)\n    else:\n        remaining_objs = self.object_scope.keys()\n\n    # Macro particles and water don't need initial conditions\n    remaining_objs = {obj_inst for obj_inst in remaining_objs\n                      if self.object_instance_to_category[obj_inst] not in MACRO_PARTICLE_SYNSETS.union(WATER_SYNSETS)}\n    if len(remaining_objs) != 0:\n        return \"Some objects do not have any kinematic condition defined for them in the initial conditions: {}\".format(\n            \", \".join(remaining_objs)\n        )\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.build_sampling_order"},{"title":"<code>check_scene(env)</code>","text":"<p>Runs sanity checks for the current scene for the given BEHAVIOR task</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - bool: Whether the generated scene activity should be accepted or not - dict: Any feedback from the sampling / initialization process</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def check_scene(self, env):\n    \"\"\"\n    Runs sanity checks for the current scene for the given BEHAVIOR task\n\n    Args:\n        env (Environment): Current active environment instance\n\n    Returns:\n        2-tuple:\n            - bool: Whether the generated scene activity should be accepted or not\n            - dict: Any feedback from the sampling / initialization process\n    \"\"\"\n    error_msg = self.parse_non_sampleable_object_room_assignment(env)\n    if error_msg:\n        logging.warning(error_msg)\n        return False, error_msg\n\n    error_msg = self.build_sampling_order(env)\n    if error_msg:\n        logging.warning(error_msg)\n        return False, error_msg\n\n    error_msg = self.build_non_sampleable_object_scope(env)\n    if error_msg:\n        logging.warning(error_msg)\n        return False, error_msg\n\n    error_msg = self.import_sampleable_objects(env)\n    if error_msg:\n        logging.warning(error_msg)\n        return False, error_msg\n\n    self.object_scope[\"agent.n.01_1\"] = self.get_agent(env)\n\n    return True, None\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.check_scene"},{"title":"<code>consolidate_room_instance(filtered_object_scope, condition_type)</code>","text":"<p>Consolidates room instances</p> <p>Parameters:</p>    Name Type Description Default     <code>filtered_object_scope</code>  <code>dict</code>  <p>Filtered object scope</p>  required    <code>condition_type</code>  <code>str</code>  <p>What type of condition to sample, e.g., \"initial\"</p>  required      Source code in <code>tasks/behavior_task.py</code> <pre><code>def consolidate_room_instance(self, filtered_object_scope, condition_type):\n    \"\"\"\n    Consolidates room instances\n\n    Args:\n        filtered_object_scope (dict): Filtered object scope\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n    \"\"\"\n    for room_type in filtered_object_scope:\n        # For each room_type, filter in room_inst that has successful\n        # sampling options for all obj_inst in this room_type\n        room_inst_satisfied = set.intersection(\n            *[\n                set(filtered_object_scope[room_type][obj_inst].keys())\n                for obj_inst in filtered_object_scope[room_type]\n            ]\n        )\n\n        if len(room_inst_satisfied) == 0:\n            error_msg = \"{}: Room type [{}] of scene [{}] do not contain or cannot sample all the objects needed.\\nThe following are the possible room instances for each object, the intersection of which is an empty set.\\n\".format(\n                condition_type, room_type, self.scene_model\n            )\n            for obj_inst in filtered_object_scope[room_type]:\n                error_msg += (\n                    \"{}: \".format(obj_inst) + \", \".join(filtered_object_scope[room_type][obj_inst].keys()) + \"\\n\"\n                )\n\n            return error_msg\n\n        for obj_inst in filtered_object_scope[room_type]:\n            filtered_object_scope[room_type][obj_inst] = {\n                key: val\n                for key, val in filtered_object_scope[room_type][obj_inst].items()\n                if key in room_inst_satisfied\n            }\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.consolidate_room_instance"},{"title":"<code>filter_object_scope(input_object_scope, conditions, condition_type)</code>","text":"<p>Filters the object scope based on given @input_object_scope, @conditions, and @condition_type</p> <p>Parameters:</p>    Name Type Description Default     <code>input_object_scope</code>  <code>dict</code>    required    <code>conditions</code>  <code>list</code>  <p>List of conditions to filter scope with, where each list entry is a tuple of (condition, positive), where @positive is True if the condition has a positive evaluation.</p>  required    <code>condition_type</code>  <code>str</code>  <p>What type of condition to sample, e.g., \"initial\"</p>  required     <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Filtered object scope</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def filter_object_scope(self, input_object_scope, conditions, condition_type):\n    \"\"\"\n    Filters the object scope based on given @input_object_scope, @conditions, and @condition_type\n\n    Args:\n        input_object_scope (dict):\n        conditions (list): List of conditions to filter scope with, where each list entry is\n            a tuple of (condition, positive), where @positive is True if the condition has a positive\n            evaluation.\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n\n    Returns:\n        dict: Filtered object scope\n    \"\"\"\n    filtered_object_scope = {}\n    for room_type in input_object_scope:\n        filtered_object_scope[room_type] = {}\n        for scene_obj in input_object_scope[room_type]:\n            filtered_object_scope[room_type][scene_obj] = {}\n            for room_inst in input_object_scope[room_type][scene_obj]:\n                # These are a list of candidate simulator objects that need sampling test\n                for obj in input_object_scope[room_type][scene_obj][room_inst]:\n                    # Temporarily set object_scope to point to this candidate object\n                    self.object_scope[scene_obj] = obj\n\n                    success = True\n                    # If this candidate object is not involved in any conditions,\n                    # success will be True by default and this object will qualify\n                    for condition, positive in conditions:\n                        # Sample positive kinematic conditions that involve this candidate object\n                        if condition.STATE_NAME in KINEMATICS_STATES and positive and scene_obj in condition.body:\n                            # Use pybullet GUI for debugging\n                            if self.debug_object_sampling is not None and self.debug_object_sampling == condition.body[0]:\n                                og.debug_sampling = True\n\n                            success = condition.sample(binary_state=positive)\n                            log_msg = \" \".join(\n                                [\n                                    \"{} condition sampling\".format(condition_type),\n                                    room_type,\n                                    scene_obj,\n                                    room_inst,\n                                    obj.name,\n                                    condition.STATE_NAME,\n                                    str(condition.body),\n                                    str(success),\n                                ]\n                            )\n                            logging.warning(log_msg)\n\n                            # If any condition fails for this candidate object, skip\n                            if not success:\n                                break\n\n                    # If this candidate object fails, move on to the next candidate object\n                    if not success:\n                        continue\n\n                    if room_inst not in filtered_object_scope[room_type][scene_obj]:\n                        filtered_object_scope[room_type][scene_obj][room_inst] = []\n                    filtered_object_scope[room_type][scene_obj][room_inst].append(obj)\n\n    return filtered_object_scope\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.filter_object_scope"},{"title":"<code>get_agent(env)</code>","text":"<p>Grab the 0th agent from @env</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required     <p>Returns:</p>    Name Type Description     <code>BaseRobot</code>   <p>The 0th robot from the environment instance</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def get_agent(self, env):\n    \"\"\"\n    Grab the 0th agent from @env\n\n    Args:\n        env (Environment): Current active environment instance\n\n    Returns:\n        BaseRobot: The 0th robot from the environment instance\n    \"\"\"\n    # We assume the relevant agent is the first agent in the scene\n    return env.robots[0]\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.get_agent"},{"title":"<code>get_potential(env)</code>","text":"<p>Compute task-specific potential: distance to the goal</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required     <p>Returns:</p>    Name Type Description     <code>float</code>   <p>Computed potential</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def get_potential(self, env):\n    \"\"\"\n    Compute task-specific potential: distance to the goal\n\n    Args:\n        env (Environment): Current active environment instance\n\n    Returns:\n        float: Computed potential\n    \"\"\"\n    # Evaluate the first ground goal state option as the potential\n    _, satisfied_predicates = evaluate_goal_conditions(self.ground_goal_state_options[0])\n    success_score = len(satisfied_predicates[\"satisfied\"]) / (\n        len(satisfied_predicates[\"satisfied\"]) + len(satisfied_predicates[\"unsatisfied\"])\n    )\n    return -success_score\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.get_potential"},{"title":"<code>group_initial_conditions()</code>","text":"<p>We group initial conditions by first splitting the desired task-relevant objects into non-sampleable objects and sampleable objects.</p> <p>Non-sampleable objects are objects that should ALREADY be in the scene, and should NOT be generated / sampled on the fly</p> <p>Sampleable objects are objects that need to be additionally imported into the scene.</p> <p>Returns:</p>    Type Description       <p>None or str: None if successful, otherwise failure string</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def group_initial_conditions(self):\n    \"\"\"\n    We group initial conditions by first splitting the desired task-relevant objects into non-sampleable objects\n    and sampleable objects.\n\n    Non-sampleable objects are objects that should ALREADY be in the scene, and should NOT be generated / sampled\n    on the fly\n\n    Sampleable objects are objects that need to be additionally imported into the scene.\n\n    Returns:\n        None or str: None if successful, otherwise failure string\n    \"\"\"\n    self.non_sampleable_object_conditions = []\n    self.sampleable_object_conditions = []\n\n    # TODO: currently we assume self.initial_conditions is a list of\n    # bddl.condition_evaluation.HEAD, each with one child.\n    # This child is either a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate or\n    # a Negation of a ObjectStateUnaryPredicate/ObjectStateBinaryPredicate\n    for condition in self.activity_initial_conditions:\n        condition, positive = self.process_single_condition(condition)\n        if condition is None:\n            continue\n\n        # Sampled conditions must always be positive\n        # Non-positive (e.g.: NOT onTop) is not restrictive enough for sampling\n        if condition.STATE_NAME in KINEMATICS_STATES and not positive:\n            return \"Initial condition has negative kinematic conditions: {}\".format(condition.body)\n\n        condition_body = set(condition.body)\n\n        # If the condition involves any non-sampleable object (e.g.: furniture), it's a non-sampleable condition\n        # This means that there's no ordering constraint in terms of sampling, because we know the, e.g., furniture\n        # object already exists in the scene and is placed, so these specific conditions can be sampled without\n        # any dependencies\n        if len(self.non_sampleable_object_instances.intersection(condition_body)) &gt; 0:\n            self.non_sampleable_object_conditions.append((condition, positive))\n        else:\n            # There are dependencies that must be taken into account\n            self.sampleable_object_conditions.append((condition, positive))\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.group_initial_conditions"},{"title":"<code>import_sampleable_objects(env)</code>","text":"<p>Import all objects that can be sampled</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required      Source code in <code>tasks/behavior_task.py</code> <pre><code>def import_sampleable_objects(self, env):\n    \"\"\"\n    Import all objects that can be sampled\n\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\n    assert og.sim.is_playing()\n    og.sim.stop()\n\n    # Move the robot object frame to a far away location, similar to other newly imported objects below\n    env.robots[0].set_position_orientation([300, 300, 300], [0, 0, 0, 1])\n\n    self.sampled_objects = set()\n    num_new_obj = 0\n    # Only populate self.object_scope for sampleable objects\n    avg_category_spec = get_og_avg_category_specs()\n    for obj_cat in self.activity_conditions.parsed_objects:\n        if obj_cat == \"agent.n.01\":\n            continue\n        if obj_cat in NON_SAMPLEABLE_OBJECTS:\n            continue\n        if obj_cat in SYSTEM_SYNSETS_TO_SYSTEM_NAMES:\n            assert len(self.activity_conditions.parsed_objects[obj_cat]) == 1, \"Systems are singletons\"\n            obj_inst = self.activity_conditions.parsed_objects[obj_cat][0]\n            self.object_scope[obj_inst] = get_system_from_element_name(SYSTEM_SYNSETS_TO_SYSTEM_NAMES[obj_cat])\n            continue\n\n        is_sliceable = self.object_taxonomy.has_ability(obj_cat, \"sliceable\")\n        categories = self.object_taxonomy.get_subtree_igibson_categories(obj_cat)\n\n        # TODO: temporary hack\n        remove_categories = [\n            \"pop_case\",  # too large\n            \"jewel\",  # too small\n            \"ring\",  # too small\n        ]\n        for remove_category in remove_categories:\n            if remove_category in categories:\n                categories.remove(remove_category)\n\n        for obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\n            category = np.random.choice(categories)\n            # for sliceable objects, only get the whole objects\n            try:\n                model_choices = get_object_models_of_category(\n                    category, filter_method=\"sliceable_whole\" if is_sliceable else None\n                )\n            except:\n                og.sim.play()\n                return f\"Missing object category: {category}\"\n\n            if len(model_choices) == 0:\n                # restore back to the play state\n                og.sim.play()\n                return f\"Missing valid object models for category: {category}\"\n\n            # TODO: This no longer works because model ID changes in the new asset\n            # Filter object models if the object category is openable\n            # synset = self.object_taxonomy.get_class_name_from_igibson_category(category)\n            # if self.object_taxonomy.has_ability(synset, \"openable\"):\n            #     # Always use the articulated version of a certain object if its category is openable\n            #     # E.g. backpack, jar, etc\n            #     model_choices = [m for m in model_choices if \"articulated_\" in m]\n            #     if len(model_choices) == 0:\n            #         return \"{} is Openable, but does not have articulated models.\".format(category)\n\n            # Randomly select an object model\n            model = np.random.choice(model_choices)\n\n            # TODO: temporary hack no longer works because model ID changes in the new asset\n            # for \"collecting aluminum cans\", we need pop cans (not bottles)\n            # if category == \"pop\" and self.activity_name in [\"collecting_aluminum_cans\"]:\n            #     model = np.random.choice([str(i) for i in range(40, 46)])\n            # if category == \"spoon\" and self.activity_name in [\"polishing_silver\"]:\n            #     model = np.random.choice([str(i) for i in [2, 5, 6]])\n\n            model_path = get_og_model_path(category, model)\n            usd_path = os.path.join(model_path, \"usd\", f\"{model}.usd\")\n            obj_name = \"{}_{}\".format(category, len(og.sim.scene.objects))\n\n            # create the object\n            simulator_obj = DatasetObject(\n                prim_path=f\"/World/{obj_name}\",\n                usd_path=usd_path,\n                name=obj_name,\n                category=category,\n                fit_avg_dim_volume=True,\n            )\n            num_new_obj += 1\n\n            # Load the object into the simulator\n            assert og.sim.scene.loaded, \"Scene is not loaded\"\n            og.sim.import_object(simulator_obj)\n\n            # Set these objects to be far-away locations\n            simulator_obj.set_position(np.array([100.0 + num_new_obj - 1, 100.0, -100.0]))\n\n            self.sampled_objects.add(simulator_obj)\n            self.object_scope[obj_inst] = simulator_obj\n\n    # Play the sim again to initialize all the newly imported objects.\n    og.sim.play()\n    # Also reset the agent\n    env.robots[0].reset()\n    # Take one extra step so that the bounding box of the agent is up-to-date.\n    og.sim.step()\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.import_sampleable_objects"},{"title":"<code>initialize_activity(env)</code>","text":"<p>Initializes the desired activity in the current environment @env</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - bool: Whether the generated scene activity should be accepted or not - dict: Any feedback from the sampling / initialization process</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def initialize_activity(self, env):\n    \"\"\"\n    Initializes the desired activity in the current environment @env\n\n    Args:\n        env (Environment): Current active environment instance\n\n    Returns:\n        2-tuple:\n            - bool: Whether the generated scene activity should be accepted or not\n            - dict: Any feedback from the sampling / initialization process\n    \"\"\"\n    accept_scene = True\n    feedback = None\n\n    if self.online_object_sampling:\n        # Reject scenes with missing non-sampleable objects\n        # Populate object_scope with sampleable objects and the robot\n        accept_scene, feedback = self.check_scene(env)\n        if not accept_scene:\n            return accept_scene, feedback\n        # Sample objects to satisfy initial conditions\n        accept_scene, feedback = self.sample(env)\n        if not accept_scene:\n            return accept_scene, feedback\n    else:\n        # Load existing scene cache and assign object scope accordingly\n        self.assign_object_scope_with_cache(env)\n\n    # Generate goal condition with the fully populated self.object_scope\n    self.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\n    self.ground_goal_state_options = get_ground_goal_state_options(\n        self.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n    )\n    return accept_scene, feedback\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.initialize_activity"},{"title":"<code>iterate_instruction()</code>","text":"<p>Increment the instruction</p>  Source code in <code>tasks/behavior_task.py</code> <pre><code>def iterate_instruction(self):\n    \"\"\"\n    Increment the instruction\n    \"\"\"\n    self.currently_viewed_index = (self.currently_viewed_index + 1) % len(self.activity_conditions.parsed_goal_conditions)\n    self.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.iterate_instruction"},{"title":"<code>maximum_bipartite_matching(filtered_object_scope, condition_type)</code>","text":"<p>Matches objects from @filtered_object_scope to specific room instances it can be sampled from</p> <p>Parameters:</p>    Name Type Description Default     <code>filtered_object_scope</code>  <code>dict</code>  <p>Filtered object scope</p>  required    <code>condition_type</code>  <code>str</code>  <p>What type of condition to sample, e.g., \"initial\"</p>  required     <p>Returns:</p>    Type Description       <p>None or str: If successful, returns None. Otherwise, returns an error message</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def maximum_bipartite_matching(self, filtered_object_scope, condition_type):\n    \"\"\"\n    Matches objects from @filtered_object_scope to specific room instances it can be\n    sampled from\n\n    Args:\n        filtered_object_scope (dict): Filtered object scope\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\n    # For each room instance, perform maximum bipartite matching between object instance in scope to simulator objects\n    # Left nodes: a list of object instance in scope\n    # Right nodes: a list of simulator objects\n    # Edges: if the simulator object can support the sampling requirement of ths object instance\n    for room_type in filtered_object_scope:\n        # The same room instances will be shared across all scene obj in a given room type\n        some_obj = list(filtered_object_scope[room_type].keys())[0]\n        room_insts = list(filtered_object_scope[room_type][some_obj].keys())\n        success = False\n        # Loop through each room instance\n        for room_inst in room_insts:\n            graph = nx.Graph()\n            # For this given room instance, gether mapping from obj instance to a list of simulator obj\n            obj_inst_to_obj_per_room_inst = {}\n            for obj_inst in filtered_object_scope[room_type]:\n                obj_inst_to_obj_per_room_inst[obj_inst] = filtered_object_scope[room_type][obj_inst][room_inst]\n            top_nodes = []\n            log_msg = \"MBM for room instance [{}]\".format(room_inst)\n            logging.warning((log_msg))\n            for obj_inst in obj_inst_to_obj_per_room_inst:\n                for obj in obj_inst_to_obj_per_room_inst[obj_inst]:\n                    # Create an edge between obj instance and each of the simulator obj that supports sampling\n                    graph.add_edge(obj_inst, obj)\n                    log_msg = \"Adding edge: {} &lt;-&gt; {}\".format(obj_inst, obj.name)\n                    logging.warning((log_msg))\n                    top_nodes.append(obj_inst)\n            # Need to provide top_nodes that contain all nodes in one bipartite node set\n            # The matches will have two items for each match (e.g. A -&gt; B, B -&gt; A)\n            matches = nx.bipartite.maximum_matching(graph, top_nodes=top_nodes)\n            if len(matches) == 2 * len(obj_inst_to_obj_per_room_inst):\n                logging.warning((\"Object scope finalized:\"))\n                for obj_inst, obj in matches.items():\n                    if obj_inst in obj_inst_to_obj_per_room_inst:\n                        self.object_scope[obj_inst] = obj\n                        logging.warning((obj_inst, obj.name))\n                success = True\n                break\n        if not success:\n            return \"{}: Room type [{}] of scene [{}] do not have enough simulator objects that can successfully sample all the objects needed. This is usually caused by specifying too many object instances in the object scope or the conditions are so stringent that too few simulator objects can satisfy them via sampling.\\n\".format(\n                condition_type, room_type, self.scene_model\n            )\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.maximum_bipartite_matching"},{"title":"<code>parse_non_sampleable_object_room_assignment(env)</code>","text":"<p>Infers which rooms each object is assigned to</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required      Source code in <code>tasks/behavior_task.py</code> <pre><code>def parse_non_sampleable_object_room_assignment(self, env):\n    \"\"\"\n    Infers which rooms each object is assigned to\n\n    Args:\n        env (Environment): Current active environment instance\n    \"\"\"\n    self.room_type_to_object_instance = OrderedDict()\n    self.non_sampleable_object_instances = set()\n    for cond in self.activity_conditions.parsed_initial_conditions:\n        if cond[0] == \"inroom\":\n            obj_inst, room_type = cond[1], cond[2]\n            obj_cat = self.object_instance_to_category[obj_inst]\n            if obj_cat not in NON_SAMPLEABLE_OBJECTS:\n                # Invalid room assignment\n                return \"You have assigned room type for [{}], but [{}] is sampleable. Only non-sampleable objects can have room assignment.\".format(\n                    obj_cat, obj_cat\n                )\n            if room_type not in og.sim.scene.seg_map.room_sem_name_to_ins_name:\n                # Missing room type\n                return \"Room type [{}] missing in scene [{}].\".format(room_type, og.sim.scene.scene_model)\n            if room_type not in self.room_type_to_object_instance:\n                self.room_type_to_object_instance[room_type] = []\n            self.room_type_to_object_instance[room_type].append(obj_inst)\n\n            if obj_inst in self.non_sampleable_object_instances:\n                # Duplicate room assignment\n                return \"Object [{}] has more than one room assignment\".format(obj_inst)\n\n            self.non_sampleable_object_instances.add(obj_inst)\n\n    for obj_cat in self.activity_conditions.parsed_objects:\n        if obj_cat not in NON_SAMPLEABLE_OBJECTS:\n            continue\n        for obj_inst in self.activity_conditions.parsed_objects[obj_cat]:\n            if obj_inst not in self.non_sampleable_object_instances:\n                # Missing room assignment\n                return \"All non-sampleable objects should have room assignment. [{}] does not have one.\".format(\n                    obj_inst\n                )\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.parse_non_sampleable_object_room_assignment"},{"title":"<code>process_single_condition(condition)</code>","text":"<p>Processes a single BDDL condition</p> <p>Parameters:</p>    Name Type Description Default     <code>condition</code>  <code>Condition</code>  <p>Condition to process</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - Expression: Condition's expression - bool: Whether this evaluated condition is positive or negative</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def process_single_condition(self, condition):\n    \"\"\"\n    Processes a single BDDL condition\n\n    Args:\n        condition (Condition): Condition to process\n\n    Returns:\n        2-tuple:\n            - Expression: Condition's expression\n            - bool: Whether this evaluated condition is positive or negative\n    \"\"\"\n    if not isinstance(condition.children[0], Negation) and not isinstance(condition.children[0], AtomicFormula):\n        logging.warning((\"Skipping over sampling of predicate that is not a negation or an atomic formula\"))\n        return None, None\n\n    if isinstance(condition.children[0], Negation):\n        condition = condition.children[0].children[0]\n        positive = False\n    else:\n        condition = condition.children[0]\n        positive = True\n\n    return condition, positive\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.process_single_condition"},{"title":"<code>sample(env, validate_goal=False)</code>","text":"<p>Run sampling for this BEHAVIOR task</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Current active environment instance</p>  required    <code>validate_goal</code>  <code>bool</code>  <p>Whether the goal should be validated or not</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - bool: Whether sampling was successful or not - None or str: None if successful, otherwise the associated error message</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def sample(self, env, validate_goal=False):\n    \"\"\"\n    Run sampling for this BEHAVIOR task\n\n    Args:\n        env (Environment): Current active environment instance\n        validate_goal (bool): Whether the goal should be validated or not\n\n    Returns:\n        2-tuple:\n            - bool: Whether sampling was successful or not\n            - None or str: None if successful, otherwise the associated error message\n    \"\"\"\n\n    error_msg = self.group_initial_conditions()\n    if error_msg:\n        logging.warning(error_msg)\n        return False, error_msg\n\n    error_msg = self.sample_initial_conditions()\n    if error_msg:\n        logging.warning(error_msg)\n        return False, error_msg\n\n    if validate_goal:\n        error_msg = self.sample_goal_conditions()\n        if error_msg:\n            logging.warning(error_msg)\n            return False, error_msg\n\n    error_msg = self.sample_initial_conditions_final()\n    if error_msg:\n        logging.warning(error_msg)\n        return False, error_msg\n\n    return True, None\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample"},{"title":"<code>sample_conditions(input_object_scope, conditions, condition_type)</code>","text":"<p>Sample conditions</p> <p>Parameters:</p>    Name Type Description Default     <code>input_object_scope</code>  <code>dict</code>    required    <code>conditions</code>  <code>list</code>  <p>List of conditions to filter scope with, where each list entry is a tuple of (condition, positive), where @positive is True if the condition has a positive evaluation.</p>  required    <code>condition_type</code>  <code>str</code>  <p>What type of condition to sample, e.g., \"initial\"</p>  required     <p>Returns:</p>    Type Description       <p>None or str: If successful, returns None. Otherwise, returns an error message</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def sample_conditions(self, input_object_scope, conditions, condition_type):\n    \"\"\"\n    Sample conditions\n\n    Args:\n        input_object_scope (dict):\n        conditions (list): List of conditions to filter scope with, where each list entry is\n            a tuple of (condition, positive), where @positive is True if the condition has a positive\n            evaluation.\n        condition_type (str): What type of condition to sample, e.g., \"initial\"\n\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\n    filtered_object_scope = self.filter_object_scope(input_object_scope, conditions, condition_type)\n    error_msg = self.consolidate_room_instance(filtered_object_scope, condition_type)\n    if error_msg:\n        return error_msg, None\n    return self.maximum_bipartite_matching(filtered_object_scope, condition_type), filtered_object_scope\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_conditions"},{"title":"<code>sample_goal_conditions()</code>","text":"<p>Sample goal conditions</p> <p>Returns:</p>    Type Description       <p>None or str: If successful, returns None. Otherwise, returns an error message</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def sample_goal_conditions(self):\n    \"\"\"\n    Sample goal conditions\n\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\n    np.random.shuffle(self.ground_goal_state_options)\n    logging.warning((\"number of ground_goal_state_options\", len(self.ground_goal_state_options)))\n    num_goal_condition_set_to_test = 10\n\n    goal_condition_success = False\n    # Try to fulfill different set of ground goal conditions (maximum num_goal_condition_set_to_test)\n    for goal_condition_set in self.ground_goal_state_options[:num_goal_condition_set_to_test]:\n        goal_condition_processed = []\n        for condition in goal_condition_set:\n            condition, positive = self.process_single_condition(condition)\n            if condition is None:\n                continue\n            goal_condition_processed.append((condition, positive))\n\n        error_msg, _ = self.sample_conditions(\n            self.non_sampleable_object_scope_filtered_initial, goal_condition_processed, \"goal\"\n        )\n        if not error_msg:\n            # if one set of goal conditions (and initial conditions) are satisfied, sampling is successful\n            goal_condition_success = True\n            break\n\n    if not goal_condition_success:\n        return error_msg\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_goal_conditions"},{"title":"<code>sample_initial_conditions()</code>","text":"<p>Sample initial conditions</p> <p>Returns:</p>    Type Description       <p>None or str: If successful, returns None. Otherwise, returns an error message</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def sample_initial_conditions(self):\n    \"\"\"\n    Sample initial conditions\n\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\n    error_msg, self.non_sampleable_object_scope_filtered_initial = self.sample_conditions(\n        self.non_sampleable_object_scope, self.non_sampleable_object_conditions, \"initial\"\n    )\n    return error_msg\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_initial_conditions"},{"title":"<code>sample_initial_conditions_final()</code>","text":"<p>Sample final initial conditions</p> <p>Returns:</p>    Type Description       <p>None or str: If successful, returns None. Otherwise, returns an error message</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def sample_initial_conditions_final(self):\n    \"\"\"\n    Sample final initial conditions\n\n    Returns:\n        None or str: If successful, returns None. Otherwise, returns an error message\n    \"\"\"\n    # Do the final round of sampling with object scope fixed\n    for condition, positive in self.non_sampleable_object_conditions:\n        num_trials = 10\n        for _ in range(num_trials):\n            success = condition.sample(binary_state=positive)\n            if success:\n                break\n        if not success:\n            error_msg = \"Non-sampleable object conditions failed even after successful matching: {}\".format(\n                condition.body\n            )\n            return error_msg\n\n    # Use ray casting for ontop and inside sampling for sampleable objects\n    for condition, positive in self.sampleable_object_conditions:\n        if condition.STATE_NAME in [\"inside\", \"ontop\"]:\n            condition.kwargs[\"use_ray_casting_method\"] = True\n\n    if len(self.object_sampling_orders) &gt; 0:\n        # Pop non-sampleable objects\n        self.object_sampling_orders.pop(0)\n        for cur_batch in self.object_sampling_orders:\n            # First sample non-sliced conditions\n            for condition, positive in self.sampleable_object_conditions:\n                if condition.STATE_NAME == \"sliced\":\n                    continue\n                # Sample conditions that involve the current batch of objects\n                if condition.body[0] in cur_batch:\n                    num_trials = 10\n                    for _ in range(num_trials):\n                        success = condition.sample(binary_state=positive)\n                        if success:\n                            break\n                    if not success:\n                        return \"Sampleable object conditions failed: {} {}\".format(\n                            condition.STATE_NAME, condition.body\n                        )\n\n            # Then sample sliced conditions\n            for condition, positive in self.sampleable_object_conditions:\n                if condition.STATE_NAME != \"sliced\":\n                    continue\n                # Sample conditions that involve the current batch of objects\n                if condition.body[0] in cur_batch:\n                    success = condition.sample(binary_state=positive)\n                    if not success:\n                        return \"Sampleable object conditions failed: {}\".format(condition.body)\n\n    # One more sim step to make sure the object states are propagated correctly\n    # E.g. after sampling Filled.set_value(True), Filled.get_value() will become True only after one step\n    og.sim.step()\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.sample_initial_conditions_final"},{"title":"<code>show_instruction()</code>","text":"<p>Get current instruction for user</p> <p>Returns:</p>    Type Description       <p>3-tuple: - str: Current goal condition in natural language - 3-tuple: (R,G,B) color to assign to text - list of BaseObject: Relevant objects for the current instruction</p>     Source code in <code>tasks/behavior_task.py</code> <pre><code>def show_instruction(self):\n    \"\"\"\n    Get current instruction for user\n\n    Returns:\n        3-tuple:\n            - str: Current goal condition in natural language\n            - 3-tuple: (R,G,B) color to assign to text\n            - list of BaseObject: Relevant objects for the current instruction\n    \"\"\"\n    satisfied = self.currently_viewed_instruction in self._termination_conditions[\"predicate\"].goal_status[\"satisfied\"]\n    natural_language_condition = self.activity_natural_language_goal_conditions[self.currently_viewed_instruction]\n    objects = self.activity_goal_conditions[self.currently_viewed_instruction].get_relevant_objects()\n    text_color = (\n        [83.0 / 255.0, 176.0 / 255.0, 72.0 / 255.0] if satisfied else [255.0 / 255.0, 51.0 / 255.0, 51.0 / 255.0]\n    )\n\n    return natural_language_condition, text_color, objects\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.show_instruction"},{"title":"<code>update_activity(activity_name, activity_definition_id, predefined_problem=None)</code>","text":"<p>Update the active Behavior activity being deployed</p> <p>Parameters:</p>    Name Type Description Default     <code>activity_name</code>  <code>None or str</code>  <p>Name of the Behavior Task to instantiate</p>  required    <code>activity_definition_id</code>  <code>int</code>  <p>Specification to load for the desired task. For a given Behavior Task, multiple task specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This ID determines which specification to use</p>  required    <code>predefined_problem</code>  <code>None or str</code>  <p>If specified, specifies the raw string definition of the Behavior Task to load. This will automatically override @activity_name and @activity_definition_id.</p>  <code>None</code>      Source code in <code>tasks/behavior_task.py</code> <pre><code>def update_activity(self, activity_name, activity_definition_id, predefined_problem=None):\n    \"\"\"\n    Update the active Behavior activity being deployed\n\n    Args:\n        activity_name (None or str): Name of the Behavior Task to instantiate\n        activity_definition_id (int): Specification to load for the desired task. For a given Behavior Task, multiple task\n            specifications can be used (i.e.: differing goal conditions, or \"ways\" to complete a given task). This\n            ID determines which specification to use\n        predefined_problem (None or str): If specified, specifies the raw string definition of the Behavior Task to\n            load. This will automatically override @activity_name and @activity_definition_id.\n    \"\"\"\n    # Update internal variables based on values\n\n    # Activity info\n    self.activity_name = activity_name\n    self.activity_definition_id = activity_definition_id\n    self.activity_conditions = Conditions(\n        activity_name,\n        activity_definition_id,\n        simulator_name=\"igibson\",       # TODO: Update!\n        predefined_problem=predefined_problem,\n    )\n\n    # Object info\n    self.object_scope = get_object_scope(self.activity_conditions)\n    self.object_instance_to_category = {\n        obj_inst: obj_cat\n        for obj_cat in self.activity_conditions.parsed_objects\n        for obj_inst in self.activity_conditions.parsed_objects[obj_cat]\n    }\n\n    # Generate initial and goal conditions\n    self.activity_initial_conditions = get_initial_conditions(self.activity_conditions, self.backend, self.object_scope)\n    self.activity_goal_conditions = get_goal_conditions(self.activity_conditions, self.backend, self.object_scope)\n    self.ground_goal_state_options = get_ground_goal_state_options(\n        self.activity_conditions, self.backend, self.object_scope, self.activity_goal_conditions\n    )\n\n    # Demo attributes\n    self.instruction_order = np.arange(len(self.activity_conditions.parsed_goal_conditions))\n    np.random.shuffle(self.instruction_order)\n    self.currently_viewed_index = 0\n    self.currently_viewed_instruction = self.instruction_order[self.currently_viewed_index]\n    self.activity_natural_language_goal_conditions = get_natural_goal_conditions(self.activity_conditions)\n</code></pre>","location":"reference/tasks/behavior_task.html#tasks.behavior_task.BehaviorTask.update_activity"},{"title":"dummy_task","text":"","location":"reference/tasks/dummy_task.html"},{"title":"<code>DummyTask</code>","text":"<p>         Bases: <code>BaseTask</code></p> <p>Dummy task</p>  Source code in <code>tasks/dummy_task.py</code> <pre><code>class DummyTask(BaseTask):\n    \"\"\"\n    Dummy task\n    \"\"\"\n\n    def _load(self, env):\n        # Do nothing here\n        pass\n\n    def _create_termination_conditions(self):\n        # Do nothing\n        return OrderedDict()\n\n    def _create_reward_functions(self):\n        # Do nothing\n        return OrderedDict()\n\n    def _reset_agent(self, env):\n        # Place agent(s) at origin by default\n        for robot in env.robots:\n            robot.reset()\n            land_object(robot, np.zeros(3), np.array([0, 0, 0, 1]), env.initial_pos_z_offset)\n\n    def _get_obs(self, env):\n        # No task-specific obs of any kind\n        return OrderedDict(), OrderedDict()\n\n    def _load_non_low_dim_observation_space(self):\n        # No non-low dim observations so we return an empty dict\n        return OrderedDict()\n\n    @classproperty\n    def valid_scene_types(cls):\n        # Any scene works\n        return {Scene}\n\n    @classproperty\n    def default_termination_config(cls):\n        # Empty dict\n        return {}\n\n    @classproperty\n    def default_reward_config(cls):\n        # Empty dict\n        return {}\n</code></pre>","location":"reference/tasks/dummy_task.html#tasks.dummy_task.DummyTask"},{"title":"furniture_closing_task","text":"","location":"reference/tasks/furniture_closing_task.html"},{"title":"<code>FurnitureClosingTask</code>","text":"<p>         Bases: <code>BaseTask</code></p> <p>Furniture Closing Task The goal is to close as many furniture (e.g. cabinets and fridges) as possible</p>  Source code in <code>tasks/furniture_closing_task.py</code> <pre><code>class FurnitureClosingTask(BaseTask):\n    \"\"\"\n    Furniture Closing Task\n    The goal is to close as many furniture (e.g. cabinets and fridges) as possible\n    \"\"\"\n\n    def __init__(\n            self,\n            robot_idn=0,\n            floor=0,\n            categories=\"all\",\n            p_open=0.5,\n            termination_config=None,\n            reward_config=None,\n\n    ):\n        # Store inputs\n        self._robot_idn = robot_idn\n        self._floor = floor\n        self._categories = FURNITURE_CATEGORIES if categories == \"all\" else \\\n            set([categories]) if isinstance(categories, str) else set(categories)\n        self._p_open = p_open\n\n        # Initialize other values that will be loaded at runtime\n        self._r_prismatic = None\n        self._r_revolute = None\n        self._opened_objects = None\n\n        # Run super init\n        super().__init__(termination_config=termination_config, reward_config=reward_config)\n\n    def _load(self, env):\n        # Nothing to do here\n        pass\n\n    def _create_termination_conditions(self):\n        # Initialize termination conditions dict and fill in with MaxCollision, Timeout, and Falling\n        terminations = OrderedDict()\n\n        terminations[\"max_collision\"] = MaxCollision(max_collisions=self._termination_config[\"max_collisions\"])\n        terminations[\"timeout\"] = Timeout(max_steps=self._termination_config[\"max_steps\"])\n        terminations[\"falling\"] = Falling(robot_idn=self._robot_idn, fall_height=self._termination_config[\"fall_height\"])\n\n        return terminations\n\n    def _create_reward_functions(self):\n        # Initialize reward functions dict and fill in with Potential reward\n        rewards = OrderedDict()\n\n        rewards[\"potential\"] = PotentialReward(\n            potential_fcn=self.get_potential,\n            r_potential=self._reward_config[\"r_potential\"],\n        )\n\n        # Also save other rewards not associated with a reward function internall\n        self._r_prismatic = self._reward_config[\"r_prismatic\"]\n        self._r_revolute = self._reward_config[\"r_revolute\"]\n\n        return rewards\n\n    def get_potential(self, env):\n        \"\"\"\n        Compute task-specific potential: furniture joint positions\n\n        Args:\n            env (Environment): Environment instance\n        \"\"\"\n        task_potential = 0.0\n        for obj in self._opened_objects:\n            for joint in obj.joints.values():\n                # Make sure we're only dealing with prismatic / revolute joints\n                assert joint.n_dof == 1, \"Can only get task potential of prismatic / revolute joints!\"\n                # Potential is scaled value of the joint's position\n                scale = self._r_prismatic if joint.joint_type == \"PrismaticJoint\" else self._r_revolute\n                task_potential += scale * joint.get_state(normalized=True)[0][0]\n\n        return task_potential\n\n    def _reset_scene(self, env):\n        # Run super first\n        super().reset(env=env)\n\n        # Make sure all objects are awake\n        env.scene.wake_scene_objects()\n        # Sample opening objects and grab their references\n        opened_objects = []\n        for category in self._categories:\n            opened_objects += env.scene.open_all_objs_by_category(category=category, mode=\"random\", p=self._p_open)\n        self._opened_objects = opened_objects\n\n    def _sample_initial_pose(self, env):\n\n        _, initial_pos = env.scene.get_random_point(floor=self._floor)\n        initial_quat = T.euler2quat(np.array([0, 0, np.random.uniform(0, np.pi * 2)]))\n        return initial_pos, initial_quat\n\n    def _reset_agent(self, env):\n        # We attempt to sample valid initial poses and goal positions\n        success, max_trials = False, 100\n\n        # Store the state of the environment now, so that we can restore it after each setting attempt\n        state = og.sim.dump_state(serialized=True)\n\n        success, initial_pos, initial_quat = False, None, None\n        for i in range(max_trials):\n            initial_pos, initial_quat = self._sample_initial_pose(env)\n            # Make sure the sampled robot start pose and goal position are both collision-free\n            success = test_valid_pose(env.robots[self._robot_idn], initial_pos, initial_quat, env.initial_pos_z_offset)\n\n            # Load the original state\n            og.sim.load_state(state=state, serialized=True)\n\n            # Don't need to continue iterating if we succeeded\n            if success:\n                break\n\n        # Notify user if we failed to reset a collision-free sampled pose\n        if not success:\n            logging.warning(\"WARNING: Failed to reset robot without collision\")\n\n        # Land the robot\n        land_object(env.robots[self._robot_idn], initial_pos, initial_quat, env.initial_pos_z_offset)\n\n    def _get_obs(self, env):\n        # No task-specific obs of any kind\n        return OrderedDict(), OrderedDict()\n\n    def _load_non_low_dim_observation_space(self):\n        # No non-low dim observations so we return an empty dict\n        return OrderedDict()\n\n    @classproperty\n    def valid_scene_types(cls):\n        # Must be an interactive traversable scene\n        return {InteractiveTraversableScene}\n\n    @classproperty\n    def default_termination_config(cls):\n        return {\n            \"max_collisions\": 500,\n            \"max_steps\": 500,\n            \"fall_height\": 0.03,\n        }\n\n    @classproperty\n    def default_reward_config(cls):\n        return {\n            \"r_prismatic\": 1.0,\n            \"r_revolute\": 1.0,\n            \"r_potential\": 1.0,\n        }\n</code></pre>","location":"reference/tasks/furniture_closing_task.html#tasks.furniture_closing_task.FurnitureClosingTask"},{"title":"<code>get_potential(env)</code>","text":"<p>Compute task-specific potential: furniture joint positions</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Environment instance</p>  required      Source code in <code>tasks/furniture_closing_task.py</code> <pre><code>def get_potential(self, env):\n    \"\"\"\n    Compute task-specific potential: furniture joint positions\n\n    Args:\n        env (Environment): Environment instance\n    \"\"\"\n    task_potential = 0.0\n    for obj in self._opened_objects:\n        for joint in obj.joints.values():\n            # Make sure we're only dealing with prismatic / revolute joints\n            assert joint.n_dof == 1, \"Can only get task potential of prismatic / revolute joints!\"\n            # Potential is scaled value of the joint's position\n            scale = self._r_prismatic if joint.joint_type == \"PrismaticJoint\" else self._r_revolute\n            task_potential += scale * joint.get_state(normalized=True)[0][0]\n\n    return task_potential\n</code></pre>","location":"reference/tasks/furniture_closing_task.html#tasks.furniture_closing_task.FurnitureClosingTask.get_potential"},{"title":"point_navigation_obstacle_task","text":"","location":"reference/tasks/point_navigation_obstacle_task.html"},{"title":"<code>PointNavigationDynamicObstacleTask</code>","text":"<p>         Bases: <code>PointNavigationObstacleTask</code></p> <p>Dynamic Navigation Random Task The goal is to navigate to a random goal position, in the presence of dynamic objects (moving turtlebots)</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>Which robot that this task corresponds to</p>  <code>0</code>    <code>floor</code>  <code>int</code>  <p>Which floor to navigate on</p>  <code>0</code>    <code>initial_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global initial position to place the robot at the start of each task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>initial_quat</code>  <code>None or 4-array</code>  <p>If specified, should be (x,y,z,w) global quaternion orientation to place the robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis</p>  <code>None</code>    <code>goal_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global goal position to reach for the given task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>goal_tolerance</code>  <code>float</code>  <p>Distance between goal position and current position below which is considered a task success</p>  <code>0.1</code>    <code>goal_in_polar</code>  <code>bool</code>  <p>Whether to represent the goal in polar coordinates or not when capturing task observations</p>  <code>False</code>    <code>path_range</code>  <code>None or 2-array</code>  <p>If specified, should be (min, max) values representing the range of valid total path lengths that are valid when sampling initial / goal positions</p>  <code>None</code>    <code>visualize_goal</code>  <code>bool</code>  <p>Whether to visualize the initial / goal locations</p>  <code>False</code>    <code>visualize_path</code>  <code>bool</code>  <p>Whether to visualize the path from initial to goal location, as represented by discrete waypoints</p>  <code>False</code>    <code>marker_height</code>  <code>float</code>  <p>If visualizing, specifies the height of the visual markers (m)</p>  <code>0.2</code>    <code>waypoint_width</code>  <code>float</code>  <p>If visualizing, specifies the width of the visual waypoints (m)</p>  <code>0.1</code>    <code>n_vis_waypoints</code>  <code>int</code>  <p>If visualizing, specifies the number of waypoints to generate</p>  <code>250</code>    <code>reward_type</code>  <code>str</code>  <p>Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}</p>  <code>'l2'</code>    <code>n_obstacles</code>  <code>int</code>  <p>Number of dynamic obstacles to generate</p>  <code>1</code>    <code>n_obstacle_action_repeat</code>  <code>int</code>  <p>How many timesteps a dynamic obstacle should repeat its action before switching</p>  <code>10</code>    <code>termination_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p>  <code>None</code>    <code>reward_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p>  <code>None</code>      Source code in <code>tasks/point_navigation_obstacle_task.py</code> <pre><code>class PointNavigationDynamicObstacleTask(PointNavigationObstacleTask):\n    \"\"\"\n    Dynamic Navigation Random Task\n    The goal is to navigate to a random goal position, in the presence of dynamic objects (moving turtlebots)\n\n    Args:\n        robot_idn (int): Which robot that this task corresponds to\n        floor (int): Which floor to navigate on\n        initial_pos (None or 3-array): If specified, should be (x,y,z) global initial position to place the robot\n            at the start of each task episode. If None, a collision-free value will be randomly sampled\n        initial_quat (None or 4-array): If specified, should be (x,y,z,w) global quaternion orientation to place the\n            robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis\n        goal_pos (None or 3-array): If specified, should be (x,y,z) global goal position to reach for the given task\n            episode. If None, a collision-free value will be randomly sampled\n        goal_tolerance (float): Distance between goal position and current position below which is considered a task\n            success\n        goal_in_polar (bool): Whether to represent the goal in polar coordinates or not when capturing task observations\n        path_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total path lengths that are valid when sampling initial / goal positions\n        visualize_goal (bool): Whether to visualize the initial / goal locations\n        visualize_path (bool): Whether to visualize the path from initial to goal location, as represented by\n            discrete waypoints\n        marker_height (float): If visualizing, specifies the height of the visual markers (m)\n        waypoint_width (float): If visualizing, specifies the width of the visual waypoints (m)\n        n_vis_waypoints (int): If visualizing, specifies the number of waypoints to generate\n        reward_type (str): Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}\n        n_obstacles (int): Number of dynamic obstacles to generate\n        n_obstacle_action_repeat (int): How many timesteps a dynamic obstacle should repeat its action before switching\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\n\n    def __init__(\n            self,\n            robot_idn=0,\n            floor=0,\n            initial_pos=None,\n            initial_quat=None,\n            goal_pos=None,\n            goal_tolerance=0.1,\n            goal_in_polar=False,\n            path_range=None,\n            visualize_goal=False,\n            visualize_path=False,\n            marker_height=0.2,\n            waypoint_width=0.1,\n            n_vis_waypoints=250,\n            reward_type=\"l2\",\n            n_obstacles=1,\n            n_obstacle_action_repeat=10,\n            reward_config=None,\n            termination_config=None,\n    ):\n        # Store inputs\n        self._n_obstacle_action_repeat = n_obstacle_action_repeat\n\n        # Initialize variables that will be filled in at runtime\n        self._current_obstacle_actions = None\n\n        # Run super init\n        super().__init__(\n            robot_idn=robot_idn,\n            floor=floor,\n            initial_pos=initial_pos,\n            initial_quat=initial_quat,\n            goal_pos=goal_pos,\n            goal_tolerance=goal_tolerance,\n            goal_in_polar=goal_in_polar,\n            path_range=path_range,\n            visualize_goal=visualize_goal,\n            visualize_path=visualize_path,\n            marker_height=marker_height,\n            waypoint_width=waypoint_width,\n            n_vis_waypoints=n_vis_waypoints,\n            reward_type=reward_type,\n            n_obstacles=n_obstacles,\n            reward_config=reward_config,\n            termination_config=termination_config,\n        )\n\n    def _load_obstacles(self, env):\n        # Load turtlebots\n        obstacles = []\n        for i in range(self._n_obstacles):\n            obstacle = Turtlebot(\n                prim_path=f\"/World/task_obstacle{i}\",\n                name=f\"task_obscale{i}\",\n            )\n            og.sim.import_object(obstacle)\n            obstacles.append(obstacle)\n\n        return obstacles\n\n    def step(self, env, action):\n        # Run super method first\n        reward, done, info = super().step(env=env, action=action)\n        # Apply actions for each dynamic obstacle\n        if env.episode_steps % self._n_obstacle_action_repeat == 0:\n            self._current_obstacle_actions = [robot.action_space.sample() for robot in self._obstacles]\n        for robot, action in zip(self._obstacles, self._current_obstacle_actions):\n            robot.apply_action(action)\n\n        return reward, done, info\n</code></pre>","location":"reference/tasks/point_navigation_obstacle_task.html#tasks.point_navigation_obstacle_task.PointNavigationDynamicObstacleTask"},{"title":"<code>PointNavigationObstacleTask</code>","text":"<p>         Bases: <code>PointNavigationTask</code></p> <p>Interactive Navigation Random Task The goal is to navigate to a random goal position, in the presence of interactive objects. This is an abstract class</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>Which robot that this task corresponds to</p>  <code>0</code>    <code>floor</code>  <code>int</code>  <p>Which floor to navigate on</p>  <code>0</code>    <code>initial_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global initial position to place the robot at the start of each task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>initial_quat</code>  <code>None or 4-array</code>  <p>If specified, should be (x,y,z,w) global quaternion orientation to place the robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis</p>  <code>None</code>    <code>goal_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global goal position to reach for the given task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>goal_tolerance</code>  <code>float</code>  <p>Distance between goal position and current position below which is considered a task success</p>  <code>0.1</code>    <code>goal_in_polar</code>  <code>bool</code>  <p>Whether to represent the goal in polar coordinates or not when capturing task observations</p>  <code>False</code>    <code>path_range</code>  <code>None or 2-array</code>  <p>If specified, should be (min, max) values representing the range of valid total path lengths that are valid when sampling initial / goal positions</p>  <code>None</code>    <code>visualize_goal</code>  <code>bool</code>  <p>Whether to visualize the initial / goal locations</p>  <code>False</code>    <code>visualize_path</code>  <code>bool</code>  <p>Whether to visualize the path from initial to goal location, as represented by discrete waypoints</p>  <code>False</code>    <code>marker_height</code>  <code>float</code>  <p>If visualizing, specifies the height of the visual markers (m)</p>  <code>0.2</code>    <code>waypoint_width</code>  <code>float</code>  <p>If visualizing, specifies the width of the visual waypoints (m)</p>  <code>0.1</code>    <code>n_vis_waypoints</code>  <code>int</code>  <p>If visualizing, specifies the number of waypoints to generate</p>  <code>250</code>    <code>reward_type</code>  <code>str</code>  <p>Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}</p>  <code>'l2'</code>    <code>n_obstacles</code>  <code>int</code>  <p>Number of obstacles to generate</p>  <code>5</code>    <code>termination_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p>  <code>None</code>    <code>reward_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p>  <code>None</code>      Source code in <code>tasks/point_navigation_obstacle_task.py</code> <pre><code>class PointNavigationObstacleTask(PointNavigationTask):\n    \"\"\"\n    Interactive Navigation Random Task\n    The goal is to navigate to a random goal position, in the presence of interactive objects. This is an abstract class\n\n    Args:\n        robot_idn (int): Which robot that this task corresponds to\n        floor (int): Which floor to navigate on\n        initial_pos (None or 3-array): If specified, should be (x,y,z) global initial position to place the robot\n            at the start of each task episode. If None, a collision-free value will be randomly sampled\n        initial_quat (None or 4-array): If specified, should be (x,y,z,w) global quaternion orientation to place the\n            robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis\n        goal_pos (None or 3-array): If specified, should be (x,y,z) global goal position to reach for the given task\n            episode. If None, a collision-free value will be randomly sampled\n        goal_tolerance (float): Distance between goal position and current position below which is considered a task\n            success\n        goal_in_polar (bool): Whether to represent the goal in polar coordinates or not when capturing task observations\n        path_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total path lengths that are valid when sampling initial / goal positions\n        visualize_goal (bool): Whether to visualize the initial / goal locations\n        visualize_path (bool): Whether to visualize the path from initial to goal location, as represented by\n            discrete waypoints\n        marker_height (float): If visualizing, specifies the height of the visual markers (m)\n        waypoint_width (float): If visualizing, specifies the width of the visual waypoints (m)\n        n_vis_waypoints (int): If visualizing, specifies the number of waypoints to generate\n        reward_type (str): Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}\n        n_obstacles (int): Number of obstacles to generate\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\n    def __init__(\n            self,\n            robot_idn=0,\n            floor=0,\n            initial_pos=None,\n            initial_quat=None,\n            goal_pos=None,\n            goal_tolerance=0.1,\n            goal_in_polar=False,\n            path_range=None,\n            visualize_goal=False,\n            visualize_path=False,\n            marker_height=0.2,\n            waypoint_width=0.1,\n            n_vis_waypoints=250,\n            reward_type=\"l2\",\n            n_obstacles=5,\n            reward_config=None,\n            termination_config=None,\n    ):\n        # Store inputs\n        self._n_obstacles = n_obstacles\n\n        # Initialize other variables that will be filled in at runtime\n        self._obstacles = None\n\n        # Run super init\n        super().__init__(\n            robot_idn=robot_idn,\n            floor=floor,\n            initial_pos=initial_pos,\n            initial_quat=initial_quat,\n            goal_pos=goal_pos,\n            goal_tolerance=goal_tolerance,\n            goal_in_polar=goal_in_polar,\n            path_range=path_range,\n            visualize_goal=visualize_goal,\n            visualize_path=visualize_path,\n            marker_height=marker_height,\n            waypoint_width=waypoint_width,\n            n_vis_waypoints=n_vis_waypoints,\n            reward_type=reward_type,\n            reward_config=reward_config,\n            termination_config=termination_config,\n        )\n\n    def _load(self, env):\n        # Load the interactive objects\n        self._obstacles = self._load_obstacles(env=env)\n\n    def _load_obstacles(self, env):\n        \"\"\"\n        Load obstacles. Must be implemented by subclass.\n\n        Args:\n            env (OmniGibsonEnv): Environment instance\n\n        Returns:\n            list of BaseObject: Obstacle(s) generated for this task\n        \"\"\"\n        raise NotImplementedError()\n\n    def _reset_obstacles(self, env):\n        \"\"\"\n        Reset the poses of obstacles to have no collisions with the scene or the robot\n\n        Args:\n            env (OmniGibsonEnv): Environment instance\n        \"\"\"\n        success, max_trials, pos, ori = False, 100, None, None\n\n        for obj in self._obstacles:\n            # Save the state of this environment so we can restore it immediately after\n            state = og.sim.dump_state(serialized=True)\n            for _ in range(max_trials):\n                _, pos = env.scene.get_random_point(floor=self._floor)\n                quat = T.euler2quat(np.array([0, 0, np.random.uniform(0, np.pi * 2)]))\n                success = test_valid_pose(obj, pos, quat, env.initial_pos_z_offset)\n                og.sim.load_state(state=state, serialized=True)\n                if success:\n                    break\n\n            if not success:\n                logging.warning(\"WARNING: Failed to reset interactive obj without collision\")\n\n            land_object(obj, pos, ori, env.initial_pos_z_offset)\n\n    def _reset_scene(self, env):\n        # Run super first\n        super()._reset_scene(env=env)\n\n        # Reset the obstacles\n        self._reset_obstacles(env=env)\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"PointNavigationObstacleTask\")\n        return classes\n</code></pre>","location":"reference/tasks/point_navigation_obstacle_task.html#tasks.point_navigation_obstacle_task.PointNavigationObstacleTask"},{"title":"point_navigation_task","text":"","location":"reference/tasks/point_navigation_task.html"},{"title":"<code>PointNavigationTask</code>","text":"<p>         Bases: <code>BaseTask</code></p> <p>Point Navigation Task The task is to navigate to a goal position</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>Which robot that this task corresponds to</p>  <code>0</code>    <code>floor</code>  <code>int</code>  <p>Which floor to navigate on</p>  <code>0</code>    <code>initial_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global initial position to place the robot at the start of each task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>initial_quat</code>  <code>None or 4-array</code>  <p>If specified, should be (x,y,z,w) global quaternion orientation to place the robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis</p>  <code>None</code>    <code>goal_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global goal position to reach for the given task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>goal_tolerance</code>  <code>float</code>  <p>Distance between goal position and current position below which is considered a task success</p>  <code>0.5</code>    <code>goal_in_polar</code>  <code>bool</code>  <p>Whether to represent the goal in polar coordinates or not when capturing task observations</p>  <code>False</code>    <code>path_range</code>  <code>None or 2-array</code>  <p>If specified, should be (min, max) values representing the range of valid total path lengths that are valid when sampling initial / goal positions</p>  <code>None</code>    <code>visualize_goal</code>  <code>bool</code>  <p>Whether to visualize the initial / goal locations</p>  <code>False</code>    <code>visualize_path</code>  <code>bool</code>  <p>Whether to visualize the path from initial to goal location, as represented by discrete waypoints</p>  <code>False</code>    <code>marker_height</code>  <code>float</code>  <p>If visualizing, specifies the height of the visual markers (m)</p>  <code>0.2</code>    <code>waypoint_width</code>  <code>float</code>  <p>If visualizing, specifies the width of the visual waypoints (m)</p>  <code>0.1</code>    <code>n_vis_waypoints</code>  <code>int</code>  <p>If visualizing, specifies the number of waypoints to generate</p>  <code>250</code>    <code>reward_type</code>  <code>str</code>  <p>Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}</p>  <code>'l2'</code>    <code>termination_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p>  <code>None</code>    <code>reward_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p>  <code>None</code>      Source code in <code>tasks/point_navigation_task.py</code> <pre><code>class PointNavigationTask(BaseTask):\n    \"\"\"\n    Point Navigation Task\n    The task is to navigate to a goal position\n\n    Args:\n        robot_idn (int): Which robot that this task corresponds to\n        floor (int): Which floor to navigate on\n        initial_pos (None or 3-array): If specified, should be (x,y,z) global initial position to place the robot\n            at the start of each task episode. If None, a collision-free value will be randomly sampled\n        initial_quat (None or 4-array): If specified, should be (x,y,z,w) global quaternion orientation to place the\n            robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis\n        goal_pos (None or 3-array): If specified, should be (x,y,z) global goal position to reach for the given task\n            episode. If None, a collision-free value will be randomly sampled\n        goal_tolerance (float): Distance between goal position and current position below which is considered a task\n            success\n        goal_in_polar (bool): Whether to represent the goal in polar coordinates or not when capturing task observations\n        path_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total path lengths that are valid when sampling initial / goal positions\n        visualize_goal (bool): Whether to visualize the initial / goal locations\n        visualize_path (bool): Whether to visualize the path from initial to goal location, as represented by\n            discrete waypoints\n        marker_height (float): If visualizing, specifies the height of the visual markers (m)\n        waypoint_width (float): If visualizing, specifies the width of the visual waypoints (m)\n        n_vis_waypoints (int): If visualizing, specifies the number of waypoints to generate\n        reward_type (str): Type of reward to use. Valid options are: {\"l2\", \"geodesic\"}\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\n\n    def __init__(\n            self,\n            robot_idn=0,\n            floor=0,\n            initial_pos=None,\n            initial_quat=None,\n            goal_pos=None,\n            goal_tolerance=0.5,\n            goal_in_polar=False,\n            path_range=None,\n            visualize_goal=False,\n            visualize_path=False,\n            marker_height=0.2,\n            waypoint_width=0.1,\n            n_vis_waypoints=250,\n            reward_type=\"l2\",\n            termination_config=None,\n            reward_config=None,\n    ):\n        # Store inputs\n        self._robot_idn = robot_idn\n        self._floor = floor\n        self._initial_pos = initial_pos if initial_pos is None else np.array(initial_pos)\n        self._initial_quat = initial_quat if initial_quat is None else np.array(initial_quat)\n        self._goal_pos = goal_pos if goal_pos is None else np.array(goal_pos)\n        self._goal_tolerance = goal_tolerance\n        self._goal_in_polar = goal_in_polar\n        self._path_range = path_range\n        self._randomize_initial_pos = initial_pos is None\n        self._randomize_initial_quat = initial_quat is None\n        self._randomize_goal_pos = goal_pos is None\n        self._visualize_goal = visualize_goal\n        self._visualize_path = visualize_path\n        self._marker_height = marker_height\n        self._waypoint_width = waypoint_width\n        self._n_vis_waypoints = n_vis_waypoints\n        assert_valid_key(key=reward_type, valid_keys=POINT_NAVIGATION_REWARD_TYPES, name=\"reward type\")\n        self._reward_type = reward_type\n\n        # Create other attributes that will be filled in at runtime\n        self._initial_pos_marker = None\n        self._goal_pos_marker = None\n        self._waypoint_markers = None\n        self._path_length = None\n        self._current_robot_pos = None\n        self._geodesic_dist = None\n\n        # Run super\n        super().__init__(termination_config=termination_config, reward_config=reward_config)\n\n    def _create_termination_conditions(self):\n        # Initialize termination conditions dict and fill in with MaxCollision, Timeout, Falling, and PointGoal\n        terminations = OrderedDict()\n        terminations[\"max_collision\"] = MaxCollision(max_collisions=self._termination_config[\"max_collisions\"])\n        terminations[\"timeout\"] = Timeout(max_steps=self._termination_config[\"max_steps\"])\n        terminations[\"falling\"] = Falling(robot_idn=self._robot_idn, fall_height=self._termination_config[\"fall_height\"])\n        terminations[\"pointgoal\"] = PointGoal(\n            robot_idn=self._robot_idn,\n            distance_tol=self._goal_tolerance,\n            distance_axes=\"xy\",\n        )\n\n        return terminations\n\n    def _create_reward_functions(self):\n        # Initialize reward functions dict and fill in with Potential, Collision, and PointGoal rewards\n        rewards = OrderedDict()\n\n        rewards[\"potential\"] = PotentialReward(\n            potential_fcn=self.get_potential,\n            r_potential=self._reward_config[\"r_potential\"],\n        )\n        rewards[\"collision\"] = CollisionReward(r_collision=self._reward_config[\"r_collision\"])\n        rewards[\"pointgoal\"] = PointGoalReward(\n            pointgoal=self._termination_conditions[\"pointgoal\"],\n            r_pointgoal=self._reward_config[\"r_pointgoal\"],\n        )\n\n        return rewards\n\n    def _load(self, env):\n        # Load visualization\n        self._load_visualization_markers(env=env)\n\n    def _load_visualization_markers(self, env):\n        \"\"\"\n        Load visualization, such as initial and target position, shortest path, etc\n\n        Args:\n            env (Environment): Active environment instance\n        \"\"\"\n        cyl_size = np.array([self._goal_tolerance, self._goal_tolerance, self._marker_height])\n        self._initial_pos_marker = PrimitiveObject(\n            prim_path=\"/World/task_initial_pos_marker\",\n            primitive_type=\"Cylinder\",\n            name=\"task_initial_pos_marker\",\n            scale=cyl_size,\n            visible=self._visualize_goal,\n            visual_only=True,\n            rgba=np.array([1, 0, 0, 0.3]),\n        )\n        self._goal_pos_marker = PrimitiveObject(\n            prim_path=\"/World/task_goal_pos_marker\",\n            primitive_type=\"Cylinder\",\n            name=\"task_goal_pos_marker\",\n            scale=cyl_size,\n            visible=self._visualize_goal,\n            visual_only=True,\n            rgba=np.array([0, 0, 1, 0.3]),\n        )\n\n        # Load the objects into the simulator\n        og.sim.import_object(self._initial_pos_marker)\n        og.sim.import_object(self._goal_pos_marker)\n\n        # Additionally generate waypoints along the path if we're building the map in the environment\n        if env.scene.trav_map.build_graph:\n            waypoints = []\n            waypoint_size = np.array([self._waypoint_width, self._waypoint_width, self._marker_height])\n            for i in range(self._n_vis_waypoints):\n                waypoint = PrimitiveObject(\n                    prim_path=f\"/World/task_waypoint_marker{i}\",\n                    primitive_type=\"Cylinder\",\n                    name=f\"task_waypoint_marker{i}\",\n                    scale=waypoint_size,\n                    visible=self._visualize_path,\n                    visual_only=True,\n                    rgba=np.array([0, 1, 0, 0.3]),\n                )\n                og.sim.import_object(waypoint)\n                waypoints.append(waypoint)\n\n            # Store waypoints\n            self._waypoint_markers = waypoints\n\n        # Take one sim step to initialize all the markers\n        og.sim.step()\n\n    def _sample_initial_pose_and_goal_pos(self, env, max_trials=100):\n        \"\"\"\n        Potentially sample the robot initial pos / ori and target pos, based on whether we're using randomized\n        initial and goal states. If not randomzied, then this value will return the corresponding values inputted\n        during this task initialization.\n\n        Args:\n            env (Environment): Environment instance\n            max_trials (int): Number of trials to attempt to sample valid poses and positions\n\n        Returns:\n            3-tuple:\n                - 3-array: (x,y,z) global sampled initial position\n                - 4-array: (x,y,z,w) global sampled initial orientation in quaternion form\n                - 3-array: (x,y,z) global sampled goal position\n        \"\"\"\n        # Possibly sample initial pos\n        if self._randomize_initial_pos:\n            _, initial_pos = env.scene.get_random_point(floor=self._floor)\n        else:\n            initial_pos = self._initial_pos\n\n        # Possibly sample initial ori\n        initial_quat = T.euler2quat(np.array([0, 0, np.random.uniform(0, np.pi * 2)])) if \\\n            self._randomize_initial_quat else self._initial_quat\n\n        # Possibly sample goal pos\n        if self._randomize_goal_pos:\n            dist, in_range_dist = 0.0, False\n            for _ in range(max_trials):\n                _, goal_pos = env.scene.get_random_point(floor=self._floor)\n                if env.scene.trav_map.build_graph:\n                    _, dist = env.scene.get_shortest_path(self._floor, initial_pos[:2], goal_pos[:2], entire_path=False)\n                else:\n                    dist = T.l2_distance(initial_pos, goal_pos)\n                # If a path range is specified, make sure distance is valid\n                if self._path_range is None or self._path_range[0] &lt; dist &lt; self._path_range[1]:\n                    in_range_dist = True\n                    break\n            # Notify if we weren't able to get a valid start / end point sampled in the requested range\n            if not in_range_dist:\n                logging.warning(\"Failed to sample initial and target positions within requested path range\")\n        else:\n            goal_pos = self._goal_pos\n\n        # Add additional logging info\n        logging.info(\"Sampled initial pose: {}, {}\".format(initial_pos, initial_quat))\n        logging.info(\"Sampled goal position: {}\".format(goal_pos))\n        return initial_pos, initial_quat, goal_pos\n\n    def _get_geodesic_potential(self, env):\n        \"\"\"\n        Get potential based on geodesic distance\n\n        Args:\n            env: environment instance\n\n        Returns:\n            float: geodesic distance to the target position\n        \"\"\"\n        _, geodesic_dist = self.get_shortest_path_to_goal(env=env)\n        return geodesic_dist\n\n    def _get_l2_potential(self, env):\n        \"\"\"\n        Get potential based on L2 distance\n\n        Args:\n            env: environment instance\n\n        Returns:\n            float: L2 distance to the target position\n        \"\"\"\n        return T.l2_distance(env.robots[self._robot_idn].get_position()[:2], self._goal_pos[:2])\n\n    def get_potential(self, env):\n        \"\"\"\n        Compute task-specific potential: distance to the goal\n\n        Args:\n            env (Environment): Environment instance\n\n        Returns:\n            float: Computed potential\n        \"\"\"\n        if self._reward_type == \"l2\":\n            reward = self._get_l2_potential(env)\n        elif self._reward_type == \"geodesic\":\n            reward = self._get_geodesic_potential(env)\n        else:\n            raise ValueError(f\"Invalid reward type! {self._reward_type}\")\n\n        return reward\n\n    def _reset_agent(self, env):\n        # Reset agent\n        env.robots[self._robot_idn].reset()\n\n        # We attempt to sample valid initial poses and goal positions\n        success, max_trials = False, 100\n\n        # Store the state of the environment now, so that we can restore it after each setting attempt\n        state = og.sim.dump_state(serialized=True)\n\n        initial_pos, initial_quat, goal_pos = None, None, None\n        for i in range(max_trials):\n            initial_pos, initial_quat, goal_pos = self._sample_initial_pose_and_goal_pos(env)\n            # Make sure the sampled robot start pose and goal position are both collision-free\n            success = test_valid_pose(\n                env.robots[self._robot_idn], initial_pos, initial_quat, env.initial_pos_z_offset\n            ) and test_valid_pose(env.robots[self._robot_idn], goal_pos, None, env.initial_pos_z_offset)\n\n            # Load the original state\n            og.sim.load_state(state=state, serialized=True)\n\n            # Don't need to continue iterating if we succeeded\n            if success:\n                break\n\n        # Notify user if we failed to reset a collision-free sampled pose\n        if not success:\n            logging.warning(\"WARNING: Failed to reset robot without collision\")\n\n        # Land the robot\n        land_object(env.robots[self._robot_idn], initial_pos, initial_quat, env.initial_pos_z_offset)\n\n        # Store the sampled values internally\n        self._initial_pos = initial_pos\n        self._initial_quat = initial_quat\n        self._goal_pos = goal_pos\n\n        # Update visuals if requested\n        if self._visualize_goal:\n            self._initial_pos_marker.set_position(self._initial_pos)\n            self._goal_pos_marker.set_position(self._goal_pos)\n\n    def _reset_variables(self, env):\n        # Run super first\n        super()._reset_variables(env=env)\n\n        # Reset internal variables\n        self._path_length = 0.0\n        self._current_robot_pos = self._initial_pos\n        self._geodesic_dist = self._get_geodesic_potential(env)\n\n    def _step_termination(self, env, action, info=None):\n        # Run super first\n        done, info = super()._step_termination(env=env, action=action, info=info)\n\n        # Add additional info\n        info[\"path_length\"] = self._path_length\n        info[\"spl\"] = float(info[\"success\"]) * min(1.0, self._geodesic_dist / self._path_length) if done else 0.0\n\n        return done, info\n\n    def _global_pos_to_robot_frame(self, env, pos):\n        \"\"\"\n        Convert a 3D point in global frame to agent's local frame\n\n        Args:\n            env (TraversableEnv): Environment instance\n            pos (3-array): global (x,y,z) position\n\n        Returns:\n            3-array: (x,y,z) position in self._robot_idn agent's local frame\n        \"\"\"\n        delta_pos_global = np.array(pos) - env.robots[self._robot_idn].get_position()\n        return T.quat2mat(env.robots[self._robot_idn].get_orientation()).T @ delta_pos_global\n\n    def _get_obs(self, env):\n        # Get relative position of goal with respect to the current agent position\n        xy_pos_to_goal = self._global_pos_to_robot_frame(env, self._goal_pos)[:2]\n        if self._goal_in_polar:\n            xy_pos_to_goal = np.array(T.cartesian_to_polar(*xy_pos_to_goal))\n\n        # linear velocity and angular velocity\n        quat = env.robots[self._robot_idn].get_orientation()\n        lin_vel = T.quat2mat(quat).T @ env.robots[self._robot_idn].get_linear_velocity()\n        ang_vel = T.quat2mat(quat).T @ env.robots[self._robot_idn].get_angular_velocity()\n\n        # Compose observation dict\n        low_dim_obs = OrderedDict(\n            xy_pos_to_goal=xy_pos_to_goal,\n            robot_lin_vel=lin_vel,\n            robot_ang_vel=ang_vel,\n        )\n\n        # We have no non-low-dim obs, so return empty dict for those\n        return low_dim_obs, OrderedDict()\n\n    def _load_non_low_dim_observation_space(self):\n        # No non-low dim observations so we return an empty dict\n        return OrderedDict()\n\n    def get_goal_pos(self):\n        \"\"\"\n        Returns:\n            3-array: (x,y,z) global current goal position\n        \"\"\"\n        return self._goal_pos\n\n    def get_current_pos(self, env):\n        \"\"\"\n        Returns:\n            3-array: (x,y,z) global current position representing the robot\n        \"\"\"\n        return env.robots[self._robot_idn].get_position()\n\n    def get_shortest_path_to_goal(self, env, start_xy_pos=None, entire_path=False):\n        \"\"\"\n        Get the shortest path and geodesic distance from @start_pos to the target position\n\n        Args:\n            env (TraversableEnv): Environment instance\n            start_xy_pos (None or 2-array): If specified, should be the global (x,y) start position from which\n                to calculate the shortest path to the goal position. If None (default), the robot's current xy position\n                will be used\n            entire_path (bool): Whether to return the entire shortest path\n\n        Returns:\n            2-tuple:\n                - list of 2-array: List of (x,y) waypoints representing the path # TODO: is this true?\n                - float: geodesic distance of the path to the goal position\n        \"\"\"\n        start_xy_pos = env.robots[self._robot_idn].get_position()[:2] if start_xy_pos is None else start_xy_pos\n        return env.scene.get_shortest_path(self._floor, start_xy_pos, self._goal_pos[:2], entire_path=entire_path)\n\n    def _step_visualization(self, env):\n        \"\"\"\n        Step visualization\n\n        Args:\n            env (Environment): Environment instance\n        \"\"\"\n        if env.scene.trav_map.build_graph and self._visualize_path:\n            shortest_path, _ = self.get_shortest_path_to_goal(env=env, entire_path=True)\n            floor_height = env.scene.get_floor_height(self._floor)\n            num_nodes = min(self._n_vis_waypoints, shortest_path.shape[0])\n            for i in range(num_nodes):\n                self._waypoint_markers[i].set_position(\n                    position=np.array([shortest_path[i][0], shortest_path[i][1], floor_height])\n                )\n            for i in range(num_nodes, self._n_vis_waypoints):\n                self._waypoint_markers[i].set_position(position=np.array([0.0, 0.0, 100.0]))\n\n    def step(self, env, action):\n        # Run super method first\n        reward, done, info = super().step(env=env, action=action)\n\n        # Step visualization\n        self._step_visualization(env=env)\n\n        # Update other internal variables\n        new_robot_pos = env.robots[self._robot_idn].get_position()\n        self._path_length += T.l2_distance(self._current_robot_pos[:2], new_robot_pos[:2])\n        self._current_robot_pos = new_robot_pos\n\n        return reward, done, info\n\n    @classproperty\n    def valid_scene_types(cls):\n        # Must be a traversable scene\n        return {TraversableScene}\n\n    @classproperty\n    def default_termination_config(cls):\n        return {\n            \"max_collisions\": 500,\n            \"max_steps\": 500,\n            \"fall_height\": 0.03,\n        }\n\n    @classproperty\n    def default_reward_config(cls):\n        return {\n            \"r_potential\": 1.0,\n            \"r_collision\": 0.1,\n            \"r_pointgoal\": 10.0,\n        }\n</code></pre>","location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask"},{"title":"<code>get_current_pos(env)</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: (x,y,z) global current position representing the robot</p>     Source code in <code>tasks/point_navigation_task.py</code> <pre><code>def get_current_pos(self, env):\n    \"\"\"\n    Returns:\n        3-array: (x,y,z) global current position representing the robot\n    \"\"\"\n    return env.robots[self._robot_idn].get_position()\n</code></pre>","location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_current_pos"},{"title":"<code>get_goal_pos()</code>","text":"<p>Returns:</p>    Type Description       <p>3-array: (x,y,z) global current goal position</p>     Source code in <code>tasks/point_navigation_task.py</code> <pre><code>def get_goal_pos(self):\n    \"\"\"\n    Returns:\n        3-array: (x,y,z) global current goal position\n    \"\"\"\n    return self._goal_pos\n</code></pre>","location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_goal_pos"},{"title":"<code>get_potential(env)</code>","text":"<p>Compute task-specific potential: distance to the goal</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Environment instance</p>  required     <p>Returns:</p>    Name Type Description     <code>float</code>   <p>Computed potential</p>     Source code in <code>tasks/point_navigation_task.py</code> <pre><code>def get_potential(self, env):\n    \"\"\"\n    Compute task-specific potential: distance to the goal\n\n    Args:\n        env (Environment): Environment instance\n\n    Returns:\n        float: Computed potential\n    \"\"\"\n    if self._reward_type == \"l2\":\n        reward = self._get_l2_potential(env)\n    elif self._reward_type == \"geodesic\":\n        reward = self._get_geodesic_potential(env)\n    else:\n        raise ValueError(f\"Invalid reward type! {self._reward_type}\")\n\n    return reward\n</code></pre>","location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_potential"},{"title":"<code>get_shortest_path_to_goal(env, start_xy_pos=None, entire_path=False)</code>","text":"<p>Get the shortest path and geodesic distance from @start_pos to the target position</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>TraversableEnv</code>  <p>Environment instance</p>  required    <code>start_xy_pos</code>  <code>None or 2-array</code>  <p>If specified, should be the global (x,y) start position from which to calculate the shortest path to the goal position. If None (default), the robot's current xy position will be used</p>  <code>None</code>    <code>entire_path</code>  <code>bool</code>  <p>Whether to return the entire shortest path</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - list of 2-array: List of (x,y) waypoints representing the path # TODO: is this true? - float: geodesic distance of the path to the goal position</p>     Source code in <code>tasks/point_navigation_task.py</code> <pre><code>def get_shortest_path_to_goal(self, env, start_xy_pos=None, entire_path=False):\n    \"\"\"\n    Get the shortest path and geodesic distance from @start_pos to the target position\n\n    Args:\n        env (TraversableEnv): Environment instance\n        start_xy_pos (None or 2-array): If specified, should be the global (x,y) start position from which\n            to calculate the shortest path to the goal position. If None (default), the robot's current xy position\n            will be used\n        entire_path (bool): Whether to return the entire shortest path\n\n    Returns:\n        2-tuple:\n            - list of 2-array: List of (x,y) waypoints representing the path # TODO: is this true?\n            - float: geodesic distance of the path to the goal position\n    \"\"\"\n    start_xy_pos = env.robots[self._robot_idn].get_position()[:2] if start_xy_pos is None else start_xy_pos\n    return env.scene.get_shortest_path(self._floor, start_xy_pos, self._goal_pos[:2], entire_path=entire_path)\n</code></pre>","location":"reference/tasks/point_navigation_task.html#tasks.point_navigation_task.PointNavigationTask.get_shortest_path_to_goal"},{"title":"point_reaching_task","text":"","location":"reference/tasks/point_reaching_task.html"},{"title":"<code>PointReachingTask</code>","text":"<p>         Bases: <code>PointNavigationTask</code></p> <p>Point Reaching Task The goal is to reach a random goal position with the robot's end effector</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>Which robot that this task corresponds to</p>  <code>0</code>    <code>floor</code>  <code>int</code>  <p>Which floor to navigate on</p>  <code>0</code>    <code>initial_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global initial position to place the robot at the start of each task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>initial_quat</code>  <code>None or 3-array</code>  <p>If specified, should be (r,p,y) global euler orientation to place the robot at the start of each task episode. If None, a value will be randomly sampled about the z-axis</p>  <code>None</code>    <code>goal_pos</code>  <code>None or 3-array</code>  <p>If specified, should be (x,y,z) global goal position to reach for the given task episode. If None, a collision-free value will be randomly sampled</p>  <code>None</code>    <code>goal_tolerance</code>  <code>float</code>  <p>Distance between goal position and current position below which is considered a task success</p>  <code>0.1</code>    <code>goal_in_polar</code>  <code>bool</code>  <p>Whether to represent the goal in polar coordinates or not when capturing task observations</p>  <code>False</code>    <code>path_range</code>  <code>None or 2-array</code>  <p>If specified, should be (min, max) values representing the range of valid total path lengths that are valid when sampling initial / goal positions</p>  <code>None</code>    <code>height_range</code>  <code>None or 2-array</code>  <p>If specified, should be (min, max) values representing the range of valid total heights that are valid when sampling goal positions</p>  <code>None</code>    <code>visualize_goal</code>  <code>bool</code>  <p>Whether to visualize the initial / goal locations</p>  <code>False</code>    <code>visualize_path</code>  <code>bool</code>  <p>Whether to visualize the path from initial to goal location, as represented by discrete waypoints</p>  <code>False</code>    <code>marker_height</code>  <code>float</code>  <p>If visualizing, specifies the height of the visual markers (m)</p>  <code>0.2</code>    <code>waypoint_width</code>  <code>float</code>  <p>If visualizing, specifies the width of the visual waypoints (m)</p>  <code>0.1</code>    <code>n_vis_waypoints</code>  <code>int</code>  <p>If visualizing, specifies the number of waypoints to generate</p>  <code>250</code>    <code>termination_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p>  <code>None</code>    <code>reward_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p>  <code>None</code>      Source code in <code>tasks/point_reaching_task.py</code> <pre><code>class PointReachingTask(PointNavigationTask):\n    \"\"\"\n    Point Reaching Task\n    The goal is to reach a random goal position with the robot's end effector\n\n    Args:\n        robot_idn (int): Which robot that this task corresponds to\n        floor (int): Which floor to navigate on\n        initial_pos (None or 3-array): If specified, should be (x,y,z) global initial position to place the robot\n            at the start of each task episode. If None, a collision-free value will be randomly sampled\n        initial_quat (None or 3-array): If specified, should be (r,p,y) global euler orientation to place the robot\n            at the start of each task episode. If None, a value will be randomly sampled about the z-axis\n        goal_pos (None or 3-array): If specified, should be (x,y,z) global goal position to reach for the given task\n            episode. If None, a collision-free value will be randomly sampled\n        goal_tolerance (float): Distance between goal position and current position below which is considered a task\n            success\n        goal_in_polar (bool): Whether to represent the goal in polar coordinates or not when capturing task observations\n        path_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total path lengths that are valid when sampling initial / goal positions\n        height_range (None or 2-array): If specified, should be (min, max) values representing the range of valid\n            total heights that are valid when sampling goal positions\n        visualize_goal (bool): Whether to visualize the initial / goal locations\n        visualize_path (bool): Whether to visualize the path from initial to goal location, as represented by\n            discrete waypoints\n        marker_height (float): If visualizing, specifies the height of the visual markers (m)\n        waypoint_width (float): If visualizing, specifies the width of the visual waypoints (m)\n        n_vis_waypoints (int): If visualizing, specifies the number of waypoints to generate\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\n\n    def __init__(\n            self,\n            robot_idn=0,\n            floor=0,\n            initial_pos=None,\n            initial_quat=None,\n            goal_pos=None,\n            goal_tolerance=0.1,\n            goal_in_polar=False,\n            path_range=None,\n            height_range=None,\n            visualize_goal=False,\n            visualize_path=False,\n            marker_height=0.2,\n            waypoint_width=0.1,\n            n_vis_waypoints=250,\n            reward_config=None,\n            termination_config=None,\n    ):\n        # Store inputs\n        self._height_range = height_range\n\n        # Run super\n        super().__init__(\n            robot_idn=robot_idn,\n            floor=floor,\n            initial_pos=initial_pos,\n            initial_quat=initial_quat,\n            goal_pos=goal_pos,\n            goal_tolerance=goal_tolerance,\n            goal_in_polar=goal_in_polar,\n            path_range=path_range,\n            visualize_goal=visualize_goal,\n            visualize_path=visualize_path,\n            marker_height=marker_height,\n            waypoint_width=waypoint_width,\n            n_vis_waypoints=n_vis_waypoints,\n            reward_type=\"l2\",           # Must use l2 for reaching task\n            reward_config=reward_config,\n            termination_config=termination_config,\n        )\n\n    def _create_termination_conditions(self):\n        # Run super first\n        terminations = super()._create_termination_conditions()\n\n        # We replace the pointgoal condition with a new one, specifying xyz instead of only xy as the axes to measure\n        # distance to the goal\n        terminations[\"pointgoal\"] = PointGoal(\n            robot_idn=self._robot_idn,\n            distance_tol=self._goal_tolerance,\n            distance_axes=\"xyz\",\n        )\n\n        return terminations\n\n    def _sample_initial_pose_and_goal_pos(self, env, max_trials=100):\n        # Run super first\n        initial_pos, initial_ori, goal_pos = super()._sample_initial_pose_and_goal_pos(env=env, max_trials=max_trials)\n\n        # Sample goal position to be within requested height range if specified\n        if self._height_range is not None:\n            goal_pos[2] += np.random.uniform(*self._height_range)\n\n        return initial_pos, initial_ori, goal_pos\n\n    def _get_l2_potential(self, env):\n        # Distance calculated from robot EEF, not base!\n        return T.l2_distance(env.robots[self._robot_idn].get_end_effector_position(), self._goal_pos)\n\n    def _get_obs(self, env):\n        # Get obs from super\n        low_dim_obs, obs = super()._get_obs(env=env)\n\n        # Remove xy-pos and replace with full xyz relative distance between current and goal pos\n        low_dim_obs.pop(\"xy_pos_to_goal\")\n        low_dim_obs[\"eef_to_goal\"] = self._global_pos_to_robot_frame(env=env, pos=self._goal_pos)\n\n        # Add local eef position as well\n        low_dim_obs[\"eef_local_pos\"] = self._global_pos_to_robot_frame(env=env, pos=env.robots[self._robot_idn].get_end_effector_position())\n\n        return low_dim_obs, obs\n\n    def get_current_pos(self, env):\n        # Current position is the robot's EEF, not base!\n        return env.robots[self._robot_idn].get_end_effector_position()\n</code></pre>","location":"reference/tasks/point_reaching_task.html#tasks.point_reaching_task.PointReachingTask"},{"title":"task_base","text":"","location":"reference/tasks/task_base.html"},{"title":"<code>BaseTask</code>","text":"<p>         Bases: <code>GymObservable</code>, <code>Registerable</code></p> <p>Base Task class. Task-specific reset_scene, reset_agent, step methods are implemented in subclasses</p> <p>Parameters:</p>    Name Type Description Default     <code>termination_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate termination conditions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_termination_config for default values used</p>  <code>None</code>    <code>reward_config</code>  <code>None or dict</code>  <p>Keyword-mapped configuration to use to generate reward functions. This should be specific to the task class. Default is None, which corresponds to a default config being usd. Note that any keyword required by a specific task class but not specified in the config will automatically be filled in with the default config. See cls.default_reward_config for default values used</p>  <code>None</code>      Source code in <code>tasks/task_base.py</code> <pre><code>class BaseTask(GymObservable, Registerable, metaclass=ABCMeta):\n    \"\"\"\n    Base Task class.\n    Task-specific reset_scene, reset_agent, step methods are implemented in subclasses\n\n    Args:\n        termination_config (None or dict): Keyword-mapped configuration to use to generate termination conditions. This\n            should be specific to the task class. Default is None, which corresponds to a default config being usd.\n            Note that any keyword required by a specific task class but not specified in the config will automatically\n            be filled in with the default config. See cls.default_termination_config for default values used\n        reward_config (None or dict): Keyword-mapped configuration to use to generate reward functions. This should be\n            specific to the task class. Default is None, which corresponds to a default config being usd. Note that\n            any keyword required by a specific task class but not specified in the config will automatically be filled\n            in with the default config. See cls.default_reward_config for default values used\n    \"\"\"\n    def __init__(self, termination_config=None, reward_config=None):\n        # Make sure configs are dictionaries\n        termination_config = dict() if termination_config is None else termination_config\n        reward_config = dict() if reward_config is None else reward_config\n\n        # Sanity check termination and reward conditions -- any keys found in the inputted config but NOT\n        # found in the default config should raise an error\n        unknown_termination_keys = set(termination_config.keys()) - set(self.default_termination_config.keys())\n        assert len(unknown_termination_keys) == 0, \\\n            f\"Got unknown termination config keys inputted: {unknown_termination_keys}\"\n        unknown_reward_keys = set(reward_config.keys()) - set(self.default_reward_config.keys())\n        assert len(unknown_reward_keys) == 0, f\"Got unknown reward config keys inputted: {unknown_reward_keys}\"\n\n        # Combine with defaults and store internally\n        self._termination_config = self.default_termination_config\n        self._termination_config.update(termination_config)\n        self._reward_config = self.default_reward_config\n        self._reward_config.update(reward_config)\n\n        # Generate reward and termination functions\n        self._termination_conditions = self._create_termination_conditions()\n        self._reward_functions = self._create_reward_functions()\n\n        # Store other internal vars that will be populated at runtime\n        self._loaded = False\n        self._reward = None\n        self._done = None\n        self._info = None\n        self._low_dim_obs_dim = None\n\n        # Run super init\n        super().__init__()\n\n    @abstractmethod\n    def _load(self, env):\n        \"\"\"\n        Load this task. Should be implemented by subclass. Can include functionality, e.g.: loading dynamic objects\n        into the environment\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def _load_non_low_dim_observation_space(self):\n        \"\"\"\n        Loads any non-low dim observation spaces for this task.\n\n        Returns:\n            OrderedDict: Keyword-mapped observation space for this object mapping non low dim task observation name to\n                observation space\n        \"\"\"\n        raise NotImplementedError()\n\n    def _load_observation_space(self):\n        # Create the non low dim obs space\n        obs_space = self._load_non_low_dim_observation_space()\n\n        # Create the low dim obs space and add to the main obs space dict -- make sure we're flattening low dim obs\n        obs_space[\"low_dim\"] = self._build_obs_box_space(shape=(self._low_dim_obs_dim,), low=-np.inf, high=np.inf, dtype=np.float64)\n\n        return obs_space\n\n    def load(self, env):\n        \"\"\"\n        Load this task\n        \"\"\"\n        # Make sure the scene is of the correct type!\n        assert any([issubclass(env.scene.__class__, valid_cls) for valid_cls in self.valid_scene_types]), \\\n            f\"Got incompatible scene type {env.scene.__class__.__name__} for task {self.__class__.__name__}! \" \\\n            f\"Scene class must be a subclass of at least one of: \" \\\n            f\"{[cls_type.__name__ for cls_type in self.valid_scene_types]}\"\n\n        # Run internal method\n        self._load(env=env)\n\n        # We're now initialized\n        self._loaded = True\n\n    @abstractmethod\n    def _create_termination_conditions(self):\n        \"\"\"\n        Creates the termination functions in the environment\n\n        Returns:\n            OrderedDict of BaseTerminationCondition: Termination functions created for this task\n        \"\"\"\n        raise NotImplementedError()\n\n    @abstractmethod\n    def _create_reward_functions(self):\n        \"\"\"\n        Creates the reward functions in the environment\n\n        Returns:\n            OrderedDict of BaseRewardFunction: Reward functions created for this task\n        \"\"\"\n        raise NotImplementedError()\n\n    def _reset_scene(self, env):\n        \"\"\"\n        Task-specific scene reset. Default is the normal scene reset\n\n        Args:\n            env (Environment): environment instance\n        \"\"\"\n        env.scene.reset()\n\n    def _reset_agent(self, env):\n        \"\"\"\n        Task-specific agent reset\n\n        Args:\n            env (Environment): environment instance\n        \"\"\"\n        # Default is no-op\n        pass\n\n    def _reset_variables(self, env):\n        \"\"\"\n        Task-specific internal variable reset\n\n        Args:\n            env (Environment): environment instance\n        \"\"\"\n        # By default, reset reward, done, and info\n        self._reward = None\n        self._done = None\n        self._info = None\n\n    def reset(self, env):\n        \"\"\"\n        Resets this task in the environment\n\n        Args:\n            env (Environment): environment instance to reset\n        \"\"\"\n        # Reset the scene, agent, and variables\n        self._reset_scene(env)\n        self._reset_agent(env)\n        self._reset_variables(env)\n\n        # Also reset all termination conditions and reward functions\n        for termination_condition in self._termination_conditions.values():\n            termination_condition.reset(self, env)\n        for reward_function in self._reward_functions.values():\n            reward_function.reset(self, env)\n\n        # Fill in low dim obs dim so we can use this to create the observation space later\n        self._low_dim_obs_dim = len(self.get_obs(env=env, flatten_low_dim=True)[\"low_dim\"])\n\n    def _step_termination(self, env, action, info=None):\n        \"\"\"\n        Step and aggregate termination conditions\n\n        Args:\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n            info (None or dict): Any info to return\n\n        Returns:\n            2-tuple:\n                - float: aggregated termination at the current timestep\n                - dict: any information passed through this function or generated by this function\n        \"\"\"\n        # Get all dones and successes from individual termination conditions\n        dones = []\n        successes = []\n        for termination_condition in self._termination_conditions.values():\n            d, s = termination_condition.step(self, env, action)\n            dones.append(d)\n            successes.append(s)\n        # Any True found corresponds to a done / success\n        done = sum(dones) &gt; 0\n        success = sum(successes) &gt; 0\n\n        # Populate info\n        info = dict() if info is None else info\n        info[\"success\"] = success\n        return done, info\n\n    def _step_reward(self, env, action, info=None):\n        \"\"\"\n        Step and aggregate reward functions\n\n        Args:\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n            info (None or dict): Any info to return\n\n        Returns:\n            2-tuple:\n                - float: aggregated reward at the current timestep\n                - dict: any information passed through this function or generated by this function\n        \"\"\"\n        # Make sure info is a dict\n        total_info = dict() if info is None else info\n        # We'll also store individual reward split as well\n        breakdown_dict = dict()\n        # Aggregate rewards over all reward functions\n        total_reward = 0.0\n        for reward_name, reward_function in self._reward_functions.items():\n            reward, reward_info = reward_function.step(self, env, action)\n            total_reward += reward\n            breakdown_dict[reward_name] = reward\n            total_info[reward_name] = reward_info\n\n        # Store breakdown dict\n        total_info[\"reward_breakdown\"] = breakdown_dict\n\n        return total_reward, total_info\n\n    @abstractmethod\n    def _get_obs(self, env):\n        \"\"\"\n        Get task-specific observation\n\n        Args:\n            env (Environment): Environment instance\n\n        Returns:\n            2-tuple:\n                - OrderedDict: Keyword-mapped low dimensional observations from this task\n                - OrderedDict: All other keyword-mapped observations from this task\n        \"\"\"\n        raise NotImplementedError()\n\n    def _flatten_low_dim_obs(self, obs):\n        \"\"\"\n        Flattens dictionary containing low-dimensional observations @obs and converts it from a dictionary into a\n        1D numpy array\n\n        Args:\n            obs (OrderedDict): Low-dim observation dictionary where each value is a 1D array\n\n        Returns:\n            n-array: 1D-numpy array of flattened low-dim observations\n        \"\"\"\n        # By default, we simply concatenate all values in our obs dict\n        return np.concatenate([ob for ob in obs.values()]) if len(obs.values()) &gt; 0 else np.array([])\n\n    def get_obs(self, env, flatten_low_dim=True):\n        # Args: env (Environment): environment instance\n        # Args: flatten_low_dim (bool): Whether to flatten low-dimensional observations\n\n        # Grab obs internally\n        low_dim_obs, obs = self._get_obs(env=env)\n\n        # Possibly flatten low dim and add to main observation dictionary\n        obs[\"low_dim\"] = self._flatten_low_dim_obs(obs=low_dim_obs) if flatten_low_dim else low_dim_obs\n\n        return obs\n\n    def step(self, env, action):\n        \"\"\"\n        Perform task-specific step for every timestep\n\n        Args:\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n        Returns:\n            3-tuple:\n                - float: reward calculated after this step\n                - bool: whether task is done or not\n                - dict: nested dictionary of reward- and done-related info\n        \"\"\"\n        # Make sure we're initialized\n        assert self._loaded, \"Task must be loaded using load() before calling step()!\"\n\n        # We calculate termination conditions first and then rewards\n        # (since some rewards can rely on termination conditions to update)\n        done, done_info = self._step_termination(env=env, action=action)\n        reward, reward_info = self._step_reward(env=env, action=action)\n\n        # Update the internal state of this task\n        self._reward = reward\n        self._done = done\n        self._info = {\n            \"reward\": reward_info,\n            \"done\": done_info,\n        }\n\n        return self._reward, self._done, deepcopy(self._info)\n\n    @property\n    def name(self):\n        \"\"\"\n        Returns:\n            str: Name of this task. Defaults to class name\n        \"\"\"\n        return self.__class__.__name__\n\n    @property\n    def reward(self):\n        \"\"\"\n        Returns:\n            float: Current reward for this task\n        \"\"\"\n        assert self._reward is not None, \"At least one step() must occur before reward can be calculated!\"\n        return self._reward\n\n    @property\n    def done(self):\n        \"\"\"\n        Returns:\n            bool: Whether this task is done or not\n        \"\"\"\n        assert self._done is not None, \"At least one step() must occur before done can be calculated!\"\n        return self._done\n\n    @property\n    def info(self):\n        \"\"\"\n        Returns:\n            dict: Nested dictionary of information for this task, including reward- and done-specific information\n        \"\"\"\n        assert self._info is not None, \"At least one step() must occur before info can be calculated!\"\n        return self._info\n\n    @classproperty\n    def valid_scene_types(cls):\n        \"\"\"\n        Returns:\n            set of Scene: Scene type(s) that are valid (i.e.: compatible) with this specific task. This will be\n                used to sanity check the task + scene combination at runtime\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def default_reward_config(cls):\n        \"\"\"\n        Returns:\n            dict: Default reward configuration for this class. Should include any kwargs necessary for\n                any of the reward classes generated in self._create_rewards(). Note: this default config\n                should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n                will raise an error!\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def default_termination_config(cls):\n        \"\"\"\n        Returns:\n            dict: Default termination configuration for this class. Should include any kwargs necessary for\n                any of the termination classes generated in self._create_terminations(). Note: this default config\n                should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n                will raise an error!\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseTask\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_TASKS\n        return REGISTERED_TASKS\n</code></pre>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask"},{"title":"<code>done</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this task is done or not</p>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.done"},{"title":"<code>info</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Nested dictionary of information for this task, including reward- and done-specific information</p>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.info"},{"title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this task. Defaults to class name</p>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.name"},{"title":"<code>reward</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>float</code>   <p>Current reward for this task</p>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.reward"},{"title":"<code>default_reward_config()</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Default reward configuration for this class. Should include any kwargs necessary for any of the reward classes generated in self._create_rewards(). Note: this default config should be fully verbose -- any keys inputted in the constructor but NOT found in this default config will raise an error!</p>     Source code in <code>tasks/task_base.py</code> <pre><code>@classproperty\ndef default_reward_config(cls):\n    \"\"\"\n    Returns:\n        dict: Default reward configuration for this class. Should include any kwargs necessary for\n            any of the reward classes generated in self._create_rewards(). Note: this default config\n            should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n            will raise an error!\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.default_reward_config"},{"title":"<code>default_termination_config()</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Default termination configuration for this class. Should include any kwargs necessary for any of the termination classes generated in self._create_terminations(). Note: this default config should be fully verbose -- any keys inputted in the constructor but NOT found in this default config will raise an error!</p>     Source code in <code>tasks/task_base.py</code> <pre><code>@classproperty\ndef default_termination_config(cls):\n    \"\"\"\n    Returns:\n        dict: Default termination configuration for this class. Should include any kwargs necessary for\n            any of the termination classes generated in self._create_terminations(). Note: this default config\n            should be fully verbose -- any keys inputted in the constructor but NOT found in this default config\n            will raise an error!\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.default_termination_config"},{"title":"<code>load(env)</code>","text":"<p>Load this task</p>  Source code in <code>tasks/task_base.py</code> <pre><code>def load(self, env):\n    \"\"\"\n    Load this task\n    \"\"\"\n    # Make sure the scene is of the correct type!\n    assert any([issubclass(env.scene.__class__, valid_cls) for valid_cls in self.valid_scene_types]), \\\n        f\"Got incompatible scene type {env.scene.__class__.__name__} for task {self.__class__.__name__}! \" \\\n        f\"Scene class must be a subclass of at least one of: \" \\\n        f\"{[cls_type.__name__ for cls_type in self.valid_scene_types]}\"\n\n    # Run internal method\n    self._load(env=env)\n\n    # We're now initialized\n    self._loaded = True\n</code></pre>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.load"},{"title":"<code>reset(env)</code>","text":"<p>Resets this task in the environment</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>environment instance to reset</p>  required      Source code in <code>tasks/task_base.py</code> <pre><code>def reset(self, env):\n    \"\"\"\n    Resets this task in the environment\n\n    Args:\n        env (Environment): environment instance to reset\n    \"\"\"\n    # Reset the scene, agent, and variables\n    self._reset_scene(env)\n    self._reset_agent(env)\n    self._reset_variables(env)\n\n    # Also reset all termination conditions and reward functions\n    for termination_condition in self._termination_conditions.values():\n        termination_condition.reset(self, env)\n    for reward_function in self._reward_functions.values():\n        reward_function.reset(self, env)\n\n    # Fill in low dim obs dim so we can use this to create the observation space later\n    self._low_dim_obs_dim = len(self.get_obs(env=env, flatten_low_dim=True)[\"low_dim\"])\n</code></pre>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.reset"},{"title":"<code>step(env, action)</code>","text":"<p>Perform task-specific step for every timestep</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>Environment</code>  <p>Environment instance</p>  required    <code>action</code>  <code>n-array</code>  <p>1D flattened array of actions executed by all agents in the environment</p>  required     <p>Returns:</p>    Type Description       <p>3-tuple: - float: reward calculated after this step - bool: whether task is done or not - dict: nested dictionary of reward- and done-related info</p>     Source code in <code>tasks/task_base.py</code> <pre><code>def step(self, env, action):\n    \"\"\"\n    Perform task-specific step for every timestep\n\n    Args:\n        env (Environment): Environment instance\n        action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n    Returns:\n        3-tuple:\n            - float: reward calculated after this step\n            - bool: whether task is done or not\n            - dict: nested dictionary of reward- and done-related info\n    \"\"\"\n    # Make sure we're initialized\n    assert self._loaded, \"Task must be loaded using load() before calling step()!\"\n\n    # We calculate termination conditions first and then rewards\n    # (since some rewards can rely on termination conditions to update)\n    done, done_info = self._step_termination(env=env, action=action)\n    reward, reward_info = self._step_reward(env=env, action=action)\n\n    # Update the internal state of this task\n    self._reward = reward\n    self._done = done\n    self._info = {\n        \"reward\": reward_info,\n        \"done\": done_info,\n    }\n\n    return self._reward, self._done, deepcopy(self._info)\n</code></pre>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.step"},{"title":"<code>valid_scene_types()</code>","text":"<p>Returns:</p>    Type Description       <p>set of Scene: Scene type(s) that are valid (i.e.: compatible) with this specific task. This will be used to sanity check the task + scene combination at runtime</p>     Source code in <code>tasks/task_base.py</code> <pre><code>@classproperty\ndef valid_scene_types(cls):\n    \"\"\"\n    Returns:\n        set of Scene: Scene type(s) that are valid (i.e.: compatible) with this specific task. This will be\n            used to sanity check the task + scene combination at runtime\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/tasks/task_base.html#tasks.task_base.BaseTask.valid_scene_types"},{"title":"termination_conditions","text":"","location":"reference/termination_conditions/index.html"},{"title":"falling","text":"","location":"reference/termination_conditions/falling.html"},{"title":"<code>Falling</code>","text":"<p>         Bases: <code>FailureCondition</code></p> <p>Falling (failure condition) used for any navigation-type tasks Episode terminates if the robot falls out of the world (i.e.: falls below the floor height by at least @fall_height</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>robot identifier to evaluate condition with. Default is 0, corresponding to the first robot added to the scene</p>  <code>0</code>    <code>fall_height</code>  <code>float</code>  <p>distance (m) &gt; 0 below the scene's floor height under which the the robot is considered to be falling out of the world</p>  <code>0.03</code>      Source code in <code>termination_conditions/falling.py</code> <pre><code>class Falling(FailureCondition):\n    \"\"\"\n    Falling (failure condition) used for any navigation-type tasks\n    Episode terminates if the robot falls out of the world (i.e.: falls below the floor height by at least\n    @fall_height\n\n    Args:\n        robot_idn (int): robot identifier to evaluate condition with. Default is 0, corresponding to the first\n            robot added to the scene\n        fall_height (float): distance (m) &gt; 0 below the scene's floor height under which the the robot is considered\n            to be falling out of the world\n    \"\"\"\n\n    def __init__(self, robot_idn=0, fall_height=0.03):\n        # Store internal vars\n        self._robot_idn = robot_idn\n        self._fall_height = fall_height\n\n        # Run super init\n        super().__init__()\n\n    def _step(self, task, env, action):\n        # Terminate if the specified robot is falling out of the scene\n        robot_z = env.scene.robots[self._robot_idn].get_position()[2]\n        return robot_z &lt; (env.scene.get_floor_height() - self._fall_height)\n</code></pre>","location":"reference/termination_conditions/falling.html#termination_conditions.falling.Falling"},{"title":"max_collision","text":"","location":"reference/termination_conditions/max_collision.html"},{"title":"<code>MaxCollision</code>","text":"<p>         Bases: <code>FailureCondition</code></p> <p>MaxCollision (failure condition) used for navigation tasks Episode terminates if the robot has collided more than max_collisions_allowed times Note that we ignore collisions with any floor objects.</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>robot identifier to evaluate collision checking with. Default is 0, corresponding to the first robot added to the scene</p>  <code>0</code>    <code>ignore_self_collisions</code>  <code>bool</code>  <p>Whether to ignore robot self-collisions or not</p>  <code>True</code>    <code>max_collisions</code>  <code>int</code>  <p>Maximum number of collisions allowed for any robots in the scene before a termination is triggered</p>  <code>500</code>      Source code in <code>termination_conditions/max_collision.py</code> <pre><code>class MaxCollision(FailureCondition):\n    \"\"\"\n    MaxCollision (failure condition) used for navigation tasks\n    Episode terminates if the robot has collided more than max_collisions_allowed times\n    Note that we ignore collisions with any floor objects.\n\n    Args:\n        robot_idn (int): robot identifier to evaluate collision checking with. Default is 0, corresponding to the first\n            robot added to the scene\n        ignore_self_collisions (bool): Whether to ignore robot self-collisions or not\n        max_collisions (int): Maximum number of collisions allowed for any robots in the scene before a termination\n            is triggered\n    \"\"\"\n\n    def __init__(self, robot_idn=0, ignore_self_collisions=True, max_collisions=500):\n        self._robot_idn = robot_idn\n        self._ignore_self_collisions = ignore_self_collisions\n        self._max_collisions = max_collisions\n        self._n_collisions = 0\n\n        # Run super init\n        super().__init__()\n\n    def reset(self, task, env):\n        # Call super first\n        super().reset(task, env)\n\n        # Also reset collision counter\n        self._n_collisions = 0\n\n    def _step(self, task, env, action):\n        # Terminate if the robot has collided more than self._max_collisions times\n        robot = env.robots[self._robot_idn]\n        floors = list(env.scene.object_registry(\"category\", \"floors\", []))\n        ignore_objs = floors if self._ignore_self_collisions is None else floors + [robot]\n        in_contact = len(env.robots[self._robot_idn].states[ContactBodies].get_value(ignore_objs=tuple(ignore_objs))) &gt; 0\n        self._n_collisions += int(in_contact)\n        return self._n_collisions &gt; self._max_collisions\n</code></pre>","location":"reference/termination_conditions/max_collision.html#termination_conditions.max_collision.MaxCollision"},{"title":"point_goal","text":"","location":"reference/termination_conditions/point_goal.html"},{"title":"<code>PointGoal</code>","text":"<p>         Bases: <code>SuccessCondition</code></p> <p>PointGoal (success condition) used for PointNavFixed/RandomTask Episode terminates if point goal is reached within @distance_tol by the @robot_idn robot's base</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>robot identifier to evaluate point goal with. Default is 0, corresponding to the first robot added to the scene</p>  <code>0</code>    <code>distance_tol</code>  <code>float</code>  <p>Distance (m) tolerance between goal position and @robot_idn's robot base position that is accepted as a success</p>  <code>0.5</code>    <code>distance_axes</code>  <code>str</code>  <p>Which axes to calculate distances when calculating the goal. Any combination of \"x\", \"y\", and \"z\" is valid (e.g.: \"xy\" or \"xyz\" or \"y\")</p>  <code>'xyz'</code>      Source code in <code>termination_conditions/point_goal.py</code> <pre><code>class PointGoal(SuccessCondition):\n    \"\"\"\n    PointGoal (success condition) used for PointNavFixed/RandomTask\n    Episode terminates if point goal is reached within @distance_tol by the @robot_idn robot's base\n\n    Args:\n        robot_idn (int): robot identifier to evaluate point goal with. Default is 0, corresponding to the first\n            robot added to the scene\n        distance_tol (float): Distance (m) tolerance between goal position and @robot_idn's robot base position\n            that is accepted as a success\n        distance_axes (str): Which axes to calculate distances when calculating the goal. Any combination of \"x\",\n            \"y\", and \"z\" is valid (e.g.: \"xy\" or \"xyz\" or \"y\")\n    \"\"\"\n\n    def __init__(self, robot_idn=0, distance_tol=0.5, distance_axes=\"xyz\"):\n        self._robot_idn = robot_idn\n        self._distance_tol = distance_tol\n        self._distance_axes = [i for i, axis in enumerate(\"xyz\") if axis in distance_axes]\n\n        # Run super init\n        super().__init__()\n\n    def _step(self, task, env, action):\n        # Make sure task is of type PointNavigation -- we import at runtime to avoid circular imports\n        from omnigibson.tasks.point_navigation_task import PointNavigationTask\n        assert isinstance(task, PointNavigationTask), \\\n            f\"Cannot use {self.__class__.__name__} with a non-PointNavigationTask task instance!\"\n        # Terminate if point goal is reached (distance below threshold)\n        return T.l2_distance(task.get_current_pos(env)[self._distance_axes], task.get_goal_pos()[self._distance_axes]) \\\n            &lt; self._distance_tol\n</code></pre>","location":"reference/termination_conditions/point_goal.html#termination_conditions.point_goal.PointGoal"},{"title":"predicate_goal","text":"","location":"reference/termination_conditions/predicate_goal.html"},{"title":"<code>PredicateGoal</code>","text":"<p>         Bases: <code>SuccessCondition</code></p> <p>PredicateGoal (success condition) used for BehaviorTask Episode terminates if all the predicates are satisfied</p> <p>Parameters:</p>    Name Type Description Default     <code>goal_fcn</code>  <code>method</code>  <p>function for calculating goal(s). Function signature should be:</p> <p>goals = goal_fcn()</p> <p>where @goals is a list of bddl.condition_evaluation.HEAD -- compiled BDDL goal conditions</p>  required      Source code in <code>termination_conditions/predicate_goal.py</code> <pre><code>class PredicateGoal(SuccessCondition):\n    \"\"\"\n    PredicateGoal (success condition) used for BehaviorTask\n    Episode terminates if all the predicates are satisfied\n\n    Args:\n        goal_fcn (method): function for calculating goal(s). Function signature should be:\n\n            goals = goal_fcn()\n\n            where @goals is a list of bddl.condition_evaluation.HEAD -- compiled BDDL goal conditions\n    \"\"\"\n    def __init__(self, goal_fcn):\n        # Store internal vars\n        self._goal_fcn = goal_fcn\n        self._goal_status = None\n\n        # Run super\n        super().__init__()\n\n    def reset(self, task, env):\n        # Run super first\n        super().reset(task, env)\n\n        # Reset status\n        self._goal_status = {\"satisfied\": [], \"unsatisfied\": []}\n\n    def _step(self, task, env, action):\n        # Terminate if all goal conditions are met in the task\n        done, self._goal_status = evaluate_goal_conditions(self._goal_fcn())\n        return done\n\n    @property\n    def goal_status(self):\n        \"\"\"\n        Returns:\n            dict: Current goal status for the active predicate(s), mapping \"satisfied\" and \"unsatisfied\" to a list\n                of the predicates matching either of those conditions\n        \"\"\"\n        return self._goal_status\n</code></pre>","location":"reference/termination_conditions/predicate_goal.html#termination_conditions.predicate_goal.PredicateGoal"},{"title":"<code>goal_status</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Current goal status for the active predicate(s), mapping \"satisfied\" and \"unsatisfied\" to a list of the predicates matching either of those conditions</p>","location":"reference/termination_conditions/predicate_goal.html#termination_conditions.predicate_goal.PredicateGoal.goal_status"},{"title":"reaching_goal","text":"","location":"reference/termination_conditions/reaching_goal.html"},{"title":"<code>ReachingGoal</code>","text":"<p>         Bases: <code>SuccessCondition</code></p> <p>ReachingGoal (success condition) used for reaching-type tasks Episode terminates if reaching goal is reached within @distance_tol by the @robot_idn robot's base</p> <p>Parameters:</p>    Name Type Description Default     <code>robot_idn</code>  <code>int</code>  <p>robot identifier to evaluate point goal with. Default is 0, corresponding to the first robot added to the scene</p>  <code>0</code>    <code>distance_tol</code>  <code>float</code>  <p>Distance (m) tolerance between goal position and @robot_idn's robot eef position that is accepted as a success</p>  <code>0.5</code>      Source code in <code>termination_conditions/reaching_goal.py</code> <pre><code>class ReachingGoal(SuccessCondition):\n    \"\"\"\n    ReachingGoal (success condition) used for reaching-type tasks\n    Episode terminates if reaching goal is reached within @distance_tol by the @robot_idn robot's base\n\n    Args:\n\n    Args:\n        robot_idn (int): robot identifier to evaluate point goal with. Default is 0, corresponding to the first\n            robot added to the scene\n        distance_tol (float): Distance (m) tolerance between goal position and @robot_idn's robot eef position\n            that is accepted as a success\n    \"\"\"\n\n    def __init__(self, robot_idn=0, distance_tol=0.5):\n        self._robot_idn = robot_idn\n        self._distance_tol = distance_tol\n\n        # Run super init\n        super().__init__()\n\n    def _step(self, task, env, action):\n        # Terminate if point goal is reached (distance below threshold)\n        return T.l2_distance(env.scene.robots[self._robot_idn].get_end_effector_position(), task.goal_pos) &lt; \\\n               self._distance_tol\n</code></pre>","location":"reference/termination_conditions/reaching_goal.html#termination_conditions.reaching_goal.ReachingGoal"},{"title":"termination_condition_base","text":"","location":"reference/termination_conditions/termination_condition_base.html"},{"title":"<code>BaseTerminationCondition</code>","text":"<p>         Bases: <code>Registerable</code></p> <p>Base TerminationCondition class Condition-specific _step() method is implemented in subclasses</p>  Source code in <code>termination_conditions/termination_condition_base.py</code> <pre><code>class BaseTerminationCondition(Registerable, metaclass=ABCMeta):\n    \"\"\"\n    Base TerminationCondition class\n    Condition-specific _step() method is implemented in subclasses\n    \"\"\"\n    def __init__(self):\n        # Initialize internal vars that will be filled in at runtime\n        self._done = None\n\n    @abstractmethod\n    def _step(self, task, env, action):\n        \"\"\"\n        Step the termination condition and return whether the episode should terminate. Overwritten by subclasses.\n\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n        Returns:\n            bool: whether environment should terminate or not\n        \"\"\"\n        raise NotImplementedError()\n\n    def step(self, task, env, action):\n        \"\"\"\n        Step the termination condition and return whether the episode should terminate.\n\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n            action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n        Returns:\n            2-tuple:\n                - bool: whether environment should terminate or not\n                - bool: whether a success was reached under this termination condition\n        \"\"\"\n        # Step internally and store the done state internally as well\n        self._done = self._step(task=task, env=env, action=action)\n\n        # We are successful if done is True AND this is a success condition\n        success = self._done and self._terminate_is_success\n\n        return self._done, success\n\n    def reset(self, task, env):\n        \"\"\"\n        Termination condition-specific reset\n\n        Args:\n            task (BaseTask): Task instance\n            env (Environment): Environment instance\n        \"\"\"\n        # Reset internal vars\n        self._done = None\n\n    @property\n    def done(self):\n        \"\"\"\n        Returns:\n            bool: Whether this termination condition has triggered or not\n        \"\"\"\n        assert self._done is not None, \"At least one step() must occur before done can be calculated!\"\n        return self._done\n\n    @property\n    def success(self):\n        \"\"\"\n        Returns:\n            bool: Whether this termination condition has been evaluated as a success or not\n        \"\"\"\n        assert self._done is not None, \"At least one step() must occur before success can be calculated!\"\n        return self._done and self._terminate_is_success\n\n    @classproperty\n    def _terminate_is_success(cls):\n        \"\"\"\n        Returns:\n            bool: Whether this termination condition corresponds to a success\n        \"\"\"\n        raise NotImplementedError()\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"BaseTerminationCondition\")\n        return classes\n\n    @classproperty\n    def _cls_registry(cls):\n        # Global registry\n        global REGISTERED_TERMINATION_CONDITIONS\n        return REGISTERED_TERMINATION_CONDITIONS\n</code></pre>","location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition"},{"title":"<code>done</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this termination condition has triggered or not</p>","location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.done"},{"title":"<code>success</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether this termination condition has been evaluated as a success or not</p>","location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.success"},{"title":"<code>reset(task, env)</code>","text":"<p>Termination condition-specific reset</p> <p>Parameters:</p>    Name Type Description Default     <code>task</code>  <code>BaseTask</code>  <p>Task instance</p>  required    <code>env</code>  <code>Environment</code>  <p>Environment instance</p>  required      Source code in <code>termination_conditions/termination_condition_base.py</code> <pre><code>def reset(self, task, env):\n    \"\"\"\n    Termination condition-specific reset\n\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n    \"\"\"\n    # Reset internal vars\n    self._done = None\n</code></pre>","location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.reset"},{"title":"<code>step(task, env, action)</code>","text":"<p>Step the termination condition and return whether the episode should terminate.</p> <p>Parameters:</p>    Name Type Description Default     <code>task</code>  <code>BaseTask</code>  <p>Task instance</p>  required    <code>env</code>  <code>Environment</code>  <p>Environment instance</p>  required    <code>action</code>  <code>n-array</code>  <p>1D flattened array of actions executed by all agents in the environment</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - bool: whether environment should terminate or not - bool: whether a success was reached under this termination condition</p>     Source code in <code>termination_conditions/termination_condition_base.py</code> <pre><code>def step(self, task, env, action):\n    \"\"\"\n    Step the termination condition and return whether the episode should terminate.\n\n    Args:\n        task (BaseTask): Task instance\n        env (Environment): Environment instance\n        action (n-array): 1D flattened array of actions executed by all agents in the environment\n\n    Returns:\n        2-tuple:\n            - bool: whether environment should terminate or not\n            - bool: whether a success was reached under this termination condition\n    \"\"\"\n    # Step internally and store the done state internally as well\n    self._done = self._step(task=task, env=env, action=action)\n\n    # We are successful if done is True AND this is a success condition\n    success = self._done and self._terminate_is_success\n\n    return self._done, success\n</code></pre>","location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.BaseTerminationCondition.step"},{"title":"<code>FailureCondition</code>","text":"<p>         Bases: <code>BaseTerminationCondition</code></p> <p>Termination condition corresponding to a failure</p>  Source code in <code>termination_conditions/termination_condition_base.py</code> <pre><code>class FailureCondition(BaseTerminationCondition):\n    \"\"\"\n    Termination condition corresponding to a failure\n    \"\"\"\n    def __init_subclass__(cls, **kwargs):\n        # Register as part of locomotion controllers\n        super().__init_subclass__(**kwargs)\n        register_failure_condition(cls)\n\n    @classproperty\n    def _terminate_is_success(cls):\n        # Done --&gt; not success\n        return False\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"FailureCondition\")\n        return classes\n</code></pre>","location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.FailureCondition"},{"title":"<code>SuccessCondition</code>","text":"<p>         Bases: <code>BaseTerminationCondition</code></p> <p>Termination condition corresponding to a success</p>  Source code in <code>termination_conditions/termination_condition_base.py</code> <pre><code>class SuccessCondition(BaseTerminationCondition):\n    \"\"\"\n    Termination condition corresponding to a success\n    \"\"\"\n    def __init_subclass__(cls, **kwargs):\n        # Register as part of locomotion controllers\n        super().__init_subclass__(**kwargs)\n        register_success_condition(cls)\n\n    @classproperty\n    def _terminate_is_success(cls):\n        # Done --&gt; success\n        return True\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        # Don't register this class since it's an abstract template\n        classes = super()._do_not_register_classes\n        classes.add(\"SuccessCondition\")\n        return classes\n</code></pre>","location":"reference/termination_conditions/termination_condition_base.html#termination_conditions.termination_condition_base.SuccessCondition"},{"title":"timeout","text":"","location":"reference/termination_conditions/timeout.html"},{"title":"<code>Timeout</code>","text":"<p>         Bases: <code>FailureCondition</code></p> <p>Timeout (failure condition) Episode terminates if max_step steps have passed</p> <p>Parameters:</p>    Name Type Description Default     <code>max_steps</code>  <code>int</code>  <p>Maximum number of episode steps before timeout occurs</p>  <code>500</code>      Source code in <code>termination_conditions/timeout.py</code> <pre><code>class Timeout(FailureCondition):\n    \"\"\"\n    Timeout (failure condition)\n    Episode terminates if max_step steps have passed\n\n    Args:\n        max_steps (int): Maximum number of episode steps before timeout occurs\n    \"\"\"\n\n    def __init__(self, max_steps=500):\n        # Store internal vars\n        self._max_steps = max_steps\n\n        # Run super\n        super().__init__()\n\n    def _step(self, task, env, action):\n        # Terminate if number of steps passed exceeds threshold\n        return env.episode_steps &gt;= self._max_steps\n</code></pre>","location":"reference/termination_conditions/timeout.html#termination_conditions.timeout.Timeout"},{"title":"utils","text":"","location":"reference/utils/index.html"},{"title":"asset_utils","text":"","location":"reference/utils/asset_utils.html"},{"title":"<code>change_data_path()</code>","text":"<p>Changes the data paths for this repo</p>  Source code in <code>utils/asset_utils.py</code> <pre><code>def change_data_path():\n    \"\"\"\n    Changes the data paths for this repo\n    \"\"\"\n    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"..\", \"global_config.yaml\")) as f:\n        global_config = yaml.load(f, Loader=yaml.FullLoader)\n    print(\"Current dataset path:\")\n    for k, v in global_config.items():\n        print(\"{}: {}\".format(k, v))\n    for k, v in global_config.items():\n        new_path = input(\"Change {} from {} to: \".format(k, v))\n        global_config[k] = new_path\n\n    print(\"New dataset path:\")\n    for k, v in global_config.items():\n        print(\"{}: {}\".format(k, v))\n    response = input(\"Save? [y/n]\")\n    if response == \"y\":\n        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), \"..\", \"global_config.yaml\"), \"w\") as f:\n            yaml.dump(global_config, f)\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.change_data_path"},{"title":"<code>download_assets()</code>","text":"<p>Download OmniGibson assets</p>  Source code in <code>utils/asset_utils.py</code> <pre><code>def download_assets():\n    \"\"\"\n    Download OmniGibson assets\n    \"\"\"\n    if os.path.exists(og.assets_path):\n        print(\"Assets already downloaded.\")\n    else:\n        tmp_file = os.path.join(tempfile.gettempdir(), \"og_assets.tar.gz\")\n        os.makedirs(og.assets_path, exist_ok=True)\n        path = \"https://storage.googleapis.com/gibson_scenes/og_assets.tar.gz\"\n        logging.info(f\"Downloading and decompressing demo OmniGibson assets from {path}\")\n        assert subprocess.call([\"wget\", \"-c\", \"--no-check-certificate\", \"--retry-connrefused\", \"--tries=5\", \"--timeout=5\", path, \"-O\", tmp_file]) == 0, \"Assets download failed.\"\n        assert subprocess.call([\"tar\", \"-zxf\", tmp_file, \"--strip-components=1\", \"--directory\", og.assets_path]) == 0, \"Assets extraction failed.\"\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.download_assets"},{"title":"<code>download_demo_data()</code>","text":"<p>Download OmniGibson demo dataset</p>  Source code in <code>utils/asset_utils.py</code> <pre><code>def download_demo_data():\n    \"\"\"\n    Download OmniGibson demo dataset\n    \"\"\"\n    # TODO: Update. Right now, OG just downloads beta release\n    download_og_dataset()\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.download_demo_data"},{"title":"<code>download_og_dataset()</code>","text":"<p>Download OmniGibson dataset</p>  Source code in <code>utils/asset_utils.py</code> <pre><code>def download_og_dataset():\n    \"\"\"\n    Download OmniGibson dataset\n    \"\"\"\n    # Print user agreement\n    if os.path.exists(og.key_path):\n        print(\"OmniGibson dataset encryption key already installed.\")\n    else:\n        print(\"\\n\")\n        print_user_agreement()\n        while (\n            input(\n                \"Do you agree to the above terms for using OmniGibson dataset? [y/n]\"\n            )\n            != \"y\"\n        ):\n            print(\"You need to agree to the terms for using OmniGibson dataset.\")\n\n        download_key()\n\n    if os.path.exists(og.og_dataset_path):\n        print(\"OmniGibson dataset already installed.\")\n    else:\n        tmp_file = os.path.join(tempfile.gettempdir(), \"og_dataset.tar.gz\")\n        os.makedirs(og.og_dataset_path, exist_ok=True)\n        path = \"https://storage.googleapis.com/gibson_scenes/og_dataset.tar.gz\"\n        logging.info(f\"Downloading and decompressing demo OmniGibson dataset from {path}\")\n        assert subprocess.call([\"wget\", \"-c\", \"--no-check-certificate\", \"--retry-connrefused\", \"--tries=5\", \"--timeout=5\", path, \"-O\", tmp_file]) == 0, \"Dataset download failed.\"\n        assert subprocess.call([\"tar\", \"-zxf\", tmp_file, \"--strip-components=1\", \"--directory\", og.og_dataset_path]) == 0, \"Dataset extraction failed.\"\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.download_og_dataset"},{"title":"<code>folder_is_hidden(p)</code>","text":"<p>Removes hidden folders from a list. Works on Linux, Mac and Windows</p> <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>true if a folder is hidden in the OS</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def folder_is_hidden(p):\n    \"\"\"\n    Removes hidden folders from a list. Works on Linux, Mac and Windows\n\n    Returns:\n        bool: true if a folder is hidden in the OS\n    \"\"\"\n    if os.name == \"nt\":\n        attribute = win32api.GetFileAttributes(p)\n        return attribute &amp; (win32con.FILE_ATTRIBUTE_HIDDEN | win32con.FILE_ATTRIBUTE_SYSTEM)\n    else:\n        return p.startswith(\".\")  # linux-osx\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.folder_is_hidden"},{"title":"<code>get_all_object_categories()</code>","text":"<p>Get OmniGibson all object categories</p> <p>Returns:</p>    Name Type Description     <code>list</code>   <p>all object categories</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_all_object_categories():\n    \"\"\"\n    Get OmniGibson all object categories\n\n    Returns:\n        list: all object categories\n    \"\"\"\n    og_dataset_path = og.og_dataset_path\n    og_categories_path = os.path.join(og_dataset_path, \"objects\")\n\n    categories = sorted([f for f in os.listdir(og_categories_path) if not folder_is_hidden(f)])\n    return categories\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_all_object_categories"},{"title":"<code>get_all_object_models()</code>","text":"<p>Get OmniGibson all object models</p> <p>Returns:</p>    Name Type Description     <code>list</code>   <p>all object model paths</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_all_object_models():\n    \"\"\"\n    Get OmniGibson all object models\n\n    Returns:\n        list: all object model paths\n    \"\"\"\n    og_dataset_path = og.og_dataset_path\n    og_categories_path = os.path.join(og_dataset_path, \"objects\")\n\n    categories = os.listdir(og_categories_path)\n    categories = [item for item in categories if os.path.isdir(os.path.join(og_categories_path, item))]\n    models = []\n    for category in categories:\n        category_models = os.listdir(os.path.join(og_categories_path, category))\n        category_models = [\n            item for item in category_models if os.path.isdir(os.path.join(og_categories_path, category, item))\n        ]\n        models.extend([os.path.join(og_categories_path, category, item) for item in category_models])\n    return models\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_all_object_models"},{"title":"<code>get_assisted_grasping_categories()</code>","text":"<p>Generate a list of categories that can be grasped using assisted grasping, using labels provided in average category specs file.</p> <p>Returns:</p>    Type Description       <p>list of str: Object category allowlist for assisted grasping</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_assisted_grasping_categories():\n    \"\"\"\n    Generate a list of categories that can be grasped using assisted grasping,\n    using labels provided in average category specs file.\n\n    Returns:\n        list of str: Object category allowlist for assisted grasping\n    \"\"\"\n    assisted_grasp_category_allow_list = set()\n    avg_category_spec = get_og_avg_category_specs()\n    for k, v in avg_category_spec.items():\n        if v[\"enable_ag\"]:\n            assisted_grasp_category_allow_list.add(k)\n    return assisted_grasp_category_allow_list\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_assisted_grasping_categories"},{"title":"<code>get_available_g_scenes()</code>","text":"<p>Returns:</p>    Name Type Description     <code>list</code>   <p>available Gibson scenes</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_available_g_scenes():\n    \"\"\"\n    Returns:\n        list: available Gibson scenes\n    \"\"\"\n    data_path = og.g_dataset_path\n    available_g_scenes = sorted([f for f in os.listdir(data_path) if not folder_is_hidden(f)])\n    return available_g_scenes\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_available_g_scenes"},{"title":"<code>get_available_og_scenes()</code>","text":"<p>OmniGibson interactive scenes</p> <p>Returns:</p>    Name Type Description     <code>list</code>   <p>Available OmniGibson interactive scenes</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_available_og_scenes():\n    \"\"\"\n    OmniGibson interactive scenes\n\n    Returns:\n        list: Available OmniGibson interactive scenes\n    \"\"\"\n    og_dataset_path = og.og_dataset_path\n    og_scenes_path = os.path.join(og_dataset_path, \"scenes\")\n    available_og_scenes = sorted(\n        [f for f in os.listdir(og_scenes_path) if (not folder_is_hidden(f) and f != \"background\")]\n    )\n    return available_og_scenes\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_available_og_scenes"},{"title":"<code>get_object_models_of_category(category_name, filter_method=None)</code>","text":"<p>Get OmniGibson all object models of a given category</p>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_object_models_of_category"},{"title":"TODO: Make this less ugly -- filter_method is a single hard-coded check","text":"<p>Parameters:</p>    Name Type Description Default     <code>category_name</code>  <code>str</code>  <p>object category</p>  required    <code>filter_method</code>  <code>str</code>  <p>Method to use for filtering object models</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>list</code>   <p>all object models of a given category</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_object_models_of_category(category_name, filter_method=None):\n    \"\"\"\n    Get OmniGibson all object models of a given category\n\n    # TODO: Make this less ugly -- filter_method is a single hard-coded check\n\n    Args:\n        category_name (str): object category\n        filter_method (str): Method to use for filtering object models\n\n    Returns:\n        list: all object models of a given category\n    \"\"\"\n    models = []\n    og_category_path = get_og_category_path(category_name)\n    for model_name in os.listdir(og_category_path):\n        if filter_method is None:\n            models.append(model_name)\n        elif filter_method in [\"sliceable_part\", \"sliceable_whole\"]:\n            model_path = get_og_model_path(category_name, model_name)\n            metadata_json = os.path.join(model_path, \"misc\", \"metadata.json\")\n            with open(metadata_json) as f:\n                metadata = json.load(f)\n            if (filter_method == \"sliceable_part\" and \"object_parts\" not in metadata) or (\n                filter_method == \"sliceable_whole\" and \"object_parts\" in metadata\n            ):\n                models.append(model_name)\n        else:\n            raise Exception(\"Unknown filter method: {}\".format(filter_method))\n    return models\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_object_models_of_category--todo-make-this-less-ugly-filter_method-is-a-single-hard-coded-check"},{"title":"<code>get_og_assets_version()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>OmniGibson asset version</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_og_assets_version():\n    \"\"\"\n    Returns:\n        str: OmniGibson asset version\n    \"\"\"\n    process = subprocess.Popen(\n        [\"git\", \"-C\", og.og_dataset_path, \"rev-parse\", \"HEAD\"], shell=False, stdout=subprocess.PIPE\n    )\n    git_head_hash = str(process.communicate()[0].strip())\n    return \"{}\".format(git_head_hash)\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_assets_version"},{"title":"<code>get_og_avg_category_specs()</code>","text":"<p>Load average object specs (dimension and mass) for objects</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Average category specifications for all object categories</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_og_avg_category_specs():\n    \"\"\"\n    Load average object specs (dimension and mass) for objects\n\n    Returns:\n        dict: Average category specifications for all object categories\n    \"\"\"\n    avg_obj_dim_file = os.path.join(og.og_dataset_path, \"metadata\", \"avg_category_specs.json\")\n    if os.path.exists(avg_obj_dim_file):\n        with open(avg_obj_dim_file) as f:\n            return json.load(f)\n    else:\n        logging.warning(\n            \"Requested average specs of the object categories in the OmniGibson Dataset of objects, but the \"\n            \"file cannot be found. Did you download the dataset? Returning an empty dictionary\"\n        )\n        return dict()\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_avg_category_specs"},{"title":"<code>get_og_category_ids()</code>","text":"<p>Get OmniGibson object categories</p> <p>Returns:</p>    Name Type Description     <code>str</code>   <p>file path to the scene name</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_og_category_ids():\n    \"\"\"\n    Get OmniGibson object categories\n\n    Returns:\n        str: file path to the scene name\n    \"\"\"\n    og_dataset_path = og.og_dataset_path\n    og_categories_files = os.path.join(og_dataset_path, \"metadata\", \"categories.txt\")\n    name_to_id = {}\n    with open(og_categories_files, \"r\") as fp:\n        for i, l in enumerate(fp.readlines()):\n            name_to_id[l.rstrip()] = i\n    return defaultdict(lambda: 255, name_to_id)\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_category_ids"},{"title":"<code>get_og_category_path(category_name)</code>","text":"<p>Get OmniGibson object category path</p> <p>Parameters:</p>    Name Type Description Default     <code>category_name</code>  <code>str</code>  <p>object category</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>file path to the object category</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_og_category_path(category_name):\n    \"\"\"\n    Get OmniGibson object category path\n\n    Args:\n        category_name (str): object category\n\n    Returns:\n        str: file path to the object category\n    \"\"\"\n    og_dataset_path = og.og_dataset_path\n    og_categories_path = os.path.join(og_dataset_path, \"objects\")\n    assert category_name in os.listdir(og_categories_path), \"Category {} does not exist\".format(category_name)\n    return os.path.join(og_categories_path, category_name)\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_category_path"},{"title":"<code>get_og_model_path(category_name, model_name)</code>","text":"<p>Get OmniGibson object model path</p> <p>Parameters:</p>    Name Type Description Default     <code>category_name</code>  <code>str</code>  <p>object category</p>  required    <code>model_name</code>  <code>str</code>  <p>object model</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>file path to the object model</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_og_model_path(category_name, model_name):\n    \"\"\"\n    Get OmniGibson object model path\n\n    Args:\n        category_name (str): object category\n        model_name (str): object model\n\n    Returns:\n        str: file path to the object model\n    \"\"\"\n    og_category_path = get_og_category_path(category_name)\n    assert model_name in os.listdir(og_category_path), \"Model {} from category {} does not exist\".format(\n        model_name, category_name\n    )\n    return os.path.join(og_category_path, model_name)\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_model_path"},{"title":"<code>get_og_scene_path(scene_name)</code>","text":"<p>Get OmniGibson scene path</p> <p>Parameters:</p>    Name Type Description Default     <code>scene_name</code>  <code>str</code>  <p>scene name, e.g., \"Rs_int\"</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>file path to the scene name</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_og_scene_path(scene_name):\n    \"\"\"\n    Get OmniGibson scene path\n\n    Args:\n        scene_name (str): scene name, e.g., \"Rs_int\"\n\n    Returns:\n        str: file path to the scene name\n    \"\"\"\n    og_dataset_path = og.og_dataset_path\n    og_scenes_path = os.path.join(og_dataset_path, \"scenes\")\n    logging.info(\"Scene name: {}\".format(scene_name))\n    assert scene_name in os.listdir(og_scenes_path), \"Scene {} does not exist\".format(scene_name)\n    return os.path.join(og_scenes_path, scene_name)\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_og_scene_path"},{"title":"<code>get_scene_path(scene_id)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>scene_id</code>  <code>str</code>  <p>scene id, e.g., \"Rs_int\"</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>scene path for this scene_id</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_scene_path(scene_id):\n    \"\"\"\n    Args:\n        scene_id (str): scene id, e.g., \"Rs_int\"\n\n    Returns:\n        str: scene path for this scene_id\n    \"\"\"\n    data_path = og.g_dataset_path\n    assert scene_id in os.listdir(data_path), \"Scene {} does not exist\".format(scene_id)\n    return os.path.join(data_path, scene_id)\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_scene_path"},{"title":"<code>get_texture_file(mesh_file)</code>","text":"<p>Get texture file</p> <p>Parameters:</p>    Name Type Description Default     <code>mesh_file</code>  <code>str</code>  <p>path to mesh obj file</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>texture file path</p>     Source code in <code>utils/asset_utils.py</code> <pre><code>def get_texture_file(mesh_file):\n    \"\"\"\n    Get texture file\n\n    Args:\n        mesh_file (str): path to mesh obj file\n\n    Returns:\n        str: texture file path\n    \"\"\"\n    model_dir = os.path.dirname(mesh_file)\n    with open(mesh_file, \"r\") as f:\n        lines = [line.strip() for line in f.readlines() if \"mtllib\" in line]\n        if len(lines) == 0:\n            return\n        mtl_file = lines[0].split()[1]\n        mtl_file = os.path.join(model_dir, mtl_file)\n\n    with open(mtl_file, \"r\") as f:\n        lines = [line.strip() for line in f.readlines() if \"map_Kd\" in line]\n        if len(lines) == 0:\n            return\n        texture_file = lines[0].split()[1]\n        texture_file = os.path.join(model_dir, texture_file)\n\n    return texture_file\n</code></pre>","location":"reference/utils/asset_utils.html#utils.asset_utils.get_texture_file"},{"title":"config_utils","text":"","location":"reference/utils/config_utils.html"},{"title":"<code>dump_config(config)</code>","text":"<p>Converts YML config into a string</p> <p>Parameters:</p>    Name Type Description Default     <code>config</code>  <code>dict</code>  <p>Config to dump</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Config as a string</p>     Source code in <code>utils/config_utils.py</code> <pre><code>def dump_config(config):\n    \"\"\"\n    Converts YML config into a string\n\n    Args:\n        config (dict): Config to dump\n\n    Returns:\n        str: Config as a string\n    \"\"\"\n    return yaml.dump(config)\n</code></pre>","location":"reference/utils/config_utils.html#utils.config_utils.dump_config"},{"title":"<code>load_default_config()</code>","text":"<p>Loads a default configuration to use for OmniGibson</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Loaded default configuration file</p>     Source code in <code>utils/config_utils.py</code> <pre><code>def load_default_config():\n    \"\"\"\n    Loads a default configuration to use for OmniGibson\n\n    Returns:\n        dict: Loaded default configuration file\n    \"\"\"\n    return parse_config(f\"{example_config_path}/default_cfg.yaml\")\n</code></pre>","location":"reference/utils/config_utils.html#utils.config_utils.load_default_config"},{"title":"<code>parse_config(config)</code>","text":"<p>Parse OmniGibson config file / object</p> <p>Parameters:</p>    Name Type Description Default     <code>config</code>  <code>dict or str</code>  <p>Either config dictionary or path to yaml config to load</p>  required     <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Parsed config</p>     Source code in <code>utils/config_utils.py</code> <pre><code>def parse_config(config):\n    \"\"\"\n    Parse OmniGibson config file / object\n\n    Args:\n        config (dict or str): Either config dictionary or path to yaml config to load\n\n    Returns:\n        dict: Parsed config\n    \"\"\"\n    if isinstance(config, collections.Mapping):\n        return config\n    else:\n        assert isinstance(config, str)\n\n    if not os.path.exists(config):\n        raise IOError(\n            \"config path {} does not exist. Please either pass in a dict or a string that represents the file path to the config yaml.\".format(\n                config\n            )\n        )\n    with open(config, \"r\") as f:\n        config_data = yaml.load(f, Loader=yaml.FullLoader)\n    return config_data\n</code></pre>","location":"reference/utils/config_utils.html#utils.config_utils.parse_config"},{"title":"<code>parse_str_config(config)</code>","text":"<p>Parse string config</p> <p>Parameters:</p>    Name Type Description Default     <code>config</code>  <code>str</code>  <p>Yaml cfg as a string to load</p>  required     <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Parsed config</p>     Source code in <code>utils/config_utils.py</code> <pre><code>def parse_str_config(config):\n    \"\"\"\n    Parse string config\n\n    Args:\n        config (str): Yaml cfg as a string to load\n\n    Returns:\n        dict: Parsed config\n    \"\"\"\n    return yaml.safe_load(config)\n</code></pre>","location":"reference/utils/config_utils.html#utils.config_utils.parse_str_config"},{"title":"constants","text":"<p>Constant Definitions</p>","location":"reference/utils/constants.html"},{"title":"<code>get_class_name_to_class_id()</code>","text":"<p>Get mapping from semantic class name to class id</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>starting class id for scene objects</p>     Source code in <code>utils/constants.py</code> <pre><code>def get_class_name_to_class_id():\n    \"\"\"\n    Get mapping from semantic class name to class id\n\n    Returns:\n        dict: starting class id for scene objects\n    \"\"\"\n    existing_classes = {item.value for item in SemanticClass}\n    category_txt = os.path.join(omnigibson.og_dataset_path, \"metadata/categories.txt\")\n    class_name_to_class_id = {\"agent\": SemanticClass.ROBOTS}  # Agents should have the robot semantic class.\n    starting_class_id = 0\n    if os.path.isfile(category_txt):\n        with open(category_txt) as f:\n            for line in f.readlines():\n                while starting_class_id in existing_classes:\n                    starting_class_id += 1\n                assert starting_class_id &lt; MAX_CLASS_COUNT, \"Class ID overflow: MAX_CLASS_COUNT is {}.\".format(\n                    MAX_CLASS_COUNT\n                )\n                class_name_to_class_id[line.strip()] = starting_class_id\n                starting_class_id += 1\n\n    return class_name_to_class_id\n</code></pre>","location":"reference/utils/constants.html#utils.constants.get_class_name_to_class_id"},{"title":"<code>get_collision_group_mask(groups_to_exclude=[])</code>","text":"<p>Get a collision group mask that has collisions enabled for every group except those in groups_to_exclude.</p>  Source code in <code>utils/constants.py</code> <pre><code>def get_collision_group_mask(groups_to_exclude=[]):\n    \"\"\"Get a collision group mask that has collisions enabled for every group except those in groups_to_exclude.\"\"\"\n    collision_mask = ALL_COLLISION_GROUPS_MASK\n    for group in groups_to_exclude:\n        collision_mask &amp;= ~(1 &lt;&lt; group)\n    return collision_mask\n</code></pre>","location":"reference/utils/constants.html#utils.constants.get_collision_group_mask"},{"title":"control_utils","text":"<p>Set of utilities for helping to execute robot control</p>","location":"reference/utils/control_utils.html"},{"title":"<code>IKSolver</code>","text":"<p>Class for thinly wrapping Lula IK solver</p>  Source code in <code>utils/control_utils.py</code> <pre><code>class IKSolver:\n    \"\"\"\n    Class for thinly wrapping Lula IK solver\n    \"\"\"\n\n    def __init__(\n        self,\n        robot_description_path,\n        robot_urdf_path,\n        eef_name,\n        default_joint_pos,\n    ):\n        # Create robot description, kinematics, and config\n        self.robot_description = lula.load_robot(robot_description_path, robot_urdf_path)\n        self.kinematics = self.robot_description.kinematics()\n        self.config = lula.CyclicCoordDescentIkConfig()\n        self.eef_name = eef_name\n        self.default_joint_pos = default_joint_pos\n\n    def solve(\n        self,\n        target_pos,\n        target_quat=None,\n        tolerance_pos=0.002,\n        tolerance_quat=0.01,\n        weight_pos=1.0,\n        weight_quat=0.05,\n        max_iterations=150,\n        initial_joint_pos=None,\n    ):\n        \"\"\"\n        Backs out joint positions to achieve desired @target_pos and @target_quat\n\n        Args:\n            target_pos (3-array): desired (x,y,z) local target cartesian position in robot's base coordinate frame\n            target_quat (4-array or None): If specified, desired (x,y,z,w) local target quaternion orientation in\n            robot's base coordinate frame. If None, IK will be position-only (will override settings such that\n            orientation's tolerance is very high and weight is 0)\n            tolerance_pos (float): Maximum position error (L2-norm) for a successful IK solution\n            tolerance_quat (float): Maximum orientation error (per-axis L2-norm) for a successful IK solution\n            weight_pos (float): Weight for the relative importance of position error during CCD\n            weight_quat (float): Weight for the relative importance of position error during CCD\n            max_iterations (int): Number of iterations used for each cyclic coordinate descent.\n            initial_joint_pos (None or n-array): If specified, will set the initial cspace seed when solving for joint\n                positions. Otherwise, will use self.default_joint_pos\n\n        Returns:\n            None or n-array: Joint positions for reaching desired target_pos and target_quat, otherwise None if no\n                solution was found\n        \"\"\"\n        pos = np.array(target_pos, dtype=np.float64).reshape(3, 1)\n        rot = np.array(T.quat2mat(np.array([0, 0, 0, 1.0]) if target_quat is None else target_quat), dtype=np.float64)\n        ik_target_pose = lula.Pose3(lula.Rotation3(rot), pos)\n\n        # Set the cspace seed and tolerance\n        initial_joint_pos = self.default_joint_pos if initial_joint_pos is None else np.array(initial_joint_pos)\n        self.config.cspace_seeds = [initial_joint_pos]\n        self.config.position_tolerance = tolerance_pos\n        self.config.orientation_tolerance = 100.0 if target_quat is None else tolerance_quat\n        self.config.position_weight = weight_pos\n        self.config.orientation_weight = 0.0 if target_quat is None else weight_quat\n        self.config.max_iterations_per_descent = max_iterations\n\n        # Compute target joint positions\n        ik_results = lula.compute_ik_ccd(self.kinematics, ik_target_pose, self.eef_name, self.config)\n        return np.array(ik_results.cspace_position)\n</code></pre>","location":"reference/utils/control_utils.html#utils.control_utils.IKSolver"},{"title":"<code>solve(target_pos, target_quat=None, tolerance_pos=0.002, tolerance_quat=0.01, weight_pos=1.0, weight_quat=0.05, max_iterations=150, initial_joint_pos=None)</code>","text":"<p>Backs out joint positions to achieve desired @target_pos and @target_quat</p> <p>Parameters:</p>    Name Type Description Default     <code>target_pos</code>  <code>3-array</code>  <p>desired (x,y,z) local target cartesian position in robot's base coordinate frame</p>  required    <code>target_quat</code>  <code>4-array or None</code>  <p>If specified, desired (x,y,z,w) local target quaternion orientation in</p>  <code>None</code>    <code>tolerance_pos</code>  <code>float</code>  <p>Maximum position error (L2-norm) for a successful IK solution</p>  <code>0.002</code>    <code>tolerance_quat</code>  <code>float</code>  <p>Maximum orientation error (per-axis L2-norm) for a successful IK solution</p>  <code>0.01</code>    <code>weight_pos</code>  <code>float</code>  <p>Weight for the relative importance of position error during CCD</p>  <code>1.0</code>    <code>weight_quat</code>  <code>float</code>  <p>Weight for the relative importance of position error during CCD</p>  <code>0.05</code>    <code>max_iterations</code>  <code>int</code>  <p>Number of iterations used for each cyclic coordinate descent.</p>  <code>150</code>    <code>initial_joint_pos</code>  <code>None or n-array</code>  <p>If specified, will set the initial cspace seed when solving for joint positions. Otherwise, will use self.default_joint_pos</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>None or n-array: Joint positions for reaching desired target_pos and target_quat, otherwise None if no solution was found</p>     Source code in <code>utils/control_utils.py</code> <pre><code>def solve(\n    self,\n    target_pos,\n    target_quat=None,\n    tolerance_pos=0.002,\n    tolerance_quat=0.01,\n    weight_pos=1.0,\n    weight_quat=0.05,\n    max_iterations=150,\n    initial_joint_pos=None,\n):\n    \"\"\"\n    Backs out joint positions to achieve desired @target_pos and @target_quat\n\n    Args:\n        target_pos (3-array): desired (x,y,z) local target cartesian position in robot's base coordinate frame\n        target_quat (4-array or None): If specified, desired (x,y,z,w) local target quaternion orientation in\n        robot's base coordinate frame. If None, IK will be position-only (will override settings such that\n        orientation's tolerance is very high and weight is 0)\n        tolerance_pos (float): Maximum position error (L2-norm) for a successful IK solution\n        tolerance_quat (float): Maximum orientation error (per-axis L2-norm) for a successful IK solution\n        weight_pos (float): Weight for the relative importance of position error during CCD\n        weight_quat (float): Weight for the relative importance of position error during CCD\n        max_iterations (int): Number of iterations used for each cyclic coordinate descent.\n        initial_joint_pos (None or n-array): If specified, will set the initial cspace seed when solving for joint\n            positions. Otherwise, will use self.default_joint_pos\n\n    Returns:\n        None or n-array: Joint positions for reaching desired target_pos and target_quat, otherwise None if no\n            solution was found\n    \"\"\"\n    pos = np.array(target_pos, dtype=np.float64).reshape(3, 1)\n    rot = np.array(T.quat2mat(np.array([0, 0, 0, 1.0]) if target_quat is None else target_quat), dtype=np.float64)\n    ik_target_pose = lula.Pose3(lula.Rotation3(rot), pos)\n\n    # Set the cspace seed and tolerance\n    initial_joint_pos = self.default_joint_pos if initial_joint_pos is None else np.array(initial_joint_pos)\n    self.config.cspace_seeds = [initial_joint_pos]\n    self.config.position_tolerance = tolerance_pos\n    self.config.orientation_tolerance = 100.0 if target_quat is None else tolerance_quat\n    self.config.position_weight = weight_pos\n    self.config.orientation_weight = 0.0 if target_quat is None else weight_quat\n    self.config.max_iterations_per_descent = max_iterations\n\n    # Compute target joint positions\n    ik_results = lula.compute_ik_ccd(self.kinematics, ik_target_pose, self.eef_name, self.config)\n    return np.array(ik_results.cspace_position)\n</code></pre>","location":"reference/utils/control_utils.html#utils.control_utils.IKSolver.solve"},{"title":"deprecated_utils","text":"<p>A set of utility functions slated to be deprecated once Omniverse bugs are fixed</p>","location":"reference/utils/deprecated_utils.html"},{"title":"<code>Core</code>","text":"<p>         Bases: <code>OmniCore</code></p> <p>Subclass that overrides a specific function within Omni's Core class to fix a bug</p>  Source code in <code>utils/deprecated_utils.py</code> <pre><code>class Core(OmniCore):\n    \"\"\"\n    Subclass that overrides a specific function within Omni's Core class to fix a bug\n    \"\"\"\n    def __init__(self, popup_callback: Callable[[str], None], particle_system_name: str):\n        self._popup_callback = popup_callback\n        # TODO: THIS IS THE ONLY LINE THAT WE CHANGE! ONCE FIXED, REMOVE THIS\n        self.utils = Utils()\n        self.context = ou.get_context()\n        self.stage = self.context.get_stage()\n        self.selection = self.context.get_selection()\n        self.particle_system_name = particle_system_name\n        self.sub_stage_update = self.context.get_stage_event_stream().create_subscription_to_pop(self.on_stage_update)\n        self.on_stage_update()\n\n    def get_compute_graph(self, selected_paths, create_new_graph=True, created_paths=None):\n        \"\"\"\n        Returns the first ComputeGraph found in selected_paths.\n        If no graph is found and create_new_graph is true, a new graph will be created and its\n        path appended to created_paths (if provided).\n        \"\"\"\n        graph = None\n        graph_paths = [path for path in selected_paths\n                       if self.stage.GetPrimAtPath(path).GetTypeName() == \"ComputeGraph\"]\n\n        if len(graph_paths) &gt; 0:\n            graph = ogc.get_graph_by_path(graph_paths[0])\n            if len(graph_paths) &gt; 1:\n                carb.log_warn(f\"Multiple ComputeGraph prims selected. Only the first will be used: {graph.get_path_to_graph()}\")\n        elif create_new_graph:\n            # If no graph was found in the selected prims, we'll make a new graph.\n            graph_path = Sdf.Path(f\"/OmniGraph/{self.particle_system_name}\").MakeAbsolutePath(Sdf.Path.absoluteRootPath)\n            graph_path = ou.get_stage_next_free_path(self.stage, graph_path, True)\n\n            # prim = self.stage.GetDefaultPrim()\n            # path = str(prim.GetPath()) if prim else \"\"\n            self.stage.DefinePrim(\"/OmniGraph\", \"Scope\")\n\n            container_graphs = ogc.get_global_container_graphs()\n            # FIXME: container_graphs[0] should be the simulation orchestration graph, but this may change in the future.\n            container_graph = container_graphs[0]\n            result, wrapper_node = ogc.cmds.CreateGraphAsNode(\n                graph=container_graph,\n                node_name=Sdf.Path(graph_path).name,\n                graph_path=graph_path,\n                evaluator_name=\"push\",\n                is_global_graph=True,\n                backed_by_usd=True,\n                fc_backing_type=ogc.GraphBackingType.GRAPH_BACKING_TYPE_FLATCACHE_SHARED,\n                pipeline_stage=ogc.GraphPipelineStage.GRAPH_PIPELINE_STAGE_SIMULATION\n            )\n            graph = wrapper_node.get_wrapped_graph()\n\n            if created_paths is not None:\n                created_paths.append(graph.get_path_to_graph())\n\n            carb.log_info(f\"No ComputeGraph selected. A new graph has been created at {graph.get_path_to_graph()}\")\n\n        return graph\n</code></pre>","location":"reference/utils/deprecated_utils.html#utils.deprecated_utils.Core"},{"title":"<code>get_compute_graph(selected_paths, create_new_graph=True, created_paths=None)</code>","text":"<p>Returns the first ComputeGraph found in selected_paths. If no graph is found and create_new_graph is true, a new graph will be created and its path appended to created_paths (if provided).</p>  Source code in <code>utils/deprecated_utils.py</code> <pre><code>def get_compute_graph(self, selected_paths, create_new_graph=True, created_paths=None):\n    \"\"\"\n    Returns the first ComputeGraph found in selected_paths.\n    If no graph is found and create_new_graph is true, a new graph will be created and its\n    path appended to created_paths (if provided).\n    \"\"\"\n    graph = None\n    graph_paths = [path for path in selected_paths\n                   if self.stage.GetPrimAtPath(path).GetTypeName() == \"ComputeGraph\"]\n\n    if len(graph_paths) &gt; 0:\n        graph = ogc.get_graph_by_path(graph_paths[0])\n        if len(graph_paths) &gt; 1:\n            carb.log_warn(f\"Multiple ComputeGraph prims selected. Only the first will be used: {graph.get_path_to_graph()}\")\n    elif create_new_graph:\n        # If no graph was found in the selected prims, we'll make a new graph.\n        graph_path = Sdf.Path(f\"/OmniGraph/{self.particle_system_name}\").MakeAbsolutePath(Sdf.Path.absoluteRootPath)\n        graph_path = ou.get_stage_next_free_path(self.stage, graph_path, True)\n\n        # prim = self.stage.GetDefaultPrim()\n        # path = str(prim.GetPath()) if prim else \"\"\n        self.stage.DefinePrim(\"/OmniGraph\", \"Scope\")\n\n        container_graphs = ogc.get_global_container_graphs()\n        # FIXME: container_graphs[0] should be the simulation orchestration graph, but this may change in the future.\n        container_graph = container_graphs[0]\n        result, wrapper_node = ogc.cmds.CreateGraphAsNode(\n            graph=container_graph,\n            node_name=Sdf.Path(graph_path).name,\n            graph_path=graph_path,\n            evaluator_name=\"push\",\n            is_global_graph=True,\n            backed_by_usd=True,\n            fc_backing_type=ogc.GraphBackingType.GRAPH_BACKING_TYPE_FLATCACHE_SHARED,\n            pipeline_stage=ogc.GraphPipelineStage.GRAPH_PIPELINE_STAGE_SIMULATION\n        )\n        graph = wrapper_node.get_wrapped_graph()\n\n        if created_paths is not None:\n            created_paths.append(graph.get_path_to_graph())\n\n        carb.log_info(f\"No ComputeGraph selected. A new graph has been created at {graph.get_path_to_graph()}\")\n\n    return graph\n</code></pre>","location":"reference/utils/deprecated_utils.html#utils.deprecated_utils.Core.get_compute_graph"},{"title":"<code>Utils</code>","text":"<p>         Bases: <code>OmniUtils</code></p> <p>Subclass that overrides a specific function within Omni's Utils class to fix a bug</p>  Source code in <code>utils/deprecated_utils.py</code> <pre><code>class Utils(OmniUtils):\n    \"\"\"\n    Subclass that overrides a specific function within Omni's Utils class to fix a bug\n    \"\"\"\n    def create_material(self, name):\n        # TODO: THIS IS THE ONLY LINE WE CHANGE! \"/\" SHOULD BE \"\"\n        material_path = \"\"\n        default_prim = self.stage.GetDefaultPrim()\n        if default_prim:\n            material_path = default_prim.GetPath().pathString\n\n        if not self.stage.GetPrimAtPath(material_path + \"/Looks\"):\n            self.stage.DefinePrim(material_path + \"/Looks\", \"Scope\")\n        material_path += \"/Looks/\" + name\n        material_path = ou.get_stage_next_free_path(\n            self.stage, material_path, False\n        )\n        material = UsdShade.Material.Define(self.stage, material_path)\n\n        shader_path = material_path + \"/Shader\"\n        shader = UsdShade.Shader.Define(self.stage, shader_path)\n\n        # Update Neuraylib MDL search paths\n        import omni.particle.system.core as core\n        core.update_mdl_search_paths()\n\n        shader.SetSourceAsset(name + \".mdl\", \"mdl\")\n        shader.SetSourceAssetSubIdentifier(name, \"mdl\")\n        shader.GetImplementationSourceAttr().Set(UsdShade.Tokens.sourceAsset)\n        shader.CreateOutput(\"out\", Sdf.ValueTypeNames.Token)\n        material.CreateSurfaceOutput().ConnectToSource(shader, \"out\")\n\n        return [material_path]\n</code></pre>","location":"reference/utils/deprecated_utils.html#utils.deprecated_utils.Utils"},{"title":"geometry_utils","text":"<p>A set of helper utility functions for dealing with 3D geometry</p>","location":"reference/utils/geometry_utils.html"},{"title":"<code>check_points_in_cone(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a cone with specified size @size.</p> <p>NOTE: Assumes the cone and positions are expressed in the same coordinate frame such that the cone's height is aligned with the z-axis</p> <p>Parameters:</p>    Name Type Description Default     <code>size</code>  <code>2-array</code>  <p>(radius, height) dimensions of the cone, specified in its local frame</p>  required    <code>pos</code>  <code>3-array</code>  <p>(x,y,z) local location of the cone</p>  required    <code>quat</code>  <code>4-array</code>  <p>(x,y,z,w) local orientation of the cone</p>  required    <code>scale</code>  <code>3-array</code>  <p>(x,y,z) local scale of the cone, specified in its local frame</p>  required    <code>particle_positions</code>  <code>N, 3) array</code>  <p>positions to check for whether it is in the cone</p>  required     <p>Returns:</p>    Type Description       <p>(N,) array: boolean numpy array specifying whether each point lies in the cone.</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def check_points_in_cone(size, pos, quat, scale, particle_positions):\n    \"\"\"\n    Checks which points are within a cone with specified size @size.\n\n    NOTE: Assumes the cone and positions are\n    expressed in the same coordinate frame such that the cone's height is aligned with the z-axis\n\n    Args:\n        size (2-array): (radius, height) dimensions of the cone, specified in its local frame\n        pos (3-array): (x,y,z) local location of the cone\n        quat (4-array): (x,y,z,w) local orientation of the cone\n        scale (3-array): (x,y,z) local scale of the cone, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the cone\n\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the cone.\n    \"\"\"\n    particle_positions = get_particle_positions_in_frame(\n        pos=pos,\n        quat=quat,\n        scale=scale,\n        particle_positions=particle_positions,\n    )\n    radius, height = size\n    in_height = (-height / 2.0 &lt; particle_positions[:, -1]) &amp; (particle_positions[:, -1] &lt; height / 2.0)\n    in_radius = np.linalg.norm(particle_positions[:, :-1], axis=-1) &lt; \\\n                (radius * (1 - (particle_positions[:, -1] + height / 2.0) / height ))\n    return in_height &amp; in_radius\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_cone"},{"title":"<code>check_points_in_convex_hull_mesh(mesh_face_centroids, mesh_face_normals, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a sphere with specified size @size.</p> <p>NOTE: Assumes the mesh and positions are expressed in the same coordinate frame</p> <p>Parameters:</p>    Name Type Description Default     <code>mesh_face_centroids</code>  <code>D, 3</code>  <p>(x,y,z) location of the centroid of each mesh face, expressed in its local frame</p>  required    <code>mesh_face_normals</code>  <code>D, 3</code>  <p>(x,y,z) normalized direction vector of each mesh face, expressed in its local frame</p>  required    <code>pos</code>  <code>3-array</code>  <p>(x,y,z) local location of the mesh</p>  required    <code>quat</code>  <code>4-array</code>  <p>(x,y,z,w) local orientation of the mesh</p>  required    <code>scale</code>  <code>3-array</code>  <p>(x,y,z) local scale of the cube, specified in its local frame</p>  required    <code>particle_positions</code>  <code>N, 3) array</code>  <p>positions to check for whether it is in the mesh</p>  required     <p>Returns:</p>    Type Description       <p>(N,) array: boolean numpy array specifying whether each point lies in the mesh</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def check_points_in_convex_hull_mesh(mesh_face_centroids, mesh_face_normals, pos, quat, scale, particle_positions):\n    \"\"\"\n    Checks which points are within a sphere with specified size @size.\n\n    NOTE: Assumes the mesh and positions are expressed in the same coordinate frame\n\n    Args:\n        mesh_face_centroids (D, 3): (x,y,z) location of the centroid of each mesh face, expressed in its local frame\n        mesh_face_normals (D, 3): (x,y,z) normalized direction vector of each mesh face, expressed in its local frame\n        pos (3-array): (x,y,z) local location of the mesh\n        quat (4-array): (x,y,z,w) local orientation of the mesh\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the mesh\n\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the mesh\n    \"\"\"\n    particle_positions = get_particle_positions_in_frame(\n        pos=pos,\n        quat=quat,\n        scale=scale,\n        particle_positions=particle_positions,\n    )\n    # For every mesh point / normal and particle position pair, we check whether it is \"inside\" (i.e.: the point lies\n    # BEHIND the normal plane -- this is easily done by taking the dot product with the vector from the point to the\n    # particle position with the normal, and validating that the value is &lt; 0)\n    D, _ = mesh_face_centroids.shape\n    N, _ = particle_positions.shape\n    mesh_points = np.tile(mesh_face_centroids.reshape(1, D, 3), (N, 1, 1))\n    mesh_normals = np.tile(mesh_face_normals.reshape(1, D, 3), (N, 1, 1))\n    particle_positions = np.tile(particle_positions.reshape(N, 1, 3), (1, D, 1))\n    # All arrays are now (N, D, 3) shape -- efficient for batching\n    in_range = ((particle_positions - mesh_points) * mesh_normals).sum(axis=-1) &lt; 0         # shape (N, D)\n    # All D normals must be satisfied for a single point to be considered inside the hull\n    in_range = in_range.sum(axis=-1) == D\n    return in_range\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_convex_hull_mesh"},{"title":"<code>check_points_in_cube(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a cube with specified size @size.</p> <p>NOTE: Assumes the cube and positions are expressed in the same coordinate frame such that the cube's dimensions are axis-aligned with (x,y,z)</p> <p>Parameters:</p>    Name Type Description Default     <code>size</code>  <code>float</code>  <p>length of each side of the cube, specified in its local frame</p>  required    <code>pos</code>  <code>3-array</code>  <p>(x,y,z) local location of the cube</p>  required    <code>quat</code>  <code>4-array</code>  <p>(x,y,z,w) local orientation of the cube</p>  required    <code>scale</code>  <code>3-array</code>  <p>(x,y,z) local scale of the cube, specified in its local frame</p>  required    <code>particle_positions</code>  <code>N, 3) array</code>  <p>positions to check for whether it is in the cube</p>  required     <p>Returns:</p>    Type Description       <p>(N,) array: boolean numpy array specifying whether each point lies in the cube.</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def check_points_in_cube(size, pos, quat, scale, particle_positions):\n    \"\"\"\n    Checks which points are within a cube with specified size @size.\n\n    NOTE: Assumes the cube and positions are expressed\n    in the same coordinate frame such that the cube's dimensions are axis-aligned with (x,y,z)\n\n    Args:\n        size float: length of each side of the cube, specified in its local frame\n        pos (3-array): (x,y,z) local location of the cube\n        quat (4-array): (x,y,z,w) local orientation of the cube\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the cube\n\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the cube.\n    \"\"\"\n    particle_positions = get_particle_positions_in_frame(\n        pos=pos,\n        quat=quat,\n        scale=scale,\n        particle_positions=particle_positions,\n    )\n    return ((-size / 2.0 &lt; particle_positions) &amp; (particle_positions &lt; size / 2.0)).sum(axis=-1) == 3\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_cube"},{"title":"<code>check_points_in_cylinder(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a cylinder with specified size @size.</p> <p>NOTE: Assumes the cylinder and positions are expressed in the same coordinate frame such that the cylinder's height is aligned with the z-axis</p> <p>Parameters:</p>    Name Type Description Default     <code>size</code>  <code>2-array</code>  <p>(radius, height) dimensions of the cylinder, specified in its local frame</p>  required    <code>pos</code>  <code>3-array</code>  <p>(x,y,z) local location of the cylinder</p>  required    <code>quat</code>  <code>4-array</code>  <p>(x,y,z,w) local orientation of the cylinder</p>  required    <code>scale</code>  <code>3-array</code>  <p>(x,y,z) local scale of the cube, specified in its local frame</p>  required    <code>particle_positions</code>  <code>N, 3) array</code>  <p>positions to check for whether it is in the cylinder</p>  required     <p>Returns:</p>    Type Description       <p>(N,) array: boolean numpy array specifying whether each point lies in the cylinder.</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def check_points_in_cylinder(size, pos, quat, scale, particle_positions):\n    \"\"\"\n    Checks which points are within a cylinder with specified size @size.\n\n    NOTE: Assumes the cylinder and positions are\n    expressed in the same coordinate frame such that the cylinder's height is aligned with the z-axis\n\n    Args:\n        size (2-array): (radius, height) dimensions of the cylinder, specified in its local frame\n        pos (3-array): (x,y,z) local location of the cylinder\n        quat (4-array): (x,y,z,w) local orientation of the cylinder\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the cylinder\n\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the cylinder.\n    \"\"\"\n    particle_positions = get_particle_positions_in_frame(\n        pos=pos,\n        quat=quat,\n        scale=scale,\n        particle_positions=particle_positions,\n    )\n    radius, height = size\n    in_height = (-height / 2.0 &lt; particle_positions[:, -1]) &amp; (particle_positions[:, -1] &lt; height / 2.0)\n    in_radius = np.linalg.norm(particle_positions[:, :-1], axis=-1) &lt; radius\n    return in_height &amp; in_radius\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_cylinder"},{"title":"<code>check_points_in_sphere(size, pos, quat, scale, particle_positions)</code>","text":"<p>Checks which points are within a sphere with specified size @size.</p> <p>NOTE: Assumes the sphere and positions are expressed in the same coordinate frame</p> <p>Parameters:</p>    Name Type Description Default     <code>size</code>  <code>float</code>  <p>radius dimensions of the sphere</p>  required    <code>pos</code>  <code>3-array</code>  <p>(x,y,z) local location of the sphere</p>  required    <code>quat</code>  <code>4-array</code>  <p>(x,y,z,w) local orientation of the sphere</p>  required    <code>scale</code>  <code>3-array</code>  <p>(x,y,z) local scale of the cube, specified in its local frame</p>  required    <code>particle_positions</code>  <code>N, 3) array</code>  <p>positions to check for whether it is in the sphere</p>  required     <p>Returns:</p>    Type Description       <p>(N,) array: boolean numpy array specifying whether each point lies in the sphere</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def check_points_in_sphere(size, pos, quat, scale, particle_positions):\n    \"\"\"\n    Checks which points are within a sphere with specified size @size.\n\n    NOTE: Assumes the sphere and positions are expressed in the same coordinate frame\n\n    Args:\n        size (float): radius dimensions of the sphere\n        pos (3-array): (x,y,z) local location of the sphere\n        quat (4-array): (x,y,z,w) local orientation of the sphere\n        scale (3-array): (x,y,z) local scale of the cube, specified in its local frame\n        particle_positions ((N, 3) array): positions to check for whether it is in the sphere\n\n    Returns:\n        (N,) array: boolean numpy array specifying whether each point lies in the sphere\n    \"\"\"\n    particle_positions = get_particle_positions_in_frame(\n        pos=pos,\n        quat=quat,\n        scale=scale,\n        particle_positions=particle_positions,\n    )\n    return np.linalg.norm(particle_positions, axis=-1) &lt; size\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.check_points_in_sphere"},{"title":"<code>generate_points_in_volume_checker_function(obj, volume_link, use_visual_meshes=True, mesh_name_prefixes=None)</code>","text":"<p>Generates a function for quickly checking which of a group of points are contained within any container volumes.</p>  Four volume types are supported <p>\"Cylinder\" - Cylinder volume \"Cube\" - Cube volume \"Sphere\" - Sphere volume \"Mesh\" - Convex hull volume</p>  <p>@volume_link should have any number of nested, visual-only meshes of types {Sphere, Cylinder, Cube, Mesh} with naming prefix \"container[...]\"</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>EntityPrim</code>  <p>Object which contains @volume_link as one of its links</p>  required    <code>volume_link</code>  <code>RigidPrim</code>  <p>Link to use to grab container volumes composing the values for checking the points</p>  required    <code>use_visual_meshes</code>  <code>bool</code>  <p>Whether to use @volume_link's visual or collision meshes to generate points fcn</p>  <code>True</code>    <code>mesh_name_prefixes</code>  <code>None or str</code>  <p>If specified, specifies the substring that must exist in @volume_link's mesh names in order for that mesh to be included in the volume checker function. If None, no filtering will be used.</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - function: Function with signature:</p> <pre><code>in_range = check_in_volumes(particle_positions)\n</code></pre> <p>where @in_range is a N-array boolean numpy array, (True where the particle is in the volume), and @particle_positions is a (N, 3) array specifying the particle positions in global coordinates</p> <ul> <li> <p>function: Function for grabbing real-time global scale volume of the container. Signature:</p> <p>vol = total_volume()</p> </li> </ul> <p>where @vol is the total volume being checked (expressed in global scale) aggregated across all container sub-volumes</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def generate_points_in_volume_checker_function(obj, volume_link, use_visual_meshes=True, mesh_name_prefixes=None):\n    \"\"\"\n    Generates a function for quickly checking which of a group of points are contained within any container volumes.\n    Four volume types are supported:\n        \"Cylinder\" - Cylinder volume\n        \"Cube\" - Cube volume\n        \"Sphere\" - Sphere volume\n        \"Mesh\" - Convex hull volume\n\n    @volume_link should have any number of nested, visual-only meshes of types {Sphere, Cylinder, Cube, Mesh} with\n    naming prefix \"container[...]\"\n\n    Args:\n        obj (EntityPrim): Object which contains @volume_link as one of its links\n        volume_link (RigidPrim): Link to use to grab container volumes composing the values for checking the points\n        use_visual_meshes (bool): Whether to use @volume_link's visual or collision meshes to generate points fcn\n        mesh_name_prefixes (None or str): If specified, specifies the substring that must exist in @volume_link's\n            mesh names in order for that mesh to be included in the volume checker function. If None, no filtering\n            will be used.\n\n    Returns:\n        2-tuple:\n            - function: Function with signature:\n\n                in_range = check_in_volumes(particle_positions)\n\n            where @in_range is a N-array boolean numpy array, (True where the particle is in the volume), and\n            @particle_positions is a (N, 3) array specifying the particle positions in global coordinates\n\n            - function: Function for grabbing real-time global scale volume of the container. Signature:\n\n                vol = total_volume()\n\n            where @vol is the total volume being checked (expressed in global scale) aggregated across\n            all container sub-volumes\n    \"\"\"\n    # If the object doesn't uniform scale, we make sure the volume link has no relative orientation w.r.t to\n    # the object (root link) frame\n    # TODO: Can we remove this restriction in the future? The current paradigm of how scale operates makes this difficult\n    if (obj.scale.max() - obj.scale.min()) &gt; 1e-3:\n        volume_link_quat = volume_link.get_orientation()\n        object_quat = obj.get_orientation()\n        quat_distance = T.quat_distance(volume_link_quat, object_quat)\n        assert np.isclose(quat_distance[3], 1, atol=1e-3), \\\n            f\"Volume link must have no relative orientation w.r.t the root link! (i.e.: quat distance [0, 0, 0, 1])! \" \\\n            f\"Got quat distance: {quat_distance}\"\n    # Iterate through all visual meshes and keep track of any that are prefixed with container\n    container_meshes = []\n    meshes = volume_link.visual_meshes if use_visual_meshes else volume_link.collision_meshes\n    for container_mesh_name, container_mesh in volume_link.visual_meshes.items():\n        if mesh_name_prefixes is None or mesh_name_prefixes in container_mesh_name:\n            container_meshes.append(container_mesh.prim)\n\n    # Programmatically define the volume checker functions based on each container found\n    volume_checker_fcns = []\n    volume_calc_fcns = []\n    for sub_container_mesh in container_meshes:\n        mesh_type = sub_container_mesh.GetTypeName()\n        if mesh_type == \"Mesh\":\n            # For efficiency, we pre-compute the mesh using trimesh and find its corresponding faces and normals\n            trimesh_mesh = mesh_prim_to_trimesh_mesh(sub_container_mesh)\n            face_centroids = trimesh_mesh.vertices[trimesh_mesh.faces].mean(axis=1)\n            face_normals = trimesh_mesh.face_normals\n\n            # This function assumes that:\n            # 1. @particle_positions are in the local container_link frame\n            # 2. the @check_points_in_[...] function will convert them into the local @mesh frame\n            fcn = lambda mesh, particle_positions: check_points_in_convex_hull_mesh(\n                mesh_face_centroids=face_centroids,\n                mesh_face_normals=face_normals,\n                pos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\n                quat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\n                scale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\n                particle_positions=particle_positions,\n            )\n            vol_fcn = lambda mesh: trimesh_mesh.volume if trimesh_mesh.is_volume else trimesh_mesh.convex_hull.volume\n        elif mesh_type == \"Sphere\":\n            fcn = lambda mesh, particle_positions: check_points_in_sphere(\n                size=mesh.GetAttribute(\"radius\").Get(),\n                pos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\n                quat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\n                scale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\n                particle_positions=particle_positions,\n            )\n            vol_fcn = lambda mesh: 4 / 3 * np.pi * (mesh.GetAttribute(\"radius\").Get() ** 3)\n        elif mesh_type == \"Cylinder\":\n            fcn = lambda mesh, particle_positions: check_points_in_cylinder(\n                size=[mesh.GetAttribute(\"radius\").Get(), mesh.GetAttribute(\"height\").Get()],\n                pos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\n                quat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\n                scale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\n                particle_positions=particle_positions,\n            )\n            vol_fcn = lambda mesh: np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get()\n        elif mesh_type == \"Cone\":\n            fcn = lambda mesh, particle_positions: check_points_in_cone(\n                size=[mesh.GetAttribute(\"radius\").Get(), mesh.GetAttribute(\"height\").Get()],\n                pos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\n                quat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\n                scale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\n                particle_positions=particle_positions,\n            )\n            vol_fcn = lambda mesh: np.pi * (mesh.GetAttribute(\"radius\").Get() ** 2) * mesh.GetAttribute(\"height\").Get() / 3.0\n        elif mesh_type == \"Cube\":\n            fcn = lambda mesh, particle_positions: check_points_in_cube(\n                size=mesh.GetAttribute(\"size\").Get(),\n                pos=np.array(mesh.GetAttribute(\"xformOp:translate\").Get()),\n                quat=np.array([*(mesh.GetAttribute(\"xformOp:orient\").Get().imaginary), mesh.GetAttribute(\"xformOp:orient\").Get().real]),\n                scale=np.array(mesh.GetAttribute(\"xformOp:scale\").Get()),\n                particle_positions=particle_positions,\n            )\n            vol_fcn = lambda mesh: mesh.GetAttribute(\"size\").Get() ** 3\n        else:\n            raise ValueError(f\"Cannot create volume checker function for mesh of type: {mesh_type}\")\n\n        volume_checker_fcns.append(fcn)\n        volume_calc_fcns.append(vol_fcn)\n\n    # Define the actual volume checker function\n    def check_points_in_volumes(particle_positions):\n        # Algo\n        # 1. Particles in global frame --&gt; particles in volume link frame (including scaling)\n        # 2. For each volume checker function, apply volume checking\n        # 3. Aggregate across all functions with OR condition (any volume satisfied for that point)\n        ######\n\n        n_particles = len(particle_positions)\n        # Get pose of origin (global frame) in frame of volume link\n        # NOTE: This assumes there is no relative scaling between obj and volume link\n        volume_link_pos, volume_link_quat = volume_link.get_position_orientation()\n        particle_positions = get_particle_positions_in_frame(\n            pos=volume_link_pos,\n            quat=volume_link_quat,\n            scale=obj.scale,\n            particle_positions=particle_positions,\n        )\n\n        in_volumes = np.zeros(n_particles).astype(bool)\n        for checker_fcn, mesh in zip(volume_checker_fcns, container_meshes):\n            in_volumes |= checker_fcn(mesh, particle_positions)\n\n        return in_volumes\n\n    # Define the actual volume calculator function\n    def calculate_volume():\n        # Aggregate values across all subvolumes\n        # NOTE: Assumes all volumes are strictly disjointed (becuase we sum over all subvolumes to calculate\n        # total raw volume)\n        # TODO: Is there a way we can explicitly check if disjointed?\n        vols = [calc_fcn(mesh) * np.product(mesh.GetAttribute(\"xformOp:scale\").Get())\n                for calc_fcn, mesh in zip(volume_calc_fcns, container_meshes)]\n        # Aggregate over all volumes and scale by the link's global scale\n        return np.sum(vols) * np.product(volume_link.get_world_scale())\n\n    return check_points_in_volumes, calculate_volume\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.generate_points_in_volume_checker_function"},{"title":"<code>get_particle_positions_from_frame(pos, quat, scale, particle_positions)</code>","text":"<p>Transforms particle positions @positions from the frame specified by @pos and @quat with new scale @scale.</p> <p>This is similar to @get_particle_positions_in_frame, but does the reverse operation, inverting @pos and @quat</p> <p>Parameters:</p>    Name Type Description Default     <code>pos</code>  <code>3-array</code>  <p>(x,y,z) pos of the local frame</p>  required    <code>quat</code>  <code>4-array</code>  <p>(x,y,z,w) quaternion orientation of the local frame</p>  required    <code>scale</code>  <code>3-array</code>  <p>(x,y,z) local scale of the local frame</p>  required    <code>particle_positions</code>  <code>N, 3) array</code>  <p>positions</p>  required     <p>Returns:</p>    Type Description       <p>(N,) array: updated particle positions in the parent coordinate frame</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def get_particle_positions_from_frame(pos, quat, scale, particle_positions):\n    \"\"\"\n    Transforms particle positions @positions from the frame specified by @pos and @quat with new scale @scale.\n\n    This is similar to @get_particle_positions_in_frame, but does the reverse operation, inverting @pos and @quat\n\n    Args:\n        pos (3-array): (x,y,z) pos of the local frame\n        quat (4-array): (x,y,z,w) quaternion orientation of the local frame\n        scale (3-array): (x,y,z) local scale of the local frame\n        particle_positions ((N, 3) array): positions\n\n    Returns:\n        (N,) array: updated particle positions in the parent coordinate frame\n    \"\"\"\n    # Scale by the new scale\n    particle_positions = particle_positions * scale.reshape(1, 3)\n\n    # Get pose of origin (global frame) in new_frame\n    origin_in_new_frame = T.pose2mat((pos, quat))\n    # Batch the transforms to get all particle points in the local link frame\n    positions_tensor = np.tile(np.eye(4).reshape(1, 4, 4), (len(particle_positions), 1, 1))  # (N, 4, 4)\n    # Scale by the new scale#\n    positions_tensor[:, :3, 3] = particle_positions\n    return (origin_in_new_frame @ positions_tensor)[:, :3, 3]  # (N, 3)\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.get_particle_positions_from_frame"},{"title":"<code>get_particle_positions_in_frame(pos, quat, scale, particle_positions)</code>","text":"<p>Transforms particle positions @positions into the frame specified by @pos and @quat with new scale @scale, where @pos and @quat are assumed to be specified in the same coordinate frame that @particle_positions is specified</p> <p>Parameters:</p>    Name Type Description Default     <code>pos</code>  <code>3-array</code>  <p>(x,y,z) pos of the new frame</p>  required    <code>quat</code>  <code>4-array</code>  <p>(x,y,z,w) quaternion orientation of the new frame</p>  required    <code>scale</code>  <code>3-array</code>  <p>(x,y,z) local scale of the new frame</p>  required    <code>particle_positions</code>  <code>N, 3) array</code>  <p>positions</p>  required     <p>Returns:</p>    Type Description       <p>(N,) array: updated particle positions in the new coordinate frame</p>     Source code in <code>utils/geometry_utils.py</code> <pre><code>def get_particle_positions_in_frame(pos, quat, scale, particle_positions):\n    \"\"\"\n    Transforms particle positions @positions into the frame specified by @pos and @quat with new scale @scale,\n    where @pos and @quat are assumed to be specified in the same coordinate frame that @particle_positions is specified\n\n    Args:\n        pos (3-array): (x,y,z) pos of the new frame\n        quat (4-array): (x,y,z,w) quaternion orientation of the new frame\n        scale (3-array): (x,y,z) local scale of the new frame\n        particle_positions ((N, 3) array): positions\n\n    Returns:\n        (N,) array: updated particle positions in the new coordinate frame\n    \"\"\"\n\n    # Get pose of origin (global frame) in new_frame\n    origin_in_new_frame = T.pose_inv(T.pose2mat((pos, quat)))\n    # Batch the transforms to get all particle points in the local link frame\n    positions_tensor = np.tile(np.eye(4).reshape(1, 4, 4), (len(particle_positions), 1, 1))  # (N, 4, 4)\n    # Scale by the new scale#\n    positions_tensor[:, :3, 3] = particle_positions\n    particle_positions = (origin_in_new_frame @ positions_tensor)[:, :3, 3]  # (N, 3)\n    # Scale by the new scale\n    return particle_positions / scale.reshape(1, 3)\n</code></pre>","location":"reference/utils/geometry_utils.html#utils.geometry_utils.get_particle_positions_in_frame"},{"title":"git_utils","text":"","location":"reference/utils/git_utils.html"},{"title":"gym_utils","text":"","location":"reference/utils/gym_utils.html"},{"title":"<code>GymObservable</code>","text":"<p>Simple class interface for observable objects. These objects should implement a way to grab observations, (get_obs()), and should define an observation space that is created when load_observation_space() is called</p> <p>Parameters:</p>    Name Type Description Default     <code>kwargs</code>   <p>dict, does nothing, used to sink any extraneous arguments during initialization</p>  <code>{}</code>      Source code in <code>utils/gym_utils.py</code> <pre><code>class GymObservable(metaclass=ABCMeta):\n    \"\"\"\n    Simple class interface for observable objects. These objects should implement a way to grab observations,\n    (get_obs()), and should define an observation space that is created when load_observation_space() is called\n\n    Args:\n        kwargs: dict, does nothing, used to sink any extraneous arguments during initialization\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        # Initialize variables that we will fill in later\n        self.observation_space = None\n\n        # Call any super methods\n        super().__init__(*args, **kwargs)\n\n    @abstractmethod\n    def get_obs(self, **kwargs):\n        \"\"\"\n        Get observations for the object. Note that the shape / nested structure should match that\n        of @self.observation_space!\n\n        Args:\n            kwargs (dict): Any keyword args necessary for grabbing observations\n\n        Returns:\n            OrderedDict: Keyword-mapped observations mapping observation names to nested observations\n        \"\"\"\n        raise NotImplementedError()\n\n    @staticmethod\n    def _build_obs_box_space(shape, low, high, dtype=np.float32):\n        \"\"\"\n        Helper function that builds individual observation box spaces.\n\n        Args:\n            shape (n-array): Shape of the space\n            low (float): Lower bound of the space\n            high (float): Upper bound of the space\n\n        Returns:\n            gym.spaces.Box: Generated gym box observation space\n        \"\"\"\n        return gym.spaces.Box(low=low, high=high, shape=shape, dtype=dtype)\n\n    @abstractmethod\n    def _load_observation_space(self):\n        \"\"\"\n        Create the observation space for this object. Should be implemented by subclass\n\n        Returns:\n            OrderedDict: Keyword-mapped observation space for this object mapping observation name to observation space\n        \"\"\"\n        raise NotImplementedError()\n\n    def load_observation_space(self):\n        \"\"\"\n        Load the observation space internally, and also return this value\n\n        Returns:\n            gym.spaces.Dict: Loaded observation space for this object\n        \"\"\"\n        # Load the observation space and convert it into a gym-compatible dictionary\n        self.observation_space = gym.spaces.Dict(self._load_observation_space())\n        print(f\"Loaded obs space dictionary for: {self.__class__.__name__}\")\n\n        return self.observation_space\n</code></pre>","location":"reference/utils/gym_utils.html#utils.gym_utils.GymObservable"},{"title":"<code>get_obs(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Get observations for the object. Note that the shape / nested structure should match that of @self.observation_space!</p> <p>Parameters:</p>    Name Type Description Default     <code>kwargs</code>  <code>dict</code>  <p>Any keyword args necessary for grabbing observations</p>  <code>{}</code>     <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Keyword-mapped observations mapping observation names to nested observations</p>     Source code in <code>utils/gym_utils.py</code> <pre><code>@abstractmethod\ndef get_obs(self, **kwargs):\n    \"\"\"\n    Get observations for the object. Note that the shape / nested structure should match that\n    of @self.observation_space!\n\n    Args:\n        kwargs (dict): Any keyword args necessary for grabbing observations\n\n    Returns:\n        OrderedDict: Keyword-mapped observations mapping observation names to nested observations\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/utils/gym_utils.html#utils.gym_utils.GymObservable.get_obs"},{"title":"<code>load_observation_space()</code>","text":"<p>Load the observation space internally, and also return this value</p> <p>Returns:</p>    Type Description       <p>gym.spaces.Dict: Loaded observation space for this object</p>     Source code in <code>utils/gym_utils.py</code> <pre><code>def load_observation_space(self):\n    \"\"\"\n    Load the observation space internally, and also return this value\n\n    Returns:\n        gym.spaces.Dict: Loaded observation space for this object\n    \"\"\"\n    # Load the observation space and convert it into a gym-compatible dictionary\n    self.observation_space = gym.spaces.Dict(self._load_observation_space())\n    print(f\"Loaded obs space dictionary for: {self.__class__.__name__}\")\n\n    return self.observation_space\n</code></pre>","location":"reference/utils/gym_utils.html#utils.gym_utils.GymObservable.load_observation_space"},{"title":"object_state_utils","text":"","location":"reference/utils/object_state_utils.html"},{"title":"<code>sample_kinematics(predicate, objA, objB, use_ray_casting_method=False, max_trials=10, z_offset=0.05, skip_falling=False)</code>","text":"<p>Samples the given @predicate kinematic state for @objA with respect to @objB</p> <p>Parameters:</p>    Name Type Description Default     <code>predicate</code>  <code>str</code>  <p>Name of the predicate to sample, e.g.: \"onTop\"</p>  required    <code>objA</code>  <code>StatefulObject</code>  <p>Object whose state should be sampled. e.g.: for sampling a microwave on a cabinet, @objA is the microwave</p>  required    <code>objB</code>  <code>StatefulObject</code>  <p>Object who is the reference point for @objA's state. e.g.: for sampling a microwave on a cabinet, @objB is the cabinet</p>  required    <code>use_ray_casting_method</code>  <code>bool</code>  <p>Whether to use raycasting for sampling or not</p>  <code>False</code>    <code>max_trials</code>  <code>int</code>  <p>Number of attempts for sampling</p>  <code>10</code>    <code>z_offset</code>  <code>float</code>  <p>Z-offset to apply to the sampled pose</p>  <code>0.05</code>    <code>skip_falling</code>  <code>bool</code>  <p>Whether to let @objA fall after its position is sampled or not</p>  <code>False</code>     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if successfully sampled, else False</p>     Source code in <code>utils/object_state_utils.py</code> <pre><code>def sample_kinematics(\n    predicate,\n    objA,\n    objB,\n    use_ray_casting_method=False,\n    max_trials=10,\n    z_offset=0.05,\n    skip_falling=False,\n):\n    \"\"\"\n    Samples the given @predicate kinematic state for @objA with respect to @objB\n\n    Args:\n        predicate (str): Name of the predicate to sample, e.g.: \"onTop\"\n        objA (StatefulObject): Object whose state should be sampled. e.g.: for sampling a microwave\n            on a cabinet, @objA is the microwave\n        objB (StatefulObject): Object who is the reference point for @objA's state. e.g.: for sampling\n            a microwave on a cabinet, @objB is the cabinet\n        use_ray_casting_method (bool): Whether to use raycasting for sampling or not\n        max_trials (int): Number of attempts for sampling\n        z_offset (float): Z-offset to apply to the sampled pose\n        skip_falling (bool): Whether to let @objA fall after its position is sampled or not\n\n    Returns:\n        bool: True if successfully sampled, else False\n    \"\"\"\n\n    assert z_offset &gt; 0.5 * 9.81 * (og.sim.get_physics_dt() ** 2) + 0.02,\\\n        f\"z_offset {z_offset} is too small for the current physics_dt {og.sim.get_physics_dt()}\"\n\n    # Run import here to avoid circular imports\n    # No supporting surface annotation found, fallback to use ray-casting\n    from omnigibson.objects.dataset_object import DatasetObject\n    if (\n        not isinstance(objB, DatasetObject) or\n        len(objB.supporting_surfaces) == 0 or\n        predicate not in objB.supporting_surfaces\n    ):\n        use_ray_casting_method = True\n\n    # Wake objects accordingly and make sure both are kept still\n    objA.wake()\n    objB.wake()\n\n    objA.keep_still()\n    objB.keep_still()\n\n    # Save the state of the simulator\n    state = og.sim.dump_state()\n\n    # Attempt sampling\n    for i in range(max_trials):\n        pos = None\n        if hasattr(objA, \"orientations\") and objA.orientations is not None:\n            orientation = objA.sample_orientation()\n        else:\n            orientation = np.array([0, 0, 0, 1.0])\n\n        # Orientation needs to be set for stable_z_on_aabb to work correctly\n        # Position needs to be set to be very far away because the object's\n        # original position might be blocking rays (use_ray_casting_method=True)\n        old_pos = np.array([200, 200, 200])\n        objA.set_position_orientation(old_pos, orientation)\n        objA.keep_still()\n        # We also need to step physics to make sure the pose propagates downstream (e.g.: to Bounding Box computations)\n        og.sim.step_physics()\n\n        # This would slightly change because of the step_physics call.\n        old_pos, orientation = objA.get_position_orientation()\n\n        if use_ray_casting_method:\n            if predicate == \"onTop\":\n                params = m.ON_TOP_RAY_CASTING_SAMPLING_PARAMS\n            elif predicate == \"inside\":\n                params = m.INSIDE_RAY_CASTING_SAMPLING_PARAMS\n            else:\n                raise ValueError(f\"predicate must be either onTop or inside in order to use ray casting-based \"\n                                 f\"kinematic sampling, but instead got: {predicate}\")\n\n            # Run import here to avoid circular imports\n            from omnigibson.objects.dataset_object import DatasetObject\n            if isinstance(objA, DatasetObject):\n                # Retrieve base CoM frame-aligned bounding box parallel to the XY plane\n                parallel_bbox_center, parallel_bbox_orn, parallel_bbox_extents, _ = objA.get_base_aligned_bbox(\n                    xy_aligned=True\n                )\n            else:\n                aabb_lower, aabb_upper = objA.states[AABB].get_value()\n                parallel_bbox_center = (aabb_lower + aabb_upper) / 2.0\n                parallel_bbox_orn = np.array([0.0, 0.0, 0.0, 1.0])\n                parallel_bbox_extents = aabb_upper - aabb_lower\n\n            sampling_results = sampling_utils.sample_cuboid_on_object_symmetric_bimodal_distribution(\n                objB,\n                num_samples=1,\n                cuboid_dimensions=parallel_bbox_extents,\n                axis_probabilities=[0, 0, 1],\n                refuse_downwards=True,\n                undo_cuboid_bottom_padding=True,\n                **params,\n            )\n\n            sampled_vector = sampling_results[0][0]\n            sampled_quaternion = sampling_results[0][2]\n\n            sampling_success = sampled_vector is not None\n            if sampling_success:\n                # Move the object from the original parallel bbox to the sampled bbox\n                parallel_bbox_rotation = R.from_quat(parallel_bbox_orn)\n                sample_rotation = R.from_quat(sampled_quaternion)\n                original_rotation = R.from_quat(orientation)\n\n                # The additional orientation to be applied should be the delta orientation\n                # between the parallel bbox orientation and the sample orientation\n                additional_rotation = sample_rotation * parallel_bbox_rotation.inv()\n                combined_rotation = additional_rotation * original_rotation\n                orientation = combined_rotation.as_quat()\n\n                # The delta vector between the base CoM frame and the parallel bbox center needs to be rotated\n                # by the same additional orientation\n                diff = old_pos - parallel_bbox_center\n                rotated_diff = additional_rotation.apply(diff)\n                pos = sampled_vector + rotated_diff\n        else:\n            random_idx = np.random.randint(len(objB.supporting_surfaces[predicate].keys()))\n            objB_link_name = list(objB.supporting_surfaces[predicate].keys())[random_idx]\n            random_height_idx = np.random.randint(len(objB.supporting_surfaces[predicate][objB_link_name]))\n            height, height_map = objB.supporting_surfaces[predicate][objB_link_name][random_height_idx]\n            obj_half_size = np.max(objA.aabb_extent) / 2 * 100\n            obj_half_size_scaled = np.array([obj_half_size / objB.scale[1], obj_half_size / objB.scale[0]])\n            obj_half_size_scaled = np.ceil(obj_half_size_scaled).astype(np.int)\n            height_map_eroded = cv2.erode(height_map, np.ones(obj_half_size_scaled, np.uint8))\n\n            valid_pos = np.array(height_map_eroded.nonzero())\n            if valid_pos.shape[1] != 0:\n                random_pos_idx = np.random.randint(valid_pos.shape[1])\n                random_pos = valid_pos[:, random_pos_idx]\n                y_map, x_map = random_pos\n                y = y_map / 100.0 - 2\n                x = x_map / 100.0 - 2\n                z = height\n\n                pos = np.array([x, y, z])\n                pos *= objB.scale\n\n                # the supporting surface is defined w.r.t to the link frame, so we need to convert it into\n                # the world frame\n                link_pos, link_quat = objB.links[objB_link_name].get_position_orientation()\n                pos = T.quat2mat(link_quat).dot(pos) + np.array(link_pos)\n                # Get the combined AABB.\n                lower, _ = objA.states[AABB].get_value()\n                # Move the position to a stable Z for the object.\n                pos[2] += objA.get_position()[2] - lower[2]\n\n        if pos is None:\n            success = False\n        else:\n            pos[2] += z_offset\n            objA.set_position_orientation(pos, orientation)\n            objA.keep_still()\n\n            og.sim.step_physics()\n            success = not objA.in_contact()\n\n        if og.debug_sampling:\n            print(\"sample_kinematics\", success)\n            embed()\n\n        if success:\n            break\n        else:\n            og.sim.load_state(state)\n\n    if success and not skip_falling:\n        objA.set_position_orientation(pos, orientation)\n        objA.keep_still()\n\n        # Let it fall for 0.2 second\n        for _ in range(int(0.2 / og.sim.get_physics_dt())):\n            og.sim.step_physics()\n            if objA.in_contact():\n                break\n\n        # Render at the end\n        og.sim.render()\n\n    return success\n</code></pre>","location":"reference/utils/object_state_utils.html#utils.object_state_utils.sample_kinematics"},{"title":"physx_utils","text":"","location":"reference/utils/physx_utils.html"},{"title":"<code>bind_material(prim_path, material_path)</code>","text":"<p>Binds material located at @material_path to the prim located at @prim_path.</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Stage path to prim to bind material to</p>  required    <code>material_path</code>  <code>str</code>  <p>Stage path to material to be bound</p>  required      Source code in <code>utils/physx_utils.py</code> <pre><code>def bind_material(prim_path, material_path):\n    \"\"\"\n    Binds material located at @material_path to the prim located at @prim_path.\n\n    Args:\n        prim_path (str): Stage path to prim to bind material to\n        material_path (str): Stage path to material to be bound\n    \"\"\"\n    omni.kit.commands.execute(\n        \"BindMaterialCommand\",\n        prim_path=prim_path,\n        material_path=material_path,\n        strength=None,\n    )\n</code></pre>","location":"reference/utils/physx_utils.html#utils.physx_utils.bind_material"},{"title":"<code>create_physx_particle_system(prim_path, physics_scene_path, particle_contact_offset, visual_only=False, smoothing=True, anisotropy=True, isosurface=True)</code>","text":"<p>Creates an Omniverse physx particle system at @prim_path. For post-processing visualization effects (anisotropy, smoothing, isosurface), see the Omniverse documentation (https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#post-processing-for-fluid-rendering) for more info</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Stage path to where particle system should be created</p>  required    <code>physics_scene_path</code>  <code>str</code>  <p>Stage path to where active physicsScene prim is defined</p>  required    <code>particle_contact_offset</code>  <code>float</code>  <p>Distance between particles which triggers a collision (m)</p>  required    <code>visual_only</code>  <code>bool</code>  <p>If True, will disable collisions between particles and non-particles, as well as self-collisions</p>  <code>False</code>    <code>smoothing</code>  <code>bool</code>  <p>Whether to smooth particle positions or not</p>  <code>True</code>    <code>anisotropy</code>  <code>bool</code>  <p>Whether to apply anisotropy post-processing when visualizing particles. Stretches generated particles in order to make the particle cluster surface appear smoother. Useful for fluids</p>  <code>True</code>    <code>isosurface</code>  <code>bool</code>  <p>Whether to apply isosurface mesh to visualize particles. Uses a monolithic surface that can have materials attached to it, useful for visualizing fluids</p>  <code>True</code>     <p>Returns:</p>    Type Description       <p>UsdGeom.PhysxParticleSystem: Generated particle system prim</p>     Source code in <code>utils/physx_utils.py</code> <pre><code>def create_physx_particle_system(\n    prim_path,\n    physics_scene_path,\n    particle_contact_offset,\n    visual_only=False,\n    smoothing=True,\n    anisotropy=True,\n    isosurface=True,\n):\n    \"\"\"\n    Creates an Omniverse physx particle system at @prim_path. For post-processing visualization effects (anisotropy,\n    smoothing, isosurface), see the Omniverse documentation\n    (https://docs.omniverse.nvidia.com/app_create/prod_extensions/ext_physics.html?highlight=isosurface#post-processing-for-fluid-rendering)\n    for more info\n\n    Args:\n        prim_path (str): Stage path to where particle system should be created\n        physics_scene_path (str): Stage path to where active physicsScene prim is defined\n        particle_contact_offset (float): Distance between particles which triggers a collision (m)\n        visual_only (bool): If True, will disable collisions between particles and non-particles,\n            as well as self-collisions\n        smoothing (bool): Whether to smooth particle positions or not\n        anisotropy (bool): Whether to apply anisotropy post-processing when visualizing particles. Stretches generated\n            particles in order to make the particle cluster surface appear smoother. Useful for fluids\n        isosurface (bool): Whether to apply isosurface mesh to visualize particles. Uses a monolithic surface that\n            can have materials attached to it, useful for visualizing fluids\n\n    Returns:\n        UsdGeom.PhysxParticleSystem: Generated particle system prim\n    \"\"\"\n    # TODO: Add sanity check to make sure GPU dynamics are enabled\n    # Create particle system\n    stage = get_current_stage()\n    particle_system = PhysxSchema.PhysxParticleSystem.Define(stage, prim_path)\n    particle_system.CreateSimulationOwnerRel().SetTargets([physics_scene_path])\n\n    # Use a smaller particle size for nicer fluid, and let the sim figure out the other offsets\n    particle_system.CreateParticleContactOffsetAttr().Set(particle_contact_offset)\n\n    # Possibly disable collisions if we're only visual\n    if visual_only:\n        particle_system.GetGlobalSelfCollisionEnabledAttr().Set(False)\n        particle_system.GetNonParticleCollisionEnabledAttr().Set(False)\n\n    if anisotropy:\n        # apply api and use all defaults\n        PhysxSchema.PhysxParticleAnisotropyAPI.Apply(particle_system.GetPrim())\n\n    if smoothing:\n        # apply api and use all defaults\n        PhysxSchema.PhysxParticleSmoothingAPI.Apply(particle_system.GetPrim())\n\n    if isosurface:\n        # apply api and use all defaults\n        PhysxSchema.PhysxParticleIsosurfaceAPI.Apply(particle_system.GetPrim())\n        # Make sure we're not casting shadows\n        primVarsApi = UsdGeom.PrimvarsAPI(particle_system.GetPrim())\n        primVarsApi.CreatePrimvar(\"doNotCastShadows\", Sdf.ValueTypeNames.Bool).Set(True)\n        # tweak anisotropy min, max, and scale to work better with isosurface:\n        if anisotropy:\n            ani_api = PhysxSchema.PhysxParticleAnisotropyAPI.Apply(particle_system.GetPrim())\n            ani_api.CreateScaleAttr().Set(5.0)\n            ani_api.CreateMinAttr().Set(1.0)  # avoids gaps in surface\n            ani_api.CreateMaxAttr().Set(2.0)\n\n    return particle_system\n</code></pre>","location":"reference/utils/physx_utils.html#utils.physx_utils.create_physx_particle_system"},{"title":"<code>create_physx_particleset_pointinstancer(name, particle_system_path, particle_group, positions, self_collision=True, fluid=False, particle_mass=None, particle_density=None, orientations=None, velocities=None, angular_velocities=None, scales=None, prototype_prim_paths=None, prototype_indices=None, enabled=True)</code>","text":"<p>Creates a particle set instancer based on a UsdGeom.PointInstancer at @prim_path on the current stage, with the specified parameters.</p> <p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>Name for this point instancer</p>  required    <code>particle_system_path</code>  <code>str</code>  <p>Stage path to particle system that simulates the set</p>  required    <code>particle_group</code>  <code>int</code>  <p>ID for this particle set. Particles from different groups will automatically collide with each other. Particles in the same group will have collision behavior dictated by @self_collision</p>  required    <code>positions</code>  <code>list of 3-tuple or np.array</code>  <p>Particle (x,y,z) positions either as a list or a (N, 3) numpy array</p>  required    <code>self_collision</code>  <code>bool</code>  <p>Whether to enable particle-particle collision within the set (as defined by @particle_group) or not</p>  <code>True</code>    <code>fluid</code>  <code>bool</code>  <p>Whether to simulated the particle set as fluid or not</p>  <code>False</code>    <code>particle_mass</code>  <code>None or float</code>  <p>If specified, should be per-particle mass. Otherwise, will be inferred from @density. Note: Either @particle_mass or @particle_density must be specified!</p>  <code>None</code>    <code>particle_density</code>  <code>None or float</code>  <p>If specified, should be per-particle density and is used to compute total point set mass. Otherwise, will be inferred from @density. Note: Either @particle_mass or @particle_density must be specified!</p>  <code>None</code>    <code>orientations</code>  <code>None or list of 4-array or np.array</code>  <p>Particle (x,y,z,w) quaternion orientations, either as a list or a (N, 4) numpy array. If not specified, all will be set to canonical orientation (0, 0, 0, 1)</p>  <code>None</code>    <code>velocities</code>  <code>None or list of 3-array or np.array</code>  <p>Particle (x,y,z) velocities either as a list or a (N, 3) numpy array. If not specified, all will be set to 0</p>  <code>None</code>    <code>angular_velocities</code>  <code>None or list of 3-array or np.array</code>  <p>Particle (x,y,z) angular velocities either as a list or a (N, 3) numpy array. If not specified, all will be set to 0</p>  <code>None</code>    <code>scales</code>  <code>None or list of 3-array or np.array</code>  <p>Particle (x,y,z) scales either as a list or a (N, 3) numpy array. If not specified, all will be set to 1.0</p>  <code>None</code>    <code>prototype_prim_paths</code>  <code>None or str or list of str</code>  <p>Stage path(s) to the prototypes to reference for this particle set. If None, will generate a default sphere called \"particlePrototype\" as the prototype.</p>  <code>None</code>    <code>prototype_indices</code>  <code>None or list of int</code>  <p>If specified, should specify which prototype should be used for each particle. If None, will use all 0s (i.e.: the first prototype created)</p>  <code>None</code>    <code>enabled</code>  <code>bool</code>  <p>Whether to enable this particle instancer. If not enabled, then no physics will be used</p>  <code>True</code>     <p>Returns:</p>    Type Description      <code>Usd.Prim</code>  <p>UsdGeom.PointInstancer: Created point instancer prim</p>     Source code in <code>utils/physx_utils.py</code> <pre><code>def create_physx_particleset_pointinstancer(\n    name,\n    particle_system_path,\n    particle_group,\n    positions,\n    self_collision=True,\n    fluid=False,\n    particle_mass=None,\n    particle_density=None,\n    orientations=None,\n    velocities=None,\n    angular_velocities=None,\n    scales=None,\n    prototype_prim_paths=None,\n    prototype_indices=None,\n    enabled=True,\n) -&gt; Usd.Prim:\n    \"\"\"\n    Creates a particle set instancer based on a UsdGeom.PointInstancer at @prim_path on the current stage, with\n    the specified parameters.\n\n    Args:\n        name (str): Name for this point instancer\n        particle_system_path (str): Stage path to particle system that simulates the set\n        particle_group (int): ID for this particle set. Particles from different groups will automatically collide\n            with each other. Particles in the same group will have collision behavior dictated by @self_collision\n        positions (list of 3-tuple or np.array): Particle (x,y,z) positions either as a list or a (N, 3) numpy array\n        self_collision (bool): Whether to enable particle-particle collision within the set\n            (as defined by @particle_group) or not\n        fluid (bool): Whether to simulated the particle set as fluid or not\n        particle_mass (None or float): If specified, should be per-particle mass. Otherwise, will be\n            inferred from @density. Note: Either @particle_mass or @particle_density must be specified!\n        particle_density (None or float): If specified, should be per-particle density and is used to compute total\n            point set mass. Otherwise, will be inferred from @density. Note: Either @particle_mass or\n            @particle_density must be specified!\n        orientations (None or list of 4-array or np.array): Particle (x,y,z,w) quaternion orientations, either as a\n            list or a (N, 4) numpy array. If not specified, all will be set to canonical orientation (0, 0, 0, 1)\n        velocities (None or list of 3-array or np.array): Particle (x,y,z) velocities either as a list or a (N, 3)\n            numpy array. If not specified, all will be set to 0\n        angular_velocities (None or list of 3-array or np.array): Particle (x,y,z) angular velocities either as a\n            list or a (N, 3) numpy array. If not specified, all will be set to 0\n        scales (None or list of 3-array or np.array): Particle (x,y,z) scales either as a list or a (N, 3)\n            numpy array. If not specified, all will be set to 1.0\n        prototype_prim_paths (None or str or list of str): Stage path(s) to the prototypes to reference for this\n            particle set. If None, will generate a default sphere called \"particlePrototype\" as the prototype.\n        prototype_indices (None or list of int): If specified, should specify which prototype should be used for\n            each particle. If None, will use all 0s (i.e.: the first prototype created)\n        enabled (bool): Whether to enable this particle instancer. If not enabled, then no physics will be used\n\n    Returns:\n        UsdGeom.PointInstancer: Created point instancer prim\n    \"\"\"\n    stage = get_current_stage()\n    n_particles = len(positions)\n    particle_system = get_prim_at_path(particle_system_path)\n\n    # Make sure no prototype doesn't already exist at this point\n    prim_path = f\"{particle_system_path}/{name}\"\n    assert not stage.GetPrimAtPath(prim_path), f\"Cannot create PointInstancer prim, prim already exists at {prim_path}!\"\n\n    # Create point instancer\n    assert not stage.GetPrimAtPath(prim_path)\n    instancer = UsdGeom.PointInstancer.Define(stage, prim_path)\n\n    # Create particle instance prototypes if none are specified\n    prototype_root_path = f\"{get_prototype_path_from_particle_system_path(particle_system_path=particle_system_path)}/{name}\"\n    stage.DefinePrim(prototype_root_path, \"Scope\")\n    if prototype_prim_paths is None:\n        prototype_path = f\"{prototype_root_path}/particlePrototype\"\n        UsdGeom.Sphere.Define(stage, prototype_path)\n        prototype_prim_paths = [prototype_path]\n    else:\n        # We copy the prototypes at the prims\n        # We need to make copies currently because omni behavior is weird (frozen particles)\n        # if multiple instancers share the same prototype prim for some reason\n        new_prototype_prim_paths = []\n        for i, p_path in enumerate(prototype_prim_paths):\n            new_path = f\"{prototype_root_path}/particlePrototype{i}\"\n            omni.kit.commands.execute(\"CopyPrim\", path_from=p_path, path_to=new_path)\n            new_prototype_prim_paths.append(new_path)\n        prototype_prim_paths = new_prototype_prim_paths\n\n    # Add prototype mesh prim paths to the prototypes relationship attribute for this point set\n    # We also hide the prototype if we're using an isosurface\n    mesh_list = instancer.GetPrototypesRel()\n    is_isosurface = particle_system.HasAPI(PhysxSchema.PhysxParticleIsosurfaceAPI) and \\\n                    particle_system.GetAttribute(\"physxParticleIsosurface:isosurfaceEnabled\").Get()\n\n    for prototype_prim_path in prototype_prim_paths:\n        # Make sure this prim is visible first if we're not using isosurface\n        if is_isosurface:\n            UsdGeom.Imageable(get_prim_at_path(prototype_prim_path)).MakeInvisible()\n        else:\n            UsdGeom.Imageable(get_prim_at_path(prototype_prim_path)).MakeVisible()\n        # Add target\n        mesh_list.AddTarget(Sdf.Path(prototype_prim_path))\n\n    # Set particle instance default data\n    prototype_indices = [0] * n_particles if prototype_indices is None else prototype_indices\n    if orientations is None:\n        orientations = np.zeros((n_particles, 4))\n        orientations[:, -1] = 1.0\n    orientations = np.array(orientations)[:, [3, 0, 1, 2]]  # x,y,z,w --&gt; w,x,y,z\n    velocities = np.zeros((n_particles, 3)) if velocities is None else velocities\n    angular_velocities = np.zeros((n_particles, 3)) if angular_velocities is None else angular_velocities\n    scales = np.ones((n_particles, 3)) if scales is None else scales\n    assert particle_mass is not None or particle_density is not None, \\\n        \"Either particle mass or particle density must be specified when creating particle instancer!\"\n    particle_mass = 0.0 if particle_mass is None else particle_mass\n    particle_density = 0.0 if particle_density is None else particle_density\n\n    # Set particle states\n    instancer.GetProtoIndicesAttr().Set(prototype_indices)\n    instancer.GetPositionsAttr().Set(array_to_vtarray(arr=positions, element_type=Gf.Vec3f))\n    instancer.GetOrientationsAttr().Set(array_to_vtarray(arr=orientations, element_type=Gf.Quath))\n    instancer.GetVelocitiesAttr().Set(array_to_vtarray(arr=velocities, element_type=Gf.Vec3f))\n    instancer.GetAngularVelocitiesAttr().Set(array_to_vtarray(arr=angular_velocities, element_type=Gf.Vec3f))\n    instancer.GetScalesAttr().Set(array_to_vtarray(arr=scales, element_type=Gf.Vec3f))\n\n    instancer_prim = instancer.GetPrim()\n\n    particleUtils.configure_particle_set(\n        instancer_prim,\n        particle_system_path,\n        self_collision,\n        fluid,\n        particle_group,\n        particle_mass * n_particles,\n        particle_density,\n    )\n\n    # Set whether the instancer is enabled or not\n    instancer_prim.GetAttribute(\"physxParticle:particleEnabled\").Set(enabled)\n\n    # Add ability to translate instancer as well\n    physicsUtils.set_or_add_translate_op(instancer, Gf.Vec3f(0, 0, 0))\n\n    if is_isosurface:\n        # We have to update the physics for a single step here, and then pause the simulator and take an additional sim\n        # step in order for the isosurface to be rendered correctly! (empirically validated, idk why)\n        # TODO: Follow-up / cleanup with omni team to see if this is expected BEHAVIOR\n        og.sim.step_physics()\n        with og.sim.paused():\n            og.app.update()\n\n    return instancer_prim\n</code></pre>","location":"reference/utils/physx_utils.html#utils.physx_utils.create_physx_particleset_pointinstancer"},{"title":"<code>get_prototype_path_from_particle_system_path(particle_system_path)</code>","text":"<p>Grabs the particle prototype directory prim path from the particle system path. This is different from before because Omni no longer allows for meshes to be nested within each other.</p> <p>Parameters:</p>    Name Type Description Default     <code>particle_system_path</code>  <code>str</code>  <p>Prim path to the particle system of interest</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Corresponding directory to the particle system's prototypes</p>     Source code in <code>utils/physx_utils.py</code> <pre><code>def get_prototype_path_from_particle_system_path(particle_system_path):\n    \"\"\"\n    Grabs the particle prototype directory prim path from the particle system path. This is different from before\n    because Omni no longer allows for meshes to be nested within each other.\n\n    Args:\n        particle_system_path (str): Prim path to the particle system of interest\n\n    Returns:\n        str: Corresponding directory to the particle system's prototypes\n    \"\"\"\n    return f\"{particle_system_path}Prototypes\"\n</code></pre>","location":"reference/utils/physx_utils.html#utils.physx_utils.get_prototype_path_from_particle_system_path"},{"title":"processing_utils","text":"","location":"reference/utils/processing_utils.html"},{"title":"<code>ExponentialAverageFilter</code>","text":"<p>         Bases: <code>Filter</code></p> <p>This class uses an exponential average of the form y_n = alpha * x_n + (1 - alpha) * y_{n - 1}. This is an IIR filter.</p>  Source code in <code>utils/processing_utils.py</code> <pre><code>class ExponentialAverageFilter(Filter):\n    \"\"\"\n    This class uses an exponential average of the form y_n = alpha * x_n + (1 - alpha) * y_{n - 1}.\n    This is an IIR filter.\n    \"\"\"\n\n    def __init__(self, obs_dim, alpha=0.9):\n        \"\"\"\n\n        Args:\n            obs_dim (int): The dimension of the points to filter.\n            alpha (float): The relative weighting of new samples relative to older samples\n        \"\"\"\n        self.obs_dim = obs_dim\n        self.avg = np.zeros(obs_dim)\n        self.num_samples = 0\n        self.alpha = alpha\n\n        super().__init__()\n\n    def estimate(self, observation):\n        \"\"\"\n        Do an online hold for state estimation given a recent observation.\n\n        Args:\n            observation (n-array): New observation to hold internal estimate of state.\n\n        Returns:\n            n-array: New estimate of state.\n        \"\"\"\n        self.avg = self.alpha * observation + (1.0 - self.alpha) * self.avg\n        self.num_samples += 1\n\n        return np.array(self.avg)\n\n    def reset(self):\n        # Clear internal state\n        self.avg *= 0.0\n        self.num_samples = 0\n\n    @property\n    def state_size(self):\n        return super().state_size + self.obs_dim + 1\n\n    def _dump_state(self):\n        # Run super init first\n        state = super()._dump_state()\n\n        # Add info from this filter\n        state[\"avg\"] = np.array(self.avg)\n        state[\"num_samples\"] = self.num_samples\n\n        return state\n\n    def _load_state(self, state):\n        # Run super first\n        super()._load_state(state=state)\n\n        # Load relevant info for this filter\n        self.avg = np.array(state[\"avg\"])\n        self.num_samples = state[\"num_samples\"]\n\n    def _serialize(self, state):\n        # Run super first\n        state_flat = super()._serialize(state=state)\n\n        # Serialize state for this filter\n        return np.concatenate([\n            state_flat,\n            state[\"avg\"],\n            [state[\"num_samples\"]],\n        ]).astype(float)\n\n    def _deserialize(self, state):\n        # Run super first\n        state_dict, idx = super()._deserialize(state=state)\n\n        # Deserialize state for this filter\n        state_dict[\"avg\"] = state[idx: idx + self.obs_dim]\n        state_dict[\"num_samples\"] = int(state[idx + self.obs_dim])\n\n        return state_dict, idx + self.obs_dim + 1\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.ExponentialAverageFilter"},{"title":"<code>__init__(obs_dim, alpha=0.9)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>obs_dim</code>  <code>int</code>  <p>The dimension of the points to filter.</p>  required    <code>alpha</code>  <code>float</code>  <p>The relative weighting of new samples relative to older samples</p>  <code>0.9</code>      Source code in <code>utils/processing_utils.py</code> <pre><code>def __init__(self, obs_dim, alpha=0.9):\n    \"\"\"\n\n    Args:\n        obs_dim (int): The dimension of the points to filter.\n        alpha (float): The relative weighting of new samples relative to older samples\n    \"\"\"\n    self.obs_dim = obs_dim\n    self.avg = np.zeros(obs_dim)\n    self.num_samples = 0\n    self.alpha = alpha\n\n    super().__init__()\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.ExponentialAverageFilter.__init__"},{"title":"<code>estimate(observation)</code>","text":"<p>Do an online hold for state estimation given a recent observation.</p> <p>Parameters:</p>    Name Type Description Default     <code>observation</code>  <code>n-array</code>  <p>New observation to hold internal estimate of state.</p>  required     <p>Returns:</p>    Type Description       <p>n-array: New estimate of state.</p>     Source code in <code>utils/processing_utils.py</code> <pre><code>def estimate(self, observation):\n    \"\"\"\n    Do an online hold for state estimation given a recent observation.\n\n    Args:\n        observation (n-array): New observation to hold internal estimate of state.\n\n    Returns:\n        n-array: New estimate of state.\n    \"\"\"\n    self.avg = self.alpha * observation + (1.0 - self.alpha) * self.avg\n    self.num_samples += 1\n\n    return np.array(self.avg)\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.ExponentialAverageFilter.estimate"},{"title":"<code>Filter</code>","text":"<p>         Bases: <code>Serializable</code></p> <p>A base class for filtering a noisy data stream in an online fashion.</p>  Source code in <code>utils/processing_utils.py</code> <pre><code>class Filter(Serializable):\n    \"\"\"\n    A base class for filtering a noisy data stream in an online fashion.\n    \"\"\"\n    def estimate(self, observation):\n        \"\"\"\n        Takes an observation and returns a de-noised estimate.\n\n        Args:\n            observation (n-array): A current observation.\n\n        Returns:\n            n-array: De-noised estimate.\n        \"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"\n        Resets this filter. Default is no-op.\n        \"\"\"\n        pass\n\n    @property\n    def state_size(self):\n        # No state by default\n        return 0\n\n    def _dump_state(self):\n        # Default is no state (empty dict)\n        return OrderedDict()\n\n    def _load_state(self, state):\n        # Default is no state (empty dict), so this is a no-op\n        pass\n\n    def _serialize(self, state):\n        # Default is no state, so do nothing\n        return np.array([])\n\n    def _deserialize(self, state):\n        # Default is no state, so do nothing\n        return OrderedDict(), 0\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.Filter"},{"title":"<code>estimate(observation)</code>","text":"<p>Takes an observation and returns a de-noised estimate.</p> <p>Parameters:</p>    Name Type Description Default     <code>observation</code>  <code>n-array</code>  <p>A current observation.</p>  required     <p>Returns:</p>    Type Description       <p>n-array: De-noised estimate.</p>     Source code in <code>utils/processing_utils.py</code> <pre><code>def estimate(self, observation):\n    \"\"\"\n    Takes an observation and returns a de-noised estimate.\n\n    Args:\n        observation (n-array): A current observation.\n\n    Returns:\n        n-array: De-noised estimate.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.Filter.estimate"},{"title":"<code>reset()</code>","text":"<p>Resets this filter. Default is no-op.</p>  Source code in <code>utils/processing_utils.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Resets this filter. Default is no-op.\n    \"\"\"\n    pass\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.Filter.reset"},{"title":"<code>MovingAverageFilter</code>","text":"<p>         Bases: <code>Filter</code></p> <p>This class uses a moving average to de-noise a noisy data stream in an online fashion. This is a FIR filter.</p>  Source code in <code>utils/processing_utils.py</code> <pre><code>class MovingAverageFilter(Filter):\n    \"\"\"\n    This class uses a moving average to de-noise a noisy data stream in an online fashion.\n    This is a FIR filter.\n    \"\"\"\n    def __init__(self, obs_dim, filter_width):\n        \"\"\"\n\n        Args:\n            obs_dim (int): The dimension of the points to filter.\n            filter_width (int): The number of past samples to take the moving average over.\n        \"\"\"\n        self.obs_dim = obs_dim\n        assert filter_width &gt; 0, f\"MovingAverageFilter must have a non-zero size! Got: {filter_width}\"\n        self.filter_width = filter_width\n        self.past_samples = np.zeros((filter_width, obs_dim))\n        self.current_idx = 0\n        self.fully_filled = False               # Whether the entire filter buffer is filled or not\n\n        super().__init__()\n\n    def estimate(self, observation):\n        \"\"\"\n        Do an online hold for state estimation given a recent observation.\n\n        Args:\n            observation (n-array): New observation to hold internal estimate of state.\n\n        Returns:\n            n-array: New estimate of state.\n        \"\"\"\n        # Write the newest observation at the appropriate index\n        self.past_samples[self.current_idx, :] = np.array(observation)\n\n        # Compute value based on whether we're fully filled or not\n        if not self.fully_filled:\n            val = self.past_samples[:self.current_idx + 1, :].mean(axis=0)\n            # Denote that we're fully filled if we're at the end of the buffer\n            if self.current_idx == self.filter_width - 1:\n                self.fully_filled = True\n        else:\n            val = self.past_samples.mean(axis=0)\n\n        # Increment the index to write the next sample to\n        self.current_idx = (self.current_idx + 1) % self.filter_width\n\n        return val\n\n    def reset(self):\n        # Clear internal state\n        self.past_samples *= 0.0\n        self.current_idx = 0\n        self.fully_filled = False\n\n    @property\n    def state_size(self):\n        return super().state_size + self.filter_width * self.obs_dim + 2\n\n    def _dump_state(self):\n        # Run super init first\n        state = super()._dump_state()\n\n        # Add info from this filter\n        state[\"past_samples\"] = np.array(self.past_samples)\n        state[\"current_idx\"] = self.current_idx\n        state[\"fully_filled\"] = self.fully_filled\n\n        return state\n\n    def _load_state(self, state):\n        # Run super first\n        super()._load_state(state=state)\n\n        # Load relevant info for this filter\n        self.past_samples = np.array(state[\"past_samples\"])\n        self.current_idx = state[\"current_idx\"]\n        self.fully_filled = state[\"fully_filled\"]\n\n    def _serialize(self, state):\n        # Run super first\n        state_flat = super()._serialize(state=state)\n\n        # Serialize state for this filter\n        return np.concatenate([\n            state_flat,\n            state[\"past_samples\"].flatten(),\n            [state[\"current_idx\"]],\n            [state[\"fully_filled\"]],\n        ]).astype(float)\n\n    def _deserialize(self, state):\n        # Run super first\n        state_dict, idx = super()._deserialize(state=state)\n\n        # Deserialize state for this filter\n        samples_len = self.filter_width * self.obs_dim\n        state_dict[\"past_samples\"] = state[idx: idx + samples_len]\n        state_dict[\"current_idx\"] = int(state[idx + samples_len])\n        state_dict[\"fully_filled\"] = bool(state[idx + samples_len + 1])\n\n        return state_dict, idx + samples_len + 2\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.MovingAverageFilter"},{"title":"<code>__init__(obs_dim, filter_width)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>obs_dim</code>  <code>int</code>  <p>The dimension of the points to filter.</p>  required    <code>filter_width</code>  <code>int</code>  <p>The number of past samples to take the moving average over.</p>  required      Source code in <code>utils/processing_utils.py</code> <pre><code>def __init__(self, obs_dim, filter_width):\n    \"\"\"\n\n    Args:\n        obs_dim (int): The dimension of the points to filter.\n        filter_width (int): The number of past samples to take the moving average over.\n    \"\"\"\n    self.obs_dim = obs_dim\n    assert filter_width &gt; 0, f\"MovingAverageFilter must have a non-zero size! Got: {filter_width}\"\n    self.filter_width = filter_width\n    self.past_samples = np.zeros((filter_width, obs_dim))\n    self.current_idx = 0\n    self.fully_filled = False               # Whether the entire filter buffer is filled or not\n\n    super().__init__()\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.MovingAverageFilter.__init__"},{"title":"<code>estimate(observation)</code>","text":"<p>Do an online hold for state estimation given a recent observation.</p> <p>Parameters:</p>    Name Type Description Default     <code>observation</code>  <code>n-array</code>  <p>New observation to hold internal estimate of state.</p>  required     <p>Returns:</p>    Type Description       <p>n-array: New estimate of state.</p>     Source code in <code>utils/processing_utils.py</code> <pre><code>def estimate(self, observation):\n    \"\"\"\n    Do an online hold for state estimation given a recent observation.\n\n    Args:\n        observation (n-array): New observation to hold internal estimate of state.\n\n    Returns:\n        n-array: New estimate of state.\n    \"\"\"\n    # Write the newest observation at the appropriate index\n    self.past_samples[self.current_idx, :] = np.array(observation)\n\n    # Compute value based on whether we're fully filled or not\n    if not self.fully_filled:\n        val = self.past_samples[:self.current_idx + 1, :].mean(axis=0)\n        # Denote that we're fully filled if we're at the end of the buffer\n        if self.current_idx == self.filter_width - 1:\n            self.fully_filled = True\n    else:\n        val = self.past_samples.mean(axis=0)\n\n    # Increment the index to write the next sample to\n    self.current_idx = (self.current_idx + 1) % self.filter_width\n\n    return val\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.MovingAverageFilter.estimate"},{"title":"<code>Subsampler</code>","text":"<p>A base class for subsampling a data stream in an online fashion.</p>  Source code in <code>utils/processing_utils.py</code> <pre><code>class Subsampler:\n    \"\"\"\n    A base class for subsampling a data stream in an online fashion.\n    \"\"\"\n\n    def subsample(self, observation):\n        \"\"\"\n        Takes an observation and returns the observation, or None, which\n        corresponds to deleting the observation.\n\n        Args:\n            observation (n-array): A current observation.\n\n        Returns:\n            None or n-array: No observation if subsampled, otherwise the observation\n        \"\"\"\n        raise NotImplementedError\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.Subsampler"},{"title":"<code>subsample(observation)</code>","text":"<p>Takes an observation and returns the observation, or None, which corresponds to deleting the observation.</p> <p>Parameters:</p>    Name Type Description Default     <code>observation</code>  <code>n-array</code>  <p>A current observation.</p>  required     <p>Returns:</p>    Type Description       <p>None or n-array: No observation if subsampled, otherwise the observation</p>     Source code in <code>utils/processing_utils.py</code> <pre><code>def subsample(self, observation):\n    \"\"\"\n    Takes an observation and returns the observation, or None, which\n    corresponds to deleting the observation.\n\n    Args:\n        observation (n-array): A current observation.\n\n    Returns:\n        None or n-array: No observation if subsampled, otherwise the observation\n    \"\"\"\n    raise NotImplementedError\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.Subsampler.subsample"},{"title":"<code>UniformSubsampler</code>","text":"<p>         Bases: <code>Subsampler</code></p> <p>A class for subsampling a data stream uniformly in time in an online fashion.</p>  Source code in <code>utils/processing_utils.py</code> <pre><code>class UniformSubsampler(Subsampler):\n    \"\"\"\n    A class for subsampling a data stream uniformly in time in an online fashion.\n    \"\"\"\n    def __init__(self, T):\n        \"\"\"\n        Args:\n            T (int): Pick one every T observations.\n        \"\"\"\n        self.T = T\n        self.counter = 0\n\n        super(UniformSubsampler, self).__init__()\n\n    def subsample(self, observation):\n        \"\"\"\n        Returns an observation once every T observations, None otherwise.\n\n        Args:\n            observation (n-array): A current observation.\n\n        Returns:\n            None or n-array: The observation, or None.\n        \"\"\"\n        self.counter += 1\n        if self.counter == self.T:\n            self.counter = 0\n            return observation\n        return None\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.UniformSubsampler"},{"title":"<code>__init__(T)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>T</code>  <code>int</code>  <p>Pick one every T observations.</p>  required      Source code in <code>utils/processing_utils.py</code> <pre><code>def __init__(self, T):\n    \"\"\"\n    Args:\n        T (int): Pick one every T observations.\n    \"\"\"\n    self.T = T\n    self.counter = 0\n\n    super(UniformSubsampler, self).__init__()\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.UniformSubsampler.__init__"},{"title":"<code>subsample(observation)</code>","text":"<p>Returns an observation once every T observations, None otherwise.</p> <p>Parameters:</p>    Name Type Description Default     <code>observation</code>  <code>n-array</code>  <p>A current observation.</p>  required     <p>Returns:</p>    Type Description       <p>None or n-array: The observation, or None.</p>     Source code in <code>utils/processing_utils.py</code> <pre><code>def subsample(self, observation):\n    \"\"\"\n    Returns an observation once every T observations, None otherwise.\n\n    Args:\n        observation (n-array): A current observation.\n\n    Returns:\n        None or n-array: The observation, or None.\n    \"\"\"\n    self.counter += 1\n    if self.counter == self.T:\n        self.counter = 0\n        return observation\n    return None\n</code></pre>","location":"reference/utils/processing_utils.html#utils.processing_utils.UniformSubsampler.subsample"},{"title":"python_utils","text":"<p>A set of utility functions for general python usage</p>","location":"reference/utils/python_utils.html"},{"title":"<code>Recreatable</code>","text":"<p>Simple class that provides an abstract interface automatically saving init args of the classes inheriting it.</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class Recreatable(metaclass=RecreatableAbcMeta):\n    \"\"\"\n    Simple class that provides an abstract interface automatically saving __init__ args of\n    the classes inheriting it.\n    \"\"\"\n\n    def get_init_info(self):\n        \"\"\"\n        Grabs relevant initialization information for this class instance. Useful for directly\n        reloading an object from this information, using @create_object_from_init_info.\n\n        Returns:\n            dict: Nested dictionary that contains this object's initialization information\n        \"\"\"\n        # Note: self._init_info is procedurally generated via @save_init_info called in metaclass\n        return self._init_info\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Recreatable"},{"title":"<code>get_init_info()</code>","text":"<p>Grabs relevant initialization information for this class instance. Useful for directly reloading an object from this information, using @create_object_from_init_info.</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Nested dictionary that contains this object's initialization information</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def get_init_info(self):\n    \"\"\"\n    Grabs relevant initialization information for this class instance. Useful for directly\n    reloading an object from this information, using @create_object_from_init_info.\n\n    Returns:\n        dict: Nested dictionary that contains this object's initialization information\n    \"\"\"\n    # Note: self._init_info is procedurally generated via @save_init_info called in metaclass\n    return self._init_info\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Recreatable.get_init_info"},{"title":"<code>RecreatableAbcMeta</code>","text":"<p>         Bases: <code>RecreatableMeta</code>, <code>ABCMeta</code></p> <p>A composite metaclass of both RecreatableMeta and ABCMeta.</p> <p>Adding in ABCMeta to resolve metadata conflicts.</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class RecreatableAbcMeta(RecreatableMeta, ABCMeta):\n    \"\"\"\n    A composite metaclass of both RecreatableMeta and ABCMeta.\n\n    Adding in ABCMeta to resolve metadata conflicts.\n    \"\"\"\n\n    pass\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.RecreatableAbcMeta"},{"title":"<code>RecreatableMeta</code>","text":"<p>         Bases: <code>type</code></p> <p>Simple metaclass that automatically saves init args of the instances it creates.</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class RecreatableMeta(type):\n    \"\"\"\n    Simple metaclass that automatically saves __init__ args of the instances it creates.\n    \"\"\"\n\n    def __new__(cls, clsname, bases, clsdict):\n        if \"__init__\" in clsdict:\n            clsdict[\"__init__\"] = save_init_info(clsdict[\"__init__\"])\n        return super().__new__(cls, clsname, bases, clsdict)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.RecreatableMeta"},{"title":"<code>Registerable</code>","text":"<p>Simple class template that provides an abstract interface for registering classes.</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class Registerable:\n    \"\"\"\n    Simple class template that provides an abstract interface for registering classes.\n    \"\"\"\n\n    def __init_subclass__(cls, **kwargs):\n        \"\"\"\n        Registers all subclasses as part of this registry. This is useful to decouple internal codebase from external\n        user additions. This way, users can add their custom subclasses by simply extending this class,\n        and it will automatically be registered internally. This allows users to then specify their classes\n        directly in string-form in e.g., their config files, without having to manually set the str-to-class mapping\n        in our code.\n        \"\"\"\n        cls._register_cls()\n\n    @classmethod\n    def _register_cls(cls):\n        \"\"\"\n        Register this class. Can be extended by subclass.\n        \"\"\"\n        # print(f\"registering: {cls.__name__}\")\n        # print(f\"registry: {cls._cls_registry}\", cls.__name__ not in cls._cls_registry)\n        # print(f\"do not register: {cls._do_not_register_classes}\", cls.__name__ not in cls._do_not_register_classes)\n        # input()\n        if cls.__name__ not in cls._cls_registry and cls.__name__ not in cls._do_not_register_classes:\n            cls._cls_registry[cls.__name__] = cls\n\n    @classproperty\n    def _do_not_register_classes(cls):\n        \"\"\"\n        Returns:\n            set of str: Name(s) of classes that should not be registered. Default is empty set.\n                Subclasses that shouldn't be added should call super() and then add their own class name to the set\n        \"\"\"\n        return set()\n\n    @classproperty\n    def _cls_registry(cls):\n        \"\"\"\n        Returns:\n            OrderedDict: Mapping from all registered class names to their classes. This should be a REFERENCE\n                to some external, global dictionary that will be filled-in at runtime.\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Registerable"},{"title":"<code>__init_subclass__(**kwargs)</code>","text":"<p>Registers all subclasses as part of this registry. This is useful to decouple internal codebase from external user additions. This way, users can add their custom subclasses by simply extending this class, and it will automatically be registered internally. This allows users to then specify their classes directly in string-form in e.g., their config files, without having to manually set the str-to-class mapping in our code.</p>  Source code in <code>utils/python_utils.py</code> <pre><code>def __init_subclass__(cls, **kwargs):\n    \"\"\"\n    Registers all subclasses as part of this registry. This is useful to decouple internal codebase from external\n    user additions. This way, users can add their custom subclasses by simply extending this class,\n    and it will automatically be registered internally. This allows users to then specify their classes\n    directly in string-form in e.g., their config files, without having to manually set the str-to-class mapping\n    in our code.\n    \"\"\"\n    cls._register_cls()\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Registerable.__init_subclass__"},{"title":"<code>Serializable</code>","text":"<p>Simple class that provides an abstract interface to dump / load states, optionally with serialized functionality as well.</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class Serializable:\n    \"\"\"\n    Simple class that provides an abstract interface to dump / load states, optionally with serialized functionality\n    as well.\n    \"\"\"\n    @property\n    def state_size(self):\n        \"\"\"\n        Returns:\n            int: Size of this object's serialized state\n        \"\"\"\n        raise NotImplementedError()\n\n    def _dump_state(self):\n        \"\"\"\n        Dumps the state of this object in dictionary form (can be empty). Should be implemented by subclass.\n\n        Returns:\n            OrderedDict: Keyword-mapped states of this object\n        \"\"\"\n        raise NotImplementedError()\n\n    def dump_state(self, serialized=False):\n        \"\"\"\n        Dumps the state of this object in either dictionary of flattened numerical form.\n\n        Args:\n            serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n                a (potentially nested) dictionary of states for this object\n\n        Returns:\n            OrderedDict or n-array: Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        \"\"\"\n        state = self._dump_state()\n        return self.serialize(state=state) if serialized else state\n\n    def _load_state(self, state):\n        \"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to set\n        \"\"\"\n        raise NotImplementedError()\n\n    def load_state(self, state, serialized=False):\n        \"\"\"\n        Deserializes and loads this object's state based on @state\n\n        Args:\n            state (OrderedDict or n-array): Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n            serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n                a (potentially nested) dictionary of states for this object\n        \"\"\"\n        state = self.deserialize(state=state) if serialized else state\n        self._load_state(state=state)\n\n    def _serialize(self, state):\n        \"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\n        raise NotImplementedError()\n\n    def serialize(self, state):\n        \"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\n        # Simply returns self._serialize() for now. this is for future proofing\n        return self._serialize(state=state)\n\n    def _deserialize(self, state):\n        \"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n\n        Returns:\n            2-tuple:\n                - OrderedDict: Keyword-mapped states of this object. Should match structure of output from\n                    self._dump_state()\n                - int: current index of the flattened state vector that is left off. This is helpful for subclasses\n                    that inherit partial deserializations from parent classes, and need to know where the\n                    deserialization left off before continuing.\n        \"\"\"\n        raise NotImplementedError\n\n    def deserialize(self, state):\n        \"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n\n        Returns:\n            OrderedDict: Keyword-mapped states of this object. Should match structure of output from\n                self._dump_state()\n        \"\"\"\n        # Sanity check the idx with the expected state size\n        state_dict, idx = self._deserialize(state=state)\n        assert idx == self.state_size, f\"Invalid state deserialization occurred! Expected {self.state_size} total \" \\\n                                           f\"values to be deserialized, only {idx} were.\"\n\n        return state_dict\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Serializable"},{"title":"<code>state_size</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Size of this object's serialized state</p>","location":"reference/utils/python_utils.html#utils.python_utils.Serializable.state_size"},{"title":"<code>deserialize(state)</code>","text":"<p>De-serializes flattened 1D numpy array @state into nested dictionary state. Should be implemented by subclass.</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>n-array</code>  <p>encoded + serialized, 1D numerical np.array capturing this object's state</p>  required     <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Keyword-mapped states of this object. Should match structure of output from self._dump_state()</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def deserialize(self, state):\n    \"\"\"\n    De-serializes flattened 1D numpy array @state into nested dictionary state.\n    Should be implemented by subclass.\n\n    Args:\n        state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n\n    Returns:\n        OrderedDict: Keyword-mapped states of this object. Should match structure of output from\n            self._dump_state()\n    \"\"\"\n    # Sanity check the idx with the expected state size\n    state_dict, idx = self._deserialize(state=state)\n    assert idx == self.state_size, f\"Invalid state deserialization occurred! Expected {self.state_size} total \" \\\n                                       f\"values to be deserialized, only {idx} were.\"\n\n    return state_dict\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Serializable.deserialize"},{"title":"<code>dump_state(serialized=False)</code>","text":"<p>Dumps the state of this object in either dictionary of flattened numerical form.</p> <p>Parameters:</p>    Name Type Description Default     <code>serialized</code>  <code>bool</code>  <p>If True, will return the state of this object as a 1D numpy array. Otherewise, will return a (potentially nested) dictionary of states for this object</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>OrderedDict or n-array: Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def dump_state(self, serialized=False):\n    \"\"\"\n    Dumps the state of this object in either dictionary of flattened numerical form.\n\n    Args:\n        serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n            a (potentially nested) dictionary of states for this object\n\n    Returns:\n        OrderedDict or n-array: Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n    \"\"\"\n    state = self._dump_state()\n    return self.serialize(state=state) if serialized else state\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Serializable.dump_state"},{"title":"<code>load_state(state, serialized=False)</code>","text":"<p>Deserializes and loads this object's state based on @state</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>OrderedDict or n-array</code>  <p>Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p>  required    <code>serialized</code>  <code>bool</code>  <p>If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is a (potentially nested) dictionary of states for this object</p>  <code>False</code>      Source code in <code>utils/python_utils.py</code> <pre><code>def load_state(self, state, serialized=False):\n    \"\"\"\n    Deserializes and loads this object's state based on @state\n\n    Args:\n        state (OrderedDict or n-array): Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n            a (potentially nested) dictionary of states for this object\n    \"\"\"\n    state = self.deserialize(state=state) if serialized else state\n    self._load_state(state=state)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Serializable.load_state"},{"title":"<code>serialize(state)</code>","text":"<p>Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency. Should be implemented by subclass.</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>OrderedDict</code>  <p>Keyword-mapped states of this object to encode. Should match structure of output from self._dump_state()</p>  required     <p>Returns:</p>    Type Description       <p>n-array: encoded + serialized, 1D numerical np.array capturing this object's state</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def serialize(self, state):\n    \"\"\"\n    Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n    Should be implemented by subclass.\n\n    Args:\n        state (OrderedDict): Keyword-mapped states of this object to encode. Should match structure of output from\n            self._dump_state()\n\n    Returns:\n        n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n    \"\"\"\n    # Simply returns self._serialize() for now. this is for future proofing\n    return self._serialize(state=state)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.Serializable.serialize"},{"title":"<code>SerializableNonInstance</code>","text":"<p>Identical to Serializable, but intended for non-instanceable classes</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class SerializableNonInstance:\n    \"\"\"\n    Identical to Serializable, but intended for non-instanceable classes\n    \"\"\"\n    @classproperty\n    def state_size(cls):\n        \"\"\"\n        Returns:\n            int: Size of this object's serialized state\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def _dump_state(cls):\n        \"\"\"\n        Dumps the state of this object in dictionary form (can be empty). Should be implemented by subclass.\n\n        Returns:\n            OrderedDict: Keyword-mapped states of this object\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def dump_state(cls, serialized=False):\n        \"\"\"\n        Dumps the state of this object in either dictionary of flattened numerical form.\n\n        Args:\n            serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n                a (potentially nested) dictionary of states for this object\n\n        Returns:\n            OrderedDict or n-array: Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        \"\"\"\n        state = cls._dump_state()\n        return cls.serialize(state=state) if serialized else state\n\n    @classmethod\n    def _load_state(cls, state):\n        \"\"\"\n        Load the internal state to this object as specified by @state. Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to set\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def load_state(cls, state, serialized=False):\n        \"\"\"\n        Deserializes and loads this object's state based on @state\n\n        Args:\n            state (OrderedDict or n-array): Either:\n                - Keyword-mapped states of this object, or\n                - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n            serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n                a (potentially nested) dictionary of states for this object\n        \"\"\"\n        state = cls.deserialize(state=state) if serialized else state\n        cls._load_state(state=state)\n\n    @classmethod\n    def _serialize(cls, state):\n        \"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def serialize(cls, state):\n        \"\"\"\n        Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n        Should be implemented by subclass.\n\n        Args:\n            state (OrderedDict): Keyword-mapped states of this object to encode. Should match structure of output from\n                self._dump_state()\n\n        Returns:\n            n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n        \"\"\"\n        # Simply returns self._serialize() for now. this is for future proofing\n        return cls._serialize(state=state)\n\n    @classmethod\n    def _deserialize(cls, state):\n        \"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n\n        Returns:\n            2-tuple:\n                - OrderedDict: Keyword-mapped states of this object. Should match structure of output from\n                    self._dump_state()\n                - int: current index of the flattened state vector that is left off. This is helpful for subclasses\n                    that inherit partial deserializations from parent classes, and need to know where the\n                    deserialization left off before continuing.\n        \"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def deserialize(cls, state):\n        \"\"\"\n        De-serializes flattened 1D numpy array @state into nested dictionary state.\n        Should be implemented by subclass.\n\n        Args:\n            state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n\n        Returns:\n            OrderedDict: Keyword-mapped states of this object. Should match structure of output from\n                self._dump_state()\n        \"\"\"\n        # Sanity check the idx with the expected state size\n        state_dict, idx = cls._deserialize(state=state)\n        assert cls.state_size is not None, \"State size must be specified by subclass!\"\n        assert idx == cls.state_size, f\"Invalid state deserialization occurred! Expected {cls.state_size} total \" \\\n                                      f\"values to be deserialized, only {idx} were.\"\n\n        return state_dict\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance"},{"title":"<code>deserialize(state)</code>  <code>classmethod</code>","text":"<p>De-serializes flattened 1D numpy array @state into nested dictionary state. Should be implemented by subclass.</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>n-array</code>  <p>encoded + serialized, 1D numerical np.array capturing this object's state</p>  required     <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Keyword-mapped states of this object. Should match structure of output from self._dump_state()</p>     Source code in <code>utils/python_utils.py</code> <pre><code>@classmethod\ndef deserialize(cls, state):\n    \"\"\"\n    De-serializes flattened 1D numpy array @state into nested dictionary state.\n    Should be implemented by subclass.\n\n    Args:\n        state (n-array): encoded + serialized, 1D numerical np.array capturing this object's state\n\n    Returns:\n        OrderedDict: Keyword-mapped states of this object. Should match structure of output from\n            self._dump_state()\n    \"\"\"\n    # Sanity check the idx with the expected state size\n    state_dict, idx = cls._deserialize(state=state)\n    assert cls.state_size is not None, \"State size must be specified by subclass!\"\n    assert idx == cls.state_size, f\"Invalid state deserialization occurred! Expected {cls.state_size} total \" \\\n                                  f\"values to be deserialized, only {idx} were.\"\n\n    return state_dict\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.deserialize"},{"title":"<code>dump_state(serialized=False)</code>  <code>classmethod</code>","text":"<p>Dumps the state of this object in either dictionary of flattened numerical form.</p> <p>Parameters:</p>    Name Type Description Default     <code>serialized</code>  <code>bool</code>  <p>If True, will return the state of this object as a 1D numpy array. Otherewise, will return a (potentially nested) dictionary of states for this object</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>OrderedDict or n-array: Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p>     Source code in <code>utils/python_utils.py</code> <pre><code>@classmethod\ndef dump_state(cls, serialized=False):\n    \"\"\"\n    Dumps the state of this object in either dictionary of flattened numerical form.\n\n    Args:\n        serialized (bool): If True, will return the state of this object as a 1D numpy array. Otherewise, will return\n            a (potentially nested) dictionary of states for this object\n\n    Returns:\n        OrderedDict or n-array: Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n    \"\"\"\n    state = cls._dump_state()\n    return cls.serialize(state=state) if serialized else state\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.dump_state"},{"title":"<code>load_state(state, serialized=False)</code>  <code>classmethod</code>","text":"<p>Deserializes and loads this object's state based on @state</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>OrderedDict or n-array</code>  <p>Either: - Keyword-mapped states of this object, or - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size</p>  required    <code>serialized</code>  <code>bool</code>  <p>If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is a (potentially nested) dictionary of states for this object</p>  <code>False</code>      Source code in <code>utils/python_utils.py</code> <pre><code>@classmethod\ndef load_state(cls, state, serialized=False):\n    \"\"\"\n    Deserializes and loads this object's state based on @state\n\n    Args:\n        state (OrderedDict or n-array): Either:\n            - Keyword-mapped states of this object, or\n            - encoded + serialized, 1D numerical np.array capturing this object's state, where n is @self.state_size\n        serialized (bool): If True, will interpret @state as a 1D numpy array. Otherewise, will assume the input is\n            a (potentially nested) dictionary of states for this object\n    \"\"\"\n    state = cls.deserialize(state=state) if serialized else state\n    cls._load_state(state=state)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.load_state"},{"title":"<code>serialize(state)</code>  <code>classmethod</code>","text":"<p>Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency. Should be implemented by subclass.</p> <p>Parameters:</p>    Name Type Description Default     <code>state</code>  <code>OrderedDict</code>  <p>Keyword-mapped states of this object to encode. Should match structure of output from self._dump_state()</p>  required     <p>Returns:</p>    Type Description       <p>n-array: encoded + serialized, 1D numerical np.array capturing this object's state</p>     Source code in <code>utils/python_utils.py</code> <pre><code>@classmethod\ndef serialize(cls, state):\n    \"\"\"\n    Serializes nested dictionary state @state into a flattened 1D numpy array for encoding efficiency.\n    Should be implemented by subclass.\n\n    Args:\n        state (OrderedDict): Keyword-mapped states of this object to encode. Should match structure of output from\n            self._dump_state()\n\n    Returns:\n        n-array: encoded + serialized, 1D numerical np.array capturing this object's state\n    \"\"\"\n    # Simply returns self._serialize() for now. this is for future proofing\n    return cls._serialize(state=state)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.serialize"},{"title":"<code>state_size()</code>","text":"<p>Returns:</p>    Name Type Description     <code>int</code>   <p>Size of this object's serialized state</p>     Source code in <code>utils/python_utils.py</code> <pre><code>@classproperty\ndef state_size(cls):\n    \"\"\"\n    Returns:\n        int: Size of this object's serialized state\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.SerializableNonInstance.state_size"},{"title":"<code>UniquelyNamed</code>","text":"<p>Simple class that implements a name property, that must be implemented by a subclass. Note that any @Named entity must be UNIQUE!</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class UniquelyNamed:\n    \"\"\"\n    Simple class that implements a name property, that must be implemented by a subclass. Note that any @Named\n    entity must be UNIQUE!\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        global NAMES\n        # Register this object, making sure it's name is unique\n        assert self.name not in NAMES, \\\n            f\"UniquelyNamed object with name {self.name} already exists!\"\n        NAMES.add(self.name)\n\n    # def __del__(self):\n    #     # Remove this object name from the registry if it's still there\n    #     self.remove_names(include_all_owned=True)\n\n    def remove_names(self, include_all_owned=True, skip_ids=None):\n        \"\"\"\n        Checks if self.name exists in the global NAMES registry, and deletes it if so. Possibly also iterates through\n        all owned member variables and checks for their corresponding names if @include_all_owned is True.\n\n        Args:\n            include_all_owned (bool): If True, will iterate through all owned members of this instance and remove their\n                names as well, if they are UniquelyNamed\n\n            skip_ids (None or set of int): If specified, will skip over any ids in the specified set that are matched\n                to any attributes found (this compares id(attr) to @skip_ids).\n        \"\"\"\n        # Make sure skip_ids is a set so we can pass this into the method, and add the dictionary so we don't\n        # get infinite recursive loops\n        skip_ids = set() if skip_ids is None else skip_ids\n        skip_ids.add(id(self))\n\n        # Check for this name, possibly remove it if it exists\n        if self.name in NAMES:\n            NAMES.remove(self.name)\n\n        # Also possibly iterate through all owned members and check if those are instances of UniquelyNamed\n        if include_all_owned:\n            self._remove_names_recursively_from_dict(dic=self.__dict__, skip_ids=skip_ids)\n\n    def _remove_names_recursively_from_dict(self, dic, skip_ids=None):\n        \"\"\"\n        Checks if self.name exists in the global NAMES registry, and deletes it if so\n\n        Args:\n            skip_ids (None or set): If specified, will skip over any objects in the specified set that are matched\n                to any attributes found.\n        \"\"\"\n        # Make sure skip_ids is a set so we can pass this into the method, and add the dictionary so we don't\n        # get infinite recursive loops\n        skip_ids = set() if skip_ids is None else skip_ids\n        skip_ids.add(id(dic))\n\n        # Loop through all values in the inputted dictionary, and check if any of the values are UniquelyNamed\n        for name, val in dic.items():\n            if id(val) not in skip_ids:\n                # No need to explicitly add val to skip objects because the methods below handle adding it\n                if isinstance(val, UniquelyNamed):\n                    val.remove_names(include_all_owned=True, skip_ids=skip_ids)\n                elif isinstance(val, dict):\n                    # Recursively iterate\n                    self._remove_names_recursively_from_dict(dic=val, skip_ids=skip_ids)\n                elif hasattr(val, \"__dict__\"):\n                    # Add the attribute and recursively iterate\n                    skip_ids.add(id(val))\n                    self._remove_names_recursively_from_dict(dic=val.__dict__, skip_ids=skip_ids)\n                else:\n                    # Otherwise we just add the value to skip_ids so we don't check it again\n                    skip_ids.add(id(val))\n\n    @property\n    def name(self):\n        \"\"\"\n        Returns:\n            str: Name of this instance. Must be unique!\n        \"\"\"\n        raise NotImplementedError\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamed"},{"title":"<code>name</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this instance. Must be unique!</p>","location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamed.name"},{"title":"<code>remove_names(include_all_owned=True, skip_ids=None)</code>","text":"<p>Checks if self.name exists in the global NAMES registry, and deletes it if so. Possibly also iterates through all owned member variables and checks for their corresponding names if @include_all_owned is True.</p> <p>Parameters:</p>    Name Type Description Default     <code>include_all_owned</code>  <code>bool</code>  <p>If True, will iterate through all owned members of this instance and remove their names as well, if they are UniquelyNamed</p>  <code>True</code>    <code>skip_ids</code>  <code>None or set of int</code>  <p>If specified, will skip over any ids in the specified set that are matched to any attributes found (this compares id(attr) to @skip_ids).</p>  <code>None</code>      Source code in <code>utils/python_utils.py</code> <pre><code>def remove_names(self, include_all_owned=True, skip_ids=None):\n    \"\"\"\n    Checks if self.name exists in the global NAMES registry, and deletes it if so. Possibly also iterates through\n    all owned member variables and checks for their corresponding names if @include_all_owned is True.\n\n    Args:\n        include_all_owned (bool): If True, will iterate through all owned members of this instance and remove their\n            names as well, if they are UniquelyNamed\n\n        skip_ids (None or set of int): If specified, will skip over any ids in the specified set that are matched\n            to any attributes found (this compares id(attr) to @skip_ids).\n    \"\"\"\n    # Make sure skip_ids is a set so we can pass this into the method, and add the dictionary so we don't\n    # get infinite recursive loops\n    skip_ids = set() if skip_ids is None else skip_ids\n    skip_ids.add(id(self))\n\n    # Check for this name, possibly remove it if it exists\n    if self.name in NAMES:\n        NAMES.remove(self.name)\n\n    # Also possibly iterate through all owned members and check if those are instances of UniquelyNamed\n    if include_all_owned:\n        self._remove_names_recursively_from_dict(dic=self.__dict__, skip_ids=skip_ids)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamed.remove_names"},{"title":"<code>UniquelyNamedNonInstance</code>","text":"<p>Identical to UniquelyNamed, but intended for non-instanceable classes</p>  Source code in <code>utils/python_utils.py</code> <pre><code>class UniquelyNamedNonInstance:\n    \"\"\"\n    Identical to UniquelyNamed, but intended for non-instanceable classes\n    \"\"\"\n\n    def __init_subclass__(cls, **kwargs):\n        global CLASS_NAMES\n        # Register this object, making sure it's name is unique\n        assert cls.name not in CLASS_NAMES, \\\n            f\"UniquelyNamed class with name {cls.name} already exists!\"\n        CLASS_NAMES.add(cls.name)\n\n    @classproperty\n    def name(cls):\n        \"\"\"\n        Returns:\n            str: Name of this instance. Must be unique!\n        \"\"\"\n        raise NotImplementedError\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamedNonInstance"},{"title":"<code>name()</code>","text":"<p>Returns:</p>    Name Type Description     <code>str</code>   <p>Name of this instance. Must be unique!</p>     Source code in <code>utils/python_utils.py</code> <pre><code>@classproperty\ndef name(cls):\n    \"\"\"\n    Returns:\n        str: Name of this instance. Must be unique!\n    \"\"\"\n    raise NotImplementedError\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.UniquelyNamedNonInstance.name"},{"title":"<code>assert_valid_key(key, valid_keys, name=None)</code>","text":"<p>Helper function that asserts that @key is in dictionary @valid_keys keys. If not, it will raise an error.</p> <p>Parameters:</p>    Name Type Description Default     <code>key</code>  <code>any</code>  <p>key to check for in dictionary @dic's keys</p>  required    <code>valid_keys</code>  <code>Iterable</code>  <p>contains keys should be checked with @key</p>  required    <code>name</code>  <code>str or None</code>  <p>if specified, is the name associated with the key that will be printed out if the key is not found. If None, default is \"value\"</p>  <code>None</code>      Source code in <code>utils/python_utils.py</code> <pre><code>def assert_valid_key(key, valid_keys, name=None):\n    \"\"\"\n    Helper function that asserts that @key is in dictionary @valid_keys keys. If not, it will raise an error.\n\n    Args:\n        key (any): key to check for in dictionary @dic's keys\n        valid_keys (Iterable): contains keys should be checked with @key\n        name (str or None): if specified, is the name associated with the key that will be printed out if the\n            key is not found. If None, default is \"value\"\n    \"\"\"\n    if name is None:\n        name = \"value\"\n    assert key in valid_keys, \"Invalid {} received! Valid options are: {}, got: {}\".format(\n        name, valid_keys.keys() if isinstance(valid_keys, dict) else valid_keys, key)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.assert_valid_key"},{"title":"<code>clear()</code>","text":"<p>Clear state tied to singleton classes</p>  Source code in <code>utils/python_utils.py</code> <pre><code>def clear():\n    \"\"\"\n    Clear state tied to singleton classes\n    \"\"\"\n    NAMES.clear()\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.clear"},{"title":"<code>create_class_from_registry_and_config(cls_name, cls_registry, cfg, cls_type_descriptor)</code>","text":"<p>Helper function to create a class with str type @cls_name, which should be a valid entry in @cls_registry, using kwargs in dictionary form @cfg to pass to the constructor, with @cls_type_name specified for debugging</p> <p>Parameters:</p>    Name Type Description Default     <code>cls_name</code>  <code>str</code>  <p>Name of the class to create. This should correspond to the actual class type, in string form</p>  required    <code>cls_registry</code>  <code>dict</code>  <p>Class registry. This should map string names of valid classes to create to the actual class type itself</p>  required    <code>cfg</code>  <code>dict</code>  <p>Any keyword arguments to pass to the class constructor</p>  required    <code>cls_type_descriptor</code>  <code>str</code>  <p>Description of the class type being created. This can be any string and is used solely for debugging purposes</p>  required     <p>Returns:</p>    Name Type Description     <code>any</code>   <p>Created class instance</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def create_class_from_registry_and_config(cls_name, cls_registry, cfg, cls_type_descriptor):\n    \"\"\"\n    Helper function to create a class with str type @cls_name, which should be a valid entry in @cls_registry, using\n    kwargs in dictionary form @cfg to pass to the constructor, with @cls_type_name specified for debugging\n\n    Args:\n        cls_name (str): Name of the class to create. This should correspond to the actual class type, in string form\n        cls_registry (dict): Class registry. This should map string names of valid classes to create to the\n            actual class type itself\n        cfg (dict): Any keyword arguments to pass to the class constructor\n        cls_type_descriptor (str): Description of the class type being created. This can be any string and is used\n            solely for debugging purposes\n\n    Returns:\n        any: Created class instance\n    \"\"\"\n    # Make sure the requested class type is valid\n    assert_valid_key(key=cls_name, valid_keys=cls_registry, name=f\"{cls_type_descriptor} type\")\n\n    # Grab the kwargs relevant for the specific class\n    cls = cls_registry[cls_name]\n    cls_kwargs = extract_class_init_kwargs_from_dict(cls=cls, dic=cfg, copy=False)\n\n    # Create the class\n    return cls(**cls_kwargs)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.create_class_from_registry_and_config"},{"title":"<code>create_object_from_init_info(init_info)</code>","text":"<p>Create a new object based on an given init info.</p> <p>Parameters:</p>    Name Type Description Default     <code>init_info</code>  <code>dict</code>  <p>Nested dictionary that contains an object's init information.</p>  required     <p>Returns:</p>    Name Type Description     <code>any</code>   <p>Newly created object.</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def create_object_from_init_info(init_info):\n    \"\"\"\n    Create a new object based on an given init info.\n\n    Args:\n        init_info (dict): Nested dictionary that contains an object's init information.\n\n    Returns:\n        any: Newly created object.\n    \"\"\"\n    module = import_module(init_info[\"class_module\"])\n    cls = getattr(module, init_info[\"class_name\"])\n    return cls(**init_info[\"args\"], **init_info.get(\"kwargs\", {}))\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.create_object_from_init_info"},{"title":"<code>extract_class_init_kwargs_from_dict(cls, dic, copy=False)</code>","text":"<p>Helper function to return a dictionary of key-values that specifically correspond to @cls class's init constructor method, from @dic which may or may not contain additional, irrelevant kwargs. Note that @dic may possibly be missing certain kwargs as specified by cls.init. No error will be raised.</p> <p>Parameters:</p>    Name Type Description Default     <code>cls</code>  <code>object</code>  <p>Class from which to grab init kwargs that will be be used as filtering keys for @dic</p>  required    <code>dic</code>  <code>dict</code>  <p>Dictionary containing multiple key-values</p>  required    <code>copy</code>  <code>bool</code>  <p>If True, will deepcopy all values corresponding to the specified @keys</p>  <code>False</code>     <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Extracted subset dictionary possibly containing only the specified keys from cls.init and their corresponding values</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def extract_class_init_kwargs_from_dict(cls, dic, copy=False):\n    \"\"\"\n    Helper function to return a dictionary of key-values that specifically correspond to @cls class's __init__\n    constructor method, from @dic which may or may not contain additional, irrelevant kwargs.\n    Note that @dic may possibly be missing certain kwargs as specified by cls.__init__. No error will be raised.\n\n    Args:\n        cls (object): Class from which to grab __init__ kwargs that will be be used as filtering keys for @dic\n        dic (dict): Dictionary containing multiple key-values\n        copy (bool): If True, will deepcopy all values corresponding to the specified @keys\n\n    Returns:\n        dict: Extracted subset dictionary possibly containing only the specified keys from cls.__init__ and their\n            corresponding values\n    \"\"\"\n    # extract only relevant kwargs for this specific backbone\n    return extract_subset_dict(\n        dic=dic,\n        keys=get_class_init_kwargs(cls),\n        copy=copy,\n    )\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.extract_class_init_kwargs_from_dict"},{"title":"<code>extract_subset_dict(dic, keys, copy=False)</code>","text":"<p>Helper function to extract a subset of dictionary key-values from a current dictionary. Optionally (deep)copies the values extracted from the original @dic if @copy is True.</p> <p>Parameters:</p>    Name Type Description Default     <code>dic</code>  <code>dict</code>  <p>Dictionary containing multiple key-values</p>  required    <code>keys</code>  <code>Iterable</code>  <p>Specific keys to extract from @dic. If the key doesn't exist in @dic, then the key is skipped</p>  required    <code>copy</code>  <code>bool</code>  <p>If True, will deepcopy all values corresponding to the specified @keys</p>  <code>False</code>     <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Extracted subset dictionary containing only the specified @keys and their corresponding values</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def extract_subset_dict(dic, keys, copy=False):\n    \"\"\"\n    Helper function to extract a subset of dictionary key-values from a current dictionary. Optionally (deep)copies\n    the values extracted from the original @dic if @copy is True.\n\n    Args:\n        dic (dict): Dictionary containing multiple key-values\n        keys (Iterable): Specific keys to extract from @dic. If the key doesn't exist in @dic, then the key is skipped\n        copy (bool): If True, will deepcopy all values corresponding to the specified @keys\n\n    Returns:\n        dict: Extracted subset dictionary containing only the specified @keys and their corresponding values\n    \"\"\"\n    subset = {k: dic[k] for k in keys if k in dic}\n    return deepcopy(subset) if copy else subset\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.extract_subset_dict"},{"title":"<code>get_class_init_kwargs(cls)</code>","text":"<p>Helper function to return a list of all valid keyword arguments (excluding \"self\") for the given @cls class.</p> <p>Parameters:</p>    Name Type Description Default     <code>cls</code>  <code>object</code>  <p>Class from which to grab init kwargs</p>  required     <p>Returns:</p>    Name Type Description     <code>list</code>   <p>All keyword arguments (excluding \"self\") specified by @cls init constructor method</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def get_class_init_kwargs(cls):\n    \"\"\"\n    Helper function to return a list of all valid keyword arguments (excluding \"self\") for the given @cls class.\n\n    Args:\n        cls (object): Class from which to grab __init__ kwargs\n\n    Returns:\n        list: All keyword arguments (excluding \"self\") specified by @cls __init__ constructor method\n    \"\"\"\n    return list(inspect.signature(cls.__init__).parameters.keys())[1:]\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.get_class_init_kwargs"},{"title":"<code>merge_nested_dicts(base_dict, extra_dict, inplace=False, verbose=False)</code>","text":"<p>Iteratively updates @base_dict with values from @extra_dict. Note: This generates a new dictionary!</p> <p>Parameters:</p>    Name Type Description Default     <code>base_dict</code>  <code>dict</code>  <p>Nested base dictionary, which should be updated with all values from @extra_dict</p>  required    <code>extra_dict</code>  <code>dict</code>  <p>Nested extra dictionary, whose values will overwrite corresponding ones in @base_dict</p>  required    <code>inplace</code>  <code>bool</code>  <p>Whether to modify @base_dict in place or not</p>  <code>False</code>    <code>verbose</code>  <code>bool</code>  <p>If True, will print when keys are mismatched</p>  <code>False</code>     <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Updated dictionary</p>     Source code in <code>utils/python_utils.py</code> <pre><code>def merge_nested_dicts(base_dict, extra_dict, inplace=False, verbose=False):\n    \"\"\"\n    Iteratively updates @base_dict with values from @extra_dict. Note: This generates a new dictionary!\n\n    Args:\n        base_dict (dict): Nested base dictionary, which should be updated with all values from @extra_dict\n        extra_dict (dict): Nested extra dictionary, whose values will overwrite corresponding ones in @base_dict\n        inplace (bool): Whether to modify @base_dict in place or not\n        verbose (bool): If True, will print when keys are mismatched\n\n    Returns:\n        dict: Updated dictionary\n    \"\"\"\n    # Loop through all keys in @extra_dict and update the corresponding values in @base_dict\n    base_dict = base_dict if inplace else deepcopy(base_dict)\n    for k, v in extra_dict.items():\n        if k not in base_dict:\n            base_dict[k] = v\n        else:\n            if isinstance(v, dict) and isinstance(base_dict[k], dict):\n                base_dict[k] = merge_nested_dicts(base_dict[k], v)\n            else:\n                not_equal = base_dict[k] != v\n                if isinstance(not_equal, np.ndarray):\n                    not_equal = not_equal.any()\n                if not_equal and verbose:\n                    print(f\"Different values for key {k}: {base_dict[k]}, {v}\\n\")\n                base_dict[k] = np.array(v) if isinstance(v, list) else v\n\n    # Return new dict\n    return base_dict\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.merge_nested_dicts"},{"title":"<code>save_init_info(func)</code>","text":"<p>Decorator to save the init info of an object to object._init_info.</p> <p>_init_info contains class name and class constructor's input args.</p>  Source code in <code>utils/python_utils.py</code> <pre><code>def save_init_info(func):\n    \"\"\"\n    Decorator to save the init info of an object to object._init_info.\n\n    _init_info contains class name and class constructor's input args.\n    \"\"\"\n    sig = inspect.signature(func)\n\n    @wraps(func) # preserve func name, docstring, arguments list, etc.\n    def wrapper(self, *args, **kwargs):\n        values = sig.bind(self, *args, **kwargs)\n\n        # Prevent args of super init from being saved.\n        if hasattr(self, \"_init_info\"):\n            func(*values.args, **values.kwargs)\n            return\n\n        # Initialize class's self._init_info.\n        self._init_info = {}\n        self._init_info[\"class_module\"] = self.__class__.__module__\n        self._init_info[\"class_name\"] = self.__class__.__name__\n        self._init_info[\"args\"] = {}\n\n        # Populate class's self._init_info.\n        for k, p in sig.parameters.items():\n            if k == 'self':\n                continue\n            if k in values.arguments:\n                val = values.arguments[k]\n                if p.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD, inspect.Parameter.KEYWORD_ONLY):\n                    self._init_info[\"args\"][k] = val\n                elif p.kind == inspect.Parameter.VAR_KEYWORD:\n                    for kwarg_k, kwarg_val in values.arguments[k].items():\n                        self._init_info[\"args\"][kwarg_k] = kwarg_val\n\n        # Call the original function.\n        func(*values.args, **values.kwargs)\n\n    return wrapper\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.save_init_info"},{"title":"<code>subclass_factory(name, base_classes, __init__=None, **kwargs)</code>","text":"<p>Programmatically generates a new class type with name @name, subclassing from base classes @base_classes, with corresponding init call @init.</p> <p>NOTE: If init is None (default), the init call from @base_classes will be used instead.</p> <p>cf. https://stackoverflow.com/questions/15247075/how-can-i-dynamically-create-derived-classes-from-a-base-class</p> <p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>Generated class name</p>  required    <code>base_classes</code>  <code>type, or list of type</code>  <p>Base class(es) to use for generating the subclass</p>  required    <code>__init__</code>  <code>None or function</code>  <p>Init call to use for the base class when it is instantiated. If None if specified, the newly generated class will automatically inherit the init call from @base_classes</p>  <code>None</code>    <code>**kwargs</code>  <code>any</code>  <p>keyword-mapped parameters to override / set in the child class, where the keys represent the class / instance attribute to modify and the values represent the functions / value to set</p>  <code>{}</code>      Source code in <code>utils/python_utils.py</code> <pre><code>def subclass_factory(name, base_classes, __init__=None, **kwargs):\n    \"\"\"\n    Programmatically generates a new class type with name @name, subclassing from base classes @base_classes, with\n    corresponding __init__ call @__init__.\n\n    NOTE: If __init__ is None (default), the __init__ call from @base_classes will be used instead.\n\n    cf. https://stackoverflow.com/questions/15247075/how-can-i-dynamically-create-derived-classes-from-a-base-class\n\n    Args:\n        name (str): Generated class name\n        base_classes (type, or list of type): Base class(es) to use for generating the subclass\n        __init__ (None or function): Init call to use for the base class when it is instantiated. If None if specified,\n            the newly generated class will automatically inherit the __init__ call from @base_classes\n        **kwargs (any): keyword-mapped parameters to override / set in the child class, where the keys represent\n            the class / instance attribute to modify and the values represent the functions / value to set\n    \"\"\"\n    # Standardize base_classes\n    base_classes = tuple(base_classes if isinstance(base_classes, Iterable) else [base_classes])\n\n    # Generate the new class\n    if __init__ is not None:\n        kwargs[\"__init__\"] = __init__\n    return type(name, base_classes, kwargs)\n</code></pre>","location":"reference/utils/python_utils.html#utils.python_utils.subclass_factory"},{"title":"registry_utils","text":"<p>A set of utility functions for registering and tracking objects</p>","location":"reference/utils/registry_utils.html"},{"title":"<code>Registry</code>","text":"<p>         Bases: <code>UniquelyNamed</code></p> <p>Simple class for easily registering and tracking arbitrary objects of the same (or very similar) class types.</p> <p>Elements added are automatically organized by attributes specified by @unique_keys and @group_keys, and can be accessed at runtime by specifying the desired key and indexing value to grab the object(s).</p>  i.e.: a single indexing value will return a single object. <p>default: \"name\" -- indexing by object.name (i.e.: every object's name should be unique)</p>   i.e.: a single indexing value will return a single object. <p>example: indexing by object.name (every object's name should be unique)</p>   i.e.: a single indexing value will return a set of objects. <p>example: indexing by object.in_rooms (many objects can be in a single room)</p>  <p>Note that if a object's attribute is an array of values, then it will be stored under ALL of its values.     example: object.in_rooms = [\"kitchen\", \"living_room\"], indexing by in_rooms with a value of either kitchen OR         living room will return this object as part of its set!</p> <p>You can also easily check for membership in this registry, via either the object's name OR the object itself, e.g.:</p> <pre><code>&gt; object.name in registry\n&gt; object in registry\n\nIf the latter, note that default_key attribute will automatically be used to search for the object\n</code></pre>  Source code in <code>utils/registry_utils.py</code> <pre><code>class Registry(UniquelyNamed):\n    \"\"\"\n    Simple class for easily registering and tracking arbitrary objects of the same (or very similar) class types.\n\n    Elements added are automatically organized by attributes specified by @unique_keys and @group_keys, and\n    can be accessed at runtime by specifying the desired key and indexing value to grab the object(s).\n\n    Default_key is a 1-to-1 mapping: i.e.: a single indexing value will return a single object.\n        default: \"name\" -- indexing by object.name (i.e.: every object's name should be unique)\n    Unique_keys are other 1-to-1 mappings: i.e.: a single indexing value will return a single object.\n        example: indexing by object.name (every object's name should be unique)\n    Group_keys are 1-to-many mappings: i.e.: a single indexing value will return a set of objects.\n        example: indexing by object.in_rooms (many objects can be in a single room)\n\n    Note that if a object's attribute is an array of values, then it will be stored under ALL of its values.\n        example: object.in_rooms = [\"kitchen\", \"living_room\"], indexing by in_rooms with a value of either kitchen OR\n            living room will return this object as part of its set!\n\n    You can also easily check for membership in this registry, via either the object's name OR the object itself,\n    e.g.:\n\n        &gt; object.name in registry\n        &gt; object in registry\n\n        If the latter, note that default_key attribute will automatically be used to search for the object\n    \"\"\"\n    def __init__(\n            self,\n            name,\n            class_types=object,\n            default_key=\"name\",\n            unique_keys=None,\n            group_keys=None,\n            default_value=m.DOES_NOT_EXIST,\n    ):\n        \"\"\"\n        Args:\n            name (str): name of this registry\n            class_types (class or list of class): class expected for all entries in this registry. Default is `object`,\n                meaning any object entered will be accepted. This is used to sanity check added entries using add()\n                to make sure their type is correct (either that the entry itself is a valid class, or that they are an\n                object of the valid class). Note that if a list of classes are passed, any one of the classes are\n                considered a valid type for added objects\n            default_key (str): default key by which to reference a given object. This key should be a\n                publically accessible attribute in a given object (e.g.: object.name) and uniquely identify\n                any entries\n            unique_keys (None or list of str): keys by which to reference a given object. Any key should be a\n                publically accessible attribute in a given object (e.g.: object.name)\n                i.e.: these keys should map to a single object\n\n            group_keys (None or list of str): keys by which to reference a group of objects, based on the key\n                (e.g.: object.room)\n                i.e.: these keys can map to multiple objects\n\n                e.g.: default is \"name\" key only, so we will store objects by their object.name attribute\n\n            default_value (any): Default value to use if the attribute @key does not exist in the object\n        \"\"\"\n        self._name = name\n        self.class_types = class_types if isinstance(class_types, Iterable) else [class_types]\n        self.default_key = default_key\n        self.unique_keys = set([] if unique_keys is None else unique_keys)\n        self.group_keys = set([] if group_keys is None else group_keys)\n        self.default_value = default_value\n\n        # We always add in the \"name\" attribute as well\n        self.unique_keys.add(self.default_key)\n\n        # Make sure there's no overlap between the unique and group keys\n        assert len(self.unique_keys.intersection(self.group_keys)) == 0,\\\n            f\"Cannot create registry with unique and group object keys that are the same! \" \\\n            f\"Unique keys: {self.unique_keys}, group keys: {self.group_keys}\"\n\n        # Create the ordered dicts programmatically\n        for k in self.unique_keys.union(self.group_keys):\n            self.__setattr__(f\"_objects_by_{k}\", OrderedDict())\n\n        # Run super init\n        super().__init__()\n\n    @property\n    def name(self):\n        return self._name\n\n    def add(self, obj):\n        \"\"\"\n        Adds Instance @obj to this registry\n\n        Args:\n            obj (any): Instance to add to this registry\n        \"\"\"\n        # Make sure that obj is of the correct class type\n        assert any([isinstance(obj, class_type) or issubclass(obj, class_type) for class_type in self.class_types]), \\\n            f\"Added object must be either an instance or subclass of one of the following classes: {self.class_types}!\"\n        self._add(obj=obj, keys=self.all_keys)\n\n    def _add(self, obj, keys=None):\n        \"\"\"\n        Same as self.add, but allows for selective @keys for adding this object to. Useful for internal things,\n        such as internal updating of mappings\n\n        Args:\n            obj (any): Instance to add to this registry\n            keys (None or set or list of str): Which object keys to use for adding the object to mappings.\n                None is default, which corresponds to all keys\n        \"\"\"\n        keys = self.all_keys if keys is None else keys\n        for k in keys:\n            obj_attr = self._get_obj_attr(obj=obj, attr=k)\n            # Standardize input as a list\n            obj_attr = obj_attr if \\\n                isinstance(obj_attr, Iterable) and not isinstance(obj_attr, str) else [obj_attr]\n\n            # Loop over all values in this attribute and add to all mappings\n            for attr in obj_attr:\n                mapping = self.get_dict(k)\n                if k in self.unique_keys:\n                    # Handle unique case\n                    if attr in mapping:\n                        logging.warning(f\"Instance identifier '{k}' should be unique for adding to this registry mapping! Existing {k}: {attr}\")\n                        # Special case for \"name\" attribute, which should ALWAYS be unique\n                        if k == \"name\":\n                            logging.error(f\"For name attribute, objects MUST be unique. Exiting.\")\n                            exit(-1)\n                    mapping[attr] = obj\n                else:\n                    # Not unique case\n                    # Possibly initialize list\n                    if attr not in mapping:\n                        mapping[attr] = set()\n                    mapping[attr].add(obj)\n\n    def remove(self, obj):\n        \"\"\"\n        Removes object @object from this registry\n\n        Args:\n            obj (any): Instance to remove from this registry\n        \"\"\"\n        # Iterate over all keys\n        for k in self.all_keys:\n            # Grab the attribute from the object\n            obj_attr = self._get_obj_attr(obj=obj, attr=k)\n            # Standardize input as a list\n            obj_attr = obj_attr if \\\n                isinstance(obj_attr, Iterable) and not isinstance(obj_attr, str) else [obj_attr]\n\n            # Loop over all values in this attribute and remove them from all mappings\n            for attr in obj_attr:\n                mapping = self.get_dict(k)\n                if k in self.unique_keys:\n                    # Handle unique case -- in this case, we just directly pop the value from the dictionary\n                    mapping.pop(attr)\n                else:\n                    # Not unique case\n                    # We remove a value from the resulting set\n                    mapping[attr].remove(obj)\n\n    def update(self, keys=None):\n        \"\"\"\n        Updates this registry, refreshing all internal mappings in case an object's value was updated\n\n        Args:\n            keys (None or str or set or list of str): Which object keys to update. None is default, which corresponds\n                to all keys\n        \"\"\"\n        objects = self.objects\n        keys = self.all_keys if keys is None else \\\n            (keys if type(keys) in {tuple, list} else [keys])\n\n        # Delete and re-create all keys mappings\n        for k in keys:\n            self.__delattr__(f\"_objects_by_{k}\")\n            self.__setattr__(f\"_objects_by_{k}\", OrderedDict())\n\n            # Iterate over all objects and re-populate the mappings\n            for obj in objects:\n                self._add(obj=obj, keys=[k])\n\n    def object_is_registered(self, obj):\n        \"\"\"\n        Check if a given object @object is registered\n\n        Args:\n            obj (any): Instance to check if it is internally registered\n        \"\"\"\n        return obj in self.objects\n\n    def get_dict(self, key):\n        \"\"\"\n        Specific mapping dictionary within this registry corresponding to the mappings of @key.\n            e.g.: if key = \"name\", this will return the ordered dictionary mapping object.name to objects\n\n        Args:\n            key (str): Key with which to grab mapping dict from\n\n        Returns:\n            OrderedDict: Mapping from identifiers to object(s) based on @key\n        \"\"\"\n        return getattr(self, f\"_objects_by_{key}\")\n\n    def get_ids(self, key):\n        \"\"\"\n        All identifiers within this registry corresponding to the mappings of @key.\n            e.g.: if key = \"name\", this will return all \"names\" stored internally that index into a object\n        Args:\n            key (str): Key with which to grab all identifiers from\n\n        Returns:\n            set: All identifiers within this registry corresponding to the mappings of @key.\n        \"\"\"\n        return set(self.get_dict(key=key).keys())\n\n    def _get_obj_attr(self, obj, attr):\n        \"\"\"\n        Grabs object's @obj's attribute @attr. Additionally checks to see if @obj is a class or a class instance, and\n        uses the correct logic\n\n        Args:\n            obj (any): Object to grab attribute from\n            attr (str): String name of the attribute to grab\n\n        Return:\n            any: Attribute @k of @obj\n        \"\"\"\n        # We try to grab the object's attribute, and if it fails we fallback to the default value\n        try:\n            val = getattr(obj, attr)\n\n        except:\n            val = self.default_value\n\n        return val\n\n    @property\n    def objects(self):\n        \"\"\"\n        Get the objects in this registry\n\n        Returns:\n            list of any: Instances owned by this registry\n        \"\"\"\n        return list(self.get_dict(self.default_key).values())\n\n    @property\n    def all_keys(self):\n        \"\"\"\n        Returns:\n            set of str: All object keys that are valid identification methods to index object(s)\n        \"\"\"\n        return self.unique_keys.union(self.group_keys)\n\n    def __call__(self, key, value, default_val=None):\n        \"\"\"\n        Grab the object in this registry based on @key and @value\n\n        Args:\n            key (str): What identification type to use to grab the requested object(s).\n                Should be one of @self.all_keys.\n            value (any): Value to grab. Should be the value of your requested object.&lt;key&gt; attribute\n            default_val (any): Default value to return if @value is not found\n\n        Returns:\n            any or set of any: requested unique object if @key is one of unique_keys, else a set if\n                @key is one of group_keys\n        \"\"\"\n        assert key in self.all_keys,\\\n            f\"Invalid key requested! Valid options are: {self.all_keys}, got: {key}\"\n\n        return self.get_dict(key).get(value, default_val)\n\n    def __contains__(self, obj):\n        # Instance can be either a string (default key) OR the object itself\n        if isinstance(obj, str):\n            obj = self(self.default_key, obj)\n        return self.object_is_registered(obj=obj)\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry"},{"title":"<code>all_keys</code>  <code>property</code>","text":"<p>Returns:</p>    Type Description       <p>set of str: All object keys that are valid identification methods to index object(s)</p>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.all_keys"},{"title":"<code>objects</code>  <code>property</code>","text":"<p>Get the objects in this registry</p> <p>Returns:</p>    Type Description       <p>list of any: Instances owned by this registry</p>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.objects"},{"title":"<code>__call__(key, value, default_val=None)</code>","text":"<p>Grab the object in this registry based on @key and @value</p> <p>Parameters:</p>    Name Type Description Default     <code>key</code>  <code>str</code>  <p>What identification type to use to grab the requested object(s). Should be one of @self.all_keys.</p>  required    <code>value</code>  <code>any</code>  <p>Value to grab. Should be the value of your requested object. attribute  required    <code>default_val</code>  <code>any</code>  <p>Default value to return if @value is not found</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>any or set of any: requested unique object if @key is one of unique_keys, else a set if @key is one of group_keys</p>     Source code in <code>utils/registry_utils.py</code> <pre><code>def __call__(self, key, value, default_val=None):\n    \"\"\"\n    Grab the object in this registry based on @key and @value\n\n    Args:\n        key (str): What identification type to use to grab the requested object(s).\n            Should be one of @self.all_keys.\n        value (any): Value to grab. Should be the value of your requested object.&lt;key&gt; attribute\n        default_val (any): Default value to return if @value is not found\n\n    Returns:\n        any or set of any: requested unique object if @key is one of unique_keys, else a set if\n            @key is one of group_keys\n    \"\"\"\n    assert key in self.all_keys,\\\n        f\"Invalid key requested! Valid options are: {self.all_keys}, got: {key}\"\n\n    return self.get_dict(key).get(value, default_val)\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.__call__"},{"title":"<code>__init__(name, class_types=object, default_key='name', unique_keys=None, group_keys=None, default_value=m.DOES_NOT_EXIST)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>name</code>  <code>str</code>  <p>name of this registry</p>  required    <code>class_types</code>  <code>class or list of class</code>  <p>class expected for all entries in this registry. Default is <code>object</code>, meaning any object entered will be accepted. This is used to sanity check added entries using add() to make sure their type is correct (either that the entry itself is a valid class, or that they are an object of the valid class). Note that if a list of classes are passed, any one of the classes are considered a valid type for added objects</p>  <code>object</code>    <code>default_key</code>  <code>str</code>  <p>default key by which to reference a given object. This key should be a publically accessible attribute in a given object (e.g.: object.name) and uniquely identify any entries</p>  <code>'name'</code>    <code>unique_keys</code>  <code>None or list of str</code>  <p>keys by which to reference a given object. Any key should be a publically accessible attribute in a given object (e.g.: object.name) i.e.: these keys should map to a single object</p>  <code>None</code>    <code>group_keys</code>  <code>None or list of str</code>  <p>keys by which to reference a group of objects, based on the key (e.g.: object.room) i.e.: these keys can map to multiple objects</p> <p>e.g.: default is \"name\" key only, so we will store objects by their object.name attribute</p>  <code>None</code>    <code>default_value</code>  <code>any</code>  <p>Default value to use if the attribute @key does not exist in the object</p>  <code>m.DOES_NOT_EXIST</code>      Source code in <code>utils/registry_utils.py</code> <pre><code>def __init__(\n        self,\n        name,\n        class_types=object,\n        default_key=\"name\",\n        unique_keys=None,\n        group_keys=None,\n        default_value=m.DOES_NOT_EXIST,\n):\n    \"\"\"\n    Args:\n        name (str): name of this registry\n        class_types (class or list of class): class expected for all entries in this registry. Default is `object`,\n            meaning any object entered will be accepted. This is used to sanity check added entries using add()\n            to make sure their type is correct (either that the entry itself is a valid class, or that they are an\n            object of the valid class). Note that if a list of classes are passed, any one of the classes are\n            considered a valid type for added objects\n        default_key (str): default key by which to reference a given object. This key should be a\n            publically accessible attribute in a given object (e.g.: object.name) and uniquely identify\n            any entries\n        unique_keys (None or list of str): keys by which to reference a given object. Any key should be a\n            publically accessible attribute in a given object (e.g.: object.name)\n            i.e.: these keys should map to a single object\n\n        group_keys (None or list of str): keys by which to reference a group of objects, based on the key\n            (e.g.: object.room)\n            i.e.: these keys can map to multiple objects\n\n            e.g.: default is \"name\" key only, so we will store objects by their object.name attribute\n\n        default_value (any): Default value to use if the attribute @key does not exist in the object\n    \"\"\"\n    self._name = name\n    self.class_types = class_types if isinstance(class_types, Iterable) else [class_types]\n    self.default_key = default_key\n    self.unique_keys = set([] if unique_keys is None else unique_keys)\n    self.group_keys = set([] if group_keys is None else group_keys)\n    self.default_value = default_value\n\n    # We always add in the \"name\" attribute as well\n    self.unique_keys.add(self.default_key)\n\n    # Make sure there's no overlap between the unique and group keys\n    assert len(self.unique_keys.intersection(self.group_keys)) == 0,\\\n        f\"Cannot create registry with unique and group object keys that are the same! \" \\\n        f\"Unique keys: {self.unique_keys}, group keys: {self.group_keys}\"\n\n    # Create the ordered dicts programmatically\n    for k in self.unique_keys.union(self.group_keys):\n        self.__setattr__(f\"_objects_by_{k}\", OrderedDict())\n\n    # Run super init\n    super().__init__()\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.__init__"},{"title":"<code>add(obj)</code>","text":"<p>Adds Instance @obj to this registry</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>any</code>  <p>Instance to add to this registry</p>  required      Source code in <code>utils/registry_utils.py</code> <pre><code>def add(self, obj):\n    \"\"\"\n    Adds Instance @obj to this registry\n\n    Args:\n        obj (any): Instance to add to this registry\n    \"\"\"\n    # Make sure that obj is of the correct class type\n    assert any([isinstance(obj, class_type) or issubclass(obj, class_type) for class_type in self.class_types]), \\\n        f\"Added object must be either an instance or subclass of one of the following classes: {self.class_types}!\"\n    self._add(obj=obj, keys=self.all_keys)\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.add"},{"title":"<code>get_dict(key)</code>","text":"<p>Specific mapping dictionary within this registry corresponding to the mappings of @key.     e.g.: if key = \"name\", this will return the ordered dictionary mapping object.name to objects</p> <p>Parameters:</p>    Name Type Description Default     <code>key</code>  <code>str</code>  <p>Key with which to grab mapping dict from</p>  required     <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Mapping from identifiers to object(s) based on @key</p>     Source code in <code>utils/registry_utils.py</code> <pre><code>def get_dict(self, key):\n    \"\"\"\n    Specific mapping dictionary within this registry corresponding to the mappings of @key.\n        e.g.: if key = \"name\", this will return the ordered dictionary mapping object.name to objects\n\n    Args:\n        key (str): Key with which to grab mapping dict from\n\n    Returns:\n        OrderedDict: Mapping from identifiers to object(s) based on @key\n    \"\"\"\n    return getattr(self, f\"_objects_by_{key}\")\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.get_dict"},{"title":"<code>get_ids(key)</code>","text":"<p>All identifiers within this registry corresponding to the mappings of @key.     e.g.: if key = \"name\", this will return all \"names\" stored internally that index into a object</p> <p>Parameters:</p>    Name Type Description Default     <code>key</code>  <code>str</code>  <p>Key with which to grab all identifiers from</p>  required     <p>Returns:</p>    Name Type Description     <code>set</code>   <p>All identifiers within this registry corresponding to the mappings of @key.</p>     Source code in <code>utils/registry_utils.py</code> <pre><code>def get_ids(self, key):\n    \"\"\"\n    All identifiers within this registry corresponding to the mappings of @key.\n        e.g.: if key = \"name\", this will return all \"names\" stored internally that index into a object\n    Args:\n        key (str): Key with which to grab all identifiers from\n\n    Returns:\n        set: All identifiers within this registry corresponding to the mappings of @key.\n    \"\"\"\n    return set(self.get_dict(key=key).keys())\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.get_ids"},{"title":"<code>object_is_registered(obj)</code>","text":"<p>Check if a given object @object is registered</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>any</code>  <p>Instance to check if it is internally registered</p>  required      Source code in <code>utils/registry_utils.py</code> <pre><code>def object_is_registered(self, obj):\n    \"\"\"\n    Check if a given object @object is registered\n\n    Args:\n        obj (any): Instance to check if it is internally registered\n    \"\"\"\n    return obj in self.objects\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.object_is_registered"},{"title":"<code>remove(obj)</code>","text":"<p>Removes object @object from this registry</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>any</code>  <p>Instance to remove from this registry</p>  required      Source code in <code>utils/registry_utils.py</code> <pre><code>def remove(self, obj):\n    \"\"\"\n    Removes object @object from this registry\n\n    Args:\n        obj (any): Instance to remove from this registry\n    \"\"\"\n    # Iterate over all keys\n    for k in self.all_keys:\n        # Grab the attribute from the object\n        obj_attr = self._get_obj_attr(obj=obj, attr=k)\n        # Standardize input as a list\n        obj_attr = obj_attr if \\\n            isinstance(obj_attr, Iterable) and not isinstance(obj_attr, str) else [obj_attr]\n\n        # Loop over all values in this attribute and remove them from all mappings\n        for attr in obj_attr:\n            mapping = self.get_dict(k)\n            if k in self.unique_keys:\n                # Handle unique case -- in this case, we just directly pop the value from the dictionary\n                mapping.pop(attr)\n            else:\n                # Not unique case\n                # We remove a value from the resulting set\n                mapping[attr].remove(obj)\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.remove"},{"title":"<code>update(keys=None)</code>","text":"<p>Updates this registry, refreshing all internal mappings in case an object's value was updated</p> <p>Parameters:</p>    Name Type Description Default     <code>keys</code>  <code>None or str or set or list of str</code>  <p>Which object keys to update. None is default, which corresponds to all keys</p>  <code>None</code>      Source code in <code>utils/registry_utils.py</code> <pre><code>def update(self, keys=None):\n    \"\"\"\n    Updates this registry, refreshing all internal mappings in case an object's value was updated\n\n    Args:\n        keys (None or str or set or list of str): Which object keys to update. None is default, which corresponds\n            to all keys\n    \"\"\"\n    objects = self.objects\n    keys = self.all_keys if keys is None else \\\n        (keys if type(keys) in {tuple, list} else [keys])\n\n    # Delete and re-create all keys mappings\n    for k in keys:\n        self.__delattr__(f\"_objects_by_{k}\")\n        self.__setattr__(f\"_objects_by_{k}\", OrderedDict())\n\n        # Iterate over all objects and re-populate the mappings\n        for obj in objects:\n            self._add(obj=obj, keys=[k])\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.Registry.update"},{"title":"<code>SerializableRegistry</code>","text":"<p>         Bases: <code>Registry</code>, <code>Serializable</code></p> <p>Registry that is serializable, i.e.: entries contain states that can themselves be serialized /deserialized.</p> <p>Note that this assumes that any objects added to this registry are themselves of @Serializable type!</p>  Source code in <code>utils/registry_utils.py</code> <pre><code>class SerializableRegistry(Registry, Serializable):\n    \"\"\"\n    Registry that is serializable, i.e.: entries contain states that can themselves be serialized /deserialized.\n\n    Note that this assumes that any objects added to this registry are themselves of @Serializable type!\n    \"\"\"\n\n    def add(self, obj):\n        # In addition to any other class types, we make sure that the object is a serializable instance / class\n        validate_class = issubclass if isclass(obj) else isinstance\n        assert any([validate_class(obj, class_type) for class_type in (Serializable, SerializableNonInstance)]), \\\n            f\"Added object must be either an instance or subclass of Serializable or SerializableNonInstance!\"\n        # Run super like normal\n        super().add(obj=obj)\n\n    @property\n    def state_size(self):\n        # Total state size is the sum of all individual states from each object\n        for obj in self.objects:\n            print(obj.name)\n            print(obj.state_size)\n        return sum(obj.state_size for obj in self.objects)\n\n    def _dump_state(self):\n        # Iterate over all objects and grab their states\n        state = OrderedDict()\n        for obj in self.objects:\n            state[obj.name] = obj.dump_state(serialized=False)\n        return state\n\n    def _load_state(self, state):\n        # Iterate over all objects and load their states\n        for obj in self.objects:\n            if obj.name not in state:\n                logging.warning(f\"Object '{obj.name}' is not in the state dict to load from. Skip loading its state.\")\n                continue\n            obj.load_state(state[obj.name], serialized=False)\n\n    def _serialize(self, state):\n        # Iterate over the entire dict and flatten\n        return np.concatenate([obj.serialize(state[obj.name]) for obj in self.objects]) if \\\n            len(self.objects) &gt; 0 else np.array([])\n\n    def _deserialize(self, state):\n        state_dict = OrderedDict()\n        # Iterate over all the objects and deserialize their individual states, incrementing the index counter\n        # along the way\n        idx = 0\n        for obj in self.objects:\n            print(f\"obj: {obj.name}, state size: {obj.state_size}, idx: {idx}, passing in state length: {len(state[idx:])}\")\n            # We pass in the entire remaining state vector, assuming the object only parses the relevant states\n            # at the beginning\n            state_dict[obj.name] = obj.deserialize(state[idx:])\n            idx += obj.state_size\n        return state_dict, idx\n</code></pre>","location":"reference/utils/registry_utils.html#utils.registry_utils.SerializableRegistry"},{"title":"render_utils","text":"<p>Set of rendering utility functions when working with Omni</p>","location":"reference/utils/render_utils.html"},{"title":"<code>create_pbr_material(prim_path)</code>","text":"<p>Creates an omni pbr material prim at the specified @prim_path</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Prim path where the PBR material should be generated</p>  required     <p>Returns:</p>    Type Description       <p>Usd.Prim: Generated PBR material prim</p>     Source code in <code>utils/render_utils.py</code> <pre><code>def create_pbr_material(prim_path):\n    \"\"\"\n    Creates an omni pbr material prim at the specified @prim_path\n\n    Args:\n        prim_path (str): Prim path where the PBR material should be generated\n\n    Returns:\n        Usd.Prim: Generated PBR material prim\n    \"\"\"\n    # Use DeepWater omni present for rendering water\n    mtl_created = []\n    omni.kit.commands.execute(\n        \"CreateAndBindMdlMaterialFromLibrary\",\n        mdl_name=\"OmniPBR.mdl\",\n        mtl_name=\"OmniPBR\",\n        mtl_created_list=mtl_created,\n    )\n    material_path = mtl_created[0]\n\n    # Move prim to desired location\n    omni.kit.commands.execute(\"MovePrim\", path_from=material_path, path_to=prim_path)\n\n    # Return generated material\n    return get_prim_at_path(material_path)\n</code></pre>","location":"reference/utils/render_utils.html#utils.render_utils.create_pbr_material"},{"title":"<code>create_skylight(intensity=500, color=(1.0, 1.0, 1.0))</code>","text":"<p>Creates a skylight object with the requested @color</p> <p>Parameters:</p>    Name Type Description Default     <code>intensity</code>  <code>float</code>  <p>Intensity of the generated skylight</p>  <code>500</code>    <code>color</code>  <code>3-array</code>  <p>Desired (R,G,B) color to assign to the skylight</p>  <code>(1.0, 1.0, 1.0)</code>     <p>Returns:</p>    Name Type Description     <code>LightObject</code>   <p>Generated skylight object</p>     Source code in <code>utils/render_utils.py</code> <pre><code>def create_skylight(intensity=500, color=(1.0, 1.0, 1.0)):\n    \"\"\"\n    Creates a skylight object with the requested @color\n\n    Args:\n        intensity (float): Intensity of the generated skylight\n        color (3-array): Desired (R,G,B) color to assign to the skylight\n\n    Returns:\n        LightObject: Generated skylight object\n    \"\"\"\n    # Avoid circular imports\n    from omnigibson.objects.light_object import LightObject\n    light = LightObject(prim_path=\"/World/skylight\", name=\"skylight\", light_type=\"Dome\", intensity=intensity)\n    og.sim.import_object(light)\n    light.set_orientation(T.euler2quat([0, 0, -np.pi / 4]))\n    light_prim = light.light_link.prim\n    light_prim.GetAttribute(\"color\").Set(Gf.Vec3f(*color))\n    return light\n</code></pre>","location":"reference/utils/render_utils.html#utils.render_utils.create_skylight"},{"title":"<code>make_glass(prim)</code>","text":"<p>Links the OmniGlass material with EntityPrim, RigidPrim, or VisualGeomPrim @obj, and procedurally generates the necessary OmniGlass material prim if necessary.</p> <p>Parameters:</p>    Name Type Description Default     <code>prim</code>  <code>EntityPrim or RigidPrim or VisualGeomPrim</code>  <p>Desired prim to convert into glass</p>  required      Source code in <code>utils/render_utils.py</code> <pre><code>def make_glass(prim):\n    \"\"\"\n    Links the OmniGlass material with EntityPrim, RigidPrim, or VisualGeomPrim @obj, and procedurally generates\n    the necessary OmniGlass material prim if necessary.\n\n    Args:\n        prim (EntityPrim or RigidPrim or VisualGeomPrim): Desired prim to convert into glass\n    \"\"\"\n    # Generate the set of visual meshes we'll convert into glass\n    if isinstance(prim, EntityPrim):\n        # Grab all visual meshes from all links\n        visual_meshes = [vm for link in prim.links.values() for vm in link.visual_meshes.values()]\n    elif isinstance(prim, RigidPrim):\n        # Grab all visual meshes from the link\n        visual_meshes = [vm for vm in prim.visual_meshes.values()]\n    elif isinstance(prim, VisualGeomPrim):\n        # Just use this visual mesh\n        visual_meshes = [prim]\n    else:\n        raise ValueError(f\"Inputted prim must an instance of EntityPrim, RigidPrim, or VisualGeomPrim \"\n                         f\"in order to be converted into glass!\")\n\n    # Grab the glass material prim; if it doesn't exist, we create it on the fly\n    glass_prim_path = \"/Looks/OmniGlass\"\n    if not get_prim_at_path(glass_prim_path):\n        mtl_created = []\n        omni.kit.commands.execute(\n            \"CreateAndBindMdlMaterialFromLibrary\",\n            mdl_name=\"OmniGlass.mdl\",\n            mtl_name=\"OmniGlass\",\n            mtl_created_list=mtl_created,\n        )\n\n    # Iterate over all meshes and bind the glass material to the mesh\n    for vm in visual_meshes:\n        bind_material(vm.prim_path, material_path=glass_prim_path)\n</code></pre>","location":"reference/utils/render_utils.html#utils.render_utils.make_glass"},{"title":"sampling_utils","text":"","location":"reference/utils/sampling_utils.html"},{"title":"<code>check_cuboid_empty(hit_normal, bottom_corner_positions, this_cuboid_dimensions, refusal_log, ignore_body_names=None)</code>","text":"<p>Check whether the cuboid defined by @this_cuboid_dimensions and @bottom_corner_positions contains empty space or not</p> <p>Parameters:</p>    Name Type Description Default     <code>hit_normal</code>  <code>3-array</code>  <p>(x,y,z) normal</p>  required    <code>bottom_corner_positions</code>  <code>4, 3)-array</code>  <p>the positions defining the bottom corners of the cuboid being sampled</p>  required    <code>this_cuboid_dimensions</code>  <code>3-array</code>  <p>(x,y,z) size of the sampled cuboid</p>  required    <code>refusal_log</code>  <code>list of str</code>  <p>Logging array for adding debug logs</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if the cuboid is empty, else False</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def check_cuboid_empty(hit_normal, bottom_corner_positions, this_cuboid_dimensions, refusal_log, ignore_body_names=None):\n    \"\"\"\n    Check whether the cuboid defined by @this_cuboid_dimensions and @bottom_corner_positions contains\n    empty space or not\n\n    Args:\n        hit_normal (3-array): (x,y,z) normal\n        bottom_corner_positions ((4, 3)-array): the positions defining the bottom corners of the cuboid\n            being sampled\n        this_cuboid_dimensions (3-array): (x,y,z) size of the sampled cuboid\n        refusal_log (list of str): Logging array for adding debug logs\n\n    Returns:\n        bool: True if the cuboid is empty, else False\n    \"\"\"\n    if og.debug_sampling:\n        draw_debug_markers(bottom_corner_positions)\n\n    # Compute top corners.\n    top_corner_positions = bottom_corner_positions + hit_normal * this_cuboid_dimensions[2]\n\n    # We only generate valid rays that have nonzero distances. If the inputted cuboid is flat (i.e.: one dimension\n    # is zero, i.e.: it is in fact a rectangle), some of our generated rays will have zero distance\n\n    # Get all the top-to-bottom corner pairs. When we cast these rays, we check for two things: that the cuboid\n    # height is actually available, and the faces &amp; volume of the cuboid are unoccupied.\n    top_to_bottom_pairs = [] if this_cuboid_dimensions[2] == 0 else \\\n        list(itertools.product(top_corner_positions, bottom_corner_positions))\n\n    # Get all the same-height pairs. These also check that the surfaces areas are empty.\n    # Note: These are redundant if our cuboid has zero height!\n    bottom_pairs = list(itertools.combinations(bottom_corner_positions, 2))\n    top_pairs = [] if this_cuboid_dimensions[2] == 0 else list(itertools.combinations(top_corner_positions, 2))\n\n    # Combine all these pairs, cast the rays, and make sure the rays don't hit anything.\n    all_pairs = np.array(top_to_bottom_pairs + bottom_pairs + top_pairs)\n    check_cast_results = raytest_batch(start_points=all_pairs[:, 0, :], end_points=all_pairs[:, 1, :], ignore_bodies=ignore_body_names)\n    if any(ray[\"hit\"] for ray in check_cast_results):\n        if og.debug_sampling:\n            refusal_log.append(\"check ray info: %r\" % (check_cast_results))\n\n        return False\n\n    return True\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_cuboid_empty"},{"title":"<code>check_distance_to_plane(points, plane_centroid, plane_normal, hit_to_plane_threshold, refusal_log)</code>","text":"<p>Calculates whether points are within @hit_to_plane_threshold distance to plane defined by @plane_centroid and @plane_normal</p> <p>Parameters:</p>    Name Type Description Default     <code>points</code>  <code>k, 3)-array</code>  <p>np.array of shape (k, 3)</p>  required    <code>plane_centroid</code>  <code>3-array</code>  <p>(x,y,z) points' centroid</p>  required    <code>plane_normal</code>  <code>3-array</code>  <p>(x,y,z) normal of the fitted plane</p>  required    <code>hit_to_plane_threshold</code>  <code>float</code>  <p>Threshold distance to check between @points and plane</p>  required    <code>refusal_log</code>  <code>dict</code>  <p>Debugging dictionary to add error messages to</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if all points are within @hit_to_plane_threshold distance to plane, otherwise False</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def check_distance_to_plane(points, plane_centroid, plane_normal, hit_to_plane_threshold, refusal_log):\n    \"\"\"\n    Calculates whether points are within @hit_to_plane_threshold distance to plane defined by @plane_centroid\n    and @plane_normal\n\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n        plane_centroid (3-array): (x,y,z) points' centroid\n        plane_normal (3-array): (x,y,z) normal of the fitted plane\n        hit_to_plane_threshold (float): Threshold distance to check between @points and plane\n        refusal_log (dict): Debugging dictionary to add error messages to\n\n    Returns:\n        bool: True if all points are within @hit_to_plane_threshold distance to plane, otherwise False\n    \"\"\"\n    distances = get_distance_to_plane(points, plane_centroid, plane_normal)\n    if np.any(distances &gt; hit_to_plane_threshold):\n        if og.debug_sampling:\n            refusal_log.append(\"distances to plane: %r\" % distances)\n        return False\n    return True\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_distance_to_plane"},{"title":"<code>check_hit_max_angle_from_z_axis(hit_normal, max_angle_with_z_axis, refusal_log)</code>","text":"<p>Check whether the normal @hit_normal deviates from the global z axis by more than @max_angle_with_z_axis</p> <p>Parameters:</p>    Name Type Description Default     <code>hit_normal</code>  <code>3-array</code>  <p>Normal vector to check with respect to global z-axis</p>  required    <code>max_angle_with_z_axis</code>  <code>float</code>  <p>Maximum acceptable angle between the global z-axis and @hit_normal</p>  required    <code>refusal_log</code>  <code>list of str</code>  <p>Logging array for adding debug logs</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if the angle between @hit_normal and the global z-axis is less than @max_angle_with_z_axis, otherwise False</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def check_hit_max_angle_from_z_axis(hit_normal, max_angle_with_z_axis, refusal_log):\n    \"\"\"\n    Check whether the normal @hit_normal deviates from the global z axis by more than @max_angle_with_z_axis\n\n    Args:\n        hit_normal (3-array): Normal vector to check with respect to global z-axis\n        max_angle_with_z_axis (float): Maximum acceptable angle between the global z-axis and @hit_normal\n        refusal_log (list of str): Logging array for adding debug logs\n\n    Returns:\n        bool: True if the angle between @hit_normal and the global z-axis is less than @max_angle_with_z_axis,\n            otherwise False\n    \"\"\"\n    hit_angle_with_z = np.arccos(np.clip(np.dot(hit_normal, np.array([0, 0, 1])), -1.0, 1.0))\n    if hit_angle_with_z &gt; max_angle_with_z_axis:\n        if og.debug_sampling:\n            refusal_log.append(\"normal %r\" % hit_normal)\n\n        return False\n\n    return True\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_hit_max_angle_from_z_axis"},{"title":"<code>check_normal_similarity(center_hit_normal, hit_normals, tolerance, refusal_log)</code>","text":"<p>Check whether the normals from @hit_normals are within some @tolerance of @center_hit_normal.</p> <p>Parameters:</p>    Name Type Description Default     <code>center_hit_normal</code>  <code>3-array</code>  <p>normal of the center hit point</p>  required    <code>hit_normals</code>  <code>n, 3)-array</code>  <p>normals of all the hit points</p>  required    <code>tolerance</code>  <code>float</code>  <p>Acceptable deviation between the center hit normal and all normals</p>  required    <code>refusal_log</code>  <code>dict</code>  <p>Dictionary to write debugging and log information to</p>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether the normal similarity is acceptable or not</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def check_normal_similarity(center_hit_normal, hit_normals, tolerance, refusal_log):\n    \"\"\"\n    Check whether the normals from @hit_normals are within some @tolerance of @center_hit_normal.\n\n    Args:\n        center_hit_normal (3-array): normal of the center hit point\n        hit_normals ((n, 3)-array): normals of all the hit points\n        tolerance (float): Acceptable deviation between the center hit normal and all normals\n        refusal_log (dict): Dictionary to write debugging and log information to\n\n    Returns:\n        bool: Whether the normal similarity is acceptable or not\n    \"\"\"\n    parallel_hit_main_hit_dot_products = np.clip(\n        np.dot(hit_normals, center_hit_normal)\n        / (np.linalg.norm(hit_normals, axis=1) * np.linalg.norm(center_hit_normal)),\n        -1.0,\n        1.0,\n    )\n    parallel_hit_normal_angles_to_hit_normal = np.arccos(parallel_hit_main_hit_dot_products)\n    all_rays_hit_with_similar_normal = np.all(\n        parallel_hit_normal_angles_to_hit_normal &lt; tolerance\n    )\n    if not all_rays_hit_with_similar_normal:\n        if og.debug_sampling:\n            refusal_log.append(\"angles %r\" % (np.rad2deg(parallel_hit_normal_angles_to_hit_normal),))\n\n        return False\n\n    return True\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_normal_similarity"},{"title":"<code>check_rays_hit_object(cast_results, threshold, refusal_log, body_names=None, ignore_body_names=None)</code>","text":"<p>Checks whether rays hit a specific object, as specified by a list of @body_names</p> <p>Parameters:</p>    Name Type Description Default     <code>cast_results</code>  <code>list of dict</code>  <p>Output from raycast_batch.</p>  required    <code>threshold</code>  <code>float</code>  <p>Relative ratio in [0, 1] specifying proportion of rays from @cast_results are required to hit @body_names to count as the object being hit</p>  required    <code>refusal_log</code>  <code>list of str</code>  <p>Logging array for adding debug logs</p>  required    <code>body_names</code>  <code>None or list or set of str</code>  <p>absolute USD paths to rigid bodies to check for hit. If not specified, then any valid hit will be accepted</p>  <code>None</code>    <code>ignore_body_names</code>  <code>None or list or set of str</code>  <p>absolute USD paths to rigid bodies to ignore for hit. If not specified, then any valid hit will be accepted</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>None or list of bool: Individual T/F for each ray -- whether it hit the object or not</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def check_rays_hit_object(cast_results, threshold, refusal_log, body_names=None, ignore_body_names=None):\n    \"\"\"\n    Checks whether rays hit a specific object, as specified by a list of @body_names\n\n    Args:\n        cast_results (list of dict): Output from raycast_batch.\n        threshold (float): Relative ratio in [0, 1] specifying proportion of rays from @cast_results are\n            required to hit @body_names to count as the object being hit\n        refusal_log (list of str): Logging array for adding debug logs\n        body_names (None or list or set of str): absolute USD paths to rigid bodies to check for hit. If not\n            specified, then any valid hit will be accepted\n        ignore_body_names (None or list or set of str): absolute USD paths to rigid bodies to ignore for hit. If not\n            specified, then any valid hit will be accepted\n\n    Returns:\n        None or list of bool: Individual T/F for each ray -- whether it hit the object or not\n    \"\"\"\n    body_names = None if body_names is None else set(body_names)\n    ray_hits = [\n        ray_res[\"hit\"] and\n        (body_names is None or ray_res[\"rigidBody\"] in body_names) and\n        (ignore_body_names is None or ray_res[\"rigidBody\"] not in ignore_body_names)\n        for ray_res in cast_results\n    ]\n    if sum(ray_hits) / len(cast_results) &lt; threshold:\n        if og.debug_sampling:\n            refusal_log.append(f\"{sum(ray_hits)} / {len(cast_results)} &lt; {threshold} hits: {[ray_res['rigidBody'] for ray_res in cast_results if ray_res['hit']]}\")\n\n        return None\n\n    return ray_hits\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.check_rays_hit_object"},{"title":"<code>compute_ray_destination(axis, is_top, start_pos, aabb_min, aabb_max)</code>","text":"<p>Compute the point on the AABB defined by @aabb_min and @aabb_max from shooting a ray at @start_pos in the direction defined by global axis @axis and @is_top</p> <p>Parameters:</p>    Name Type Description Default     <code>axis</code>  <code>int</code>  <p>Which direction to compute the ray destination. Valid options are {0, 1, 2} -- the x, y, or z axes</p>  required    <code>is_top</code>  <code>bool</code>  <p>Whether to shoot in the positive or negative @axis direction</p>  required    <code>aabb_min</code>  <code>3-array</code>  <p>(x,y,z) position defining the lower corner of the AABB</p>  required    <code>aabb_max</code>  <code>3-array</code>  <p>(x,y,z) position defining the upper corner of the AABB</p>  required     <p>Returns:</p>    Type Description       <p>3-array: computed (x,y,z) point on the AABB surface</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def compute_ray_destination(axis, is_top, start_pos, aabb_min, aabb_max):\n    \"\"\"\n    Compute the point on the AABB defined by @aabb_min and @aabb_max from shooting a ray at @start_pos\n    in the direction defined by global axis @axis and @is_top\n\n    Args:\n        axis (int): Which direction to compute the ray destination. Valid options are {0, 1, 2} -- the\n            x, y, or z axes\n        is_top (bool): Whether to shoot in the positive or negative @axis direction\n        aabb_min (3-array): (x,y,z) position defining the lower corner of the AABB\n        aabb_max (3-array): (x,y,z) position defining the upper corner of the AABB\n\n    Returns:\n        3-array: computed (x,y,z) point on the AABB surface\n    \"\"\"\n    # Get the ray casting direction - we want to do it parallel to the sample axis.\n    ray_direction = np.array([0, 0, 0])\n    ray_direction[axis] = 1\n    ray_direction *= -1 if is_top else 1\n\n    # We want to extend our ray until it intersects one of the AABB's faces.\n    # Start by getting the distances towards the min and max boundaries of the AABB on each axis.\n    point_to_min = aabb_min - start_pos\n    point_to_max = aabb_max - start_pos\n\n    # Then choose the distance to the point in the correct direction on each axis.\n    closer_point_on_each_axis = np.where(ray_direction &lt; 0, point_to_min, point_to_max)\n\n    # For each axis, find how many times the ray direction should be multiplied to reach the AABB's boundary.\n    multiple_to_face_on_each_axis = closer_point_on_each_axis / ray_direction\n\n    # Choose the minimum of these multiples, e.g. how many times the ray direction should be multiplied\n    # to reach the nearest boundary.\n    multiple_to_face = np.min(multiple_to_face_on_each_axis[np.isfinite(multiple_to_face_on_each_axis)])\n\n    # Finally, use the multiple we found to calculate the point on the AABB boundary that we want to cast our\n    # ray until.\n    point_on_face = start_pos + ray_direction * multiple_to_face\n\n    # Make sure that we did not end up with all NaNs or infinities due to division issues.\n    assert not np.any(np.isnan(point_on_face)) and not np.any(np.isinf(point_on_face))\n\n    return point_on_face\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.compute_ray_destination"},{"title":"<code>compute_rotation_from_grid_sample(two_d_grid, projected_hits, cuboid_centroid, this_cuboid_dimensions, hits, refusal_log)</code>","text":"<p>Computes</p> <p>Parameters:</p>    Name Type Description Default     <code>two_d_grid</code>  <code>n, 2</code>  <p>(x,y) raycast origin points in the local plane frame</p>  required    <code>projected_hits</code>  <code>k,3)-array</code>  <p>Points' positions projected onto the plane generated</p>  required    <code>cuboid_centroid</code>  <code>3-array</code>  <p>(x,y,z) sampled position of the hit cuboid centroid in the global frame</p>  required    <code>this_cuboid_dimensions</code>  <code>3-array</code>  <p>(x,y,z) size of cuboid being sampled from the grid</p>  required    <code>hits</code>  <code>list of bool</code>  <p>whether each point from @two_d_grid is a valid hit or not</p>  required    <code>refusal_log</code>  <code>dict</code>  <p>Dictionary to write debugging and log information to</p>  required     <p>Returns:</p>    Type Description       <p>None or scipy.Rotation: If successfully hit, returns relative rotation from two_d_grid to generated hit plane. Otherwise, returns None</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def compute_rotation_from_grid_sample(two_d_grid, projected_hits, cuboid_centroid, this_cuboid_dimensions, hits, refusal_log):\n    \"\"\"\n    Computes\n\n    Args:\n        two_d_grid (n, 2): (x,y) raycast origin points in the local plane frame\n        projected_hits ((k,3)-array): Points' positions projected onto the plane generated\n        cuboid_centroid (3-array): (x,y,z) sampled position of the hit cuboid centroid in the global frame\n        this_cuboid_dimensions (3-array): (x,y,z) size of cuboid being sampled from the grid\n        hits (list of bool): whether each point from @two_d_grid is a valid hit or not\n        refusal_log (dict): Dictionary to write debugging and log information to\n\n    Returns:\n        None or scipy.Rotation: If successfully hit, returns relative rotation from two_d_grid to\n            generated hit plane. Otherwise, returns None\n    \"\"\"\n    if np.sum(hits) &lt; 3:\n        if og.debug_sampling:\n            refusal_log.append(f\"insufficient hits to compute the rotation of the grid: needs 3, has {np.sum(hits)}\")\n        return None\n\n    grid_in_planar_coordinates = two_d_grid.reshape(-1, 2)\n    grid_in_planar_coordinates = grid_in_planar_coordinates[hits]\n    grid_in_object_coordinates = np.zeros((len(grid_in_planar_coordinates), 3))\n    grid_in_object_coordinates[:, :2] = grid_in_planar_coordinates\n    grid_in_object_coordinates[:, 2] = -this_cuboid_dimensions[2] / 2.0\n\n    projected_hits = projected_hits[hits]\n    sampled_grid_relative_vectors = projected_hits - cuboid_centroid\n\n    rotation, _ = R.align_vectors(sampled_grid_relative_vectors, grid_in_object_coordinates)\n\n    return rotation\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.compute_rotation_from_grid_sample"},{"title":"<code>draw_debug_markers(hit_positions, radius=0.01)</code>","text":"<p>Helper method to generate and place debug markers at @hit_positions</p> <p>Parameters:</p>    Name Type Description Default     <code>hit_positions</code>  <code>n, 3)-array</code>  <p>Desired positions to place markers at</p>  required    <code>radius</code>  <code>float</code>  <p>Radius of the generated virtual marker</p>  <code>0.01</code>      Source code in <code>utils/sampling_utils.py</code> <pre><code>def draw_debug_markers(hit_positions, radius=0.01):\n    \"\"\"\n    Helper method to generate and place debug markers at @hit_positions\n\n    Args:\n        hit_positions ((n, 3)-array): Desired positions to place markers at\n        radius (float): Radius of the generated virtual marker\n    \"\"\"\n    # Import here to avoid circular imports\n    from omnigibson.objects.primitive_object import PrimitiveObject\n\n    color = np.concatenate([np.random.rand(3), [1]])\n    for vec in hit_positions:\n        time_str = str(time.time())\n        cur_time = time_str[(time_str.index(\".\") + 1):]\n        obj = PrimitiveObject(\n            prim_path=f\"/World/debug_marker_{cur_time}\",\n            name=f\"debug_marker_{cur_time}\",\n            primitive_type=\"Sphere\",\n            visual_only=True,\n            rgba=color,\n            radius=radius,\n        )\n        og.sim.import_object(obj)\n        obj.set_position(vec)\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.draw_debug_markers"},{"title":"<code>fit_plane(points)</code>","text":"<p>Fits a plane to the given 3D points. Copied from https://stackoverflow.com/a/18968498</p> <p>Parameters:</p>    Name Type Description Default     <code>points</code>  <code>k, 3)-array</code>  <p>np.array of shape (k, 3)</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: (x,y,z) points' centroid - 3-array: (x,y,z) normal of the fitted plane</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def fit_plane(points):\n    \"\"\"\n    Fits a plane to the given 3D points.\n    Copied from https://stackoverflow.com/a/18968498\n\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n\n    Returns:\n        2-tuple:\n            - 3-array: (x,y,z) points' centroid\n            - 3-array: (x,y,z) normal of the fitted plane\n    \"\"\"\n    assert points.shape[1] &lt;= points.shape[0], \"Cannot fit plane with only {} points in {} dimensions.\".format(\n        points.shape[0], points.shape[1]\n    )\n    ctr = points.mean(axis=0)\n    x = points - ctr\n    normal = np.linalg.svd(np.dot(x.T, x))[0][:, -1]\n    normal /= np.linalg.norm(normal)\n    return ctr, normal\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.fit_plane"},{"title":"<code>get_distance_to_plane(points, plane_centroid, plane_normal)</code>","text":"<p>Computes distance from @points to plane defined by @plane_centroid and @plane_normal</p> <p>Parameters:</p>    Name Type Description Default     <code>points</code>  <code>k, 3)-array</code>  <p>np.array of shape (k, 3)</p>  required    <code>plane_centroid</code>  <code>3-array</code>  <p>(x,y,z) points' centroid</p>  required    <code>plane_normal</code>  <code>3-array</code>  <p>(x,y,z) normal of the fitted plane</p>  required     <p>Returns:</p>    Type Description       <p>k-array: Absolute distances from each point to the plane</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def get_distance_to_plane(points, plane_centroid, plane_normal):\n    \"\"\"\n    Computes distance from @points to plane defined by @plane_centroid and @plane_normal\n\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n        plane_centroid (3-array): (x,y,z) points' centroid\n        plane_normal (3-array): (x,y,z) normal of the fitted plane\n\n    Returns:\n        k-array: Absolute distances from each point to the plane\n    \"\"\"\n    return np.abs(np.dot(points - plane_centroid, plane_normal))\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.get_distance_to_plane"},{"title":"<code>get_parallel_rays(source, destination, offset, new_ray_per_horizontal_distance)</code>","text":"<p>Given an input ray described by a source and a destination, sample parallel rays around it as the center.</p> <p>The parallel rays start at the corners of a square of edge length <code>offset</code> centered on <code>source</code>, with the square orthogonal to the ray direction. That is, the cast rays are the height edges of a square-base cuboid with bases centered on <code>source</code> and <code>destination</code>.</p> <p>Parameters:</p>    Name Type Description Default     <code>source</code>  <code>3-array</code>  <p>(x,y,z) source of the ray to sample parallel rays of.</p>  required    <code>destination</code>  <code>3-array</code>  <p>Source of the ray to sample parallel rays of.</p>  required    <code>offset</code>  <code>float</code>  <p>Orthogonal distance of parallel rays from input ray.</p>  required    <code>new_ray_per_horizontal_distance</code>  <code>float</code>  <p>Step in offset beyond which an additional split will be applied in the parallel ray grid (which at minimum is 3x3 at the AABB corners &amp; center).</p>  required     <p>Returns:</p>    Type Description       <p>3-tuple: - list: generated sources from the original ray - list: generated destinations from the original ray - (W, H, 3)-array: unflattened, untransformed grid of parallel rays in object coordinates</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def get_parallel_rays(\n    source, destination, offset, new_ray_per_horizontal_distance\n):\n    \"\"\"\n    Given an input ray described by a source and a destination, sample parallel rays around it as the center.\n\n    The parallel rays start at the corners of a square of edge length `offset` centered on `source`, with the square\n    orthogonal to the ray direction. That is, the cast rays are the height edges of a square-base cuboid with bases\n    centered on `source` and `destination`.\n\n    Args:\n        source (3-array): (x,y,z) source of the ray to sample parallel rays of.\n        destination (3-array): Source of the ray to sample parallel rays of.\n        offset (float): Orthogonal distance of parallel rays from input ray.\n        new_ray_per_horizontal_distance (float): Step in offset beyond which an additional split will be applied in the\n            parallel ray grid (which at minimum is 3x3 at the AABB corners &amp; center).\n\n    Returns:\n        3-tuple:\n            - list: generated sources from the original ray\n            - list: generated destinations from the original ray\n            - (W, H, 3)-array: unflattened, untransformed grid of parallel rays in object coordinates\n    \"\"\"\n    ray_direction = destination - source\n\n    # Get an orthogonal vector using a random vector.\n    random_vector = np.random.rand(3)\n    orthogonal_vector_1 = np.cross(ray_direction, random_vector)\n    orthogonal_vector_1 /= np.linalg.norm(orthogonal_vector_1)\n\n    # Get a second vector orthogonal to both the ray and the first vector.\n    orthogonal_vector_2 = -np.cross(ray_direction, orthogonal_vector_1)\n    orthogonal_vector_2 /= np.linalg.norm(orthogonal_vector_2)\n\n    orthogonal_vectors = np.array([orthogonal_vector_1, orthogonal_vector_2])\n    assert np.all(np.isfinite(orthogonal_vectors))\n\n    # Convert the offset into a 2-vector if it already isn't one.\n    offset = np.array([1, 1]) * offset\n\n    # Compute the grid of rays\n    steps = (offset / new_ray_per_horizontal_distance).astype(int) * 2 + 1\n    steps = np.maximum(steps, 3)\n    x_range = np.linspace(-offset[0], offset[0], steps[0])\n    y_range = np.linspace(-offset[1], offset[1], steps[1])\n    ray_grid = np.dstack(np.meshgrid(x_range, y_range, indexing=\"ij\"))\n    ray_grid_flattened = ray_grid.reshape(-1, 2)\n\n    # Apply the grid onto the orthogonal vectors to obtain the rays in the world frame.\n    sources = [source + np.dot(offsets, orthogonal_vectors) for offsets in ray_grid_flattened]\n    destinations = [destination + np.dot(offsets, orthogonal_vectors) for offsets in ray_grid_flattened]\n\n    return sources, destinations, ray_grid\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.get_parallel_rays"},{"title":"<code>get_projection_onto_plane(points, plane_centroid, plane_normal)</code>","text":"<p>Computes @points' projection onto the plane defined by @plane_centroid and @plane_normal</p> <p>Parameters:</p>    Name Type Description Default     <code>points</code>  <code>k, 3)-array</code>  <p>np.array of shape (k, 3)</p>  required    <code>plane_centroid</code>  <code>3-array</code>  <p>(x,y,z) points' centroid</p>  required    <code>plane_normal</code>  <code>3-array</code>  <p>(x,y,z) normal of the fitted plane</p>  required     <p>Returns:</p>    Type Description       <p>(k,3)-array: Points' positions projected onto the plane</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def get_projection_onto_plane(points, plane_centroid, plane_normal):\n    \"\"\"\n    Computes @points' projection onto the plane defined by @plane_centroid and @plane_normal\n\n    Args:\n        points ((k, 3)-array): np.array of shape (k, 3)\n        plane_centroid (3-array): (x,y,z) points' centroid\n        plane_normal (3-array): (x,y,z) normal of the fitted plane\n\n    Returns:\n        (k,3)-array: Points' positions projected onto the plane\n    \"\"\"\n    distances_to_plane = get_distance_to_plane(points, plane_centroid, plane_normal)\n    return points - np.outer(distances_to_plane, plane_normal)\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.get_projection_onto_plane"},{"title":"<code>raytest(start_point, end_point, only_closest=True, ignore_bodies=None, ignore_collisions=None)</code>","text":"<p>Computes raytest collision for ray cast from @start_point to @end_point</p> <p>Parameters:</p>    Name Type Description Default     <code>start_point</code>  <code>3-array</code>  <p>(x,y,z) global start location of the ray</p>  required    <code>end_point</code>  <code>3-array</code>  <p>(x,y,z) global end location of the ray</p>  required    <code>only_closest</code>  <code>bool</code>  <p>Whether we report the first (closest) hit from the ray or grab all hits</p>  <code>True</code>    <code>ignore_bodies</code>  <code>None or list of str</code>  <p>If specified, specifies absolute USD paths to rigid bodies whose collisions should be ignored</p>  <code>None</code>    <code>ignore_collisions</code>  <code>None or list of str</code>  <p>If specified, specifies absolute USD paths to collision geoms whose collisions should be ignored</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>dict or list of dict: Results for this raytest. If @only_closest=True, then we only return the information from the closest hit. Otherwise, we return an (unordered) list of information for all hits encountered. Each dict is composed of:</p> <p>\"hit\" (bool): Whether an object was hit or not \"position\" (3-array): Location of the hit position \"normal\" (3-array): normal vector of the face hit \"distance\" (float): distance from @start_point the hit occurred \"collision\" (str): absolute USD path to the collision body hit \"rigidBody\" (str): absolute USD path to the associated rigid body hit</p> <p>Note that only \"hit\" = False exists in the dict if no hit was found</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def raytest(\n    start_point,\n    end_point,\n    only_closest=True,\n    ignore_bodies=None,\n    ignore_collisions=None,\n):\n    \"\"\"\n    Computes raytest collision for ray cast from @start_point to @end_point\n\n    Args:\n        start_point (3-array): (x,y,z) global start location of the ray\n        end_point (3-array): (x,y,z) global end location of the ray\n        only_closest (bool): Whether we report the first (closest) hit from the ray or grab all hits\n        ignore_bodies (None or list of str): If specified, specifies absolute USD paths to rigid bodies\n            whose collisions should be ignored\n        ignore_collisions (None or list of str): If specified, specifies absolute USD paths to collision geoms\n            whose collisions should be ignored\n\n    Returns:\n        dict or list of dict: Results for this raytest. If @only_closest=True, then we only return the information from\n            the closest hit. Otherwise, we return an (unordered) list of information for all hits encountered.\n            Each dict is composed of:\n\n            \"hit\" (bool): Whether an object was hit or not\n            \"position\" (3-array): Location of the hit position\n            \"normal\" (3-array): normal vector of the face hit\n            \"distance\" (float): distance from @start_point the hit occurred\n            \"collision\" (str): absolute USD path to the collision body hit\n            \"rigidBody\" (str): absolute USD path to the associated rigid body hit\n\n            Note that only \"hit\" = False exists in the dict if no hit was found\n    \"\"\"\n    # Make sure start point, end point are numpy arrays\n    start_point, end_point = np.array(start_point), np.array(end_point)\n    point_diff = end_point - start_point\n    distance = np.linalg.norm(point_diff)\n    direction = point_diff / distance\n\n    # For efficiency's sake, we handle special case of no ignore_bodies, ignore_collisions, and closest_hit\n    if only_closest and ignore_bodies is None and ignore_collisions is None:\n        return get_physx_scene_query_interface().raycast_closest(\n            origin=start_point,\n            dir=direction,\n            distance=distance,\n        )\n    else:\n        # Compose callback function for finding raycasts\n        hits = []\n        ignore_bodies = set() if ignore_bodies is None else set(ignore_bodies)\n        ignore_collisions = set() if ignore_collisions is None else set(ignore_collisions)\n\n        def callback(hit):\n            # Only add to hits if we're not ignoring this body or collision\n            if hit.rigid_body not in ignore_bodies and hit.collision not in ignore_collisions:\n                hits.append({\n                    \"hit\": True,\n                    \"position\": np.array(hit.position),\n                    \"normal\": np.array(hit.normal),\n                    \"distance\": hit.distance,\n                    \"collision\": hit.collision,\n                    \"rigidBody\": hit.rigid_body,\n                })\n            # We always want to continue traversing to collect all hits\n            return True\n\n        # Grab all collisions\n        get_physx_scene_query_interface().raycast_all(\n            origin=start_point,\n            dir=direction,\n            distance=distance,\n            reportFn=callback,\n        )\n\n        # If we only want the closest, we need to sort these hits, otherwise we return them all\n        if only_closest:\n            # Return the empty hit dictionary if our ray did not hit anything, otherwise we return the closest\n            return {\"hit\": False} if len(hits) == 0 else sorted(hits, key=lambda hit: hit[\"distance\"])[0]\n        else:\n            # Return all hits (list)\n            return hits\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.raytest"},{"title":"<code>raytest_batch(start_points, end_points, only_closest=True, ignore_bodies=None, ignore_collisions=None)</code>","text":"<p>Computes raytest collisions for a set of rays cast from @start_points to @end_points.</p> <p>Parameters:</p>    Name Type Description Default     <code>start_points</code>  <code>list of 3-array</code>  <p>Array of start locations to cast rays, where each is (x,y,z) global start location of the ray</p>  required    <code>end_points</code>  <code>list of 3-array</code>  <p>Array of end locations to cast rays, where each is (x,y,z) global end location of the ray</p>  required    <code>only_closest</code>  <code>bool</code>  <p>Whether we report the first (closest) hit from the ray or grab all hits</p>  <code>True</code>    <code>ignore_bodies</code>  <code>None or list of str</code>  <p>If specified, specifies absolute USD paths to rigid bodies whose collisions should be ignored</p>  <code>None</code>    <code>ignore_collisions</code>  <code>None or list of str</code>  <p>If specified, specifies absolute USD paths to collision geoms whose collisions should be ignored</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>list of dict or list of list of dict: Results for all rays, where each entry corresponds to the result for the ith ray cast. If @only_closest=True, each entry in the list is the closest hit. Otherwise, each entry is its own (unordered) list of hits for that ray. Each dict is composed of:</p> <p>\"hit\" (bool): Whether an object was hit or not \"position\" (3-array): Location of the hit position \"normal\" (3-array): normal vector of the face hit \"distance\" (float): distance from @start_point the hit occurred \"collision\" (str): absolute USD path to the collision body hit \"rigidBody\" (str): absolute USD path to the associated rigid body hit</p> <p>Note that only \"hit\" = False exists in the dict if no hit was found</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def raytest_batch(start_points, end_points, only_closest=True, ignore_bodies=None, ignore_collisions=None):\n    \"\"\"\n    Computes raytest collisions for a set of rays cast from @start_points to @end_points.\n\n    Args:\n        start_points (list of 3-array): Array of start locations to cast rays, where each is (x,y,z) global\n            start location of the ray\n        end_points (list of 3-array): Array of end locations to cast rays, where each is (x,y,z) global\n            end location of the ray\n        only_closest (bool): Whether we report the first (closest) hit from the ray or grab all hits\n        ignore_bodies (None or list of str): If specified, specifies absolute USD paths to rigid bodies\n            whose collisions should be ignored\n        ignore_collisions (None or list of str): If specified, specifies absolute USD paths to collision geoms\n            whose collisions should be ignored\n\n    Returns:\n        list of dict or list of list of dict: Results for all rays, where each entry corresponds to the result for the\n            ith ray cast. If @only_closest=True, each entry in the list is the closest hit. Otherwise, each entry is\n            its own (unordered) list of hits for that ray. Each dict is composed of:\n\n            \"hit\" (bool): Whether an object was hit or not\n            \"position\" (3-array): Location of the hit position\n            \"normal\" (3-array): normal vector of the face hit\n            \"distance\" (float): distance from @start_point the hit occurred\n            \"collision\" (str): absolute USD path to the collision body hit\n            \"rigidBody\" (str): absolute USD path to the associated rigid body hit\n\n            Note that only \"hit\" = False exists in the dict if no hit was found\n    \"\"\"\n    # For now, we do a naive for loop over individual raytests until a better API comes out\n    results = []\n    for start_point, end_point in zip(start_points, end_points):\n        results.append(raytest(\n            start_point=start_point,\n            end_point=end_point,\n            only_closest=only_closest,\n            ignore_bodies=ignore_bodies,\n            ignore_collisions=ignore_collisions,\n        ))\n\n    return results\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.raytest_batch"},{"title":"<code>sample_cuboid_on_object(obj, start_points, end_points, cuboid_dimensions, ignore_objs=None, new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE, hit_proportion=m.DEFAULT_HIT_PROPORTION, max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS, parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE, hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD, cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING, undo_cuboid_bottom_padding=True, refuse_downwards=False)</code>","text":"<p>Samples points on an object's surface using ray casting.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>DatasetObject</code>  <p>The object to sample points on.</p>  required    <code>start_points</code>  <code>n, s, 3)-array</code>  <p>(num_samples, max_sampling_attempts, 3) shaped array representing the start points for raycasting defined in the world frame</p>  required    <code>end_points</code>  <code>n, s, 3)-array</code>  <p>(num_samples, max_sampling_attempts, 3) shaped array representing the end points for raycasting defined in the world frame</p>  required    <code>cuboid_dimensions</code>  <code>n, 3)-array</code>  <p>Float sequence of len 3, the size of the empty cuboid we are trying to sample. Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to sample points (instead of cuboids) for significantly better performance. This applies when the user wants to sample very small particles.</p>  required    <code>ignore_objs</code>  <code>None or list of EntityPrim</code>  <p>If @obj is None, this can be used to filter objects when checking for valid cuboid locations. Any sampled rays that hit an object in @ignore_objs will be ignored. If None, no filtering will be used</p>  <code>None</code>    <code>new_ray_per_horizontal_distance</code>  <code>float</code>  <p>per this distance of the cuboid dimension, increase the grid size of the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to the size of the sampled cuboid.</p>  <code>m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE</code>    <code>hit_proportion</code>  <code>float</code>  <p>the minimum percentage of the hits required across the grid.</p>  <code>m.DEFAULT_HIT_PROPORTION</code>    <code>max_angle_with_z_axis</code>  <code>float</code>  <p>maximum angle between hit normal and positive Z axis allowed. Can be used to disallow downward-facing hits when refuse_downwards=True.</p>  <code>m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS</code>    <code>parallel_ray_normal_angle_tolerance</code>  <code>float</code>  <p>maximum angle difference between the normal of the center hit and the normal of other hits allowed.</p>  <code>m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE</code>    <code>hit_to_plane_threshold</code>  <code>float</code>  <p>how far any given hit position can be from the least-squares fit plane to all of the hit positions before the sample is rejected.</p>  <code>m.DEFAULT_HIT_TO_PLANE_THRESHOLD</code>    <code>cuboid_bottom_padding</code>  <code>float</code>  <p>additional padding applied to the bottom of the cuboid. This is needed for the emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove the padding after the emptiness check.</p>  <code>m.DEFAULT_CUBOID_BOTTOM_PADDING</code>    <code>refuse_downwards</code>  <code>bool</code>  <p>whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.</p>  <code>False</code>    <code>undo_cuboid_bottom_padding</code>  <code>bool</code>  <p>Whether the bottom padding that's applied to the cuboid should be removed before return. Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will simply make the sampler undo the padding prior to returning.</p>  <code>True</code>     <p>Returns:</p>    Type Description       <p>list of tuple: list of length num_samples elements where each element is a tuple in the form of (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions are set to None when no successful sampling happens within the max number of attempts. Refusal details are only filled if the debug_sampling flag is globally set to True.</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def sample_cuboid_on_object(\n    obj,\n    start_points,\n    end_points,\n    cuboid_dimensions,\n    ignore_objs=None,\n    new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE,\n    hit_proportion=m.DEFAULT_HIT_PROPORTION,\n    max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS,\n    parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE,\n    hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD,\n    cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING,\n    undo_cuboid_bottom_padding=True,\n    refuse_downwards=False,\n):\n    \"\"\"\n    Samples points on an object's surface using ray casting.\n\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        start_points ((n, s, 3)-array): (num_samples, max_sampling_attempts, 3) shaped array representing the start points for\n            raycasting defined in the world frame\n        end_points ((n, s, 3)-array): (num_samples, max_sampling_attempts, 3) shaped array representing the end points for\n            raycasting defined in the world frame\n        cuboid_dimensions ((n, 3)-array): Float sequence of len 3, the size of the empty cuboid we are trying to sample.\n            Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using\n            the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to\n            sample points (instead of cuboids) for significantly better performance. This applies when the user wants\n            to sample very small particles.\n        ignore_objs (None or list of EntityPrim): If @obj is None, this can be used to filter objects when checking\n            for valid cuboid locations. Any sampled rays that hit an object in @ignore_objs will be ignored. If None,\n            no filtering will be used\n        new_ray_per_horizontal_distance (float): per this distance of the cuboid dimension, increase the grid size of\n            the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to\n            the size of the sampled cuboid.\n        hit_proportion (float): the minimum percentage of the hits required across the grid.\n        max_angle_with_z_axis (float): maximum angle between hit normal and positive Z axis allowed. Can be used to\n            disallow downward-facing hits when refuse_downwards=True.\n        parallel_ray_normal_angle_tolerance (float): maximum angle difference between the normal of the center hit\n            and the normal of other hits allowed.\n        hit_to_plane_threshold (float): how far any given hit position can be from the least-squares fit plane to\n            all of the hit positions before the sample is rejected.\n        cuboid_bottom_padding (float): additional padding applied to the bottom of the cuboid. This is needed for the\n            emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove\n            the padding after the emptiness check.\n        refuse_downwards (bool): whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.\n        undo_cuboid_bottom_padding (bool): Whether the bottom padding that's applied to the cuboid should be removed before return.\n            Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still\n            be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise\n            the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will\n            simply make the sampler undo the padding prior to returning.\n\n    Returns:\n        list of tuple: list of length num_samples elements where each element is a tuple in the form of\n            (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions\n            are set to None when no successful sampling happens within the max number of attempts. Refusal details are only\n            filled if the debug_sampling flag is globally set to True.\n    \"\"\"\n\n    assert start_points.shape == end_points.shape, \\\n        \"the start and end points of raycasting are expected to have the same shape.\"\n    num_samples = start_points.shape[0]\n\n    cuboid_dimensions = np.array(cuboid_dimensions)\n    if np.any(cuboid_dimensions &gt; 50.0):\n        print(\"WARNING: Trying to sample for a very large cuboid (at least one dimensions &gt; 50).\"\n              \"This will take a prohibitively large amount of time!\")\n    assert cuboid_dimensions.ndim &lt;= 2\n    assert cuboid_dimensions.shape[-1] == 3, \"Cuboid dimensions need to contain all three dimensions.\"\n    if cuboid_dimensions.ndim == 2:\n        assert cuboid_dimensions.shape[0] == num_samples, \"Need as many offsets as samples requested.\"\n\n    results = [(None, None, None, None, defaultdict(list)) for _ in range(num_samples)]\n    rigid_bodies = None if obj is None else [link.prim_path for link in obj.links.values()]\n    ignore_rigid_bodies = None if ignore_objs is None else \\\n        [link.prim_path for ignore_obj in ignore_objs for link in ignore_obj.links.values()]\n\n    for i in range(num_samples):\n        refusal_reasons = results[i][4]\n        # Try each sampled position in the AABB.\n        for start_pos, end_pos in zip(start_points[i], end_points[i]):\n            # If we have a list of cuboid dimensions, pick the one that corresponds to this particular sample.\n            this_cuboid_dimensions = cuboid_dimensions if cuboid_dimensions.ndim == 1 else cuboid_dimensions[i]\n\n            zero_cuboid_dimension = (this_cuboid_dimensions == 0.0).all()\n\n            if not zero_cuboid_dimension:\n                # Make sure we have valid (nonzero) x and y values\n                assert (this_cuboid_dimensions[:-1] &gt; 0).all(), \\\n                    f\"Cuboid x and y dimensions must not be zero if z dimension is nonzero! Got: {this_cuboid_dimensions}\"\n                # Obtain the parallel rays using the direction sampling method.\n                sources, destinations, grid = np.array(get_parallel_rays(\n                    start_pos, end_pos, this_cuboid_dimensions[:2] / 2.0, new_ray_per_horizontal_distance,\n                ))\n            else:\n                sources = np.array([start_pos])\n                destinations = np.array([end_pos])\n\n            # Time to cast the rays.\n            cast_results = raytest_batch(start_points=sources, end_points=destinations)\n\n            # Check whether sufficient number of rays hit the object\n            hits = check_rays_hit_object(\n                cast_results, hit_proportion, refusal_reasons[\"missed_object\"], rigid_bodies, ignore_rigid_bodies)\n            if hits is None:\n                continue\n\n            center_idx = int(len(hits) / 2)\n            # Only consider objects whose center idx has a ray hit\n            if not hits[center_idx]:\n                continue\n\n            filtered_cast_results = []\n            filtered_center_idx = None\n            for idx, hit in enumerate(hits):\n                if hit:\n                    filtered_cast_results.append(cast_results[idx])\n                    if idx == center_idx:\n                        filtered_center_idx = len(filtered_cast_results) - 1\n\n            # Process the hit positions and normals.\n            hit_positions = np.array([ray_res[\"position\"] for ray_res in filtered_cast_results])\n            hit_normals = np.array([ray_res[\"normal\"] for ray_res in filtered_cast_results])\n            hit_normals /= np.linalg.norm(hit_normals, axis=1, keepdims=True)\n\n            assert filtered_center_idx is not None\n            hit_link = filtered_cast_results[filtered_center_idx][\"rigidBody\"]\n            center_hit_pos = hit_positions[filtered_center_idx]\n            center_hit_normal = hit_normals[filtered_center_idx]\n\n            # Reject anything facing more than 45deg downwards if requested.\n            if refuse_downwards:\n                if not check_hit_max_angle_from_z_axis(\n                    center_hit_normal, max_angle_with_z_axis, refusal_reasons[\"downward_normal\"]\n                ):\n                    continue\n\n            # Check that none of the parallel rays' hit normal differs from center ray by more than threshold.\n            if not zero_cuboid_dimension:\n                if not check_normal_similarity(center_hit_normal, hit_normals, parallel_ray_normal_angle_tolerance, refusal_reasons[\"hit_normal_similarity\"]):\n                    continue\n\n                # Fit a plane to the points.\n                plane_centroid, plane_normal = fit_plane(hit_positions)\n\n                # The fit_plane normal can be facing either direction on the normal axis, but we want it to face away from\n                # the object for purposes of normal checking and padding. To do this:\n                # We get a vector from the centroid towards the center ray source, and flip the plane normal to match it.\n                # The cosine has positive sign if the two vectors are similar and a negative one if not.\n                plane_to_source = sources[center_idx] - plane_centroid\n                plane_normal *= np.sign(np.dot(plane_to_source, plane_normal))\n\n                # Check that the plane normal is similar to the hit normal\n                if not check_normal_similarity(\n                    center_hit_normal, plane_normal[None, :], parallel_ray_normal_angle_tolerance, refusal_reasons[\"plane_normal_similarity\"]\n                ):\n                    continue\n\n                # Check that the points are all within some acceptable distance of the plane.\n                if not check_distance_to_plane(\n                    hit_positions, plane_centroid, plane_normal, hit_to_plane_threshold, refusal_reasons[\"dist_to_plane\"]\n                ):\n                    continue\n\n                # Get projection of the base onto the plane, fit a rotation, and compute the new center hit / corners.\n                hit_positions = np.array([ray_res.get(\"position\", np.zeros(3)) for ray_res in cast_results])\n                projected_hits = get_projection_onto_plane(hit_positions, plane_centroid, plane_normal)\n                padding = cuboid_bottom_padding * plane_normal\n                projected_hits += padding\n                center_projected_hit = projected_hits[center_idx]\n                cuboid_centroid = center_projected_hit + plane_normal * this_cuboid_dimensions[2] / 2.0\n\n                rotation = compute_rotation_from_grid_sample(\n                    grid, projected_hits, cuboid_centroid, this_cuboid_dimensions,\n                    hits, refusal_reasons[\"rotation_not_computable\"])\n\n                # Make sure there are enough hit points that can be used for alignment to find the rotation\n                if rotation is None:\n                    continue\n\n                corner_positions = cuboid_centroid[None, :] + (\n                    rotation.apply(\n                        0.5\n                        * this_cuboid_dimensions\n                        * np.array(\n                            [\n                                [1, 1, -1],\n                                [-1, 1, -1],\n                                [-1, -1, -1],\n                                [1, -1, -1],\n                            ]\n                        )\n                    )\n                )\n\n                # Now we use the cuboid's diagonals to check that the cuboid is actually empty\n                if not check_cuboid_empty(\n                        plane_normal,\n                        corner_positions,\n                        this_cuboid_dimensions,\n                        refusal_reasons[\"cuboid_not_empty\"],\n                        ignore_body_names=ignore_rigid_bodies,\n                ):\n                    continue\n\n                if undo_cuboid_bottom_padding:\n                    cuboid_centroid -= padding\n\n            else:\n                cuboid_centroid = center_hit_pos\n                if not undo_cuboid_bottom_padding:\n                    padding = cuboid_bottom_padding * center_hit_normal\n                    cuboid_centroid += padding\n                plane_normal = np.zeros(3)\n                rotation = R.from_quat([0, 0, 0, 1])\n\n            # We've found a nice attachment point. Continue onto next point to sample.\n            results[i] = (cuboid_centroid, plane_normal, rotation.as_quat(), hit_link, refusal_reasons)\n            break\n\n    if og.debug_sampling:\n        print(\"Sampling rejection reasons:\")\n        counter = Counter()\n\n        for instance in results:\n            for reason, refusals in instance[-1].items():\n                counter[reason] += len(refusals)\n\n        print(\"\\n\".join(\"%s: %d\" % pair for pair in counter.items()))\n\n    return results\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_cuboid_on_object"},{"title":"<code>sample_cuboid_on_object_full_grid_topdown(obj, ray_spacing, cuboid_dimensions, new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE, hit_proportion=m.DEFAULT_HIT_PROPORTION, aabb_offset=m.DEFAULT_AABB_OFFSET, max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS, parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE, hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD, cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING, undo_cuboid_bottom_padding=True, refuse_downwards=False)</code>","text":"<p>Samples points on an object's surface using ray casting. Rays are sampled with a dense grid from top down.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>DatasetObject</code>  <p>The object to sample points on.</p>  required    <code>ray_spacing</code>  <code>float</code>  <p>spacing between the rays, or equivalently, size of the grid cell, when sampling the start and end points. This implicitly determines the number of cuboids that will be sampled.</p>  required    <code>cuboid_dimensions</code>  <code>n, 3)-array</code>  <p>Float sequence of len 3, the size of the empty cuboid we are trying to sample. Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to sample points (instead of cuboids) for significantly better performance. This applies when the user wants to sample very small particles.</p>  required    <code>new_ray_per_horizontal_distance</code>  <code>float</code>  <p>per this distance of the cuboid dimension, increase the grid size of the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to the size of the sampled cuboid.</p>  <code>m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE</code>    <code>hit_proportion</code>  <code>float</code>  <p>the minimum percentage of the hits required across the grid.</p>  <code>m.DEFAULT_HIT_PROPORTION</code>    <code>aabb_offset</code>  <code>float or 3-array</code>  <p>padding for AABB to initiate ray-testing.</p>  <code>m.DEFAULT_AABB_OFFSET</code>    <code>max_angle_with_z_axis</code>  <code>float</code>  <p>maximum angle between hit normal and positive Z axis allowed. Can be used to disallow downward-facing hits when refuse_downwards=True.</p>  <code>m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS</code>    <code>parallel_ray_normal_angle_tolerance</code>  <code>float</code>  <p>maximum angle difference between the normal of the center hit and the normal of other hits allowed.</p>  <code>m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE</code>    <code>hit_to_plane_threshold</code>  <code>float</code>  <p>how far any given hit position can be from the least-squares fit plane to all of the hit positions before the sample is rejected.</p>  <code>m.DEFAULT_HIT_TO_PLANE_THRESHOLD</code>    <code>cuboid_bottom_padding</code>  <code>float</code>  <p>additional padding applied to the bottom of the cuboid. This is needed for the emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove the padding after the emptiness check.</p>  <code>m.DEFAULT_CUBOID_BOTTOM_PADDING</code>    <code>refuse_downwards</code>  <code>bool</code>  <p>whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.</p>  <code>False</code>    <code>undo_cuboid_bottom_padding</code>  <code>bool</code>  <p>Whether the bottom padding that's applied to the cuboid should be removed before return. Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will simply make the sampler undo the padding prior to returning.</p>  <code>True</code>     <p>Returns:</p>    Type Description       <p>list of tuple: list of length num_samples elements where each element is a tuple in the form of (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions are set to None when no successful sampling happens within the max number of attempts. Refusal details are only filled if the debug_sampling flag is globally set to True.</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def sample_cuboid_on_object_full_grid_topdown(\n    obj,\n    ray_spacing,\n    cuboid_dimensions,\n    new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE,\n    hit_proportion=m.DEFAULT_HIT_PROPORTION,\n    aabb_offset=m.DEFAULT_AABB_OFFSET,\n    max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS,\n    parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE,\n    hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD,\n    cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING,\n    undo_cuboid_bottom_padding=True,\n    refuse_downwards=False,\n):\n    \"\"\"\n    Samples points on an object's surface using ray casting.\n    Rays are sampled with a dense grid from top down.\n\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        ray_spacing (float): spacing between the rays, or equivalently, size of the grid cell, when sampling the\n            start and end points. This implicitly determines the number of cuboids that will be sampled.\n        cuboid_dimensions ((n, 3)-array): Float sequence of len 3, the size of the empty cuboid we are trying to sample.\n            Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using\n            the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to\n            sample points (instead of cuboids) for significantly better performance. This applies when the user wants\n            to sample very small particles.\n        new_ray_per_horizontal_distance (float): per this distance of the cuboid dimension, increase the grid size of\n            the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to\n            the size of the sampled cuboid.\n        hit_proportion (float): the minimum percentage of the hits required across the grid.\n        aabb_offset (float or 3-array): padding for AABB to initiate ray-testing.\n        max_angle_with_z_axis (float): maximum angle between hit normal and positive Z axis allowed. Can be used to\n            disallow downward-facing hits when refuse_downwards=True.\n        parallel_ray_normal_angle_tolerance (float): maximum angle difference between the normal of the center hit\n            and the normal of other hits allowed.\n        hit_to_plane_threshold (float): how far any given hit position can be from the least-squares fit plane to\n            all of the hit positions before the sample is rejected.\n        cuboid_bottom_padding (float): additional padding applied to the bottom of the cuboid. This is needed for the\n            emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove\n            the padding after the emptiness check.\n        refuse_downwards (bool): whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.\n        undo_cuboid_bottom_padding (bool): Whether the bottom padding that's applied to the cuboid should be removed before return.\n            Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still\n            be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise\n            the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will\n            simply make the sampler undo the padding prior to returning.\n\n    Returns:\n        list of tuple: list of length num_samples elements where each element is a tuple in the form of\n            (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions\n            are set to None when no successful sampling happens within the max number of attempts. Refusal details are only\n            filled if the debug_sampling flag is globally set to True.\n    \"\"\"\n    start_points, end_points = sample_raytest_start_end_full_grid_topdown(\n        obj,\n        ray_spacing,\n        aabb_offset=aabb_offset,\n    )\n    return sample_cuboid_on_object(\n        obj,\n        start_points,\n        end_points,\n        cuboid_dimensions,\n        undo_cuboid_bottom_padding=undo_cuboid_bottom_padding,\n        new_ray_per_horizontal_distance=new_ray_per_horizontal_distance,\n        hit_proportion=hit_proportion,\n        max_angle_with_z_axis=max_angle_with_z_axis,\n        parallel_ray_normal_angle_tolerance=parallel_ray_normal_angle_tolerance,\n        hit_to_plane_threshold=hit_to_plane_threshold,\n        cuboid_bottom_padding=cuboid_bottom_padding,\n        refuse_downwards=refuse_downwards,\n    )\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_cuboid_on_object_full_grid_topdown"},{"title":"<code>sample_cuboid_on_object_symmetric_bimodal_distribution(obj, num_samples, cuboid_dimensions, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities, new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE, hit_proportion=m.DEFAULT_HIT_PROPORTION, aabb_offset=m.DEFAULT_AABB_OFFSET, max_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS, max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS, parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE, hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD, cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING, undo_cuboid_bottom_padding=True, refuse_downwards=False)</code>","text":"<p>Samples points on an object's surface using ray casting. Rays are sampled with a symmetric bimodal distribution.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>DatasetObject</code>  <p>The object to sample points on.</p>  required    <code>num_samples</code>  <code>int</code>  <p>the number of points to try to sample.</p>  required    <code>cuboid_dimensions</code>  <code>n, 3)-array</code>  <p>Float sequence of len 3, the size of the empty cuboid we are trying to sample. Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to sample points (instead of cuboids) for significantly better performance. This applies when the user wants to sample very small particles.</p>  required    <code>bimodal_mean_fraction</code>  <code>float</code>  <p>the mean of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p>  required    <code>bimodal_stdev_fraction</code>  <code>float</code>  <p>the standard deviation of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p>  required    <code>axis_probabilities</code>  <code>3-array</code>  <p>the probability of ray casting along each axis.</p>  required    <code>new_ray_per_horizontal_distance</code>  <code>float</code>  <p>per this distance of the cuboid dimension, increase the grid size of the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to the size of the sampled cuboid.</p>  <code>m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE</code>    <code>hit_proportion</code>  <code>float</code>  <p>the minimum percentage of the hits required across the grid.</p>  <code>m.DEFAULT_HIT_PROPORTION</code>    <code>aabb_offset</code>  <code>float or 3-array</code>  <p>padding for AABB to initiate ray-testing.</p>  <code>m.DEFAULT_AABB_OFFSET</code>    <code>max_sampling_attempts</code>  <code>int</code>  <p>how many times sampling will be attempted for each requested point.</p>  <code>m.DEFAULT_MAX_SAMPLING_ATTEMPTS</code>    <code>max_angle_with_z_axis</code>  <code>float</code>  <p>maximum angle between hit normal and positive Z axis allowed. Can be used to disallow downward-facing hits when refuse_downwards=True.</p>  <code>m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS</code>    <code>parallel_ray_normal_angle_tolerance</code>  <code>float</code>  <p>maximum angle difference between the normal of the center hit and the normal of other hits allowed.</p>  <code>m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE</code>    <code>hit_to_plane_threshold</code>  <code>float</code>  <p>how far any given hit position can be from the least-squares fit plane to all of the hit positions before the sample is rejected.</p>  <code>m.DEFAULT_HIT_TO_PLANE_THRESHOLD</code>    <code>cuboid_bottom_padding</code>  <code>float</code>  <p>additional padding applied to the bottom of the cuboid. This is needed for the emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove the padding after the emptiness check.</p>  <code>m.DEFAULT_CUBOID_BOTTOM_PADDING</code>    <code>refuse_downwards</code>  <code>bool</code>  <p>whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.</p>  <code>False</code>    <code>undo_cuboid_bottom_padding</code>  <code>bool</code>  <p>Whether the bottom padding that's applied to the cuboid should be removed before return. Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will simply make the sampler undo the padding prior to returning.</p>  <code>True</code>     <p>Returns:</p>    Type Description       <p>list of tuple: list of length num_samples elements where each element is a tuple in the form of (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions are set to None when no successful sampling happens within the max number of attempts. Refusal details are only filled if the debug_sampling flag is globally set to True.</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def sample_cuboid_on_object_symmetric_bimodal_distribution(\n    obj,\n    num_samples,\n    cuboid_dimensions,\n    bimodal_mean_fraction,\n    bimodal_stdev_fraction,\n    axis_probabilities,\n    new_ray_per_horizontal_distance=m.DEFAULT_NEW_RAY_PER_HORIZONTAL_DISTANCE,\n    hit_proportion=m.DEFAULT_HIT_PROPORTION,\n    aabb_offset=m.DEFAULT_AABB_OFFSET,\n    max_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS,\n    max_angle_with_z_axis=m.DEFAULT_MAX_ANGLE_WITH_Z_AXIS,\n    parallel_ray_normal_angle_tolerance=m.DEFAULT_PARALLEL_RAY_NORMAL_ANGLE_TOLERANCE,\n    hit_to_plane_threshold=m.DEFAULT_HIT_TO_PLANE_THRESHOLD,\n    cuboid_bottom_padding=m.DEFAULT_CUBOID_BOTTOM_PADDING,\n    undo_cuboid_bottom_padding=True,\n    refuse_downwards=False,\n):\n    \"\"\"\n    Samples points on an object's surface using ray casting.\n    Rays are sampled with a symmetric bimodal distribution.\n\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        num_samples (int): the number of points to try to sample.\n        cuboid_dimensions ((n, 3)-array): Float sequence of len 3, the size of the empty cuboid we are trying to sample.\n            Can also provide list of cuboid dimension triplets in which case each i'th sample will be sampled using\n            the i'th triplet. Alternatively, cuboid_dimensions can be set to be all zeros if the user just want to\n            sample points (instead of cuboids) for significantly better performance. This applies when the user wants\n            to sample very small particles.\n        bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the\n            min-max range.\n        bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a\n            fraction of the min-max range.\n        axis_probabilities (3-array): the probability of ray casting along each axis.\n        new_ray_per_horizontal_distance (float): per this distance of the cuboid dimension, increase the grid size of\n            the parallel ray-testing by 1. This controls how fine-grained the grid ray-casting should be with respect to\n            the size of the sampled cuboid.\n        hit_proportion (float): the minimum percentage of the hits required across the grid.\n        aabb_offset (float or 3-array): padding for AABB to initiate ray-testing.\n        max_sampling_attempts (int): how many times sampling will be attempted for each requested point.\n        max_angle_with_z_axis (float): maximum angle between hit normal and positive Z axis allowed. Can be used to\n            disallow downward-facing hits when refuse_downwards=True.\n        parallel_ray_normal_angle_tolerance (float): maximum angle difference between the normal of the center hit\n            and the normal of other hits allowed.\n        hit_to_plane_threshold (float): how far any given hit position can be from the least-squares fit plane to\n            all of the hit positions before the sample is rejected.\n        cuboid_bottom_padding (float): additional padding applied to the bottom of the cuboid. This is needed for the\n            emptiness check (@check_cuboid_empty) within the cuboid. un_padding=True can be set if the user wants to remove\n            the padding after the emptiness check.\n        refuse_downwards (bool): whether downward-facing hits (as defined by max_angle_with_z_axis) are allowed.\n        undo_cuboid_bottom_padding (bool): Whether the bottom padding that's applied to the cuboid should be removed before return.\n            Useful when the cuboid needs to be flush with the surface for whatever reason. Note that the padding will still\n            be applied initially (since it's not possible to do the cuboid emptiness check without doing this - otherwise\n            the rays will hit the sampled-on object), so the emptiness check still checks a padded cuboid. This flag will\n            simply make the sampler undo the padding prior to returning.\n\n    Returns:\n        list of tuple: list of length num_samples elements where each element is a tuple in the form of\n            (cuboid_centroid, cuboid_up_vector, cuboid_rotation, {refusal_reason: [refusal_details...]}). Cuboid positions\n            are set to None when no successful sampling happens within the max number of attempts. Refusal details are only\n            filled if the debug_sampling flag is globally set to True.\n    \"\"\"\n    start_points, end_points = sample_raytest_start_end_symmetric_bimodal_distribution(\n        obj,\n        num_samples,\n        bimodal_mean_fraction,\n        bimodal_stdev_fraction,\n        axis_probabilities,\n        aabb_offset=aabb_offset,\n        max_sampling_attempts=max_sampling_attempts,\n    )\n    return sample_cuboid_on_object(\n        obj,\n        start_points,\n        end_points,\n        cuboid_dimensions,\n        undo_cuboid_bottom_padding=undo_cuboid_bottom_padding,\n        new_ray_per_horizontal_distance=new_ray_per_horizontal_distance,\n        hit_proportion=hit_proportion,\n        max_angle_with_z_axis=max_angle_with_z_axis,\n        parallel_ray_normal_angle_tolerance=parallel_ray_normal_angle_tolerance,\n        hit_to_plane_threshold=hit_to_plane_threshold,\n        cuboid_bottom_padding=cuboid_bottom_padding,\n        refuse_downwards=refuse_downwards,\n    )\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_cuboid_on_object_symmetric_bimodal_distribution"},{"title":"<code>sample_origin_positions(mins, maxes, count, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities)</code>","text":"<p>Sample ray casting origin positions with a given distribution.</p> <p>The way the sampling works is that for each particle, it will sample two coordinates uniformly and one using a symmetric, bimodal truncated normal distribution. This way, the particles will mostly be close to the faces of the AABB (given a correctly parameterized bimodal truncated normal) and will be spread across each face, but there will still be a small number of particles spawned inside the object if it has an interior.</p> <p>Parameters:</p>    Name Type Description Default     <code>mins</code>  <code>3-array</code>  <p>the minimum coordinate along each axis.</p>  required    <code>maxes</code>  <code>3-array</code>  <p>the maximum coordinate along each axis.</p>  required    <code>count</code>  <code>int</code>  <p>Number of origins to sample.</p>  required    <code>bimodal_mean_fraction</code>  <code>float</code>  <p>the mean of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p>  required    <code>bimodal_stdev_fraction</code>  <code>float</code>  <p>the standard deviation of one side of the symmetric bimodal distribution as a fraction of the min-max range.</p>  required    <code>axis_probabilities</code>  <code>3-array</code>  <p>the probability of ray casting along each axis.</p>  required     <p>Returns:</p>    Name Type Description     <code>list</code>   <p>List where each element is (ray cast axis index, bool whether the axis was sampled from the top side, [x, y, z]) tuples.</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def sample_origin_positions(mins, maxes, count, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities):\n    \"\"\"\n    Sample ray casting origin positions with a given distribution.\n\n    The way the sampling works is that for each particle, it will sample two coordinates uniformly and one\n    using a symmetric, bimodal truncated normal distribution. This way, the particles will mostly be close to the faces\n    of the AABB (given a correctly parameterized bimodal truncated normal) and will be spread across each face,\n    but there will still be a small number of particles spawned inside the object if it has an interior.\n\n    Args:\n        mins (3-array): the minimum coordinate along each axis.\n        maxes (3-array): the maximum coordinate along each axis.\n        count (int): Number of origins to sample.\n        bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the\n            min-max range.\n        bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a\n            fraction of the min-max range.\n        axis_probabilities (3-array): the probability of ray casting along each axis.\n\n    Returns:\n        list: List where each element is (ray cast axis index, bool whether the axis was sampled from the top side,\n            [x, y, z]) tuples.\n    \"\"\"\n    assert len(mins.shape) == 1\n    assert mins.shape == maxes.shape\n\n    results = []\n    for i in range(count):\n        # Get the uniform sample first.\n        position = np.random.rand(3)\n\n        # Sample the bimodal normal.\n        bottom = (0 - bimodal_mean_fraction) / bimodal_stdev_fraction\n        top = (1 - bimodal_mean_fraction) / bimodal_stdev_fraction\n        bimodal_sample = truncnorm.rvs(bottom, top, loc=bimodal_mean_fraction, scale=bimodal_stdev_fraction)\n\n        # Pick which axis the bimodal normal sample should go to.\n        bimodal_axis = np.random.choice([0, 1, 2], p=axis_probabilities)\n\n        # Choose which side of the axis to sample from. We only sample from the top for the Z axis.\n        if bimodal_axis == 2:\n            bimodal_axis_top_side = True\n        else:\n            bimodal_axis_top_side = np.random.choice([True, False])\n\n        # Move sample based on chosen side.\n        position[bimodal_axis] = bimodal_sample if bimodal_axis_top_side else 1 - bimodal_sample\n\n        # Scale the position from the standard normal range to the min-max range.\n        scaled_position = mins + (maxes - mins) * position\n\n        # Save the result.\n        results.append((bimodal_axis, bimodal_axis_top_side, scaled_position))\n\n    return results\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_origin_positions"},{"title":"<code>sample_raytest_start_end_full_grid_topdown(obj, ray_spacing, aabb_offset=m.DEFAULT_AABB_OFFSET)</code>","text":"<p>Sample the start points and end points around a given object by a dense grid from top down.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>DatasetObject</code>  <p>The object to sample points on.</p>  required    <code>ray_spacing</code>  <code>float</code>  <p>spacing between the rays, or equivalently, size of the grid cell</p>  required    <code>aabb_offset</code>  <code>float or numpy array</code>  <p>padding for AABB to initiate ray-testing.</p>  <code>m.DEFAULT_AABB_OFFSET</code>     <p>Returns:</p>    Type Description       <p>2-tuple: - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for     raycasting defined in the world frame - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for     raycasting defined in the world frame</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def sample_raytest_start_end_full_grid_topdown(\n    obj,\n    ray_spacing,\n    aabb_offset=m.DEFAULT_AABB_OFFSET,\n):\n    \"\"\"\n    Sample the start points and end points around a given object by a dense grid from top down.\n\n    Args:\n        obj (DatasetObject): The object to sample points on.\n        ray_spacing (float): spacing between the rays, or equivalently, size of the grid cell\n        aabb_offset (float or numpy array): padding for AABB to initiate ray-testing.\n\n    Returns:\n        2-tuple:\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for\n                raycasting defined in the world frame\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for\n                raycasting defined in the world frame\n    \"\"\"\n    bbox_center, bbox_orn, bbox_bf_extent, _ = obj.get_base_aligned_bbox(xy_aligned=True, fallback_to_aabb=True)\n\n    half_extent_with_offset = (bbox_bf_extent / 2) + aabb_offset\n    x = np.linspace(-half_extent_with_offset[0], half_extent_with_offset[0], int(half_extent_with_offset[0] * 2 / ray_spacing))\n    y = np.linspace(-half_extent_with_offset[1], half_extent_with_offset[1], int(half_extent_with_offset[1] * 2 / ray_spacing))\n    n_rays = len(x) * len(y)\n\n    start_points = np.stack([\n        np.tile(x, len(y)),\n        np.repeat(y, len(x)),\n        np.ones(n_rays) * half_extent_with_offset[2],\n    ]).T\n\n    end_points = np.copy(start_points)\n    end_points[:, 2] = -half_extent_with_offset[2]\n\n    # Convert the points into the world frame\n    to_wf_transform = T.pose2mat((bbox_center, bbox_orn))\n    start_points = trimesh.transformations.transform_points(start_points, to_wf_transform)\n    end_points = trimesh.transformations.transform_points(end_points, to_wf_transform)\n\n    start_points = np.expand_dims(start_points, axis=1)\n    end_points = np.expand_dims(end_points, axis=1)\n\n    return start_points, end_points\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_raytest_start_end_full_grid_topdown"},{"title":"<code>sample_raytest_start_end_symmetric_bimodal_distribution(obj, num_samples, bimodal_mean_fraction, bimodal_stdev_fraction, axis_probabilities, aabb_offset=m.DEFAULT_AABB_OFFSET, max_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS)</code>","text":"<p>Sample the start points and end points around a given object by a symmetric bimodal distribution</p> <p>obj (DatasetObject): The object to sample points on. num_samples (int): the number of points to try to sample. bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the     min-max range. bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a     fraction of the min-max range. axis_probabilities (3-array): probability of ray casting along each axis. aabb_offset (float or 3-array): padding for AABB to initiate ray-testing. max_sampling_attempts (int): how many times sampling will be attempted for each requested point.</p> <p>Returns:</p>    Type Description       <p>2-tuple: - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for     raycasting defined in the world frame - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for     raycasting defined in the world frame</p>     Source code in <code>utils/sampling_utils.py</code> <pre><code>def sample_raytest_start_end_symmetric_bimodal_distribution(\n    obj,\n    num_samples,\n    bimodal_mean_fraction,\n    bimodal_stdev_fraction,\n    axis_probabilities,\n    aabb_offset=m.DEFAULT_AABB_OFFSET,\n    max_sampling_attempts=m.DEFAULT_MAX_SAMPLING_ATTEMPTS,\n):\n    \"\"\"\n    Sample the start points and end points around a given object by a symmetric bimodal distribution\n\n    obj (DatasetObject): The object to sample points on.\n    num_samples (int): the number of points to try to sample.\n    bimodal_mean_fraction (float): the mean of one side of the symmetric bimodal distribution as a fraction of the\n        min-max range.\n    bimodal_stdev_fraction (float): the standard deviation of one side of the symmetric bimodal distribution as a\n        fraction of the min-max range.\n    axis_probabilities (3-array): probability of ray casting along each axis.\n    aabb_offset (float or 3-array): padding for AABB to initiate ray-testing.\n    max_sampling_attempts (int): how many times sampling will be attempted for each requested point.\n\n    Returns:\n        2-tuple:\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the start points for\n                raycasting defined in the world frame\n            - (n, s, 3)-array: (num_samples, max_sampling_attempts, 3) shaped array representing the end points for\n                raycasting defined in the world frame\n    \"\"\"\n    bbox_center, bbox_orn, bbox_bf_extent, _ = obj.get_base_aligned_bbox(xy_aligned=True, fallback_to_aabb=True)\n    half_extent_with_offset = (bbox_bf_extent / 2) + aabb_offset\n\n    start_points = np.zeros((num_samples, max_sampling_attempts, 3))\n    end_points = np.zeros((num_samples, max_sampling_attempts, 3))\n    for i in range(num_samples):\n        # Sample the starting positions in advance.\n        # TODO: Narrow down the sampling domain so that we don't sample scenarios where the center is in-domain but the\n        # full extent isn't. Currently a lot of samples are being wasted because of this.\n        samples = sample_origin_positions(\n            -half_extent_with_offset,\n            half_extent_with_offset,\n            max_sampling_attempts,\n            bimodal_mean_fraction,\n            bimodal_stdev_fraction,\n            axis_probabilities,\n        )\n\n        # Try each sampled position in the AABB.\n        for j, (axis, is_top, start_point) in enumerate(samples):\n            # Compute the ray's destination using the sampling &amp; AABB information.\n            end_point = compute_ray_destination(\n                axis, is_top, start_point, -half_extent_with_offset, half_extent_with_offset\n            )\n            start_points[i][j] = start_point\n            end_points[i][j] = end_point\n\n    # Convert the points into the world frame\n    orig_shape = start_points.shape\n    to_wf_transform = T.pose2mat((bbox_center, bbox_orn))\n    start_points = trimesh.transformations.transform_points(start_points.reshape(-1, 3), to_wf_transform).reshape(orig_shape)\n    end_points = trimesh.transformations.transform_points(end_points.reshape(-1, 3), to_wf_transform).reshape(orig_shape)\n\n    return start_points, end_points\n</code></pre>","location":"reference/utils/sampling_utils.html#utils.sampling_utils.sample_raytest_start_end_symmetric_bimodal_distribution"},{"title":"sim_utils","text":"","location":"reference/utils/sim_utils.html"},{"title":"<code>check_collision(prims=None, prims_check=None, prims_exclude=None, step_physics=False)</code>","text":"<p>Checks if any valid collisions occurred during the most recent physics timestep associated with prims @prims</p> <p>Parameters:</p>    Name Type Description Default     <code>prims</code>  <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>Prim(s) to check for collision. If None, will check against all objects currently in the scene.</p>  <code>None</code>    <code>prims_check</code>  <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>If specified, will only check for collisions with these specific prim(s)</p>  <code>None</code>    <code>prims_exclude</code>  <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>If specified, will explicitly ignore any collisions with these specific prim(s)</p>  <code>None</code>    <code>step_physics</code>  <code>bool</code>  <p>Whether to step the physics first before checking collisions. Default is False</p>  <code>False</code>     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if a valid collision has occurred, else False</p>     Source code in <code>utils/sim_utils.py</code> <pre><code>def check_collision(prims=None, prims_check=None, prims_exclude=None, step_physics=False):\n    \"\"\"\n    Checks if any valid collisions occurred during the most recent physics timestep associated with prims @prims\n\n    Args:\n        prims (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) to check for collision.\n            If None, will check against all objects currently in the scene.\n        prims_check (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            only check for collisions with these specific prim(s)\n        prims_exclude (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            explicitly ignore any collisions with these specific prim(s)\n        step_physics (bool): Whether to step the physics first before checking collisions. Default is False\n\n    Returns:\n        bool: True if a valid collision has occurred, else False\n    \"\"\"\n    return len(get_collisions(\n        prims=prims,\n        prims_check=prims_check,\n        prims_exclude=prims_exclude,\n        step_physics=step_physics)) &gt; 0\n</code></pre>","location":"reference/utils/sim_utils.html#utils.sim_utils.check_collision"},{"title":"<code>filter_collisions(collisions, filter_prims)</code>","text":"<p>Filters collision pairs @collisions based on a set of prims @filter_prims.</p> <p>Parameters:</p>    Name Type Description Default     <code>collisions</code>  <code>set of 2-tuple</code>  <p>Collision pairs that should be filtered</p>  required    <code>filter_prims</code>  <code>EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>Prim(s) specifying which collisions to filter for. Any collisions that include prims from this filter set will be removed</p>  required     <p>Returns:</p>    Type Description       <p>set of 2-tuple: Filtered collision pairs</p>     Source code in <code>utils/sim_utils.py</code> <pre><code>def filter_collisions(collisions, filter_prims):\n    \"\"\"\n    Filters collision pairs @collisions based on a set of prims @filter_prims.\n\n    Args:\n        collisions (set of 2-tuple): Collision pairs that should be filtered\n        filter_prims (EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) specifying which\n            collisions to filter for. Any collisions that include prims from this filter\n            set will be removed\n\n    Returns:\n        set of 2-tuple: Filtered collision pairs\n    \"\"\"\n    paths = prims_to_rigid_prim_set(filter_prims)\n\n    filtered_collisions = set()\n    for pair in collisions:\n        if set(pair).isdisjoint(paths):\n            filtered_collisions.add(pair)\n\n    return filtered_collisions\n</code></pre>","location":"reference/utils/sim_utils.html#utils.sim_utils.filter_collisions"},{"title":"<code>get_collisions(prims=None, prims_check=None, prims_exclude=None, step_physics=False)</code>","text":"<p>Grab collisions that occurred during the most recent physics timestep associated with prims @prims</p> <p>Parameters:</p>    Name Type Description Default     <code>prims</code>  <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>Prim(s) to check for collision. If None, will check against all objects currently in the scene.</p>  <code>None</code>    <code>prims_check</code>  <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>If specified, will only check for collisions with these specific prim(s)</p>  <code>None</code>    <code>prims_exclude</code>  <code>None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim</code>  <p>If specified, will explicitly ignore any collisions with these specific prim(s)</p>  <code>None</code>    <code>step_physics</code>  <code>bool</code>  <p>Whether to step the physics first before checking collisions. Default is False</p>  <code>False</code>     <p>Returns:</p>    Type Description       <p>set of 2-tuple: Unique collision pairs occurring in the simulation at the current timestep between the specified prim(s), represented by their prim_paths</p>     Source code in <code>utils/sim_utils.py</code> <pre><code>def get_collisions(prims=None, prims_check=None, prims_exclude=None, step_physics=False):\n    \"\"\"\n    Grab collisions that occurred during the most recent physics timestep associated with prims @prims\n\n    Args:\n        prims (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): Prim(s) to check for collision.\n            If None, will check against all objects currently in the scene.\n        prims_check (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            only check for collisions with these specific prim(s)\n        prims_exclude (None or EntityPrim or RigidPrim or tuple of EntityPrim or RigidPrim): If specified, will\n            explicitly ignore any collisions with these specific prim(s)\n        step_physics (bool): Whether to step the physics first before checking collisions. Default is False\n\n    Returns:\n        set of 2-tuple: Unique collision pairs occurring in the simulation at the current timestep between the\n            specified prim(s), represented by their prim_paths\n    \"\"\"\n    # Make sure sim is playing\n    assert og.sim.is_playing(), \"Cannot get collisions while sim is not playing!\"\n\n    # Optionally step physics and then update contacts\n    if step_physics:\n        og.sim.step_physics()\n\n    # Standardize inputs\n    prims = og.sim.scene.objects if prims is None else prims if isinstance(prims, Iterable) else [prims]\n    prims_check = [] if prims_check is None else prims_check if isinstance(prims_check, Iterable) else [prims_check]\n    prims_exclude = [] if prims_exclude is None else prims_exclude if isinstance(prims_exclude, Iterable) else [prims_exclude]\n\n    # Convert into prim paths to check for collision\n    def get_paths_from_rigid_prims(inp_prims):\n        return {prim.prim_path for prim in inp_prims}\n\n    def get_contacts(inp_prims):\n        return {(c.body0, c.body1) for prim in inp_prims for c in prim.contact_list()}\n\n    rprims = prims_to_rigid_prim_set(prims)\n    rprims_check = prims_to_rigid_prim_set(prims_check)\n    rprims_exclude = prims_to_rigid_prim_set(prims_exclude)\n\n    paths = get_paths_from_rigid_prims(rprims)\n    paths_check = get_paths_from_rigid_prims(rprims_check)\n    paths_exclude = get_paths_from_rigid_prims(rprims_exclude)\n\n    # Run sanity checks\n    assert paths_check.isdisjoint(paths_exclude), \\\n        f\"Paths to check and paths to ignore collisions for should be mutually exclusive! \" \\\n        f\"paths_check: {paths_check}, paths_exclude: {paths_exclude}\"\n\n    # Determine whether we're checking / filtering any collision from collision set A\n    should_check_collisions = len(paths_check) &gt; 0\n    should_filter_collisions = len(paths_exclude) &gt; 0\n\n    # Get all collisions from the objects set\n    collisions = get_contacts(rprims)\n\n    # Only run the following (expensive) code if we are actively using filtering criteria\n    if should_check_collisions or should_filter_collisions:\n\n        # First filter out unnecessary collisions\n        if should_filter_collisions:\n            # First filter pass, remove the intersection of the main contacts and the contacts from the exclusion set minus\n            # the intersection between the exclusion and normal set\n            # This filters out any matching collisions in the exclusion set that are NOT an overlap\n            # between @rprims and @rprims_exclude\n            rprims_exclude_intersect = rprims_exclude.intersection(rprims)\n            exclude_disjoint_collisions = get_contacts(rprims_exclude - rprims_exclude_intersect)\n            collisions.difference_update(exclude_disjoint_collisions)\n\n            # Second filter pass, we remove collisions that may include self-collisions\n            # This is a bit more tricky because we need to actually look at the individual contact pairs to determine\n            # whether it's a collision (which may include a self-collision) that should be filtered\n            # We do this by grabbing the contacts of the intersection between the exclusion and normal rprims sets,\n            # and then making sure the resulting contact pair sets are completely disjoint from the paths intersection\n            exclude_intersect_collisions = get_contacts(rprims_exclude_intersect)\n            collisions.difference_update({pair for pair in exclude_intersect_collisions if paths.issuperset(set(pair))})\n\n        # Now, we additionally check for explicit collisions, filtering out any that do not meet this criteria\n        # This is essentially the inverse of the filter collision process, where we do two passes again, but for each\n        # case we look at the union rather than the subtraction of the two sets\n        if should_check_collisions:\n            # First check pass, keep the intersection of the main contacts and the contacts from the check set minus\n            # the intersection between the check and normal set\n            # This keeps any matching collisions in the check set that overlap between @rprims and @rprims_check\n            rprims_check_intersect = rprims_check.intersection(rprims)\n            check_disjoint_collisions = get_contacts(rprims_check - rprims_check_intersect)\n            valid_other_collisions = collisions.intersection(check_disjoint_collisions)\n\n            # Second check pass, we additionally keep collisions that may include self-collisions\n            # This is a bit more tricky because we need to actually look at the individual contact pairs to determine\n            # whether it's a collision (which may include a self-collision) that should be kept\n            # We do this by grabbing the contacts of the intersection between the check and normal rprims sets,\n            # and then making sure the resulting contact pair sets is strictly a subset of the original set\n            # Lastly, we only keep the intersection of this resulting set with the original collision set, so that\n            # any previously filtered collisions are respected\n            check_intersect_collisions = get_contacts(rprims_check_intersect)\n            valid_intersect_collisions = collisions.intersection({pair for pair in check_intersect_collisions if paths.issuperset(set(pair))})\n\n            # Collisions is union of valid other and valid self collisions\n            collisions = valid_other_collisions.union(valid_intersect_collisions)\n\n    # Only going into this if it is for logging --&gt; efficiency\n    if logging.root.level &lt;= logging.DEBUG:\n        for item in collisions:\n            logging.debug(\"linkA:{}, linkB:{}\".format(item[0], item[1]))\n\n    return collisions\n</code></pre>","location":"reference/utils/sim_utils.html#utils.sim_utils.get_collisions"},{"title":"<code>land_object(obj, pos, quat=None, z_offset=None)</code>","text":"<p>Land the object at the specified position @pos, given a valid position and orientation.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object to place in the environment</p>  required    <code>pos</code>  <code>3-array</code>  <p>Global (x,y,z) location to place the object</p>  required    <code>quat</code>  <code>None or 4-array</code>  <p>Optional (x,y,z,w) quaternion orientation when placing the object. If None, a random orientation about the z-axis will be sampled</p>  <code>None</code>    <code>z_offset</code>  <code>None or float</code>  <p>Optional additional z_offset to apply</p>  <code>None</code>      Source code in <code>utils/sim_utils.py</code> <pre><code>def land_object(obj, pos, quat=None, z_offset=None):\n    \"\"\"\n    Land the object at the specified position @pos, given a valid position and orientation.\n\n    Args:\n        obj (BaseObject): Object to place in the environment\n        pos (3-array): Global (x,y,z) location to place the object\n        quat (None or 4-array): Optional (x,y,z,w) quaternion orientation when placing the object.\n            If None, a random orientation about the z-axis will be sampled\n        z_offset (None or float): Optional additional z_offset to apply\n    \"\"\"\n    # Make sure sim is playing\n    assert og.sim.is_playing(), \"Cannot land object while sim is not playing!\"\n\n    # Set the object's pose\n    quat = T.euler2quat([0, 0, np.random.uniform(0, np.pi * 2)]) if quat is None else quat\n    place_base_pose(obj, pos, quat, z_offset)\n\n    # If we're placing a robot, make sure it's reset and not moving\n    # Run import here to avoid circular imports\n    from omnigibson.robots.robot_base import BaseRobot\n    is_robot = isinstance(obj, BaseRobot)\n    if is_robot:\n        obj.reset()\n        obj.keep_still()\n\n    # Check to make sure we landed successfully\n    # land for maximum 1 second, should fall down ~5 meters\n    land_success = False\n    max_simulator_step = int(1.0 / og.sim.get_rendering_dt())\n    for _ in range(max_simulator_step):\n        # Run a sim step and see if we have any contacts\n        og.sim.step()\n        land_success = check_collision(prims=obj)\n        if land_success:\n            # Once we're successful, we can break immediately\n            print(f\"Landed object {obj.name} successfully!\")\n            break\n\n    # Print out warning in case we failed to land the object successfully\n    if not land_success:\n        logging.warning(f\"Object {obj.name} failed to land.\")\n\n    # Make sure robot isn't moving at the end if we're a robot\n    if is_robot:\n        obj.reset()\n        obj.keep_still()\n</code></pre>","location":"reference/utils/sim_utils.html#utils.sim_utils.land_object"},{"title":"<code>place_base_pose(obj, pos, quat=None, z_offset=None)</code>","text":"<p>Place the object so that its base (z-min) rests at the location of @pos</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object to place in the environment</p>  required    <code>pos</code>  <code>3-array</code>  <p>Global (x,y,z) location to place the base of the robot</p>  required    <code>quat</code>  <code>None or 4-array</code>  <p>Optional (x,y,z,w) quaternion orientation when placing the object. If None, the object's current orientation will be used</p>  <code>None</code>    <code>z_offset</code>  <code>None or float</code>  <p>Optional additional z_offset to apply</p>  <code>None</code>      Source code in <code>utils/sim_utils.py</code> <pre><code>def place_base_pose(obj, pos, quat=None, z_offset=None):\n    \"\"\"\n    Place the object so that its base (z-min) rests at the location of @pos\n\n    Args:\n        obj (BaseObject): Object to place in the environment\n        pos (3-array): Global (x,y,z) location to place the base of the robot\n        quat (None or 4-array): Optional (x,y,z,w) quaternion orientation when placing the object.\n            If None, the object's current orientation will be used\n        z_offset (None or float): Optional additional z_offset to apply\n    \"\"\"\n    # avoid circular dependency\n    from omnigibson.object_states import AABB\n\n    # Make sure AABB is up-to-date before grabbing value\n    get_physx_simulation_interface().fetch_results()\n    BoundingBoxAPI.clear()\n    obj.states[AABB].clear_cache()\n\n    lower, _ = obj.states[AABB].get_value()\n    cur_pos = obj.get_position()\n    z_diff = cur_pos[2] - lower[2]\n    obj.set_position_orientation(pos + np.array([0, 0, z_diff if z_offset is None else z_diff + z_offset]), quat)\n</code></pre>","location":"reference/utils/sim_utils.html#utils.sim_utils.place_base_pose"},{"title":"<code>prims_to_rigid_prim_set(inp_prims)</code>","text":"<p>Converts prims @inp_prims into its corresponding set of rigid prims</p> <p>Parameters:</p>    Name Type Description Default     <code>inp_prims</code>  <code>list of RigidPrim or EntityPrim</code>  <p>Arbitrary prims</p>  required     <p>Returns:</p>    Type Description       <p>set of RigidPrim: Aggregated set of RigidPrims from @inp_prims</p>     Source code in <code>utils/sim_utils.py</code> <pre><code>def prims_to_rigid_prim_set(inp_prims):\n    \"\"\"\n    Converts prims @inp_prims into its corresponding set of rigid prims\n\n    Args:\n        inp_prims (list of RigidPrim or EntityPrim): Arbitrary prims\n\n    Returns:\n        set of RigidPrim: Aggregated set of RigidPrims from @inp_prims\n    \"\"\"\n    # Avoid circular imports\n    from omnigibson.prims.entity_prim import EntityPrim\n    from omnigibson.prims.rigid_prim import RigidPrim\n\n    out = set()\n    for prim in inp_prims:\n        if isinstance(prim, EntityPrim):\n            out.update({link for link in prim.links.values()})\n        elif isinstance(prim, RigidPrim):\n            out.add(prim)\n        else:\n            raise ValueError(f\"Inputted prims must be either EntityPrim or RigidPrim instances \"\n                             f\"when getting collisions! Type: {type(prim)}\")\n    return out\n</code></pre>","location":"reference/utils/sim_utils.html#utils.sim_utils.prims_to_rigid_prim_set"},{"title":"<code>test_valid_pose(obj, pos, quat=None, z_offset=None)</code>","text":"<p>Test if the object can be placed with no collision.</p> <p>Parameters:</p>    Name Type Description Default     <code>obj</code>  <code>BaseObject</code>  <p>Object to place in the environment</p>  required    <code>pos</code>  <code>3-array</code>  <p>Global (x,y,z) location to place the object</p>  required    <code>quat</code>  <code>None or 4-array</code>  <p>Optional (x,y,z,w) quaternion orientation when placing the object. If None, the object's current orientation will be used</p>  <code>None</code>    <code>z_offset</code>  <code>None or float</code>  <p>Optional additional z_offset to apply</p>  <code>None</code>     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>Whether the placed object position is valid</p>     Source code in <code>utils/sim_utils.py</code> <pre><code>def test_valid_pose(obj, pos, quat=None, z_offset=None):\n    \"\"\"\n    Test if the object can be placed with no collision.\n\n    Args:\n        obj (BaseObject): Object to place in the environment\n        pos (3-array): Global (x,y,z) location to place the object\n        quat (None or 4-array): Optional (x,y,z,w) quaternion orientation when placing the object.\n            If None, the object's current orientation will be used\n        z_offset (None or float): Optional additional z_offset to apply\n\n    Returns:\n        bool: Whether the placed object position is valid\n    \"\"\"\n    # Make sure sim is playing\n    assert og.sim.is_playing(), \"Cannot test valid pose while sim is not playing!\"\n\n    # Store state before checking object position\n    state = og.sim.scene.dump_state(serialized=False)\n\n    # Set the pose of the object\n    place_base_pose(obj, pos, quat, z_offset)\n\n    # If we're placing a robot, make sure it's reset and not moving\n    # Run import here to avoid circular imports\n    from omnigibson.robots.robot_base import BaseRobot\n    if isinstance(obj, BaseRobot):\n        obj.reset()\n        obj.keep_still()\n\n    # Check whether we're in collision after taking a single physics step\n    in_collision = check_collision(prims=obj, step_physics=True)\n\n    # Restore state after checking the collision\n    og.sim.load_state(state, serialized=False)\n\n    # Valid if there are no collisions\n    return not in_collision\n</code></pre>","location":"reference/utils/sim_utils.html#utils.sim_utils.test_valid_pose"},{"title":"transform_utils","text":"<p>Utility functions of matrix and vector transformations.</p> <p>NOTE: convention for quaternions is (x, y, z, w)</p>","location":"reference/utils/transform_utils.html"},{"title":"<code>anorm(x, axis=None, keepdims=False)</code>","text":"<p>Compute L2 norms alogn specified axes.</p>  Source code in <code>utils/transform_utils.py</code> <pre><code>def anorm(x, axis=None, keepdims=False):\n    \"\"\"Compute L2 norms alogn specified axes.\"\"\"\n    return np.linalg.norm(x, axis=axis, keepdims=keepdims)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.anorm"},{"title":"<code>axisangle2quat(vec)</code>","text":"<p>Converts scaled axis-angle to quat.</p> <p>Parameters:</p>    Name Type Description Default     <code>vec</code>  <code>np.array</code>  <p>(ax,ay,az) axis-angle exponential coordinates</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) vec4 float angles</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def axisangle2quat(vec):\n    \"\"\"\n    Converts scaled axis-angle to quat.\n\n    Args:\n        vec (np.array): (ax,ay,az) axis-angle exponential coordinates\n\n    Returns:\n        np.array: (x,y,z,w) vec4 float angles\n    \"\"\"\n    # Grab angle\n    angle = np.linalg.norm(vec)\n\n    # handle zero-rotation case\n    if math.isclose(angle, 0.0):\n        return np.array([0.0, 0.0, 0.0, 1.0])\n\n    # otherwise convert like normal\n    return R.from_rotvec(vec).as_quat()\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.axisangle2quat"},{"title":"<code>cartesian_to_polar(x, y)</code>","text":"<p>Convert cartesian coordinate to polar coordinate</p>  Source code in <code>utils/transform_utils.py</code> <pre><code>def cartesian_to_polar(x, y):\n    \"\"\"Convert cartesian coordinate to polar coordinate\"\"\"\n    rho = np.sqrt(x ** 2 + y ** 2)\n    phi = np.arctan2(y, x)\n    return rho, phi\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.cartesian_to_polar"},{"title":"<code>clip_rotation(quat, limit)</code>","text":"<p>Limits a (delta) rotation to a specified limit</p> <p>Converts rotation to axis-angle, clips, then re-converts back into quaternion</p> <p>Parameters:</p>    Name Type Description Default     <code>quat</code>  <code>np.array</code>  <p>(x,y,z,w) rotation being clipped</p>  required    <code>limit</code>  <code>float</code>  <p>Value to limit rotation by -- magnitude (scalar, in radians)</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple:</p> <ul> <li>(np.array) Clipped rotation quaternion (x, y, z, w)</li> <li>(bool) whether the value was clipped or not</li> </ul>     Source code in <code>utils/transform_utils.py</code> <pre><code>def clip_rotation(quat, limit):\n    \"\"\"\n    Limits a (delta) rotation to a specified limit\n\n    Converts rotation to axis-angle, clips, then re-converts back into quaternion\n\n    Args:\n        quat (np.array): (x,y,z,w) rotation being clipped\n        limit (float): Value to limit rotation by -- magnitude (scalar, in radians)\n\n    Returns:\n        2-tuple:\n\n            - (np.array) Clipped rotation quaternion (x, y, z, w)\n            - (bool) whether the value was clipped or not\n    \"\"\"\n    clipped = False\n\n    # First, normalize the quaternion\n    quat = quat / np.linalg.norm(quat)\n\n    den = np.sqrt(max(1 - quat[3] * quat[3], 0))\n    if den == 0:\n        # This is a zero degree rotation, immediately return\n        return quat, clipped\n    else:\n        # This is all other cases\n        x = quat[0] / den\n        y = quat[1] / den\n        z = quat[2] / den\n        a = 2 * math.acos(quat[3])\n\n    # Clip rotation if necessary and return clipped quat\n    if abs(a) &gt; limit:\n        a = limit * np.sign(a) / 2\n        sa = math.sin(a)\n        ca = math.cos(a)\n        quat = np.array([x * sa, y * sa, z * sa, ca])\n        clipped = True\n\n    return quat, clipped\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.clip_rotation"},{"title":"<code>clip_translation(dpos, limit)</code>","text":"<p>Limits a translation (delta position) to a specified limit</p> <p>Scales down the norm of the dpos to 'limit' if norm(dpos) &gt; limit, else returns immediately</p> <p>Parameters:</p>    Name Type Description Default     <code>dpos</code>  <code>n-array</code>  <p>n-dim Translation being clipped (e,g.: (x, y, z)) -- numpy array</p>  required    <code>limit</code>  <code>float</code>  <p>Value to limit translation by -- magnitude (scalar, in same units as input)</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple:</p> <ul> <li>(np.array) Clipped translation (same dimension as inputs)</li> <li>(bool) whether the value was clipped or not</li> </ul>     Source code in <code>utils/transform_utils.py</code> <pre><code>def clip_translation(dpos, limit):\n    \"\"\"\n    Limits a translation (delta position) to a specified limit\n\n    Scales down the norm of the dpos to 'limit' if norm(dpos) &gt; limit, else returns immediately\n\n    Args:\n        dpos (n-array): n-dim Translation being clipped (e,g.: (x, y, z)) -- numpy array\n        limit (float): Value to limit translation by -- magnitude (scalar, in same units as input)\n\n    Returns:\n        2-tuple:\n\n            - (np.array) Clipped translation (same dimension as inputs)\n            - (bool) whether the value was clipped or not\n    \"\"\"\n    input_norm = np.linalg.norm(dpos)\n    return (dpos * limit / input_norm, True) if input_norm &gt; limit else (dpos, False)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.clip_translation"},{"title":"<code>convert_quat(q, to='xyzw')</code>","text":"<p>Converts quaternion from one convention to another. The convention to convert TO is specified as an optional argument. If to == 'xyzw', then the input is in 'wxyz' format, and vice-versa.</p> <p>Parameters:</p>    Name Type Description Default     <code>q</code>  <code>np.array</code>  <p>a 4-dim array corresponding to a quaternion</p>  required    <code>to</code>  <code>str</code>  <p>either 'xyzw' or 'wxyz', determining which convention to convert to.</p>  <code>'xyzw'</code>      Source code in <code>utils/transform_utils.py</code> <pre><code>def convert_quat(q, to=\"xyzw\"):\n    \"\"\"\n    Converts quaternion from one convention to another.\n    The convention to convert TO is specified as an optional argument.\n    If to == 'xyzw', then the input is in 'wxyz' format, and vice-versa.\n\n    Args:\n        q (np.array): a 4-dim array corresponding to a quaternion\n        to (str): either 'xyzw' or 'wxyz', determining which convention to convert to.\n    \"\"\"\n    if to == \"xyzw\":\n        return q[[1, 2, 3, 0]]\n    if to == \"wxyz\":\n        return q[[3, 0, 1, 2]]\n    raise Exception(\"convert_quat: choose a valid `to` argument (xyzw or wxyz)\")\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.convert_quat"},{"title":"<code>euler2mat(euler)</code>","text":"<p>Converts euler angles into rotation matrix form</p> <p>Parameters:</p>    Name Type Description Default     <code>euler</code>  <code>np.array</code>  <p>(r,p,y) angles</p>  required     <p>Returns:</p>    Type Description       <p>np.array: 3x3 rotation matrix</p>    <p>Raises:</p>    Type Description      <code>AssertionError</code>  <p>[Invalid input shape]</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def euler2mat(euler):\n    \"\"\"\n    Converts euler angles into rotation matrix form\n\n    Args:\n        euler (np.array): (r,p,y) angles\n\n    Returns:\n        np.array: 3x3 rotation matrix\n\n    Raises:\n        AssertionError: [Invalid input shape]\n    \"\"\"\n\n    euler = np.asarray(euler, dtype=np.float64)\n    assert euler.shape[-1] == 3, \"Invalid shaped euler {}\".format(euler)\n\n    return R.from_euler(\"xyz\", euler).as_matrix()\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.euler2mat"},{"title":"<code>euler2quat(euler)</code>","text":"<p>Converts euler angles into quaternion form</p> <p>Parameters:</p>    Name Type Description Default     <code>euler</code>  <code>np.array</code>  <p>(r,p,y) angles</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) float quaternion angles</p>    <p>Raises:</p>    Type Description      <code>AssertionError</code>  <p>[Invalid input shape]</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def euler2quat(euler):\n    \"\"\"\n    Converts euler angles into quaternion form\n\n    Args:\n        euler (np.array): (r,p,y) angles\n\n    Returns:\n        np.array: (x,y,z,w) float quaternion angles\n\n    Raises:\n        AssertionError: [Invalid input shape]\n    \"\"\"\n    return R.from_euler(\"xyz\", euler).as_quat()\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.euler2quat"},{"title":"<code>ewma_vectorized(data, alpha, offset=None, dtype=None, order='C', out=None)</code>","text":"<p>Calculates the exponential moving average over a vector. Will fail for large inputs.</p> <p>Parameters:</p>    Name Type Description Default     <code>data</code>  <code>Iterable</code>  <p>Input data</p>  required    <code>alpha</code>  <code>float</code>  <p>scalar in range (0,1) The alpha parameter for the moving average.</p>  required    <code>offset</code>  <code>None or float</code>  <p>If specified, the offset for the moving average. None defaults to data[0].</p>  <code>None</code>    <code>dtype</code>  <code>None or type</code>  <p>Data type used for calculations. If None, defaults to float64 unless data.dtype is float32, then it will use float32.</p>  <code>None</code>    <code>order</code>  <code>None or str</code>  <p>Order to use when flattening the data. Valid options are {'C', 'F', 'A'}. None defaults to 'C'.</p>  <code>'C'</code>    <code>out</code>  <code>None or np.array</code>  <p>If specified, the location into which the result is stored. If provided, it must have the same shape as the input. If not provided or <code>None</code>, a freshly-allocated array is returned.</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>np.array: Exponential moving average from @data</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def ewma_vectorized(data, alpha, offset=None, dtype=None, order=\"C\", out=None):\n    \"\"\"\n    Calculates the exponential moving average over a vector.\n    Will fail for large inputs.\n\n    Args:\n        data (Iterable): Input data\n        alpha (float): scalar in range (0,1)\n            The alpha parameter for the moving average.\n        offset (None or float): If specified, the offset for the moving average. None defaults to data[0].\n        dtype (None or type): Data type used for calculations. If None, defaults to float64 unless\n            data.dtype is float32, then it will use float32.\n        order (None or str): Order to use when flattening the data. Valid options are {'C', 'F', 'A'}.\n            None defaults to 'C'.\n        out (None or np.array): If specified, the location into which the result is stored. If provided, it must have\n            the same shape as the input. If not provided or `None`,\n            a freshly-allocated array is returned.\n\n    Returns:\n        np.array: Exponential moving average from @data\n    \"\"\"\n    data = np.array(data, copy=False)\n\n    if dtype is None:\n        if data.dtype == np.float32:\n            dtype = np.float32\n        else:\n            dtype = np.float64\n    else:\n        dtype = np.dtype(dtype)\n\n    if data.ndim &gt; 1:\n        # flatten input\n        data = data.reshape(-1, order)\n\n    if out is None:\n        out = np.empty_like(data, dtype=dtype)\n    else:\n        assert out.shape == data.shape\n        assert out.dtype == dtype\n\n    if data.size &lt; 1:\n        # empty input, return empty array\n        return out\n\n    if offset is None:\n        offset = data[0]\n\n    alpha = np.array(alpha, copy=False).astype(dtype, copy=False)\n\n    # scaling_factors -&gt; 0 as len(data) gets large\n    # this leads to divide-by-zeros below\n    scaling_factors = np.power(1.0 - alpha, np.arange(data.size + 1, dtype=dtype), dtype=dtype)\n    # create cumulative sum array\n    np.multiply(data, (alpha * scaling_factors[-2]) / scaling_factors[:-1], dtype=dtype, out=out)\n    np.cumsum(out, dtype=dtype, out=out)\n\n    # cumsums / scaling\n    out /= scaling_factors[-2::-1]\n\n    if offset != 0:\n        offset = np.array(offset, copy=False).astype(dtype, copy=False)\n        # add offsets\n        out += offset * scaling_factors[1:]\n\n    return out\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.ewma_vectorized"},{"title":"<code>force_in_A_to_force_in_B(force_A, torque_A, pose_A_in_B)</code>","text":"<p>Converts linear and rotational force at a point in frame A to the equivalent in frame B.</p> <p>Parameters:</p>    Name Type Description Default     <code>force_A</code>  <code>np.array</code>  <p>(fx,fy,fz) linear force in A</p>  required    <code>torque_A</code>  <code>np.array</code>  <p>(tx,ty,tz) rotational force (moment) in A</p>  required    <code>pose_A_in_B</code>  <code>np.array</code>  <p>4x4 matrix corresponding to the pose of A in frame B</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple:</p> <ul> <li>(np.array) (fx,fy,fz) linear forces in frame B</li> <li>(np.array) (tx,ty,tz) moments in frame B</li> </ul>     Source code in <code>utils/transform_utils.py</code> <pre><code>def force_in_A_to_force_in_B(force_A, torque_A, pose_A_in_B):\n    \"\"\"\n    Converts linear and rotational force at a point in frame A to the equivalent in frame B.\n\n    Args:\n        force_A (np.array): (fx,fy,fz) linear force in A\n        torque_A (np.array): (tx,ty,tz) rotational force (moment) in A\n        pose_A_in_B (np.array): 4x4 matrix corresponding to the pose of A in frame B\n\n    Returns:\n        2-tuple:\n\n            - (np.array) (fx,fy,fz) linear forces in frame B\n            - (np.array) (tx,ty,tz) moments in frame B\n    \"\"\"\n    pos_A_in_B = pose_A_in_B[:3, 3]\n    rot_A_in_B = pose_A_in_B[:3, :3]\n    skew_symm = _skew_symmetric_translation(pos_A_in_B)\n    force_B = rot_A_in_B.T.dot(force_A)\n    torque_B = -rot_A_in_B.T.dot(skew_symm.dot(force_A)) + rot_A_in_B.T.dot(torque_A)\n    return force_B, torque_B\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.force_in_A_to_force_in_B"},{"title":"<code>frustum(left, right, bottom, top, znear, zfar)</code>","text":"<p>Create view frustum matrix.</p>  Source code in <code>utils/transform_utils.py</code> <pre><code>def frustum(left, right, bottom, top, znear, zfar):\n    \"\"\"Create view frustum matrix.\"\"\"\n    assert right != left\n    assert bottom != top\n    assert znear != zfar\n\n    M = np.zeros((4, 4), dtype=np.float32)\n    M[0, 0] = +2.0 * znear / (right - left)\n    M[2, 0] = (right + left) / (right - left)\n    M[1, 1] = +2.0 * znear / (top - bottom)\n    # TODO: Put this back to 3,1\n    # M[3, 1] = (top + bottom) / (top - bottom)\n    M[2, 1] = (top + bottom) / (top - bottom)\n    M[2, 2] = -(zfar + znear) / (zfar - znear)\n    M[3, 2] = -2.0 * znear * zfar / (zfar - znear)\n    M[2, 3] = -1.0\n    return M\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.frustum"},{"title":"<code>get_orientation_error(target_orn, current_orn)</code>","text":"<p>Returns the difference between two quaternion orientations as a 3 DOF numpy array. For use in an impedance controller / task-space PD controller.</p> <p>Parameters:</p>    Name Type Description Default     <code>target_orn</code>  <code>np.array</code>  <p>(x, y, z, w) desired quaternion orientation</p>  required    <code>current_orn</code>  <code>np.array</code>  <p>(x, y, z, w) current quaternion orientation</p>  required     <p>Returns:</p>    Name Type Description     <code>orn_error</code>  <code>np.array</code>  <p>(ax,ay,az) current orientation error, corresponds to (target_orn - current_orn)</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def get_orientation_error(target_orn, current_orn):\n    \"\"\"\n    Returns the difference between two quaternion orientations as a 3 DOF numpy array.\n    For use in an impedance controller / task-space PD controller.\n\n    Args:\n        target_orn (np.array): (x, y, z, w) desired quaternion orientation\n        current_orn (np.array): (x, y, z, w) current quaternion orientation\n\n    Returns:\n        orn_error (np.array): (ax,ay,az) current orientation error, corresponds to\n            (target_orn - current_orn)\n    \"\"\"\n    current_orn = np.array([current_orn[3], current_orn[0], current_orn[1], current_orn[2]])\n    target_orn = np.array([target_orn[3], target_orn[0], target_orn[1], target_orn[2]])\n\n    pinv = np.zeros((3, 4))\n    pinv[0, :] = [-current_orn[1], current_orn[0], -current_orn[3], current_orn[2]]\n    pinv[1, :] = [-current_orn[2], current_orn[3], current_orn[0], -current_orn[1]]\n    pinv[2, :] = [-current_orn[3], -current_orn[2], current_orn[1], current_orn[0]]\n    orn_error = 2.0 * pinv.dot(np.array(target_orn))\n    return orn_error\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.get_orientation_error"},{"title":"<code>get_pose_error(target_pose, current_pose)</code>","text":"<p>Computes the error corresponding to target pose - current pose as a 6-dim vector. The first 3 components correspond to translational error while the last 3 components correspond to the rotational error.</p> <p>Parameters:</p>    Name Type Description Default     <code>target_pose</code>  <code>np.array</code>  <p>a 4x4 homogenous matrix for the target pose</p>  required    <code>current_pose</code>  <code>np.array</code>  <p>a 4x4 homogenous matrix for the current pose</p>  required     <p>Returns:</p>    Type Description       <p>np.array: 6-dim pose error.</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def get_pose_error(target_pose, current_pose):\n    \"\"\"\n    Computes the error corresponding to target pose - current pose as a 6-dim vector.\n    The first 3 components correspond to translational error while the last 3 components\n    correspond to the rotational error.\n\n    Args:\n        target_pose (np.array): a 4x4 homogenous matrix for the target pose\n        current_pose (np.array): a 4x4 homogenous matrix for the current pose\n\n    Returns:\n        np.array: 6-dim pose error.\n    \"\"\"\n    error = np.zeros(6)\n\n    # compute translational error\n    target_pos = target_pose[:3, 3]\n    current_pos = current_pose[:3, 3]\n    pos_err = target_pos - current_pos\n\n    # compute rotational error\n    r1 = current_pose[:3, 0]\n    r2 = current_pose[:3, 1]\n    r3 = current_pose[:3, 2]\n    r1d = target_pose[:3, 0]\n    r2d = target_pose[:3, 1]\n    r3d = target_pose[:3, 2]\n    rot_err = 0.5 * (np.cross(r1, r1d) + np.cross(r2, r2d) + np.cross(r3, r3d))\n\n    error[:3] = pos_err\n    error[3:] = rot_err\n    return error\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.get_pose_error"},{"title":"<code>l2_distance(v1, v2)</code>","text":"<p>Returns the L2 distance between vector v1 and v2.</p>  Source code in <code>utils/transform_utils.py</code> <pre><code>def l2_distance(v1, v2):\n    \"\"\"Returns the L2 distance between vector v1 and v2.\"\"\"\n    return np.linalg.norm(np.array(v1) - np.array(v2))\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.l2_distance"},{"title":"<code>make_pose(translation, rotation)</code>","text":"<p>Makes a homogeneous pose matrix from a translation vector and a rotation matrix.</p> <p>Parameters:</p>    Name Type Description Default     <code>translation</code>  <code>np.array</code>  <p>(x,y,z) translation value</p>  required    <code>rotation</code>  <code>np.array</code>  <p>a 3x3 matrix representing rotation</p>  required     <p>Returns:</p>    Name Type Description     <code>pose</code>  <code>np.array</code>  <p>a 4x4 homogeneous matrix</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def make_pose(translation, rotation):\n    \"\"\"\n    Makes a homogeneous pose matrix from a translation vector and a rotation matrix.\n\n    Args:\n        translation (np.array): (x,y,z) translation value\n        rotation (np.array): a 3x3 matrix representing rotation\n\n    Returns:\n        pose (np.array): a 4x4 homogeneous matrix\n    \"\"\"\n    pose = np.zeros((4, 4))\n    pose[:3, :3] = rotation\n    pose[:3, 3] = translation\n    pose[3, 3] = 1.0\n    return pose\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.make_pose"},{"title":"<code>mat2euler(rmat)</code>","text":"<p>Converts given rotation matrix to euler angles in radian.</p> <p>Parameters:</p>    Name Type Description Default     <code>rmat</code>  <code>np.array</code>  <p>3x3 rotation matrix</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (r,p,y) converted euler angles in radian vec3 float</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def mat2euler(rmat):\n    \"\"\"\n    Converts given rotation matrix to euler angles in radian.\n\n    Args:\n        rmat (np.array): 3x3 rotation matrix\n\n    Returns:\n        np.array: (r,p,y) converted euler angles in radian vec3 float\n    \"\"\"\n    M = np.array(rmat, dtype=np.float32, copy=False)[:3, :3]\n    return R.from_matrix(M).as_euler(\"xyz\")\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.mat2euler"},{"title":"<code>mat2pose(hmat)</code>","text":"<p>Converts a homogeneous 4x4 matrix into pose.</p> <p>Parameters:</p>    Name Type Description Default     <code>hmat</code>  <code>np.array</code>  <p>a 4x4 homogeneous matrix</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple:</p> <ul> <li>(np.array) (x,y,z) position array in cartesian coordinates</li> <li>(np.array) (x,y,z,w) orientation array in quaternion form</li> </ul>     Source code in <code>utils/transform_utils.py</code> <pre><code>def mat2pose(hmat):\n    \"\"\"\n    Converts a homogeneous 4x4 matrix into pose.\n\n    Args:\n        hmat (np.array): a 4x4 homogeneous matrix\n\n    Returns:\n        2-tuple:\n\n            - (np.array) (x,y,z) position array in cartesian coordinates\n            - (np.array) (x,y,z,w) orientation array in quaternion form\n    \"\"\"\n    pos = hmat[:3, 3]\n    orn = mat2quat(hmat[:3, :3])\n    return pos, orn\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.mat2pose"},{"title":"<code>mat2quat(rmat)</code>","text":"<p>Converts given rotation matrix to quaternion.</p> <p>Parameters:</p>    Name Type Description Default     <code>rmat</code>  <code>np.array</code>  <p>3x3 rotation matrix</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) float quaternion angles</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def mat2quat(rmat):\n    \"\"\"\n    Converts given rotation matrix to quaternion.\n\n    Args:\n        rmat (np.array): 3x3 rotation matrix\n\n    Returns:\n        np.array: (x,y,z,w) float quaternion angles\n    \"\"\"\n    M = np.asarray(rmat).astype(np.float32)[:3, :3]\n    return R.from_matrix(M).as_quat()\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.mat2quat"},{"title":"<code>mat4(array)</code>","text":"<p>Converts an array to 4x4 matrix.</p> <p>Parameters:</p>    Name Type Description Default     <code>array</code>  <code>n-array</code>  <p>the array in form of vec, list, or tuple</p>  required     <p>Returns:</p>    Type Description       <p>np.array: a 4x4 numpy matrix</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def mat4(array):\n    \"\"\"\n    Converts an array to 4x4 matrix.\n\n    Args:\n        array (n-array): the array in form of vec, list, or tuple\n\n    Returns:\n        np.array: a 4x4 numpy matrix\n    \"\"\"\n    return np.array(array, dtype=np.float32).reshape((4, 4))\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.mat4"},{"title":"<code>matrix_inverse(matrix)</code>","text":"<p>Helper function to have an efficient matrix inversion function.</p> <p>Parameters:</p>    Name Type Description Default     <code>matrix</code>  <code>np.array</code>  <p>2d-array representing a matrix</p>  required     <p>Returns:</p>    Type Description       <p>np.array: 2d-array representing the matrix inverse</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def matrix_inverse(matrix):\n    \"\"\"\n    Helper function to have an efficient matrix inversion function.\n\n    Args:\n        matrix (np.array): 2d-array representing a matrix\n\n    Returns:\n        np.array: 2d-array representing the matrix inverse\n    \"\"\"\n    return np.linalg.inv(matrix)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.matrix_inverse"},{"title":"<code>normalize(v, axis=None, eps=1e-10)</code>","text":"<p>L2 Normalize along specified axes.</p>  Source code in <code>utils/transform_utils.py</code> <pre><code>def normalize(v, axis=None, eps=1e-10):\n    \"\"\"L2 Normalize along specified axes.\"\"\"\n    return v / max(anorm(v, axis=axis, keepdims=True), eps)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.normalize"},{"title":"<code>ortho(left, right, bottom, top, znear, zfar)</code>","text":"<p>Create orthonormal projection matrix.</p>  Source code in <code>utils/transform_utils.py</code> <pre><code>def ortho(left, right, bottom, top, znear, zfar):\n    \"\"\"Create orthonormal projection matrix.\"\"\"\n    assert right != left\n    assert bottom != top\n    assert znear != zfar\n\n    M = np.zeros((4, 4), dtype=np.float32)\n    M[0, 0] = 2.0 / (right - left)\n    M[1, 1] = 2.0 / (top - bottom)\n    M[2, 2] = -2.0 / (zfar - znear)\n    M[3, 0] = -(right + left) / (right - left)\n    M[3, 1] = -(top + bottom) / (top - bottom)\n    M[3, 2] = -(zfar + znear) / (zfar - znear)\n    M[3, 3] = 1.0\n    return M\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.ortho"},{"title":"<code>perspective(fovy, aspect, znear, zfar)</code>","text":"<p>Create perspective projection matrix.</p>  Source code in <code>utils/transform_utils.py</code> <pre><code>def perspective(fovy, aspect, znear, zfar):\n    \"\"\"Create perspective projection matrix.\"\"\"\n    # fovy is in degree\n    assert znear != zfar\n    h = np.tan(fovy / 360.0 * np.pi) * znear\n    w = h * aspect\n    return frustum(-w, w, -h, h, znear, zfar)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.perspective"},{"title":"<code>pose2mat(pose)</code>","text":"<p>Converts pose to homogeneous matrix.</p> <p>Parameters:</p>    Name Type Description Default     <code>pose</code>  <code>2-tuple</code>  <p>a (pos, orn) tuple where pos is vec3 float cartesian, and orn is vec4 float quaternion.</p>  required     <p>Returns:</p>    Type Description       <p>np.array: 4x4 homogeneous matrix</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def pose2mat(pose):\n    \"\"\"\n    Converts pose to homogeneous matrix.\n\n    Args:\n        pose (2-tuple): a (pos, orn) tuple where pos is vec3 float cartesian, and\n            orn is vec4 float quaternion.\n\n    Returns:\n        np.array: 4x4 homogeneous matrix\n    \"\"\"\n    homo_pose_mat = np.zeros((4, 4), dtype=np.float32)\n    homo_pose_mat[:3, :3] = quat2mat(pose[1])\n    homo_pose_mat[:3, 3] = np.array(pose[0], dtype=np.float32)\n    homo_pose_mat[3, 3] = 1.0\n    return homo_pose_mat\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.pose2mat"},{"title":"<code>pose_in_A_to_pose_in_B(pose_A, pose_A_in_B)</code>","text":"<p>Converts a homogenous matrix corresponding to a point C in frame A to a homogenous matrix corresponding to the same point C in frame B.</p> <p>Parameters:</p>    Name Type Description Default     <code>pose_A</code>  <code>np.array</code>  <p>4x4 matrix corresponding to the pose of C in frame A</p>  required    <code>pose_A_in_B</code>  <code>np.array</code>  <p>4x4 matrix corresponding to the pose of A in frame B</p>  required     <p>Returns:</p>    Type Description       <p>np.array: 4x4 matrix corresponding to the pose of C in frame B</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def pose_in_A_to_pose_in_B(pose_A, pose_A_in_B):\n    \"\"\"\n    Converts a homogenous matrix corresponding to a point C in frame A\n    to a homogenous matrix corresponding to the same point C in frame B.\n\n    Args:\n        pose_A (np.array): 4x4 matrix corresponding to the pose of C in frame A\n        pose_A_in_B (np.array): 4x4 matrix corresponding to the pose of A in frame B\n\n    Returns:\n        np.array: 4x4 matrix corresponding to the pose of C in frame B\n    \"\"\"\n\n    # pose of A in B takes a point in A and transforms it to a point in C.\n\n    # pose of C in B = pose of A in B * pose of C in A\n    # take a point in C, transform it to A, then to B\n    # T_B^C = T_A^C * T_B^A\n    return pose_A_in_B.dot(pose_A)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.pose_in_A_to_pose_in_B"},{"title":"<code>pose_inv(pose_mat)</code>","text":"<p>Computes the inverse of a homogeneous matrix corresponding to the pose of some frame B in frame A. The inverse is the pose of frame A in frame B.</p> <p>Parameters:</p>    Name Type Description Default     <code>pose_mat</code>  <code>np.array</code>  <p>4x4 matrix for the pose to inverse</p>  required     <p>Returns:</p>    Type Description       <p>np.array: 4x4 matrix for the inverse pose</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def pose_inv(pose_mat):\n    \"\"\"\n    Computes the inverse of a homogeneous matrix corresponding to the pose of some\n    frame B in frame A. The inverse is the pose of frame A in frame B.\n\n    Args:\n        pose_mat (np.array): 4x4 matrix for the pose to inverse\n\n    Returns:\n        np.array: 4x4 matrix for the inverse pose\n    \"\"\"\n\n    # Note, the inverse of a pose matrix is the following\n    # [R t; 0 1]^-1 = [R.T -R.T*t; 0 1]\n\n    # Intuitively, this makes sense.\n    # The original pose matrix translates by t, then rotates by R.\n    # We just invert the rotation by applying R-1 = R.T, and also translate back.\n    # Since we apply translation first before rotation, we need to translate by\n    # -t in the original frame, which is -R-1*t in the new frame, and then rotate back by\n    # R-1 to align the axis again.\n\n    pose_inv = np.zeros((4, 4))\n    pose_inv[:3, :3] = pose_mat[:3, :3].T\n    pose_inv[:3, 3] = -pose_inv[:3, :3].dot(pose_mat[:3, 3])\n    pose_inv[3, 3] = 1.0\n    return pose_inv\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.pose_inv"},{"title":"<code>pose_transform(pos1, quat1, pos0, quat0)</code>","text":"<p>Conducts forward transform from pose (pos0, quat0) to pose (pos1, quat1):</p> <p>pose1 @ pose0, NOT pose0 @ pose1</p> <p>Parameters:</p>    Name Type Description Default     <code>pos1</code>   <p>(x,y,z) position to transform</p>  required    <code>quat1</code>   <p>(x,y,z,w) orientation to transform</p>  required    <code>pos0</code>   <p>(x,y,z) initial position</p>  required    <code>quat0</code>   <p>(x,y,z,w) initial orientation</p>  required      Source code in <code>utils/transform_utils.py</code> <pre><code>def pose_transform(pos1, quat1, pos0, quat0):\n    \"\"\"\n    Conducts forward transform from pose (pos0, quat0) to pose (pos1, quat1):\n\n    pose1 @ pose0, NOT pose0 @ pose1\n\n    Args:\n        pos1: (x,y,z) position to transform\n        quat1: (x,y,z,w) orientation to transform\n        pos0: (x,y,z) initial position\n        quat0: (x,y,z,w) initial orientation\n    \"\"\"\n    # Get poses\n    mat0 = pose2mat((pos0, quat0))\n    mat1 = pose2mat((pos1, quat1))\n\n    # Multiply and convert back to pos, quat\n    return mat2pose(mat1 @ mat0)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.pose_transform"},{"title":"<code>quat2axisangle(quat)</code>","text":"<p>Converts quaternion to axis-angle format. Returns a unit vector direction scaled by its angle in radians.</p> <p>Parameters:</p>    Name Type Description Default     <code>quat</code>  <code>np.array</code>  <p>(x,y,z,w) vec4 float angles</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (ax,ay,az) axis-angle exponential coordinates</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat2axisangle(quat):\n    \"\"\"\n    Converts quaternion to axis-angle format.\n    Returns a unit vector direction scaled by its angle in radians.\n\n    Args:\n        quat (np.array): (x,y,z,w) vec4 float angles\n\n    Returns:\n        np.array: (ax,ay,az) axis-angle exponential coordinates\n    \"\"\"\n    return R.from_quat(quat).as_rotvec()\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat2axisangle"},{"title":"<code>quat2euler(quat)</code>","text":"<p>Converts euler angles into quaternion form</p> <p>Parameters:</p>    Name Type Description Default     <code>quat</code>  <code>np.array</code>  <p>(x,y,z,w) float quaternion angles</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (r,p,y) angles</p>    <p>Raises:</p>    Type Description      <code>AssertionError</code>  <p>[Invalid input shape]</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat2euler(quat):\n    \"\"\"\n    Converts euler angles into quaternion form\n\n    Args:\n        quat (np.array): (x,y,z,w) float quaternion angles\n\n    Returns:\n        np.array: (r,p,y) angles\n\n    Raises:\n        AssertionError: [Invalid input shape]\n    \"\"\"\n    return R.from_quat(quat).as_euler(\"xyz\")\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat2euler"},{"title":"<code>quat2mat(quaternion)</code>","text":"<p>Converts given quaternion to matrix.</p> <p>Parameters:</p>    Name Type Description Default     <code>quaternion</code>  <code>np.array</code>  <p>(x,y,z,w) vec4 float angles</p>  required     <p>Returns:</p>    Type Description       <p>np.array: 3x3 rotation matrix</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat2mat(quaternion):\n    \"\"\"\n    Converts given quaternion to matrix.\n\n    Args:\n        quaternion (np.array): (x,y,z,w) vec4 float angles\n\n    Returns:\n        np.array: 3x3 rotation matrix\n    \"\"\"\n    return R.from_quat(quaternion).as_matrix()\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat2mat"},{"title":"<code>quat_conjugate(quaternion)</code>","text":"<p>Return conjugate of quaternion.</p> <p>E.g.:</p>    <p>q0 = random_quaternion() q1 = quat_conjugate(q0) q1[3] == q0[3] and all(q1[:3] == -q0[:3]) True</p>    <p>Parameters:</p>    Name Type Description Default     <code>quaternion</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) quaternion conjugate</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat_conjugate(quaternion):\n    \"\"\"\n    Return conjugate of quaternion.\n\n    E.g.:\n    &gt;&gt;&gt; q0 = random_quaternion()\n    &gt;&gt;&gt; q1 = quat_conjugate(q0)\n    &gt;&gt;&gt; q1[3] == q0[3] and all(q1[:3] == -q0[:3])\n    True\n\n    Args:\n        quaternion (np.array): (x,y,z,w) quaternion\n\n    Returns:\n        np.array: (x,y,z,w) quaternion conjugate\n    \"\"\"\n    return np.array(\n        (-quaternion[0], -quaternion[1], -quaternion[2], quaternion[3]),\n        dtype=np.float32,\n    )\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat_conjugate"},{"title":"<code>quat_distance(quaternion1, quaternion0)</code>","text":"<p>Returns distance between two quaternions, such that distance * quaternion0 = quaternion1</p> <p>Parameters:</p>    Name Type Description Default     <code>quaternion1</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion</p>  required    <code>quaternion0</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) quaternion distance</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat_distance(quaternion1, quaternion0):\n    \"\"\"\n    Returns distance between two quaternions, such that distance * quaternion0 = quaternion1\n\n    Args:\n        quaternion1 (np.array): (x,y,z,w) quaternion\n        quaternion0 (np.array): (x,y,z,w) quaternion\n\n    Returns:\n        np.array: (x,y,z,w) quaternion distance\n    \"\"\"\n    return quat_multiply(quaternion1, quat_inverse(quaternion0))\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat_distance"},{"title":"<code>quat_inverse(quaternion)</code>","text":"<p>Return inverse of quaternion.</p> <p>E.g.:</p>    <p>q0 = random_quaternion() q1 = quat_inverse(q0) np.allclose(quat_multiply(q0, q1), [0, 0, 0, 1]) True</p>    <p>Parameters:</p>    Name Type Description Default     <code>quaternion</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) quaternion inverse</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat_inverse(quaternion):\n    \"\"\"\n    Return inverse of quaternion.\n\n    E.g.:\n    &gt;&gt;&gt; q0 = random_quaternion()\n    &gt;&gt;&gt; q1 = quat_inverse(q0)\n    &gt;&gt;&gt; np.allclose(quat_multiply(q0, q1), [0, 0, 0, 1])\n    True\n\n    Args:\n        quaternion (np.array): (x,y,z,w) quaternion\n\n    Returns:\n        np.array: (x,y,z,w) quaternion inverse\n    \"\"\"\n    return quat_conjugate(quaternion) / np.dot(quaternion, quaternion)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat_inverse"},{"title":"<code>quat_multiply(quaternion1, quaternion0)</code>","text":"<p>Return multiplication of two quaternions (q1 * q0).</p> <p>E.g.:</p>    <p>q = quat_multiply([1, -2, 3, 4], [-5, 6, 7, 8]) np.allclose(q, [-44, -14, 48, 28]) True</p>    <p>Parameters:</p>    Name Type Description Default     <code>quaternion1</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion</p>  required    <code>quaternion0</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion</p>  required     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) multiplied quaternion</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat_multiply(quaternion1, quaternion0):\n    \"\"\"\n    Return multiplication of two quaternions (q1 * q0).\n\n    E.g.:\n    &gt;&gt;&gt; q = quat_multiply([1, -2, 3, 4], [-5, 6, 7, 8])\n    &gt;&gt;&gt; np.allclose(q, [-44, -14, 48, 28])\n    True\n\n    Args:\n        quaternion1 (np.array): (x,y,z,w) quaternion\n        quaternion0 (np.array): (x,y,z,w) quaternion\n\n    Returns:\n        np.array: (x,y,z,w) multiplied quaternion\n    \"\"\"\n    x0, y0, z0, w0 = quaternion0\n    x1, y1, z1, w1 = quaternion1\n    return np.array(\n        (\n            x1 * w0 + y1 * z0 - z1 * y0 + w1 * x0,\n            -x1 * z0 + y1 * w0 + z1 * x0 + w1 * y0,\n            x1 * y0 - y1 * x0 + z1 * w0 + w1 * z0,\n            -x1 * x0 - y1 * y0 - z1 * z0 + w1 * w0,\n        ),\n        dtype=np.float32,\n    )\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat_multiply"},{"title":"<code>quat_slerp(quat0, quat1, fraction, shortestpath=True)</code>","text":"<p>Return spherical linear interpolation between two quaternions.</p> <p>E.g.:</p>    <p>q0 = random_quat() q1 = random_quat() q = quat_slerp(q0, q1, 0.0) np.allclose(q, q0) True</p> <p>q = quat_slerp(q0, q1, 1.0) np.allclose(q, q1) True</p> <p>q = quat_slerp(q0, q1, 0.5) angle = math.acos(np.dot(q0, q)) np.allclose(2.0, math.acos(np.dot(q0, q1)) / angle) or         np.allclose(2.0, math.acos(-np.dot(q0, q1)) / angle) True</p>    <p>Parameters:</p>    Name Type Description Default     <code>quat0</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion startpoint</p>  required    <code>quat1</code>  <code>np.array</code>  <p>(x,y,z,w) quaternion endpoint</p>  required    <code>fraction</code>  <code>float</code>  <p>fraction of interpolation to calculate</p>  required    <code>shortestpath</code>  <code>bool</code>  <p>If True, will calculate the shortest path</p>  <code>True</code>     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) quaternion distance</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def quat_slerp(quat0, quat1, fraction, shortestpath=True):\n    \"\"\"\n    Return spherical linear interpolation between two quaternions.\n\n    E.g.:\n    &gt;&gt;&gt; q0 = random_quat()\n    &gt;&gt;&gt; q1 = random_quat()\n    &gt;&gt;&gt; q = quat_slerp(q0, q1, 0.0)\n    &gt;&gt;&gt; np.allclose(q, q0)\n    True\n\n    &gt;&gt;&gt; q = quat_slerp(q0, q1, 1.0)\n    &gt;&gt;&gt; np.allclose(q, q1)\n    True\n\n    &gt;&gt;&gt; q = quat_slerp(q0, q1, 0.5)\n    &gt;&gt;&gt; angle = math.acos(np.dot(q0, q))\n    &gt;&gt;&gt; np.allclose(2.0, math.acos(np.dot(q0, q1)) / angle) or \\\n        np.allclose(2.0, math.acos(-np.dot(q0, q1)) / angle)\n    True\n\n    Args:\n        quat0 (np.array): (x,y,z,w) quaternion startpoint\n        quat1 (np.array): (x,y,z,w) quaternion endpoint\n        fraction (float): fraction of interpolation to calculate\n        shortestpath (bool): If True, will calculate the shortest path\n\n    Returns:\n        np.array: (x,y,z,w) quaternion distance\n    \"\"\"\n    q0 = unit_vector(quat0[:4])\n    q1 = unit_vector(quat1[:4])\n    if fraction == 0.0:\n        return q0\n    elif fraction == 1.0:\n        return q1\n    d = np.dot(q0, q1)\n    if abs(abs(d) - 1.0) &lt; EPS:\n        return q0\n    if shortestpath and d &lt; 0.0:\n        # invert rotation\n        d = -d\n        q1 *= -1.0\n    angle = math.acos(np.clip(d, -1, 1))\n    if abs(angle) &lt; EPS:\n        return q0\n    isin = 1.0 / math.sin(angle)\n    q0 *= math.sin((1.0 - fraction) * angle) * isin\n    q1 *= math.sin(fraction * angle) * isin\n    q0 += q1\n    return q0\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.quat_slerp"},{"title":"<code>random_axis_angle(angle_limit=None, random_state=None)</code>","text":"<p>Samples an axis-angle rotation by first sampling a random axis and then sampling an angle. If @angle_limit is provided, the size of the rotation angle is constrained.</p> <p>If @random_state is provided (instance of np.random.RandomState), it will be used to generate random numbers.</p> <p>Parameters:</p>    Name Type Description Default     <code>angle_limit</code>  <code>None or float</code>  <p>If set, determines magnitude limit of angles to generate</p>  <code>None</code>    <code>random_state</code>  <code>None or RandomState</code>  <p>RNG to use if specified</p>  <code>None</code>     <p>Raises:</p>    Type Description      <code>AssertionError</code>  <p>[Invalid RNG]</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def random_axis_angle(angle_limit=None, random_state=None):\n    \"\"\"\n    Samples an axis-angle rotation by first sampling a random axis\n    and then sampling an angle. If @angle_limit is provided, the size\n    of the rotation angle is constrained.\n\n    If @random_state is provided (instance of np.random.RandomState), it\n    will be used to generate random numbers.\n\n    Args:\n        angle_limit (None or float): If set, determines magnitude limit of angles to generate\n        random_state (None or RandomState): RNG to use if specified\n\n    Raises:\n        AssertionError: [Invalid RNG]\n    \"\"\"\n    if angle_limit is None:\n        angle_limit = 2.0 * np.pi\n\n    if random_state is not None:\n        assert isinstance(random_state, np.random.RandomState)\n        npr = random_state\n    else:\n        npr = np.random\n\n    # sample random axis using a normalized sample from spherical Gaussian.\n    # see (http://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/)\n    # for why it works.\n    random_axis = npr.randn(3)\n    random_axis /= np.linalg.norm(random_axis)\n    random_angle = npr.uniform(low=0.0, high=angle_limit)\n    return random_axis, random_angle\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.random_axis_angle"},{"title":"<code>random_quat(rand=None)</code>","text":"<p>Return uniform random unit quaternion.</p> <p>E.g.:</p>    <p>q = random_quat() np.allclose(1.0, vector_norm(q)) True q = random_quat(np.random.random(3)) q.shape (4,)</p>    <p>Parameters:</p>    Name Type Description Default     <code>rand</code>  <code>3-array or None</code>  <p>If specified, must be three independent random variables that are uniformly distributed between 0 and 1.</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>np.array: (x,y,z,w) random quaternion</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def random_quat(rand=None):\n    \"\"\"\n    Return uniform random unit quaternion.\n\n    E.g.:\n    &gt;&gt;&gt; q = random_quat()\n    &gt;&gt;&gt; np.allclose(1.0, vector_norm(q))\n    True\n    &gt;&gt;&gt; q = random_quat(np.random.random(3))\n    &gt;&gt;&gt; q.shape\n    (4,)\n\n    Args:\n        rand (3-array or None): If specified, must be three independent random variables that are uniformly distributed\n            between 0 and 1.\n\n    Returns:\n        np.array: (x,y,z,w) random quaternion\n    \"\"\"\n    if rand is None:\n        rand = np.random.rand(3)\n    else:\n        assert len(rand) == 3\n    r1 = np.sqrt(1.0 - rand[0])\n    r2 = np.sqrt(rand[0])\n    pi2 = math.pi * 2.0\n    t1 = pi2 * rand[1]\n    t2 = pi2 * rand[2]\n    return np.array(\n        (np.sin(t1) * r1, np.cos(t1) * r1, np.sin(t2) * r2, np.cos(t2) * r2),\n        dtype=np.float32,\n    )\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.random_quat"},{"title":"<code>relative_pose_transform(pos1, quat1, pos0, quat0)</code>","text":"<p>Computes relative forward transform from pose (pos0, quat0) to pose (pos1, quat1), i.e.: solves:</p> <p>pose1 = pose0 @ transform</p> <p>Parameters:</p>    Name Type Description Default     <code>pos1</code>   <p>(x,y,z) position to transform</p>  required    <code>quat1</code>   <p>(x,y,z,w) orientation to transform</p>  required    <code>pos0</code>   <p>(x,y,z) initial position</p>  required    <code>quat0</code>   <p>(x,y,z,w) initial orientation</p>  required      Source code in <code>utils/transform_utils.py</code> <pre><code>def relative_pose_transform(pos1, quat1, pos0, quat0):\n    \"\"\"\n    Computes relative forward transform from pose (pos0, quat0) to pose (pos1, quat1), i.e.: solves:\n\n    pose1 = pose0 @ transform\n\n    Args:\n        pos1: (x,y,z) position to transform\n        quat1: (x,y,z,w) orientation to transform\n        pos0: (x,y,z) initial position\n        quat0: (x,y,z,w) initial orientation\n    \"\"\"\n    # Get poses\n    mat0 = pose2mat((pos0, quat0))\n    mat1 = pose2mat((pos1, quat1))\n\n    # Invert pose0 and calculate transform\n    return mat2pose(pose_inv(mat0) @ mat1)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.relative_pose_transform"},{"title":"<code>rotation_matrix(angle, direction, point=None)</code>","text":"<p>Returns matrix to rotate about axis defined by point and direction.</p> <p>E.g.:     &gt;&gt;&gt; angle = (random.random() - 0.5) * (2math.pi)     &gt;&gt;&gt; direc = numpy.random.random(3) - 0.5     &gt;&gt;&gt; point = numpy.random.random(3) - 0.5     &gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)     &gt;&gt;&gt; R1 = rotation_matrix(angle-2math.pi, direc, point)     &gt;&gt;&gt; is_same_transform(R0, R1)     True</p> <pre><code>&gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)\n&gt;&gt;&gt; R1 = rotation_matrix(-angle, -direc, point)\n&gt;&gt;&gt; is_same_transform(R0, R1)\nTrue\n\n&gt;&gt;&gt; I = numpy.identity(4, numpy.float32)\n&gt;&gt;&gt; numpy.allclose(I, rotation_matrix(math.pi*2, direc))\nTrue\n\n&gt;&gt;&gt; numpy.allclose(2., numpy.trace(rotation_matrix(math.pi/2,\n...                                                direc, point)))\nTrue\n</code></pre> <p>Parameters:</p>    Name Type Description Default     <code>angle</code>  <code>float</code>  <p>Magnitude of rotation</p>  required    <code>direction</code>  <code>np.array</code>  <p>(ax,ay,az) axis about which to rotate</p>  required    <code>point</code>  <code>None or np.array</code>  <p>If specified, is the (x,y,z) point about which the rotation will occur</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>np.array: 4x4 homogeneous matrix that includes the desired rotation</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def rotation_matrix(angle, direction, point=None):\n    \"\"\"\n    Returns matrix to rotate about axis defined by point and direction.\n\n    E.g.:\n        &gt;&gt;&gt; angle = (random.random() - 0.5) * (2*math.pi)\n        &gt;&gt;&gt; direc = numpy.random.random(3) - 0.5\n        &gt;&gt;&gt; point = numpy.random.random(3) - 0.5\n        &gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)\n        &gt;&gt;&gt; R1 = rotation_matrix(angle-2*math.pi, direc, point)\n        &gt;&gt;&gt; is_same_transform(R0, R1)\n        True\n\n        &gt;&gt;&gt; R0 = rotation_matrix(angle, direc, point)\n        &gt;&gt;&gt; R1 = rotation_matrix(-angle, -direc, point)\n        &gt;&gt;&gt; is_same_transform(R0, R1)\n        True\n\n        &gt;&gt;&gt; I = numpy.identity(4, numpy.float32)\n        &gt;&gt;&gt; numpy.allclose(I, rotation_matrix(math.pi*2, direc))\n        True\n\n        &gt;&gt;&gt; numpy.allclose(2., numpy.trace(rotation_matrix(math.pi/2,\n        ...                                                direc, point)))\n        True\n\n    Args:\n        angle (float): Magnitude of rotation\n        direction (np.array): (ax,ay,az) axis about which to rotate\n        point (None or np.array): If specified, is the (x,y,z) point about which the rotation will occur\n\n    Returns:\n        np.array: 4x4 homogeneous matrix that includes the desired rotation\n    \"\"\"\n    sina = math.sin(angle)\n    cosa = math.cos(angle)\n    direction = unit_vector(direction[:3])\n    # rotation matrix around unit vector\n    R = np.array(((cosa, 0.0, 0.0), (0.0, cosa, 0.0), (0.0, 0.0, cosa)), dtype=np.float32)\n    R += np.outer(direction, direction) * (1.0 - cosa)\n    direction *= sina\n    R += np.array(\n        (\n            (0.0, -direction[2], direction[1]),\n            (direction[2], 0.0, -direction[0]),\n            (-direction[1], direction[0], 0.0),\n        ),\n        dtype=np.float32,\n    )\n    M = np.identity(4)\n    M[:3, :3] = R\n    if point is not None:\n        # rotation not around origin\n        point = np.array(point[:3], dtype=np.float32, copy=False)\n        M[:3, 3] = point - np.dot(R, point)\n    return M\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.rotation_matrix"},{"title":"<code>unit_vector(data, axis=None, out=None)</code>","text":"<p>Returns ndarray normalized by length, i.e. eucledian norm, along axis.</p> <p>E.g.:     &gt;&gt;&gt; v0 = numpy.random.random(3)     &gt;&gt;&gt; v1 = unit_vector(v0)     &gt;&gt;&gt; numpy.allclose(v1, v0 / numpy.linalg.norm(v0))     True</p> <pre><code>&gt;&gt;&gt; v0 = numpy.random.rand(5, 4, 3)\n&gt;&gt;&gt; v1 = unit_vector(v0, axis=-1)\n&gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=2)), 2)\n&gt;&gt;&gt; numpy.allclose(v1, v2)\nTrue\n\n&gt;&gt;&gt; v1 = unit_vector(v0, axis=1)\n&gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=1)), 1)\n&gt;&gt;&gt; numpy.allclose(v1, v2)\nTrue\n\n&gt;&gt;&gt; v1 = numpy.empty((5, 4, 3), dtype=numpy.float32)\n&gt;&gt;&gt; unit_vector(v0, axis=1, out=v1)\n&gt;&gt;&gt; numpy.allclose(v1, v2)\nTrue\n\n&gt;&gt;&gt; list(unit_vector([]))\n[]\n\n&gt;&gt;&gt; list(unit_vector([1.0]))\n[1.0]\n</code></pre> <p>Parameters:</p>    Name Type Description Default     <code>data</code>  <code>np.array</code>  <p>data to normalize</p>  required    <code>axis</code>  <code>None or int</code>  <p>If specified, determines specific axis along data to normalize</p>  <code>None</code>    <code>out</code>  <code>None or np.array</code>  <p>If specified, will store computation in this variable</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>None or np.array: If @out is not specified, will return normalized vector. Otherwise, stores the output in @out</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def unit_vector(data, axis=None, out=None):\n    \"\"\"\n    Returns ndarray normalized by length, i.e. eucledian norm, along axis.\n\n    E.g.:\n        &gt;&gt;&gt; v0 = numpy.random.random(3)\n        &gt;&gt;&gt; v1 = unit_vector(v0)\n        &gt;&gt;&gt; numpy.allclose(v1, v0 / numpy.linalg.norm(v0))\n        True\n\n        &gt;&gt;&gt; v0 = numpy.random.rand(5, 4, 3)\n        &gt;&gt;&gt; v1 = unit_vector(v0, axis=-1)\n        &gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=2)), 2)\n        &gt;&gt;&gt; numpy.allclose(v1, v2)\n        True\n\n        &gt;&gt;&gt; v1 = unit_vector(v0, axis=1)\n        &gt;&gt;&gt; v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=1)), 1)\n        &gt;&gt;&gt; numpy.allclose(v1, v2)\n        True\n\n        &gt;&gt;&gt; v1 = numpy.empty((5, 4, 3), dtype=numpy.float32)\n        &gt;&gt;&gt; unit_vector(v0, axis=1, out=v1)\n        &gt;&gt;&gt; numpy.allclose(v1, v2)\n        True\n\n        &gt;&gt;&gt; list(unit_vector([]))\n        []\n\n        &gt;&gt;&gt; list(unit_vector([1.0]))\n        [1.0]\n\n    Args:\n        data (np.array): data to normalize\n        axis (None or int): If specified, determines specific axis along data to normalize\n        out (None or np.array): If specified, will store computation in this variable\n\n    Returns:\n        None or np.array: If @out is not specified, will return normalized vector. Otherwise, stores the output in @out\n    \"\"\"\n    if out is None:\n        data = np.array(data, dtype=np.float32, copy=True)\n        if data.ndim == 1:\n            data /= math.sqrt(np.dot(data, data))\n            return data\n    else:\n        if out is not data:\n            out[:] = np.array(data, copy=False)\n        data = out\n    length = np.atleast_1d(np.sum(data * data, axis))\n    np.sqrt(length, length)\n    if axis is not None:\n        length = np.expand_dims(length, axis)\n    data /= length\n    if out is None:\n        return data\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.unit_vector"},{"title":"<code>vec(values)</code>","text":"<p>Converts value tuple into a numpy vector.</p> <p>Parameters:</p>    Name Type Description Default     <code>values</code>  <code>n-array</code>  <p>a tuple of numbers</p>  required     <p>Returns:</p>    Type Description       <p>np.array: vector of given values</p>     Source code in <code>utils/transform_utils.py</code> <pre><code>def vec(values):\n    \"\"\"\n    Converts value tuple into a numpy vector.\n\n    Args:\n        values (n-array): a tuple of numbers\n\n    Returns:\n        np.array: vector of given values\n    \"\"\"\n    return np.array(values, dtype=np.float32)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.vec"},{"title":"<code>vec2quat(vec, up=(0, 0, 1.0))</code>","text":"<p>Converts given 3d-direction vector @vec to quaternion orientation with respect to another direction vector @up</p> <p>Parameters:</p>    Name Type Description Default     <code>vec</code>  <code>3-array</code>  <p>(x,y,z) direction vector (possible non-normalized)</p>  required    <code>up</code>  <code>3-array</code>  <p>(x,y,z) direction vector representing the canonical up direction (possible non-normalized)</p>  <code>(0, 0, 1.0)</code>      Source code in <code>utils/transform_utils.py</code> <pre><code>def vec2quat(vec, up=(0, 0, 1.0)):\n    \"\"\"\n    Converts given 3d-direction vector @vec to quaternion orientation with respect to another direction vector @up\n\n    Args:\n        vec (3-array): (x,y,z) direction vector (possible non-normalized)\n        up (3-array): (x,y,z) direction vector representing the canonical up direction (possible non-normalized)\n    \"\"\"\n    # See https://stackoverflow.com/questions/15873996/converting-a-direction-vector-to-a-quaternion-rotation\n    # Take cross product of @up and @vec to get @s_n, and then cross @vec and @s_n to get @u_n\n    # Then compose 3x3 rotation matrix and convert into quaternion\n    vec_n = vec / np.linalg.norm(vec)       # x\n    up_n = up / np.linalg.norm(up)\n    s_n = np.cross(up_n, vec_n)             # y\n    u_n = np.cross(vec_n, s_n)              # z\n    return mat2quat(np.array([vec_n, s_n, u_n]).T)\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.vec2quat"},{"title":"<code>vecs2axisangle(vec0, vec1)</code>","text":"<p>Converts the angle from unnormalized 3D vectors @vec0 to @vec1 into an axis-angle representation of the angle</p> <p>Parameters:</p>    Name Type Description Default     <code>vec0</code>  <code>3-array</code>  <p>(x,y,z) 3D vector, possibly unnormalized</p>  required    <code>vec1</code>  <code>3-array</code>  <p>(x,y,z) 3D vector, possibly unnormalized</p>  required      Source code in <code>utils/transform_utils.py</code> <pre><code>def vecs2axisangle(vec0, vec1):\n    \"\"\"\n    Converts the angle from unnormalized 3D vectors @vec0 to @vec1 into an axis-angle representation of the angle\n\n    Args:\n        vec0 (3-array): (x,y,z) 3D vector, possibly unnormalized\n        vec1 (3-array): (x,y,z) 3D vector, possibly unnormalized\n    \"\"\"\n    # Normalize vectors\n    vec0 = normalize(vec0)\n    vec1 = normalize(vec1)\n\n    # Get cross product for direction of angle, and multiply by arcos of the dot product which is the angle\n    return np.cross(vec0, vec1) * np.arccos(np.dot(vec0, vec1))\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.vecs2axisangle"},{"title":"<code>vel_in_A_to_vel_in_B(vel_A, ang_vel_A, pose_A_in_B)</code>","text":"<p>Converts linear and angular velocity of a point in frame A to the equivalent in frame B.</p> <p>Parameters:</p>    Name Type Description Default     <code>vel_A</code>  <code>np.array</code>  <p>(vx,vy,vz) linear velocity in A</p>  required    <code>ang_vel_A</code>  <code>np.array</code>  <p>(wx,wy,wz) angular velocity in A</p>  required    <code>pose_A_in_B</code>  <code>np.array</code>  <p>4x4 matrix corresponding to the pose of A in frame B</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple:</p> <ul> <li>(np.array) (vx,vy,vz) linear velocities in frame B</li> <li>(np.array) (wx,wy,wz) angular velocities in frame B</li> </ul>     Source code in <code>utils/transform_utils.py</code> <pre><code>def vel_in_A_to_vel_in_B(vel_A, ang_vel_A, pose_A_in_B):\n    \"\"\"\n    Converts linear and angular velocity of a point in frame A to the equivalent in frame B.\n\n    Args:\n        vel_A (np.array): (vx,vy,vz) linear velocity in A\n        ang_vel_A (np.array): (wx,wy,wz) angular velocity in A\n        pose_A_in_B (np.array): 4x4 matrix corresponding to the pose of A in frame B\n\n    Returns:\n        2-tuple:\n\n            - (np.array) (vx,vy,vz) linear velocities in frame B\n            - (np.array) (wx,wy,wz) angular velocities in frame B\n    \"\"\"\n    pos_A_in_B = pose_A_in_B[:3, 3]\n    rot_A_in_B = pose_A_in_B[:3, :3]\n    skew_symm = _skew_symmetric_translation(pos_A_in_B)\n    vel_B = rot_A_in_B.dot(vel_A) + skew_symm.dot(rot_A_in_B.dot(ang_vel_A))\n    ang_vel_B = rot_A_in_B.dot(ang_vel_A)\n    return vel_B, ang_vel_B\n</code></pre>","location":"reference/utils/transform_utils.html#utils.transform_utils.vel_in_A_to_vel_in_B"},{"title":"ui_utils","text":"<p>Helper classes and functions for streamlining user interactions</p>","location":"reference/utils/ui_utils.html"},{"title":"<code>CameraMover</code>","text":"<p>A helper class for manipulating a camera via the keyboard. Utilizes carb keyboard callbacks to move the camera around.</p> <p>Parameters:</p>    Name Type Description Default     <code>cam</code>  <code>VisionSensor</code>  <p>The camera vision sensor to manipulate via the keyboard</p>  required    <code>delta</code>  <code>float</code>  <p>Change (m) per keypress when moving the camera</p>  <code>0.25</code>      Source code in <code>utils/ui_utils.py</code> <pre><code>class CameraMover:\n    \"\"\"\n    A helper class for manipulating a camera via the keyboard. Utilizes carb keyboard callbacks to move\n    the camera around.\n\n    Args:\n        cam (VisionSensor): The camera vision sensor to manipulate via the keyboard\n        delta (float): Change (m) per keypress when moving the camera\n    \"\"\"\n    def __init__(self, cam, delta=0.25):\n        self.cam = cam\n        self.delta = delta\n        self.light_val = 5e5\n\n        self._appwindow = omni.appwindow.get_default_app_window()\n        self._input = carb.input.acquire_input_interface()\n        self._keyboard = self._appwindow.get_keyboard()\n        self._sub_keyboard = self._input.subscribe_to_keyboard_events(self._keyboard, self._sub_keyboard_event)\n\n    def change_light(self, delta):\n        self.light_val += delta\n        self.set_lights(self.light_val)\n\n    def set_lights(self, intensity):\n        from omni.isaac.core.utils.prims import get_prim_at_path\n        world = get_prim_at_path(\"/World\")\n        for prim in world.GetChildren():\n            for prim_child in prim.GetChildren():\n                for prim_child_child in prim_child.GetChildren():\n                    if \"Light\" in prim_child_child.GetPrimTypeInfo().GetTypeName():\n                        prim_child_child.GetAttribute(\"intensity\").Set(intensity)\n\n    def print_info(self):\n        \"\"\"\n        Prints keyboard command info out to the user\n        \"\"\"\n        print(\"*\" * 40)\n        print(\"CameraMover! Commands:\")\n        print()\n        print(f\"\\t Right Click + Drag: Rotate camera\")\n        print(f\"\\t W / S : Move camera forward / backward\")\n        print(f\"\\t A / D : Move camera left / right\")\n        print(f\"\\t T / G : Move camera up / down\")\n        print(f\"\\t 9 / 0 : Increase / decrease the lights\")\n        print(f\"\\t P : Print current camera pose\")\n\n    def print_cam_pose(self):\n        \"\"\"\n        Prints out the camera pose as (position, quaternion) in the world frame\n        \"\"\"\n        print(f\"cam pose: {self.cam.get_position_orientation()}\")\n\n    def set_delta(self, delta):\n        \"\"\"\n        Sets the delta value (how much the camera moves with each keypress) for this CameraMover\n\n        Args:\n            delta (float): Change (m) per keypress when moving the camera\n        \"\"\"\n        self.delta = delta\n\n    def set_cam(self, cam):\n        \"\"\"\n        Sets the active camera sensor for this CameraMover\n\n        Args:\n            cam (VisionSensor): The camera vision sensor to manipulate via the keyboard\n        \"\"\"\n        self.cam = cam\n\n    @property\n    def input_to_function(self):\n        \"\"\"\n        Returns:\n            dict: Mapping from relevant keypresses to corresponding function call to use\n        \"\"\"\n        return {\n            carb.input.KeyboardInput.P: lambda: self.print_cam_pose(),\n            carb.input.KeyboardInput.KEY_9: lambda: self.change_light(delta=2e4),\n            carb.input.KeyboardInput.KEY_0: lambda: self.change_light(delta=-2e4),\n        }\n\n    @property\n    def input_to_command(self):\n        \"\"\"\n        Returns:\n            dict: Mapping from relevant keypresses to corresponding delta command to apply to the camera pose\n        \"\"\"\n        return {\n            carb.input.KeyboardInput.D: np.array([self.delta, 0, 0]),\n            carb.input.KeyboardInput.A: np.array([-self.delta, 0, 0]),\n            carb.input.KeyboardInput.W: np.array([0, 0, -self.delta]),\n            carb.input.KeyboardInput.S: np.array([0, 0, self.delta]),\n            carb.input.KeyboardInput.T: np.array([0, self.delta, 0]),\n            carb.input.KeyboardInput.G: np.array([0, -self.delta, 0]),\n        }\n\n    def _sub_keyboard_event(self, event, *args, **kwargs):\n        \"\"\"\n        Handle keyboard events. Note: The signature is pulled directly from omni.\n\n        Args:\n            event (int): keyboard event type\n        \"\"\"\n        if event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\n\n            if event.type == carb.input.KeyboardEventType.KEY_PRESS and event.input in self.input_to_function:\n                self.input_to_function[event.input]()\n\n            else:\n                command = self.input_to_command.get(event.input, None)\n\n                if command is not None:\n                    # Convert to world frame to move the camera\n                    transform = T.quat2mat(self.cam.get_orientation())\n                    delta_pos_global = transform @ command\n                    self.cam.set_position(self.cam.get_position() + delta_pos_global)\n\n        return True\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover"},{"title":"<code>input_to_command</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Mapping from relevant keypresses to corresponding delta command to apply to the camera pose</p>","location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.input_to_command"},{"title":"<code>input_to_function</code>  <code>property</code>","text":"<p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Mapping from relevant keypresses to corresponding function call to use</p>","location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.input_to_function"},{"title":"<code>print_cam_pose()</code>","text":"<p>Prints out the camera pose as (position, quaternion) in the world frame</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>def print_cam_pose(self):\n    \"\"\"\n    Prints out the camera pose as (position, quaternion) in the world frame\n    \"\"\"\n    print(f\"cam pose: {self.cam.get_position_orientation()}\")\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.print_cam_pose"},{"title":"<code>print_info()</code>","text":"<p>Prints keyboard command info out to the user</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>def print_info(self):\n    \"\"\"\n    Prints keyboard command info out to the user\n    \"\"\"\n    print(\"*\" * 40)\n    print(\"CameraMover! Commands:\")\n    print()\n    print(f\"\\t Right Click + Drag: Rotate camera\")\n    print(f\"\\t W / S : Move camera forward / backward\")\n    print(f\"\\t A / D : Move camera left / right\")\n    print(f\"\\t T / G : Move camera up / down\")\n    print(f\"\\t 9 / 0 : Increase / decrease the lights\")\n    print(f\"\\t P : Print current camera pose\")\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.print_info"},{"title":"<code>set_cam(cam)</code>","text":"<p>Sets the active camera sensor for this CameraMover</p> <p>Parameters:</p>    Name Type Description Default     <code>cam</code>  <code>VisionSensor</code>  <p>The camera vision sensor to manipulate via the keyboard</p>  required      Source code in <code>utils/ui_utils.py</code> <pre><code>def set_cam(self, cam):\n    \"\"\"\n    Sets the active camera sensor for this CameraMover\n\n    Args:\n        cam (VisionSensor): The camera vision sensor to manipulate via the keyboard\n    \"\"\"\n    self.cam = cam\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.set_cam"},{"title":"<code>set_delta(delta)</code>","text":"<p>Sets the delta value (how much the camera moves with each keypress) for this CameraMover</p> <p>Parameters:</p>    Name Type Description Default     <code>delta</code>  <code>float</code>  <p>Change (m) per keypress when moving the camera</p>  required      Source code in <code>utils/ui_utils.py</code> <pre><code>def set_delta(self, delta):\n    \"\"\"\n    Sets the delta value (how much the camera moves with each keypress) for this CameraMover\n\n    Args:\n        delta (float): Change (m) per keypress when moving the camera\n    \"\"\"\n    self.delta = delta\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.CameraMover.set_delta"},{"title":"<code>KeyboardEventHandler</code>","text":"<p>Simple singleton class for handing keyboard events</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>class KeyboardEventHandler:\n    \"\"\"\n    Simple singleton class for handing keyboard events\n    \"\"\"\n    # Global keyboard callbacks\n    KEYBOARD_CALLBACKS = OrderedDict()\n\n    # ID assigned to meta callback method for this class\n    _CALLBACK_ID = None\n\n    def __init__(self):\n        raise ValueError(\"Cannot create an instance of keyboard event handler!\")\n\n    @classmethod\n    def initialize(cls):\n        \"\"\"\n        Hook up a meta function callback to the omni backend\n        \"\"\"\n        appwindow = omni.appwindow.get_default_app_window()\n        input_interface = carb.input.acquire_input_interface()\n        keyboard = appwindow.get_keyboard()\n        cls._CALLBACK_ID = input_interface.subscribe_to_keyboard_events(keyboard, cls._meta_callback)\n\n    @classmethod\n    def reset(cls):\n        \"\"\"\n        Resets this callback interface by removing all current callback functions\n        \"\"\"\n        appwindow = omni.appwindow.get_default_app_window()\n        input_interface = carb.input.acquire_input_interface()\n        keyboard = appwindow.get_keyboard()\n        input_interface.unsubscribe_to_keyboard_events(keyboard, cls._CALLBACK_ID)\n        cls.KEYBOARD_CALLBACKS = OrderedDict()\n        cls._CALLBACK_ID = None\n\n    @classmethod\n    def add_keyboard_callback(cls, key, callback_fn):\n        \"\"\"\n        Registers a keyboard callback function with omni, mapping a keypress from @key to run the callback_function\n        @callback_fn\n\n        Args:\n            key (carb.input.KeyboardInput): key to associate with the callback\n            callback_fn (function): Callback function to call if the key @key is pressed or repeated. Note that this\n                function's signature should be:\n\n                callback_fn() --&gt; None\n        \"\"\"\n        # Initialize the interface if not initialized yet\n        if cls._CALLBACK_ID is None:\n            cls.initialize()\n        # Add the callback\n        cls.KEYBOARD_CALLBACKS[key] = callback_fn\n\n    @classmethod\n    def _meta_callback(cls, event, *args, **kwargs):\n        \"\"\"\n        Meta callback function that is hooked up to omni's backend\n        \"\"\"\n        # Check if we've received a key press or repeat\n        if event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\n            # Run the specific callback\n            cls.KEYBOARD_CALLBACKS.get(event.input, lambda: None)()\n\n        # Always return True\n        return True\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler"},{"title":"<code>add_keyboard_callback(key, callback_fn)</code>  <code>classmethod</code>","text":"<p>Registers a keyboard callback function with omni, mapping a keypress from @key to run the callback_function @callback_fn</p> <p>Parameters:</p>    Name Type Description Default     <code>key</code>  <code>carb.input.KeyboardInput</code>  <p>key to associate with the callback</p>  required    <code>callback_fn</code>  <code>function</code>  <p>Callback function to call if the key @key is pressed or repeated. Note that this function's signature should be:</p> <p>callback_fn() --&gt; None</p>  required      Source code in <code>utils/ui_utils.py</code> <pre><code>@classmethod\ndef add_keyboard_callback(cls, key, callback_fn):\n    \"\"\"\n    Registers a keyboard callback function with omni, mapping a keypress from @key to run the callback_function\n    @callback_fn\n\n    Args:\n        key (carb.input.KeyboardInput): key to associate with the callback\n        callback_fn (function): Callback function to call if the key @key is pressed or repeated. Note that this\n            function's signature should be:\n\n            callback_fn() --&gt; None\n    \"\"\"\n    # Initialize the interface if not initialized yet\n    if cls._CALLBACK_ID is None:\n        cls.initialize()\n    # Add the callback\n    cls.KEYBOARD_CALLBACKS[key] = callback_fn\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler.add_keyboard_callback"},{"title":"<code>initialize()</code>  <code>classmethod</code>","text":"<p>Hook up a meta function callback to the omni backend</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>@classmethod\ndef initialize(cls):\n    \"\"\"\n    Hook up a meta function callback to the omni backend\n    \"\"\"\n    appwindow = omni.appwindow.get_default_app_window()\n    input_interface = carb.input.acquire_input_interface()\n    keyboard = appwindow.get_keyboard()\n    cls._CALLBACK_ID = input_interface.subscribe_to_keyboard_events(keyboard, cls._meta_callback)\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler.initialize"},{"title":"<code>reset()</code>  <code>classmethod</code>","text":"<p>Resets this callback interface by removing all current callback functions</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>@classmethod\ndef reset(cls):\n    \"\"\"\n    Resets this callback interface by removing all current callback functions\n    \"\"\"\n    appwindow = omni.appwindow.get_default_app_window()\n    input_interface = carb.input.acquire_input_interface()\n    keyboard = appwindow.get_keyboard()\n    input_interface.unsubscribe_to_keyboard_events(keyboard, cls._CALLBACK_ID)\n    cls.KEYBOARD_CALLBACKS = OrderedDict()\n    cls._CALLBACK_ID = None\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardEventHandler.reset"},{"title":"<code>KeyboardRobotController</code>","text":"<p>Simple class for controlling OmniGibson robots using keyboard commands</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>class KeyboardRobotController:\n    \"\"\"\n    Simple class for controlling OmniGibson robots using keyboard commands\n    \"\"\"\n\n    def __init__(self, robot):\n        \"\"\"\n        Args:\n            robot (BaseRobot): robot to control\n        \"\"\"\n        # Store relevant info from robot\n        self.robot = robot\n        self.action_dim = robot.action_dim\n        self.controller_info = OrderedDict()\n        idx = 0\n        for name, controller in robot._controllers.items():\n            self.controller_info[name] = {\n                \"name\": type(controller).__name__,\n                \"start_idx\": idx,\n                \"dofs\": controller.dof_idx,\n                \"command_dim\": controller.command_dim,\n            }\n            idx += controller.command_dim\n\n        # Other persistent variables we need to keep track of\n        self.joint_names = [name for name in robot.joints.keys()]  # Ordered list of joint names belonging to the robot\n        self.joint_command_idx = None   # Indices of joints being directly controlled in the action array\n        self.joint_control_idx = None  # Indices of joints being directly controlled in the actual joint array\n        self.active_joint_command_idx_idx = 0   # Which index within the joint_command_idx variable is being controlled by the user\n        self.current_joint = -1  # Active joint being controlled for joint control\n        self.ik_arms = []               # List of arm controller names to be controlled by IK\n        self.active_arm_idx = 0         # Which index within self.ik_arms is actively being controlled (only relevant for IK)\n        self.binary_grippers = []           # Grippers being controlled using multi-finger binary controller\n        self.active_gripper_idx = 0     # Which index within self.binary_grippers is actively being controlled\n        self.gripper_direction = None  # Flips between -1 and 1, per arm controlled by multi-finger binary control\n        self.persistent_gripper_action = None  # Persistent gripper commands, per arm controlled by multi-finger binary control\n        # i.e.: if using binary gripper control and when no keypress is active, the gripper action should still the last executed gripper action\n        self.keypress_mapping = None    # Maps omni keybindings to information for controlling various parts of the robot\n        self.current_keypress = None    # Current key that is being pressed\n        self.active_action = None       # Current action information based on the current keypress\n        self.toggling_gripper = False   # Whether we should toggle the gripper during the next action\n\n        # Populate the keypress mapping dictionary\n        self.populate_keypress_mapping()\n\n        # Register the keyboard callback function\n        self.register_keyboard_handler()\n\n    def register_keyboard_handler(self):\n        \"\"\"\n        Sets up the keyboard callback functionality with omniverse\n        \"\"\"\n        appwindow = omni.appwindow.get_default_app_window()\n        input_interface = carb.input.acquire_input_interface()\n        keyboard = appwindow.get_keyboard()\n        sub_keyboard = input_interface.subscribe_to_keyboard_events(keyboard, self.keyboard_event_handler)\n\n    def generate_ik_keypress_mapping(self, controller_info):\n        \"\"\"\n        Generates a dictionary for keypress mappings for IK control, based on the inputted @controller_info\n\n        Args:\n            controller_info (dict): Dictionary of controller information for the specific robot arm to control\n                with IK\n\n        Returns:\n            dict: Populated keypress mappings for IK to control the specified controller\n        \"\"\"\n        mapping = {}\n\n        mapping[carb.input.KeyboardInput.UP] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": 0.5}\n        mapping[carb.input.KeyboardInput.DOWN] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": -0.5}\n        mapping[carb.input.KeyboardInput.RIGHT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": -0.5}\n        mapping[carb.input.KeyboardInput.LEFT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": 0.5}\n        mapping[carb.input.KeyboardInput.P] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": 0.5}\n        mapping[carb.input.KeyboardInput.SEMICOLON] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": -0.5}\n        mapping[carb.input.KeyboardInput.N] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": 0.5}\n        mapping[carb.input.KeyboardInput.B] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": -0.5}\n        mapping[carb.input.KeyboardInput.O] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": 0.5}\n        mapping[carb.input.KeyboardInput.U] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": -0.5}\n        mapping[carb.input.KeyboardInput.V] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": 0.5}\n        mapping[carb.input.KeyboardInput.C] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": -0.5}\n\n        return mapping\n\n    def populate_keypress_mapping(self):\n        \"\"\"\n        Populates the mapping @self.keypress_mapping, which maps keypresses to action info:\n\n            keypress:\n                idx: &lt;int&gt;\n                val: &lt;float&gt;\n        \"\"\"\n        self.keypress_mapping = {}\n        self.joint_command_idx = []\n        self.joint_control_idx = []\n        self.gripper_direction = {}\n        self.persistent_gripper_action = {}\n\n        # Add mapping for joint control directions (no index because these are inferred at runtime)\n        self.keypress_mapping[carb.input.KeyboardInput.RIGHT_BRACKET] = {\"idx\": None, \"val\": 0.1}\n        self.keypress_mapping[carb.input.KeyboardInput.LEFT_BRACKET] = {\"idx\": None, \"val\": -0.1}\n\n        # Iterate over all controller info and populate mapping\n        for component, info in self.controller_info.items():\n            if info[\"name\"] == \"JointController\":\n                for i in range(info[\"command_dim\"]):\n                    cmd_idx = info[\"start_idx\"] + i\n                    self.joint_command_idx.append(cmd_idx)\n                self.joint_control_idx += info[\"dofs\"].tolist()\n            elif info[\"name\"] == \"DifferentialDriveController\":\n                self.keypress_mapping[carb.input.KeyboardInput.I] = {\"idx\": info[\"start_idx\"] + 0, \"val\": 0.4}\n                self.keypress_mapping[carb.input.KeyboardInput.K] = {\"idx\": info[\"start_idx\"] + 0, \"val\": -0.4}\n                self.keypress_mapping[carb.input.KeyboardInput.L] = {\"idx\": info[\"start_idx\"] + 1, \"val\": -0.2}\n                self.keypress_mapping[carb.input.KeyboardInput.J] = {\"idx\": info[\"start_idx\"] + 1, \"val\": 0.2}\n            elif info[\"name\"] == \"InverseKinematicsController\":\n                self.ik_arms.append(component)\n                self.keypress_mapping.update(self.generate_ik_keypress_mapping(controller_info=info))\n            elif info[\"name\"] == \"MultiFingerGripperController\":\n                if info[\"command_dim\"] &gt; 1:\n                    for i in range(info[\"command_dim\"]):\n                        cmd_idx = info[\"start_idx\"] + i\n                        self.joint_command_idx.append(cmd_idx)\n                    self.joint_control_idx += info[\"dofs\"].tolist()\n                else:\n                    self.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": info[\"start_idx\"], \"val\": 1.0}\n                    self.gripper_direction[component] = 1.0\n                    self.persistent_gripper_action[component] = 1.0\n                    self.binary_grippers.append(component)\n            elif info[\"name\"] == \"NullJointController\":\n                # We won't send actions if using a null gripper controller\n                self.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": None, \"val\": None}\n            else:\n                raise ValueError(\"Unknown controller name received: {}\".format(info[\"name\"]))\n\n    def keyboard_event_handler(self, event, *args, **kwargs):\n        # Check if we've received a key press or repeat\n        if event.type == carb.input.KeyboardEventType.KEY_PRESS \\\n                or event.type == carb.input.KeyboardEventType.KEY_REPEAT:\n\n            # Handle special cases\n            if event.input in {carb.input.KeyboardInput.KEY_1, carb.input.KeyboardInput.KEY_2} and len(self.joint_control_idx) &gt; 1:\n                # Update joint and print out new joint being controlled\n                self.active_joint_command_idx_idx = max(0, self.active_joint_command_idx_idx - 1) \\\n                    if event.input == carb.input.KeyboardInput.KEY_1 \\\n                    else min(len(self.joint_control_idx) - 1, self.active_joint_command_idx_idx + 1)\n                print(f\"Now controlling joint {self.joint_names[self.joint_control_idx[self.active_joint_command_idx_idx]]}\")\n\n            elif event.input in {carb.input.KeyboardInput.KEY_3, carb.input.KeyboardInput.KEY_4} and len(self.ik_arms) &gt; 1:\n                # Update arm, update keypress mapping, and print out new arm being controlled\n                self.active_arm_idx = max(0, self.active_arm_idx - 1) \\\n                    if event.input == carb.input.KeyboardInput.KEY_3 \\\n                    else min(len(self.ik_arms) - 1, self.active_arm_idx + 1)\n                new_arm = self.ik_arms[self.active_arm_idx]\n                self.keypress_mapping.update(self.generate_ik_keypress_mapping(self.controller_info[new_arm]))\n                print(f\"Now controlling arm {new_arm} with IK\")\n\n            elif event.input in {carb.input.KeyboardInput.KEY_5, carb.input.KeyboardInput.KEY_6} and len(self.binary_grippers) &gt; 1:\n                # Update gripper, update keypress mapping, and print out new gripper being controlled\n                self.active_gripper_idx = max(0, self.active_gripper_idx - 1) \\\n                    if event.input == carb.input.KeyboardInput.KEY_5 \\\n                    else min(len(self.binary_grippers) - 1, self.active_gripper_idx + 1)\n                print(f\"Now controlling gripper {self.binary_grippers[self.active_gripper_idx]} with binary toggling\")\n\n            elif event.input == carb.input.KeyboardInput.R:\n                # Render the sensors from the robot's camera and lidar\n                self.robot.visualize_sensors()\n\n            elif event.input == carb.input.KeyboardInput.ESCAPE:\n                # Terminate immediately\n                og.shutdown()\n\n            else:\n                # Handle all other actions and update accordingly\n                self.active_action = self.keypress_mapping.get(event.input, None)\n\n            if event.type == carb.input.KeyboardEventType.KEY_PRESS:\n                # Store the current keypress\n                self.current_keypress = event.input\n\n                # Also store whether we pressed the key for toggling gripper actions\n                if event.input == carb.input.KeyboardInput.T:\n                    self.toggling_gripper = True\n\n        # If we release a key, clear the active action and keypress\n        elif event.type == carb.input.KeyboardEventType.KEY_RELEASE:\n            self.active_action = None\n            self.current_keypress = None\n\n        # Callback always needs to return True\n        return True\n\n    def get_random_action(self):\n        \"\"\"\n        Returns:\n            n-array: Generated random action vector (normalized)\n        \"\"\"\n        return np.random.uniform(-1, 1, self.action_dim)\n\n    def get_teleop_action(self):\n        \"\"\"\n        Returns:\n            n-array: Generated action vector based on received user inputs from the keyboard\n        \"\"\"\n        action = np.zeros(self.action_dim)\n\n        # Handle the action if any key is actively being pressed\n        if self.active_action is not None:\n            idx, val = self.active_action[\"idx\"], self.active_action[\"val\"]\n\n            # Only handle the action if the value is specified\n            if val is not None:\n                # If there is no index, the user is controlling a joint with \"[\" and \"]\"\n                if idx is None:\n                    idx = self.joint_command_idx[self.active_joint_command_idx_idx]\n\n                # Set the action\n                action[idx] = val\n\n        # Possibly set the persistent gripper action\n        if len(self.binary_grippers) &gt; 0 and self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] is not None:\n\n            for i, binary_gripper in enumerate(self.binary_grippers):\n                # Possibly update the stored value if the toggle gripper key has been pressed and\n                # it's the active gripper being controlled\n                if self.toggling_gripper and i == self.active_gripper_idx:\n                    # We toggle the gripper direction or this gripper\n                    self.gripper_direction[binary_gripper] *= -1.0\n                    self.persistent_gripper_action[binary_gripper] = \\\n                        self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] * self.gripper_direction[binary_gripper]\n\n                    # Clear the toggling gripper flag\n                    self.toggling_gripper = False\n\n                # Set the persistent action\n                action[self.controller_info[binary_gripper][\"start_idx\"]] = self.persistent_gripper_action[binary_gripper]\n\n        # Print out the user what is being pressed / controlled\n        sys.stdout.write(\"\\033[K\")\n        keypress_str = self.current_keypress.__str__().split(\".\")[-1]\n        print(\"Pressed {}. Action: {}\".format(keypress_str, action))\n        sys.stdout.write(\"\\033[F\")\n\n        # Return action\n        return action\n\n    @staticmethod\n    def print_keyboard_teleop_info():\n        \"\"\"\n        Prints out relevant information for teleop controlling a robot\n        \"\"\"\n\n        def print_command(char, info):\n            char += \" \" * (10 - len(char))\n            print(\"{}\\t{}\".format(char, info))\n\n        print()\n        print(\"*\" * 30)\n        print(\"Controlling the Robot Using the Keyboard\")\n        print(\"*\" * 30)\n        print()\n        print(\"Joint Control\")\n        print_command(\"1, 2\", \"decrement / increment the joint to control\")\n        print_command(\"[, ]\", \"move the joint backwards, forwards, respectively\")\n        print()\n        print(\"Differential Drive Control\")\n        print_command(\"i, k\", \"turn left, right\")\n        print_command(\"l, j\", \"move forward, backwards\")\n        print()\n        print(\"Inverse Kinematics Control\")\n        print_command(\"3, 4\", \"toggle between the different arm(s) to control\")\n        print_command(u\"\\u2190, \\u2192\", \"translate arm eef along x-axis\")\n        print_command(u\"\\u2191, \\u2193\", \"translate arm eef along y-axis\")\n        print_command(\"p, ;\", \"translate arm eef along z-axis\")\n        print_command(\"n, b\", \"rotate arm eef about x-axis\")\n        print_command(\"o, u\", \"rotate arm eef about y-axis\")\n        print_command(\"v, c\", \"rotate arm eef about z-axis\")\n        print()\n        print(\"Boolean Gripper Control\")\n        print_command(\"5, 6\", \"toggle between the different gripper(s) using binary control\")\n        print_command(\"t\", \"toggle gripper (open/close)\")\n        print()\n        print(\"Sensor Rendering\")\n        print_command(\"r\", \"render the onboard sensors (RGB, Depth, Normals, Instance Segmentation, Occupancy Map\")\n        print()\n        print(\"*\" * 30)\n        print()\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController"},{"title":"<code>__init__(robot)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>robot</code>  <code>BaseRobot</code>  <p>robot to control</p>  required      Source code in <code>utils/ui_utils.py</code> <pre><code>def __init__(self, robot):\n    \"\"\"\n    Args:\n        robot (BaseRobot): robot to control\n    \"\"\"\n    # Store relevant info from robot\n    self.robot = robot\n    self.action_dim = robot.action_dim\n    self.controller_info = OrderedDict()\n    idx = 0\n    for name, controller in robot._controllers.items():\n        self.controller_info[name] = {\n            \"name\": type(controller).__name__,\n            \"start_idx\": idx,\n            \"dofs\": controller.dof_idx,\n            \"command_dim\": controller.command_dim,\n        }\n        idx += controller.command_dim\n\n    # Other persistent variables we need to keep track of\n    self.joint_names = [name for name in robot.joints.keys()]  # Ordered list of joint names belonging to the robot\n    self.joint_command_idx = None   # Indices of joints being directly controlled in the action array\n    self.joint_control_idx = None  # Indices of joints being directly controlled in the actual joint array\n    self.active_joint_command_idx_idx = 0   # Which index within the joint_command_idx variable is being controlled by the user\n    self.current_joint = -1  # Active joint being controlled for joint control\n    self.ik_arms = []               # List of arm controller names to be controlled by IK\n    self.active_arm_idx = 0         # Which index within self.ik_arms is actively being controlled (only relevant for IK)\n    self.binary_grippers = []           # Grippers being controlled using multi-finger binary controller\n    self.active_gripper_idx = 0     # Which index within self.binary_grippers is actively being controlled\n    self.gripper_direction = None  # Flips between -1 and 1, per arm controlled by multi-finger binary control\n    self.persistent_gripper_action = None  # Persistent gripper commands, per arm controlled by multi-finger binary control\n    # i.e.: if using binary gripper control and when no keypress is active, the gripper action should still the last executed gripper action\n    self.keypress_mapping = None    # Maps omni keybindings to information for controlling various parts of the robot\n    self.current_keypress = None    # Current key that is being pressed\n    self.active_action = None       # Current action information based on the current keypress\n    self.toggling_gripper = False   # Whether we should toggle the gripper during the next action\n\n    # Populate the keypress mapping dictionary\n    self.populate_keypress_mapping()\n\n    # Register the keyboard callback function\n    self.register_keyboard_handler()\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.__init__"},{"title":"<code>generate_ik_keypress_mapping(controller_info)</code>","text":"<p>Generates a dictionary for keypress mappings for IK control, based on the inputted @controller_info</p> <p>Parameters:</p>    Name Type Description Default     <code>controller_info</code>  <code>dict</code>  <p>Dictionary of controller information for the specific robot arm to control with IK</p>  required     <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Populated keypress mappings for IK to control the specified controller</p>     Source code in <code>utils/ui_utils.py</code> <pre><code>def generate_ik_keypress_mapping(self, controller_info):\n    \"\"\"\n    Generates a dictionary for keypress mappings for IK control, based on the inputted @controller_info\n\n    Args:\n        controller_info (dict): Dictionary of controller information for the specific robot arm to control\n            with IK\n\n    Returns:\n        dict: Populated keypress mappings for IK to control the specified controller\n    \"\"\"\n    mapping = {}\n\n    mapping[carb.input.KeyboardInput.UP] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": 0.5}\n    mapping[carb.input.KeyboardInput.DOWN] = {\"idx\": controller_info[\"start_idx\"] + 0, \"val\": -0.5}\n    mapping[carb.input.KeyboardInput.RIGHT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": -0.5}\n    mapping[carb.input.KeyboardInput.LEFT] = {\"idx\": controller_info[\"start_idx\"] + 1, \"val\": 0.5}\n    mapping[carb.input.KeyboardInput.P] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": 0.5}\n    mapping[carb.input.KeyboardInput.SEMICOLON] = {\"idx\": controller_info[\"start_idx\"] + 2, \"val\": -0.5}\n    mapping[carb.input.KeyboardInput.N] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": 0.5}\n    mapping[carb.input.KeyboardInput.B] = {\"idx\": controller_info[\"start_idx\"] + 3, \"val\": -0.5}\n    mapping[carb.input.KeyboardInput.O] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": 0.5}\n    mapping[carb.input.KeyboardInput.U] = {\"idx\": controller_info[\"start_idx\"] + 4, \"val\": -0.5}\n    mapping[carb.input.KeyboardInput.V] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": 0.5}\n    mapping[carb.input.KeyboardInput.C] = {\"idx\": controller_info[\"start_idx\"] + 5, \"val\": -0.5}\n\n    return mapping\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.generate_ik_keypress_mapping"},{"title":"<code>get_random_action()</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Generated random action vector (normalized)</p>     Source code in <code>utils/ui_utils.py</code> <pre><code>def get_random_action(self):\n    \"\"\"\n    Returns:\n        n-array: Generated random action vector (normalized)\n    \"\"\"\n    return np.random.uniform(-1, 1, self.action_dim)\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.get_random_action"},{"title":"<code>get_teleop_action()</code>","text":"<p>Returns:</p>    Type Description       <p>n-array: Generated action vector based on received user inputs from the keyboard</p>     Source code in <code>utils/ui_utils.py</code> <pre><code>def get_teleop_action(self):\n    \"\"\"\n    Returns:\n        n-array: Generated action vector based on received user inputs from the keyboard\n    \"\"\"\n    action = np.zeros(self.action_dim)\n\n    # Handle the action if any key is actively being pressed\n    if self.active_action is not None:\n        idx, val = self.active_action[\"idx\"], self.active_action[\"val\"]\n\n        # Only handle the action if the value is specified\n        if val is not None:\n            # If there is no index, the user is controlling a joint with \"[\" and \"]\"\n            if idx is None:\n                idx = self.joint_command_idx[self.active_joint_command_idx_idx]\n\n            # Set the action\n            action[idx] = val\n\n    # Possibly set the persistent gripper action\n    if len(self.binary_grippers) &gt; 0 and self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] is not None:\n\n        for i, binary_gripper in enumerate(self.binary_grippers):\n            # Possibly update the stored value if the toggle gripper key has been pressed and\n            # it's the active gripper being controlled\n            if self.toggling_gripper and i == self.active_gripper_idx:\n                # We toggle the gripper direction or this gripper\n                self.gripper_direction[binary_gripper] *= -1.0\n                self.persistent_gripper_action[binary_gripper] = \\\n                    self.keypress_mapping[carb.input.KeyboardInput.T][\"val\"] * self.gripper_direction[binary_gripper]\n\n                # Clear the toggling gripper flag\n                self.toggling_gripper = False\n\n            # Set the persistent action\n            action[self.controller_info[binary_gripper][\"start_idx\"]] = self.persistent_gripper_action[binary_gripper]\n\n    # Print out the user what is being pressed / controlled\n    sys.stdout.write(\"\\033[K\")\n    keypress_str = self.current_keypress.__str__().split(\".\")[-1]\n    print(\"Pressed {}. Action: {}\".format(keypress_str, action))\n    sys.stdout.write(\"\\033[F\")\n\n    # Return action\n    return action\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.get_teleop_action"},{"title":"<code>populate_keypress_mapping()</code>","text":"<p>Populates the mapping @self.keypress_mapping, which maps keypresses to action info:</p> <pre><code>keypress:\n    idx: &lt;int&gt;\n    val: &lt;float&gt;\n</code></pre>  Source code in <code>utils/ui_utils.py</code> <pre><code>def populate_keypress_mapping(self):\n    \"\"\"\n    Populates the mapping @self.keypress_mapping, which maps keypresses to action info:\n\n        keypress:\n            idx: &lt;int&gt;\n            val: &lt;float&gt;\n    \"\"\"\n    self.keypress_mapping = {}\n    self.joint_command_idx = []\n    self.joint_control_idx = []\n    self.gripper_direction = {}\n    self.persistent_gripper_action = {}\n\n    # Add mapping for joint control directions (no index because these are inferred at runtime)\n    self.keypress_mapping[carb.input.KeyboardInput.RIGHT_BRACKET] = {\"idx\": None, \"val\": 0.1}\n    self.keypress_mapping[carb.input.KeyboardInput.LEFT_BRACKET] = {\"idx\": None, \"val\": -0.1}\n\n    # Iterate over all controller info and populate mapping\n    for component, info in self.controller_info.items():\n        if info[\"name\"] == \"JointController\":\n            for i in range(info[\"command_dim\"]):\n                cmd_idx = info[\"start_idx\"] + i\n                self.joint_command_idx.append(cmd_idx)\n            self.joint_control_idx += info[\"dofs\"].tolist()\n        elif info[\"name\"] == \"DifferentialDriveController\":\n            self.keypress_mapping[carb.input.KeyboardInput.I] = {\"idx\": info[\"start_idx\"] + 0, \"val\": 0.4}\n            self.keypress_mapping[carb.input.KeyboardInput.K] = {\"idx\": info[\"start_idx\"] + 0, \"val\": -0.4}\n            self.keypress_mapping[carb.input.KeyboardInput.L] = {\"idx\": info[\"start_idx\"] + 1, \"val\": -0.2}\n            self.keypress_mapping[carb.input.KeyboardInput.J] = {\"idx\": info[\"start_idx\"] + 1, \"val\": 0.2}\n        elif info[\"name\"] == \"InverseKinematicsController\":\n            self.ik_arms.append(component)\n            self.keypress_mapping.update(self.generate_ik_keypress_mapping(controller_info=info))\n        elif info[\"name\"] == \"MultiFingerGripperController\":\n            if info[\"command_dim\"] &gt; 1:\n                for i in range(info[\"command_dim\"]):\n                    cmd_idx = info[\"start_idx\"] + i\n                    self.joint_command_idx.append(cmd_idx)\n                self.joint_control_idx += info[\"dofs\"].tolist()\n            else:\n                self.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": info[\"start_idx\"], \"val\": 1.0}\n                self.gripper_direction[component] = 1.0\n                self.persistent_gripper_action[component] = 1.0\n                self.binary_grippers.append(component)\n        elif info[\"name\"] == \"NullJointController\":\n            # We won't send actions if using a null gripper controller\n            self.keypress_mapping[carb.input.KeyboardInput.T] = {\"idx\": None, \"val\": None}\n        else:\n            raise ValueError(\"Unknown controller name received: {}\".format(info[\"name\"]))\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.populate_keypress_mapping"},{"title":"<code>print_keyboard_teleop_info()</code>  <code>staticmethod</code>","text":"<p>Prints out relevant information for teleop controlling a robot</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>@staticmethod\ndef print_keyboard_teleop_info():\n    \"\"\"\n    Prints out relevant information for teleop controlling a robot\n    \"\"\"\n\n    def print_command(char, info):\n        char += \" \" * (10 - len(char))\n        print(\"{}\\t{}\".format(char, info))\n\n    print()\n    print(\"*\" * 30)\n    print(\"Controlling the Robot Using the Keyboard\")\n    print(\"*\" * 30)\n    print()\n    print(\"Joint Control\")\n    print_command(\"1, 2\", \"decrement / increment the joint to control\")\n    print_command(\"[, ]\", \"move the joint backwards, forwards, respectively\")\n    print()\n    print(\"Differential Drive Control\")\n    print_command(\"i, k\", \"turn left, right\")\n    print_command(\"l, j\", \"move forward, backwards\")\n    print()\n    print(\"Inverse Kinematics Control\")\n    print_command(\"3, 4\", \"toggle between the different arm(s) to control\")\n    print_command(u\"\\u2190, \\u2192\", \"translate arm eef along x-axis\")\n    print_command(u\"\\u2191, \\u2193\", \"translate arm eef along y-axis\")\n    print_command(\"p, ;\", \"translate arm eef along z-axis\")\n    print_command(\"n, b\", \"rotate arm eef about x-axis\")\n    print_command(\"o, u\", \"rotate arm eef about y-axis\")\n    print_command(\"v, c\", \"rotate arm eef about z-axis\")\n    print()\n    print(\"Boolean Gripper Control\")\n    print_command(\"5, 6\", \"toggle between the different gripper(s) using binary control\")\n    print_command(\"t\", \"toggle gripper (open/close)\")\n    print()\n    print(\"Sensor Rendering\")\n    print_command(\"r\", \"render the onboard sensors (RGB, Depth, Normals, Instance Segmentation, Occupancy Map\")\n    print()\n    print(\"*\" * 30)\n    print()\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.print_keyboard_teleop_info"},{"title":"<code>register_keyboard_handler()</code>","text":"<p>Sets up the keyboard callback functionality with omniverse</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>def register_keyboard_handler(self):\n    \"\"\"\n    Sets up the keyboard callback functionality with omniverse\n    \"\"\"\n    appwindow = omni.appwindow.get_default_app_window()\n    input_interface = carb.input.acquire_input_interface()\n    keyboard = appwindow.get_keyboard()\n    sub_keyboard = input_interface.subscribe_to_keyboard_events(keyboard, self.keyboard_event_handler)\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.KeyboardRobotController.register_keyboard_handler"},{"title":"<code>choose_from_options(options, name, random_selection=False)</code>","text":"<p>Prints out options from a list, and returns the requested option.</p> <p>Parameters:</p>    Name Type Description Default     <code>options</code>  <code>dict or list</code>  <p>options to choose from. If dict, the value entries are assumed to be docstrings explaining the individual options</p>  required    <code>name</code>  <code>str</code>  <p>name of the options</p>  required    <code>random_selection</code>  <code>bool</code>  <p>if the selection is random (for automatic demo execution). Default False</p>  <code>False</code>     <p>Returns:</p>    Name Type Description     <code>str</code>   <p>Requested option</p>     Source code in <code>utils/ui_utils.py</code> <pre><code>def choose_from_options(options, name, random_selection=False):\n    \"\"\"\n    Prints out options from a list, and returns the requested option.\n\n    Args:\n        options (dict or list): options to choose from. If dict, the value entries are assumed to be docstrings\n            explaining the individual options\n        name (str): name of the options\n        random_selection (bool): if the selection is random (for automatic demo execution). Default False\n\n    Returns:\n        str: Requested option\n    \"\"\"\n    # Select robot\n    print(\"\\nHere is a list of available {}s:\\n\".format(name))\n\n    for k, option in enumerate(options):\n        docstring = \": {}\".format(options[option]) if isinstance(options, dict) else \"\"\n        print(\"[{}] {}{}\".format(k + 1, option, docstring))\n    print()\n\n    if not random_selection:\n        try:\n            s = input(\"Choose a {} (enter a number from 1 to {}): \".format(name, len(options)))\n            # parse input into a number within range\n            k = min(max(int(s), 1), len(options)) - 1\n        except:\n            k = 0\n            print(\"Input is not valid. Use {} by default.\".format(list(options)[k]))\n    else:\n        k = random.choice(range(len(options)))\n\n    # Return requested option\n    return list(options)[k]\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.choose_from_options"},{"title":"<code>disclaimer(msg)</code>","text":"<p>Prints a disclaimer message, i.e.: \"We know this doesn't work; it's an omni issue; we expect it to be fixed in the next release!</p>  Source code in <code>utils/ui_utils.py</code> <pre><code>def disclaimer(msg):\n    \"\"\"\n    Prints a disclaimer message, i.e.: \"We know this doesn't work; it's an omni issue; we expect it to be fixed in the\n    next release!\n    \"\"\"\n    if gm.SHOW_DISCLAIMERS:\n        print(\"****** DISCLAIMER ******\")\n        print(\"Isaac Sim / Omniverse has some significant limitations and bugs in its current release.\")\n        print(\"This message has popped up because a potential feature in OmniGibson relies upon a feature in Omniverse that \"\n              \"is yet to be released publically. Currently, the expected behavior may not be fully functional, but \"\n              \"should be resolved by the next Isaac Sim release.\")\n        print(f\"Exact Limitation: {msg}\")\n        print(\"************************\")\n</code></pre>","location":"reference/utils/ui_utils.html#utils.ui_utils.disclaimer"},{"title":"usd_utils","text":"","location":"reference/utils/usd_utils.html"},{"title":"<code>BoundingBoxAPI</code>","text":"<p>Class containing class methods to facilitate bounding box handling</p>  Source code in <code>utils/usd_utils.py</code> <pre><code>class BoundingBoxAPI:\n    \"\"\"\n    Class containing class methods to facilitate bounding box handling\n    \"\"\"\n    CACHE = None\n\n    @classmethod\n    def compute_aabb(cls, prim_path):\n        \"\"\"\n        Computes the AABB (world-frame oriented) for the prim specified at @prim_path\n\n        Args:\n            prim_path (str): Path to the prim to calculate AABB for\n\n        Returns:\n            2-tuple:\n                - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n                - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n        \"\"\"\n        assert not gm.ENABLE_FLATCACHE, f\"Cannot compute aabb bounding boxes with flatcache enabled!\"\n        # Create cache if it doesn't already exist\n        if cls.CACHE is None:\n            cls.CACHE = create_bbox_cache(use_extents_hint=False)\n\n        # Grab aabb\n        aabb = compute_aabb(bbox_cache=cls.CACHE, prim_path=prim_path)\n\n        # Sanity check values\n        if np.any(aabb[3:] &lt; aabb[:3]):\n            raise ValueError(f\"Got invalid aabb values: low={aabb[:3]}, high={aabb[3:]}\")\n\n        return aabb[:3], aabb[3:]\n\n    @classmethod\n    def compute_center_extent(cls, prim_path):\n        \"\"\"\n        Computes the AABB (world-frame oriented) for the prim specified at @prim_path, and convert it into the center\n        and extent values\n\n        Args:\n            prim_path (str): Path to the prim to calculate AABB for\n\n        Returns:\n            2-tuple:\n                - 3-array: center position (x,y,z) of world-coordinate frame aligned bounding box\n                - 3-array: end-to-end extent size (x,y,z) of world-coordinate frame aligned bounding box\n        \"\"\"\n        assert not gm.ENABLE_FLATCACHE, f\"Cannot compute aabb bounding boxes with flatcache enabled!\"\n        low, high = cls.compute_aabb(prim_path=prim_path)\n\n        return (low + high) / 2.0, high - low\n\n    @classmethod\n    def clear(cls):\n        \"\"\"\n        Clears the internal state of this BoundingBoxAPI\n        \"\"\"\n        cls.CACHE = None\n\n    @classmethod\n    def union(cls, prim_paths):\n        \"\"\"\n        Computes the union of AABBs (world-frame oriented) for the prims specified at @prim_paths\n\n        Args:\n            prim_paths (str): Paths to the prims to calculate union AABB for\n\n        Returns:\n            2-tuple:\n                - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n                - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n        \"\"\"\n        # Create cache if it doesn't already exist\n        if cls.CACHE is None:\n            cls.CACHE = create_bbox_cache(use_extents_hint=False)\n\n        # Grab aabb\n        aabb = compute_combined_aabb(bbox_cache=cls.CACHE, prim_paths=prim_paths)\n\n        return aabb[:3], aabb[3:]\n\n    @classmethod\n    def aabb_contains_point(cls, point, container):\n        \"\"\"\n        Returns true if the point is contained in the container AABB\n\n        Args:\n            point (tuple): (x,y,z) position in world-coordinates\n            container (tuple):\n                - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n                - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n\n        Returns:\n            bool: True if AABB contains @point, otherwise False\n        \"\"\"\n        lower, upper = container\n        return np.less_equal(lower, point).all() and np.less_equal(point, upper).all()\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI"},{"title":"<code>aabb_contains_point(point, container)</code>  <code>classmethod</code>","text":"<p>Returns true if the point is contained in the container AABB</p> <p>Parameters:</p>    Name Type Description Default     <code>point</code>  <code>tuple</code>  <p>(x,y,z) position in world-coordinates</p>  required    <code>container</code>  <code>tuple</code>  <ul> <li>3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box</li> <li>3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box</li> </ul>  required     <p>Returns:</p>    Name Type Description     <code>bool</code>   <p>True if AABB contains @point, otherwise False</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>@classmethod\ndef aabb_contains_point(cls, point, container):\n    \"\"\"\n    Returns true if the point is contained in the container AABB\n\n    Args:\n        point (tuple): (x,y,z) position in world-coordinates\n        container (tuple):\n            - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n            - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n\n    Returns:\n        bool: True if AABB contains @point, otherwise False\n    \"\"\"\n    lower, upper = container\n    return np.less_equal(lower, point).all() and np.less_equal(point, upper).all()\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.aabb_contains_point"},{"title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clears the internal state of this BoundingBoxAPI</p>  Source code in <code>utils/usd_utils.py</code> <pre><code>@classmethod\ndef clear(cls):\n    \"\"\"\n    Clears the internal state of this BoundingBoxAPI\n    \"\"\"\n    cls.CACHE = None\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.clear"},{"title":"<code>compute_aabb(prim_path)</code>  <code>classmethod</code>","text":"<p>Computes the AABB (world-frame oriented) for the prim specified at @prim_path</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Path to the prim to calculate AABB for</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>@classmethod\ndef compute_aabb(cls, prim_path):\n    \"\"\"\n    Computes the AABB (world-frame oriented) for the prim specified at @prim_path\n\n    Args:\n        prim_path (str): Path to the prim to calculate AABB for\n\n    Returns:\n        2-tuple:\n            - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n            - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n    \"\"\"\n    assert not gm.ENABLE_FLATCACHE, f\"Cannot compute aabb bounding boxes with flatcache enabled!\"\n    # Create cache if it doesn't already exist\n    if cls.CACHE is None:\n        cls.CACHE = create_bbox_cache(use_extents_hint=False)\n\n    # Grab aabb\n    aabb = compute_aabb(bbox_cache=cls.CACHE, prim_path=prim_path)\n\n    # Sanity check values\n    if np.any(aabb[3:] &lt; aabb[:3]):\n        raise ValueError(f\"Got invalid aabb values: low={aabb[:3]}, high={aabb[3:]}\")\n\n    return aabb[:3], aabb[3:]\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.compute_aabb"},{"title":"<code>compute_center_extent(prim_path)</code>  <code>classmethod</code>","text":"<p>Computes the AABB (world-frame oriented) for the prim specified at @prim_path, and convert it into the center and extent values</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Path to the prim to calculate AABB for</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: center position (x,y,z) of world-coordinate frame aligned bounding box - 3-array: end-to-end extent size (x,y,z) of world-coordinate frame aligned bounding box</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>@classmethod\ndef compute_center_extent(cls, prim_path):\n    \"\"\"\n    Computes the AABB (world-frame oriented) for the prim specified at @prim_path, and convert it into the center\n    and extent values\n\n    Args:\n        prim_path (str): Path to the prim to calculate AABB for\n\n    Returns:\n        2-tuple:\n            - 3-array: center position (x,y,z) of world-coordinate frame aligned bounding box\n            - 3-array: end-to-end extent size (x,y,z) of world-coordinate frame aligned bounding box\n    \"\"\"\n    assert not gm.ENABLE_FLATCACHE, f\"Cannot compute aabb bounding boxes with flatcache enabled!\"\n    low, high = cls.compute_aabb(prim_path=prim_path)\n\n    return (low + high) / 2.0, high - low\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.compute_center_extent"},{"title":"<code>union(prim_paths)</code>  <code>classmethod</code>","text":"<p>Computes the union of AABBs (world-frame oriented) for the prims specified at @prim_paths</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_paths</code>  <code>str</code>  <p>Paths to the prims to calculate union AABB for</p>  required     <p>Returns:</p>    Type Description       <p>2-tuple: - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>@classmethod\ndef union(cls, prim_paths):\n    \"\"\"\n    Computes the union of AABBs (world-frame oriented) for the prims specified at @prim_paths\n\n    Args:\n        prim_paths (str): Paths to the prims to calculate union AABB for\n\n    Returns:\n        2-tuple:\n            - 3-array: start (x,y,z) corner of world-coordinate frame aligned bounding box\n            - 3-array: end (x,y,z) corner of world-coordinate frame aligned bounding box\n    \"\"\"\n    # Create cache if it doesn't already exist\n    if cls.CACHE is None:\n        cls.CACHE = create_bbox_cache(use_extents_hint=False)\n\n    # Grab aabb\n    aabb = compute_combined_aabb(bbox_cache=cls.CACHE, prim_paths=prim_paths)\n\n    return aabb[:3], aabb[3:]\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.BoundingBoxAPI.union"},{"title":"<code>CollisionAPI</code>","text":"<p>Class containing class methods to facilitate collision handling, e.g. collision groups</p>  Source code in <code>utils/usd_utils.py</code> <pre><code>class CollisionAPI:\n    \"\"\"\n    Class containing class methods to facilitate collision handling, e.g. collision groups\n    \"\"\"\n    ACTIVE_COLLISION_GROUPS = {}\n\n    @classmethod\n    def add_to_collision_group(cls, col_group, prim_path, create_if_not_exist=False):\n        \"\"\"\n        Adds the prim and all nested prims specified by @prim_path to the global collision group @col_group. If @col_group\n        does not exist, then it will either be created if @create_if_not_exist is True, otherwise will raise an Error.\n\n        Args:\n            col_group (str): Name of the collision group to assign the prim at @prim_path to\n            prim_path (str): Prim (and all nested prims) to assign to this @col_group\n            create_if_not_exist (bool): True if @col_group should be created if it does not already exist, otherwise an\n                error will be raised\n        \"\"\"\n        # TODO: This slows things down and / or crashes the sim with large number of objects. Skipping this for now, look into this later\n        pass\n        # # Check if collision group exists or not\n        # if col_group not in cls.ACTIVE_COLLISION_GROUPS:\n        #     # Raise error if we don't explicitly want to create a new group\n        #     if not create_if_not_exist:\n        #         raise ValueError(f\"Collision group {col_group} not found in current registry, and create_if_not_exist\"\n        #                          f\"was set to False!\")\n        #     # Otherwise, create the new group\n        #     col_group_name = f\"/World/collisionGroup_{col_group}\"\n        #     group = UsdPhysics.CollisionGroup.Define(get_current_stage(), col_group_name)\n        #     group.GetFilteredGroupsRel().AddTarget(col_group_name)  # Make sure that we can collide within our own group\n        #     cls.ACTIVE_COLLISION_GROUPS[col_group] = group\n        #\n        # # Add this prim to the collision group\n        # cls.ACTIVE_COLLISION_GROUPS[col_group].GetCollidersCollectionAPI().GetIncludesRel().AddTarget(prim_path)\n\n    @classmethod\n    def clear(cls):\n        \"\"\"\n        Clears the internal state of this CollisionAPI\n        \"\"\"\n        cls.ACTIVE_COLLISION_GROUPS = {}\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.CollisionAPI"},{"title":"<code>add_to_collision_group(col_group, prim_path, create_if_not_exist=False)</code>  <code>classmethod</code>","text":"<p>Adds the prim and all nested prims specified by @prim_path to the global collision group @col_group. If @col_group does not exist, then it will either be created if @create_if_not_exist is True, otherwise will raise an Error.</p> <p>Parameters:</p>    Name Type Description Default     <code>col_group</code>  <code>str</code>  <p>Name of the collision group to assign the prim at @prim_path to</p>  required    <code>prim_path</code>  <code>str</code>  <p>Prim (and all nested prims) to assign to this @col_group</p>  required    <code>create_if_not_exist</code>  <code>bool</code>  <p>True if @col_group should be created if it does not already exist, otherwise an error will be raised</p>  <code>False</code>      Source code in <code>utils/usd_utils.py</code> <pre><code>@classmethod\ndef add_to_collision_group(cls, col_group, prim_path, create_if_not_exist=False):\n    \"\"\"\n    Adds the prim and all nested prims specified by @prim_path to the global collision group @col_group. If @col_group\n    does not exist, then it will either be created if @create_if_not_exist is True, otherwise will raise an Error.\n\n    Args:\n        col_group (str): Name of the collision group to assign the prim at @prim_path to\n        prim_path (str): Prim (and all nested prims) to assign to this @col_group\n        create_if_not_exist (bool): True if @col_group should be created if it does not already exist, otherwise an\n            error will be raised\n    \"\"\"\n    # TODO: This slows things down and / or crashes the sim with large number of objects. Skipping this for now, look into this later\n    pass\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.CollisionAPI.add_to_collision_group"},{"title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clears the internal state of this CollisionAPI</p>  Source code in <code>utils/usd_utils.py</code> <pre><code>@classmethod\ndef clear(cls):\n    \"\"\"\n    Clears the internal state of this CollisionAPI\n    \"\"\"\n    cls.ACTIVE_COLLISION_GROUPS = {}\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.CollisionAPI.clear"},{"title":"<code>add_asset_to_stage(asset_path, prim_path)</code>","text":"<p>Adds asset file (either USD or OBJ) at @asset_path at the location @prim_path</p> <p>Parameters:</p>    Name Type Description Default     <code>asset_path</code>  <code>str</code>  <p>Absolute or relative path to the asset file to load</p>  required    <code>prim_path</code>  <code>str</code>  <p>Where loaded asset should exist on the stage</p>  required     <p>Returns:</p>    Type Description       <p>Usd.Prim: Loaded prim as a USD prim</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def add_asset_to_stage(asset_path, prim_path):\n    \"\"\"\n    Adds asset file (either USD or OBJ) at @asset_path at the location @prim_path\n\n    Args:\n        asset_path (str): Absolute or relative path to the asset file to load\n        prim_path (str): Where loaded asset should exist on the stage\n\n    Returns:\n        Usd.Prim: Loaded prim as a USD prim\n    \"\"\"\n    # Make sure this is actually a supported asset type\n    assert asset_path[-4:].lower() in {\".usd\", \".obj\"}, f\"Cannot load a non-USD or non-OBJ file as a USD prim!\"\n    asset_type = asset_path[-3:]\n\n    # Make sure the path exists\n    assert os.path.exists(asset_path), f\"{asset_type.upper()} file {asset_path} does not exist!\"\n\n    # Add reference to stage and grab prim\n    add_reference_to_stage(usd_path=asset_path, prim_path=prim_path)\n    prim = get_prim_at_path(prim_path)\n\n    # Make sure prim was loaded correctly\n    assert prim, f\"Failed to load {asset_type.upper()} object from path: {asset_path}\"\n\n    return prim\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.add_asset_to_stage"},{"title":"<code>array_to_vtarray(arr, element_type)</code>","text":"<p>Converts array @arr into a Vt-typed array, where each individual element of type @element_type.</p> <p>Parameters:</p>    Name Type Description Default     <code>arr</code>  <code>n-array</code>  <p>An array of values. Can be, e.g., a list, or numpy array</p>  required    <code>element_type</code>  <code>type</code>  <p>Per-element type to convert the elements from @arr into. Valid options are keys of GF_TO_VT_MAPPING</p>  required     <p>Returns:</p>    Type Description       <p>Vt.Array: Vt-typed array, of specified type corresponding to @element_type</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def array_to_vtarray(arr, element_type):\n    \"\"\"\n    Converts array @arr into a Vt-typed array, where each individual element of type @element_type.\n\n    Args:\n        arr (n-array): An array of values. Can be, e.g., a list, or numpy array\n        element_type (type): Per-element type to convert the elements from @arr into.\n            Valid options are keys of GF_TO_VT_MAPPING\n\n    Returns:\n        Vt.Array: Vt-typed array, of specified type corresponding to @element_type\n    \"\"\"\n    # Make sure array type is valid\n    assert_valid_key(key=element_type, valid_keys=GF_TO_VT_MAPPING, name=\"array element type\")\n\n    # Construct list of values\n    arr_list = []\n\n    # Check first to see if elements are vectors or not. If this is an iterable value that is not a string,\n    # then this is a vector and we have to map it to the correct type via *\n    is_vec_element = (isinstance(arr[0], Iterable)) and (not isinstance(arr[0], str))\n\n    # Loop over array and set values\n    for ele in arr:\n        arr_list.append(element_type(*ele) if is_vec_element else ele)\n\n    return GF_TO_VT_MAPPING[element_type](arr_list)\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.array_to_vtarray"},{"title":"<code>clear()</code>","text":"<p>Clear state tied to singleton classes</p>  Source code in <code>utils/usd_utils.py</code> <pre><code>def clear():\n    \"\"\"\n    Clear state tied to singleton classes\n    \"\"\"\n    CollisionAPI.clear()\n    BoundingBoxAPI.clear()\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.clear"},{"title":"<code>create_joint(prim_path, joint_type, body0=None, body1=None, enabled=True, stage=None)</code>","text":"<p>Creates a joint between @body0 and @body1 of specified type @joint_type</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>absolute path to where the joint will be created</p>  required    <code>joint_type</code>  <code>str</code>  <p>type of joint to create. Valid options are: \"FixedJoint\", \"Joint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"             (equivalently, one of JointType)</p>  required    <code>body0</code>  <code>str</code>  <p>absolute path to the first body's prim. At least @body0 or @body1 must be specified.</p>  <code>None</code>    <code>body1</code>  <code>str</code>  <p>absolute path to the second body's prim. At least @body0 or @body1 must be specified.</p>  <code>None</code>    <code>enabled</code>  <code>bool</code>  <p>whether to enable this joint or not</p>  <code>True</code>    <code>stage</code>  <code>Usd.Stage</code>  <p>if specified, should be specific stage to be used to load the joint. Otherwise, the current active stage will be used.</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>Usd.Prim: Created joint prim</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def create_joint(prim_path, joint_type, body0=None, body1=None, enabled=True, stage=None):\n    \"\"\"\n    Creates a joint between @body0 and @body1 of specified type @joint_type\n\n    Args:\n        prim_path (str): absolute path to where the joint will be created\n        joint_type (str): type of joint to create. Valid options are:\n            \"FixedJoint\", \"Joint\", \"PrismaticJoint\", \"RevoluteJoint\", \"SphericalJoint\"\n                        (equivalently, one of JointType)\n        body0 (str): absolute path to the first body's prim. At least @body0 or @body1 must be specified.\n        body1 (str): absolute path to the second body's prim. At least @body0 or @body1 must be specified.\n        enabled (bool): whether to enable this joint or not\n        stage (Usd.Stage): if specified, should be specific stage to be used to load the joint.\n            Otherwise, the current active stage will be used.\n\n    Returns:\n        Usd.Prim: Created joint prim\n    \"\"\"\n    # Make sure we have valid joint_type\n    assert JointType.is_valid(joint_type=joint_type), \\\n        f\"Invalid joint specified for creation: {joint_type}\"\n\n    # Make sure at least body0 or body1 is specified\n    assert body0 is not None or body1 is not None, \\\n        f\"At least either body0 or body1 must be specified when creating a joint!\"\n\n    # Define an Xform prim at the current stage, or the simulator's stage if specified\n    stage = get_current_stage() if stage is None else stage\n\n    # Create the joint\n    joint = UsdPhysics.__dict__[joint_type].Define(stage, prim_path)\n\n    # Possibly add body0, body1 targets\n    if body0 is not None:\n        assert is_prim_path_valid(body0), f\"Invalid body0 path specified: {body0}\"\n        joint.GetBody0Rel().SetTargets([Sdf.Path(body0)])\n    if body1 is not None:\n        assert is_prim_path_valid(body1), f\"Invalid body1 path specified: {body1}\"\n        joint.GetBody1Rel().SetTargets([Sdf.Path(body1)])\n\n    # Get the prim pointed to at this path\n    joint_prim = get_prim_at_path(prim_path)\n\n    # Apply joint API interface\n    PhysxSchema.PhysxJointAPI.Apply(joint_prim)\n\n    # Possibly (un-/)enable this joint\n    joint_prim.GetAttribute(\"physics:jointEnabled\").Set(enabled)\n\n    # We need to step rendering once to auto-fill the local pose before overwriting it.\n    og.sim.render()\n\n    # Return this joint\n    return joint_prim\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.create_joint"},{"title":"<code>create_mesh_prim_with_default_xform(primitive_type, prim_path, stage=None, u_patches=None, v_patches=None)</code>","text":"<p>Creates a mesh prim of the specified @primitive_type at the specified @prim_path</p> <p>Parameters:</p>    Name Type Description Default     <code>primitive_type</code>  <code>str</code>  <p>Primitive mesh type, should be one of PRIMITIVE_MESH_TYPES to be valid</p>  required    <code>prim_path</code>  <code>str</code>  <p>Destination prim path to store the mesh prim</p>  required    <code>stage</code>  <code>Usd.Stage or None</code>  <p>If specified, should be specific stage to be used to load the mesh prim. Otherwise, the current active stage will be used.</p>  <code>None</code>    <code>u_patches</code>  <code>int or None</code>  <p>If specified, should be an integer that represents how many segments to create in the u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.</p>  <code>None</code>    <code>v_patches</code>  <code>int or None</code>  <p>If specified, should be an integer that represents how many segments to create in the v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created. Both u_patches and v_patches need to be specified for them to be effective.</p>  <code>None</code>      Source code in <code>utils/usd_utils.py</code> <pre><code>def create_mesh_prim_with_default_xform(primitive_type, prim_path, stage=None, u_patches=None, v_patches=None):\n    \"\"\"\n    Creates a mesh prim of the specified @primitive_type at the specified @prim_path\n\n    Args:\n        primitive_type (str): Primitive mesh type, should be one of PRIMITIVE_MESH_TYPES to be valid\n        prim_path (str): Destination prim path to store the mesh prim\n        stage (Usd.Stage or None): If specified, should be specific stage to be used to load the mesh prim.\n            Otherwise, the current active stage will be used.\n        u_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n        v_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n            Both u_patches and v_patches need to be specified for them to be effective.\n    \"\"\"\n\n    assert primitive_type in PRIMITIVE_MESH_TYPES, \"Invalid primitive mesh type: {primitive_type}\"\n    evaluator = MESH_PRIM_TYPE_TO_EVALUATOR_MAPPING[primitive_type]\n    u_backup = carb.settings.get_settings().get(evaluator.SETTING_U_SCALE)\n    v_backup = carb.settings.get_settings().get(evaluator.SETTING_V_SCALE)\n    hs_backup = carb.settings.get_settings().get(evaluator.SETTING_OBJECT_HALF_SCALE)\n    carb.settings.get_settings().set(evaluator.SETTING_U_SCALE, 1)\n    carb.settings.get_settings().set(evaluator.SETTING_V_SCALE, 1)\n\n    # Default half_scale (i.e. half-extent, half_height, radius) is 1.\n    # TODO (eric): change it to 0.5 once the mesh generator API accepts floating-number HALF_SCALE\n    #  (currently it only accepts integer-number and floors 0.5 into 0).\n    carb.settings.get_settings().set(evaluator.SETTING_OBJECT_HALF_SCALE, 1)\n\n    stage = get_current_stage() if stage is None else stage\n    prim_path_from = Sdf.Path(omni.usd.get_stage_next_free_path(stage, primitive_type, True))\n    if u_patches is not None and v_patches is not None:\n        omni.kit.commands.execute(\n            \"CreateMeshPrimWithDefaultXform\",\n            prim_type=primitive_type,\n            u_patches=u_patches,\n            v_patches=v_patches,\n        )\n    else:\n        omni.kit.commands.execute(\n            \"CreateMeshPrimWithDefaultXform\",\n            prim_type=primitive_type,\n        )\n    omni.kit.commands.execute(\"MovePrim\", path_from=prim_path_from, path_to=prim_path)\n\n    carb.settings.get_settings().set(evaluator.SETTING_U_SCALE, u_backup)\n    carb.settings.get_settings().set(evaluator.SETTING_V_SCALE, v_backup)\n    carb.settings.get_settings().set(evaluator.SETTING_OBJECT_HALF_SCALE, hs_backup)\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.create_mesh_prim_with_default_xform"},{"title":"<code>create_primitive_mesh(prim_path, primitive_type, extents=1.0, u_patches=None, v_patches=None)</code>","text":"<p>Helper function that generates a UsdGeom.Mesh prim at specified @prim_path of type @primitive_type.</p> <p>NOTE: Generated mesh prim will, by default, have extents equaling [1, 1, 1]</p> <p>Parameters:</p>    Name Type Description Default     <code>prim_path</code>  <code>str</code>  <p>Where the loaded mesh should exist on the stage</p>  required    <code>primitive_type</code>  <code>str</code>  <p>Type of primitive mesh to create. Should be one of:</p>  required    <code>extents</code>  <code>float or 3-array</code>  <p>Specifies the extents of the generated mesh. Default is 1.0, i.e.: generated mesh will be in be contained in a [1,1,1] sized bounding box</p>  <code>1.0</code>    <code>u_patches</code>  <code>int or None</code>  <p>If specified, should be an integer that represents how many segments to create in the u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.</p>  <code>None</code>    <code>v_patches</code>  <code>int or None</code>  <p>If specified, should be an integer that represents how many segments to create in the v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created. Both u_patches and v_patches need to be specified for them to be effective.</p>  <code>None</code>     <p>Returns:</p>    Type Description       <p>UsdGeom.Mesh: Generated primitive mesh as a prim on the active stage</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def create_primitive_mesh(prim_path, primitive_type, extents=1.0, u_patches=None, v_patches=None):\n    \"\"\"\n    Helper function that generates a UsdGeom.Mesh prim at specified @prim_path of type @primitive_type.\n\n    NOTE: Generated mesh prim will, by default, have extents equaling [1, 1, 1]\n\n    Args:\n        prim_path (str): Where the loaded mesh should exist on the stage\n        primitive_type (str): Type of primitive mesh to create. Should be one of:\n            {\"Cone\", \"Cube\", \"Cylinder\", \"Disk\", \"Plane\", \"Sphere\", \"Torus\"}\n        extents (float or 3-array): Specifies the extents of the generated mesh. Default is 1.0, i.e.:\n            generated mesh will be in be contained in a [1,1,1] sized bounding box\n        u_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            u-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n        v_patches (int or None): If specified, should be an integer that represents how many segments to create in the\n            v-direction. E.g. 10 means 10 segments (and therefore 11 vertices) will be created.\n            Both u_patches and v_patches need to be specified for them to be effective.\n\n    Returns:\n        UsdGeom.Mesh: Generated primitive mesh as a prim on the active stage\n    \"\"\"\n    assert_valid_key(key=primitive_type, valid_keys=PRIMITIVE_MESH_TYPES, name=\"primitive mesh type\")\n    create_mesh_prim_with_default_xform(primitive_type, prim_path, stage=og.sim.stage, u_patches=u_patches, v_patches=v_patches)\n    mesh = UsdGeom.Mesh.Define(og.sim.stage, prim_path)\n\n    # Modify the points and normals attributes so that total extents is the desired\n    # This means multiplying omni's default by extents / 2.0\n    extents = np.ones(3) * extents if isinstance(extents, float) else np.array(extents)\n    for attr in (mesh.GetPointsAttr(), mesh.GetNormalsAttr()):\n        vals = np.array(attr.Get()).astype(np.float64)\n        attr.Set(Vt.Vec3fArray([Gf.Vec3f(*(val * extents / 2.0)) for val in vals]))\n\n    return mesh\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.create_primitive_mesh"},{"title":"<code>get_camera_params(viewport)</code>","text":"<p>Get active camera intrinsic and extrinsic parameters.</p> <p>Returns:</p>    Name Type Description     <code>dict</code>   <p>Keyword-mapped values of the active camera's parameters:</p> <p>pose (numpy.ndarray): camera position in world coordinates, fov (float): horizontal field of view in radians focal_length (float) horizontal_aperture (float) view_projection_matrix (numpy.ndarray(dtype=float64, shape=(4, 4))) resolution (dict): resolution as a dict with 'width' and 'height'. clipping_range (tuple(float, float)): Near and Far clipping values.</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def get_camera_params(viewport):\n    \"\"\"\n    Get active camera intrinsic and extrinsic parameters.\n\n    Returns:\n        dict: Keyword-mapped values of the active camera's parameters:\n\n            pose (numpy.ndarray): camera position in world coordinates,\n            fov (float): horizontal field of view in radians\n            focal_length (float)\n            horizontal_aperture (float)\n            view_projection_matrix (numpy.ndarray(dtype=float64, shape=(4, 4)))\n            resolution (dict): resolution as a dict with 'width' and 'height'.\n            clipping_range (tuple(float, float)): Near and Far clipping values.\n    \"\"\"\n    stage = omni.usd.get_context().get_stage()\n    prim = stage.GetPrimAtPath(viewport.get_active_camera())\n    prim_tf = omni.usd.get_world_transform_matrix(prim)\n    view_params = helpers.get_view_params(viewport)\n    fov = 2 * math.atan(view_params[\"horizontal_aperture\"] / (2 * view_params[\"focal_length\"]))\n    view_proj_mat = helpers.get_view_proj_mat(view_params)\n\n    return {\n        \"pose\": np.array(prim_tf),\n        \"fov\": fov,\n        \"focal_length\": view_params[\"focal_length\"],\n        \"horizontal_aperture\": view_params[\"horizontal_aperture\"],\n        \"view_projection_matrix\": view_proj_mat,\n        \"resolution\": {\"width\": view_params[\"width\"], \"height\": view_params[\"height\"]},\n        \"clipping_range\": view_params[\"clipping_range\"],\n    }\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.get_camera_params"},{"title":"<code>get_prim_nested_children(prim)</code>","text":"<p>Grabs all nested prims starting from root @prim via depth-first-search</p> <p>Parameters:</p>    Name Type Description Default     <code>prim</code>  <code>Usd.Prim</code>  <p>root prim from which to search for nested children prims</p>  required     <p>Returns:</p>    Type Description       <p>list of Usd.Prim: nested prims</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def get_prim_nested_children(prim):\n    \"\"\"\n    Grabs all nested prims starting from root @prim via depth-first-search\n\n    Args:\n        prim (Usd.Prim): root prim from which to search for nested children prims\n\n    Returns:\n        list of Usd.Prim: nested prims\n    \"\"\"\n    prims = []\n    for child in get_prim_children(prim):\n        prims.append(child)\n        prims += get_prim_nested_children(prim=child)\n\n    return prims\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.get_prim_nested_children"},{"title":"<code>get_semantic_objects_pose()</code>","text":"<p>Get pose of all objects with a semantic label.</p>  Source code in <code>utils/usd_utils.py</code> <pre><code>def get_semantic_objects_pose():\n    \"\"\"\n    Get pose of all objects with a semantic label.\n    \"\"\"\n    stage = omni.usd.get_context().get_stage()\n    mappings = helpers.get_instance_mappings()\n    pose = []\n    for m in mappings:\n        prim_path = m[1]\n        prim = stage.GetPrimAtPath(prim_path)\n        prim_tf = omni.usd.get_world_transform_matrix(prim)\n        pose.append((str(prim_path), m[2], str(m[3]), np.array(prim_tf)))\n    return pose\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.get_semantic_objects_pose"},{"title":"<code>get_world_prim()</code>","text":"<p>Returns:</p>    Type Description       <p>Usd.Prim: Active world prim in the current stage</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def get_world_prim():\n    \"\"\"\n    Returns:\n        Usd.Prim: Active world prim in the current stage\n    \"\"\"\n    return get_prim_at_path(\"/World\")\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.get_world_prim"},{"title":"<code>mesh_prim_to_trimesh_mesh(mesh_prim)</code>","text":"<p>Generates trimesh mesh from @mesh_prim</p> <p>Parameters:</p>    Name Type Description Default     <code>mesh_prim</code>  <code>Usd.Prim</code>  <p>Mesh prim to convert into trimesh mesh</p>  required     <p>Returns:</p>    Type Description       <p>trimesh.Trimesh: Generated trimesh mesh</p>     Source code in <code>utils/usd_utils.py</code> <pre><code>def mesh_prim_to_trimesh_mesh(mesh_prim):\n    \"\"\"\n    Generates trimesh mesh from @mesh_prim\n\n    Args:\n        mesh_prim (Usd.Prim): Mesh prim to convert into trimesh mesh\n\n    Returns:\n        trimesh.Trimesh: Generated trimesh mesh\n    \"\"\"\n    face_vertex_counts = np.array(mesh_prim.GetAttribute(\"faceVertexCounts\").Get())\n    vertices = np.array(mesh_prim.GetAttribute(\"points\").Get())\n    face_indices = np.array(mesh_prim.GetAttribute(\"faceVertexIndices\").Get())\n\n    faces = []\n    i = 0\n    for count in face_vertex_counts:\n        for j in range(count - 2):\n            faces.append([face_indices[i], face_indices[i + j + 1], face_indices[i + j + 2]])\n        i += count\n\n    return trimesh.Trimesh(vertices=vertices, faces=faces)\n</code></pre>","location":"reference/utils/usd_utils.html#utils.usd_utils.mesh_prim_to_trimesh_mesh"},{"title":"vision_utils","text":"","location":"reference/utils/vision_utils.html"},{"title":"<code>RandomScale</code>","text":"<p>Rescale the input PIL.Image to the given size.</p> <p>Parameters:</p>    Name Type Description Default     <code>minsize</code>  <code>sequence or int</code>  <p>Desired min output size. If size is a sequence like (w, h), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height &gt; width, then image will be rescaled to (size * height / width, size)</p>  required    <code>maxsize</code>  <code>sequence or int</code>  <p>Desired max output size. If size is a sequence like (w, h), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height &gt; width, then image will be rescaled to (size * height / width, size)</p>  required    <code>interpolation</code>  <code>int</code>  <p>Desired interpolation. Default is <code>PIL.Image.BILINEAR</code></p>  <code>Image.BILINEAR</code>      Source code in <code>utils/vision_utils.py</code> <pre><code>class RandomScale:\n    \"\"\"Rescale the input PIL.Image to the given size.\n    Args:\n        minsize (sequence or int): Desired min output size. If size is a sequence like\n            (w, h), output size will be matched to this. If size is an int,\n            smaller edge of the image will be matched to this number.\n            i.e, if height &gt; width, then image will be rescaled to\n            (size * height / width, size)\n        maxsize (sequence or int): Desired max output size. If size is a sequence like\n            (w, h), output size will be matched to this. If size is an int,\n            smaller edge of the image will be matched to this number.\n            i.e, if height &gt; width, then image will be rescaled to\n            (size * height / width, size)\n        interpolation (int, optional): Desired interpolation. Default is ``PIL.Image.BILINEAR``\n    \"\"\"\n\n    def __init__(self, minsize, maxsize, interpolation=Image.BILINEAR):\n        assert isinstance(minsize, int)\n        assert isinstance(maxsize, int)\n        self.minsize = minsize\n        self.maxsize = maxsize\n        self.interpolation = interpolation\n\n    def __call__(self, img):\n        \"\"\"\n        Args:\n            img (PIL.Image): Image to be scaled.\n\n        Returns:\n            PIL.Image: Rescaled image.\n        \"\"\"\n\n        size = random.randint(self.minsize, self.maxsize)\n\n        if isinstance(size, int):\n            w, h = img.size\n            if (w &lt;= h and w == size) or (h &lt;= w and h == size):\n                return img\n            if w &lt; h:\n                ow = size\n                oh = int(size * h / w)\n                return img.resize((ow, oh), self.interpolation)\n            else:\n                oh = size\n                ow = int(size * w / h)\n                return img.resize((ow, oh), self.interpolation)\n        else:\n            raise NotImplementedError()\n</code></pre>","location":"reference/utils/vision_utils.html#utils.vision_utils.RandomScale"},{"title":"<code>__call__(img)</code>","text":"<p>Parameters:</p>    Name Type Description Default     <code>img</code>  <code>PIL.Image</code>  <p>Image to be scaled.</p>  required     <p>Returns:</p>    Type Description       <p>PIL.Image: Rescaled image.</p>     Source code in <code>utils/vision_utils.py</code> <pre><code>def __call__(self, img):\n    \"\"\"\n    Args:\n        img (PIL.Image): Image to be scaled.\n\n    Returns:\n        PIL.Image: Rescaled image.\n    \"\"\"\n\n    size = random.randint(self.minsize, self.maxsize)\n\n    if isinstance(size, int):\n        w, h = img.size\n        if (w &lt;= h and w == size) or (h &lt;= w and h == size):\n            return img\n        if w &lt; h:\n            ow = size\n            oh = int(size * h / w)\n            return img.resize((ow, oh), self.interpolation)\n        else:\n            oh = size\n            ow = int(size * w / h)\n            return img.resize((ow, oh), self.interpolation)\n    else:\n        raise NotImplementedError()\n</code></pre>","location":"reference/utils/vision_utils.html#utils.vision_utils.RandomScale.__call__"},{"title":"<code>randomize_colors(N, bright=True)</code>","text":"<p>Modified from https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py#L59 Generate random colors. To get visually distinct colors, generate them in HSV space then convert to RGB.</p> <p>Parameters:</p>    Name Type Description Default     <code>N</code>  <code>int</code>  <p>Number of colors to generate</p>  required     <p>Returns:</p>    Name Type Description     <code>bright</code>  <code>bool</code>  <p>whether to increase the brightness of the colors or not</p>     Source code in <code>utils/vision_utils.py</code> <pre><code>def randomize_colors(N, bright=True):\n    \"\"\"\n    Modified from https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py#L59\n    Generate random colors.\n    To get visually distinct colors, generate them in HSV space then\n    convert to RGB.\n\n    Args:\n        N (int): Number of colors to generate\n\n    Returns:\n        bright (bool): whether to increase the brightness of the colors or not\n    \"\"\"\n    brightness = 1.0 if bright else 0.5\n    hsv = [(1.0 * i / N, 1, brightness) for i in range(N)]\n    colors = np.array(list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv)))\n    rstate = np.random.RandomState(seed=20)\n    np.random.shuffle(colors)\n    colors[0] = [0, 0, 0]  # First color is black\n    return colors\n</code></pre>","location":"reference/utils/vision_utils.html#utils.vision_utils.randomize_colors"},{"title":"<code>segmentation_to_rgb(seg_im, N, colors=None)</code>","text":"<p>Helper function to visualize segmentations as RGB frames. NOTE: assumes that geom IDs go up to N at most - if not, multiple geoms might be assigned to the same color.</p> <p>Parameters:</p>    Name Type Description Default     <code>seg_im</code>  <code>W, H)-array</code>  <p>Segmentation image</p>  required    <code>N</code>  <code>int</code>  <p>Maximum segmentation ID from @seg_im</p>  required    <code>colors</code>  <code>None or list of 3-array</code>  <p>If specified, colors to apply to different segmentation IDs. Otherwise, will be generated randomly</p>  <code>None</code>      Source code in <code>utils/vision_utils.py</code> <pre><code>def segmentation_to_rgb(seg_im, N, colors=None):\n    \"\"\"\n    Helper function to visualize segmentations as RGB frames.\n    NOTE: assumes that geom IDs go up to N at most - if not,\n    multiple geoms might be assigned to the same color.\n\n    Args:\n        seg_im ((W, H)-array): Segmentation image\n        N (int): Maximum segmentation ID from @seg_im\n        colors (None or list of 3-array): If specified, colors to apply\n            to different segmentation IDs. Otherwise, will be generated randomly\n    \"\"\"\n    # ensure all values lie within [0, N]\n    seg_im = np.mod(seg_im, N)\n\n    if colors is None:\n        use_colors = randomize_colors(N=N, bright=True)\n    else:\n        use_colors = colors\n\n    if N &lt;= 256:\n        return (255.0 * use_colors[seg_im]).astype(np.uint8)\n    else:\n        return (use_colors[seg_im]).astype(np.float)\n</code></pre>","location":"reference/utils/vision_utils.html#utils.vision_utils.segmentation_to_rgb"},{"title":"wrappers","text":"","location":"reference/wrappers/index.html"},{"title":"wrapper_base","text":"<p>This file contains the base wrapper class for OmnOmniGibson environments Wrappers are useful for data collection and logging. Highly recommended.</p>","location":"reference/wrappers/wrapper_base.html"},{"title":"<code>BaseWrapper</code>","text":"<p>Base class for all wrappers in OmniGibson</p> <p>Parameters:</p>    Name Type Description Default     <code>env</code>  <code>OmniGibsonEnv</code>  <p>The environment to wrap.</p>  required      Source code in <code>wrappers/wrapper_base.py</code> <pre><code>class BaseWrapper:\n    \"\"\"\n    Base class for all wrappers in OmniGibson\n\n    Args:\n        env (OmniGibsonEnv): The environment to wrap.\n    \"\"\"\n\n    def __init__(self, env):\n        self.env = env\n\n    @classmethod\n    def class_name(cls):\n        return cls.__name__\n\n    def _warn_double_wrap(self):\n        \"\"\"\n        Utility function that checks if we're accidentally trying to double wrap an env\n        Raises:\n            Exception: [Double wrapping env]\n        \"\"\"\n        env = self.env\n        while True:\n            if isinstance(env, BaseWrapper):\n                if env.class_name() == self.class_name():\n                    raise Exception(\"Attempted to double wrap with Wrapper: {}\".format(self.__class__.__name__))\n                env = env.env\n            else:\n                break\n\n    def step(self, action):\n        \"\"\"\n        By default, run the normal environment step() function\n        Args:\n            action (np.array): action to take in environment\n        Returns:\n            4-tuple:\n                - (OrderedDict) observations from the environment\n                - (float) reward from the environment\n                - (bool) whether the current episode is completed or not\n                - (dict) misc information\n        \"\"\"\n        return self.env.step(action)\n\n    def reset(self):\n        \"\"\"\n        By default, run the normal environment reset() function\n        Returns:\n            OrderedDict: Environment observation space after reset occurs\n        \"\"\"\n        return self.env.reset()\n\n    def observation_spec(self):\n        \"\"\"\n        By default, grabs the normal environment observation_spec\n        Returns:\n            OrderedDict: Observations from the environment\n        \"\"\"\n        return self.env.observation_spec()\n\n    @property\n    def unwrapped(self):\n        \"\"\"\n        Grabs unwrapped environment\n        Returns:\n            env (OmniGibsonEnv): The unwrapped environment\n        \"\"\"\n        if hasattr(self.env, \"unwrapped\"):\n            return self.env.unwrapped\n        else:\n            return self.env\n\n    # this method is a fallback option on any methods the original env might support\n    def __getattr__(self, attr):\n        # using getattr ensures that both __getattribute__ and __getattr__ (fallback) get called\n        # (see https://stackoverflow.com/questions/3278077/difference-between-getattr-vs-getattribute)\n        orig_attr = getattr(self.env, attr)\n        if callable(orig_attr):\n            def hooked(*args, **kwargs):\n                result = orig_attr(*args, **kwargs)\n                # prevent wrapped_class from becoming unwrapped\n                if result == self.env:\n                    return self\n                return result\n            return hooked\n        else:\n            return orig_attr\n</code></pre>","location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper"},{"title":"<code>unwrapped</code>  <code>property</code>","text":"<p>Grabs unwrapped environment</p> <p>Returns:</p>    Name Type Description     <code>env</code>  <code>OmniGibsonEnv</code>  <p>The unwrapped environment</p>","location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.unwrapped"},{"title":"<code>observation_spec()</code>","text":"<p>By default, grabs the normal environment observation_spec</p> <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Observations from the environment</p>     Source code in <code>wrappers/wrapper_base.py</code> <pre><code>def observation_spec(self):\n    \"\"\"\n    By default, grabs the normal environment observation_spec\n    Returns:\n        OrderedDict: Observations from the environment\n    \"\"\"\n    return self.env.observation_spec()\n</code></pre>","location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.observation_spec"},{"title":"<code>reset()</code>","text":"<p>By default, run the normal environment reset() function</p> <p>Returns:</p>    Name Type Description     <code>OrderedDict</code>   <p>Environment observation space after reset occurs</p>     Source code in <code>wrappers/wrapper_base.py</code> <pre><code>def reset(self):\n    \"\"\"\n    By default, run the normal environment reset() function\n    Returns:\n        OrderedDict: Environment observation space after reset occurs\n    \"\"\"\n    return self.env.reset()\n</code></pre>","location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.reset"},{"title":"<code>step(action)</code>","text":"<p>By default, run the normal environment step() function</p> <p>Parameters:</p>    Name Type Description Default     <code>action</code>  <code>np.array</code>  <p>action to take in environment</p>  required     <p>Returns:</p>    Type Description       <p>4-tuple: - (OrderedDict) observations from the environment - (float) reward from the environment - (bool) whether the current episode is completed or not - (dict) misc information</p>     Source code in <code>wrappers/wrapper_base.py</code> <pre><code>def step(self, action):\n    \"\"\"\n    By default, run the normal environment step() function\n    Args:\n        action (np.array): action to take in environment\n    Returns:\n        4-tuple:\n            - (OrderedDict) observations from the environment\n            - (float) reward from the environment\n            - (bool) whether the current episode is completed or not\n            - (dict) misc information\n    \"\"\"\n    return self.env.step(action)\n</code></pre>","location":"reference/wrappers/wrapper_base.html#wrappers.wrapper_base.BaseWrapper.step"},{"title":"Index","text":"","location":"src/examples/index.html"},{"title":"Code Examples","text":"<p>The following examples illustrate the use of OmniGibson.</p> <p>If you are interested in just getting started as an end-user, you only need check out <code>./environments</code>.</p> <p>If you are looking for examples of BEHAVIOR, the benchmark of household activities that uses OmniGibson, please check the BEHAVIOR repository at https://github.com/StanfordVL/behavior.</p> <ul> <li>environments: how to instantiate OmniGibson environments with interactive or static scenes, optionally with a scene selector.</li> <li>learning: how to train RL policies for robot navigation using stable baselines 3, and how to save and replay demos of agents for imitation learning.</li> <li>objects: how to create, load, and place objects to predefined locations or using a logic sampler (e.g. onTop(A, B)), how to change texture as a function of the temperature, and how to generate the minimum volume bounding boxes of objects.</li> <li>object_states: how to change various objects states, including dusty, stained, (water sources) toggled on, (cleaning tool) soaked, sliced, and temprature, and how to save and reload object states.</li> <li>observations: how to generate different observation modalities such as RGB, depth, LiDAR, segmentation, etc.</li> <li>renderer: how to use the renderer directly, without the physics engine.</li> <li>robots: how to (keyboard) control robots with differential drive controllers, IK controllers and sampling-based motion planners.</li> <li>ros: how to run ROS with OmniGibson as if it is the real world.</li> <li>scenes: how to load interactive and non-interactive scenes, how to use domain randomization (of object models and/or texture), and how to create a tour video of the scenes.</li> <li>vr: how to use OmniGibson with VR.</li> <li>web_ui: how to start a web server that hosts OmniGibson environments.</li> </ul>","location":"src/examples/index.html#code-examples"}]}