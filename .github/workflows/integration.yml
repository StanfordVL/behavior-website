name: Update Integration

on:
  schedule:
    - cron: "0 * * * *"  # Every hour
  workflow_dispatch:
  push: 

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"

jobs:
  update:
    runs-on: [self-hosted, linux]

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      # Checkout all repos
      - name: Checkout integration repo
        uses: actions/checkout@v3
        with:
          path: b1k-integration

      - name: Clone BDDL Repo
        uses: actions/checkout@v3
        with:
          repository: StanfordVL/bddl
          path: bddl
          ref: develop

      - name: Clone ig pipeline Repo
        uses: actions/checkout@v3
        with:
          repository: StanfordVL/ig_pipeline
          path: ig_pipeline
          token: ${{ secrets.REPO_TOKEN }}

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: "3.8"
          architecture: x64

      # See if we need to re-pull any ig_pipeline data from DVC.
      - name: Check cache for ig_pipeline data
        id: cache-pipeline
        uses: actions/cache@v3
        with:
          key: ig_pipeline-${{ hashFiles('ig_pipeline/dvc.lock') }}
          path: |
            ig_pipeline/artifacts/pipeline/combined_room_object_list.json
            ig_pipeline/artifacts/pipeline/combined_room_object_list_future.json
            ig_pipeline/artifacts/pipeline/object_inventory.json
            ig_pipeline/artifacts/pipeline/object_inventory_future.json

      - if: ${{ steps.cache-pipeline.outputs.cache-hit != 'true' }}
        name: Install dvc
        run: pip install dvc[gs]

      - if: ${{ steps.cache-pipeline.outputs.cache-hit != 'true' }}
        name: Authenticate on Google Cloud
        uses: 'google-github-actions/auth@v1'
        with:
          credentials_json: '${{ secrets.GCP_CREDENTIALS }}'

      - if: ${{ steps.cache-pipeline.outputs.cache-hit != 'true' }}
        name: Pull dvc data
        working-directory: ig_pipeline
        run: dvc pull combined_room_object_list combined_room_object_list_future object_inventory object_inventory_future

      - if: ${{ steps.cache-pipeline.outputs.cache-hit != 'true' }}
        name: Unprotect images
        working-directory: ig_pipeline
        run: dvc unprotect artifacts/pipeline/combined_room_object_list.json artifacts/pipeline/combined_room_object_list_future.json artifacts/pipeline/object_inventory.json artifacts/pipeline/object_inventory_future.json

      # See if we need to rebuild the whole thing
      - name: Get BDDL hash
        id: bddl-hash
        working-directory: bddl
        run: echo hash=$(git rev-parse HEAD) >> "$GITHUB_OUTPUT"

      - name: Get b1k-integration hash
        id: b1k-integration-hash
        working-directory: b1k-integration
        run: echo hash=$(git rev-parse HEAD) >> "$GITHUB_OUTPUT"

      - name: Check cache for overall data
        id: cache-integration
        uses: actions/cache@v3
        with:
          key: integration-${{ steps.b1k-integration-hash.outputs.hash }}-${{ steps.bddl-hash.outputs.hash }}-${{ hashFiles('ig_pipeline/artifacts/pipeline/combined_room_object_list.json', 'ig_pipeline/artifacts/pipeline/combined_room_object_list_future.json', 'ig_pipeline/artifacts/pipeline/object_inventory.json', 'ig_pipeline/artifacts/pipeline/object_inventory_future.json') }}
          path: README.md
          lookup-only: true

      # Rebuild if necessary
      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: Install BDDL
        working-directory: bddl
        run: pip install -e .

      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: Install other dependencies
        working-directory: b1k-integration
        run: pip install -r requirements.txt

      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: Build database
        working-directory: b1k-integration
        run: python manage.py makemigrations data && python manage.py migrate && python manage.py update

      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: Start local server
        working-directory: b1k-integration
        run: python manage.py runserver &

      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: freeze static files
        working-directory: b1k-integration
        run: wget -mpEk http://localhost:8000/b1k-integration/
        
      - name: kill local server
        if: success() || failure() 
        run: kill $(lsof -t -i:8000) || true
      
      # Deploy to github pages
      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: Setup Pages
        uses: actions/configure-pages@v3

      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: Upload artifact
        uses: actions/upload-pages-artifact@v1
        with:
          path: b1k-integration/localhost:8000/b1k-integration

      - if: ${{ steps.cache-integration.outputs.cache-hit != 'true' }}
        name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v2

